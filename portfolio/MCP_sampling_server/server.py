"""
Servidor MCP Multi-Turn con Sampling
====================================

Este servidor demuestra cÃ³mo implementar interacciones multi-turn usando sampling
para solicitar completions de AI del cliente durante la ejecuciÃ³n de herramientas.

Funcionalidades implementadas:
1. GeneraciÃ³n de contenido asistida por AI
2. AnÃ¡lisis de texto con IA
3. CreaciÃ³n de cÃ³digo con AI
4. TraducciÃ³n inteligente
5. Resumen de documentos
6. CombinaciÃ³n de elicitaciÃ³n + sampling

Uso:
    python server.py
"""

import asyncio
import json
from typing import Any, Dict, List, Optional
from datetime import datetime
from enum import Enum

from fastmcp import FastMCP, Context
from fastmcp.server.elicitation import AcceptedElicitation, DeclinedElicitation, CancelledElicitation
from mcp.types import TextContent

# Instancia del servidor MCP
mcp = FastMCP("Multi-Turn Sampling Server")

# Enumeraciones
class ContentType(str, Enum):
    ARTICLE = "artÃ­culo"
    EMAIL = "email"
    BLOG_POST = "blog post"
    DOCUMENTATION = "documentaciÃ³n"
    SOCIAL_MEDIA = "social media"

class ProgrammingLanguage(str, Enum):
    PYTHON = "python"
    JAVASCRIPT = "javascript"
    TYPESCRIPT = "typescript"
    JAVA = "java"
    GO = "go"
    RUST = "rust"

# Storage temporal para contenido generado
generated_content: Dict[str, Dict[str, Any]] = {}

@mcp.tool
async def ai_content_generator(context: Context) -> str:
    """
    Generador de contenido que usa AI sampling para crear textos personalizados.
    Combina elicitaciÃ³n para obtener parÃ¡metros y sampling para generar contenido.
    """
    # Paso 1: Elicitar el tipo de contenido
    content_type_result = await context.elicit(
        message="Â¿QuÃ© tipo de contenido quieres generar?",
        response_type=ContentType
    )
    
    if not isinstance(content_type_result, AcceptedElicitation):
        return "ğŸš« GeneraciÃ³n cancelada: No se especificÃ³ tipo de contenido"
    
    content_type = content_type_result.data.value
    
    # Paso 2: Obtener el tema
    topic_result = await context.elicit(
        message=f"Â¿Sobre quÃ© tema quieres que genere el {content_type}?",
        response_type=str
    )
    
    if not isinstance(topic_result, AcceptedElicitation):
        return f"âš ï¸ GeneraciÃ³n parcial: Solo se configurÃ³ el tipo '{content_type}'"
    
    topic = topic_result.data
    
    # Paso 3: Obtener audiencia objetivo (opcional)
    audience_result = await context.elicit(
        message="Â¿CuÃ¡l es la audiencia objetivo? (tÃ©cnica, general, estudiantes, etc.)",
        response_type=str
    )
    
    audience = "general"
    if isinstance(audience_result, AcceptedElicitation):
        audience = audience_result.data
    
    # Paso 4: Usar AI sampling para generar el contenido
    system_prompt = f"""Eres un experto escritor creando contenido de alta calidad. 
Debes generar un {content_type} sobre el tema '{topic}' dirigido a audiencia {audience}.
Usa un tono profesional pero accesible. Estructura el contenido de manera clara y aÃ±ade valor."""
    
    user_message = f"Genera un {content_type} completo y bien estructurado sobre: {topic}"
    
    # Realizar el sampling de AI
    response = await context.sample(
        messages=user_message,
        system_prompt=system_prompt,
        max_tokens=1500,
        temperature=0.7
    )
    
    # Extraer el texto generado
    if isinstance(response, TextContent):
        generated_text = response.text
        
        # Guardar en storage
        content_id = f"content_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        generated_content[content_id] = {
            "type": content_type,
            "topic": topic,
            "audience": audience,
            "content": generated_text,
            "timestamp": datetime.now().isoformat()
        }
        
        return f"""
âœ… Contenido generado exitosamente!

ğŸ“ Tipo: {content_type.title()}
ğŸ¯ Tema: {topic}
ğŸ‘¥ Audiencia: {audience}
ğŸ†” ID: {content_id}

ğŸ“„ Contenido:
{generated_text}

ğŸ’¡ El contenido ha sido guardado y puede ser referenciado con ID: {content_id}
        """.strip()
    
    return "âŒ Error: No se pudo generar el contenido"

@mcp.tool
async def intelligent_text_analyzer(context: Context) -> str:
    """
    Analizador de texto inteligente que usa AI para analizar contenido.
    """
    # Obtener el texto a analizar
    text_result = await context.elicit(
        message="Proporciona el texto que quieres analizar:",
        response_type=str
    )
    
    if not isinstance(text_result, AcceptedElicitation):
        return "ğŸš« AnÃ¡lisis cancelado: No se proporcionÃ³ texto"
    
    text_to_analyze = text_result.data
    
    # Solicitar tipo de anÃ¡lisis
    analysis_options = [
        "sentimiento",
        "temas principales",
        "resumen ejecutivo",
        "anÃ¡lisis completo"
    ]
    
    analysis_type_result = await context.elicit(
        message="Â¿QuÃ© tipo de anÃ¡lisis quieres realizar?",
        response_type=analysis_options
    )
    
    if not isinstance(analysis_type_result, AcceptedElicitation):
        return "âš ï¸ AnÃ¡lisis bÃ¡sico realizado"
    
    analysis_type = analysis_type_result.data
    
    # Configurar prompt segÃºn el tipo de anÃ¡lisis
    analysis_prompts = {
        "sentimiento": "Analiza el sentimiento del texto proporcionado. Identifica si es positivo, negativo o neutral, y explica los indicadores que llevan a esta conclusiÃ³n.",
        "temas principales": "Identifica y lista los temas principales del texto. Proporciona una explicaciÃ³n breve de cada tema encontrado.",
        "resumen ejecutivo": "Crea un resumen ejecutivo conciso del texto, destacando los puntos mÃ¡s importantes y conclusiones clave.",
        "anÃ¡lisis completo": "Realiza un anÃ¡lisis completo del texto incluyendo: sentimiento, temas principales, estructura, audiencia objetivo, y recomendaciones de mejora."
    }
    
    system_prompt = f"Eres un experto analista de textos. {analysis_prompts[analysis_type]}"
    
    # Realizar sampling de AI para el anÃ¡lisis
    response = await context.sample(
        messages=f"Analiza este texto:\n\n{text_to_analyze}",
        system_prompt=system_prompt,
        max_tokens=800,
        temperature=0.3
    )
    
    if isinstance(response, TextContent):
        analysis_result = response.text
        
        return f"""
ğŸ” AnÃ¡lisis de Texto Completado

ğŸ“Š Tipo de anÃ¡lisis: {analysis_type.title()}
ğŸ“ Longitud del texto: {len(text_to_analyze)} caracteres

ğŸ“‹ Resultado del anÃ¡lisis:
{analysis_result}

â° AnÃ¡lisis realizado: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
        """.strip()
    
    return "âŒ Error: No se pudo completar el anÃ¡lisis"

@mcp.tool
async def ai_code_generator(context: Context) -> str:
    """
    Generador de cÃ³digo que combina elicitaciÃ³n y AI sampling.
    """
    # Obtener lenguaje de programaciÃ³n
    language_result = await context.elicit(
        message="Â¿En quÃ© lenguaje de programaciÃ³n quieres generar cÃ³digo?",
        response_type=ProgrammingLanguage
    )
    
    if not isinstance(language_result, AcceptedElicitation):
        return "ğŸš« GeneraciÃ³n cancelada: No se especificÃ³ lenguaje"
    
    language = language_result.data.value
    
    # Obtener descripciÃ³n de la funcionalidad
    functionality_result = await context.elicit(
        message=f"Describe la funcionalidad que quieres implementar en {language.title()}:",
        response_type=str
    )
    
    if not isinstance(functionality_result, AcceptedElicitation):
        return f"âš ï¸ GeneraciÃ³n incompleta: Solo se configurÃ³ {language}"
    
    functionality = functionality_result.data
    
    # Preguntar sobre tests
    include_tests_result = await context.elicit(
        message="Â¿Quieres incluir tests unitarios?",
        response_type=["sÃ­", "no"]
    )
    
    include_tests = isinstance(include_tests_result, AcceptedElicitation) and include_tests_result.data == "sÃ­"
    
    # Configurar prompt para generaciÃ³n de cÃ³digo
    system_prompt = f"""Eres un experto desarrollador de {language.title()}. 
Genera cÃ³digo limpio, bien documentado y siguiendo las mejores prÃ¡cticas.
Incluye comentarios explicativos y maneja errores apropiadamente."""
    
    if include_tests:
        user_message = f"Implementa la siguiente funcionalidad en {language} e incluye tests unitarios:\n{functionality}"
    else:
        user_message = f"Implementa la siguiente funcionalidad en {language}:\n{functionality}"
    
    # Generar cÃ³digo usando AI sampling
    response = await context.sample(
        messages=user_message,
        system_prompt=system_prompt,
        max_tokens=1200,
        temperature=0.2
    )
    
    if isinstance(response, TextContent):
        generated_code = response.text
        
        return f"""
ğŸ’» CÃ³digo Generado - {language.title()}

ğŸ¯ Funcionalidad: {functionality}
ğŸ§ª Tests incluidos: {"SÃ­" if include_tests else "No"}

```{language}
{generated_code}
```

ğŸ’¡ Consejos adicionales:
- Revisa el cÃ³digo antes de usarlo en producciÃ³n
- Ajusta las importaciones segÃºn tu entorno
- Considera agregar logging para debugging
        """.strip()
    
    return "âŒ Error: No se pudo generar el cÃ³digo"

@mcp.tool
async def smart_translator(context: Context) -> str:
    """
    Traductor inteligente que mantiene contexto y estilo.
    """
    # Obtener texto a traducir
    text_result = await context.elicit(
        message="Proporciona el texto que quieres traducir:",
        response_type=str
    )
    
    if not isinstance(text_result, AcceptedElicitation):
        return "ğŸš« TraducciÃ³n cancelada: No se proporcionÃ³ texto"
    
    text_to_translate = text_result.data
    
    # Obtener idiomas
    target_language_result = await context.elicit(
        message="Â¿A quÃ© idioma quieres traducir?",
        response_type=["inglÃ©s", "espaÃ±ol", "portuguÃ©s", "francÃ©s", "alemÃ¡n", "italiano", "japonÃ©s"]
    )
    
    if not isinstance(target_language_result, AcceptedElicitation):
        return "âš ï¸ TraducciÃ³n incompleta: No se especificÃ³ idioma objetivo"
    
    target_language = target_language_result.data
    
    # Obtener contexto (opcional)
    context_result = await context.elicit(
        message="Proporciona contexto adicional para una mejor traducciÃ³n (opcional):",
        response_type=str
    )
    
    additional_context = ""
    if isinstance(context_result, AcceptedElicitation) and context_result.data.strip():
        additional_context = f"\nContexto: {context_result.data}"
    
    # Configurar prompt para traducciÃ³n
    system_prompt = f"""Eres un traductor experto especializado en mantener el tono, estilo y contexto original.
Traduce al {target_language} preservando:
- Significado preciso
- Tono y estilo
- Expresiones idiomÃ¡ticas apropiadas
- Formato original{additional_context}"""
    
    # Realizar traducciÃ³n usando AI sampling
    response = await context.sample(
        messages=f"Traduce este texto al {target_language}:\n\n{text_to_translate}",
        system_prompt=system_prompt,
        max_tokens=1000,
        temperature=0.1
    )
    
    if isinstance(response, TextContent):
        translation = response.text
        
        return f"""
ğŸŒ TraducciÃ³n Completada

ğŸ“ Idioma objetivo: {target_language.title()}
ğŸ“ Texto original: {len(text_to_translate)} caracteres
ğŸ“ TraducciÃ³n: {len(translation)} caracteres

ğŸ”¤ Texto original:
{text_to_translate}

ğŸŒ TraducciÃ³n:
{translation}

â° TraducciÃ³n realizada: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
        """.strip()
    
    return "âŒ Error: No se pudo completar la traducciÃ³n"

@mcp.tool
async def document_summarizer(context: Context) -> str:
    """
    Resumidor de documentos que ajusta el nivel de detalle segÃºn necesidades.
    """
    # Obtener documento
    document_result = await context.elicit(
        message="Proporciona el documento o texto largo que quieres resumir:",
        response_type=str
    )
    
    if not isinstance(document_result, AcceptedElicitation):
        return "ğŸš« Resumen cancelado: No se proporcionÃ³ documento"
    
    document = document_result.data
    
    # Obtener tipo de resumen
    summary_types = [
        "ejecutivo (1-2 pÃ¡rrafos)",
        "detallado (3-5 pÃ¡rrafos)",
        "puntos clave (lista)",
        "abstracto acadÃ©mico"
    ]
    
    summary_type_result = await context.elicit(
        message="Â¿QuÃ© tipo de resumen necesitas?",
        response_type=summary_types
    )
    
    if not isinstance(summary_type_result, AcceptedElicitation):
        return "âš ï¸ Resumen bÃ¡sico generado"
    
    summary_type = summary_type_result.data
    
    # Configurar prompt segÃºn tipo de resumen
    summary_prompts = {
        "ejecutivo (1-2 pÃ¡rrafos)": "Crea un resumen ejecutivo conciso en 1-2 pÃ¡rrafos que capture lo mÃ¡s importante para tomadores de decisiones.",
        "detallado (3-5 pÃ¡rrafos)": "Genera un resumen detallado en 3-5 pÃ¡rrafos que cubra todos los puntos importantes manteniendo la estructura lÃ³gica.",
        "puntos clave (lista)": "Extrae los puntos clave mÃ¡s importantes y presÃ©ntalos como una lista numerada clara y organizada.",
        "abstracto acadÃ©mico": "Crea un abstracto acadÃ©mico estructurado con objetivo, metodologÃ­a, resultados principales y conclusiones."
    }
    
    system_prompt = f"Eres un experto en sÃ­ntesis de informaciÃ³n. {summary_prompts[summary_type]} MantÃ©n precisiÃ³n y claridad."
    
    # Generar resumen usando AI sampling
    response = await context.sample(
        messages=f"Resume este documento:\n\n{document}",
        system_prompt=system_prompt,
        max_tokens=600,
        temperature=0.3
    )
    
    if isinstance(response, TextContent):
        summary = response.text
        
        return f"""
ğŸ“„ Resumen de Documento Generado

ğŸ“Š Tipo de resumen: {summary_type}
ğŸ“ Documento original: {len(document)} caracteres  
ğŸ“ Resumen: {len(summary)} caracteres
ğŸ“‰ ReducciÃ³n: {((len(document) - len(summary)) / len(document) * 100):.1f}%

ğŸ“‹ Resumen:
{summary}

â° Resumen generado: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
        """.strip()
    
    return "âŒ Error: No se pudo generar el resumen"

@mcp.tool
async def creative_writing_assistant(context: Context) -> str:
    """
    Asistente de escritura creativa que combina elicitaciÃ³n y sampling
    para generar contenido creativo personalizado.
    """
    # Paso 1: Obtener gÃ©nero/estilo
    genres = [
        "ficciÃ³n cientÃ­fica",
        "fantasÃ­a",
        "misterio/thriller",
        "romance",
        "drama",
        "comedia",
        "terror"
    ]
    
    genre_result = await context.elicit(
        message="Â¿En quÃ© gÃ©nero quieres escribir?",
        response_type=genres
    )
    
    if not isinstance(genre_result, AcceptedElicitation):
        return "ğŸš« Escritura cancelada: No se especificÃ³ gÃ©nero"
    
    genre = genre_result.data
    
    # Paso 2: Obtener elementos de la historia
    elements_result = await context.elicit(
        message="Describe elementos clave para la historia (personajes, situaciÃ³n, tema, etc.):",
        response_type=str
    )
    
    if not isinstance(elements_result, AcceptedElicitation):
        return f"âš ï¸ Escritura incompleta: Solo se configurÃ³ gÃ©nero '{genre}'"
    
    elements = elements_result.data
    
    # Paso 3: Longitud deseada
    lengths = [
        "cuento corto (500-1000 palabras)",
        "historia mediana (1000-2000 palabras)", 
        "solo el inicio (200-400 palabras)",
        "outline/esquema"
    ]
    
    length_result = await context.elicit(
        message="Â¿QuÃ© longitud prefieres?",
        response_type=lengths
    )
    
    length = "cuento corto (500-1000 palabras)"
    if isinstance(length_result, AcceptedElicitation):
        length = length_result.data
    
    # Configurar prompt para escritura creativa
    system_prompt = f"""Eres un escritor creativo experto en {genre}. 
Crea contenido original, envolvente y bien estructurado.
Desarrolla personajes interesantes, diÃ¡logos naturales y descripciones vÃ­vidas.
MantÃ©n consistencia en tono y estilo apropiados para el gÃ©nero."""
    
    user_message = f"""Escribe una {length} en gÃ©nero {genre} incorporando estos elementos:
{elements}

AsegÃºrate de crear una narrativa envolvente con:
- Personajes bien desarrollados
- Conflicto interesante  
- Desarrollo de trama coherente
- Final satisfactorio (si aplica)"""
    
    # Generar contenido creativo usando AI sampling
    response = await context.sample(
        messages=user_message,
        system_prompt=system_prompt,
        max_tokens=1800,
        temperature=0.8  # Mayor temperatura para creatividad
    )
    
    if isinstance(response, TextContent):
        creative_content = response.text
        
        return f"""
âœï¸ Contenido Creativo Generado

ğŸ­ GÃ©nero: {genre.title()}
ğŸ“ Longitud: {length}
ğŸ¯ Elementos incorporados: {elements[:100]}...

ğŸ“š Historia:
{creative_content}

ğŸ’¡ Sugerencias para continuar:
- Desarrolla mÃ¡s los personajes secundarios
- Explora subtemas interesantes
- Considera diferentes perspectivas narrativas
        """.strip()
    
    return "âŒ Error: No se pudo generar el contenido creativo"

@mcp.tool
async def get_generated_content_list(context: Context) -> str:
    """
    Muestra lista de todo el contenido generado en esta sesiÃ³n.
    """
    if not generated_content:
        return "ğŸ“­ No hay contenido generado en esta sesiÃ³n"
    
    content_list = ["ğŸ“‹ Contenido Generado en Esta SesiÃ³n:", "=" * 45]
    
    for content_id, data in generated_content.items():
        content_list.append(f"\nğŸ†” {content_id}")
        content_list.append(f"   Tipo: {data['type']}")
        content_list.append(f"   Tema: {data['topic']}")
        content_list.append(f"   Creado: {data['timestamp']}")
        content_list.append(f"   Longitud: {len(data['content'])} caracteres")
    
    return "\n".join(content_list)

if __name__ == "__main__":
    print("ğŸš€ Iniciando Servidor MCP Multi-Turn con Sampling...")
    print("=" * 55)
    print("Funcionalidades disponibles:")
    print("1. ğŸ“ ai_content_generator - Generador de contenido con AI")
    print("2. ğŸ” intelligent_text_analyzer - Analizador de texto inteligente")
    print("3. ğŸ’» ai_code_generator - Generador de cÃ³digo con AI")
    print("4. ğŸŒ smart_translator - Traductor inteligente")
    print("5. ğŸ“„ document_summarizer - Resumidor de documentos")
    print("6. âœï¸ creative_writing_assistant - Asistente de escritura creativa")
    print("7. ğŸ“‹ get_generated_content_list - Ver contenido generado")
    print("=" * 55)
    
    mcp.run()