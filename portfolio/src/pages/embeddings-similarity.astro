---
import PostLayout from '@layouts/PostLayout.astro';
import CodeBlockInputCell from '@components/CodeBlockInputCell.astro';
import CodeBlockOutputCell from '@components/CodeBlockOutputCell.astro';

const { metadata_page } = await import('@portfolio/consts.json');
const { colors } = await import('@portfolio/consts.json');
const { svg_paths } = await import('@portfolio/consts.json');

const page_title = 'Embeddings similarity measure';
const end_url = 'embeddings-similarity';
const description = 'Descubre cómo se mide la similitud entre embeddings, la base del mecanismo de atención de los transformers y de los algoritmos de RAG';
const keywords = 'embeddings, similitud, similitud por coseno, similitud L2, similitud por producto escalar';
const languaje = 'ES';
const image_path = 'https://images.maximofn.com/embeddings-similarity.webp';
const opening_brace = '{';
const closing_brace = '}';
---

<PostLayout 
    title={page_title}
    languaje={languaje}
    description={description}
    keywords={keywords}
    author={metadata_page.author}
    theme_color={colors.background_color}
    end_url={end_url}
    image_path={image_path}
    image_width=1024
    image_height=1024
    image_extension=webp
    article_date=2023-12-18+T00:00:00Z
>

  <section class="post-body">


    <aside class="post-index">
      <a class="anchor-link" href="#Similitud por el cuadrado L2"><h2>Similitud por el cuadrado L2</h2></a>
      <a class="anchor-link" href="#Similitud por coseno"><h2>Similitud por coseno</h2></a>
      <a class="anchor-link" href="#Similitud del producto escalar"><h2>Similitud del producto escalar</h2></a>
      <a class="anchor-link" href="#Que sistema de similitud usar"><h2>Qué sistema de similitud usar</h2></a>
    </aside>


    <div class="post-body-content">
      
      <section class="section-block-markdown-cell">
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Ahora que hemos visto lo que son los <a href="https://maximofn.com/embeddings">embeddings</a>, sabemos que podemos medir la similitud entre dos palabras midiendo la similitud entre sus embeddings. En el post de <a href="https://maximofn.com/embeddings">embeddings</a> vimos el ejemplo de uso de la medida de similitud por coseno, pero existen otras medidas de similitud que podemos usar, el cuadrado L2, la similitud del producto escalar, la similitud por coseno, etc.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>En este post vamos a ver estas tres que hemos mencionado</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Similitud por el cuadrado L2">Similitud por el cuadrado L2<a class="anchor-link" href="#Similitud por el cuadrado L2"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 1" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Esta similitud viene derivada de la distancia euclídea, que es la distancia en línea recta entre dos puntos en un espacio multidimensional, la que se calcula con el teorema de Pitágoras.</p>
      <img decoding="async" onerror="this.parentNode.removeChild(this)" src="https://images.maximofn.com/distancia_euclidiana.webp" alt="distancia euclidiana">
      <p>La distancia euclídea entre dos puntos <span class="math-inline">p</span> y <span class="math-inline">q</span> se calcula como:</p>
      <p><span class="math-display">d(p,q) = &radic;((p<sub>1</sub> - q<sub>1</sub>)<sup>2</sup> + (p<sub>2</sub> - q<sub>2</sub>)<sup>2</sup> + ··· + (p<sub>n</sub> - q<sub>n</sub>)<sup>2</sup>) = &radic;(&sum;<sub>i=1</sub><sup>n</sup> (p<sub>i</sub> - q<sub>i</sub>)<sup>2</sup>)</span></p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>La similitud por el cuadrado L2 es el cuadrado de la distancia euclídea, es decir:</p>
      <p><span class="math-display">similitud(p,q) = d(p,q)<sup>2</sup> = &sum;<sub>i=1</sub><sup>n</sup> (p<sub>i</sub> - q<sub>i</sub>)<sup>2</sup></span></p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Similitud por coseno">Similitud por coseno<a class="anchor-link" href="#Similitud por coseno"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 2" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Si recordamos lo que aprendimos de senos y cosenos en la escuela, recordaremos que cuando dos vectores tienen un ángulo de 0º entre ellos, su coseno es 1, cuando el ángulo entre ellos es de 90º, su coseno es 0 y cuando el ángulo es de 180º, su coseno es -1.</p>
      <img decoding="async" onerror="this.parentNode.removeChild(this)" src="https://images.maximofn.com/dot-product.gif" alt="cosine similarity">
      <img decoding="async" onerror="this.parentNode.removeChild(this)" src="https://images.maximofn.com/dot-product-unity.gif" alt="cosine similarity">
      <p>Por lo tanto, podemos usar el coseno del ángulo entre dos vectores para medir su similitud. Se puede demostrar que el coseno del ángulo entre dos vectores es igual al producto escalar de los dos vectores dividido por el producto de sus módulos. No es el objetivo de este post demostrarlo, pero si queréis podéis ver la demostración <a href="https://www.wwwinsights.com/wp-content/uploads/2023/05/image-11-1024x694.png" target="_blank" rel="nofollow noreferrer">aquí</a>.</p>
      <p><span class="math-display">similitud(U,V) = <span class="math-fraction"><span class="math-fraction-numerator">U · V</span><span class="math-fraction-denominator">||U|| ||V||</span></span></span></p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Similitud del producto escalar">Similitud del producto escalar<a class="anchor-link" href="#Similitud del producto escalar"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 3" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>La similitud del producto escalar es el producto escalar de dos vectores</p>
      <p><span class="math-display">similitud(U,V) = U · V</span></p>
      <p>Como hemos escrito la fórmula de la similitud por coseno, cuando la longitud de los vectores es 1, es decir, están normalizados, la similitud por coseno es igual a la similitud del producto escalar.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Entonces, ¿Para qué nos sirve la similitud por el producto escalar? Pues para medir la similitud entre dos vectores que no están normalizados, es decir, que no tienen longitud 1.</p>
      <p>Por ejemplo, youtube, para crear los embeddings de sus vídeos, hace que los embeddings de los vídeos que clasifica con mayor calidad sean más largos que los de los vídeos que clasifica con menor calidad.</p>
      <p>De esta forma, cuando un usuario hace una búsqueda, la similitud por producto escalar dará mayor similitud a los vídeos de mayor calidad, por lo que le dará al usuario los vídeos de mayor calidad en primer lugar.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Que sistema de similitud usar">Qué sistema de similitud usar<a class="anchor-link" href="#Que sistema de similitud usar"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 4" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Para elegir el sistema de similitud que vamos a usar, debemos tener en cuenta el espacio en el que estamos trabajando.</p>
      <ul>
        <li>Si estamos trabajando en un espacio de alta dimensionalidad, con embeddings normalizados, la similitud por coseno es la que mejor funciona. Por ejemplo OpenAI genera embeddings normalizados, por lo que la similitud por coseno es la que mejor funciona.</li>
        <li>Si estamos trabajando en un sistema de clasificación, donde la distancia entre dos clases es importante, la similitud por el cuadrado L2 es la que mejor funciona.</li>
        <li>Si estamos trabajando en un sistema de recomendación, donde la longitud de los vectores es importante, la similitud del producto escalar es la que mejor funciona.</li>
      </ul>
      </section>







    </div>

  </section>

</PostLayout>
