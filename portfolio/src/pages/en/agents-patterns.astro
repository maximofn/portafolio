---
import PostLayout from '@layouts/PostLayout.astro';
import CodeBlockInputCell from '@components/CodeBlockInputCell.astro';
import CodeBlockOutputCell from '@components/CodeBlockOutputCell.astro';

const { metadata_page } = await import('@portfolio/consts.json');
const { colors } = await import('@portfolio/consts.json');
const { svg_paths } = await import('@portfolio/consts.json');

const page_title = 'Agents patterns';
const end_url = 'agents-patterns';
const description = 'Are your agents falling short? Elevate your AI projects with advanced patterns: ReAct, planning, multi-agents, and more. Practical guide with code!';
const keywords = 'langgraph, ai, agents, orchestration, framework, memory, human in the loop, agents patterns';
const languaje = 'EN';
const image_path = 'https://images.maximofn.com/agent_patterns_thumbnail_ES.webp';
const opening_brace = '{';
const closing_brace = '}';
---

<PostLayout 
    title={page_title}
    languaje={languaje}
    description={description}
    keywords={keywords}
    author={metadata_page.author}
    theme_color={colors.background_color}
    end_url={end_url}
    image_path={image_path}
    image_width=1536
    image_height=1024
    image_extension=webp
    article_date=2025-06-04+T00:00:00Z
>

  <section class="post-body">


    <aside class="post-index">
      <a class="anchor-link" href="#Prompt responder (chain block)"><h2>Prompt responder (chain block)</h2></a>
      <a class="anchor-link" href="#Chain of blocks"><h2>Chain of blocks</h2></a>
      <a class="anchor-link" href="#Routing"><h2>Routing</h2></a>
      <a class="anchor-link" href="#Parallelization"><h2>Parallelization</h2></a>
      <a class="anchor-link" href="#Evaluator-optimizer (reflection pattern)"><h2>Evaluator-optimizer (reflection pattern)</h2></a>
      <a class="anchor-link" href="#Agent with tools (ReAct pattern)"><h2>Agent with tools (ReAct pattern)</h2></a>
      <a class="anchor-link" href="#Planning pattern"><h2>Planning pattern</h2></a>
      <a class="anchor-link" href="#Multi agent pattern"><h2>Multi agent pattern</h2></a>
      <a class="anchor-link" href="#Worker 1: News Agent"><h3>Worker 1: News Agent</h3></a>
      <a class="anchor-link" href="#Worker 2: news synthesizer agent"><h3>Worker 2: news synthesizer agent</h3></a>
      <a class="anchor-link" href="#Main graph"><h3>Main graph</h3></a>
    </aside>


    <div class="post-body-content">
      
      <section class="section-block-markdown-cell">
      </section>
      
      <section class="section-block-markdown-cell">
      <blockquote>
      <p>Disclaimer: This post has been translated to English using a machine translation model. Please, let me know if you find any mistakes.</p>
      </blockquote>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>In my previous post, I explained how to use <a href="https://www.maximofn.com/langgraph/">LangGraph</a> to create agents.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>So in this we are going to look at the different patterns of agents we can build and we will do it with LangGraph.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <blockquote>
      <p>**Note**: We will start from the most basic model consisting of a chatbot with an LLM and progress to more complex architectures.</p>
      </blockquote>
      </section>
      
      <section class="section-block-markdown-cell">
      <blockquote>
      <p>**Note**: Whenever possible, we will use <code>Qwen2-72B-Instruct</code> to be able to use it for free with Hugging Face.</p>
      </blockquote>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Prompt responder (chain block)">Prompt responder (chain block)<a class="anchor-link" href="#Prompt responder (chain block)"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 13" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <img decoding="async" onerror="this.parentNode.removeChild(this)" src="https://images.maximofn.com/agent_patterns_01_chain_block.webp" alt="chain block">
      </section>
      
      <section class="section-block-markdown-cell">
      <p>It is the most basic model; the LLM receives a prompt and returns a response.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Annotated</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">typing_extensions</span><span class="w"> </span><span class="kn">import</span> <span class="n">TypedDict</span>',
      '<span class="w"> </span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">langgraph.graph</span><span class="w"> </span><span class="kn">import</span> <span class="n">StateGraph</span><span class="p">,</span> <span class="n">START</span><span class="p">,</span> <span class="n">END</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">langgraph.graph.message</span><span class="w"> </span><span class="kn">import</span> <span class="n">add_messages</span>',
      '<span class="w"> </span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_huggingface</span><span class="w"> </span><span class="kn">import</span> <span class="n">HuggingFaceEndpoint</span><span class="p">,</span> <span class="n">ChatHuggingFace</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">huggingface_hub</span><span class="w"> </span><span class="kn">import</span> <span class="n">login</span>',
      '<span class="w"> </span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">IPython.display</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span><span class="p">,</span> <span class="n">display</span>',
      '<span class="w"> </span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>',
      '<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;LANGCHAIN_TRACING_V2&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;false&quot;</span>    <span class="c1"># Disable LangSmith tracing</span>',
      '<span class="w"> </span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">dotenv</span>',
      '<span class="n">dotenv</span><span class="o">.</span><span class="n">load_dotenv</span><span class="p">()</span>',
      '<span class="n">HUGGINGFACE_TOKEN</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;HUGGINGFACE_LANGGRAPH&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># State</span>',
      '<span class="k">class</span><span class="w"> </span><span class="nc">State</span><span class="p">(</span><span class="n">TypedDict</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">messages</span><span class="p">:</span> <span class="n">Annotated</span><span class="p">[</span><span class="nb">list</span><span class="p">,</span> <span class="n">add_messages</span><span class="p">]</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Create the LLM model</span>',
      '<span class="n">login</span><span class="p">(</span><span class="n">token</span><span class="o">=</span><span class="n">HUGGINGFACE_TOKEN</span><span class="p">)</span>  <span class="c1"># Login to HuggingFace to use the model</span>',
      '<span class="n">MODEL</span> <span class="o">=</span> <span class="s2">&quot;Qwen/Qwen2.5-72B-Instruct&quot;</span>',
      '<span class="n">model</span> <span class="o">=</span> <span class="n">HuggingFaceEndpoint</span><span class="p">(</span>',
      '<span class="w">    </span><span class="n">repo_id</span><span class="o">=</span><span class="n">MODEL</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">task</span><span class="o">=</span><span class="s2">&quot;text-generation&quot;</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">do_sample</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">repetition_penalty</span><span class="o">=</span><span class="mf">1.03</span><span class="p">,</span>',
      '<span class="p">)</span>',
      '<span class="c1"># Create the chat model</span>',
      '<span class="n">llm</span> <span class="o">=</span> <span class="n">ChatHuggingFace</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Function</span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">chatbot_function</span><span class="p">(</span><span class="n">state</span><span class="p">:</span> <span class="n">State</span><span class="p">):</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="p">{</span><span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">llm</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">])]}</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Start to build the graph</span>',
      '<span class="n">graph_builder</span> <span class="o">=</span> <span class="n">StateGraph</span><span class="p">(</span><span class="n">State</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Add nodes to the graph</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;chatbot_node&quot;</span><span class="p">,</span> <span class="n">chatbot_function</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Add edges</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">START</span><span class="p">,</span> <span class="s2">&quot;chatbot_node&quot;</span><span class="p">)</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;chatbot_node&quot;</span><span class="p">,</span> <span class="n">END</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Compile the graph</span>',
      '<span class="n">graph</span> <span class="o">=</span> <span class="n">graph_builder</span><span class="o">.</span><span class="n">compile</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Display the graph</span>',
      '<span class="k">try</span><span class="p">:</span>',
      '<span class="w">    </span><span class="n">display</span><span class="p">(</span><span class="n">Image</span><span class="p">(</span><span class="n">graph</span><span class="o">.</span><span class="n">get_graph</span><span class="p">()</span><span class="o">.</span><span class="n">draw_mermaid_png</span><span class="p">()))</span>',
      '<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error al visualizar el grafo: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '&amp;lt;IPython.core.display.Image object&amp;gt;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Let's test it out</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.messages</span><span class="w"> </span><span class="kn">import</span> <span class="n">HumanMessage</span>',
      '<span class="w"> </span>',
      '<span class="n">messages</span> <span class="o">=</span> <span class="p">[</span><span class="n">HumanMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="s2">&quot;Hello, how are you?&quot;</span><span class="p">)]</span>',
      '<span class="w"> </span>',
      '<span class="n">result</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="n">messages</span><span class="p">})</span>',
      '<span class="n">result</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">pretty_print</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '================================== Ai Message ==================================',
          'Hello! I&#x27;m doing well, thank you for asking. How about you? How can I assist you today?',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h2 id="Chain of blocks">Chain of blocks<a class="anchor-link" href="#Chain of blocks"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 14" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <img decoding="async" onerror="this.parentNode.removeChild(this)" src="https://images.maximofn.com/agent_patterns_02_chain_of_blocks.webp" alt="chain of blocks">
      </section>
      
      <section class="section-block-markdown-cell">
      <p>When a task can be divided into several subtasks, we can use a chain of blocks. For example, if we want to summarize and translate a text, we can do it in two steps:</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Annotated</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">typing_extensions</span><span class="w"> </span><span class="kn">import</span> <span class="n">TypedDict</span>',
      '<span class="w"> </span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">langgraph.graph</span><span class="w"> </span><span class="kn">import</span> <span class="n">StateGraph</span><span class="p">,</span> <span class="n">START</span><span class="p">,</span> <span class="n">END</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">langgraph.graph.message</span><span class="w"> </span><span class="kn">import</span> <span class="n">add_messages</span>',
      '<span class="w"> </span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_huggingface</span><span class="w"> </span><span class="kn">import</span> <span class="n">HuggingFaceEndpoint</span><span class="p">,</span> <span class="n">ChatHuggingFace</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.messages</span><span class="w"> </span><span class="kn">import</span> <span class="n">SystemMessage</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">huggingface_hub</span><span class="w"> </span><span class="kn">import</span> <span class="n">login</span>',
      '<span class="w"> </span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">IPython.display</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span><span class="p">,</span> <span class="n">display</span>',
      '<span class="w"> </span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>',
      '<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;LANGCHAIN_TRACING_V2&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;false&quot;</span>    <span class="c1"># Disable LangSmith tracing</span>',
      '<span class="w"> </span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">dotenv</span>',
      '<span class="n">dotenv</span><span class="o">.</span><span class="n">load_dotenv</span><span class="p">()</span>',
      '<span class="n">HUGGINGFACE_TOKEN</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;HUGGINGFACE_LANGGRAPH&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># State</span>',
      '<span class="k">class</span><span class="w"> </span><span class="nc">State</span><span class="p">(</span><span class="n">TypedDict</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">messages</span><span class="p">:</span> <span class="n">Annotated</span><span class="p">[</span><span class="nb">list</span><span class="p">,</span> <span class="n">add_messages</span><span class="p">]</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Create the LLM model</span>',
      '<span class="n">login</span><span class="p">(</span><span class="n">token</span><span class="o">=</span><span class="n">HUGGINGFACE_TOKEN</span><span class="p">)</span>  <span class="c1"># Login to HuggingFace to use the model</span>',
      '<span class="n">MODEL</span> <span class="o">=</span> <span class="s2">&quot;Qwen/Qwen2.5-72B-Instruct&quot;</span>',
      '<span class="n">model</span> <span class="o">=</span> <span class="n">HuggingFaceEndpoint</span><span class="p">(</span>',
      '<span class="w">    </span><span class="n">repo_id</span><span class="o">=</span><span class="n">MODEL</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">task</span><span class="o">=</span><span class="s2">&quot;text-generation&quot;</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">do_sample</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">repetition_penalty</span><span class="o">=</span><span class="mf">1.03</span><span class="p">,</span>',
      '<span class="p">)</span>',
      '<span class="c1"># Create the chat model</span>',
      '<span class="n">llm</span> <span class="o">=</span> <span class="n">ChatHuggingFace</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Function</span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">summary</span><span class="p">(</span><span class="n">state</span><span class="p">:</span> <span class="n">State</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">input_text</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">content</span>',
      '<span class="w">    </span><span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Summarize the following text: </span><span class="si">{</span><span class="n">input_text</span><span class="si">}</span><span class="s2">&quot;</span>',
      '<span class="w">    </span><span class="n">llm_response</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="p">{</span><span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">llm_response</span><span class="p">]}</span>',
      '<span class="w"> </span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">translate</span><span class="p">(</span><span class="n">state</span><span class="p">:</span> <span class="n">State</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">input_text</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">content</span>',
      '<span class="w">    </span><span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Translate the following text to Spanish: </span><span class="si">{</span><span class="n">input_text</span><span class="si">}</span><span class="s2">&quot;</span>',
      '<span class="w">    </span><span class="n">llm_response</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="p">{</span><span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">llm_response</span><span class="p">]}</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Start to build the graph</span>',
      '<span class="n">graph_builder</span> <span class="o">=</span> <span class="n">StateGraph</span><span class="p">(</span><span class="n">State</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Add nodes to the graph</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;summary&quot;</span><span class="p">,</span> <span class="n">summary</span><span class="p">)</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;translate&quot;</span><span class="p">,</span> <span class="n">translate</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Add edges</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">START</span><span class="p">,</span> <span class="s2">&quot;summary&quot;</span><span class="p">)</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;summary&quot;</span><span class="p">,</span> <span class="s2">&quot;translate&quot;</span><span class="p">)</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;translate&quot;</span><span class="p">,</span> <span class="n">END</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Compile the graph</span>',
      '<span class="n">graph</span> <span class="o">=</span> <span class="n">graph_builder</span><span class="o">.</span><span class="n">compile</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Display the graph</span>',
      '<span class="k">try</span><span class="p">:</span>',
      '<span class="w">    </span><span class="n">display</span><span class="p">(</span><span class="n">Image</span><span class="p">(</span><span class="n">graph</span><span class="o">.</span><span class="n">get_graph</span><span class="p">()</span><span class="o">.</span><span class="n">draw_mermaid_png</span><span class="p">()))</span>',
      '<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error al visualizar el grafo: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '&amp;lt;IPython.core.display.Image object&amp;gt;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.messages</span><span class="w"> </span><span class="kn">import</span> <span class="n">HumanMessage</span>',
      '<span class="w"> </span>',
      '<span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;Large language models are powerful AI systems trained on vast amounts of text data.</span>',
      '<span class="s2">They can generate human-like text, translate languages, write different kinds of creative content, and answer your questions in an informative way.&quot;&quot;&quot;</span>',
      '<span class="w"> </span>',
      '<span class="n">messages</span> <span class="o">=</span> <span class="p">[</span><span class="n">HumanMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="n">text</span><span class="p">)]</span>',
      '<span class="w"> </span>',
      '<span class="n">result</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="n">messages</span><span class="p">})</span>',
      '<span class="w"> </span>',
      '<span class="k">for</span> <span class="n">message</span> <span class="ow">in</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">]:</span>',
      '<span class="w">    </span><span class="n">message</span><span class="o">.</span><span class="n">pretty_print</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '================================ Human Message =================================',
          'Large language models are powerful AI systems trained on vast amounts of text data.',
          'They can generate human-like text, translate languages, write different kinds of creative content, and answer your questions in an informative way.',
          '================================== Ai Message ==================================',
          'Large language models are advanced AI systems trained on extensive text data, enabling them to produce human-like text, translate languages, create various types of creative content, and provide informative answers to questions.',
          '================================== Ai Message ==================================',
          'Los modelos de lenguaje grandes son sistemas de IA avanzados entrenados con extensos datos de texto, lo que les permite producir texto similar al humano, traducir idiomas, crear diversos tipos de contenido creativo y proporcionar respuestas informativas a preguntas.',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h2 id="Routing">Routing<a class="anchor-link" href="#Routing"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 15" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <img decoding="async" onerror="this.parentNode.removeChild(this)" src="https://images.maximofn.com/agent_patterns_03_routing.webp" alt="routing">
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Another thing we can do is create several routes based on the problem and choose the one that best fits our problem. Let's look at an example where the user can choose between summarizing or translating a text.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Annotated</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">typing_extensions</span><span class="w"> </span><span class="kn">import</span> <span class="n">TypedDict</span>',
      '<span class="w"> </span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">langgraph.graph</span><span class="w"> </span><span class="kn">import</span> <span class="n">StateGraph</span><span class="p">,</span> <span class="n">START</span><span class="p">,</span> <span class="n">END</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">langgraph.graph.message</span><span class="w"> </span><span class="kn">import</span> <span class="n">add_messages</span>',
      '<span class="w"> </span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_huggingface</span><span class="w"> </span><span class="kn">import</span> <span class="n">HuggingFaceEndpoint</span><span class="p">,</span> <span class="n">ChatHuggingFace</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.messages</span><span class="w"> </span><span class="kn">import</span> <span class="n">SystemMessage</span><span class="p">,</span> <span class="n">HumanMessage</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">huggingface_hub</span><span class="w"> </span><span class="kn">import</span> <span class="n">login</span>',
      '<span class="w"> </span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">IPython.display</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span><span class="p">,</span> <span class="n">display</span>',
      '<span class="w"> </span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>',
      '<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;LANGCHAIN_TRACING_V2&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;false&quot;</span>    <span class="c1"># Disable LangSmith tracing</span>',
      '<span class="w"> </span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">dotenv</span>',
      '<span class="n">dotenv</span><span class="o">.</span><span class="n">load_dotenv</span><span class="p">()</span>',
      '<span class="n">HUGGINGFACE_TOKEN</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;HUGGINGFACE_LANGGRAPH&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># State</span>',
      '<span class="k">class</span><span class="w"> </span><span class="nc">State</span><span class="p">(</span><span class="n">TypedDict</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">messages</span><span class="p">:</span> <span class="n">Annotated</span><span class="p">[</span><span class="nb">list</span><span class="p">,</span> <span class="n">add_messages</span><span class="p">]</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Create the LLM model</span>',
      '<span class="n">login</span><span class="p">(</span><span class="n">token</span><span class="o">=</span><span class="n">HUGGINGFACE_TOKEN</span><span class="p">)</span>  <span class="c1"># Login to HuggingFace to use the model</span>',
      '<span class="n">MODEL</span> <span class="o">=</span> <span class="s2">&quot;Qwen/Qwen2.5-72B-Instruct&quot;</span>',
      '<span class="n">model</span> <span class="o">=</span> <span class="n">HuggingFaceEndpoint</span><span class="p">(</span>',
      '<span class="w">    </span><span class="n">repo_id</span><span class="o">=</span><span class="n">MODEL</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">task</span><span class="o">=</span><span class="s2">&quot;text-generation&quot;</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">do_sample</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">repetition_penalty</span><span class="o">=</span><span class="mf">1.03</span><span class="p">,</span>',
      '<span class="p">)</span>',
      '<span class="c1"># Create the chat model</span>',
      '<span class="n">llm</span> <span class="o">=</span> <span class="n">ChatHuggingFace</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Function</span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">chatbot_function</span><span class="p">(</span><span class="n">state</span><span class="p">:</span> <span class="n">State</span><span class="p">):</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="p">{</span><span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">llm</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">])]}</span>',
      '<span class="w"> </span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">summary</span><span class="p">(</span><span class="n">state</span><span class="p">:</span> <span class="n">State</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">input_text</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">content</span>',
      '<span class="w">    </span><span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Summarize the following text: </span><span class="si">{</span><span class="n">input_text</span><span class="si">}</span><span class="s2">&quot;</span>',
      '<span class="w">    </span><span class="n">llm_response</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="p">{</span><span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">llm_response</span><span class="p">]}</span>',
      '<span class="w"> </span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">translate</span><span class="p">(</span><span class="n">state</span><span class="p">:</span> <span class="n">State</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">input_text</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">content</span>',
      '<span class="w">    </span><span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Translate the following text to Spanish: </span><span class="si">{</span><span class="n">input_text</span><span class="si">}</span><span class="s2">&quot;</span>',
      '<span class="w">    </span><span class="n">llm_response</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="p">{</span><span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">llm_response</span><span class="p">]}</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Decision function for conditional edges</span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">decide_next_step</span><span class="p">(</span><span class="n">state</span><span class="p">:</span> <span class="n">State</span><span class="p">)</span> <span class="o">-&amp;</span><span class="n">gt</span><span class="p">;</span> <span class="nb">str</span><span class="p">:</span>',
      '<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>',
      '<span class="sd">    Decides the next step after the chatbot_node.</span>',
      '<span class="sd">    It checks the user&#39;s last message for keywords like &#39;summarize&#39; or &#39;translate&#39;.</span>',
      '<span class="sd">    &quot;&quot;&quot;</span>',
      '<span class="w">    </span><span class="c1"># Filter out human messages from the state</span>',
      '<span class="w">    </span><span class="n">user_messages</span> <span class="o">=</span> <span class="p">[</span><span class="n">msg</span> <span class="k">for</span> <span class="n">msg</span> <span class="ow">in</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">msg</span><span class="p">,</span> <span class="n">HumanMessage</span><span class="p">)]</span>',
      '<span class="w">    </span>',
      '<span class="w">    </span><span class="k">if</span> <span class="ow">not</span> <span class="n">user_messages</span><span class="p">:</span>',
      '<span class="w">        </span><span class="c1"># If there are no human messages, default to ending the process</span>',
      '<span class="w">        </span><span class="k">return</span> <span class="s2">&quot;end&quot;</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="c1"># Get the content of the last human message</span>',
      '<span class="w">    </span><span class="n">last_user_message_content</span> <span class="o">=</span> <span class="n">user_messages</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">content</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="k">if</span> <span class="s2">&quot;summarize&quot;</span> <span class="ow">in</span> <span class="n">last_user_message_content</span> <span class="ow">or</span> <span class="s2">&quot;resumir&quot;</span> <span class="ow">in</span> <span class="n">last_user_message_content</span><span class="p">:</span>',
      '<span class="w">        </span><span class="c1"># If the user asked to summarize</span>',
      '<span class="w">        </span><span class="k">return</span> <span class="s2">&quot;summary&quot;</span>',
      '<span class="w">    </span><span class="k">elif</span> <span class="s2">&quot;translate&quot;</span> <span class="ow">in</span> <span class="n">last_user_message_content</span> <span class="ow">or</span> <span class="s2">&quot;traducir&quot;</span> <span class="ow">in</span> <span class="n">last_user_message_content</span><span class="p">:</span>',
      '<span class="w">        </span><span class="c1"># If the user asked to translate</span>',
      '<span class="w">        </span><span class="k">return</span> <span class="s2">&quot;translate&quot;</span>',
      '<span class="w">    </span><span class="k">else</span><span class="p">:</span>',
      '<span class="w">        </span><span class="c1"># Otherwise, end the process</span>',
      '<span class="w">        </span><span class="k">return</span> <span class="s2">&quot;end&quot;</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Start to build the graph</span>',
      '<span class="n">graph_builder</span> <span class="o">=</span> <span class="n">StateGraph</span><span class="p">(</span><span class="n">State</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Add nodes to the graph</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;chatbot_node&quot;</span><span class="p">,</span> <span class="n">chatbot_function</span><span class="p">)</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;summary&quot;</span><span class="p">,</span> <span class="n">summary</span><span class="p">)</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;translate&quot;</span><span class="p">,</span> <span class="n">translate</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Add edges</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">START</span><span class="p">,</span> <span class="s2">&quot;chatbot_node&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Add conditional edges from chatbot_node</span>',
      '<span class="c1"># The decide_next_step function will determine which path to take</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_conditional_edges</span><span class="p">(</span>',
      '<span class="w">    </span><span class="s2">&quot;chatbot_node&quot;</span><span class="p">,</span>         <span class="c1"># The node where the decision is made</span>',
      '<span class="w">    </span><span class="n">decide_next_step</span><span class="p">,</span>       <span class="c1"># The function that makes the decision</span>',
      '<span class="w">    </span><span class="p">{</span>                       <span class="c1"># A dictionary mapping decision outcomes to next nodes</span>',
      '<span class="w">        </span><span class="s2">&quot;summary&quot;</span><span class="p">:</span> <span class="s2">&quot;summary&quot;</span><span class="p">,</span>   <span class="c1"># If decide_next_step returns &quot;summary&quot;, go to the &quot;summary&quot; node</span>',
      '<span class="w">        </span><span class="s2">&quot;translate&quot;</span><span class="p">:</span> <span class="s2">&quot;translate&quot;</span><span class="p">,</span> <span class="c1"># If decide_next_step returns &quot;translate&quot;, go to the &quot;translate&quot; node</span>',
      '<span class="w">        </span><span class="s2">&quot;end&quot;</span><span class="p">:</span> <span class="n">END</span>              <span class="c1"># If decide_next_step returns &quot;end&quot;, end the graph</span>',
      '<span class="w">    </span><span class="p">}</span>',
      '<span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Add edges to end the graph after summary or translate</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;summary&quot;</span><span class="p">,</span> <span class="n">END</span><span class="p">)</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;translate&quot;</span><span class="p">,</span> <span class="n">END</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Compile the graph</span>',
      '<span class="n">graph</span> <span class="o">=</span> <span class="n">graph_builder</span><span class="o">.</span><span class="n">compile</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Display the graph</span>',
      '<span class="k">try</span><span class="p">:</span>',
      '<span class="w">    </span><span class="n">display</span><span class="p">(</span><span class="n">Image</span><span class="p">(</span><span class="n">graph</span><span class="o">.</span><span class="n">get_graph</span><span class="p">()</span><span class="o">.</span><span class="n">draw_mermaid_png</span><span class="p">()))</span>',
      '<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error al visualizar el grafo: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '&amp;lt;IPython.core.display.Image object&amp;gt;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.messages</span><span class="w"> </span><span class="kn">import</span> <span class="n">HumanMessage</span>',
      '<span class="w"> </span>',
      '<span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;Large language models are powerful AI systems trained on vast amounts of text data.</span>',
      '<span class="s2">They can generate human-like text, translate languages, write different kinds of creative content, and answer your questions in an informative way.&quot;&quot;&quot;</span>',
      '<span class="w"> </span>',
      '<span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Summarize the following text: </span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s2">&quot;</span>',
      '<span class="w"> </span>',
      '<span class="n">messages</span> <span class="o">=</span> <span class="p">[</span><span class="n">HumanMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="n">prompt</span><span class="p">)]</span>',
      '<span class="w"> </span>',
      '<span class="n">result</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="n">messages</span><span class="p">})</span>',
      '<span class="w"> </span>',
      '<span class="k">for</span> <span class="n">message</span> <span class="ow">in</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">]:</span>',
      '<span class="w">    </span><span class="n">message</span><span class="o">.</span><span class="n">pretty_print</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '================================ Human Message =================================',
          'Summarize the following text: Large language models are powerful AI systems trained on vast amounts of text data.',
          'They can generate human-like text, translate languages, write different kinds of creative content, and answer your questions in an informative way.',
          '================================== Ai Message ==================================',
          'Large language models are advanced AI systems trained on extensive text data, enabling them to produce human-like text, translate languages, create various types of creative content, and provide informative answers to questions.',
          '================================== Ai Message ==================================',
          'Large language models are sophisticated AI systems trained on vast amounts of text data, which allows them to generate human-like text, translate languages, produce creative content, and answer questions informatively.',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.messages</span><span class="w"> </span><span class="kn">import</span> <span class="n">HumanMessage</span>',
      '<span class="w"> </span>',
      '<span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;Large language models are powerful AI systems trained on vast amounts of text data.</span>',
      '<span class="s2">They can generate human-like text, translate languages, write different kinds of creative content, and answer your questions in an informative way.&quot;&quot;&quot;</span>',
      '<span class="w"> </span>',
      '<span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Translate the following text to Spanish: </span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s2">&quot;</span>',
      '<span class="w"> </span>',
      '<span class="n">messages</span> <span class="o">=</span> <span class="p">[</span><span class="n">HumanMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="n">prompt</span><span class="p">)]</span>',
      '<span class="w"> </span>',
      '<span class="n">result</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="n">messages</span><span class="p">})</span>',
      '<span class="w"> </span>',
      '<span class="k">for</span> <span class="n">message</span> <span class="ow">in</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">]:</span>',
      '<span class="w">    </span><span class="n">message</span><span class="o">.</span><span class="n">pretty_print</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '================================ Human Message =================================',
          'Translate the following text to Spanish: Large language models are powerful AI systems trained on vast amounts of text data.',
          'They can generate human-like text, translate languages, write different kinds of creative content, and answer your questions in an informative way.',
          '================================== Ai Message ==================================',
          'Los modelos de lenguaje grandes son sistemas de IA potentes entrenados en enormes cantidades de datos de texto. Pueden generar texto similar al humano, traducir idiomas, escribir diversos tipos de contenido creativo y responder a tus preguntas de manera informativa.',
          '================================== Ai Message ==================================',
          'Los grandes modelos de lenguaje son sistemas de IA potentes entrenados en enormes cantidades de datos de texto. Pueden generar texto similar al humano, traducir idiomas, escribir diversos tipos de contenido creativo y responder a tus preguntas de manera informativa.',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h2 id="Parallelization">Parallelization<a class="anchor-link" href="#Parallelization"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 16" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <img decoding="async" onerror="this.parentNode.removeChild(this)" src="https://images.maximofn.com/agent_patterns_04_paralellitation.webp" alt="parallelization">
      </section>
      
      <section class="section-block-markdown-cell">
      <p>When a task is very important or complex, we can parallelize it so that different LLMs can execute it. Then we pass the result to an LLM to combine them. Let's look at an example where we have three LLMs that summarize a text in different ways and then combine them.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Annotated</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">typing_extensions</span><span class="w"> </span><span class="kn">import</span> <span class="n">TypedDict</span>',
      '<span class="w"> </span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">langgraph.graph</span><span class="w"> </span><span class="kn">import</span> <span class="n">StateGraph</span><span class="p">,</span> <span class="n">START</span><span class="p">,</span> <span class="n">END</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">langgraph.graph.message</span><span class="w"> </span><span class="kn">import</span> <span class="n">add_messages</span>',
      '<span class="w"> </span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_huggingface</span><span class="w"> </span><span class="kn">import</span> <span class="n">HuggingFaceEndpoint</span><span class="p">,</span> <span class="n">ChatHuggingFace</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.messages</span><span class="w"> </span><span class="kn">import</span> <span class="n">SystemMessage</span><span class="p">,</span> <span class="n">HumanMessage</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">huggingface_hub</span><span class="w"> </span><span class="kn">import</span> <span class="n">login</span>',
      '<span class="w"> </span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">IPython.display</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span><span class="p">,</span> <span class="n">display</span>',
      '<span class="w"> </span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>',
      '<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;LANGCHAIN_TRACING_V2&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;false&quot;</span>    <span class="c1"># Disable LangSmith tracing</span>',
      '<span class="w"> </span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">dotenv</span>',
      '<span class="n">dotenv</span><span class="o">.</span><span class="n">load_dotenv</span><span class="p">()</span>',
      '<span class="n">HUGGINGFACE_TOKEN</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;HUGGINGFACE_LANGGRAPH&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># State</span>',
      '<span class="k">class</span><span class="w"> </span><span class="nc">State</span><span class="p">(</span><span class="n">TypedDict</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">messages</span><span class="p">:</span> <span class="n">Annotated</span><span class="p">[</span><span class="nb">list</span><span class="p">,</span> <span class="n">add_messages</span><span class="p">]</span>',
      '<span class="w">    </span><span class="n">tiny_summary</span><span class="p">:</span> <span class="nb">str</span>',
      '<span class="w">    </span><span class="n">normal_summary</span><span class="p">:</span> <span class="nb">str</span>',
      '<span class="w">    </span><span class="n">extended_summary</span><span class="p">:</span> <span class="nb">str</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Create the LLM model</span>',
      '<span class="n">login</span><span class="p">(</span><span class="n">token</span><span class="o">=</span><span class="n">HUGGINGFACE_TOKEN</span><span class="p">)</span>  <span class="c1"># Login to HuggingFace to use the model</span>',
      '<span class="n">MODEL</span> <span class="o">=</span> <span class="s2">&quot;Qwen/Qwen2.5-72B-Instruct&quot;</span>',
      '<span class="n">model</span> <span class="o">=</span> <span class="n">HuggingFaceEndpoint</span><span class="p">(</span>',
      '<span class="w">    </span><span class="n">repo_id</span><span class="o">=</span><span class="n">MODEL</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">task</span><span class="o">=</span><span class="s2">&quot;text-generation&quot;</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">do_sample</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">repetition_penalty</span><span class="o">=</span><span class="mf">1.03</span><span class="p">,</span>',
      '<span class="p">)</span>',
      '<span class="c1"># Create the chat model</span>',
      '<span class="n">llm</span> <span class="o">=</span> <span class="n">ChatHuggingFace</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Function</span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">tiny_summary</span><span class="p">(</span><span class="n">state</span><span class="p">:</span> <span class="n">State</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">input_text</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">content</span>',
      '<span class="w">    </span><span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Summarize the following text in 10 words: </span><span class="si">{</span><span class="n">input_text</span><span class="si">}</span><span class="s2">&quot;</span>',
      '<span class="w">    </span><span class="n">llm_response</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="p">{</span><span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">llm_response</span><span class="p">],</span> <span class="s2">&quot;tiny_summary&quot;</span><span class="p">:</span> <span class="n">llm_response</span><span class="o">.</span><span class="n">content</span><span class="p">}</span>',
      '<span class="w"> </span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">normal_summary</span><span class="p">(</span><span class="n">state</span><span class="p">:</span> <span class="n">State</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">input_text</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">content</span>',
      '<span class="w">    </span><span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Summarize the following text: </span><span class="si">{</span><span class="n">input_text</span><span class="si">}</span><span class="s2">&quot;</span>',
      '<span class="w">    </span><span class="n">llm_response</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="p">{</span><span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">llm_response</span><span class="p">],</span> <span class="s2">&quot;normal_summary&quot;</span><span class="p">:</span> <span class="n">llm_response</span><span class="o">.</span><span class="n">content</span><span class="p">}</span>',
      '<span class="w"> </span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">extended_summary</span><span class="p">(</span><span class="n">state</span><span class="p">:</span> <span class="n">State</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">input_text</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">content</span>',
      '<span class="w">    </span><span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Summarize the following text in 100 words: </span><span class="si">{</span><span class="n">input_text</span><span class="si">}</span><span class="s2">&quot;</span>',
      '<span class="w">    </span><span class="n">llm_response</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="p">{</span><span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">llm_response</span><span class="p">],</span> <span class="s2">&quot;extended_summary&quot;</span><span class="p">:</span> <span class="n">llm_response</span><span class="o">.</span><span class="n">content</span><span class="p">}</span>',
      '<span class="w"> </span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">aggregate</span><span class="p">(</span><span class="n">state</span><span class="p">:</span> <span class="n">State</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Combine the following summaries into a single one: </span><span class="si">{</span><span class="n">state</span><span class="p">[</span><span class="s1">&#39;tiny_summary&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">state</span><span class="p">[</span><span class="s1">&#39;normal_summary&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">state</span><span class="p">[</span><span class="s1">&#39;extended_summary&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>',
      '<span class="w">    </span><span class="n">llm_response</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="p">{</span><span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">llm_response</span><span class="p">]}</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Start to build the graph</span>',
      '<span class="n">graph_builder</span> <span class="o">=</span> <span class="n">StateGraph</span><span class="p">(</span><span class="n">State</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Add nodes to the graph</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;tiny_summary_node&quot;</span><span class="p">,</span> <span class="n">tiny_summary</span><span class="p">)</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;normal_summary_node&quot;</span><span class="p">,</span> <span class="n">normal_summary</span><span class="p">)</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;extended_summary_node&quot;</span><span class="p">,</span> <span class="n">extended_summary</span><span class="p">)</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;aggregate_node&quot;</span><span class="p">,</span> <span class="n">aggregate</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Add edges</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">START</span><span class="p">,</span> <span class="s2">&quot;tiny_summary_node&quot;</span><span class="p">)</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">START</span><span class="p">,</span> <span class="s2">&quot;normal_summary_node&quot;</span><span class="p">)</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">START</span><span class="p">,</span> <span class="s2">&quot;extended_summary_node&quot;</span><span class="p">)</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;tiny_summary_node&quot;</span><span class="p">,</span> <span class="s2">&quot;aggregate_node&quot;</span><span class="p">)</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;normal_summary_node&quot;</span><span class="p">,</span> <span class="s2">&quot;aggregate_node&quot;</span><span class="p">)</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;extended_summary_node&quot;</span><span class="p">,</span> <span class="s2">&quot;aggregate_node&quot;</span><span class="p">)</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;aggregate_node&quot;</span><span class="p">,</span> <span class="n">END</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Compile the graph</span>',
      '<span class="n">graph</span> <span class="o">=</span> <span class="n">graph_builder</span><span class="o">.</span><span class="n">compile</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Display the graph</span>',
      '<span class="k">try</span><span class="p">:</span>',
      '<span class="w">    </span><span class="n">display</span><span class="p">(</span><span class="n">Image</span><span class="p">(</span><span class="n">graph</span><span class="o">.</span><span class="n">get_graph</span><span class="p">()</span><span class="o">.</span><span class="n">draw_mermaid_png</span><span class="p">()))</span>',
      '<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error al visualizar el grafo: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '&amp;lt;IPython.core.display.Image object&amp;gt;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.messages</span><span class="w"> </span><span class="kn">import</span> <span class="n">HumanMessage</span>',
      '<span class="w"> </span>',
      '<span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;Large language models are powerful AI systems trained on vast amounts of text data.</span>',
      '<span class="s2">They can generate human-like text, translate languages, write different kinds of creative content, and answer your questions in an informative way.&quot;&quot;&quot;</span>',
      '<span class="w"> </span>',
      '<span class="n">messages</span> <span class="o">=</span> <span class="p">[</span><span class="n">HumanMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="n">text</span><span class="p">)]</span>',
      '<span class="w"> </span>',
      '<span class="n">result</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="n">messages</span><span class="p">})</span>',
      '<span class="w"> </span>',
      '<span class="k">for</span> <span class="n">message</span> <span class="ow">in</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">]:</span>',
      '<span class="w">    </span><span class="n">message</span><span class="o">.</span><span class="n">pretty_print</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '================================ Human Message =================================',
          'Large language models are powerful AI systems trained on vast amounts of text data.',
          'They can generate human-like text, translate languages, write different kinds of creative content, and answer your questions in an informative way.',
          '================================== Ai Message ==================================',
          'Large language models are advanced AI systems trained on extensive text data, enabling them to produce human-like text, translate languages, create diverse content, and provide informative answers to questions. These models leverage their vast training data to understand context and generate responses that are often indistinguishable from those written by humans, making them useful in various applications such as writing, translation, and customer service.',
          '================================== Ai Message ==================================',
          'Large language models are advanced AI systems trained on extensive text data, enabling them to produce human-like text, translate languages, create various types of creative content, and provide informative answers to questions.',
          '================================== Ai Message ==================================',
          'AI models trained on text data generate human-like responses, translations, and content.',
          '================================== Ai Message ==================================',
          'Large language models are advanced AI systems trained on extensive text data, enabling them to produce human-like text, translate languages, create diverse and creative content, and provide informative answers to questions. These models leverage their vast training data to understand context and generate responses that are often indistinguishable from those written by humans, making them useful in various applications such as writing, translation, and customer service.',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h2 id="Evaluator-optimizer (reflection pattern)">Evaluator-optimizer (reflection pattern)<a class="anchor-link" href="#Evaluator-optimizer (reflection pattern)"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 17" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <img decoding="async" onerror="this.parentNode.removeChild(this)" src="https://images.maximofn.com/agent_patterns_05_reflection_pattern.webp" alt="reflection pattern">
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Another way to solve complex tasks is to have one LLM to solve the task and another LLM to evaluate the result, so they run in a loop until the evaluator considers that the work has been completed correctly. Let's look at an example where one LLM adds 1 to a number and another checks if the number is 10.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Annotated</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">typing_extensions</span><span class="w"> </span><span class="kn">import</span> <span class="n">TypedDict</span>',
      '<span class="w"> </span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">langgraph.graph</span><span class="w"> </span><span class="kn">import</span> <span class="n">StateGraph</span><span class="p">,</span> <span class="n">START</span><span class="p">,</span> <span class="n">END</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">langgraph.graph.message</span><span class="w"> </span><span class="kn">import</span> <span class="n">add_messages</span>',
      '<span class="w"> </span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_huggingface</span><span class="w"> </span><span class="kn">import</span> <span class="n">HuggingFaceEndpoint</span><span class="p">,</span> <span class="n">ChatHuggingFace</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.messages</span><span class="w"> </span><span class="kn">import</span> <span class="n">SystemMessage</span><span class="p">,</span> <span class="n">HumanMessage</span><span class="p">,</span> <span class="n">AIMessage</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">huggingface_hub</span><span class="w"> </span><span class="kn">import</span> <span class="n">login</span>',
      '<span class="w"> </span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">IPython.display</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span><span class="p">,</span> <span class="n">display</span>',
      '<span class="w"> </span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>',
      '<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;LANGCHAIN_TRACING_V2&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;false&quot;</span>    <span class="c1"># Disable LangSmith tracing</span>',
      '<span class="w"> </span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">dotenv</span>',
      '<span class="n">dotenv</span><span class="o">.</span><span class="n">load_dotenv</span><span class="p">()</span>',
      '<span class="n">HUGGINGFACE_TOKEN</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;HUGGINGFACE_LANGGRAPH&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># State</span>',
      '<span class="k">class</span><span class="w"> </span><span class="nc">State</span><span class="p">(</span><span class="n">TypedDict</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">messages</span><span class="p">:</span> <span class="n">Annotated</span><span class="p">[</span><span class="nb">list</span><span class="p">,</span> <span class="n">add_messages</span><span class="p">]</span>',
      '<span class="w">    </span><span class="n">number</span><span class="p">:</span> <span class="nb">int</span>',
      '<span class="w">    </span><span class="n">evaluator</span><span class="p">:</span> <span class="nb">str</span>',
      '<span class="w">    </span>',
      '<span class="c1"># Create the LLM model</span>',
      '<span class="n">login</span><span class="p">(</span><span class="n">token</span><span class="o">=</span><span class="n">HUGGINGFACE_TOKEN</span><span class="p">)</span>  <span class="c1"># Login to HuggingFace to use the model</span>',
      '<span class="n">MODEL</span> <span class="o">=</span> <span class="s2">&quot;Qwen/Qwen2.5-72B-Instruct&quot;</span>',
      '<span class="n">model</span> <span class="o">=</span> <span class="n">HuggingFaceEndpoint</span><span class="p">(</span>',
      '<span class="w">    </span><span class="n">repo_id</span><span class="o">=</span><span class="n">MODEL</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">task</span><span class="o">=</span><span class="s2">&quot;text-generation&quot;</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">do_sample</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">repetition_penalty</span><span class="o">=</span><span class="mf">1.03</span><span class="p">,</span>',
      '<span class="p">)</span>',
      '<span class="c1"># Create the chat model</span>',
      '<span class="n">llm</span> <span class="o">=</span> <span class="n">ChatHuggingFace</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Function</span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">agregate_1</span><span class="p">(</span><span class="n">state</span><span class="p">:</span> <span class="n">State</span><span class="p">):</span>',
      '<span class="w">    </span><span class="k">if</span> <span class="n">state</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;number&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">input_text</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">content</span>',
      '<span class="w">        </span><span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Get the number from the following text: </span><span class="si">{</span><span class="n">input_text</span><span class="si">}</span><span class="s2">. Respond only with the number.&quot;</span>',
      '<span class="w">        </span><span class="n">number_str</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">number</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">number_str</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">state</span><span class="p">[</span><span class="s2">&quot;number&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">number</span>',
      '<span class="w">    </span>',
      '<span class="w">    </span><span class="n">number_state</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;number&quot;</span><span class="p">]</span>',
      '<span class="w">    </span><span class="n">number_plus_1</span> <span class="o">=</span> <span class="n">number_state</span> <span class="o">+</span> <span class="mi">1</span>',
      '<span class="w">    </span><span class="n">response</span> <span class="o">=</span> <span class="n">AIMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;[Agregator] --&amp;gt; The number is </span><span class="si">{</span><span class="n">number_state</span><span class="si">}</span><span class="s2"> and the next number is </span><span class="si">{</span><span class="n">number_plus_1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="p">{</span><span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">response</span><span class="p">],</span> <span class="s2">&quot;number&quot;</span><span class="p">:</span> <span class="n">number_plus_1</span><span class="p">,</span> <span class="s2">&quot;evaluator&quot;</span><span class="p">:</span> <span class="s2">&quot;no&quot;</span><span class="p">}</span>',
      '<span class="w"> </span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">evaluator</span><span class="p">(</span><span class="n">state</span><span class="p">:</span> <span class="n">State</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Is the following number </span><span class="si">{</span><span class="n">state</span><span class="p">[</span><span class="s1">&#39;number&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> equal to 10? Respond only with &#39;yes&#39; or &#39;no&#39;.&quot;</span>',
      '<span class="w">    </span><span class="n">result</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">number_state</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;number&quot;</span><span class="p">]</span>',
      '<span class="w">    </span><span class="n">response</span> <span class="o">=</span> <span class="n">AIMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;[Evaluator] --&amp;gt; Is the following number </span><span class="si">{</span><span class="n">number_state</span><span class="si">}</span><span class="s2"> equal to 10? Result: </span><span class="si">{</span><span class="n">result</span><span class="o">.</span><span class="n">content</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="p">{</span><span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">response</span><span class="p">],</span> <span class="s2">&quot;evaluator&quot;</span><span class="p">:</span> <span class="n">result</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="s2">&quot;number&quot;</span><span class="p">:</span> <span class="n">number_state</span><span class="p">}</span>',
      '<span class="w"> </span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">decide_next_step</span><span class="p">(</span><span class="n">state</span><span class="p">:</span> <span class="n">State</span><span class="p">):</span>',
      '<span class="w">    </span><span class="k">if</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;evaluator&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;yes&quot;</span><span class="p">:</span>',
      '<span class="w">        </span><span class="k">return</span> <span class="n">END</span>',
      '<span class="w">    </span><span class="k">else</span><span class="p">:</span>',
      '<span class="w">        </span><span class="k">return</span> <span class="s2">&quot;agregate_1_node&quot;</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Start to build the graph</span>',
      '<span class="n">graph_builder</span> <span class="o">=</span> <span class="n">StateGraph</span><span class="p">(</span><span class="n">State</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Add nodes to the graph</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;agregate_1_node&quot;</span><span class="p">,</span> <span class="n">agregate_1</span><span class="p">)</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;evaluator_node&quot;</span><span class="p">,</span> <span class="n">evaluator</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Add edges</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">START</span><span class="p">,</span> <span class="s2">&quot;agregate_1_node&quot;</span><span class="p">)</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;agregate_1_node&quot;</span><span class="p">,</span> <span class="s2">&quot;evaluator_node&quot;</span><span class="p">)</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_conditional_edges</span><span class="p">(</span>',
      '<span class="w">    </span><span class="s2">&quot;evaluator_node&quot;</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">decide_next_step</span><span class="p">,</span>',
      '<span class="w">    </span><span class="p">{</span>',
      '<span class="w">        </span><span class="s2">&quot;agregate_1_node&quot;</span><span class="p">:</span> <span class="s2">&quot;agregate_1_node&quot;</span><span class="p">,</span>',
      '<span class="w">        </span><span class="n">END</span><span class="p">:</span> <span class="n">END</span>',
      '<span class="w">    </span><span class="p">}</span>',
      '<span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Compile the graph</span>',
      '<span class="n">graph</span> <span class="o">=</span> <span class="n">graph_builder</span><span class="o">.</span><span class="n">compile</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Display the graph</span>',
      '<span class="k">try</span><span class="p">:</span>',
      '<span class="w">    </span><span class="n">display</span><span class="p">(</span><span class="n">Image</span><span class="p">(</span><span class="n">graph</span><span class="o">.</span><span class="n">get_graph</span><span class="p">()</span><span class="o">.</span><span class="n">draw_mermaid_png</span><span class="p">()))</span>',
      '<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error al visualizar el grafo: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '&amp;lt;IPython.core.display.Image object&amp;gt;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.messages</span><span class="w"> </span><span class="kn">import</span> <span class="n">HumanMessage</span>',
      '<span class="w"> </span>',
      '<span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;Start the process with the number 1&quot;</span>',
      '<span class="w"> </span>',
      '<span class="n">messages</span> <span class="o">=</span> <span class="p">[</span><span class="n">HumanMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="n">prompt</span><span class="p">)]</span>',
      '<span class="w"> </span>',
      '<span class="n">result</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="n">messages</span><span class="p">},</span> <span class="p">{</span><span class="s2">&quot;number&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">})</span>',
      '<span class="w"> </span>',
      '<span class="k">for</span> <span class="n">message</span> <span class="ow">in</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">]:</span>',
      '<span class="w">    </span><span class="n">message</span><span class="o">.</span><span class="n">pretty_print</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '================================ Human Message =================================',
          'Start the process with the number 1',
          '================================== Ai Message ==================================',
          '[Agregator] --&amp;gt; The number is 1 and the next number is 2',
          '================================== Ai Message ==================================',
          '[Evaluator] --&amp;gt; Is the following number 2 equal to 10? Result: no',
          '================================== Ai Message ==================================',
          '[Agregator] --&amp;gt; The number is 2 and the next number is 3',
          '================================== Ai Message ==================================',
          '[Evaluator] --&amp;gt; Is the following number 3 equal to 10? Result: no',
          '================================== Ai Message ==================================',
          '[Agregator] --&amp;gt; The number is 3 and the next number is 4',
          '================================== Ai Message ==================================',
          '[Evaluator] --&amp;gt; Is the following number 4 equal to 10? Result: no',
          '================================== Ai Message ==================================',
          '[Agregator] --&amp;gt; The number is 4 and the next number is 5',
          '================================== Ai Message ==================================',
          '[Evaluator] --&amp;gt; Is the following number 5 equal to 10? Result: no',
          '================================== Ai Message ==================================',
          '[Agregator] --&amp;gt; The number is 5 and the next number is 6',
          '================================== Ai Message ==================================',
          '[Evaluator] --&amp;gt; Is the following number 6 equal to 10? Result: no',
          '================================== Ai Message ==================================',
          '[Agregator] --&amp;gt; The number is 6 and the next number is 7',
          '================================== Ai Message ==================================',
          '[Evaluator] --&amp;gt; Is the following number 7 equal to 10? Result: no',
          '================================== Ai Message ==================================',
          '[Agregator] --&amp;gt; The number is 7 and the next number is 8',
          '================================== Ai Message ==================================',
          '[Evaluator] --&amp;gt; Is the following number 8 equal to 10? Result: no',
          '================================== Ai Message ==================================',
          '[Agregator] --&amp;gt; The number is 8 and the next number is 9',
          '================================== Ai Message ==================================',
          '[Evaluator] --&amp;gt; Is the following number 9 equal to 10? Result: no',
          '================================== Ai Message ==================================',
          '[Agregator] --&amp;gt; The number is 9 and the next number is 10',
          '================================== Ai Message ==================================',
          '[Evaluator] --&amp;gt; Is the following number 10 equal to 10? Result: yes',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h2 id="Agent with tools (ReAct pattern)">Agent with tools (ReAct pattern)<a class="anchor-link" href="#Agent with tools (ReAct pattern)"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 18" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <img decoding="async" onerror="this.parentNode.removeChild(this)" src="https://images.maximofn.com/agent_patterns_06_react_pattern.webp" alt="ReAct pattern">
      </section>
      
      <section class="section-block-markdown-cell">
      <blockquote>
      <p>**Note**: I will have to solve this pattern with Sonnet</p>
      </blockquote>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Another possibility is to provide the agent with tools</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Annotated</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">typing_extensions</span><span class="w"> </span><span class="kn">import</span> <span class="n">TypedDict</span>',
      '<span class="w"> </span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">langgraph.graph</span><span class="w"> </span><span class="kn">import</span> <span class="n">StateGraph</span><span class="p">,</span> <span class="n">START</span><span class="p">,</span> <span class="n">END</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">langgraph.graph.message</span><span class="w"> </span><span class="kn">import</span> <span class="n">add_messages</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">langgraph.prebuilt</span><span class="w"> </span><span class="kn">import</span> <span class="n">ToolNode</span><span class="p">,</span> <span class="n">tools_condition</span>',
      '<span class="w"> </span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_huggingface</span><span class="w"> </span><span class="kn">import</span> <span class="n">HuggingFaceEndpoint</span><span class="p">,</span> <span class="n">ChatHuggingFace</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_anthropic</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatAnthropic</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.messages</span><span class="w"> </span><span class="kn">import</span> <span class="n">SystemMessage</span><span class="p">,</span> <span class="n">HumanMessage</span><span class="p">,</span> <span class="n">AIMessage</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.tools</span><span class="w"> </span><span class="kn">import</span> <span class="n">tool</span>',
      '<span class="w"> </span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">huggingface_hub</span><span class="w"> </span><span class="kn">import</span> <span class="n">login</span>',
      '<span class="w"> </span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">IPython.display</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span><span class="p">,</span> <span class="n">display</span>',
      '<span class="w"> </span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>',
      '<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;LANGCHAIN_TRACING_V2&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;false&quot;</span>    <span class="c1"># Disable LangSmith tracing</span>',
      '<span class="w"> </span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">dotenv</span>',
      '<span class="n">dotenv</span><span class="o">.</span><span class="n">load_dotenv</span><span class="p">()</span>',
      '<span class="n">ANTHROPIC_TOKEN</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;ANTHROPIC_LANGGRAPH_API_KEY&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># State</span>',
      '<span class="k">class</span><span class="w"> </span><span class="nc">State</span><span class="p">(</span><span class="n">TypedDict</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">messages</span><span class="p">:</span> <span class="n">Annotated</span><span class="p">[</span><span class="nb">list</span><span class="p">,</span> <span class="n">add_messages</span><span class="p">]</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Tools</span>',
      '<span class="nd">@tool</span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">multiply</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&amp;</span><span class="n">gt</span><span class="p">;</span> <span class="nb">int</span><span class="p">:</span>',
      '<span class="w">    </span><span class="sd">&quot;&quot;&quot;Multiply a and b.</span>',
      '<span class="w"> </span>',
      '<span class="sd">    Args:</span>',
      '<span class="sd">        a: first int</span>',
      '<span class="sd">        b: second int</span>',
      '<span class="w"> </span>',
      '<span class="sd">    Returns:</span>',
      '<span class="sd">        The product of a and b.</span>',
      '<span class="sd">    &quot;&quot;&quot;</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">a</span> <span class="o">*</span> <span class="n">b</span>',
      '<span class="w"> </span>',
      '<span class="n">tools_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">multiply</span><span class="p">]</span>',
      '<span class="w">    </span>',
      '<span class="c1"># Create the LLM model</span>',
      '<span class="n">llm</span> <span class="o">=</span> <span class="n">ChatAnthropic</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;claude-3-7-sonnet-20250219&quot;</span><span class="p">,</span> <span class="n">api_key</span><span class="o">=</span><span class="n">ANTHROPIC_TOKEN</span><span class="p">)</span>',
      '<span class="n">llm_with_tools</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">bind_tools</span><span class="p">(</span><span class="n">tools_list</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Function</span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">chatbot_function</span><span class="p">(</span><span class="n">state</span><span class="p">:</span> <span class="n">State</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">system_message</span> <span class="o">=</span> <span class="s2">&quot;You are a helpful assistant that can use tools to answer questions. Once you have the result of a tool, provide a final answer without calling more tools.&quot;</span>',
      '<span class="w">    </span><span class="n">messages</span> <span class="o">=</span> <span class="p">[</span><span class="n">SystemMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="n">system_message</span><span class="p">)]</span> <span class="o">+</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">]</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="p">{</span><span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">llm_with_tools</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">messages</span><span class="p">)]}</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Start to build the graph</span>',
      '<span class="n">graph_builder</span> <span class="o">=</span> <span class="n">StateGraph</span><span class="p">(</span><span class="n">State</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Add nodes to the graph</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;chatbot_node&quot;</span><span class="p">,</span> <span class="n">chatbot_function</span><span class="p">)</span>',
      '<span class="n">tool_node</span> <span class="o">=</span> <span class="n">ToolNode</span><span class="p">(</span><span class="n">tools</span><span class="o">=</span><span class="n">tools_list</span><span class="p">)</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;tools&quot;</span><span class="p">,</span> <span class="n">tool_node</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Add edges</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">START</span><span class="p">,</span> <span class="s2">&quot;chatbot_node&quot;</span><span class="p">)</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_conditional_edges</span><span class="p">(</span><span class="s2">&quot;chatbot_node&quot;</span><span class="p">,</span> <span class="n">tools_condition</span><span class="p">)</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;tools&quot;</span><span class="p">,</span> <span class="s2">&quot;chatbot_node&quot;</span><span class="p">)</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;chatbot_node&quot;</span><span class="p">,</span> <span class="n">END</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Compile the graph</span>',
      '<span class="n">graph</span> <span class="o">=</span> <span class="n">graph_builder</span><span class="o">.</span><span class="n">compile</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Display the graph</span>',
      '<span class="k">try</span><span class="p">:</span>',
      '<span class="w">    </span><span class="n">display</span><span class="p">(</span><span class="n">Image</span><span class="p">(</span><span class="n">graph</span><span class="o">.</span><span class="n">get_graph</span><span class="p">()</span><span class="o">.</span><span class="n">draw_mermaid_png</span><span class="p">()))</span>',
      '<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error al visualizar el grafo: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '&amp;lt;IPython.core.display.Image object&amp;gt;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.messages</span><span class="w"> </span><span class="kn">import</span> <span class="n">HumanMessage</span>',
      '<span class="w"> </span>',
      '<span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;Multiply 2 and 3&quot;</span>',
      '<span class="w"> </span>',
      '<span class="n">messages</span> <span class="o">=</span> <span class="p">[</span><span class="n">HumanMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="n">prompt</span><span class="p">)]</span>',
      '<span class="w"> </span>',
      '<span class="n">result</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="n">messages</span><span class="p">},</span> <span class="p">{</span><span class="s2">&quot;number&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">})</span>',
      '<span class="w"> </span>',
      '<span class="k">for</span> <span class="n">message</span> <span class="ow">in</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">]:</span>',
      '<span class="w">    </span><span class="n">message</span><span class="o">.</span><span class="n">pretty_print</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '================================ Human Message =================================',
          'Multiply 2 and 3',
          '================================== Ai Message ==================================',
          '[&#x7B;&#x27;text&#x27;: &quot;I&#x27;ll calculate the product of 2 and 3 for you using the multiply function.&quot;, &#x27;type&#x27;: &#x27;text&#x27;&#x7D;, &#x7B;&#x27;id&#x27;: &#x27;toolu_01BEDxEjrJX51kGLfYENBEot&#x27;, &#x27;input&#x27;: &#x7B;&#x27;a&#x27;: 2, &#x27;b&#x27;: 3&#x7D;, &#x27;name&#x27;: &#x27;multiply&#x27;, &#x27;type&#x27;: &#x27;tool_use&#x27;&#x7D;]',
          'Tool Calls:',
          '&#x20;&#x20;multiply (toolu_01BEDxEjrJX51kGLfYENBEot)',
          'Call ID: toolu_01BEDxEjrJX51kGLfYENBEot',
          '&#x20;&#x20;Args:',
          '&#x20;&#x20;&#x20;&#x20;a: 2',
          '&#x20;&#x20;&#x20;&#x20;b: 3',
          '================================= Tool Message =================================',
          'Name: multiply',
          '6',
          '================================== Ai Message ==================================',
          'The product of 2 and 3 is 6.',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h2 id="Planning pattern">Planning pattern<a class="anchor-link" href="#Planning pattern"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 19" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <img decoding="async" onerror="this.parentNode.removeChild(this)" src="https://images.maximofn.com/agent_patterns_07_planning_pattern.webp" alt="planning pattern">
      </section>
      
      <section class="section-block-markdown-cell">
      <p>In this case, an LLM breaks down the problem into several tasks and assigns them to other agents, then another LLM combines the responses from the agents to provide a final answer. Let's look at the problem of summarizing and translating a text.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Annotated</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">typing_extensions</span><span class="w"> </span><span class="kn">import</span> <span class="n">TypedDict</span>',
      '<span class="w"> </span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">langgraph.graph</span><span class="w"> </span><span class="kn">import</span> <span class="n">StateGraph</span><span class="p">,</span> <span class="n">START</span><span class="p">,</span> <span class="n">END</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">langgraph.graph.message</span><span class="w"> </span><span class="kn">import</span> <span class="n">add_messages</span>',
      '<span class="w"> </span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_huggingface</span><span class="w"> </span><span class="kn">import</span> <span class="n">HuggingFaceEndpoint</span><span class="p">,</span> <span class="n">ChatHuggingFace</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.messages</span><span class="w"> </span><span class="kn">import</span> <span class="n">SystemMessage</span><span class="p">,</span> <span class="n">HumanMessage</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">huggingface_hub</span><span class="w"> </span><span class="kn">import</span> <span class="n">login</span>',
      '<span class="w"> </span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">IPython.display</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span><span class="p">,</span> <span class="n">display</span>',
      '<span class="w"> </span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>',
      '<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;LANGCHAIN_TRACING_V2&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;false&quot;</span>    <span class="c1"># Disable LangSmith tracing</span>',
      '<span class="w"> </span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">dotenv</span>',
      '<span class="n">dotenv</span><span class="o">.</span><span class="n">load_dotenv</span><span class="p">()</span>',
      '<span class="n">HUGGINGFACE_TOKEN</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;HUGGINGFACE_LANGGRAPH&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># State</span>',
      '<span class="k">class</span><span class="w"> </span><span class="nc">State</span><span class="p">(</span><span class="n">TypedDict</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">messages</span><span class="p">:</span> <span class="n">Annotated</span><span class="p">[</span><span class="nb">list</span><span class="p">,</span> <span class="n">add_messages</span><span class="p">]</span>',
      '<span class="w">    </span><span class="n">text_to_summarize</span><span class="p">:</span> <span class="nb">str</span>',
      '<span class="w">    </span><span class="n">text_to_translate</span><span class="p">:</span> <span class="nb">str</span>',
      '<span class="w">    </span><span class="n">summary</span><span class="p">:</span> <span class="nb">str</span>',
      '<span class="w">    </span><span class="n">translation</span><span class="p">:</span> <span class="nb">str</span>',
      '<span class="c1"># Create the LLM model</span>',
      '<span class="n">login</span><span class="p">(</span><span class="n">token</span><span class="o">=</span><span class="n">HUGGINGFACE_TOKEN</span><span class="p">)</span>  <span class="c1"># Login to HuggingFace to use the model</span>',
      '<span class="n">MODEL</span> <span class="o">=</span> <span class="s2">&quot;Qwen/Qwen2.5-72B-Instruct&quot;</span>',
      '<span class="n">model</span> <span class="o">=</span> <span class="n">HuggingFaceEndpoint</span><span class="p">(</span>',
      '<span class="w">    </span><span class="n">repo_id</span><span class="o">=</span><span class="n">MODEL</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">task</span><span class="o">=</span><span class="s2">&quot;text-generation&quot;</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">do_sample</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">repetition_penalty</span><span class="o">=</span><span class="mf">1.03</span><span class="p">,</span>',
      '<span class="p">)</span>',
      '<span class="c1"># Create the chat model</span>',
      '<span class="n">llm</span> <span class="o">=</span> <span class="n">ChatHuggingFace</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Function</span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">planner_function</span><span class="p">(</span><span class="n">state</span><span class="p">:</span> <span class="n">State</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">input_text</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">content</span>',
      '<span class="w">    </span><span class="n">text_to_summarize</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Summarize the following text: </span><span class="si">{</span><span class="n">input_text</span><span class="si">}</span><span class="s2">&quot;</span>',
      '<span class="w">    </span><span class="n">text_to_translate</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Translate the following text to Spanish: </span><span class="si">{</span><span class="n">input_text</span><span class="si">}</span><span class="s2">&quot;</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="p">{</span>',
      '<span class="w">        </span><span class="s2">&quot;text_to_summarize&quot;</span><span class="p">:</span> <span class="n">text_to_summarize</span><span class="p">,</span>',
      '<span class="w">        </span><span class="s2">&quot;text_to_translate&quot;</span><span class="p">:</span> <span class="n">text_to_translate</span>',
      '<span class="w">    </span><span class="p">}</span>',
      '<span class="w"> </span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">summary_function</span><span class="p">(</span><span class="n">state</span><span class="p">:</span> <span class="n">State</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">input_text</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;text_to_summarize&quot;</span><span class="p">]</span>',
      '<span class="w">    </span><span class="n">llm_response</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">input_text</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">summary</span> <span class="o">=</span> <span class="n">llm_response</span><span class="o">.</span><span class="n">content</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="p">{</span><span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">llm_response</span><span class="p">],</span> <span class="s2">&quot;summary&quot;</span><span class="p">:</span> <span class="n">summary</span><span class="p">}</span>',
      '<span class="w"> </span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">translate_function</span><span class="p">(</span><span class="n">state</span><span class="p">:</span> <span class="n">State</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">input_text</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;text_to_translate&quot;</span><span class="p">]</span>',
      '<span class="w">    </span><span class="n">llm_response</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">input_text</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">translation</span> <span class="o">=</span> <span class="n">llm_response</span><span class="o">.</span><span class="n">content</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="p">{</span><span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">llm_response</span><span class="p">],</span> <span class="s2">&quot;translation&quot;</span><span class="p">:</span> <span class="n">translation</span><span class="p">}</span>',
      '<span class="w"> </span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">aggregate_function</span><span class="p">(</span><span class="n">state</span><span class="p">:</span> <span class="n">State</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;Combine the following summary and translation into a single one: </span>',
      '<span class="s2">    SUMMARY: </span><span class="si">{</span><span class="n">state</span><span class="p">[</span><span class="s1">&#39;summary&#39;</span><span class="p">]</span><span class="si">}</span>',
      '<span class="s2">    TRANSLATION: </span><span class="si">{</span><span class="n">state</span><span class="p">[</span><span class="s1">&#39;translation&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;&quot;&quot;</span>',
      '<span class="w">    </span><span class="n">llm_response</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="p">{</span><span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">llm_response</span><span class="p">]}</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Start to build the graph</span>',
      '<span class="n">graph_builder</span> <span class="o">=</span> <span class="n">StateGraph</span><span class="p">(</span><span class="n">State</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Add nodes to the graph</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;planner_node&quot;</span><span class="p">,</span> <span class="n">planner_function</span><span class="p">)</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;summary_node&quot;</span><span class="p">,</span> <span class="n">summary_function</span><span class="p">)</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;translate_node&quot;</span><span class="p">,</span> <span class="n">translate_function</span><span class="p">)</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;aggregate_node&quot;</span><span class="p">,</span> <span class="n">aggregate_function</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Add edges</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">START</span><span class="p">,</span> <span class="s2">&quot;planner_node&quot;</span><span class="p">)</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;planner_node&quot;</span><span class="p">,</span> <span class="s2">&quot;summary_node&quot;</span><span class="p">)</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;planner_node&quot;</span><span class="p">,</span> <span class="s2">&quot;translate_node&quot;</span><span class="p">)</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;summary_node&quot;</span><span class="p">,</span> <span class="s2">&quot;aggregate_node&quot;</span><span class="p">)</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;translate_node&quot;</span><span class="p">,</span> <span class="s2">&quot;aggregate_node&quot;</span><span class="p">)</span>',
      '<span class="n">graph_builder</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;aggregate_node&quot;</span><span class="p">,</span> <span class="n">END</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Compile the graph</span>',
      '<span class="n">graph</span> <span class="o">=</span> <span class="n">graph_builder</span><span class="o">.</span><span class="n">compile</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Display the graph</span>',
      '<span class="k">try</span><span class="p">:</span>',
      '<span class="w">    </span><span class="n">display</span><span class="p">(</span><span class="n">Image</span><span class="p">(</span><span class="n">graph</span><span class="o">.</span><span class="n">get_graph</span><span class="p">()</span><span class="o">.</span><span class="n">draw_mermaid_png</span><span class="p">()))</span>',
      '<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error al visualizar el grafo: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '&amp;lt;IPython.core.display.Image object&amp;gt;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.messages</span><span class="w"> </span><span class="kn">import</span> <span class="n">HumanMessage</span>',
      '<span class="w"> </span>',
      '<span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;Large language models are powerful AI systems trained on vast amounts of text data.</span>',
      '<span class="s2">They can generate human-like text, translate languages, write different kinds of creative content, and answer your questions in an informative way.&quot;&quot;&quot;</span>',
      '<span class="w"> </span>',
      '<span class="n">messages</span> <span class="o">=</span> <span class="p">[</span><span class="n">HumanMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="n">text</span><span class="p">)]</span>',
      '<span class="w"> </span>',
      '<span class="n">result</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="n">messages</span><span class="p">})</span>',
      '<span class="w"> </span>',
      '<span class="k">for</span> <span class="n">message</span> <span class="ow">in</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">]:</span>',
      '<span class="w">    </span><span class="n">message</span><span class="o">.</span><span class="n">pretty_print</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '================================ Human Message =================================',
          'Large language models are powerful AI systems trained on vast amounts of text data.',
          'They can generate human-like text, translate languages, write different kinds of creative content, and answer your questions in an informative way.',
          '================================== Ai Message ==================================',
          'Large language models are advanced AI systems trained on extensive text data. These models can produce text that resembles human writing, translate between languages, create various types of creative content, and provide informative answers to questions.',
          '================================== Ai Message ==================================',
          'Los grandes modelos de lenguaje son potentes sistemas de IA entrenados con enormes cantidades de datos de texto. Pueden generar texto similar al humano, traducir idiomas, escribir diversos tipos de contenido creativo y responder tus preguntas de manera informativa.',
          '================================== Ai Message ==================================',
          'Los grandes modelos de lenguaje son potentes sistemas de IA entrenados con enormes cantidades de datos de texto. Estos modelos pueden generar texto similar al humano, traducir entre idiomas, crear diversos tipos de contenido creativo y proporcionar respuestas informativas a tus preguntas.',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h2 id="Multi agent pattern">Multi agent pattern<a class="anchor-link" href="#Multi agent pattern"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 20" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <img decoding="async" onerror="this.parentNode.removeChild(this)" src="https://images.maximofn.com/agent_patterns_08_multi_agent_pattern.webp" alt="multi agent pattern">
      </section>
      
      <section class="section-block-markdown-cell">
      <p>In this case, we have a coordinator agent that is responsible for assigning tasks to the agents. Additionally, agents can request tasks from each other.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>This would be a possible workflow:</p>
      <img decoding="async" onerror="this.parentNode.removeChild(this)" src="https://images.maximofn.com/agent_patterns_08_multi_agent_workflow.webp" alt="multi agent workflow">
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Let's do a little deep research</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Worker 1: News Agent">Worker 1: News Agent<a class="anchor-link" href="#Worker 1: News Agent"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 21" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>We create the first worker, an agent responsible for searching the internet and generating extensive reports, requesting more than 200 words. Additionally, I will create a checkpoint for it to have context of what it has already searched.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Annotated</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">typing_extensions</span><span class="w"> </span><span class="kn">import</span> <span class="n">TypedDict</span>',
      '<span class="w"> </span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">langgraph.graph</span><span class="w"> </span><span class="kn">import</span> <span class="n">StateGraph</span><span class="p">,</span> <span class="n">START</span><span class="p">,</span> <span class="n">END</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">langgraph.graph.message</span><span class="w"> </span><span class="kn">import</span> <span class="n">add_messages</span>',
      '<span class="w"> </span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_huggingface</span><span class="w"> </span><span class="kn">import</span> <span class="n">HuggingFaceEndpoint</span><span class="p">,</span> <span class="n">ChatHuggingFace</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">huggingface_hub</span><span class="w"> </span><span class="kn">import</span> <span class="n">login</span>',
      '<span class="w"> </span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_community.utilities.tavily_search</span><span class="w"> </span><span class="kn">import</span> <span class="n">TavilySearchAPIWrapper</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_community.tools.tavily_search</span><span class="w"> </span><span class="kn">import</span> <span class="n">TavilySearchResults</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.messages</span><span class="w"> </span><span class="kn">import</span> <span class="n">SystemMessage</span><span class="p">,</span> <span class="n">ToolMessage</span>',
      '<span class="w"> </span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">langgraph.prebuilt</span><span class="w"> </span><span class="kn">import</span> <span class="n">ToolNode</span><span class="p">,</span> <span class="n">tools_condition</span>',
      '<span class="w"> </span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">langgraph.checkpoint.memory</span><span class="w"> </span><span class="kn">import</span> <span class="n">MemorySaver</span>',
      '<span class="w"> </span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">IPython.display</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span><span class="p">,</span> <span class="n">display</span>',
      '<span class="w"> </span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>',
      '<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;LANGCHAIN_TRACING_V2&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;false&quot;</span>    <span class="c1"># Disable LangSmith tracing</span>',
      '<span class="w"> </span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">dotenv</span>',
      '<span class="n">dotenv</span><span class="o">.</span><span class="n">load_dotenv</span><span class="p">()</span>',
      '<span class="n">HUGGINGFACE_TOKEN</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;HUGGINGFACE_LANGGRAPH&quot;</span><span class="p">)</span>',
      '<span class="n">TAVILY_API_KEY</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;TAVILY_LANGGRAPH_API_KEY&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># State</span>',
      '<span class="k">class</span><span class="w"> </span><span class="nc">State_searcher</span><span class="p">(</span><span class="n">TypedDict</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">messages</span><span class="p">:</span> <span class="n">Annotated</span><span class="p">[</span><span class="nb">list</span><span class="p">,</span> <span class="n">add_messages</span><span class="p">]</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Tools</span>',
      '<span class="n">wrapper</span> <span class="o">=</span> <span class="n">TavilySearchAPIWrapper</span><span class="p">(</span><span class="n">tavily_api_key</span><span class="o">=</span><span class="n">TAVILY_API_KEY</span><span class="p">)</span>',
      '<span class="n">tool_search</span> <span class="o">=</span> <span class="n">TavilySearchResults</span><span class="p">(</span><span class="n">api_wrapper</span><span class="o">=</span><span class="n">wrapper</span><span class="p">,</span> <span class="n">max_results</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>',
      '<span class="n">tools_searcher_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">tool_search</span><span class="p">]</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Create the LLM model</span>',
      '<span class="n">login</span><span class="p">(</span><span class="n">token</span><span class="o">=</span><span class="n">HUGGINGFACE_TOKEN</span><span class="p">)</span>  <span class="c1"># Login to HuggingFace to use the model</span>',
      '<span class="n">MODEL</span> <span class="o">=</span> <span class="s2">&quot;Qwen/Qwen2.5-72B-Instruct&quot;</span>',
      '<span class="n">model_searcher</span> <span class="o">=</span> <span class="n">HuggingFaceEndpoint</span><span class="p">(</span>',
      '<span class="w">    </span><span class="n">repo_id</span><span class="o">=</span><span class="n">MODEL</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">task</span><span class="o">=</span><span class="s2">&quot;text-generation&quot;</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">do_sample</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">repetition_penalty</span><span class="o">=</span><span class="mf">1.03</span><span class="p">,</span>',
      '<span class="p">)</span>',
      '<span class="c1"># Create the chat model</span>',
      '<span class="n">llm_searcher</span> <span class="o">=</span> <span class="n">ChatHuggingFace</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">model_searcher</span><span class="p">)</span>',
      '<span class="c1"># Create the LLM with tools</span>',
      '<span class="n">llm_searcher_with_tools</span> <span class="o">=</span> <span class="n">llm_searcher</span><span class="o">.</span><span class="n">bind_tools</span><span class="p">(</span><span class="n">tools_searcher_list</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Tool node</span>',
      '<span class="n">tool_searcher_node</span> <span class="o">=</span> <span class="n">ToolNode</span><span class="p">(</span><span class="n">tools</span><span class="o">=</span><span class="n">tools_searcher_list</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Functions</span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">searcher_function</span><span class="p">(</span><span class="n">state</span><span class="p">:</span> <span class="n">State_searcher</span><span class="p">):</span>',
      '<span class="w">    </span><span class="c1"># Check if the last message is a ToolMessage</span>',
      '<span class="w">    </span><span class="k">if</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">]</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">ToolMessage</span><span class="p">):</span>',
      '<span class="w">        </span><span class="c1"># If it is, it means the tool has run, so we pass the messages as they are.</span>',
      '<span class="w">        </span><span class="k">return</span> <span class="p">{</span><span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">]}</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="n">system_prompt</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;You are a helpful assistant.</span>',
      '<span class="s2">    Your task is to decide if you need to search the web for information based on the user&#39;s query.</span>',
      '<span class="s2">    If you need to search the web, invoke the available search tool.</span>',
      '<span class="s2">    Do NOT process or summarize the search results. Simply return the raw output from the search tool.</span>',
      '<span class="s2">    If you don&#39;t need to search, respond to the user directly.</span>',
      '<span class="s2">    The document must to have more than 200 words.</span>',
      '<span class="s2">    &quot;&quot;&quot;</span>',
      '<span class="w">    </span><span class="n">messages</span> <span class="o">=</span> <span class="p">[</span><span class="n">SystemMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="n">system_prompt</span><span class="p">)]</span> <span class="o">+</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">]</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="p">{</span><span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">llm_searcher_with_tools</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">messages</span><span class="p">)]}</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Start to build the graph</span>',
      '<span class="n">graph_searcher</span> <span class="o">=</span> <span class="n">StateGraph</span><span class="p">(</span><span class="n">State_searcher</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Add nodes to the graph</span>',
      '<span class="n">graph_searcher</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;searcher_node&quot;</span><span class="p">,</span> <span class="n">searcher_function</span><span class="p">)</span>',
      '<span class="n">graph_searcher</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;tools&quot;</span><span class="p">,</span> <span class="n">tool_searcher_node</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Add edges</span>',
      '<span class="n">graph_searcher</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">START</span><span class="p">,</span> <span class="s2">&quot;searcher_node&quot;</span><span class="p">)</span>',
      '<span class="n">graph_searcher</span><span class="o">.</span><span class="n">add_conditional_edges</span><span class="p">(</span> <span class="s2">&quot;searcher_node&quot;</span><span class="p">,</span> <span class="n">tools_condition</span><span class="p">)</span>',
      '<span class="n">graph_searcher</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;tools&quot;</span><span class="p">,</span> <span class="s2">&quot;searcher_node&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Compile the graph</span>',
      '<span class="n">memory_searcher</span> <span class="o">=</span> <span class="n">MemorySaver</span><span class="p">()</span>',
      '<span class="n">graph_searcher_compiled</span> <span class="o">=</span> <span class="n">graph_searcher</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">checkpointer</span><span class="o">=</span><span class="n">memory_searcher</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Display the graph</span>',
      '<span class="k">try</span><span class="p">:</span>',
      '<span class="w">    </span><span class="n">display</span><span class="p">(</span><span class="n">Image</span><span class="p">(</span><span class="n">graph_searcher_compiled</span><span class="o">.</span><span class="n">get_graph</span><span class="p">()</span><span class="o">.</span><span class="n">draw_mermaid_png</span><span class="p">()))</span>',
      '<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error al visualizar el grafo: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '&amp;lt;IPython.core.display.Image object&amp;gt;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Let's test it, I'm going to ask for the finalists of this year's (2025) Champions League, which obviously is not in the LLM's knowledge.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.messages</span><span class="w"> </span><span class="kn">import</span> <span class="n">HumanMessage</span>',
      '<span class="w"> </span>',
      '<span class="n">USER1_THREAD_ID</span> <span class="o">=</span> <span class="s2">&quot;1&quot;</span>',
      '<span class="n">config_USER1</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;configurable&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;thread_id&quot;</span><span class="p">:</span> <span class="n">USER1_THREAD_ID</span><span class="p">}}</span>',
      '<span class="w"> </span>',
      '<span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;Who are the Champions League 2025 finalists?&quot;</span>',
      '<span class="w"> </span>',
      '<span class="n">messages</span> <span class="o">=</span> <span class="p">[</span><span class="n">HumanMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="n">prompt</span><span class="p">)]</span>',
      '<span class="w"> </span>',
      '<span class="n">result_searcher</span> <span class="o">=</span> <span class="n">graph_searcher_compiled</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="n">messages</span><span class="p">},</span> <span class="n">config</span><span class="o">=</span><span class="n">config_USER1</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="k">for</span> <span class="n">message</span> <span class="ow">in</span> <span class="n">result_searcher</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">]:</span>',
      '<span class="w">    </span><span class="n">message</span><span class="o">.</span><span class="n">pretty_print</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '================================ Human Message =================================',
          'Who are the Champions League 2025 finalists?',
          '================================== Ai Message ==================================',
          'Tool Calls:',
          '&#x20;&#x20;tavily_search_results_json (0)',
          'Call ID: 0',
          '&#x20;&#x20;Args:',
          '&#x20;&#x20;&#x20;&#x20;query: Champions League 2025 finalists',
          '================================= Tool Message =================================',
          'Name: tavily_search_results_json',
          '[&#x7B;&quot;title&quot;: &quot;2025 UEFA Champions League final: Munich Football Arena&quot;, &quot;url&quot;: &quot;https://www.uefa.com/uefachampionsleague/news/0283-186742eb3c74-d5eb4afca229-1000--2025-uefa-champions-league-final-munich-football-arena/&quot;, &quot;content&quot;: &quot;2024/25 Champions League final date\nThe 2025 Champions League final between Paris and Inter takes place on Saturday 31 May 2025. It will be culmination of the 70th season of Europe&#x27;s elite club competition and the 33rd since it was renamed the UEFA Champions League.\nWhat do the Champions League winners get? [...] MoreTeamsNew formatNewsFinalHistorySeasonsAll-time statsVideoTeamsMost titlesAboutStore\nFavourite team\nUEFA Champions League - 2025 UEFA Champions League final: Munich Football Arena - News \nGo back\n2025 UEFA Champions League final: Munich Football Arena\nWednesday, May 7, 2025\nArticle summary\nThe 2024/25 UEFA Champions League final between Paris and Inter will take place at the Munich Football Arena.\nArticle top media content [...] Your custom access to:\nand much more!\nYour custom access to:\nand much more!\nWe Care About Your Privacy&quot;, &quot;score&quot;: 0.8825193&#x7D;, &#x7B;&quot;title&quot;: &quot;2025 UEFA Champions League final: All you need to know&quot;, &quot;url&quot;: &quot;https://www.uefa.com/uefachampionsleague/news/0296-1d2ab6f54da7-c43a66bc7b77-1000--2025-uefa-champions-league-final-all-you-need-to-know/&quot;, &quot;content&quot;: &quot;UEFA.com works better on other browsers\nFor the best possible experience, we recommend using Chrome, Firefox or Microsoft Edge.\nSkip to main content\nUEFA Champions League\nFavourite team\nUEFA Champions League - 2025 UEFA Champions League final: All you need to know - News \n2025 UEFA Champions League final: All you need to know\nWednesday, May 7, 2025\nArticle summary\nThe 2024/25 UEFA Champions League final between Paris and Inter will take place at the Munich Football Arena. [...] Paris will face Inter in the final. Inter were the first side to book their place in the decider courtesy of their incredible 7-6 aggregate victory over Barcelona in the semi-finals. The following night, Paris joined them thanks to a 3-1 overall success against Arsenal.\nBarcelona vs Inter: Every goal from the epic semi-final\nWhere is the 2025 Champions League final? [...] Live 09/05/2025 Olympiacos earn automatic place in 2025/26 league phase thanks to Champions League rebalancing ---------------------------------------------------------------------------------------------- Olympiacos have earned a league phase spot next season since UEFA Champions League finalists Paris and Inter have already qualified via their domestic league position.\nWho will perform before the Champions League final?&quot;, &quot;score&quot;: 0.82694983&#x7D;, &#x7B;&quot;title&quot;: &quot;Champions League final: Paris vs Inter – meet the teams - UEFA.com&quot;, &quot;url&quot;: &quot;https://www.uefa.com/uefachampionsleague/news/0299-1db3ed7babb3-e6227af6104f-1000--champions-league-final-paris-vs-inter-meet-the-teams/&quot;, &quot;content&quot;: &quot;MoreTeamsNew formatNewsFinalHistorySeasonsAll-time statsVideoTeamsMost titlesAboutStore\nFavourite team\nUEFA Champions League - Champions League final: Paris vs Inter – meet the teams - News \nGo back\nChampions League final: Paris vs Inter – meet the teams\nWednesday, May 7, 2025\nArticle summary\nPivotal players, season so far, key stats; all you need to know about 2024/25 UEFA Champions League finalists Paris and Inter.\nArticle top media content [...] Published Time: 5/7/2025 9:51:00 PM +00:00\nChampions League final: Paris vs Inter – meet the teams | UEFA Champions League | UEFA.com\nChampions League Official Live football scores &amp;amp; Fantasy\nGet\n\nUEFA.com works better on other browsers\nFor the best possible experience, we recommend using Chrome, Firefox or Microsoft Edge.\nSkip to main content\nUEFA.com\n\nHome\nAbout\nNational associations\nRunning competitions\nDevelopment\nSustainability\nNews &amp;amp; media [...] Paris are the third French team to reach the final of the European Cup/UEFA Champions League more than once after Reims (1955/56, 1958/59) and Marseille (1990/91, 1992/93).\nAll Paris&#x27; 2024/25 Champions League goals\n© 1998-2025 UEFA. All rights reserved. Last updated: Wednesday, May 7, 2025\nUEFA Champions League&quot;, &quot;score&quot;: 0.8190992&#x7D;, &#x7B;&quot;title&quot;: &quot;2025 Champions League semi-finals: matchups, bracket and dates ...&quot;, &quot;url&quot;: &quot;https://en.as.com/soccer/2025-champions-league-semi-finals-matchups-bracket-and-dates-of-the-games-n/&quot;, &quot;content&quot;: &quot;3:00 p.m. ET: Arsenal vs Paris Saint-Germain\nWednesday, April 30:\n3:00 p.m. ET: Barcelona vs Inter Milan\nSecond legs:\nTuesday, May 6:\n3:00 p.m. ET: Inter Milan vs Barcelona\nWednesday, May 7:\n3:00 p.m. ET: Paris Saint-Germain vs Arsenal\nWhen and where is the 2025 Champions League final?\nThe final is to be played at the Allianz Arena in Munich, Germany, on May 31.\nRelated stories [...] Aston Villa 3-2 Paris Saint-Germain (4-5 on aggregate)\nBorussia Dortmund 3-1 Barcelona (3-5 on aggregate)\nInter Milan 2-2 Bayern Munich (4-3 on aggregate)\nReal Madrid 1-2 Arsenal (1-5 on aggregate)\nChampions League bracket:\nWhen are the UCL semi-finals?\nThe first legs of the Champions League semi-finals are due to be played on April 29 and 30. The second legs are scheduled for May 6 and 7.\nUCL semi-finals - schedule in full:\nFirst legs:\nTuesday, April 29: [...] Fútbol\nChampions League\nArsenal FC\nFC Barcelona\nPSG\nInter Milan\n\nComments0Rules\nComments\nRules\nSign in to commentAlready have an account\nComplete your personal details to comment\nComplete data\nYour opinion will be published with first and last names\nWe recommend these for you in Soccer&quot;, &quot;score&quot;: 0.8051581&#x7D;, &#x7B;&quot;title&quot;: &quot;2025 UEFA Champions League final - Simple Wikipedia&quot;, &quot;url&quot;: &quot;https://simple.wikipedia.org/wiki/2025_UEFA_Champions_League_final&quot;, &quot;content&quot;: &quot;The 2025 UEFA Champions League final will be a match of the 2024–25 season, Europe&#x27;s top club football tournament. It&#x27;s the 70th season, and they changed the name to UEFA Champions League 33 seasons ago. The final will happen on May 31, 2025, at Allianz Arena in Munich, Germany.[1] It&#x27;s the first final with the new Swiss-system format.[2] The winners will face the Europa League winners in the 2025 UEFA Super Cup.\nMatch\n[change | change source]\nDetails\n[change | change source] [...] Appearance\nmove to sidebar hide\nFrom Simple English Wikipedia, the free encyclopedia\n2025 UEFA Champions League finalThe Allianz Arena in Germany will host the final.Event2024–25 UEFA Champions LeagueDate31 May 2025 (2025-05-31)VenueAllianz Arena, Munich← 20242026 → [...] Contents\nmove to sidebar hide\n\nBeginning\n\n1 MatchToggle Match subsection\n\n1.1 Details\n\n\n\n2 References\n\n\n3 Other websites\n\n\nToggle the table of contents\n2025 UEFA Champions League final\n22 languages\n\nالعربية\nবাংলা\nCymraeg\nDansk\nEnglish\nEspañol\nفارسی\nFrançais\nBahasa Indonesia\nעברית\nҚазақша\nBahasa Melayu\n日本語\nPortuguês\nRomână\nРусский\nСрпски / srpski\nไทย\nTürkçe\nУкраїнська\nTiếng Việt\n中文\n\nChange links\n\nPage\nTalk\n\nEnglish\n\nRead\nChange\nChange source\nView history&quot;, &quot;score&quot;: 0.8005209&#x7D;, &#x7B;&quot;title&quot;: &quot;UEFA Women&#x27;s Champions League 2025 Final Full Match - YouTube&quot;, &quot;url&quot;: &quot;https://www.youtube.com/watch?v=xlf3HrJ35R4&quot;, &quot;content&quot;: &quot;May 24, 2025 -- Arsenal vs. Barcelona | UEFA Women&#x27;s Champions League Final 2025. DAZN is proud to present a New Deal for women&#x27;s football!&quot;, &quot;score&quot;: 0.7206637&#x7D;, &#x7B;&quot;title&quot;: &quot;Europe&#x27;s top soccer leagues: Titles, cup finals, UCL, relegation - ESPN&quot;, &quot;url&quot;: &quot;https://www.espn.com/soccer/story/_/id/44835154/europe-top-soccer-leagues-whats-was-decided-premier-league-laliga-bundesliga-serie-ligue-1&quot;, &quot;content&quot;: &quot;| GP | PTS | GD\n1 - Liverpool | 38 | 84 | +45\n2 - Arsenal | 38 | 74 | +35\n3 - Man City | 38 | 71 | +28\n4 - Chelsea | 38 | 69 | +21\n5 - Newcastle | 38 | 66 | +21\n6 - Aston Villa | 38 | 66 | +7\n7 - Nottm Forest | 38 | 65 | +12\nIn 2025-26, the Premier League has been allocated five teams in the Champions League due to the performance of its clubs in Europe this season, meaning the top five will qualify for the UCL. Liverpool and Arsenal (71) have booked two of them.&quot;, &quot;score&quot;: 0.6496014&#x7D;]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>It has returned a list of search results, now we are going to synthesize it.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Worker 2: news synthesizer agent">Worker 2: news synthesizer agent<a class="anchor-link" href="#Worker 2: news synthesizer agent"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 22" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Now we create the second worker, an agent responsible for synthesizing the information from the reports of the other agents.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="c1"># State</span>',
      '<span class="k">class</span><span class="w"> </span><span class="nc">State_summarizer</span><span class="p">(</span><span class="n">TypedDict</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">messages</span><span class="p">:</span> <span class="n">Annotated</span><span class="p">[</span><span class="nb">list</span><span class="p">,</span> <span class="n">add_messages</span><span class="p">]</span>',
      '<span class="w">    </span><span class="n">decision</span><span class="p">:</span> <span class="nb">str</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Create the LLM model</span>',
      '<span class="n">login</span><span class="p">(</span><span class="n">token</span><span class="o">=</span><span class="n">HUGGINGFACE_TOKEN</span><span class="p">)</span>  <span class="c1"># Login to HuggingFace to use the model</span>',
      '<span class="n">MODEL</span> <span class="o">=</span> <span class="s2">&quot;Qwen/Qwen2.5-72B-Instruct&quot;</span>',
      '<span class="n">model_summarizer</span> <span class="o">=</span> <span class="n">HuggingFaceEndpoint</span><span class="p">(</span>',
      '<span class="w">    </span><span class="n">repo_id</span><span class="o">=</span><span class="n">MODEL</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">task</span><span class="o">=</span><span class="s2">&quot;text-generation&quot;</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">do_sample</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">repetition_penalty</span><span class="o">=</span><span class="mf">1.03</span><span class="p">,</span>',
      '<span class="p">)</span>',
      '<span class="c1"># Create the chat model</span>',
      '<span class="n">llm_summarizer</span> <span class="o">=</span> <span class="n">ChatHuggingFace</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">model_summarizer</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Functions</span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">summarizer_function</span><span class="p">(</span><span class="n">state</span><span class="p">:</span> <span class="n">State_summarizer</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">system_prompt</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;You are an advanced AI assistant specialized in summarizing complex information from multiple documents.</span>',
      '<span class="s2">    Your task is to process a list of provided documents (typically search results) and generate a comprehensive yet concise summary.</span>',
      '<span class="w"> </span>',
      '<span class="s2">    Key objectives for your summary:</span>',
      '<span class="s2">    1.  **Accuracy:** Ensure all information is derived strictly from the provided documents. Do not infer or add external knowledge.</span>',
      '<span class="s2">    2.  **Relevance:** Focus on the most important facts, findings, and answers related to the core topic of the documents.</span>',
      '<span class="s2">    3.  **Clarity:** Write in clear, precise, and easily understandable language. Define any jargon if present in the source and necessary for understanding.</span>',
      '<span class="s2">    4.  **Structure:** Organize the summary logically. Use paragraphs to separate distinct ideas. If helpful for the content, consider using bullet points for lists of key facts or findings.</span>',
      '<span class="s2">    5.  **Conciseness:** Be thorough but avoid unnecessary repetition or overly verbose phrasing. Capture the essence efficiently.</span>',
      '<span class="s2">    6.  **Neutrality:** Maintain an objective tone.</span>',
      '<span class="w"> </span>',
      '<span class="s2">    Synthesize the information into a coherent piece that gives a full picture of what the documents collectively state about the topic.</span>',
      '<span class="s2">    &quot;&quot;&quot;</span> <span class="c1"># End of the new system_prompt</span>',
      '<span class="w">    </span><span class="n">messages</span> <span class="o">=</span> <span class="p">[</span><span class="n">SystemMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="n">system_prompt</span><span class="p">)]</span> <span class="o">+</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">]</span>',
      '<span class="w">    </span><span class="n">summarizer_result</span> <span class="o">=</span> <span class="n">llm_summarizer</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">messages</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="p">{</span><span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">summarizer_result</span><span class="p">]}</span>',
      '<span class="w"> </span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">check_summarizer_result</span><span class="p">(</span><span class="n">state</span><span class="p">:</span> <span class="n">State_summarizer</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">system_prompt</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;You are a critical reviewer AI, tasked with validating text summaries against specific quality criteria.</span>',
      '<span class="s2">    You will receive an original text and a summary generated from it. The summary was intended to meet the following objectives:</span>',
      '<span class="s2">    - Accuracy (derived strictly from the original, no external knowledge).</span>',
      '<span class="s2">    - Relevance (focus on most important facts related to the core topic).</span>',
      '<span class="s2">    - Clarity (clear, precise, easily understandable language).</span>',
      '<span class="s2">    - Good Structure (logically organized, paragraphs/bullets if appropriate).</span>',
      '<span class="s2">    - Conciseness (thorough but not verbose).</span>',
      '<span class="s2">    - Neutrality (objective tone).</span>',
      '<span class="w"> </span>',
      '<span class="s2">    Carefully compare the summary against the original text.</span>',
      '<span class="s2">    If the summary successfully meets ALL the above objectives, return the single word &quot;good&quot;.</span>',
      '<span class="s2">    If the summary fails to meet one or more of these objectives adequately, return the single word &quot;bad&quot;.</span>',
      '<span class="s2">    Provide only &quot;good&quot; or &quot;bad&quot; as your response.</span>',
      '<span class="s2">    &quot;&quot;&quot;</span> <span class="c1"># End of new system_prompt</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="n">text_to_summarize</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">content</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="n">summarizer_result</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">content</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>',
      '<span class="s2">    Here is the summary:</span>',
      '<span class="s2">    </span><span class="si">{</span><span class="n">summarizer_result</span><span class="si">}</span>',
      '<span class="w"> </span>',
      '<span class="s2">    And here is the original text:</span>',
      '<span class="s2">    </span><span class="si">{</span><span class="n">text_to_summarize</span><span class="si">}</span>',
      '<span class="w"> </span>',
      '<span class="s2">    Please, return only one word, &quot;good&quot; or &quot;bad&quot;.</span>',
      '<span class="s2">    &quot;&quot;&quot;</span>',
      '<span class="w">    </span><span class="n">messages</span> <span class="o">=</span> <span class="p">[</span><span class="n">SystemMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="n">system_prompt</span><span class="p">)]</span> <span class="o">+</span> <span class="p">[</span><span class="n">HumanMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="n">prompt</span><span class="p">)]</span>',
      '<span class="w">    </span><span class="n">decision</span> <span class="o">=</span> <span class="n">llm_summarizer</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">messages</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="p">{</span><span class="s2">&quot;decision&quot;</span><span class="p">:</span> <span class="n">decision</span><span class="o">.</span><span class="n">content</span><span class="p">}</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Start to build the graph</span>',
      '<span class="n">graph_summarizer</span> <span class="o">=</span> <span class="n">StateGraph</span><span class="p">(</span><span class="n">State_summarizer</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Add nodes to the graph</span>',
      '<span class="n">graph_summarizer</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;summarizer_node&quot;</span><span class="p">,</span> <span class="n">summarizer_function</span><span class="p">)</span>',
      '<span class="n">graph_summarizer</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;check_summarizer_result&quot;</span><span class="p">,</span> <span class="n">check_summarizer_result</span><span class="p">)</span>',
      '<span class="c1"># Add edges</span>',
      '<span class="n">graph_summarizer</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">START</span><span class="p">,</span> <span class="s2">&quot;summarizer_node&quot;</span><span class="p">)</span>',
      '<span class="n">graph_summarizer</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;summarizer_node&quot;</span><span class="p">,</span> <span class="s2">&quot;check_summarizer_result&quot;</span><span class="p">)</span>',
      '<span class="n">graph_summarizer</span><span class="o">.</span><span class="n">add_conditional_edges</span><span class="p">(</span>',
      '<span class="w">    </span><span class="n">source</span><span class="o">=</span><span class="s2">&quot;check_summarizer_result&quot;</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">path</span><span class="o">=</span><span class="k">lambda</span> <span class="n">state</span><span class="p">:</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;decision&quot;</span><span class="p">],</span>',
      '<span class="w">    </span><span class="n">path_map</span><span class="o">=</span><span class="p">{</span>',
      '<span class="w">        </span><span class="s2">&quot;good&quot;</span><span class="p">:</span> <span class="n">END</span><span class="p">,</span>',
      '<span class="w">        </span><span class="s2">&quot;bad&quot;</span><span class="p">:</span> <span class="s2">&quot;summarizer_node&quot;</span>',
      '<span class="w">    </span><span class="p">}</span>',
      '<span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Compile the graph</span>',
      '<span class="n">memory_summarizer</span> <span class="o">=</span> <span class="n">MemorySaver</span><span class="p">()</span>',
      '<span class="n">graph_summarizer_compiled</span> <span class="o">=</span> <span class="n">graph_summarizer</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">checkpointer</span><span class="o">=</span><span class="n">memory_summarizer</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Display the graph</span>',
      '<span class="k">try</span><span class="p">:</span>',
      '<span class="w">    </span><span class="n">display</span><span class="p">(</span><span class="n">Image</span><span class="p">(</span><span class="n">graph_summarizer_compiled</span><span class="o">.</span><span class="n">get_graph</span><span class="p">()</span><span class="o">.</span><span class="n">draw_mermaid_png</span><span class="p">()))</span>',
      '<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error al visualizar el grafo: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '&amp;lt;IPython.core.display.Image object&amp;gt;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Let's test it, I'm going to pass the result of the first worker to see how it synthesizes it.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">search_result</span> <span class="o">=</span> <span class="n">result_searcher</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">content</span>',
      '<span class="w"> </span>',
      '<span class="n">messages</span> <span class="o">=</span> <span class="p">[</span><span class="n">HumanMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="n">search_result</span><span class="p">)]</span>',
      '<span class="w"> </span>',
      '<span class="n">result_sumarizer</span> <span class="o">=</span> <span class="n">graph_summarizer_compiled</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="n">messages</span><span class="p">},</span> <span class="n">config</span><span class="o">=</span><span class="n">config_USER1</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="k">for</span> <span class="n">message</span> <span class="ow">in</span> <span class="n">result_sumarizer</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">]:</span>',
      '<span class="w">    </span><span class="n">message</span><span class="o">.</span><span class="n">pretty_print</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Decision on Summary:&quot;</span><span class="p">)</span>',
      '<span class="n">decision</span> <span class="o">=</span> <span class="n">result_sumarizer</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;decision&quot;</span><span class="p">)</span>',
      '<span class="k">if</span> <span class="n">decision</span><span class="p">:</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="n">decision</span><span class="p">)</span>',
      '<span class="k">else</span><span class="p">:</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No decision was found.&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--- End of Summarizer Graph Output ---&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '================================ Human Message =================================',
          '[&#x7B;&quot;title&quot;: &quot;2025 UEFA Champions League final: Munich Football Arena&quot;, &quot;url&quot;: &quot;https://www.uefa.com/uefachampionsleague/news/0283-186742eb3c74-d5eb4afca229-1000--2025-uefa-champions-league-final-munich-football-arena/&quot;, &quot;content&quot;: &quot;2024/25 Champions League final date\nThe 2025 Champions League final between Paris and Inter takes place on Saturday 31 May 2025. It will be culmination of the 70th season of Europe&#x27;s elite club competition and the 33rd since it was renamed the UEFA Champions League.\nWhat do the Champions League winners get? [...] MoreTeamsNew formatNewsFinalHistorySeasonsAll-time statsVideoTeamsMost titlesAboutStore\nFavourite team\nUEFA Champions League - 2025 UEFA Champions League final: Munich Football Arena - News \nGo back\n2025 UEFA Champions League final: Munich Football Arena\nWednesday, May 7, 2025\nArticle summary\nThe 2024/25 UEFA Champions League final between Paris and Inter will take place at the Munich Football Arena.\nArticle top media content [...] Your custom access to:\nand much more!\nYour custom access to:\nand much more!\nWe Care About Your Privacy&quot;, &quot;score&quot;: 0.8825193&#x7D;, &#x7B;&quot;title&quot;: &quot;2025 UEFA Champions League final: All you need to know&quot;, &quot;url&quot;: &quot;https://www.uefa.com/uefachampionsleague/news/0296-1d2ab6f54da7-c43a66bc7b77-1000--2025-uefa-champions-league-final-all-you-need-to-know/&quot;, &quot;content&quot;: &quot;UEFA.com works better on other browsers\nFor the best possible experience, we recommend using Chrome, Firefox or Microsoft Edge.\nSkip to main content\nUEFA Champions League\nFavourite team\nUEFA Champions League - 2025 UEFA Champions League final: All you need to know - News \n2025 UEFA Champions League final: All you need to know\nWednesday, May 7, 2025\nArticle summary\nThe 2024/25 UEFA Champions League final between Paris and Inter will take place at the Munich Football Arena. [...] Paris will face Inter in the final. Inter were the first side to book their place in the decider courtesy of their incredible 7-6 aggregate victory over Barcelona in the semi-finals. The following night, Paris joined them thanks to a 3-1 overall success against Arsenal.\nBarcelona vs Inter: Every goal from the epic semi-final\nWhere is the 2025 Champions League final? [...] Live 09/05/2025 Olympiacos earn automatic place in 2025/26 league phase thanks to Champions League rebalancing ---------------------------------------------------------------------------------------------- Olympiacos have earned a league phase spot next season since UEFA Champions League finalists Paris and Inter have already qualified via their domestic league position.\nWho will perform before the Champions League final?&quot;, &quot;score&quot;: 0.82694983&#x7D;, &#x7B;&quot;title&quot;: &quot;Champions League final: Paris vs Inter – meet the teams - UEFA.com&quot;, &quot;url&quot;: &quot;https://www.uefa.com/uefachampionsleague/news/0299-1db3ed7babb3-e6227af6104f-1000--champions-league-final-paris-vs-inter-meet-the-teams/&quot;, &quot;content&quot;: &quot;MoreTeamsNew formatNewsFinalHistorySeasonsAll-time statsVideoTeamsMost titlesAboutStore\nFavourite team\nUEFA Champions League - Champions League final: Paris vs Inter – meet the teams - News \nGo back\nChampions League final: Paris vs Inter – meet the teams\nWednesday, May 7, 2025\nArticle summary\nPivotal players, season so far, key stats; all you need to know about 2024/25 UEFA Champions League finalists Paris and Inter.\nArticle top media content [...] Published Time: 5/7/2025 9:51:00 PM +00:00\nChampions League final: Paris vs Inter – meet the teams | UEFA Champions League | UEFA.com\nChampions League Official Live football scores &amp;amp; Fantasy\nGet\n\nUEFA.com works better on other browsers\nFor the best possible experience, we recommend using Chrome, Firefox or Microsoft Edge.\nSkip to main content\nUEFA.com\n\nHome\nAbout\nNational associations\nRunning competitions\nDevelopment\nSustainability\nNews &amp;amp; media [...] Paris are the third French team to reach the final of the European Cup/UEFA Champions League more than once after Reims (1955/56, 1958/59) and Marseille (1990/91, 1992/93).\nAll Paris&#x27; 2024/25 Champions League goals\n© 1998-2025 UEFA. All rights reserved. Last updated: Wednesday, May 7, 2025\nUEFA Champions League&quot;, &quot;score&quot;: 0.8190992&#x7D;, &#x7B;&quot;title&quot;: &quot;2025 Champions League semi-finals: matchups, bracket and dates ...&quot;, &quot;url&quot;: &quot;https://en.as.com/soccer/2025-champions-league-semi-finals-matchups-bracket-and-dates-of-the-games-n/&quot;, &quot;content&quot;: &quot;3:00 p.m. ET: Arsenal vs Paris Saint-Germain\nWednesday, April 30:\n3:00 p.m. ET: Barcelona vs Inter Milan\nSecond legs:\nTuesday, May 6:\n3:00 p.m. ET: Inter Milan vs Barcelona\nWednesday, May 7:\n3:00 p.m. ET: Paris Saint-Germain vs Arsenal\nWhen and where is the 2025 Champions League final?\nThe final is to be played at the Allianz Arena in Munich, Germany, on May 31.\nRelated stories [...] Aston Villa 3-2 Paris Saint-Germain (4-5 on aggregate)\nBorussia Dortmund 3-1 Barcelona (3-5 on aggregate)\nInter Milan 2-2 Bayern Munich (4-3 on aggregate)\nReal Madrid 1-2 Arsenal (1-5 on aggregate)\nChampions League bracket:\nWhen are the UCL semi-finals?\nThe first legs of the Champions League semi-finals are due to be played on April 29 and 30. The second legs are scheduled for May 6 and 7.\nUCL semi-finals - schedule in full:\nFirst legs:\nTuesday, April 29: [...] Fútbol\nChampions League\nArsenal FC\nFC Barcelona\nPSG\nInter Milan\n\nComments0Rules\nComments\nRules\nSign in to commentAlready have an account\nComplete your personal details to comment\nComplete data\nYour opinion will be published with first and last names\nWe recommend these for you in Soccer&quot;, &quot;score&quot;: 0.8051581&#x7D;, &#x7B;&quot;title&quot;: &quot;2025 UEFA Champions League final - Simple Wikipedia&quot;, &quot;url&quot;: &quot;https://simple.wikipedia.org/wiki/2025_UEFA_Champions_League_final&quot;, &quot;content&quot;: &quot;The 2025 UEFA Champions League final will be a match of the 2024–25 season, Europe&#x27;s top club football tournament. It&#x27;s the 70th season, and they changed the name to UEFA Champions League 33 seasons ago. The final will happen on May 31, 2025, at Allianz Arena in Munich, Germany.[1] It&#x27;s the first final with the new Swiss-system format.[2] The winners will face the Europa League winners in the 2025 UEFA Super Cup.\nMatch\n[change | change source]\nDetails\n[change | change source] [...] Appearance\nmove to sidebar hide\nFrom Simple English Wikipedia, the free encyclopedia\n2025 UEFA Champions League finalThe Allianz Arena in Germany will host the final.Event2024–25 UEFA Champions LeagueDate31 May 2025 (2025-05-31)VenueAllianz Arena, Munich← 20242026 → [...] Contents\nmove to sidebar hide\n\nBeginning\n\n1 MatchToggle Match subsection\n\n1.1 Details\n\n\n\n2 References\n\n\n3 Other websites\n\n\nToggle the table of contents\n2025 UEFA Champions League final\n22 languages\n\nالعربية\nবাংলা\nCymraeg\nDansk\nEnglish\nEspañol\nفارسی\nFrançais\nBahasa Indonesia\nעברית\nҚазақша\nBahasa Melayu\n日本語\nPortuguês\nRomână\nРусский\nСрпски / srpski\nไทย\nTürkçe\nУкраїнська\nTiếng Việt\n中文\n\nChange links\n\nPage\nTalk\n\nEnglish\n\nRead\nChange\nChange source\nView history&quot;, &quot;score&quot;: 0.8005209&#x7D;, &#x7B;&quot;title&quot;: &quot;UEFA Women&#x27;s Champions League 2025 Final Full Match - YouTube&quot;, &quot;url&quot;: &quot;https://www.youtube.com/watch?v=xlf3HrJ35R4&quot;, &quot;content&quot;: &quot;May 24, 2025 -- Arsenal vs. Barcelona | UEFA Women&#x27;s Champions League Final 2025. DAZN is proud to present a New Deal for women&#x27;s football!&quot;, &quot;score&quot;: 0.7206637&#x7D;, &#x7B;&quot;title&quot;: &quot;Europe&#x27;s top soccer leagues: Titles, cup finals, UCL, relegation - ESPN&quot;, &quot;url&quot;: &quot;https://www.espn.com/soccer/story/_/id/44835154/europe-top-soccer-leagues-whats-was-decided-premier-league-laliga-bundesliga-serie-ligue-1&quot;, &quot;content&quot;: &quot;| GP | PTS | GD\n1 - Liverpool | 38 | 84 | +45\n2 - Arsenal | 38 | 74 | +35\n3 - Man City | 38 | 71 | +28\n4 - Chelsea | 38 | 69 | +21\n5 - Newcastle | 38 | 66 | +21\n6 - Aston Villa | 38 | 66 | +7\n7 - Nottm Forest | 38 | 65 | +12\nIn 2025-26, the Premier League has been allocated five teams in the Champions League due to the performance of its clubs in Europe this season, meaning the top five will qualify for the UCL. Liverpool and Arsenal (71) have booked two of them.&quot;, &quot;score&quot;: 0.6496014&#x7D;]',
          '================================== Ai Message ==================================',
          '### Summary of the 2025 UEFA Champions League Final',
          '#### Final Details',
          '- **Date:** Saturday, 31 May 2025',
          '- **Venue:** Allianz Arena, Munich, Germany',
          '- **Teams:** Paris Saint-Germain (Paris) vs. Inter Milan (Inter)',
          '- **Significance:** This will be the culmination of the 70th season of Europe&#x27;s elite club competition and the 33rd since it was renamed the UEFA Champions League. It will also be the first final under the new Swiss-system format.',
          '#### Path to the Final',
          '- **Semi-final Matches:**',
          '&#x20;&#x20;- **First Legs:**',
          '&#x20;&#x20;&#x20;&#x20;- Tuesday, April 29: Barcelona vs. Inter Milan',
          '&#x20;&#x20;&#x20;&#x20;- Wednesday, April 30: Arsenal vs. Paris Saint-Germain',
          '&#x20;&#x20;- **Second Legs:**',
          '&#x20;&#x20;&#x20;&#x20;- Tuesday, May 6: Inter Milan vs. Barcelona',
          '&#x20;&#x20;&#x20;&#x20;- Wednesday, May 7: Paris Saint-Germain vs. Arsenal',
          '- **Semi-final Results:**',
          '&#x20;&#x20;- **Inter Milan:** Aggregated 7-6 victory over Barcelona',
          '&#x20;&#x20;- **Paris Saint-Germain:** Aggregated 3-1 victory over Arsenal',
          '#### Team Backgrounds',
          '- **Paris Saint-Germain:**',
          '&#x20;&#x20;- Third French team to reach the final of the European Cup/UEFA Champions League more than once, following Reims and Marseille.',
          '&#x20;&#x20;- Had a strong run, defeating Arsenal convincingly in the semi-finals.',
          '- **Inter Milan:**',
          '&#x20;&#x20;- Booked their place in the final with an epic 7-6 aggregate victory over Barcelona.',
          '&#x20;&#x20;- Known for their resilience and attacking prowess.',
          '#### Additional Information',
          '- **Pre-Final Performances:**',
          '&#x20;&#x20;- Inter&#x27;s victory over Barcelona included a dramatic comeback, highlighting their strength and determination.',
          '&#x20;&#x20;- Paris Saint-Germain&#x27;s consistent performance and tactical discipline were key in their semi-final win.',
          '- **Impact on European Leagues:**',
          '&#x20;&#x20;- Due to the performance of clubs in Europe, the Premier League has been allocated five teams in the 2025-26 UEFA Champions League, with Liverpool and Arsenal securing two of the spots.',
          '- **Pre-Final Event:**',
          '&#x20;&#x20;- There will be a performance before the Champions League final, though the artist or act has not been specified as of the latest update.',
          'This final promises to be an exciting culmination of the season, showcasing the best of European club football.',
          'Decision on Summary:',
          'good',
          '--- End of Summarizer Graph Output ---',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We see that it has summarized the news</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Main graph">Main graph<a class="anchor-link" href="#Main graph"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 23" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Once we have the two workers, we can build the main graph.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="c1"># Entry Graph</span>',
      '<span class="k">class</span><span class="w"> </span><span class="nc">State_agent_pattern</span><span class="p">(</span><span class="n">TypedDict</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">messages</span><span class="p">:</span> <span class="n">Annotated</span><span class="p">[</span><span class="nb">list</span><span class="p">,</span> <span class="n">add_messages</span><span class="p">]</span>  <span class="c1"># Holds all messages: user query, tool calls/results, summaries</span>',
      '<span class="w">    </span><span class="n">agent_decision</span><span class="p">:</span> <span class="nb">str</span>  <span class="c1"># Routing: &quot;route_to_searcher&quot;, &quot;route_to_summarizer&quot;, &quot;route_to_end&quot;</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Create the LLM model</span>',
      '<span class="n">login</span><span class="p">(</span><span class="n">token</span><span class="o">=</span><span class="n">HUGGINGFACE_TOKEN</span><span class="p">)</span>  <span class="c1"># Login to HuggingFace to use the model</span>',
      '<span class="n">MODEL</span> <span class="o">=</span> <span class="s2">&quot;Qwen/Qwen2.5-72B-Instruct&quot;</span>',
      '<span class="n">model_agent_pattern</span> <span class="o">=</span> <span class="n">HuggingFaceEndpoint</span><span class="p">(</span>',
      '<span class="w">    </span><span class="n">repo_id</span><span class="o">=</span><span class="n">MODEL</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">task</span><span class="o">=</span><span class="s2">&quot;text-generation&quot;</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">do_sample</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">repetition_penalty</span><span class="o">=</span><span class="mf">1.03</span><span class="p">,</span>',
      '<span class="p">)</span>',
      '<span class="c1"># Create the chat model</span>',
      '<span class="n">llm_agent_pattern</span> <span class="o">=</span> <span class="n">ChatHuggingFace</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">model_agent_pattern</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Functions</span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">decision_function</span><span class="p">(</span><span class="n">state</span><span class="p">:</span> <span class="n">State_agent_pattern</span><span class="p">)</span> <span class="o">-&amp;</span><span class="n">gt</span><span class="p">;</span> <span class="nb">dict</span><span class="p">:</span>',
      '<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>',
      '<span class="sd">    Decides the next action for the agent based on the current state of messages.</span>',
      '<span class="sd">    Updates &#39;agent_decision&#39; to route to the searcher, summarizer, or end the process.</span>',
      '<span class="sd">    &quot;&quot;&quot;</span>',
      '<span class="w">    </span><span class="n">current_messages</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;messages&quot;</span><span class="p">,</span> <span class="p">[])</span>',
      '<span class="w">    </span><span class="n">next_route</span> <span class="o">=</span> <span class="s2">&quot;route_to_searcher&quot;</span>  <span class="c1"># Default action</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="k">if</span> <span class="ow">not</span> <span class="n">current_messages</span><span class="p">:</span>',
      '<span class="w">        </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Warning: decision_function called with empty messages. Defaulting to search.&quot;</span><span class="p">)</span>',
      '<span class="w">        </span><span class="k">return</span> <span class="p">{</span><span class="s2">&quot;agent_decision&quot;</span><span class="p">:</span> <span class="s2">&quot;route_to_searcher&quot;</span><span class="p">}</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="n">last_message</span> <span class="o">=</span> <span class="n">current_messages</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">last_message</span><span class="p">,</span> <span class="n">ToolMessage</span><span class="p">):</span>',
      '<span class="w">        </span><span class="c1"># Search results are available (ToolMessage). Next step: summarize.</span>',
      '<span class="w">        </span><span class="n">next_route</span> <span class="o">=</span> <span class="s2">&quot;route_to_summarizer&quot;</span>',
      '<span class="w">    </span><span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">last_message</span><span class="p">,</span> <span class="n">AIMessage</span><span class="p">):</span>',
      '<span class="w">        </span><span class="c1"># AIMessage could be a direct answer from searcher or a summary from summarizer.</span>',
      '<span class="w">        </span><span class="n">ai_content</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">last_message</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="k">if</span> <span class="ow">not</span> <span class="n">ai_content</span><span class="p">:</span>',
      '<span class="w">            </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Warning: AIMessage has no content. Defaulting to search.&quot;</span><span class="p">)</span>',
      '<span class="w">            </span><span class="n">next_route</span> <span class="o">=</span> <span class="s2">&quot;route_to_searcher&quot;</span>',
      '<span class="w">        </span><span class="k">else</span><span class="p">:</span>',
      '<span class="w">            </span><span class="c1"># Use LLM to evaluate the AIMessage content</span>',
      '<span class="w">            </span><span class="n">system_prompt_eval</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;You are an expert content analyst.</span>',
      '<span class="s2">Analyze the provided text. The text could be a direct answer to a query or a summary.</span>',
      '<span class="s2">- If the text is a comprehensive and sufficient final answer, respond with &quot;enough&quot;.</span>',
      '<span class="s2">- If the text seems like raw search results that were not properly captured as a ToolMessage but as an AIMessage, or requires summarization, respond with &quot;needs_summary&quot;.</span>',
      '<span class="s2">- If the text is a summary, but it&#39;s insufficient and more searching/refinement is needed, respond with &quot;search_again&quot;.</span>',
      '<span class="s2">Respond with only one of: &quot;enough&quot;, &quot;needs_summary&quot;, &quot;search_again&quot;.</span>',
      '<span class="s2">&quot;&quot;&quot;</span>',
      '<span class="w">            </span><span class="n">eval_messages</span> <span class="o">=</span> <span class="p">[</span>',
      '<span class="w">                </span><span class="n">SystemMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="n">system_prompt_eval</span><span class="p">),</span>',
      '<span class="w">                </span><span class="n">HumanMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="n">ai_content</span><span class="p">)</span>',
      '<span class="w">            </span><span class="p">]</span>',
      '<span class="w">            </span><span class="k">try</span><span class="p">:</span>',
      '<span class="w">                </span><span class="n">llm_eval_decision_obj</span> <span class="o">=</span> <span class="n">llm_agent_pattern</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">eval_messages</span><span class="p">)</span>',
      '<span class="w">                </span><span class="n">eval_decision_str</span> <span class="o">=</span> <span class="n">llm_eval_decision_obj</span><span class="o">.</span><span class="n">content</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="w">                </span><span class="k">if</span> <span class="n">eval_decision_str</span> <span class="o">==</span> <span class="s2">&quot;enough&quot;</span><span class="p">:</span>',
      '<span class="w">                    </span><span class="n">next_route</span> <span class="o">=</span> <span class="s2">&quot;route_to_end&quot;</span>',
      '<span class="w">                </span><span class="k">elif</span> <span class="n">eval_decision_str</span> <span class="o">==</span> <span class="s2">&quot;needs_summary&quot;</span><span class="p">:</span>',
      '<span class="w">                    </span><span class="n">next_route</span> <span class="o">=</span> <span class="s2">&quot;route_to_summarizer&quot;</span>',
      '<span class="w">                </span><span class="k">elif</span> <span class="n">eval_decision_str</span> <span class="o">==</span> <span class="s2">&quot;search_again&quot;</span><span class="p">:</span>',
      '<span class="w">                    </span><span class="n">next_route</span> <span class="o">=</span> <span class="s2">&quot;route_to_searcher&quot;</span>',
      '<span class="w">                </span><span class="k">else</span><span class="p">:</span>',
      '<span class="w">                    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Warning: LLM in decision_function (AIMessage eval) returned: &#39;</span><span class="si">{</span><span class="n">eval_decision_str</span><span class="si">}</span><span class="s2">&#39;. Defaulting to end.&quot;</span><span class="p">)</span>',
      '<span class="w">                    </span><span class="n">next_route</span> <span class="o">=</span> <span class="s2">&quot;route_to_end&quot;</span> <span class="c1"># Safer default for unrecognized LLM output</span>',
      '<span class="w">            </span><span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>',
      '<span class="w">                </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error during LLM call in decision_function: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">. Defaulting to search.&quot;</span><span class="p">)</span>',
      '<span class="w">                </span><span class="n">next_route</span> <span class="o">=</span> <span class="s2">&quot;route_to_searcher&quot;</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">last_message</span><span class="p">,</span> <span class="n">HumanMessage</span><span class="p">):</span>',
      '<span class="w">        </span><span class="c1"># Initial user query or a follow-up. Start by searching.</span>',
      '<span class="w">        </span><span class="n">next_route</span> <span class="o">=</span> <span class="s2">&quot;route_to_searcher&quot;</span>',
      '<span class="w">    </span><span class="k">else</span><span class="p">:</span>',
      '<span class="w">        </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Warning: decision_function encountered an unexpected last message type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">last_message</span><span class="p">)</span><span class="si">}</span><span class="s2">. Defaulting to search.&quot;</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">next_route</span> <span class="o">=</span> <span class="s2">&quot;route_to_searcher&quot;</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="k">return</span> <span class="p">{</span><span class="s2">&quot;agent_decision&quot;</span><span class="p">:</span> <span class="n">next_route</span><span class="p">}</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Build the graph</span>',
      '<span class="n">agent_pattern_builder</span> <span class="o">=</span> <span class="n">StateGraph</span><span class="p">(</span><span class="n">State_agent_pattern</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Add nodes</span>',
      '<span class="n">agent_pattern_builder</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;decision_node&quot;</span><span class="p">,</span> <span class="n">decision_function</span><span class="p">)</span>',
      '<span class="n">agent_pattern_builder</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;searcher_node&quot;</span><span class="p">,</span> <span class="n">graph_searcher</span><span class="o">.</span><span class="n">compile</span><span class="p">())</span>',
      '<span class="n">agent_pattern_builder</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;summarizer_node&quot;</span><span class="p">,</span> <span class="n">graph_summarizer</span><span class="o">.</span><span class="n">compile</span><span class="p">())</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Add edges</span>',
      '<span class="n">agent_pattern_builder</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">START</span><span class="p">,</span> <span class="s2">&quot;decision_node&quot;</span><span class="p">)</span>',
      '<span class="n">agent_pattern_builder</span><span class="o">.</span><span class="n">add_conditional_edges</span><span class="p">(</span>',
      '<span class="w">    </span><span class="n">source</span><span class="o">=</span><span class="s2">&quot;decision_node&quot;</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">path</span><span class="o">=</span><span class="k">lambda</span> <span class="n">state</span><span class="p">:</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;agent_decision&quot;</span><span class="p">],</span>',
      '<span class="w">    </span><span class="n">path_map</span><span class="o">=</span><span class="p">{</span>',
      '<span class="w">        </span><span class="s2">&quot;route_to_searcher&quot;</span><span class="p">:</span> <span class="s2">&quot;searcher_node&quot;</span><span class="p">,</span>',
      '<span class="w">        </span><span class="s2">&quot;route_to_summarizer&quot;</span><span class="p">:</span> <span class="s2">&quot;summarizer_node&quot;</span><span class="p">,</span>',
      '<span class="w">        </span><span class="s2">&quot;route_to_end&quot;</span><span class="p">:</span> <span class="n">END</span>',
      '<span class="w">    </span><span class="p">}</span>',
      '<span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Edges to loop back to the decision node after search or summarization</span>',
      '<span class="n">agent_pattern_builder</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;searcher_node&quot;</span><span class="p">,</span> <span class="s2">&quot;decision_node&quot;</span><span class="p">)</span>',
      '<span class="n">agent_pattern_builder</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;summarizer_node&quot;</span><span class="p">,</span> <span class="s2">&quot;decision_node&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Compile the graph</span>',
      '<span class="n">graph_agent_pattern</span> <span class="o">=</span> <span class="n">agent_pattern_builder</span><span class="o">.</span><span class="n">compile</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Setting xray to 1 will show the internal structure of the nested graph</span>',
      '<span class="k">try</span><span class="p">:</span>',
      '<span class="w">    </span><span class="n">display</span><span class="p">(</span><span class="n">Image</span><span class="p">(</span><span class="n">graph_agent_pattern</span><span class="o">.</span><span class="n">get_graph</span><span class="p">(</span><span class="n">xray</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">draw_mermaid_png</span><span class="p">()))</span>',
      '<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error al visualizar el grafo: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '&amp;lt;IPython.core.display.Image object&amp;gt;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Let's test it by asking about <a href="https://jules.google/" target="_blank" rel="nofollow noreferrer">Jules</a> an asynchronous coding agent that came out a week ago (as of the writing of the post), so obviously it shouldn't be in the LLM's knowledge.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.messages</span><span class="w"> </span><span class="kn">import</span> <span class="n">HumanMessage</span><span class="p">,</span> <span class="n">AIMessage</span>',
      '<span class="w"> </span>',
      '<span class="n">USER2_THREAD_ID</span> <span class="o">=</span> <span class="s2">&quot;2&quot;</span>',
      '<span class="n">config_USER2</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;configurable&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;thread_id&quot;</span><span class="p">:</span> <span class="n">USER2_THREAD_ID</span><span class="p">}}</span>',
      '<span class="w"> </span>',
      '<span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;Can you explain me what is Jules asyncronous coding agent?&quot;</span>',
      '<span class="w"> </span>',
      '<span class="n">messages</span> <span class="o">=</span> <span class="p">[</span><span class="n">HumanMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="n">prompt</span><span class="p">)]</span>',
      '<span class="w"> </span>',
      '<span class="n">result_agent_pattern</span> <span class="o">=</span> <span class="n">graph_agent_pattern</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="n">messages</span><span class="p">},</span> <span class="n">config</span><span class="o">=</span><span class="n">config_USER2</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="k">for</span> <span class="n">message</span> <span class="ow">in</span> <span class="n">result_agent_pattern</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">]:</span>',
      '<span class="w">    </span><span class="n">message</span><span class="o">.</span><span class="n">pretty_print</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '================================ Human Message =================================',
          'Can you explain me what is Jules asyncronous coding agent?',
          '================================== Ai Message ==================================',
          'Tool Calls:',
          '&#x20;&#x20;tavily_search_results_json (0)',
          'Call ID: 0',
          '&#x20;&#x20;Args:',
          '&#x20;&#x20;&#x20;&#x20;query: Jules asynchronous coding agent',
          '================================= Tool Message =================================',
          'Name: tavily_search_results_json',
          '[&#x7B;&quot;title&quot;: &quot;Build with Jules, your asynchronous coding agent - Google Blog&quot;, &quot;url&quot;: &quot;https://blog.google/technology/google-labs/jules/&quot;, &quot;content&quot;: &quot;Today, Jules is entering public beta, available to everyone. No waitlist. Worldwide, everywhere where the Gemini model is available.\nWhat is Jules?\nJules is an asynchronous, agentic coding assistant that integrates directly with your existing repositories. It clones your codebase into a secure Google Cloud virtual machine (VM), understands the full context of your project, and performs tasks such as: [...] Google&#x27;s Jules coding agent is now in public beta. Jules autonomously reads your code performs tasks like writing tests and fixing bugs. It works asynchronously in a secure cloud environment and offers features like audio changelogs and GitHub integration.\nSummaries were generated by Google AI. Generative AI is experimental. \nShare\nTwitterFacebookLinkedInMail\nCopy link [...] Subscribe\nBreadcrumb\n1.   \n2.   Technology\n3.   Google Labs\nBuild with Jules, your asynchronous coding agent\nMay 20, 2025\n·\n3 min read\nShare\nTwitterFacebookLinkedInMail\nCopy link\nOur autonomous coding agent, Jules, is now in public beta.\nKathy Korevec\nDirector, Product Management, Google Labs \nRead AI-generated summary \nGeneral summary&quot;, &quot;score&quot;: 0.91399205&#x7D;, &#x7B;&quot;title&quot;: &quot;Meet Jules: Google AI Coding Agent — Codex/Copilot Killer?&quot;, &quot;url&quot;: &quot;https://medium.com/@samarrana407/meet-jules-google-ai-coding-agent-codex-copilot-killer-bb9e38867436&quot;, &quot;content&quot;: &quot;The landscape of AI coding agents is currently experiencing explosive growth, with new tools emerging rapidly to assist developers. Among the latest and most intriguing entries is Google’s Jules, an AI agent they are specifically labeling as an “asynchronous coding agent.” This designation hints at a fundamental difference from some other AI tools we’ve seen, suggesting a potentially significant shift in how developers interact with AI assistants. [...] Jules, however, operates differently. It aligns more closely with the concept of autonomous coding agents like OpenAI’s Codex Agent (distinct from the model). The key distinction is the asynchronous nature. Instead of working interactively line-by-line, you assign Jules a specific, potentially complex coding task. The agent then takes ownership of that task, works on it independently in the background, and presents the completed work once it’s ready. This promises a step closer to the early [...] What Sets Jules Apart? Asynchronous vs. Interactive Agents\n\nMany developers are familiar with AI coding tools integrated directly into their IDEs, such as Cursor or Windsurf. These tools typically work alongside the developer in real-time, offering code suggestions, completing lines, or refactoring code as you type — essentially “babysitting” your IDE.&quot;, &quot;score&quot;: 0.9051298&#x7D;, &#x7B;&quot;title&quot;: &quot;You can sign up for Google&#x27;s AI coding tool Jules right now - Mashable&quot;, &quot;url&quot;: &quot;https://mashable.com/article/jules-google-ai-coding-tool-sign-up&quot;, &quot;content&quot;: &quot;According to a Google blog post, Jules is an \&quot;asynchronous, agentic coding assistant that integrates directly with your existing repositories. It clones your codebase into a secure Google Cloud virtual machine (VM), understands the full context of your project, and performs tasks.\&quot;\n\nHow to sign up for Jules right now\n\nTo try Jules out for yourself, you can sign up at jules.google. Click \&quot;Try Jules\&quot; in the top right corner to create your own account.&quot;, &quot;score&quot;: 0.8839694&#x7D;, &#x7B;&quot;title&quot;: &quot;Google releases its asynchronous Jules AI agent for coding - ZDNet&quot;, &quot;url&quot;: &quot;https://www.zdnet.com/article/google-releases-its-asynchronous-jules-ai-agent-for-coding-how-to-try-it-for-free/&quot;, &quot;content&quot;: &quot;Originally unveiled by Google Labs in December, Jules is positioned as a reliable, automated coding assistant that can manage a broad suite of time-consuming tasks on behalf of human users. The model is \&quot;asynchronous,\&quot; which, in programming-speak, means it can start and work on tasks without having to wait for any single one of them to finish.\n\nAfterward, the model provides a full outline of the changes that were made to a user&#x27;s code, providing clarity into its reasoning process. [...] Google releases its asynchronous Jules AI agent for coding - how to try it for free\n\nThe race to deploy AI agents is heating up. At its annual I/O developer conference yesterday, Google announced that Jules, its new AI coding assistant, is now available worldwide in public beta. [...] As such, Jules offers some advanced coding capabilities. It can work directly within a user&#x27;s codebase, for example, absorbing a project&#x27;s full context and making decisions without the need for a sandbox (that is, a separate and controlled testing environment). It also integrates directly with GitHub, eliminating the need for developers to manually switch back and forth between coding platforms.\n\nAlso: Gemini Pro 2.5 is a stunningly capable coding assistant - and a big threat to ChatGPT&quot;, &quot;score&quot;: 0.86981434&#x7D;, &#x7B;&quot;title&quot;: &quot;Google Jules - Is this the end of Coding ? - YouTube&quot;, &quot;url&quot;: &quot;https://www.youtube.com/watch?v=2MjN1LpO60k&quot;, &quot;content&quot;: &quot;Google&#x27;s new AI tool, Jules, is set to transform the coding landscape. As an asynchronous coding agent, Jules can autonomously handle tasks&quot;, &quot;score&quot;: 0.8627572&#x7D;, &#x7B;&quot;title&quot;: &quot;Introducing Jules: An AI Coding Agent for GitHub - LinkedIn&quot;, &quot;url&quot;: &quot;https://www.linkedin.com/posts/shubhamsaboo_google-just-released-an-asynchronous-ai-coding-activity-7331143519350231040-JIyG&quot;, &quot;content&quot;: &quot;Google just released an Asynchronous AI Coding Agent...🤯 Powered by Gemini, it works on your GitHub Repos while you sleep. Submit a task. Go grab coffee. Come back to completed code. Jules doesn&#x27;t just write code snippets. It&#x27;s an Autonomous AI Agent that: ↳ Clones your entire GitHub repo ↳ Understands your full codebase context ↳ Fixes bugs and builds features independently ↳ Works on multiple tasks simultaneously ↳ Creates branches and prepares PRs for you The best part? You give it a task [...] and walk away. Jules runs in a secure cloud VM, handling everything while you focus on strategy, meetings, or other priorities. When it&#x27;s done, you get: → A complete plan with reasoning → Code diffs showing exactly what changed → Real-time activity logs → Ready-to-review PRs Jules is like having a dedicated developer on your team. → One that never sleeps. → One that understands your project inside and out. → One that can juggle multiple features while you focus on strategy. The asynchronous&quot;, &quot;score&quot;: 0.8252664&#x7D;, &#x7B;&quot;title&quot;: &quot;Jules - An Asynchronous Coding Agent&quot;, &quot;url&quot;: &quot;https://jules.google/&quot;, &quot;content&quot;: &quot;Jules does coding tasks you don&#x27;t want to do.\n\nJules does coding tasks you don&#x27;t want to do.\n\nMore time for the code you want to write, and everything else.\n\nSelect your GitHub repository and branch. Write a detailed prompt for Jules.\n\n*coming soon* use \&quot;assign-to-jules\&quot; label in an issue to assign a task directly in GitHub.\n\nJules fetches your repository, clones it to a Cloud VM, and develops a plan utilizing the latest Gemini 2.5 Pro model.\n\nHere is my plan: [...] I plan to update the following files to the new app directory structure.\n\nJules provides a diff of the changes. Quickly browse and approve code edits.\n\nJules creates a PR of the changes. Approve the PR, merge it to your branch, and publish it on GitHub.\n\nAlso, you can get caught up fast. Jules creates an audio summary of the changes.&quot;, &quot;score&quot;: 0.7771143&#x7D;, &#x7B;&quot;title&quot;: &quot;Jules - An Asynchronous Coding Agent (New Codex alternative from ...&quot;, &quot;url&quot;: &quot;https://www.reddit.com/r/ChatGPTCoding/comments/1kqompk/jules_an_asynchronous_coding_agent_new_codex/&quot;, &quot;content&quot;: &quot;It&#x27;s 5 tasks per day. A task can have many separate messages.&quot;, &quot;score&quot;: 0.6991933&#x7D;, &#x7B;&quot;title&quot;: &quot;Jules: An asynchronous coding agent | Hacker News&quot;, &quot;url&quot;: &quot;https://news.ycombinator.com/item?id=44034918&quot;, &quot;content&quot;: &quot;So, you can assign github issues to this thing, and it can handle them, merge the results in, and mark the bug as fixed?&quot;, &quot;score&quot;: 0.6638657&#x7D;]',
          '================================== Ai Message ==================================',
          '### Jules: An Asynchronous Coding Agent',
          '**Overview:**',
          'Jules is an asynchronous coding assistant developed by Google Labs, now available in public beta. It integrates directly with your existing code repositories, such as GitHub, and operates in a secure Google Cloud Virtual Machine (VM). The key feature of Jules is its asynchronous nature, meaning it can work on tasks independently in the background, without constant human oversight.',
          '**Key Features:**',
          '- **Asynchronous Task Handling:** Jules takes on specific coding tasks, works on them independently, and presents the completed work once ready. This allows developers to focus on strategic tasks and reduce repetitive coding chores.',
          '- **Full Codebase Understanding:** Jules clones your entire codebase into a secure cloud VM, where it gains a comprehensive understanding of your project&#x27;s context. This enables it to make informed decisions and perform tasks more effectively.',
          '- **Task Execution:** Jules can handle a variety of tasks, including writing tests, fixing bugs, and building features. It can work on multiple tasks simultaneously, enhancing productivity.',
          '- **GitHub Integration:** The tool integrates seamlessly with GitHub, allowing you to assign tasks directly from GitHub issues. Jules will create branches, prepare pull requests (PRs), and manage the entire process.',
          '- **Detailed Change Logs:** After completing a task, Jules provides a comprehensive outline of the changes made, along with reasoning and code diffs. It also offers real-time activity logs for transparency.',
          '- **Audio Summaries:** Jules can create audio summaries of the changes, helping you quickly catch up on what has been done.',
          '**How to Use Jules:**',
          '1. **Sign Up:** Visit the Jules website and click &quot;Try Jules&quot; to create an account.',
          '2. **Select Repository:** Choose the GitHub repository and branch you want Jules to work on.',
          '3. **Assign Tasks:** Write a detailed prompt or use the &quot;assign-to-jules&quot; label in a GitHub issue to assign tasks.',
          '4. **Review Changes:** Jules will provide a diff of the changes, which you can browse and approve.',
          '5. **Merge PRs:** Once you approve the changes, Jules will create a PR, which you can merge into your branch.',
          '**Advantages:**',
          '- **Increased Productivity:** By offloading repetitive and time-consuming tasks, Jules allows developers to focus on more strategic and creative aspects of their work.',
          '- **Consistent Quality:** Jules ensures that code changes are consistent and adhere to best practices.',
          '- **Scalability:** The ability to handle multiple tasks simultaneously makes Jules a valuable tool for large and complex projects.',
          '**Conclusion:**',
          'Jules represents a significant advancement in AI-assisted coding, offering a unique asynchronous approach that can significantly enhance the efficiency and effectiveness of development workflows. Its integration with GitHub and comprehensive task management features make it a powerful tool for developers looking to streamline their coding processes.',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We have a summary of what Jules is, let's print it.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">result_agent_pattern</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">pretty_print</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '================================== Ai Message ==================================',
          '### Jules: An Asynchronous Coding Agent',
          '**Overview:**',
          'Jules is an asynchronous coding assistant developed by Google Labs, now available in public beta. It integrates directly with your existing code repositories, such as GitHub, and operates in a secure Google Cloud Virtual Machine (VM). The key feature of Jules is its asynchronous nature, meaning it can work on tasks independently in the background, without constant human oversight.',
          '**Key Features:**',
          '- **Asynchronous Task Handling:** Jules takes on specific coding tasks, works on them independently, and presents the completed work once ready. This allows developers to focus on strategic tasks and reduce repetitive coding chores.',
          '- **Full Codebase Understanding:** Jules clones your entire codebase into a secure cloud VM, where it gains a comprehensive understanding of your project&#x27;s context. This enables it to make informed decisions and perform tasks more effectively.',
          '- **Task Execution:** Jules can handle a variety of tasks, including writing tests, fixing bugs, and building features. It can work on multiple tasks simultaneously, enhancing productivity.',
          '- **GitHub Integration:** The tool integrates seamlessly with GitHub, allowing you to assign tasks directly from GitHub issues. Jules will create branches, prepare pull requests (PRs), and manage the entire process.',
          '- **Detailed Change Logs:** After completing a task, Jules provides a comprehensive outline of the changes made, along with reasoning and code diffs. It also offers real-time activity logs for transparency.',
          '- **Audio Summaries:** Jules can create audio summaries of the changes, helping you quickly catch up on what has been done.',
          '**How to Use Jules:**',
          '1. **Sign Up:** Visit the Jules website and click &quot;Try Jules&quot; to create an account.',
          '2. **Select Repository:** Choose the GitHub repository and branch you want Jules to work on.',
          '3. **Assign Tasks:** Write a detailed prompt or use the &quot;assign-to-jules&quot; label in a GitHub issue to assign tasks.',
          '4. **Review Changes:** Jules will provide a diff of the changes, which you can browse and approve.',
          '5. **Merge PRs:** Once you approve the changes, Jules will create a PR, which you can merge into your branch.',
          '**Advantages:**',
          '- **Increased Productivity:** By offloading repetitive and time-consuming tasks, Jules allows developers to focus on more strategic and creative aspects of their work.',
          '- **Consistent Quality:** Jules ensures that code changes are consistent and adhere to best practices.',
          '- **Scalability:** The ability to handle multiple tasks simultaneously makes Jules a valuable tool for large and complex projects.',
          '**Conclusion:**',
          'Jules represents a significant advancement in AI-assisted coding, offering a unique asynchronous approach that can significantly enhance the efficiency and effectiveness of development workflows. Its integration with GitHub and comprehensive task management features make it a powerful tool for developers looking to streamline their coding processes.',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>













































    </div>

  </section>

</PostLayout>
