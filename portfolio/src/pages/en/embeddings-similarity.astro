---
import PostLayout from '@layouts/PostLayout.astro';
import CodeBlockInputCell from '@components/CodeBlockInputCell.astro';
import CodeBlockOutputCell from '@components/CodeBlockOutputCell.astro';

const { metadata_page } = await import('@portfolio/consts.json');
const { colors } = await import('@portfolio/consts.json');
const { svg_paths } = await import('@portfolio/consts.json');

const page_title = 'Medida de similitud entre embeddings';
const end_url = 'embeddings-similarity';
const description = 'Discover how similarity is measured between embeddings, the basis of the attention mechanism of transformers and RAG algorithms';
const keywords = 'embeddings, similarity, cosine similarity, L2 similarity, dot product similarity';
const languaje = 'EN';
const image_path = 'https://images.maximofn.com/embeddings-similarity.webp';
const opening_brace = '{';
const closing_brace = '}';
---

<PostLayout 
    title={page_title}
    languaje={languaje}
    description={description}
    keywords={keywords}
    author={metadata_page.author}
    theme_color={colors.background_color}
    end_url={end_url}
    image_path={image_path}
    image_width=1024
    image_height=1024
    image_extension=webp
    article_date=2023-12-18+T00:00:00Z
>

  <section class="post-body">


    <aside class="post-index">
      <a class="anchor-link" href="#L2 Square Similarity"><h2>L2 Square Similarity</h2></a>
      <a class="anchor-link" href="#Cosine Similarity"><h2>Cosine Similarity</h2></a>
      <a class="anchor-link" href="#Dot Product Similarity"><h2>Dot Product Similarity</h2></a>
      <a class="anchor-link" href="#Which similarity system to use"><h2>Which similarity system to use</h2></a>
    </aside>


    <div class="post-body-content">
      
      <section class="section-block-markdown-cell">
      </section>
      
      <section class="section-block-markdown-cell">
      <blockquote>
      <p>Disclaimer: This post has been translated to English using a machine translation model. Please, let me know if you find any mistakes.</p>
      </blockquote>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Now that we have seen what <a href="https://maximofn.com/embeddings">embeddings</a> are, we know that we can measure the similarity between two words by measuring the similarity between their embeddings. In the post on <a href="https://maximofn.com/embeddings">embeddings</a>, we saw an example of using cosine similarity as a measure, but there are other similarity measures we can use, such as L2 squared, dot product similarity, cosine similarity, etc.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>In this post, we are going to cover the three that we have mentioned.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="L2 Square Similarity">L2 Square Similarity<a class="anchor-link" href="#L2 Square Similarity"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 6" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>This similarity is derived from the Euclidean distance, which is the straight-line distance between two points in a multidimensional space, calculated using the Pythagorean theorem.</p>
      <img decoding="async" onerror="this.parentNode.removeChild(this)" src="https://images.maximofn.com/distancia_euclidiana.webp" alt="Euclidean distance">
      <p>The Euclidean distance between two points <span class="math-inline">p</span> and <span class="math-inline">q</span> is calculated as:</p>
      <p><span class="math-display">d(p,q) = &radic;((p<sub>1</sub> - q<sub>1</sub>)<sup>2</sup> + (p<sub>2</sub> - q<sub>2</sub>)<sup>2</sup> + ··· + (p<sub>n</sub> - q<sub>n</sub>)<sup>2</sup>) = &radic;(&sum;<sub>i=1</sub><sup>n</sup> (p<sub>i</sub> - q<sub>i</sub>)<sup>2</sup>)</span></p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>The L2 similarity is the square of the Euclidean distance, that is:</p>
      <p><span class="math-display">similarity(p,q) = d(p,q)<sup>2</sup> = &sum;<sub>i=1</sub><sup>n</sup> (p<sub>i</sub> - q<sub>i</sub>)<sup>2</sup></span></p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Cosine Similarity">Cosine Similarity<a class="anchor-link" href="#Cosine Similarity"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 7" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>If we remember what we learned about sines and cosines in school, we will recall that when two vectors have an angle of 0° between them, their cosine is 1, when the angle between them is 90°, their cosine is 0, and when the angle is 180°, their cosine is -1.</p>
      <img decoding="async" onerror="this.parentNode.removeChild(this)" src="https://images.maximofn.com/dot-product.gif" alt="cosine similarity">
      <img decoding="async" onerror="this.parentNode.removeChild(this)" src="https://images.maximofn.com/dot-product-unity.gif" alt="cosine similarity">
      <p>Therefore, we can use the cosine of the angle between two vectors to measure their similarity. It can be shown that the cosine of the angle between two vectors is equal to the dot product of the two vectors divided by the product of their magnitudes. Proving this is not the goal of this post, but if you want, you can see the proof <a href="https://www.wwwinsights.com/wp-content/uploads/2023/05/image-11-1024x694.png" target="_blank" rel="nofollow noreferrer">here</a>.</p>
      <p><span class="math-display">similarity(U,V) = <span class="math-fraction"><span class="math-fraction-numerator">U · V</span><span class="math-fraction-denominator">||U|| ||V||</span></span></span></p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Dot Product Similarity">Dot Product Similarity<a class="anchor-link" href="#Dot Product Similarity"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 8" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>The dot product similarity is the dot product of two vectors</p>
      <p><span class="math-display">similarity(U,V) = U · V</span></p>
      <p>As we have written the cosine similarity formula, when the length of the vectors is 1, that is, they are normalized, the cosine similarity is equal to the dot product similarity.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>So, what is the use of the dot product similarity? It is used to measure the similarity between two vectors that are not normalized, that is, they do not have a length of 1.</p>
      <p>For example, YouTube, to create the embeddings of its videos, makes the embeddings of the videos it classifies as higher quality longer than those of the videos it classifies as lower quality.</p>
      <p>In this way, when a user performs a search, the dot product similarity will give higher similarity to higher quality videos, so it will provide the user with the highest quality videos first.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Which similarity system to use">Which similarity system to use<a class="anchor-link" href="#Which similarity system to use"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 9" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>To choose the similarity system we are going to use, we must take into account the space in which we are working.</p>
      <ul>
        <li>If we are working in a high-dimensional space, with normalized embeddings, cosine similarity works best. For example, OpenAI generates normalized embeddings, so cosine similarity works best.</li>
        <li>If we are working on a classification system where the distance between two classes is important, the L2 squared similarity works best.</li>
        <li>If we are working on a recommendation system where the length of the vectors is important, the dot product similarity works best.</li>
      </ul>
      </section>







    </div>

  </section>

</PostLayout>
