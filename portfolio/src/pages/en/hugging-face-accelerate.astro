---
import PostLayout from '@layouts/PostLayout.astro';
import CodeBlockInputCell from '@components/CodeBlockInputCell.astro';
import CodeBlockOutputCell from '@components/CodeBlockOutputCell.astro';

const { metadata_page } = await import('@portfolio/consts.json');
const { colors } = await import('@portfolio/consts.json');
const { svg_paths } = await import('@portfolio/consts.json');

const page_title = 'HuggingFace Accelerate: Complete Guide to Train Models on GPU/TPU';
const end_url = 'hugging-face-accelerate/';
const description = 'Learn how to use Hugging Face Accelerate to train ML models on multiple GPUs and TPUs. Complete tutorial with practical examples and code.';
const keywords = 'hugging face, accelerate, pytorch, deep learning, machine learning, transformers';
const languaje = 'EN';
const image_path = 'https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/huggingface_accelerate.webp';
const opening_brace = '{';
const closing_brace = '}';
---

<PostLayout 
    title={page_title}
    languaje={languaje}
    description={description}
    keywords={keywords}
    author={metadata_page.author}
    theme_color={colors.background_color}
    end_url={end_url}
    image_path={image_path}
    image_width=1280
    image_height=670
    image_extension=webp
    article_date=2024-05-16+T00:00:00Z
>

  <section class="post-body">


    <aside class="post-index">
      <a class="anchor-link" href="#Installation"><h2>Installation</h2></a>
      <a class="anchor-link" href="#Configuration"><h2>Configuration</h2></a>
      <a class="anchor-link" href="#Training"><h2>Training</h2></a>
      <a class="anchor-link" href="#Training-optimization"><h3>Training optimization</h3></a>
      <a class="anchor-link" href="#Base-code"><h4>Base code</h4></a>
      <a class="anchor-link" href="#Script-with-the-code-base"><h4>Script with the code base</h4></a>
      <a class="anchor-link" href="#Code-with-accelerate"><h4>Code with accelerate</h4></a>
      <a class="anchor-link" href="#Process-execution"><h3>Process execution</h3></a>
      <a class="anchor-link" href="#Execution-of-code-in-a-single-process"><h4>Execution of code in a single process</h4></a>
      <a class="anchor-link" href="#Code-execution-in-all-processes"><h4>Code execution in all processes</h4></a>
      <a class="anchor-link" href="#Execution-of-code-in-the-process-X"><h4>Execution of code in the process X</h4></a>
      <a class="anchor-link" href="#Synchronize-processes"><h4>Synchronize processes</h4></a>
      <a class="anchor-link" href="#Save-and-load-the-state-dict"><h3>Save and load the state dict</h3></a>
      <a class="anchor-link" href="#Save-the-model"><h3>Save the model</h3></a>
      <a class="anchor-link" href="#Save-the-pretrained-model"><h3>Save the <code>pretrained</code> model</h3></a>
      <a class="anchor-link" href="#Training-on-notebooks"><h3>Training on notebooks</h3></a>
      <a class="anchor-link" href="#Training-in-FP16"><h3>Training in FP16</h3></a>
      <a class="anchor-link" href="#BF16-Training"><h3>BF16 Training</h3></a>
      <a class="anchor-link" href="#Training-in-FP8"><h3>Training in FP8</h3></a>
      <a class="anchor-link" href="#Model-inference"><h2>Model inference</h2></a>
      <a class="anchor-link" href="#Using-the-Hugging-Face-Ecosystem"><h3>Using the Hugging Face Ecosystem</h3></a>
      <a class="anchor-link" href="#Inference-with-pipeline."><h4>Inference with <code>pipeline</code>.</h4></a>
      <a class="anchor-link" href="#Inference-with-AutoClass"><h4>Inference with <code>AutoClass</code></h4></a>
      <a class="anchor-link" href="#Use-pytorch"><h3>Use pytorch</h3></a>
      <a class="anchor-link" href="#How-accelerate-works-below"><h3>How accelerate works below</h3></a>
      <a class="anchor-link" href="#Initialization-of-an-empty-model"><h4>Initialization of an empty model</h4></a>
      <a class="anchor-link" href="#Loading-weights"><h4>Loading weights</h4></a>
    </aside>


    <div class="post-body-content">
      
      <section class="section-block-markdown-cell">
      <h1 id="Hugging-Face-Accelerate">Hugging Face Accelerate<a class="anchor-link" href="#Hugging-Face-Accelerate"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 28" src={svg_paths.link_svg_path}/></a></h1>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Accelerate is a Hugging Face library that allows you to run the same PyTorch code in any distributed configuration by adding only four lines of code.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>This notebook has been automatically translated to make it accessible to more people, please let me know if you see any typos.</p>
      <h2 id="Installation">Installation<a class="anchor-link" href="#Installation"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 29" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>To install <code>accelerate</code> with <code>pip</code> simply run:</p>
      <div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>accelerate
      </pre></div>
      <p>And with <code>conda</code>:</p>
      <div class="highlight"><pre><span></span>conda<span class="w"> </span>install<span class="w"> </span>-c<span class="w"> </span>conda-forge<span class="w"> </span>accelerate
      </pre></div>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Configuration">Configuration<a class="anchor-link" href="#Configuration"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 30" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>In every environment in which <code>accelerate</code> is installed, the first thing to do is to configure it, for that we execute in a terminal:</p>
      <div class="highlight"><pre><span></span>accelerate<span class="w"> </span>config
      </pre></div>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">!</span>accelerate<span class="w"> </span>config',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '--------------------------------------------------------------------------------',
          'In which compute environment are you running?',
          'This machine',
          '--------------------------------------------------------------------------------',
          'multi-GPU',
          'How many different machines will you use (use more than 1 for multi-node training)? [1]: 1',
          'Should distributed operations be checked while running for errors? This can avoid timeout issues but will be slower. [yes/NO]: no',
          'Do you wish to optimize your script with torch dynamo?[yes/NO]:no',
          'Do you want to use DeepSpeed? [yes/NO]: no',
          'Do you want to use FullyShardedDataParallel? [yes/NO]: no',
          'Do you want to use Megatron-LM ? [yes/NO]: no',
          'How many GPU(s) should be used for distributed training? [1]:2',
          'What GPU(s) (by id) should be used for training on this machine as a comma-seperated list? [all]:0,1',
          '--------------------------------------------------------------------------------',
          'Do you wish to use FP16 or BF16 (mixed precision)?',
          'no',
          'accelerate configuration saved at ~/.cache/huggingface/accelerate/default_config.yaml',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>In my case the answers have been</p>
      <ul>
      <li>In which compute environment are you running?<ul>
      <li class="task-list-item"><input checked="" class="task-list-item-checkbox" disabled="" type="checkbox"/>"This machine"</li>
      <li>[_] "AWS (Amazon SageMaker)"</li>
      </ul>
      </li>
      </ul>
      <blockquote>
      <p>I want to configure it on my computer</p>
      </blockquote>
      <ul>
      <li>Which type of machine are you using?<ul>
      <li>[_] multi-CPU</li>
      <li>[_] multi-XPU</li>
      <li>x] multi-GPU</li>
      <li>[_] multi-NPU</li>
      <li>[_] TPU</li>
      </ul>
      </li>
      </ul>
      <blockquote>
      <p>As I have 2 GPUs and I want to run distributed codes on them I choose <code>multi-GPU</code>.</p>
      </blockquote>
      <ul>
      <li>How many different machines will you use (use more than 1 for multi-node training)? [1]:<ul>
      <li>1</li>
      </ul>
      </li>
      </ul>
      <blockquote>
      <p>I choose <code>1</code> because I am only going to run on my computer.</p>
      </blockquote>
      <ul>
      <li>Should distributed operations be checked while running for errors? This can avoid timeout issues but will be slower. [yes/NO]:<ul>
      <li>no</li>
      </ul>
      </li>
      </ul>
      <blockquote>
      <p>With this option, you can choose to have <code>accelerate</code> check for errors on execution, but it would slow it down, so I choose <code>no</code>, and in case there are errors I change it to <code>yes</code>.</p>
      </blockquote>
      <ul>
      <li><p>Do you wish to optimize your script with torch dynamo? [yes/NO]:</p>
      <ul>
      <li>no</li>
      </ul>
      </li>
      <li><p>Do you want to use FullyShardedDataParallel? [yes/NO]:</p>
      <ul>
      <li>no</li>
      </ul>
      </li>
      <li><p>Do you want to use Megatron-LM ? [yes/NO]:</p>
      <ul>
      <li>no</li>
      </ul>
      </li>
      <li><p>How many GPU(s) should be used for distributed training? [1]:</p>
      </li>
      </ul>
      <blockquote>
      <p>I choose <code>2</code> because I have 2 GPUs</p>
      </blockquote>
      <ul>
      <li>What GPU(s) (by id) should be used for training on this machine as a comma-seperated list? [all]:<ul>
      <li>0,1</li>
      </ul>
      </li>
      </ul>
      <blockquote>
      <p>I choose <code>0,1</code> because I want to use both GPUs.</p>
      </blockquote>
      <ul>
      <li>Do you wish to use FP16 or BF16 (mixed precision)?<ul>
      <li>x] no</li>
      <li>[_] fp16</li>
      <li>[_] bf16</li>
      <li>[_] fp8</li>
      </ul>
      </li>
      </ul>
      <blockquote>
      <p>For the moment I choose <code>no</code>, because to simplify the code when not using <code>accelerate</code> we are going to train on fp32, but ideally we should use fp16</p>
      </blockquote>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>The configuration will be stored in <code>~/.cache/huggingface/accelerate/default_config.yaml</code> and can be modified at any time. Let's see what's inside</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">!</span>cat<span class="w"> </span>~/.cache/huggingface/accelerate/default_config.yaml',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'compute_environment: LOCAL_MACHINE',
          'debug: false',
          'distributed_type: MULTI_GPU',
          'downcast_bf16: \'no\'',
          'gpu_ids: 0,1',
          'machine_rank: 0',
          'main_training_function: main',
          'mixed_precision: fp16',
          'num_machines: 1',
          'num_processes: 2',
          'rdzv_backend: static',
          'same_network: true',
          'tpu_env: []',
          'tpu_use_cluster: false',
          'tpu_use_sudo: false',
          'use_cpu: false',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Another way to see the configuration we have is to run it in a terminal:</p>
      <div class="highlight"><pre><span></span>accelerate<span class="w"> </span>env
      </pre></div>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">!</span>accelerate<span class="w"> </span>env',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Copy-and-paste the text below in your GitHub issue',
          '- `Accelerate` version: 0.28.0',
          '- Platform: Linux-5.15.0-105-generic-x86_64-with-glibc2.31',
          '- Python version: 3.11.8',
          '- Numpy version: 1.26.4',
          '- PyTorch version (GPU?): 2.2.1+cu121 (True)',
          '- PyTorch XPU available: False',
          '- PyTorch NPU available: False',
          '- System RAM: 31.24 GB',
          '- GPU type: NVIDIA GeForce RTX 3090',
          '- `Accelerate` default config:',
          '	- compute_environment: LOCAL_MACHINE',
          '	- distributed_type: MULTI_GPU',
          '	- mixed_precision: fp16',
          '	- use_cpu: False',
          '	- debug: False',
          '	- num_processes: 2',
          '	- machine_rank: 0',
          '	- num_machines: 1',
          '	- gpu_ids: 0,1',
          '	- rdzv_backend: static',
          '	- same_network: True',
          '	- main_training_function: main',
          '	- downcast_bf16: no',
          '	- tpu_use_cluster: False',
          '	- tpu_use_sudo: False',
          '	- tpu_env: []',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Once we have configured <code>accelerate</code> we can test if we have done it right by running it in a terminal:</p>
      <div class="highlight"><pre><span></span>accelerate<span class="w"> </span><span class="nb">test</span>
      </pre></div>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">!</span>accelerate<span class="w"> </span>test',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Running:  accelerate-launch ~/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/test_utils/scripts/test_script.py',
          'stdout: **Initialization**',
          'stdout: Testing, testing. 1, 2, 3.',
          'stdout: Distributed environment: DistributedType.MULTI_GPU  Backend: nccl',
          'stdout: Num processes: 2',
          'stdout: Process index: 0',
          'stdout: Local process index: 0',
          'stdout: Device: cuda:0',
          'stdout: ',
          'stdout: Mixed precision type: fp16',
          'stdout: ',
          'stdout: Distributed environment: DistributedType.MULTI_GPU  Backend: nccl',
          'stdout: Num processes: 2',
          'stdout: Process index: 1',
          'stdout: Local process index: 1',
          'stdout: Device: cuda:1',
          'stdout: ',
          'stdout: Mixed precision type: fp16',
          'stdout: ',
          'stdout: ',
          'stdout: **Test process execution**',
          'stdout: ',
          'stdout: **Test split between processes as a list**',
          'stdout: ',
          'stdout: **Test split between processes as a dict**',
          'stdout: ',
          'stdout: **Test split between processes as a tensor**',
          'stdout: ',
          'stdout: **Test random number generator synchronization**',
          'stdout: All rng are properly synched.',
          'stdout: ',
          'stdout: **DataLoader integration test**',
          'stdout: 0 1 tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,',
          'stdout:         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,',
          'stdout:         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,',
          'stdout:         54, 55, 56, 57, 58, 59, 60, 61, 62, 63], device=\'cuda:1\') &lt;class \'accelerate.data_loader.DataLoaderShard\'&gt;',
          'stdout: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,',
          'stdout:         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,',
          'stdout:         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,',
          'stdout:         54, 55, 56, 57, 58, 59, 60, 61, 62, 63], device=\'cuda:0\') &lt;class \'accelerate.data_loader.DataLoaderShard\'&gt;',
          'stdout: Non-shuffled dataloader passing.',
          'stdout: Shuffled dataloader passing.',
          'stdout: Non-shuffled central dataloader passing.',
          'stdout: Shuffled central dataloader passing.',
          'stdout: ',
          'stdout: **Training integration test**',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Training yielded the same results on one CPU or distributed setup with no batch split.',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Training yielded the same results on one CPU or distributes setup with batch split.',
          'stdout: FP16 training check.',
          'stdout: FP16 training check.',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Keep fp32 wrapper check.',
          'stdout: Keep fp32 wrapper check.',
          'stdout: BF16 training check.',
          'stdout: BF16 training check.',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: ',
          'stdout: Training yielded the same results on one CPU or distributed setup with no batch split.',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: FP16 training check.',
          'stdout: Training yielded the same results on one CPU or distributes setup with batch split.',
          'stdout: FP16 training check.',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Keep fp32 wrapper check.',
          'stdout: Keep fp32 wrapper check.',
          'stdout: BF16 training check.',
          'stdout: BF16 training check.',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: ',
          'stdout: **Breakpoint trigger test**',
          'Test is a success! You are ready for your distributed training!',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We see that it ends saying <code>Test is a success! You are ready for your distributed training!</code> so everything is correct.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Training">Training<a class="anchor-link" href="#Training"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 31" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Training-optimization">Training optimization<a class="anchor-link" href="#Training-optimization"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 32" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <h4 id="Base-code">Base code<a class="anchor-link" href="#Base-code"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 33" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>We will first make a base training code and then optimize it to see how it is done and how it improves.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>First let's look for a dataset, in my case I will use the dataset <a href="https://huggingface.co/datasets/tweet_eval" target="_blank" rel="nofollow noreferrer">tweet_eval</a>, which is a tweet classification dataset, specifically I will download the subset <code>emoji</code> which classifies tweets with emoticons.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">dataset</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'DatasetDict({',
          '    train: Dataset({',
          '        features: [\'text\', \'label\'],',
          '        num_rows: 45000',
          '    })',
          '    test: Dataset({',
          '        features: [\'text\', \'label\'],',
          '        num_rows: 50000',
          '    })',
          '    validation: Dataset({',
          '        features: [\'text\', \'label\'],',
          '        num_rows: 5000',
          '    })',
          '})',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'DatasetInfo(description=\'\', citation=\'\', homepage=\'\', license=\'\', features={\'text\': Value(dtype=\'string\', id=None), \'label\': ClassLabel(names=[\'â¤\', \'ðŸ˜\', \'ðŸ˜‚\', \'ðŸ’•\', \'ðŸ”¥\', \'ðŸ˜Š\', \'ðŸ˜Ž\', \'âœ¨\', \'ðŸ’™\', \'ðŸ˜˜\', \'ðŸ“·\', \'ðŸ‡ºðŸ‡¸\', \'â˜€\', \'ðŸ’œ\', \'ðŸ˜‰\', \'ðŸ’¯\', \'ðŸ˜\', \'ðŸŽ„\', \'ðŸ“¸\', \'ðŸ˜œ\'], id=None)}, post_processed=None, supervised_keys=None, task_templates=None, builder_name=\'parquet\', dataset_name=\'tweet_eval\', config_name=\'emoji\', version=0.0.0, splits={\'train\': SplitInfo(name=\'train\', num_bytes=3808792, num_examples=45000, shard_lengths=None, dataset_name=\'tweet_eval\'), \'test\': SplitInfo(name=\'test\', num_bytes=4262151, num_examples=50000, shard_lengths=None, dataset_name=\'tweet_eval\'), \'validation\': SplitInfo(name=\'validation\', num_bytes=396704, num_examples=5000, shard_lengths=None, dataset_name=\'tweet_eval\')}, download_checksums={\'hf://datasets/tweet_eval@b3a375baf0f409c77e6bc7aa35102b7b3534f8be/emoji/train-00000-of-00001.parquet\': {\'num_bytes\': 2609973, \'checksum\': None}, \'hf://datasets/tweet_eval@b3a375baf0f409c77e6bc7aa35102b7b3534f8be/emoji/test-00000-of-00001.parquet\': {\'num_bytes\': 3047341, \'checksum\': None}, \'hf://datasets/tweet_eval@b3a375baf0f409c77e6bc7aa35102b7b3534f8be/emoji/validation-00000-of-00001.parquet\': {\'num_bytes\': 281994, \'checksum\': None}}, download_size=5939308, post_processing_size=None, dataset_size=8467647, size_in_bytes=14406955)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Let's take a look at the classes</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="nb">print</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '[\'â¤\', \'ðŸ˜\', \'ðŸ˜‚\', \'ðŸ’•\', \'ðŸ”¥\', \'ðŸ˜Š\', \'ðŸ˜Ž\', \'âœ¨\', \'ðŸ’™\', \'ðŸ˜˜\', \'ðŸ“·\', \'ðŸ‡ºðŸ‡¸\', \'â˜€\', \'ðŸ’œ\', \'ðŸ˜‰\', \'ðŸ’¯\', \'ðŸ˜\', \'ðŸŽ„\', \'ðŸ“¸\', \'ðŸ˜œ\']',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>And the number of classes</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">num_classes</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '20',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We see that the dataset has 20 classes</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Let's see the maximum sequence of each split</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">max_len_train</span> <span class="o">=</span> <span class="mi">0</span>',
          '<span class="n">max_len_val</span> <span class="o">=</span> <span class="mi">0</span>',
          '<span class="n">max_len_test</span> <span class="o">=</span> <span class="mi">0</span>',
          '',
          '<span class="n">split</span> <span class="o">=</span> <span class="s2">"train"</span>',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">])):</span>',
          '    <span class="n">len_i</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s2">"text"</span><span class="p">])</span>',
          '    <span class="k">if</span> <span class="n">len_i</span> <span class="o">&gt;</span> <span class="n">max_len_train</span><span class="p">:</span>',
          '        <span class="n">max_len_train</span> <span class="o">=</span> <span class="n">len_i</span>',
          '<span class="n">split</span> <span class="o">=</span> <span class="s2">"validation"</span>',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">])):</span>',
          '    <span class="n">len_i</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s2">"text"</span><span class="p">])</span>',
          '    <span class="k">if</span> <span class="n">len_i</span> <span class="o">&gt;</span> <span class="n">max_len_val</span><span class="p">:</span>',
          '        <span class="n">max_len_val</span> <span class="o">=</span> <span class="n">len_i</span>',
          '<span class="n">split</span> <span class="o">=</span> <span class="s2">"test"</span>',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">])):</span>',
          '    <span class="n">len_i</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s2">"text"</span><span class="p">])</span>',
          '    <span class="k">if</span> <span class="n">len_i</span> <span class="o">&gt;</span> <span class="n">max_len_test</span><span class="p">:</span>',
          '        <span class="n">max_len_test</span> <span class="o">=</span> <span class="n">len_i</span>',
          '',
          '<span class="n">max_len_train</span><span class="p">,</span> <span class="n">max_len_val</span><span class="p">,</span> <span class="n">max_len_test</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '(142, 139, 167)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>So we define the maximum sequence in general as 130 for tokeniaztion</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>






      
      <section class="section-block-markdown-cell">
      <p>We are interested in the tokenized dataset, not the raw sequences, so we create a tokenizer</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>',
      '      ',
      '      <span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
      '      <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>









      
      <section class="section-block-markdown-cell">
      <p>We create a tokenization function</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>',
      '      ',
      '      <span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
      '      <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span></span><span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
      '          <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>







      
      <section class="section-block-markdown-cell">
      <p>And now we tokenize the dataset</p>
      </section>
      
      <section class="section-block-code-cell-">
      <div class="input-code">
      <div class="highlight hl-ipython3">
<pre><span></span><span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{opening_brace}</span>
          <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>
          <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>
          <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>
      <span class="p">{closing_brace}</span>
      </pre></div>
      </div>
      <div class="output-wrapper">
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-text-output-subarea">
      <pre>Map:   0%|          | 0/45000 [00:00&lt;?, ? examples/s]</pre>
      </div>
      </div>
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-text-output-subarea">
      <pre>Map:   0%|          | 0/5000 [00:00&lt;?, ? examples/s]</pre>
      </div>
      </div>
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-text-output-subarea">
      <pre>Map:   0%|          | 0/50000 [00:00&lt;?, ? examples/s]</pre>
      </div>
      </div>
      </div>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>As we see now we have the tokens (<code>input_ids</code>) and the attention masks (<code>attention_mask</code>), but let's see what kind of data we have</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '</span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '</span><span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '</span><span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '</span><span class="nb">type</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">"input_ids"</span><span class="p">]),</span> <span class="nb">type</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">"attention_mask"</span><span class="p">]),</span> <span class="nb">type</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">"label"</span><span class="p">])</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Map:   0%|          | 0/45000 [00:00&lt;?, ? examples/s]',
          '(list, list, int)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="nb">type</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">"label"</span><span class="p">]),</span> <span class="nb">type</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">"input_ids"</span><span class="p">]),</span> <span class="nb">type</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">"attention_mask"</span><span class="p">])</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '(torch.Tensor, torch.Tensor, torch.Tensor)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We create a dataloader</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
      '      <span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
      '      <span class="n">BS</span> <span class="o">=</span> <span class="mi">64</span>',
      '      ',
      '      <span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
      '          <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '          <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '          <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '      <span class="p">}</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>














      
      <section class="section-block-markdown-cell">
      <p>We load the model</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
      '      <span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
      '      <span class="n">BS</span> <span class="o">=</span> <span class="mi">64</span>',
      '      ',
      '      <span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
      '          <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '          <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '          <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '      <span class="p">}</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span>',
      '      ',
      '      <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>








      
      <section class="section-block-markdown-cell">
      <p>Let's see what the model looks like</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">64</span>',
          '',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '</span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '</span><span class="n">model</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'RobertaForSequenceClassification(',
          '  (roberta): RobertaModel(',
          '    (embeddings): RobertaEmbeddings(',
          '      (word_embeddings): Embedding(50265, 768, padding_idx=1)',
          '      (position_embeddings): Embedding(514, 768, padding_idx=1)',
          '      (token_type_embeddings): Embedding(1, 768)',
          '      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)',
          '      (dropout): Dropout(p=0.1, inplace=False)',
          '    )',
          '    (encoder): RobertaEncoder(',
          '      (layer): ModuleList(',
          '        (0-11): 12 x RobertaLayer(',
          '          (attention): RobertaAttention(',
          '            (self): RobertaSelfAttention(',
          '              (query): Linear(in_features=768, out_features=768, bias=True)',
          '              (key): Linear(in_features=768, out_features=768, bias=True)',
          '              (value): Linear(in_features=768, out_features=768, bias=True)',
          '              (dropout): Dropout(p=0.1, inplace=False)',
          '            )',
          '            (output): RobertaSelfOutput(',
          '              (dense): Linear(in_features=768, out_features=768, bias=True)',
          '              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)',
          '              (dropout): Dropout(p=0.1, inplace=False)',
          '            )',
          '          )',
          '          (intermediate): RobertaIntermediate(',
          '            (dense): Linear(in_features=768, out_features=3072, bias=True)',
          '            (intermediate_act_fn): GELUActivation()',
          '          )',
          '          (output): RobertaOutput(',
          '            (dense): Linear(in_features=3072, out_features=768, bias=True)',
          '            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)',
          '            (dropout): Dropout(p=0.1, inplace=False)',
          '          )',
          '        )',
          '      )',
          '    )',
          '  )',
          '  (classifier): RobertaClassificationHead(',
          '    (dense): Linear(in_features=768, out_features=768, bias=True)',
          '    (dropout): Dropout(p=0.1, inplace=False)',
          '    (out_proj): Linear(in_features=768, out_features=2, bias=True)',
          '  )',
          ')',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Let's take a look at its last layer</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Linear(in_features=768, out_features=2, bias=True)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">out_features</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '(768, 2)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We have seen that our dataset has 20 classes, but this model is trained for 2 classes, so we have to modify the last layer</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Linear(in_features=768, out_features=20, bias=True)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Now it is</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Now we create a loss function</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>






      
      <section class="section-block-markdown-cell">
      <p>An optimizer</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
      '<span></span><span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
      '      ',
      '      <span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>








      
      <section class="section-block-markdown-cell">
      <p>And finally a metric</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
      '<span></span><span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
      '      ',
      '      <span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
      '<span></span><span class="kn">import</span> <span class="nn">evaluate</span>',
      '      ',
      '      <span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>








      
      <section class="section-block-markdown-cell">
      <p>Let's check that everything is all right with a sample</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
      '<span></span><span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
      '      ',
      '      <span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
      '<span></span><span class="kn">import</span> <span class="nn">evaluate</span>',
      '      ',
      '      <span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
      '<span></span><span class="n">sample</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]))</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>






      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '</span><span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '</span><span class="kn">import</span> <span class="nn">evaluate</span>',
          '',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '</span><span class="n">sample</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]))</span>',
          '</span><span class="n">sample</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">sample</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '(torch.Size([64, 130]), torch.Size([64, 130]))',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Now we put that sample into the model</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">"cuda"</span><span class="p">)</span>',
          '<span class="n">ouputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">sample</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">"cuda"</span><span class="p">),</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">sample</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">"cuda"</span><span class="p">))</span>',
          '<span class="n">ouputs</span><span class="o">.</span><span class="n">logits</span><span class="o">.</span><span class="n">shape</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'torch.Size([64, 20])',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We see that the model outputs 64 batches, which is fine, because we set <code>BS = 20</code> and each with 20 outputs, which is fine because we changed the model to output 20 values.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>We obtain the one with the highest value</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">ouputs</span><span class="o">.</span><span class="n">logits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '<span class="n">predictions</span><span class="o">.</span><span class="n">shape</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'torch.Size([64])',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We obtain the loss</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">ouputs</span><span class="o">.</span><span class="n">logits</span><span class="p">,</span> <span class="n">sample</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">"cuda"</span><span class="p">))</span>',
          '<span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '2.9990389347076416',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>And the accuracy</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">sample</span><span class="p">[</span><span class="s2">"label"</span><span class="p">])[</span><span class="s2">"accuracy"</span><span class="p">]</span>',
          '<span class="n">accuracy</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '0.015625',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We can now create a small training loop</p>
      </section>
      
      <section class="section-block-code-cell-">
      <div class="input-code">
      <div class="highlight hl-ipython3">
<pre><span></span><span class="kn">from</span> <span class="nn">fastprogress.fastprogress</span> <span class="kn">import</span> <span class="n">master_bar</span><span class="p">,</span> <span class="n">progress_bar</span>
      
      <span class="n">epochs</span> <span class="o">=</span> <span class="mi">1</span>
      <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>
      <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
      
      <span class="n">master_progress_bar</span> <span class="o">=</span> <span class="n">master_bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">))</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">master_progress_bar</span><span class="p">:</span>
          <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
          <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>
          <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>
              <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
      
              <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
              <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
              <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
      
              <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
              <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">'logits'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
              <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">'loss: </span><span class="si">{opening_brace}</span><span class="n">loss</span><span class="si">{closing_brace}</span><span class="s1">'</span>
      
              <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
              <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
      
          <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
          <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>
          <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>
              <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
              <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
              <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
      
              <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                  <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
              <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">'logits'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
      
              <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
          <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
          
          <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">main_bar</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"Validation accuracy: </span><span class="si">{opening_brace}</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">]</span><span class="si">{closing_brace}</span><span class="se">\n</span><span class="s2">"</span>
      </pre></div>
      </div>
      <div class="output-wrapper">
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-html-rendered-html-output-subarea">
      <style>
          /* Turns off some styling */
          progress {
              /* gets rid of default border in Firefox and Opera. */
              border: none;
              /* Needs to be in here for Safari polyfill so background images work as expected. */
              background-size: auto;
          }
          progress:not([value]), progress:not([value])::-webkit-progress-bar {
              background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
          }
          .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
              background: #F44336;
          }
      </style>
      </div>
      </div>
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-html-rendered-html-output-subarea"></div>
      </div>
      </div>
      </section>
      
      <section class="section-block-markdown-cell">
      <h4 id="Script-with-the-code-base">Script with the code base<a class="anchor-link" href="#Script-with-the-code-base"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 34" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>In most of the <code>accelerate</code> documentation it is explained how to use <code>accelerate</code> with scripts, so for the moment we will do it like this and at the end we will explain how to do it with a notebook</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>First we are going to create a folder where we are going to save the scripts</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">fastprogress.fastprogress</span> <span class="kn">import</span> <span class="n">master_bar</span><span class="p">,</span> <span class="n">progress_bar</span>',
      '      ',
      '      <span class="n">epochs</span> <span class="o">=</span> <span class="mi">1</span>',
      '      <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>',
      '      <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '      ',
      '      <span class="n">master_progress_bar</span> <span class="o">=</span> <span class="n">master_bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">))</span>',
      '      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">master_progress_bar</span><span class="p">:</span>',
      '          <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '          <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
      '          <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
      '              <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
      '      ',
      '              <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '              <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '              <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '      ',
      '              <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '              <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
      '              <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">\'loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s1">\'</span>',
      '      ',
      '              <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>',
      '              <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
      '      ',
      '          <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
      '          <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
      '          <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
      '              <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '              <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '              <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '      ',
      '              <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
      '                  <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '              <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
      '      ',
      '              <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
      '          <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
      '          ',
      '          <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">main_bar</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"Validation accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span>',
      '<span></span><span class="o">!</span>mkdir<span class="w"> </span>accelerate_scripts',
        ]}
        languaje='python'
      ></CodeBlockInputCell>






      
      <section class="section-block-markdown-cell">
      <p>Now we write the base code in a script</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">fastprogress.fastprogress</span> <span class="kn">import</span> <span class="n">master_bar</span><span class="p">,</span> <span class="n">progress_bar</span>',
          '',
          '<span class="n">epochs</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '',
          '<span class="n">master_progress_bar</span> <span class="o">=</span> <span class="n">master_bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">))</span>',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">master_progress_bar</span><span class="p">:</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '        <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">\'loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s1">\'</span>',
          '',
          '        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '    ',
          '    <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">main_bar</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"Validation accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="se">\\n</span><span class="s2">"</span>',
          '</span><span class="o">!</span>mkdir<span class="w"> </span>accelerate_scripts',
          '</span><span class="o">%%writefile</span> accelerate_scripts/01_code_base.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">from</span> <span class="nn">fastprogress.fastprogress</span> <span class="kn">import</span> <span class="n">master_bar</span><span class="p">,</span> <span class="n">progress_bar</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">64</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '',
          '<span class="n">master_progress_bar</span> <span class="o">=</span> <span class="n">master_bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">))</span>',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">master_progress_bar</span><span class="p">:</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '        <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">\'loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s1">\'</span>',
          '',
          '        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '    ',
          '    <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">main_bar</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"Validation accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="se">\\n</span><span class="s2">"</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/01_code_base.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>And now we run it</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%time</span>',
          '',
          '<span class="err">!</span><span class="n">python</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">01</span><span class="n">_code_base</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Accuracy = 0.2112                                                               ',
          'CPU times: user 2.12 s, sys: 391 ms, total: 2.51 s',
          'Wall time: 3min 36s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We can see that on my computer it took about 3.5 minutes.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h4 id="Code-with-accelerate">Code with accelerate<a class="anchor-link" href="#Code-with-accelerate"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 35" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Now we replace some things</p>
      <ul>
      <li>First we import <code>Accelerator</code> and initialize it.</li>
      </ul>
      <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>
      <span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>
      </pre></div>
      <ul>
      <li>We no longer do the typical</li>
      </ul>
      <div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>
      </pre></div>
      <ul>
      <li>Instead, we let <code>accelerate</code> choose the device by means of</li>
      </ul>
      <div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>
      </pre></div>
      <ul>
      <li>We pass the relevant elements for training through the <code>prepare</code> method and no longer do <code>model.to(device)</code>.</li>
      </ul>
      <div class="highlight"><pre><span></span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">preprare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>
      </pre></div>
      <ul>
      <li><p>We no longer send the data and the model to the GPU with <code>.to(device)</code> since <code>accelerate</code> has taken care of it with the <code>prepare</code> method.</p>
      </li>
      <li><p>Instead of doing the backpropagation with <code>loss.backward()</code> we let <code>accelerate</code> do it with <code>loss.backward()</code>.</p>
      </li>
      </ul>
      <div class="highlight"><pre><span></span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
      </pre></div>
      <ul>
      <li>When calculating the metric in the validation loop, we need to collect the values of all the points, in case we are doing a distributed training.</li>
      </ul>
      <div class="highlight"><pre><span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
      </pre></div>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/02_accelerate_base_code.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">from</span> <span class="nn">fastprogress.fastprogress</span> <span class="kn">import</span> <span class="n">master_bar</span><span class="p">,</span> <span class="n">progress_bar</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">64</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="n">master_progress_bar</span> <span class="o">=</span> <span class="n">master_bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">))</span>',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">master_progress_bar</span><span class="p">:</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '        <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">\'loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s1">\'</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"End of training epoch </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">, outputs[\'logits\'].shape: </span><span class="si">{</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, labels.shape: </span><span class="si">{</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"End of validation epoch </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">, outputs[\'logits\'].shape: </span><span class="si">{</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, labels.shape: </span><span class="si">{</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '    ',
          '    <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">main_bar</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"Validation accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="se">\\n</span><span class="s2">"</span>',
          '',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/02_accelerate_base_code.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>If you notice I have added these two lines <code>print(f "End of training epoch {opening_brace}i{closing_brace}, outputs['logits'].shape: {opening_brace}outputs['logits'].shape{closing_brace}, labels.shape: {opening_brace}labels.shape{closing_brace}")</code> and the line <code>print(f "End of validation epoch {opening_brace}i{closing_brace}, outputs['logits'].shape: {opening_brace}outputs['logits'].shape{closing_brace}, labels.shape: {opening_brace}labels.shape{closing_brace}")</code>, I added them on purpose because they will reveal something very important</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Now we execute it, to execute the <code>accelerate</code> scripts it is done with the command <code>accelerate launch</code>.</p>
      <div class="highlight"><pre><span></span>accelerate<span class="w"> </span>launch<span class="w"> </span>script.py
      </pre></div>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%time</span>',
          '',
          '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">02</span><span class="n">_accelerate_base_code</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'End of training epoch 0, outputs[\'logits\'].shape: torch.Size([64, 20]), labels.shape: torch.Size([64])',
          'End of training epoch 0, outputs[\'logits\'].shape: torch.Size([64, 20]), labels.shape: torch.Size([64])',
          'End of validation epoch 0, outputs[\'logits\'].shape: torch.Size([64, 20]), labels.shape: torch.Size([8])',
          'Accuracy = 0.206',
          'End of validation epoch 0, outputs[\'logits\'].shape: torch.Size([64, 20]), labels.shape: torch.Size([8])',
          'Accuracy = 0.206',
          'CPU times: user 1.6 s, sys: 272 ms, total: 1.88 s',
          'Wall time: 2min 37s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We see that before it took about 3 and a half minutes and now it takes about 2 and a half minutes. Quite an improvement. Also if we look at the <code>print</code>s we can see that they have been printed twice.</p>
      <p>And how can this be? Because <code>accelerate</code> has parallelized the training on the two GPUs I have, so it has been much faster.</p>
      <p>Also, when I ran the first script, that is, when I did not use <code>accelerate</code>, the GPU was almost full, while when I ran the second one, that is, the one using <code>accelerate</code>, the two GPUs were very little used, so we can increase the batch size to try to fill both of them, let's go for it!</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/03_accelerate_base_code_more_bs.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">from</span> <span class="nn">fastprogress.fastprogress</span> <span class="kn">import</span> <span class="n">master_bar</span><span class="p">,</span> <span class="n">progress_bar</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="n">master_progress_bar</span> <span class="o">=</span> <span class="n">master_bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">))</span>',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">master_progress_bar</span><span class="p">:</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '        <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">\'loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s1">\'</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '    ',
          '    <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">main_bar</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"Validation accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="se">\\n</span><span class="s2">"</span>',
          '',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/03_accelerate_base_code_more_bs.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>I have removed the extra prints, because we have already seen that the code is running on both GPUs, and I have increased the batch size from 64 to 128.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%time</span>',
          '',
          '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">03</span><span class="n">_accelerate_base_code_more_bs</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Accuracy = 0.1052                                                               ',
          'Accuracy = 0.1052',
          'CPU times: user 1.41 s, sys: 180 ms, total: 1.59 s',
          'Wall time: 2min 22s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Increasing the batch size has reduced the execution time by a few seconds.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Process-execution">Process execution<a class="anchor-link" href="#Process-execution"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 36" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <h4 id="Execution-of-code-in-a-single-process">Execution of code in a single process<a class="anchor-link" href="#Execution-of-code-in-a-single-process"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 37" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Before we have seen that the <code>print</code>s were printed twice, this is because <code>accelerate</code> creates as many processes as devices where the code is executed, in my case it creates two processes because I have two GPUs.</p>
      <p>However, not all code should be executed in all processes, for example, the <code>print</code>s slow down the code too much to execute it several times, if checkpoints are saved, they would be saved twice, etc.</p>
      <p>In order to execute part of a code in a single process you have to encapsulate it in a function and decorate it with <code>accelerator.on_local_main_process</code>, for example in the following code you will see that I created the following function</p>
      <div class="highlight"><pre><span></span><span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>
      <span class="k">def</span> <span class="nf">print_something</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>
          <span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>
      </pre></div>
      <p>Another option is to put the code inside an <code>if accelerator.is_local_main_process</code> as in the following code</p>
      <div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">:</span>
          <span class="nb">print</span><span class="p">(</span><span class="s2">"Something"</span><span class="p">)</span>
      </pre></div>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/04_accelerate_base_code_some_code_in_one_process.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">from</span> <span class="nn">fastprogress.fastprogress</span> <span class="kn">import</span> <span class="n">master_bar</span><span class="p">,</span> <span class="n">progress_bar</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>',
          '<span class="k">def</span> <span class="nf">print_something</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="n">master_progress_bar</span> <span class="o">=</span> <span class="n">master_bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">))</span>',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">master_progress_bar</span><span class="p">:</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '        <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">\'loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s1">\'</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '    ',
          '    <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">main_bar</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"Validation accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="se">\\n</span><span class="s2">"</span>',
          '',
          '<span class="c1"># print(f"Accuracy = {accuracy[\'accuracy\']}")</span>',
          '<span class="n">print_something</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">:</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/04_accelerate_base_code_some_code_in_one_process.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Let's run it and see</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%time</span>',
          '',
          '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">04</span><span class="n">_accelerate_base_code_some_code_in_one_process</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Accuracy = 0.2098                                                               ',
          'End of script with 0.2098 accuracy',
          'CPU times: user 1.38 s, sys: 197 ms, total: 1.58 s',
          'Wall time: 2min 22s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Now the print has only been printed once</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>However, although you don't see much, progress bars are executed in each process.</p>
      <p>I have not found a way to avoid this with <code>fastprogress</code> progress bars, but with <code>tqdm</code> progress bars, so I will replace <code>fastprogress</code> progress bars with <code>tqdm</code> progress bars and to make them run in a single process add the argument <code>disable=not accelerator.is_local_main_process</code>.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/05_accelerate_base_code_some_code_in_one_process.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">import</span> <span class="nn">tqdm</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>',
          '<span class="k">def</span> <span class="nf">print_something</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="c1"># progress_bar_train = progress_bar(dataloader["train"], parent=master_progress_bar)</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '        <span class="c1"># master_progress_bar.child.comment = f\'loss: {loss}\'</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="c1"># progress_bar_validation = progress_bar(dataloader["validation"], parent=master_progress_bar)</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '    ',
          '<span class="c1"># print(f"Accuracy = {accuracy[\'accuracy\']}")</span>',
          '<span class="n">print_something</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">:</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/05_accelerate_base_code_some_code_in_one_process.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%time</span>',
          '',
          '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">05</span><span class="n">_accelerate_base_code_some_code_in_one_process</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [02:01&lt;00:00,  1.45it/s]',
          '100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:06&lt;00:00,  3.30it/s]',
          'Accuracy = 0.2166',
          'End of script with 0.2166 accuracy',
          'CPU times: user 1.33 s, sys: 195 ms, total: 1.52 s',
          'Wall time: 2min 22s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We have shown an example of how to print in a single process, and this has been a way to execute processes in a single process. But if you just want to print in a single process you can use the <code>print</code> method of <code>accelerate</code>. Let's see the same example of before with this method</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/06_accelerate_base_code_print_one_process.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">import</span> <span class="nn">tqdm</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="c1"># progress_bar_train = progress_bar(dataloader["train"], parent=master_progress_bar)</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '        <span class="c1"># master_progress_bar.child.comment = f\'loss: {loss}\'</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="c1"># progress_bar_validation = progress_bar(dataloader["validation"], parent=master_progress_bar)</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '    ',
          '<span class="c1"># print(f"Accuracy = {accuracy[\'accuracy\']}")</span>',
          '<span class="n">accelerator</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">:</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Writing accelerate_scripts/06_accelerate_base_code_print_one_process.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We run it</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%time</span>',
          '',
          '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">06</span><span class="n">_accelerate_base_code_print_one_process</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45000/45000 [00:02&lt;00:00, 15433.52 examples/s]',
          'Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:00&lt;00:00, 11406.61 examples/s]',
          'Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45000/45000 [00:02&lt;00:00, 15036.87 examples/s]',
          'Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50000/50000 [00:03&lt;00:00, 14932.76 examples/s]',
          'Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50000/50000 [00:03&lt;00:00, 14956.60 examples/s]',
          '100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [02:00&lt;00:00,  1.46it/s]',
          '100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05&lt;00:00,  3.33it/s]',
          'Accuracy = 0.2134',
          'End of script with 0.2134 accuracy',
          'CPU times: user 1.4 s, sys: 189 ms, total: 1.59 s',
          'Wall time: 2min 27s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h4 id="Code-execution-in-all-processes">Code execution in all processes<a class="anchor-link" href="#Code-execution-in-all-processes"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 38" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>However there is code that must be executed in all processes, for example if we upload the checkpoints to the hub, so here we have two options, encapsulate the code in a function and decorate it with <code>accelerator.on_main_process</code>.</p>
      <div class="highlight"><pre><span></span><span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_main_process</span>
      <span class="k">def</span> <span class="nf">do_my_thing</span><span class="p">():</span>
          <span class="s2">"Something done once per server"</span>
          <span class="n">do_thing_once</span><span class="p">()</span>
      </pre></div>
      <p>or put the code inside an <code>if accelerator.is_main_process</code>.</p>
      <div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">:</span>
          <span class="n">repo</span><span class="o">.</span><span class="n">push_to_hub</span><span class="p">()</span>
      </pre></div>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>As we are training just to show the <code>accelerate</code> library and the model we are training is not good, there is no sense now to upload the checkpoints to the hub, so I am going to make an example with <code>print</code>s</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/07_accelerate_base_code_some_code_in_all_process.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">import</span> <span class="nn">tqdm</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>',
          '<span class="k">def</span> <span class="nf">print_in_one_process</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_main_process</span>',
          '<span class="k">def</span> <span class="nf">print_in_all_processes</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '    ',
          '<span class="n">print_in_one_process</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">:</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">print_in_all_processes</span><span class="p">(</span><span class="sa">f</span><span class="s2">"All process: Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">:</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"All process: End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/06_accelerate_base_code_some_code_in_all_process.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We run it to see</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%time</span>',
          '',
          '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">07</span><span class="n">_accelerate_base_code_some_code_in_all_process</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45000/45000 [00:03&lt;00:00, 14518.44 examples/s]',
          'Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45000/45000 [00:03&lt;00:00, 14368.77 examples/s]',
          'Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:00&lt;00:00, 16466.33 examples/s]',
          'Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:00&lt;00:00, 14806.14 examples/s]',
          'Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50000/50000 [00:03&lt;00:00, 14253.33 examples/s]',
          'Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50000/50000 [00:03&lt;00:00, 14337.07 examples/s]',
          '100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [02:00&lt;00:00,  1.46it/s]',
          '100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05&lt;00:00,  3.34it/s]',
          'Accuracy = 0.2092',
          'End of script with 0.2092 accuracy',
          'All process: Accuracy = 0.2092',
          'All process: End of script with 0.2092 accuracy',
          'CPU times: user 1.42 s, sys: 216 ms, total: 1.64 s',
          'Wall time: 2min 27s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h4 id="Execution-of-code-in-the-process-X">Execution of code in the process X<a class="anchor-link" href="#Execution-of-code-in-the-process-X"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 39" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Finally we can specify in which process we want to execute code, for this we must create a function and decorate it with <code>@accelerator.on_process(process_index=0)</code>.</p>
      <div class="highlight"><pre><span></span><span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_process</span><span class="p">(</span><span class="n">process_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
      <span class="k">def</span> <span class="nf">do_my_thing</span><span class="p">():</span>
          <span class="s2">"Something done on process index 0"</span>
          <span class="n">do_thing_on_index_zero</span><span class="p">()</span>
      </pre></div>
      <p>or decorate it with <code>@accelerator.on_local_process(local_process_idx=0)</code>.</p>
      <div class="highlight"><pre><span></span><span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_process</span><span class="p">(</span><span class="n">local_process_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
      <span class="k">def</span> <span class="nf">do_my_thing</span><span class="p">():</span>
          <span class="s2">"Something done on process index 0 on each server"</span><span class="o">.</span>
          <span class="n">do_thing_on_index_zero_on_each_server</span><span class="p">()</span>
      </pre></div>
      <p>Here I have put the process 0, but you can put any number</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/08_accelerate_base_code_some_code_in_some_process.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">import</span> <span class="nn">tqdm</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>',
          '<span class="k">def</span> <span class="nf">print_in_one_process</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_main_process</span>',
          '<span class="k">def</span> <span class="nf">print_in_all_processes</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_process</span><span class="p">(</span><span class="n">process_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>',
          '<span class="k">def</span> <span class="nf">print_in_process_0</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="s2">"Process 0: "</span> <span class="o">+</span> <span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_process</span><span class="p">(</span><span class="n">local_process_index</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
          '<span class="k">def</span> <span class="nf">print_in_process_1</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="s2">"Process 1: "</span> <span class="o">+</span> <span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '    ',
          '<span class="n">print_in_one_process</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">:</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">print_in_all_processes</span><span class="p">(</span><span class="sa">f</span><span class="s2">"All process: Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">:</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"All process: End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">print_in_process_0</span><span class="p">(</span><span class="s2">"End of process 0"</span><span class="p">)</span>',
          '<span class="n">print_in_process_1</span><span class="p">(</span><span class="s2">"End of process 1"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/07_accelerate_base_code_some_code_in_some_process.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We run it</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%time</span>',
          '',
          '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">08</span><span class="n">_accelerate_base_code_some_code_in_some_process</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:00&lt;00:00, 15735.58 examples/s]',
          'Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50000/50000 [00:03&lt;00:00, 14906.20 examples/s]',
          '100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [02:02&lt;00:00,  1.44it/s]',
          '100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:06&lt;00:00,  3.27it/s]',
          'Process 1: End of process 1',
          'Accuracy = 0.2128',
          'End of script with 0.2128 accuracy',
          'All process: Accuracy = 0.2128',
          'All process: End of script with 0.2128 accuracy',
          'Process 0: End of process 0',
          'CPU times: user 1.42 s, sys: 295 ms, total: 1.71 s',
          'Wall time: 2min 37s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h4 id="Synchronize-processes">Synchronize processes<a class="anchor-link" href="#Synchronize-processes"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 40" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>If we have code that must be executed in all processes, it is interesting to wait for it to finish in all processes before doing another task, so for this we use <code>accelerator.wait_for_everyone()</code>.</p>
      <p>To see this we are going to put a delay in one of the print functions in a process</p>
      <p>I've also put a break in the training loop so that he doesn't spend too much time training, which is not what we're interested in right now.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/09_accelerate_base_code_sync_all_process.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">import</span> <span class="nn">tqdm</span>',
          '<span class="kn">import</span> <span class="nn">time</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>',
          '<span class="k">def</span> <span class="nf">print_in_one_process</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_main_process</span>',
          '<span class="k">def</span> <span class="nf">print_in_all_processes</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_process</span><span class="p">(</span><span class="n">process_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>',
          '<span class="k">def</span> <span class="nf">print_in_process_0</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="s2">"Process 0: "</span> <span class="o">+</span> <span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_process</span><span class="p">(</span><span class="n">local_process_index</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
          '<span class="k">def</span> <span class="nf">print_in_process_1</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="s2">"Process 1: "</span> <span class="o">+</span> <span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '        <span class="k">break</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '    ',
          '<span class="n">print_in_one_process</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">:</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">print_in_all_processes</span><span class="p">(</span><span class="sa">f</span><span class="s2">"All process: Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">:</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"All process: End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">print_in_one_process</span><span class="p">(</span><span class="s2">"Printing with delay in process 0"</span><span class="p">)</span>',
          '<span class="n">print_in_process_0</span><span class="p">(</span><span class="s2">"End of process 0"</span><span class="p">)</span>',
          '<span class="n">print_in_process_1</span><span class="p">(</span><span class="s2">"End of process 1"</span><span class="p">)</span>',
          '<span class="n">accelerator</span><span class="o">.</span><span class="n">wait_for_everyone</span><span class="p">()</span>',
          '',
          '<span class="n">print_in_one_process</span><span class="p">(</span><span class="s2">"End of script"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/08_accelerate_base_code_sync_all_process.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We run it</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">!</span>accelerate<span class="w"> </span>launch<span class="w"> </span>accelerate_scripts/09_accelerate_base_code_sync_all_process.py',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:00&lt;00:00, 14218.23 examples/s]',
          'Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:00&lt;00:00, 14666.25 examples/s]',
          '  0%|                                                   | 0/176 [00:00&lt;?, ?it/s]',
          '100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05&lt;00:00,  3.58it/s]',
          'Process 1: End of process 1',
          'Accuracy = 0.212',
          'End of script with 0.212 accuracy',
          'All process: Accuracy = 0.212',
          'All process: End of script with 0.212 accuracy',
          'Printing with delay in process 0',
          'Process 0: End of process 0',
          'End of script',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>As you can see first we have printed <code>Process 1: End of process 1</code> and then the rest, this is because the rest of the prints are made either in process 0 or in all processes, so until the 2 seconds delay we have set is not finished the rest of the code is not executed.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Save-and-load-the-state-dict">Save and load the state dict<a class="anchor-link" href="#Save-and-load-the-state-dict"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 41" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>When we train, we sometimes save the state so that we can continue at a later time.</p>
      <p>To save the state we will have to use the <code>save_state()</code> and <code>load_state()</code> methods.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/10_accelerate_save_and_load_checkpoints.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">import</span> <span class="nn">tqdm</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>',
          '<span class="k">def</span> <span class="nf">print_something</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '',
          '    <span class="c1"># Guardamos los pesos</span>',
          '    <span class="n">accelerator</span><span class="o">.</span><span class="n">save_state</span><span class="p">(</span><span class="s2">"accelerate_scripts/checkpoints"</span><span class="p">)</span>',
          '',
          '<span class="n">print_something</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '<span class="c1"># Cargamos los pesos</span>',
          '<span class="n">accelerator</span><span class="o">.</span><span class="n">load_state</span><span class="p">(</span><span class="s2">"accelerate_scripts/checkpoints"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/09_accelerate_save_and_load_checkpoints.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We run it</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">!</span>accelerate<span class="w"> </span>launch<span class="w"> </span>accelerate_scripts/10_accelerate_save_and_load_checkpoints.py',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [01:58&lt;00:00,  1.48it/s]',
          '100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05&lt;00:00,  3.40it/s]',
          'Accuracy = 0.2142',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Save-the-model">Save the model<a class="anchor-link" href="#Save-the-model"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 42" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>When the <code>prepare</code> method was used, the model was wrapped in order to save it to the necessary devices. So when saving it we have to use the <code>save_model</code> method which first unwraps it and then saves it. Also if we use the <code>safe_serialization=True</code> parameter the model will be saved as a <code>safe tensor</code>.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/11_accelerate_save_model.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">import</span> <span class="nn">tqdm</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>',
          '<span class="k">def</span> <span class="nf">print_something</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '',
          '    <span class="c1"># Guardamos el modelo</span>',
          '    <span class="n">accelerator</span><span class="o">.</span><span class="n">wait_for_everyone</span><span class="p">()</span>',
          '    <span class="n">accelerator</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">"accelerate_scripts/model"</span><span class="p">,</span> <span class="n">safe_serialization</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">print_something</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Writing accelerate_scripts/11_accelerate_save_model.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We run it</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">!</span>accelerate<span class="w"> </span>launch<span class="w"> </span>accelerate_scripts/11_accelerate_save_model.py',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [01:58&lt;00:00,  1.48it/s]',
          '100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05&lt;00:00,  3.35it/s]',
          'Accuracy = 0.214',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Save-the-pretrained-model">Save the <code>pretrained</code> model<a class="anchor-link" href="#Save-the-pretrained-model"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 43" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>In models that use the <code>transformers</code> library we must save the model with the <code>save_pretrained</code> method to be able to load it with the <code>from_pretrained</code> method. Before saving it we must unwrap it with the <code>unwrap_model</code> method.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/12_accelerate_save_pretrained.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">import</span> <span class="nn">tqdm</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>',
          '<span class="k">def</span> <span class="nf">print_something</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '',
          '    <span class="c1"># Guardamos el modelo pretrained</span>',
          '    <span class="n">unwrapped_model</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">unwrap_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>',
          '    <span class="n">unwrapped_model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span>',
          '        <span class="s2">"accelerate_scripts/model_pretrained"</span><span class="p">,</span>',
          '        <span class="n">is_main_process</span><span class="o">=</span><span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">,</span>',
          '        <span class="n">save_function</span><span class="o">=</span><span class="n">accelerator</span><span class="o">.</span><span class="n">save</span><span class="p">,</span>',
          '    <span class="p">)</span>',
          '',
          '<span class="n">print_something</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Writing accelerate_scripts/11_accelerate_save_pretrained.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We run it</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">!</span>accelerate<span class="w"> </span>launch<span class="w"> </span>accelerate_scripts/12_accelerate_save_pretrained.py',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45000/45000 [00:02&lt;00:00, 15152.47 examples/s]',
          'Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45000/45000 [00:02&lt;00:00, 15119.13 examples/s]',
          'Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:00&lt;00:00, 12724.70 examples/s]',
          'Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:00&lt;00:00, 12397.49 examples/s]',
          'Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50000/50000 [00:03&lt;00:00, 15247.21 examples/s]',
          'Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50000/50000 [00:03&lt;00:00, 15138.03 examples/s]',
          '100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [01:59&lt;00:00,  1.48it/s]',
          '100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05&lt;00:00,  3.37it/s]',
          'Accuracy = 0.21',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Now we could load it</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModel</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"accelerate_scripts/model_pretrained"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Some weights of RobertaModel were not initialized from the model checkpoint at accelerate_scripts/model_pretrained and are newly initialized: [\'roberta.pooler.dense.bias\', \'roberta.pooler.dense.weight\']',
          'You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Training-on-notebooks">Training on notebooks<a class="anchor-link" href="#Training-on-notebooks"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 44" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>So far we have seen how to run scripts, but if you want to run the code on a notebook, we can write the same code as before, but encapsulated in a function</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>First we import the libraries</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
      '      <span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
      '      <span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
      '      <span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
      '      <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
      '      <span class="kn">import</span> <span class="nn">evaluate</span>',
      '      <span class="kn">import</span> <span class="nn">tqdm</span>',
      '      <span class="kn">import</span> <span class="nn">time</span>',
      '      <span class="c1"># from accelerate import Accelerator</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>














      
      <section class="section-block-markdown-cell">
      <p>Now we create the function</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
      '      <span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
      '      <span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
      '      <span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
      '      <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
      '      <span class="kn">import</span> <span class="nn">evaluate</span>',
      '      <span class="kn">import</span> <span class="nn">tqdm</span>',
      '      <span class="kn">import</span> <span class="nn">time</span>',
      '      <span class="c1"># from accelerate import Accelerator</span>',
      '<span></span><span class="k">def</span> <span class="nf">train_code</span><span class="p">(</span><span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span><span class="p">):</span>',
      '          <span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
      '          <span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
      '      ',
      '          <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
      '          <span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
      '          <span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
      '      ',
      '          <span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
      '          <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '      ',
      '          <span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
      '              <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
      '          <span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
      '              <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
      '              <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
      '              <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
      '          <span class="p">}</span>',
      '          <span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
      '          <span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
      '          <span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
      '      ',
      '          <span class="n">BS</span> <span class="o">=</span> <span class="n">batch_size</span>',
      '          <span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
      '              <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '              <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '              <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '          <span class="p">}</span>',
      '      ',
      '          <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '          <span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
      '      ',
      '          <span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
      '          <span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
      '          <span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
      '      ',
      '          <span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
      '          <span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
      '          <span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
      '      ',
      '          <span class="c1"># model.to(device)</span>',
      '          <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
      '      ',
      '          <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
      '              <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '              <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
      '              <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
      '                  <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
      '      ',
      '                  <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '                  <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '                  <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '      ',
      '                  <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '                  <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
      '      ',
      '                  <span class="c1"># loss.backward()</span>',
      '                  <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
      '                  <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
      '      ',
      '              <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
      '              <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
      '              <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
      '                  <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '                  <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '                  <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '      ',
      '                  <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
      '                      <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '                  <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
      '                  <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
      '                  <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
      '                  <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
      '      ',
      '                  <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
      '              <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
      '              ',
      '          <span class="n">accelerator</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>



















































































      
      <section class="section-block-markdown-cell">
      <p>In order to run the training on the notebook we use the <code>notebook_launcher</code> function, to which we pass the function we want to run, the arguments of that function and the number of GPUs on which we are going to train with the variable <code>num_processes</code>.</p>
      </section>
      
      <section class="section-block-code-cell-">
      <div class="input-code">
      <div class="highlight hl-ipython3">
<pre><span></span><span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">notebook_launcher</span>
      
      <span class="n">args</span> <span class="o">=</span> <span class="p">(</span><span class="mi">128</span><span class="p">,)</span>
      <span class="n">notebook_launcher</span><span class="p">(</span><span class="n">train_code</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">num_processes</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
      </pre></div>
      </div>
      <div class="output-wrapper">
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-subarea-output-stream-output-stdout-output-text">
      <pre>Launching training on 2 GPUs.
      </pre>
      </div>
      </div>
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-subarea-output-stream-output-stderr-output-text">
      <pre>100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [02:01&lt;00:00,  1.45it/s]
      100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:06&lt;00:00,  3.31it/s]
      </pre>
      </div>
      </div>
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-subarea-output-stream-output-stdout-output-text">
      <pre>Accuracy = 0.2112
      </pre>
      </div>
      </div>
      </div>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Training-in-FP16">Training in FP16<a class="anchor-link" href="#Training-in-FP16"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 45" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>When we first set up <code>accelerate</code> it asked us <code>Do you wish to use FP16 or BF16 (mixed precision)?</code> and we said no, so now we are going to say yes, we want to use FP16.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>So far we have trained in FP32, which means that each weight of the model is a 32-bit floating point number, and now we are going to use a 16-bit floating point number, that is, the model will occupy less space. So two things will happen, we will be able to use a larger batch size and it will also be faster.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>First we re-launch <code>accelerate config</code> and we will tell it that we want FP16</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">import</span> <span class="nn">tqdm</span>',
          '<span class="kn">import</span> <span class="nn">time</span>',
          '<span class="c1"># from accelerate import Accelerator</span>',
          '</span><span class="k">def</span> <span class="nf">train_code</span><span class="p">(</span><span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span><span class="p">):</span>',
          '    <span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '    <span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '    <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '    <span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '    <span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '    <span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '    <span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '        <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '    <span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '        <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '        <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '        <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="p">}</span>',
          '    <span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '    <span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '    <span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '    <span class="n">BS</span> <span class="o">=</span> <span class="n">batch_size</span>',
          '    <span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '        <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '        <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '        <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="p">}</span>',
          '',
          '    <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '    <span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '    <span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '    <span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '    <span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '    <span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '    <span class="c1"># model.to(device)</span>',
          '    <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
          '        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '        <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '            <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '            <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '',
          '            <span class="c1"># loss.backward()</span>',
          '            <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '        <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '            <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '            <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '                <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '            <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '            <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '            <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '            <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '            <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '        ',
          '    <span class="n">accelerator</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '</span><span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">notebook_launcher</span>',
          '',
          '<span class="n">args</span> <span class="o">=</span> <span class="p">(</span><span class="mi">128</span><span class="p">,)</span>',
          '<span class="n">notebook_launcher</span><span class="p">(</span><span class="n">train_code</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">num_processes</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>',
          '</span><span class="o">!</span>accelerate<span class="w"> </span>config',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Launching training on 2 GPUs.',
          '--------------------------------------------------------------------------------',
          'In which compute environment are you running?',
          'This machine',
          '--------------------------------------------------------------------------------',
          'multi-GPU',
          'How many different machines will you use (use more than 1 for multi-node training)? [1]: 1',
          'Should distributed operations be checked while running for errors? This can avoid timeout issues but will be slower. [yes/NO]: no',
          'Do you wish to optimize your script with torch dynamo?[yes/NO]:no',
          'Do you want to use DeepSpeed? [yes/NO]: no',
          'Do you want to use FullyShardedDataParallel? [yes/NO]: no',
          'Do you want to use Megatron-LM ? [yes/NO]: no',
          'How many GPU(s) should be used for distributed training? [1]:2',
          'What GPU(s) (by id) should be used for training on this machine as a comma-seperated list? [all]:0,1',
          '--------------------------------------------------------------------------------',
          'Do you wish to use FP16 or BF16 (mixed precision)?',
          'fp16',
          'accelerate configuration saved at ~/.cache/huggingface/accelerate/default_config.yaml',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Now we create a script to train, with the same batch size as before, to see if it takes less time to train</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/13_accelerate_base_code_fp16_bs128.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">import</span> <span class="nn">tqdm</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '    ',
          '<span class="n">accelerator</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/12_accelerate_base_code_fp16_bs128.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We run it and see how long it takes</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%time</span>',
          '',
          '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">13</span><span class="n">_accelerate_base_code_fp16_bs128</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:00&lt;00:00, 14983.76 examples/s]',
          'Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50000/50000 [00:03&lt;00:00, 14315.47 examples/s]',
          '100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [01:01&lt;00:00,  2.88it/s]',
          '100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:02&lt;00:00,  6.84it/s]',
          'Accuracy = 0.2094',
          'CPU times: user 812 ms, sys: 163 ms, total: 976 ms',
          'Wall time: 1min 27s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>When we ran this training in FP32 it took about 2 minutes and a half, and now it takes about 1 minute and a half. Let's see if now instead of training with a batch size of 128, we do it with a batch size of 256.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/14_accelerate_base_code_fp16_bs256.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">import</span> <span class="nn">tqdm</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">256</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '    ',
          '<span class="n">accelerator</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/13_accelerate_base_code_fp16_bs256.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We run it</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%time</span>',
          '',
          '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">14</span><span class="n">_accelerate_base_code_fp16_bs256</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:00&lt;00:00, 15390.30 examples/s]',
          'Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:00&lt;00:00, 14990.92 examples/s]',
          '100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:54&lt;00:00,  1.62it/s]',
          '100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02&lt;00:00,  3.45it/s]',
          'Accuracy = 0.2236',
          'CPU times: user 670 ms, sys: 91.6 ms, total: 761 ms',
          'Wall time: 1min 12s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>It has dropped only about 15 seconds</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="BF16-Training">BF16 Training<a class="anchor-link" href="#BF16-Training"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 46" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Before we have trained in FP16 and now we are going to train in BF16, what is the difference?</p>
      <p><img decoding="async" onerror="this.parentNode.removeChild(this)" alt="FP32_FP16_BF16" src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/FP32_FP16_BF16.webp" width="894" height="253"/></p>
      <p>As we can see in the picture, while FP16 compared to FP32 has fewer bits in the mantissa and exponent, which makes its range much smaller, BF16 compared to FP32 has the same number of bits in the exponent but fewer in the mantissa, which makes BF16 have the same range of numbers as FP32, but it is less accurate.</p>
      <p>This is beneficial because in FP16 some calculations could give very high numbers, which in FP16 format could not be represented. In addition there are certain HW devices that are optimized for this format.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>As before, we execute <code>accelerate config</code> and indicate that we want BF16.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">!</span>accelerate<span class="w"> </span>config',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '--------------------------------------------------------------------------------',
          'In which compute environment are you running?',
          'This machine',
          '--------------------------------------------------------------------------------',
          'multi-GPU',
          'How many different machines will you use (use more than 1 for multi-node training)? [1]: 1',
          'Should distributed operations be checked while running for errors? This can avoid timeout issues but will be slower. [yes/NO]: no',
          'Do you wish to optimize your script with torch dynamo?[yes/NO]:no',
          'Do you want to use DeepSpeed? [yes/NO]: no',
          'Do you want to use FullyShardedDataParallel? [yes/NO]: no',
          'Do you want to use Megatron-LM ? [yes/NO]: no',
          'How many GPU(s) should be used for distributed training? [1]:2',
          'What GPU(s) (by id) should be used for training on this machine as a comma-seperated list? [all]:0,1',
          '--------------------------------------------------------------------------------',
          'Do you wish to use FP16 or BF16 (mixed precision)?',
          'bf16',
          'accelerate configuration saved at ~/.cache/huggingface/accelerate/default_config.yaml',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Now we run the last script we created, i.e. with a batch size of 256</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%time</span>',
          '',
          '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">14</span><span class="n">_accelerate_base_code_fp16_bs256</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50000/50000 [00:03&lt;00:00, 14814.95 examples/s]',
          'Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50000/50000 [00:03&lt;00:00, 14506.83 examples/s]',
          '100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:51&lt;00:00,  1.70it/s]',
          '100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:03&lt;00:00,  3.21it/s]',
          'Accuracy = 0.2112',
          'CPU times: user 688 ms, sys: 144 ms, total: 832 ms',
          'Wall time: 1min 17s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>It took a similar time to what it took before, which is normal, since we have trained a model with 16-bit weights, just like before.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Training-in-FP8">Training in FP8<a class="anchor-link" href="#Training-in-FP8"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 47" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Now we are going to train in FP8 format, which as its name suggests, is a floating point format, where each weight has 8 bits, so we run <code>accelerate config</code> to tell it that we want FP8</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">!</span>accelerate<span class="w"> </span>config',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '--------------------------------------------------------------------------------',
          'In which compute environment are you running?',
          'This machine',
          '--------------------------------------------------------------------------------',
          'multi-GPU',
          'How many different machines will you use (use more than 1 for multi-node training)? [1]: 1',
          'Should distributed operations be checked while running for errors? This can avoid timeout issues but will be slower. [yes/NO]: no',
          'Do you wish to optimize your script with torch dynamo?[yes/NO]:no',
          'Do you want to use DeepSpeed? [yes/NO]: no',
          'Do you want to use FullyShardedDataParallel? [yes/NO]: no',
          'Do you want to use Megatron-LM ? [yes/NO]: no',
          'How many GPU(s) should be used for distributed training? [1]:2',
          'What GPU(s) (by id) should be used for training on this machine as a comma-seperated list? [all]:0,1',
          '--------------------------------------------------------------------------------',
          'Do you wish to use FP16 or BF16 (mixed precision)?',
          'fp8',
          'accelerate configuration saved at ~/.cache/huggingface/accelerate/default_config.yaml',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Now we execute the last script, the batch size of 256</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%time</span>',
          '',
          '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">14</span><span class="n">_accelerate_base_code_fp16_bs256</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Traceback (most recent call last):',
          '  File "/home/wallabot/Documentos/web/portafolio/posts/accelerate_scripts/13_accelerate_base_code_fp16_bs256.py", line 12, in &lt;module&gt;',
          '    accelerator = Accelerator()',
          '                  ^^^^^^^^^^^^^',
          '  File "/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/accelerator.py", line 371, in __init__',
          '    self.state = AcceleratorState(',
          '                 ^^^^^^^^^^^^^^^^^',
          '  File "/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/state.py", line 790, in __init__',
          '    raise ValueError(',
          'ValueError: Using `fp8` precision requires `transformer_engine` or `MS-AMP` to be installed.',
          'Traceback (most recent call last):',
          '  File "/home/wallabot/Documentos/web/portafolio/posts/accelerate_scripts/13_accelerate_base_code_fp16_bs256.py", line 12, in &lt;module&gt;',
          '    accelerator = Accelerator()',
          '                  ^^^^^^^^^^^^^',
          '  File "/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/accelerator.py", line 371, in __init__',
          '    self.state = AcceleratorState(',
          '                 ^^^^^^^^^^^^^^^^^',
          '  File "/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/state.py", line 790, in __init__',
          '    raise ValueError(',
          'ValueError: Using `fp8` precision requires `transformer_engine` or `MS-AMP` to be installed.',
          '[2024-05-13 21:40:56,455] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 501480) of binary: /home/wallabot/miniconda3/envs/nlp/bin/python',
          'Traceback (most recent call last):',
          '  File "/home/wallabot/miniconda3/envs/nlp/bin/accelerate", line 8, in &lt;module&gt;',
          '    sys.exit(main())',
          '             ^^^^^^',
          '  File "/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/commands/accelerate_cli.py", line 46, in main',
          '    args.func(args)',
          '  File "/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/commands/launch.py", line 1048, in launch_command',
          '    multi_gpu_launcher(args)',
          '  File "/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/commands/launch.py", line 702, in multi_gpu_launcher',
          '    distrib_run.run(args)',
          '  File "/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/distributed/run.py", line 803, in run',
          '    elastic_launch(',
          '  File "/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 135, in __call__',
          '    return launch_agent(self._config, self._entrypoint, list(args))',
          '           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^',
          '  File "/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent',
          '    raise ChildFailedError(',
          'torch.distributed.elastic.multiprocessing.errors.ChildFailedError: ',
          '============================================================',
          'accelerate_scripts/13_accelerate_base_code_fp16_bs256.py FAILED',
          '------------------------------------------------------------',
          'Failures:',
          '[1]:',
          '  time      : 2024-05-13_21:40:56',
          '  host      : wallabot',
          '  rank      : 1 (local_rank: 1)',
          '  exitcode  : 1 (pid: 501481)',
          '  error_file: &lt;N/A&gt;',
          '  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html',
          '------------------------------------------------------------',
          'Root Cause (first observed failure):',
          '[0]:',
          '  time      : 2024-05-13_21:40:56',
          '  host      : wallabot',
          '  rank      : 0 (local_rank: 0)',
          '  exitcode  : 1 (pid: 501480)',
          '  error_file: &lt;N/A&gt;',
          '  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html',
          '============================================================',
          'CPU times: user 65.1 ms, sys: 14.5 ms, total: 79.6 ms',
          'Wall time: 7.24 s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>As the weights are now 8 bits and occupy half of the memory, we will increase the batch size to 512.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/15_accelerate_base_code_fp8_bs512.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">import</span> <span class="nn">tqdm</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">512</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '    ',
          '<span class="n">accelerator</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Writing accelerate_scripts/15_accelerate_base_code_fp8_bs512.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We run it</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="o">%%time</span>',
      '      ',
      '      <span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">15</span><span class="n">_accelerate_base_code_fp8_bs512</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>








      
      <section class="section-block-markdown-cell">
      <h2 id="Model-inference">Model inference<a class="anchor-link" href="#Model-inference"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 48" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Using-the-Hugging-Face-Ecosystem">Using the Hugging Face Ecosystem<a class="anchor-link" href="#Using-the-Hugging-Face-Ecosystem"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 49" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Let's see how to do large model inference with the <code>transformers</code> library of hugging face.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h4 id="Inference-with-pipeline.">Inference with <code>pipeline</code>.<a class="anchor-link" href="#Inference-with-pipeline."><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 50" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>If we use the Hugging Face ecosystem it is very simple, since everything is produced underneath without us having to do much. In the case of using <code>pipeline</code>, which is the easiest way to do inference with the <code>transformers</code> library, we simply have to tell it the model we want to use and very important, pass <code>device_map="auto"</code>. This will cause <code>accelerate</code> to distribute the model among the different GPUs, CPU RAM or hard disk if necessary.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>There are more possible values for <code>device_map</code>, which we will see later, but for now stay with <code>"auto"</code>.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>We are going to use the <code>Llama3 8B</code> model, which as its name indicates is a model of about 8 billion parameters, as each parameter by default is in FP32 format, which corresponds to 4 bytes (32 bits), that means that if we multiply 8 billion parameters by 4 bytes, we would need a GPU with about 32 GB of VRAM.</p>
      <p>In my case I have 2 GPUs with 24 GB of VRAM, so it would not fit on a single GPU. But thanks to put <code>device_map="auto"</code>, accelerate will distribute the model between the two GPUs and I will be able to make the inference.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%time</span>',
          '',
          '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">15</span><span class="n">_accelerate_base_code_fp8_bs512</span><span class="o">.</span><span class="n">py</span>',
          '</span><span class="o">%%writefile</span> accelerate_scripts/16_inference_with_pipeline.py',
          '',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">pipeline</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"meta-llama/Meta-Llama-3-8B-Instruct"</span>',
          '<span class="n">generator</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">checkpoints</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s2">"auto"</span><span class="p">)</span>',
          '',
          '<span class="n">prompt</span> <span class="o">=</span> <span class="s2">"Conoces accelerate de hugging face?"</span>',
          '<span class="n">output</span> <span class="o">=</span> <span class="n">generator</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/09_inference_with_pipeline.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Now we run it, but since pipeline uses accelerate below, we don't need to run it with <code>accelerate launch script.py</code> but with <code>python script.py</code> will do.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">!</span>python<span class="w"> </span>accelerate_scripts/16_inference_with_pipeline.py',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:09&lt;00:00,  2.27s/it]',
          'Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.',
          'Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.',
          '[{\'generated_text\': \'Conoces accelerate de hugging face? Â¿QuÃ© es el modelo de lenguaje de transformers y cÃ³mo se utiliza en el marco de hugging face? Â¿CÃ³mo puedo utilizar modelos de lenguaje de transformers en mi aplicaciÃ³n? Â¿QuÃ© son los tokenizers y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo crear un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los datasets y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar datasets para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los evaluadores y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los pre-trainados y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los finetuning y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los checkpoints y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los evaluadores y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los pre-trainados y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los finetuning y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los checkpoints y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los evaluadores y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los pre-trainados y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los finetuning y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los checkpoints y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los evaluadores y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los pre-trainados y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los finetuning y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los checkpoints y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los evaluadores y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los pre-trainados y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los finetuning y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los checkpoints y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los evaluadores y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los pre-trainados y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los finetuning y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los checkpoints y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los evaluadores y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los pre-trainados y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los finetuning y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los checkpoints y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los evaluadores y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los pre-trainados y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los finetuning y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los checkpoints y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los evaluadores y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los pre-trainados y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los finetuning y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los checkpoints y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los evaluadores y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los pre-trainados y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los finetuning y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los checkpoints y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los evaluadores y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los pre-trainados y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los finetuning y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los checkpoints y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los evaluadores y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los pre-trainados y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los finetuning y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los checkpoints y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los evaluadores y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los pre-trainados y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los finetuning y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los checkpoints y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los evaluadores y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los pre-trainados y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los finetuning y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los checkpoints y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los evaluadores y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los pre-trainados y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los finetuning y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los checkpoints y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los evaluadores y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los pre-trainados y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los finetuning y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los checkpoints y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los evaluadores y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los pre-trainados y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los finetuning y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los checkpoints y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los evaluadores y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los pre-trainados y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los finetuning y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los checkpoints y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los evaluadores y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los pre-trainados y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los finetuning y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los checkpoints y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los evaluadores y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los pre-trainados y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los finetuning y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los checkpoints y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los evaluadores y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los pre-trainados y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los finetuning y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los checkpoints y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los evaluadores y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los pre-trainados y cÃ³mo se utilizan en el marco de hugging face? Â¿CÃ³mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? Â¿QuÃ© son los finetuning\'}]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>As you can see, it did not answer, but kept asking questions. This is because Llama3 is a language model that predicts the next token, so with the prompt that I have passed it, it has considered that the next best tokens are those that correspond to more questions. Which makes sense, because there are times when people have doubts about a topic and generates many questions, so to answer the question we have to condition it a little bit</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/17_inference_with_pipeline_condition.py',
          '',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">pipeline</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"meta-llama/Meta-Llama-3-8B-Instruct"</span>',
          '<span class="n">generator</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">checkpoints</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s2">"auto"</span><span class="p">)</span>',
          '',
          '<span class="n">prompt</span> <span class="o">=</span> <span class="s2">"Conoces accelerate de hugging face?"</span>',
          '<span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>',
          '    <span class="p">{</span>',
          '        <span class="s2">"role"</span><span class="p">:</span> <span class="s2">"system"</span><span class="p">,</span>',
          '        <span class="s2">"content"</span><span class="p">:</span> <span class="s2">"Eres un chatbot amigable que siempre intenta solucionar las dudas"</span><span class="p">,</span>',
          '    <span class="p">},</span>',
          '    <span class="p">{</span><span class="s2">"role"</span><span class="p">:</span> <span class="s2">"user"</span><span class="p">,</span> <span class="s2">"content"</span><span class="p">:</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">prompt</span><span class="si">}</span><span class="s2">"</span><span class="p">},</span>',
          '<span class="p">]</span>',
          '<span class="n">output</span> <span class="o">=</span> <span class="n">generator</span><span class="p">(</span><span class="n">messages</span><span class="p">)</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">\'generated_text\'</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/10_inference_with_pipeline_condition.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>As you can see, a message has been generated with roles, conditioning the model and with the following prompt</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">!</span>python<span class="w"> </span>accelerate_scripts/17_inference_with_pipeline_condition.py',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:09&lt;00:00,  2.41s/it]',
          'Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.',
          'Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.',
          '{\'role\': \'assistant\', \'content\': \'Â¡Hola!\n\nSÃ­, conozco Accelerate de Hugging Face. Accelerate es una biblioteca de Python desarrollada por Hugging Face que se enfoca en simplificar y acelerar el entrenamiento y la evaluaciÃ³n de modelos de lenguaje en diferentes dispositivos y entornos.\n\nCon Accelerate, puedes entrenar modelos de lenguaje en diferentes plataformas y dispositivos, como GPUs, TPUs, CPUs y servidores, sin necesidad de cambiar el cÃ³digo de tu modelo. Esto te permite aprovechar al mÃ¡ximo la potencia de cÃ¡lculo de tus dispositivos y reducir el tiempo de entrenamiento.\n\nAccelerate tambiÃ©n ofrece varias caracterÃ­sticas adicionales, como:\n\n* Soporte para diferentes frameworks de machine learning, como TensorFlow, PyTorch y JAX.\n* IntegraciÃ³n con diferentes sistemas de almacenamiento y procesamiento de datos, como Amazon S3 y Google Cloud Storage.\n* Soporte para diferentes protocolos de comunicaciÃ³n, como HTTP y gRPC.\n* Herramientas para monitorear y depurar tus modelos en tiempo real.\n\nEn resumen, Accelerate es una herramienta muy Ãºtil para desarrolladores de modelos de lenguaje que buscan simplificar y acelerar el proceso de entrenamiento y evaluaciÃ³n de sus modelos.\n\nÂ¿Tienes alguna pregunta especÃ­fica sobre Accelerate o necesitas ayuda para implementarlo en tu proyecto?\'}',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Now the answer if it responds to our prompt</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h4 id="Inference-with-AutoClass">Inference with <code>AutoClass</code><a class="anchor-link" href="#Inference-with-AutoClass"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 51" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Finally we will see how to do the inference only with <code>AutoClass</code>.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/18_inference_with_autoclass.py',
          '',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">TextStreamer</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"meta-llama/Meta-Llama-3-8B-Instruct"</span>',
          '',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s2">"auto"</span><span class="p">)</span>',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s2">"auto"</span><span class="p">)</span>',
          '<span class="n">streamer</span> <span class="o">=</span> <span class="n">TextStreamer</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">)</span>',
          '',
          '<span class="n">prompt</span> <span class="o">=</span> <span class="s2">"Conoces accelerate de hugging face?"</span>',
          '<span class="n">tokens_input</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">([</span><span class="n">prompt</span><span class="p">],</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>',
          '',
          '<span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="o">**</span><span class="n">tokens_input</span><span class="p">,</span> <span class="n">streamer</span><span class="o">=</span><span class="n">streamer</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">do_sample</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">top_p</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/11_inference_with_autoclass.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>As you can see, the <code>streamer</code> object has been created and then passed to the <code>generate</code> method of the model. This is useful so that each word is printed as it is generated and you don't have to wait for all the output to be generated before printing it.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">!</span>python<span class="w"> </span>accelerate_scripts/18_inference_with_autoclass.py',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.',
          'Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:09&lt;00:00,  2.28s/it]',
          'Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.',
          '&lt;|begin_of_text|&gt;Conoces accelerate de hugging face? Si es asÃ­, puedes utilizar la biblioteca `transformers` de Hugging Face para crear un modelo de lenguaje que pueda predecir la siguiente palabra en una secuencia de texto.',
          'AquÃ­ te muestro un ejemplo de cÃ³mo hacerlo:',
          '```',
          'import pandas as pd',
          'import torch',
          'from transformers import AutoModelForSequenceClassification, AutoTokenizer',
          '# Cargar el modelo y el tokenizador',
          'model_name = "bert-base-uncased"',
          'model = AutoModelForSequenceClassification.from_pretrained(model_name)',
          'tokenizer = AutoTokenizer.from_pretrained(model_name)',
          '# Cargar el conjunto de datos',
          'train_df = pd.read_csv("train.csv")',
          'test_df = pd.read_csv("test.csv")',
          '# Preprocesar los datos',
          'train_texts = train_df["text"]',
          'train_labels = train_df["label"]',
          'test_texts = test_df["text"]',
          '# Convertir los textos en entradas para el modelo',
          'train_encodings = tokenizer.batch_encode_plus(train_texts, ',
          '                                              add_special_tokens=True, ',
          '                                              max_length=512, ',
          '                                              return_attention_mask=True, ',
          '                                              return_tensors=\'pt\')',
          'test_encodings = tokenizer.batch_encode_plus(test_texts, ',
          '                                             add_special_tokens=True, ',
          '                                             max_length=512, ',
          '                                             return_attention_mask=True, ',
          '                                             return_tensors=\'pt\')',
          '# Crear un dataloader para entrenar el modelo',
          'train_dataset = torch.utils.data.TensorDataset(train_encodings["input_ids"], ',
          '                                               train_encodings["attention_mask"], ',
          '                                               torch.tensor(train_labels))',
          'train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)',
          '# Entrenar el modelo',
          'device = torch.device("cuda" if torch.cuda.is_available() else "cpu")',
          'model.to(device)',
          'criterion = torch.nn.CrossEntropyLoss()',
          'optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)',
          'for epoch in range(5):',
          '    model.train()',
          '    total_loss = 0',
          '    for batch in train_loader:',
          '        input_ids = batch[0].to(device)',
          '        attention_mask = batch[1].to(device)',
          '        labels = batch[2].to(device)',
          '        optimizer.zero_grad()',
          '        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)',
          '        loss = criterion(outputs, labels)',
          '        loss.backward()',
          '        optimizer.step()',
          '        total_loss += loss.item()',
          '    print(f"Epoch {epoch+1}, Loss: {total',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Use-pytorch">Use pytorch<a class="anchor-link" href="#Use-pytorch"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 52" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Normally the way to make inferences with pytorch is to create a model with the weights initialized randomly and then load a <code>state dict</code> with the weights of the pre-trained model, so to get that <code>state dict</code> we are going to make a little trick first and download them</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">import</span> <span class="nn">torchvision.models</span> <span class="k">as</span> <span class="nn">models</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet152</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">models</span><span class="o">.</span><span class="n">ResNet152_Weights</span><span class="o">.</span><span class="n">IMAGENET1K_V1</span><span class="p">)</span>',
          '<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">\'accelerate_scripts/resnet152_pretrained.pth\'</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Downloading: "https://download.pytorch.org/models/resnet152-394f9c45.pth" to /home/maximo.fernandez/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth',
          '100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230M/230M [02:48&lt;00:00, 1.43MB/s] ',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Now that we have the <code>state dict</code> let's do inference as it is normally done in pytorch</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">import</span> <span class="nn">torchvision.models</span> <span class="k">as</span> <span class="nn">models</span>',
          '',
          '<span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span>     <span class="c1"># Set device</span>',
          '',
          '<span class="n">resnet152</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet152</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="c1"># Create model with random weights and move to device</span>',
          '<span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">\'accelerate_scripts/resnet152_pretrained.pth\'</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="c1"># Load pretrained weights into device memory</span>',
          '<span class="n">resnet152</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span> <span class="c1"># Load this weights into the model</span>',
          '',
          '<span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Random image with batch size 1</span>',
          '<span class="n">output</span> <span class="o">=</span> <span class="n">resnet152</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>',
          '<span class="n">output</span><span class="o">.</span><span class="n">shape</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'torch.Size([1, 1000])',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Let us explain what happened</p>
      <ul>
      <li>When we did <code>resnet152 = models.resnet152().to(device)</code> a resnet152 with random weights was loaded into GPU memory.</li>
      <li>When we did <code>state_dict = torch.load('accelerate_scripts/resnet152_pretrained.pth', map_location=device)</code> a dictionary with the trained weights was loaded into GPU memory.</li>
      <li>When we have done <code>resnet152.load_state_dict(state_dict)</code> these pre-trained weights have been assigned to the model.</li>
      </ul>
      <p>In other words, the model has been loaded twice in the GPU memory.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>You may be wondering why we have done this first.</p>
      <div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet152</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">models</span><span class="o">.</span><span class="n">ResNet152_Weights</span><span class="o">.</span><span class="n">IMAGENET1K_V1</span><span class="p">)</span>
      <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">'accelerate_scripts/resnet152_pretrained.pth'</span><span class="p">)</span>
      </pre></div>
      <p>To then make</p>
      <div class="highlight"><pre><span></span><span class="n">resnet152</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet152</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
      <span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">'accelerate_scripts/resnet152_pretrained.pth'</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
      <span class="n">resnet152</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span>
      </pre></div>
      <p>And why don't we use directly</p>
      <pre><code>model = models.resnet152(weights=models.ResNet152_Weights.IMAGENET1K_V1)</code></pre>
      <p>And we stop saving the <code>state dict</code> to load it later. Well, because Pytorch, by edbajo does the same thing that we have done. So to be able to see the whole process we have done in several lines what Pytorch does in one line</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>This way of working has worked well until now, as long as the models had a manageable size for user GPUs. But since the advent of LLMs this approach does not make sense.</p>
      <p>For example, a 6B model of parameters would occupy 24 GB of memory, and since it is loaded twice with this way of working, a 48 GB GPU would be required.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>So to fix this, the way to load a pre-trained Pytorch model is:</p>
      <ul>
      <li>Create an empty model with <code>init_empty_weights</code> that will not occupy RAM.</li>
      <li>Then load the weights with <code>load_checkpoint_and_dispatch</code> which will load a checkpoint inside the empty model and distribute the weights for each layer on all available devices (GPU, CPU RAM and hard disk), thanks to setting <code>device_map="auto"</code>.</li>
      </ul>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">import</span> <span class="nn">torchvision.models</span> <span class="k">as</span> <span class="nn">models</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">init_empty_weights</span><span class="p">,</span> <span class="n">load_checkpoint_and_dispatch</span>',
          '',
          '<span class="k">with</span> <span class="n">init_empty_weights</span><span class="p">():</span>',
          '    <span class="n">resnet152</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet152</span><span class="p">()</span>',
          '',
          '<span class="n">resnet152</span> <span class="o">=</span> <span class="n">load_checkpoint_and_dispatch</span><span class="p">(</span><span class="n">resnet152</span><span class="p">,</span> <span class="n">checkpoint</span><span class="o">=</span><span class="s1">\'accelerate_scripts/resnet152_pretrained.pth\'</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s2">"auto"</span><span class="p">)</span>',
          '',
          '<span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span>',
          '',
          '<span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Random image with batch size 1</span>',
          '<span class="n">output</span> <span class="o">=</span> <span class="n">resnet152</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>',
          '<span class="n">output</span><span class="o">.</span><span class="n">shape</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'torch.Size([1, 1000])',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="How-accelerate-works-below">How accelerate works below<a class="anchor-link" href="#How-accelerate-works-below"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 53" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>In this video you can see graphically how accelerate works below</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" frameborder="0" height="720" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/MWCSGj9jEAo" title="Accelerate Big Model Inference: How Does it Work?" width="1280"></iframe>
      </section>
      
      <section class="section-block-markdown-cell">
      <h4 id="Initialization-of-an-empty-model">Initialization of an empty model<a class="anchor-link" href="#Initialization-of-an-empty-model"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 54" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Accelerate creates the skeleton of an empty model using <code>init_empty_weights</code> to occupy as little memory as possible.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>For example, let's see how much RAM I now have available on my computer</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">import</span> <span class="nn">psutil</span>',
          '',
          '<span class="k">def</span> <span class="nf">get_ram_info</span><span class="p">():</span>',
          '    <span class="n">ram</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">psutil</span><span class="o">.</span><span class="n">virtual_memory</span><span class="p">()</span><span class="o">.</span><span class="n">_asdict</span><span class="p">())</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Total RAM: </span><span class="si">{</span><span class="p">(</span><span class="n">ram</span><span class="p">[</span><span class="s1">\'total\'</span><span class="p">]</span><span class="o">/</span><span class="mi">1024</span><span class="o">/</span><span class="mi">1024</span><span class="o">/</span><span class="mi">1024</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> GB, Available RAM: </span><span class="si">{</span><span class="p">(</span><span class="n">ram</span><span class="p">[</span><span class="s1">\'available\'</span><span class="p">]</span><span class="o">/</span><span class="mi">1024</span><span class="o">/</span><span class="mi">1024</span><span class="o">/</span><span class="mi">1024</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> GB, Used RAM: </span><span class="si">{</span><span class="p">(</span><span class="n">ram</span><span class="p">[</span><span class="s1">\'used\'</span><span class="p">]</span><span class="o">/</span><span class="mi">1024</span><span class="o">/</span><span class="mi">1024</span><span class="o">/</span><span class="mi">1024</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> GB"</span><span class="p">)</span>',
          '',
          '<span class="n">get_ram_info</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Total RAM: 31.24 GB, Available RAM: 22.62 GB, Used RAM: 7.82 GB',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>I have about 22 GB of RAM available</p>
      <p>Now let's try to create a model 5000x1000x1000 parameters, i.e. 5B parameters, if each parameter is in FP32, it means 20 GB of RAM.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
      '      <span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>',
      '      ',
      '      <span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">)])</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>









      
      <section class="section-block-markdown-cell">
      <p>If we look at RAM again</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">)])</span>',
          '</span><span class="n">get_ram_info</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Total RAM: 31.24 GB, Available RAM: 3.77 GB, Used RAM: 26.70 GB',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>As we can see now we only have 3 GB of RAM available.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Now let's delete the model to free RAM</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="k">del</span> <span class="n">model</span>',
          '<span class="n">get_ram_info</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Total RAM: 31.24 GB, Available RAM: 22.44 GB, Used RAM: 8.03 GB',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We again have about 22 GB of RAM available.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Let's now use <code>init_empty_weights</code> from <code>accelerate</code> and then we see the RAM</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">init_empty_weights</span>',
          '',
          '<span class="k">with</span> <span class="n">init_empty_weights</span><span class="p">():</span>',
          '    <span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">)])</span>',
          '',
          '<span class="n">get_ram_info</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Total RAM: 31.24 GB, Available RAM: 22.32 GB, Used RAM: 8.16 GB',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Before we had exactly 22.44 GB free and after creating the model with <code>init_empty_weights</code> we have 22.32 GB. The saving in RAM is enormous! Almost no RAM has been used to create the model.</p>
      <p>This is based on the metadevice introduced in PyTorch 1.9, so it is important that to use <code>accelerate</code> we have a later version of Pytorch.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h4 id="Loading-weights">Loading weights<a class="anchor-link" href="#Loading-weights"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 55" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Once we have initialized the model we have to load the weights using <code>load_checkpoint_and_dispatch</code> which, as its name indicates, loads the weights and sends them to the device or devices required.</p>
      </section>
      






    </div>

  </section>

</PostLayout>
