---
import PostLayout from '@layouts/PostLayout.astro';
import CodeBlockInputCell from '@components/CodeBlockInputCell.astro';
import CodeBlockOutputCell from '@components/CodeBlockOutputCell.astro';

const { metadata_page } = await import('@portfolio/consts.json');
const { colors } = await import('@portfolio/consts.json');
const { svg_paths } = await import('@portfolio/consts.json');

const page_title = 'HuggingFace Accelerate: Complete Guide to Train Models on GPU/TPU';
const end_url = 'hugging-face-accelerate';
const description = 'Learn how to use Hugging Face Accelerate to train ML models on multiple GPUs and TPUs. Complete tutorial with practical examples and code.';
const keywords = 'hugging face, accelerate, pytorch, deep learning, machine learning, transformers';
const languaje = 'EN';
const image_path = 'https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/huggingface_accelerate.webp';
const opening_brace = '{';
const closing_brace = '}';
---

<PostLayout 
    title={page_title}
    languaje={languaje}
    description={description}
    keywords={keywords}
    author={metadata_page.author}
    theme_color={colors.background_color}
    end_url={end_url}
    image_path={image_path}
    image_width=1280
    image_height=670
    image_extension=webp
    article_date=2024-05-16+T00:00:00Z
>

  <section class="post-body">


    <aside class="post-index">
      <a class="anchor-link" href="#Installation"><h2>Installation</h2></a>
      <a class="anchor-link" href="#Configuration"><h2>Configuration</h2></a>
      <a class="anchor-link" href="#Training"><h2>Training</h2></a>
      <a class="anchor-link" href="#Optimization of Training"><h3>Optimization of Training</h3></a>
      <a class="anchor-link" href="#Base code"><h4>Base code</h4></a>
      <a class="anchor-link" href="#Script with the base code"><h4>Script with the base code</h4></a>
      <a class="anchor-link" href="#Code with accelerate"><h4>Code with accelerate</h4></a>
      <a class="anchor-link" href="#Execution of processes"><h3>Execution of processes</h3></a>
      <a class="anchor-link" href="#Execution of code in a single process"><h4>Execution of code in a single process</h4></a>
      <a class="anchor-link" href="#Code Execution in All Processes"><h4>Code Execution in All Processes</h4></a>
      <a class="anchor-link" href="#Code Execution in Process X"><h4>Code Execution in Process X</h4></a>
      <a class="anchor-link" href="#Synchronizing Processes"><h4>Synchronizing Processes</h4></a>
      <a class="anchor-link" href="#Save and load the state dict"><h3>Save and load the state dict</h3></a>
      <a class="anchor-link" href="#Save the model"><h3>Save the model</h3></a>
      <a class="anchor-link" href="#Save the pretrained model"><h3>Save the <code>pretrained</code> model</h3></a>
      <a class="anchor-link" href="#Training in notebooks"><h3>Training in notebooks</h3></a>
      <a class="anchor-link" href="#Training in FP16"><h3>Training in FP16</h3></a>
      <a class="anchor-link" href="#Training in BF16"><h3>Training in BF16</h3></a>
      <a class="anchor-link" href="#Training in FP8"><h3>Training in FP8</h3></a>
      <a class="anchor-link" href="#Model Inference"><h2>Model Inference</h2></a>
      <a class="anchor-link" href="#Usage of the Hugging Face Ecosystem"><h3>Usage of the Hugging Face Ecosystem</h3></a>
      <a class="anchor-link" href="#Inference with pipeline"><h4>Inference with <code>pipeline</code></h4></a>
      <a class="anchor-link" href="#Inference with AutoClass"><h4>Inference with <code>AutoClass</code></h4></a>
      <a class="anchor-link" href="#Use PyTorch"><h3>Use PyTorch</h3></a>
      <a class="anchor-link" href="#How accelerate works under the hood"><h3>How accelerate works under the hood</h3></a>
      <a class="anchor-link" href="#Initialization of an empty model"><h4>Initialization of an empty model</h4></a>
      <a class="anchor-link" href="#Loading the weights"><h4>Loading the weights</h4></a>
    </aside>


    <div class="post-body-content">
      
      <section class="section-block-markdown-cell">
      </section>
      
      <section class="section-block-markdown-cell">
      <blockquote>
      <p>Disclaimer: This post has been translated to English using a machine translation model. Please, let me know if you find any mistakes.</p>
      </blockquote>
      </section>
      
      <section class="section-block-markdown-cell">
      <p><code>Accelerate</code> is a Hugging Face library that allows running the same PyTorch code in any distributed setup by adding only four lines of code.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Installation">Installation<a class="anchor-link" href="#Installation"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 26" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>To install <code>accelerate</code> with <code>pip</code>, simply run:</p>
      <div class='highlight'><pre><code class="language-bash">pip install accelerate</code></pre></div>
      <p>And with <code>conda</code>:</p>
      <div class='highlight'><pre><code class="language-bash">conda install -c conda-forge accelerate</code></pre></div>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Configuration">Configuration<a class="anchor-link" href="#Configuration"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 27" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>In each environment where <code>accelerate</code> is installed, the first thing to do is to configure it. To do this, run in a terminal:</p>
      <div class='highlight'><pre><code class="language-bash">`accelerate config`</code></pre></div>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="err">!</span><span class="n">accelerate</span> <span class="n">config</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '--------------------------------------------------------------------------------',
          'In which compute environment are you running?',
          'This machine',
          '--------------------------------------------------------------------------------',
          'multi-GPU',
          'How many different machines will you use (use more than 1 for multi-node training)? [1]: 1',
          'Should distributed operations be checked while running for errors? This can avoid timeout issues but will be slower. [yes/NO]: no',
          'Do you wish to optimize your script with torch dynamo?[yes/NO]:no',
          'Do you want to use DeepSpeed? [yes/NO]: no',
          'Do you want to use FullyShardedDataParallel? [yes/NO]: no',
          'Do you want to use Megatron-LM ? [yes/NO]: no',
          'How many GPU(s) should be used for distributed training? [1]:2',
          'What GPU(s) (by id) should be used for training on this machine as a comma-seperated list? [all]:0,1',
          '--------------------------------------------------------------------------------',
          'Do you wish to use FP16 or BF16 (mixed precision)?',
          'no',
          'accelerate configuration saved at ~/.cache/huggingface/accelerate/default_config.yaml',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>In my case, the answers have been</p>
      <ul>
        <li>In which compute environment are you running?</li>
        <li>[x] "This machine"</li>
        <li>[_] "AWS (Amazon SageMaker)"</li>
      </ul>
      <blockquote>
      <p>I want to set it up on my computer</p>
      </blockquote>
      <ul>
        <li>What type of machine are you using?</li>
        <li>[_] multi-CPU</li>
        <li>[_] multi-XPU</li>
        <li>[x] multi-GPU</li>
        <li>[_] multi-NPU</li>
        <li>[_] TPU</li>
      </ul>
      <blockquote>
      <p>Since I have 2 GPUs and want to run distributed codes on them, I choose <code>multi-GPU</code></p>
      </blockquote>
      <ul>
        <li>How many different machines will you use (use more than 1 for multi-node training)? [1]:</li>
        <li>1</li>
      </ul>
      <blockquote>
      <p>I choose <code>1</code> because I'm only going to run it on my computer</p>
      </blockquote>
      <ul>
        <li>Should distributed operations be checked while running for errors? This can avoid timeout issues but will be slower. [yes/NO]:</li>
        <li>no</li>
      </ul>
      <blockquote>
      <p>With this option, you can choose to have <code>accelerate</code> check for errors during execution, but it would make it slower, so I choose <code>no</code>, and if there are any errors I change it to <code>yes</code>.</p>
      </blockquote>
      <ul>
        <li>Do you wish to optimize your script with torch dynamo? [yes/NO]:</li>
        <li>no</li>
      </ul>
      <ul>
        <li>Do you want to use FullyShardedDataParallel? [yes/NO]:</li>
        <li>no</li>
      </ul>
      <ul>
        <li>Do you want to use Megatron-LM? [yes/NO]:</li>
        <li>no</li>
      </ul>
      <ul>
        <li>How many GPU(s) should be used for distributed training? [1]:</li>
        <li>2</li>
      </ul>
      <blockquote>
      <p>I choose <code>2</code> because I have 2 GPUs</p>
      </blockquote>
      <ul>
        <li>What GPU(s) (by id) should be used for training on this machine as a comma-separated list? [all]:</li>
        <li>0.1</li>
      </ul>
      <blockquote>
      <p>I choose <code>0,1</code> because I want to use both GPUs</p>
      </blockquote>
      <ul>
        <li>Do you wish to use FP16 or BF16 (mixed precision)?</li>
        <li>[x] no</li>
        <li>[_] fp16</li>
        <li>[_] bf16</li>
        <li>[_] fp8</li>
      </ul>
      <blockquote>
      <p>For now I choose <code>no</code>, because to simplify the code when not using <code>accelerate</code> we are going to train in fp32, but ideally we would use fp16</p>
      </blockquote>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>The configuration will be saved in <code>~/.cache/huggingface/accelerate/default_config.yaml</code> and can be modified at any time. Let's see what's inside.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="err">!</span><span class="n">cat</span> <span class="o">~/.</span><span class="n">cache</span><span class="o">/</span><span class="n">huggingface</span><span class="o">/</span><span class="n">accelerate</span><span class="o">/</span><span class="n">default_config</span><span class="o">.</span><span class="n">yaml</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'compute_environment: LOCAL_MACHINE',
          'debug: false',
          'distributed_type: MULTI_GPU',
          'downcast_bf16: &#x27;no&#x27;',
          'gpu_ids: 0,1',
          'machine_rank: 0',
          'main_training_function: main',
          'mixed_precision: fp16',
          'num_machines: 1',
          'num_processes: 2',
          'rdzv_backend: static',
          'same_network: true',
          'tpu_env: []',
          'tpu_use_cluster: false',
          'tpu_use_sudo: false',
          'use_cpu: false',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Another way to view the configuration we have is by running in a terminal:</p>
      <div class='highlight'><pre><code class="language-bash">accelerate env</code></pre></div>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="err">!</span><span class="n">accelerate</span> <span class="n">env</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Copy-and-paste the text below in your GitHub issue',
          '- `Accelerate` version: 0.28.0',
          '- Platform: Linux-5.15.0-105-generic-x86_64-with-glibc2.31',
          '- Python version: 3.11.8',
          '- Numpy version: 1.26.4',
          '- PyTorch version (GPU?): 2.2.1+cu121 (True)',
          '- PyTorch XPU available: False',
          '- PyTorch NPU available: False',
          '- System RAM: 31.24 GB',
          '- GPU type: NVIDIA GeForce RTX 3090',
          '- `Accelerate` default config:',
          '- compute_environment: LOCAL_MACHINE',
          '- distributed_type: MULTI_GPU',
          '- mixed_precision: fp16',
          '- use_cpu: False',
          '- debug: False',
          '- num_processes: 2',
          '- machine_rank: 0',
          '- num_machines: 1',
          '- gpu_ids: 0,1',
          '- rdzv_backend: static',
          '- same_network: True',
          '- main_training_function: main',
          '- downcast_bf16: no',
          '- tpu_use_cluster: False',
          '- tpu_use_sudo: False',
          '- tpu_env: []',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Once we have configured <code>accelerate</code> we can test if we have done it correctly by running in a terminal:</p>
      <div class='highlight'><pre><code class="language-bash">accelerate test</code></pre></div>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="err">!</span><span class="n">accelerate</span> <span class="n">test</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Running:  accelerate-launch ~/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/test_utils/scripts/test_script.py',
          'stdout: **Initialization**',
          'stdout: Testing, testing. 1, 2, 3.',
          'stdout: Distributed environment: DistributedType.MULTI_GPU  Backend: nccl',
          'stdout: Num processes: 2',
          'stdout: Process index: 0',
          'stdout: Local process index: 0',
          'stdout: Device: cuda:0',
          'stdout:',
          'stdout: Mixed precision type: fp16',
          'stdout:',
          'stdout: Distributed environment: DistributedType.MULTI_GPU  Backend: nccl',
          'stdout: Num processes: 2',
          'stdout: Process index: 1',
          'stdout: Local process index: 1',
          'stdout: Device: cuda:1',
          'stdout:',
          'stdout: Mixed precision type: fp16',
          'stdout:',
          'stdout:',
          'stdout: **Test process execution**',
          'stdout:',
          'stdout: **Test split between processes as a list**',
          'stdout:',
          'stdout: **Test split between processes as a dict**',
          'stdout:',
          'stdout: **Test split between processes as a tensor**',
          'stdout:',
          'stdout: **Test random number generator synchronization**',
          'stdout: All rng are properly synched.',
          'stdout:',
          'stdout: **DataLoader integration test**',
          'stdout: 0 1 tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,',
          'stdout:         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,',
          'stdout:         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,',
          'stdout:         54, 55, 56, 57, 58, 59, 60, 61, 62, 63], device=&#x27;cuda:1&#x27;) &amp;lt;class &#x27;accelerate.data_loader.DataLoaderShard&#x27;&amp;gt;',
          'stdout: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,',
          'stdout:         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,',
          'stdout:         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,',
          'stdout:         54, 55, 56, 57, 58, 59, 60, 61, 62, 63], device=&#x27;cuda:0&#x27;) &amp;lt;class &#x27;accelerate.data_loader.DataLoaderShard&#x27;&amp;gt;',
          'stdout: Non-shuffled dataloader passing.',
          'stdout: Shuffled dataloader passing.',
          'stdout: Non-shuffled central dataloader passing.',
          'stdout: Shuffled central dataloader passing.',
          'stdout:',
          'stdout: **Training integration test**',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Training yielded the same results on one CPU or distributed setup with no batch split.',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Training yielded the same results on one CPU or distributes setup with batch split.',
          'stdout: FP16 training check.',
          'stdout: FP16 training check.',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Keep fp32 wrapper check.',
          'stdout: Keep fp32 wrapper check.',
          'stdout: BF16 training check.',
          'stdout: BF16 training check.',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout:',
          'stdout: Training yielded the same results on one CPU or distributed setup with no batch split.',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: FP16 training check.',
          'stdout: Training yielded the same results on one CPU or distributes setup with batch split.',
          'stdout: FP16 training check.',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Keep fp32 wrapper check.',
          'stdout: Keep fp32 wrapper check.',
          'stdout: BF16 training check.',
          'stdout: BF16 training check.',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout:',
          'stdout: **Breakpoint trigger test**',
          'Test is a success! You are ready for your distributed training!',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We see that it ends by saying <code>Test is a success! You are ready for your distributed training!</code> so everything is correct.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Training">Training<a class="anchor-link" href="#Training"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 28" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Optimization of Training">Optimization of Training<a class="anchor-link" href="#Optimization of Training"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 29" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <h4 id="Base code">Base code<a class="anchor-link" href="#Base code"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 30" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Let's start by creating a basic training code and then we'll optimize it to see how it's done and how it improves.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>First, let's find a dataset. In my case, I will use the <a href="https://huggingface.co/datasets/tweet_eval" target="_blank" rel="nofollow noreferrer">tweet_eval</a> dataset, which is a tweet classification dataset. Specifically, I will download the <code>emoji</code> subset that classifies tweets with emojis.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>',
      '<span class="w"> </span>',
      '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>',
      '<span class="n">dataset</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'DatasetDict(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;train: Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;text&#x27;, &#x27;label&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 45000',
          '&#x20;&#x20;&#x20;&#x20;&#x7D;)',
          '&#x20;&#x20;&#x20;&#x20;test: Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;text&#x27;, &#x27;label&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 50000',
          '&#x20;&#x20;&#x20;&#x20;&#x7D;)',
          '&#x20;&#x20;&#x20;&#x20;validation: Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;text&#x27;, &#x27;label&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 5000',
          '&#x20;&#x20;&#x20;&#x20;&#x7D;)',
          '&#x7D;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'DatasetInfo(description=&#x27;&#x27;, citation=&#x27;&#x27;, homepage=&#x27;&#x27;, license=&#x27;&#x27;, features=&#x7B;&#x27;text&#x27;: Value(dtype=&#x27;string&#x27;, id=None), &#x27;label&#x27;: ClassLabel(names=[&#x27;❤&#x27;, &#x27;😍&#x27;, &#x27;😂&#x27;, &#x27;💕&#x27;, &#x27;🔥&#x27;, &#x27;😊&#x27;, &#x27;😎&#x27;, &#x27;✨&#x27;, &#x27;💙&#x27;, &#x27;😘&#x27;, &#x27;📷&#x27;, &#x27;🇺🇸&#x27;, &#x27;☀&#x27;, &#x27;💜&#x27;, &#x27;😉&#x27;, &#x27;💯&#x27;, &#x27;😁&#x27;, &#x27;🎄&#x27;, &#x27;📸&#x27;, &#x27;😜&#x27;], id=None)&#x7D;, post_processed=None, supervised_keys=None, task_templates=None, builder_name=&#x27;parquet&#x27;, dataset_name=&#x27;tweet_eval&#x27;, config_name=&#x27;emoji&#x27;, version=0.0.0, splits=&#x7B;&#x27;train&#x27;: SplitInfo(name=&#x27;train&#x27;, num_bytes=3808792, num_examples=45000, shard_lengths=None, dataset_name=&#x27;tweet_eval&#x27;), &#x27;test&#x27;: SplitInfo(name=&#x27;test&#x27;, num_bytes=4262151, num_examples=50000, shard_lengths=None, dataset_name=&#x27;tweet_eval&#x27;), &#x27;validation&#x27;: SplitInfo(name=&#x27;validation&#x27;, num_bytes=396704, num_examples=5000, shard_lengths=None, dataset_name=&#x27;tweet_eval&#x27;)&#x7D;, download_checksums=&#x7B;&#x27;hf://datasets/tweet_eval@b3a375baf0f409c77e6bc7aa35102b7b3534f8be/emoji/train-00000-of-00001.parquet&#x27;: &#x7B;&#x27;num_bytes&#x27;: 2609973, &#x27;checksum&#x27;: None&#x7D;, &#x27;hf://datasets/tweet_eval@b3a375baf0f409c77e6bc7aa35102b7b3534f8be/emoji/test-00000-of-00001.parquet&#x27;: &#x7B;&#x27;num_bytes&#x27;: 3047341, &#x27;checksum&#x27;: None&#x7D;, &#x27;hf://datasets/tweet_eval@b3a375baf0f409c77e6bc7aa35102b7b3534f8be/emoji/validation-00000-of-00001.parquet&#x27;: &#x7B;&#x27;num_bytes&#x27;: 281994, &#x27;checksum&#x27;: None&#x7D;&#x7D;, download_size=5939308, post_processing_size=None, dataset_size=8467647, size_in_bytes=14406955)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Let's see the classes</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="nb">print</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '[&#x27;❤&#x27;, &#x27;😍&#x27;, &#x27;😂&#x27;, &#x27;💕&#x27;, &#x27;🔥&#x27;, &#x27;😊&#x27;, &#x27;😎&#x27;, &#x27;✨&#x27;, &#x27;💙&#x27;, &#x27;😘&#x27;, &#x27;📷&#x27;, &#x27;🇺🇸&#x27;, &#x27;☀&#x27;, &#x27;💜&#x27;, &#x27;😉&#x27;, &#x27;💯&#x27;, &#x27;😁&#x27;, &#x27;🎄&#x27;, &#x27;📸&#x27;, &#x27;😜&#x27;]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>And the number of classes</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
      '<span class="n">num_classes</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '20',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We see that the dataset has 20 classes</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Let's look at the maximum sequence of each split</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">max_len_train</span> <span class="o">=</span> <span class="mi">0</span>',
      '<span class="n">max_len_val</span> <span class="o">=</span> <span class="mi">0</span>',
      '<span class="n">max_len_test</span> <span class="o">=</span> <span class="mi">0</span>',
      '<span class="w"> </span>',
      '<span class="n">split</span> <span class="o">=</span> <span class="s2">&quot;train&quot;</span>',
      '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">])):</span>',
      '<span class="w">    </span><span class="n">len_i</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s2">&quot;text&quot;</span><span class="p">])</span>',
      '<span class="w">    </span><span class="k">if</span> <span class="n">len_i</span> <span class="o">&amp;</span><span class="n">gt</span><span class="p">;</span> <span class="n">max_len_train</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">max_len_train</span> <span class="o">=</span> <span class="n">len_i</span>',
      '<span class="n">split</span> <span class="o">=</span> <span class="s2">&quot;validation&quot;</span>',
      '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">])):</span>',
      '<span class="w">    </span><span class="n">len_i</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s2">&quot;text&quot;</span><span class="p">])</span>',
      '<span class="w">    </span><span class="k">if</span> <span class="n">len_i</span> <span class="o">&amp;</span><span class="n">gt</span><span class="p">;</span> <span class="n">max_len_val</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">max_len_val</span> <span class="o">=</span> <span class="n">len_i</span>',
      '<span class="n">split</span> <span class="o">=</span> <span class="s2">&quot;test&quot;</span>',
      '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">])):</span>',
      '<span class="w">    </span><span class="n">len_i</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s2">&quot;text&quot;</span><span class="p">])</span>',
      '<span class="w">    </span><span class="k">if</span> <span class="n">len_i</span> <span class="o">&amp;</span><span class="n">gt</span><span class="p">;</span> <span class="n">max_len_test</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">max_len_test</span> <span class="o">=</span> <span class="n">len_i</span>',
      '<span class="w"> </span>',
      '<span class="n">max_len_train</span><span class="p">,</span> <span class="n">max_len_val</span><span class="p">,</span> <span class="n">max_len_test</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '(142, 139, 167)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>So we define the maximum sequence in general as 130 for tokenization</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>We are interested in the tokenized dataset, not the raw sequences, so we create a tokenizer</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>',
      '<span class="w"> </span>',
      '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>',
      '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>We create a tokenization function</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>And now we tokenize the dataset</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
      '<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="p">}</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Map:   0%|          | 0/45000 [00:00&amp;lt;?, ? examples/s]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockOutputCell
        text={[
          'Map:   0%|          | 0/5000 [00:00&amp;lt;?, ? examples/s]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockOutputCell
        text={[
          'Map:   0%|          | 0/50000 [00:00&amp;lt;?, ? examples/s]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>As we can see, now we have the tokens (<code>input_ids</code>) and the attention masks (<code>attention_mask</code>), but let's take a look at what kind of data we have.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="nb">type</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]),</span> <span class="nb">type</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]),</span> <span class="nb">type</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;label&quot;</span><span class="p">])</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '(list, list, int)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>',
      '<span class="nb">type</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;label&quot;</span><span class="p">]),</span> <span class="nb">type</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]),</span> <span class="nb">type</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">])</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '(torch.Tensor, torch.Tensor, torch.Tensor)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We create a DataLoader</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>',
      '<span class="n">BS</span> <span class="o">=</span> <span class="mi">64</span>',
      '<span class="w"> </span>',
      '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
      '<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="p">}</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>We load the model</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span>',
      '<span class="w"> </span>',
      '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Let's see how the model is.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">model</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'RobertaForSequenceClassification(',
          '&#x20;&#x20;(roberta): RobertaModel(',
          '&#x20;&#x20;&#x20;&#x20;(embeddings): RobertaEmbeddings(',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(word_embeddings): Embedding(50265, 768, padding_idx=1)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(position_embeddings): Embedding(514, 768, padding_idx=1)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(token_type_embeddings): Embedding(1, 768)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(dropout): Dropout(p=0.1, inplace=False)',
          '&#x20;&#x20;&#x20;&#x20;)',
          '&#x20;&#x20;&#x20;&#x20;(encoder): RobertaEncoder(',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(layer): ModuleList(',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(0-11): 12 x RobertaLayer(',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(attention): RobertaAttention(',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(self): RobertaSelfAttention(',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(query): Linear(in_features=768, out_features=768, bias=True)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(key): Linear(in_features=768, out_features=768, bias=True)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(value): Linear(in_features=768, out_features=768, bias=True)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(dropout): Dropout(p=0.1, inplace=False)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(output): RobertaSelfOutput(',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(dense): Linear(in_features=768, out_features=768, bias=True)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(dropout): Dropout(p=0.1, inplace=False)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(intermediate): RobertaIntermediate(',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(dense): Linear(in_features=768, out_features=3072, bias=True)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(intermediate_act_fn): GELUActivation()',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(output): RobertaOutput(',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(dense): Linear(in_features=3072, out_features=768, bias=True)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(dropout): Dropout(p=0.1, inplace=False)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)',
          '&#x20;&#x20;&#x20;&#x20;)',
          '&#x20;&#x20;)',
          '&#x20;&#x20;(classifier): RobertaClassificationHead(',
          '&#x20;&#x20;&#x20;&#x20;(dense): Linear(in_features=768, out_features=768, bias=True)',
          '&#x20;&#x20;&#x20;&#x20;(dropout): Dropout(p=0.1, inplace=False)',
          '&#x20;&#x20;&#x20;&#x20;(out_proj): Linear(in_features=768, out_features=2, bias=True)',
          '&#x20;&#x20;)',
          ')',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Let's take a look at its last layer</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Linear(in_features=768, out_features=2, bias=True)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">out_features</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '(768, 2)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We have seen that our dataset has 20 classes, but this model is trained for 2 classes, so we need to modify the last layer.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
      '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Linear(in_features=768, out_features=20, bias=True)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Now yes</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Now we create a loss function</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>An optimizer</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>',
      '<span class="w"> </span>',
      '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>And lastly, a metric</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>',
      '<span class="w"> </span>',
      '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Let's check that everything is fine with a sample.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">sample</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]))</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">sample</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '(torch.Size([64, 130]), torch.Size([64, 130]))',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Now we feed that sample to the model</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>',
      '<span class="n">ouputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">),</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">))</span>',
      '<span class="n">ouputs</span><span class="o">.</span><span class="n">logits</span><span class="o">.</span><span class="n">shape</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'torch.Size([64, 20])',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We see that the model outputs 64 batches, which is fine because we set <code>BS = 20</code> and each one with 20 outputs, which is good because we modified the model to have an output of 20 values.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>We obtain the one with the highest value</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">ouputs</span><span class="o">.</span><span class="n">logits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
      '<span class="n">predictions</span><span class="o">.</span><span class="n">shape</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'torch.Size([64])',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We obtain the loss</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">ouputs</span><span class="o">.</span><span class="n">logits</span><span class="p">,</span> <span class="n">sample</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">))</span>',
      '<span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '2.9990389347076416',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>And the accuracy</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">])[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]</span>',
      '<span class="n">accuracy</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '0.015625',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We can now create a small training loop</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">fastprogress.fastprogress</span><span class="w"> </span><span class="kn">import</span> <span class="n">master_bar</span><span class="p">,</span> <span class="n">progress_bar</span>',
      '<span class="w"> </span>',
      '<span class="n">epochs</span> <span class="o">=</span> <span class="mi">1</span>',
      '<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>',
      '<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">master_progress_bar</span> <span class="o">=</span> <span class="n">master_bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">))</span>',
      '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">master_progress_bar</span><span class="p">:</span>',
      '<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">master_progress_bar</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s1">&#39;</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>',
      '<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
      '<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
      '<span class="w">    </span>',
      '<span class="w">    </span><span class="n">master_progress_bar</span><span class="o">.</span><span class="n">main_bar</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Validation accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '&amp;lt;IPython.core.display.HTML object&amp;gt;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockOutputCell
        text={[
          '&amp;lt;IPython.core.display.HTML object&amp;gt;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h4 id="Script with the base code">Script with the base code<a class="anchor-link" href="#Script with the base code"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 31" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>In most of the <code>accelerate</code> documentation, it is explained how to use <code>accelerate</code> with scripts, so for now we will do it this way and at the end we will explain how to do it with a notebook.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>First, we are going to create a folder where we will save the scripts</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="err">!</span><span class="n">mkdir</span> <span class="n">accelerate_scripts</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Now we write the base code in a script</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">01</span><span class="n">_code_base</span><span class="o">.</span><span class="n">py</span>',
      '<span class="w"> </span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">fastprogress.fastprogress</span><span class="w"> </span><span class="kn">import</span> <span class="n">master_bar</span><span class="p">,</span> <span class="n">progress_bar</span>',
      '<span class="w"> </span>',
      '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>',
      '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
      '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
      '<span class="w"> </span>',
      '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>',
      '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>',
      '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
      '<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="p">}</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>',
      '<span class="w"> </span>',
      '<span class="n">BS</span> <span class="o">=</span> <span class="mi">64</span>',
      '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
      '<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="p">}</span>',
      '<span class="w"> </span>',
      '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
      '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
      '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
      '<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>',
      '<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">master_progress_bar</span> <span class="o">=</span> <span class="n">master_bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">))</span>',
      '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">master_progress_bar</span><span class="p">:</span>',
      '<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">master_progress_bar</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s1">&#39;</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>',
      '<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
      '<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
      '<span class="w">    </span>',
      '<span class="w">    </span><span class="n">master_progress_bar</span><span class="o">.</span><span class="n">main_bar</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Validation accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>',
      '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/01_code_base.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>And now we run it</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="o">%%</span><span class="n">time</span>',
      '<span class="w"> </span>',
      '<span class="err">!</span><span class="n">python</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">01</span><span class="n">_code_base</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Accuracy = 0.2112',
          'CPU times: user 2.12 s, sys: 391 ms, total: 2.51 s',
          'Wall time: 3min 36s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We see that on my computer it took about 3 and a half minutes</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h4 id="Code with accelerate">Code with accelerate<a class="anchor-link" href="#Code with accelerate"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 32" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Now we replace some things</p>
      <ul>
        <li>First, we import <code>Accelerator</code> and initialize it</li>
      </ul>
      
      <section class="section-block-markdown-cell">
            <div class='highlight'><pre><code class="language-python">from accelerate import Accelerator<br>accelerator = Accelerator()</code></pre></div>
            </section>
      <ul>
        <li>We don't do the typical anymore</li>
      </ul>
      <p>``` python</p>
      <p>torch.device("cuda" if torch.cuda.is_available() else "cpu")</p>
      <p>```</p>
      <ul>
        <li>But we let <code>accelerate</code> choose the device.</li>
      </ul>
      <div class='highlight'><pre><code class="language-python">device = accelerator.device</code></pre></div>
      <ul>
        <li>We pass the relevant elements for training through the <code>prepare</code> method and no longer do <code>model.to(device)</code></li>
      </ul>
      <div class='highlight'><pre><code class="language-python">model, optimizer, dataloader["train"], dataloader["validation"] = prepare(model, optimizer, dataloader["train"], dataloader["validation"])</code></pre></div>
      <ul>
        <li>We no longer send the data and model to the GPU with <code>.to(device)</code> since <code>accelerate</code> has taken care of it with the <code>prepare</code> method.</li>
      </ul>
      <ul>
        <li>Instead of performing backpropagation with <code>loss.backward()</code>, we let <code>accelerate</code> handle it with</li>
      </ul>
      <div class='highlight'><pre><code class="language-python">accelerator.backward(loss)</code></pre></div>
      <ul>
        <li>When calculating the metric in the validation loop, we need to gather the values from all points, especially if we are doing distributed training, for this we do</li>
      </ul>
      <div class='highlight'><pre><code class="language-python">predictions = accelerator.gather_for_metrics(predictions)</code></pre></div>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">02</span><span class="n">_accelerate_base_code</span><span class="o">.</span><span class="n">py</span>',
      '<span class="w"> </span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">fastprogress.fastprogress</span><span class="w"> </span><span class="kn">import</span> <span class="n">master_bar</span><span class="p">,</span> <span class="n">progress_bar</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Importamos e inicializamos Accelerator</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>',
      '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>',
      '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
      '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
      '<span class="w"> </span>',
      '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>',
      '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>',
      '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
      '<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="p">}</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>',
      '<span class="w"> </span>',
      '<span class="n">BS</span> <span class="o">=</span> <span class="mi">64</span>',
      '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
      '<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="p">}</span>',
      '<span class="w"> </span>',
      '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
      '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
      '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
      '<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>',
      '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
      '<span class="w"> </span>',
      '<span class="c1"># model.to(device)</span>',
      '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>',
      '<span class="w"> </span>',
      '<span class="n">master_progress_bar</span> <span class="o">=</span> <span class="n">master_bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">))</span>',
      '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">master_progress_bar</span><span class="p">:</span>',
      '<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">master_progress_bar</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s1">&#39;</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="c1"># loss.backward()</span>',
      '<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;End of training epoch </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">, outputs[&#39;logits&#39;].shape: </span><span class="si">{</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, labels.shape: </span><span class="si">{</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
      '<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
      '<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
      '<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;End of validation epoch </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">, outputs[&#39;logits&#39;].shape: </span><span class="si">{</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, labels.shape: </span><span class="si">{</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
      '<span class="w">    </span>',
      '<span class="w">    </span><span class="n">master_progress_bar</span><span class="o">.</span><span class="n">main_bar</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Validation accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>',
      '<span class="w"> </span>',
      '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/02_accelerate_base_code.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>If you notice, I've added these two lines <code>print(f&quot;End of training epoch &#123;i&#125;, outputs[&#x27;logits&#x27;].shape: &#123;outputs[&#x27;logits&#x27;].shape&#125;, labels.shape: &#123;labels.shape&#125;&quot;)</code> and the line <code>print(f&quot;End of validation epoch &#123;i&#125;, outputs[&#x27;logits&#x27;].shape: &#123;outputs[&#x27;logits&#x27;].shape&#125;, labels.shape: &#123;labels.shape&#125;&quot;)</code>, I added them on purpose because they will reveal something very important.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Now let's run it. To execute the <code>accelerate</code> scripts, use the command <code>accelerate launch</code></p>
      <div class='highlight'><pre><code class="language-bash">accelerate launch script.py</code></pre></div>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="o">%%</span><span class="n">time</span>',
      '<span class="w"> </span>',
      '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">02</span><span class="n">_accelerate_base_code</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'End of training epoch 0, outputs[&#x27;logits&#x27;].shape: torch.Size([64, 20]), labels.shape: torch.Size([64])',
          'End of training epoch 0, outputs[&#x27;logits&#x27;].shape: torch.Size([64, 20]), labels.shape: torch.Size([64])',
          'End of validation epoch 0, outputs[&#x27;logits&#x27;].shape: torch.Size([64, 20]), labels.shape: torch.Size([8])',
          'Accuracy = 0.206',
          'End of validation epoch 0, outputs[&#x27;logits&#x27;].shape: torch.Size([64, 20]), labels.shape: torch.Size([8])',
          'Accuracy = 0.206',
          'CPU times: user 1.6 s, sys: 272 ms, total: 1.88 s',
          'Wall time: 2min 37s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We see that before it took about 3 and a half minutes, and now it takes around 2 and a half minutes. Quite an improvement. Additionally, if we look at the <code>print</code>s, we can see that they have been printed twice.</p>
      <p>And how can this be? Well, because <code>accelerate</code> has parallelized the training across the two GPUs I have, so it was much faster.</p>
      <p>Moreover, when I ran the first script, that is, when I didn't use <code>accelerate</code>, the GPU was almost full, while when I ran the second one, that is, the one that uses <code>accelerate</code>, both GPUs were barely utilized, so we can increase the batch size to try to fill both. Let's do it!</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">03</span><span class="n">_accelerate_base_code_more_bs</span><span class="o">.</span><span class="n">py</span>',
      '<span class="w"> </span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">fastprogress.fastprogress</span><span class="w"> </span><span class="kn">import</span> <span class="n">master_bar</span><span class="p">,</span> <span class="n">progress_bar</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Importamos e inicializamos Accelerator</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>',
      '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>',
      '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
      '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
      '<span class="w"> </span>',
      '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>',
      '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>',
      '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
      '<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="p">}</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>',
      '<span class="w"> </span>',
      '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
      '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
      '<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="p">}</span>',
      '<span class="w"> </span>',
      '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
      '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
      '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
      '<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>',
      '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
      '<span class="w"> </span>',
      '<span class="c1"># model.to(device)</span>',
      '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>',
      '<span class="w"> </span>',
      '<span class="n">master_progress_bar</span> <span class="o">=</span> <span class="n">master_bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">))</span>',
      '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">master_progress_bar</span><span class="p">:</span>',
      '<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">master_progress_bar</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s1">&#39;</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="c1"># loss.backward()</span>',
      '<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
      '<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
      '<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
      '<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
      '<span class="w">    </span>',
      '<span class="w">    </span><span class="n">master_progress_bar</span><span class="o">.</span><span class="n">main_bar</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Validation accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>',
      '<span class="w"> </span>',
      '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/03_accelerate_base_code_more_bs.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>I have removed the extra prints, as we have already seen that the code is running on both GPUs, and I increased the batch size from 64 to 128. Let's run it and see.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="o">%%</span><span class="n">time</span>',
      '<span class="w"> </span>',
      '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">03</span><span class="n">_accelerate_base_code_more_bs</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Accuracy = 0.1052',
          'Accuracy = 0.1052',
          'CPU times: user 1.41 s, sys: 180 ms, total: 1.59 s',
          'Wall time: 2min 22s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Increasing the batch size has reduced the execution time by a few seconds.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Execution of processes">Execution of processes<a class="anchor-link" href="#Execution of processes"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 33" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <h4 id="Execution of code in a single process">Execution of code in a single process<a class="anchor-link" href="#Execution of code in a single process"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 34" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>We have previously seen that the <code>print</code>s were printed twice, this is because <code>accelerate</code> creates as many processes as there are devices where the code is executed, in my case it creates two processes due to having two GPUs.</p>
      <p>However, not all code should be executed in all processes, for example, the <code>print</code>s slow down the code a lot, especially if they are executed multiple times, if checkpoints are saved, they would be saved twice, etc.</p>
      <p>To be able to execute part of the code in a single process, it has to be encapsulated in a function and decorated with <code>accelerator.on_local_main_process</code>. For example, in the following code you will see that I have created the following function</p>
      
      <section class="section-block-markdown-cell">
            <div class='highlight'><pre><code class="language-python">@accelerator.on_local_main_process<br>def print_something(something):<br>print(something)</code></pre></div>
            </section>
      <p>Another option is to include the code within an <code>if accelerator.is_local_main_process</code> as in the following code</p>
      
      <section class="section-block-markdown-cell">
            <div class='highlight'><pre><code class="language-python">if accelerator.is_local_main_process:<br>print("Something")</code></pre></div>
            </section>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">04</span><span class="n">_accelerate_base_code_some_code_in_one_process</span><span class="o">.</span><span class="n">py</span>',
      '<span class="w"> </span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">fastprogress.fastprogress</span><span class="w"> </span><span class="kn">import</span> <span class="n">master_bar</span><span class="p">,</span> <span class="n">progress_bar</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Importamos e inicializamos Accelerator</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>',
      '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>',
      '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
      '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
      '<span class="w"> </span>',
      '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>',
      '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>',
      '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
      '<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="p">}</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>',
      '<span class="w"> </span>',
      '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
      '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
      '<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="p">}</span>',
      '<span class="w"> </span>',
      '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
      '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
      '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
      '<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>',
      '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
      '<span class="w"> </span>',
      '<span class="c1"># model.to(device)</span>',
      '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>',
      '<span class="w"> </span>',
      '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">print_something</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">master_progress_bar</span> <span class="o">=</span> <span class="n">master_bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">))</span>',
      '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">master_progress_bar</span><span class="p">:</span>',
      '<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">master_progress_bar</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s1">&#39;</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="c1"># loss.backward()</span>',
      '<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
      '<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
      '<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
      '<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
      '<span class="w">    </span>',
      '<span class="w">    </span><span class="n">master_progress_bar</span><span class="o">.</span><span class="n">main_bar</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Validation accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>',
      '<span class="w"> </span>',
      '<span class="c1"># print(f&quot;Accuracy = {accuracy[&#39;accuracy&#39;]}&quot;)</span>',
      '<span class="n">print_something</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">:</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/04_accelerate_base_code_some_code_in_one_process.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Let's run it and see</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="o">%%</span><span class="n">time</span>',
      '<span class="w"> </span>',
      '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">04</span><span class="n">_accelerate_base_code_some_code_in_one_process</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Accuracy = 0.2098',
          'End of script with 0.2098 accuracy',
          'CPU times: user 1.38 s, sys: 197 ms, total: 1.58 s',
          'Wall time: 2min 22s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Now the print has only been executed once</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>However, although not visible much, the progress bars run in each process.</p>
      <p>I haven't found a way to avoid this with the progress bars from <code>fastprogress</code>, but I have with those from <code>tqdm</code>, so I'm going to replace the <code>fastprogress</code> progress bars with <code>tqdm</code> ones, and to make them run in a single process, you need to add the argument <code>disable=not accelerator.is_local_main_process</code></p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">05</span><span class="n">_accelerate_base_code_some_code_in_one_process</span><span class="o">.</span><span class="n">py</span>',
      '<span class="w"> </span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">tqdm</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Importamos e inicializamos Accelerator</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>',
      '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>',
      '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
      '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
      '<span class="w"> </span>',
      '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>',
      '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>',
      '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
      '<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="p">}</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>',
      '<span class="w"> </span>',
      '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
      '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
      '<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="p">}</span>',
      '<span class="w"> </span>',
      '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
      '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
      '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
      '<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>',
      '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
      '<span class="w"> </span>',
      '<span class="c1"># model.to(device)</span>',
      '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>',
      '<span class="w"> </span>',
      '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">print_something</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span class="w">    </span><span class="c1"># progress_bar_train = progress_bar(dataloader[&quot;train&quot;], parent=master_progress_bar)</span>',
      '<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
      '<span class="w">        </span><span class="c1"># master_progress_bar.child.comment = f&#39;loss: {loss}&#39;</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="c1"># loss.backward()</span>',
      '<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
      '<span class="w">    </span><span class="c1"># progress_bar_validation = progress_bar(dataloader[&quot;validation&quot;], parent=master_progress_bar)</span>',
      '<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
      '<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
      '<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
      '<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
      '<span class="w">    </span>',
      '<span class="c1"># print(f&quot;Accuracy = {accuracy[&#39;accuracy&#39;]}&quot;)</span>',
      '<span class="n">print_something</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">:</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/05_accelerate_base_code_some_code_in_one_process.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="o">%%</span><span class="n">time</span>',
      '<span class="w"> </span>',
      '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">05</span><span class="n">_accelerate_base_code_some_code_in_one_process</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '100%|█████████████████████████████████████████| 176/176 [02:01&amp;lt;00:00,  1.45it/s]',
          '100%|███████████████████████████████████████████| 20/20 [00:06&amp;lt;00:00,  3.30it/s]',
          'Accuracy = 0.2166',
          'End of script with 0.2166 accuracy',
          'CPU times: user 1.33 s, sys: 195 ms, total: 1.52 s',
          'Wall time: 2min 22s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We have shown an example of how to print in a single process, and this has been a way to execute processes in a single process. But if what you want is just to print in a single process, the <code>print</code> method from <code>accelerate</code> can be used. Let's see the same example as before with this method.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">06</span><span class="n">_accelerate_base_code_print_one_process</span><span class="o">.</span><span class="n">py</span>',
      '<span class="w"> </span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">tqdm</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Importamos e inicializamos Accelerator</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>',
      '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>',
      '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
      '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
      '<span class="w"> </span>',
      '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>',
      '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>',
      '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
      '<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="p">}</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>',
      '<span class="w"> </span>',
      '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
      '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
      '<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="p">}</span>',
      '<span class="w"> </span>',
      '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
      '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
      '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
      '<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>',
      '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
      '<span class="w"> </span>',
      '<span class="c1"># model.to(device)</span>',
      '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>',
      '<span class="w"> </span>',
      '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span class="w">    </span><span class="c1"># progress_bar_train = progress_bar(dataloader[&quot;train&quot;], parent=master_progress_bar)</span>',
      '<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
      '<span class="w">        </span><span class="c1"># master_progress_bar.child.comment = f&#39;loss: {loss}&#39;</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="c1"># loss.backward()</span>',
      '<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
      '<span class="w">    </span><span class="c1"># progress_bar_validation = progress_bar(dataloader[&quot;validation&quot;], parent=master_progress_bar)</span>',
      '<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
      '<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
      '<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
      '<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
      '<span class="w">    </span>',
      '<span class="c1"># print(f&quot;Accuracy = {accuracy[&#39;accuracy&#39;]}&quot;)</span>',
      '<span class="n">accelerator</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">:</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Writing accelerate_scripts/06_accelerate_base_code_print_one_process.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We run it</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="o">%%</span><span class="n">time</span>',
      '<span class="w"> </span>',
      '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">06</span><span class="n">_accelerate_base_code_print_one_process</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Map: 100%|██████████████████████| 45000/45000 [00:02&amp;lt;00:00, 15433.52 examples/s]',
          'Map: 100%|████████████████████████| 5000/5000 [00:00&amp;lt;00:00, 11406.61 examples/s]',
          'Map: 100%|██████████████████████| 45000/45000 [00:02&amp;lt;00:00, 15036.87 examples/s]',
          'Map: 100%|██████████████████████| 50000/50000 [00:03&amp;lt;00:00, 14932.76 examples/s]',
          'Map: 100%|██████████████████████| 50000/50000 [00:03&amp;lt;00:00, 14956.60 examples/s]',
          '100%|█████████████████████████████████████████| 176/176 [02:00&amp;lt;00:00,  1.46it/s]',
          '100%|███████████████████████████████████████████| 20/20 [00:05&amp;lt;00:00,  3.33it/s]',
          'Accuracy = 0.2134',
          'End of script with 0.2134 accuracy',
          'CPU times: user 1.4 s, sys: 189 ms, total: 1.59 s',
          'Wall time: 2min 27s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h4 id="Code Execution in All Processes">Code Execution in All Processes<a class="anchor-link" href="#Code Execution in All Processes"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 35" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>However, there is code that must run in all processes, for example, if we upload the checkpoints to the hub, so here we have two options: wrap the code in a function and decorate it with <code>accelerator.on_main_process</code></p>
      
      <section class="section-block-markdown-cell">
            <div class='highlight'><pre><code class="language-python">@accelerator.on_main_process<br>def do_my_thing():<br>"Something done once per server"<br>do_thing_once()</code></pre></div>
            </section>
      <p>or put the code inside an <code>if accelerator.is_main_process</code></p>
      
      <section class="section-block-markdown-cell">
            <div class='highlight'><pre><code class="language-python">if accelerator.is_main_process:<br>repo.push_to_hub()</code></pre></div>
            </section>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Since we are only doing training to showcase the <code>accelerate</code> library and the model we are training is not good, it doesn't make sense to upload the checkpoints to the hub right now, so I will do an example with <code>print</code>s.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">07</span><span class="n">_accelerate_base_code_some_code_in_all_process</span><span class="o">.</span><span class="n">py</span>',
      '<span class="w"> </span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">tqdm</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Importamos e inicializamos Accelerator</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>',
      '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>',
      '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
      '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
      '<span class="w"> </span>',
      '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>',
      '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>',
      '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
      '<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="p">}</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>',
      '<span class="w"> </span>',
      '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
      '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
      '<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="p">}</span>',
      '<span class="w"> </span>',
      '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
      '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
      '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
      '<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>',
      '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
      '<span class="w"> </span>',
      '<span class="c1"># model.to(device)</span>',
      '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>',
      '<span class="w"> </span>',
      '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">print_in_one_process</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_main_process</span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">print_in_all_processes</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="c1"># loss.backward()</span>',
      '<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
      '<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
      '<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
      '<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
      '<span class="w">    </span>',
      '<span class="n">print_in_one_process</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">:</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">print_in_all_processes</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;All process: Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">:</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;All process: End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/06_accelerate_base_code_some_code_in_all_process.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Let's run it to see</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="o">%%</span><span class="n">time</span>',
      '<span class="w"> </span>',
      '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">07</span><span class="n">_accelerate_base_code_some_code_in_all_process</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Map: 100%|██████████████████████| 45000/45000 [00:03&amp;lt;00:00, 14518.44 examples/s]',
          'Map: 100%|██████████████████████| 45000/45000 [00:03&amp;lt;00:00, 14368.77 examples/s]',
          'Map: 100%|████████████████████████| 5000/5000 [00:00&amp;lt;00:00, 16466.33 examples/s]',
          'Map: 100%|████████████████████████| 5000/5000 [00:00&amp;lt;00:00, 14806.14 examples/s]',
          'Map: 100%|██████████████████████| 50000/50000 [00:03&amp;lt;00:00, 14253.33 examples/s]',
          'Map: 100%|██████████████████████| 50000/50000 [00:03&amp;lt;00:00, 14337.07 examples/s]',
          '100%|█████████████████████████████████████████| 176/176 [02:00&amp;lt;00:00,  1.46it/s]',
          '100%|███████████████████████████████████████████| 20/20 [00:05&amp;lt;00:00,  3.34it/s]',
          'Accuracy = 0.2092',
          'End of script with 0.2092 accuracy',
          'All process: Accuracy = 0.2092',
          'All process: End of script with 0.2092 accuracy',
          'CPU times: user 1.42 s, sys: 216 ms, total: 1.64 s',
          'Wall time: 2min 27s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h4 id="Code Execution in Process X">Code Execution in Process X<a class="anchor-link" href="#Code Execution in Process X"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 36" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Finally, we can specify in which process we want to execute code. For this, we need to create a function and decorate it with <code>@accelerator.on_process(process_index=0)</code></p>
      
      <section class="section-block-markdown-cell">
            <div class='highlight'><pre><code class="language-python">@accelerator.on_process(process_index=0)<br>def do_my_thing():<br>"Something done on process index 0"<br>do_thing_on_index_zero()</code></pre></div>
            </section>
      <p>or decorate it with <code>@accelerator.on_local_process(local_process_idx=0)</code></p>
      
      <section class="section-block-markdown-cell">
            <div class='highlight'><pre><code class="language-python">@accelerator.on_local_process(local_process_index=0)def do_my_thing():<br>"Something done on process index 0 on each server"<br>do_thing_on_index_zero_on_each_server()</code></pre></div>
            </section>
      <p>Here I have put process 0, but any number can be put</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">08</span><span class="n">_accelerate_base_code_some_code_in_some_process</span><span class="o">.</span><span class="n">py</span>',
      '<span class="w"> </span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">tqdm</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Importamos e inicializamos Accelerator</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>',
      '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>',
      '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
      '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
      '<span class="w"> </span>',
      '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>',
      '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>',
      '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
      '<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="p">}</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>',
      '<span class="w"> </span>',
      '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
      '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
      '<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="p">}</span>',
      '<span class="w"> </span>',
      '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
      '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
      '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
      '<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>',
      '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
      '<span class="w"> </span>',
      '<span class="c1"># model.to(device)</span>',
      '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>',
      '<span class="w"> </span>',
      '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">print_in_one_process</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_main_process</span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">print_in_all_processes</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_process</span><span class="p">(</span><span class="n">process_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">print_in_process_0</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Process 0: &quot;</span> <span class="o">+</span> <span class="n">something</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_process</span><span class="p">(</span><span class="n">local_process_index</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">print_in_process_1</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Process 1: &quot;</span> <span class="o">+</span> <span class="n">something</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="c1"># loss.backward()</span>',
      '<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
      '<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
      '<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
      '<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
      '<span class="w">    </span>',
      '<span class="n">print_in_one_process</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">:</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">print_in_all_processes</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;All process: Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">:</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;All process: End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">print_in_process_0</span><span class="p">(</span><span class="s2">&quot;End of process 0&quot;</span><span class="p">)</span>',
      '<span class="n">print_in_process_1</span><span class="p">(</span><span class="s2">&quot;End of process 1&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/07_accelerate_base_code_some_code_in_some_process.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We run it</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="o">%%</span><span class="n">time</span>',
      '<span class="w"> </span>',
      '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">08</span><span class="n">_accelerate_base_code_some_code_in_some_process</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Map: 100%|████████████████████████| 5000/5000 [00:00&amp;lt;00:00, 15735.58 examples/s]',
          'Map: 100%|██████████████████████| 50000/50000 [00:03&amp;lt;00:00, 14906.20 examples/s]',
          '100%|█████████████████████████████████████████| 176/176 [02:02&amp;lt;00:00,  1.44it/s]',
          '100%|███████████████████████████████████████████| 20/20 [00:06&amp;lt;00:00,  3.27it/s]',
          'Process 1: End of process 1',
          'Accuracy = 0.2128',
          'End of script with 0.2128 accuracy',
          'All process: Accuracy = 0.2128',
          'All process: End of script with 0.2128 accuracy',
          'Process 0: End of process 0',
          'CPU times: user 1.42 s, sys: 295 ms, total: 1.71 s',
          'Wall time: 2min 37s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h4 id="Synchronizing Processes">Synchronizing Processes<a class="anchor-link" href="#Synchronizing Processes"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 37" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>If we have code that needs to run on all processes, it's interesting to wait for it to finish on all processes before doing another task, so for this we use <code>accelerator.wait_for_everyone()</code></p>
      <p>To see it, we are going to introduce a delay in one of the print functions in a process.</p>
      <p>I've also added a break in the training loop so that it doesn't train for too long, which isn't what we're interested in right now.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">09</span><span class="n">_accelerate_base_code_sync_all_process</span><span class="o">.</span><span class="n">py</span>',
      '<span class="w"> </span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">tqdm</span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Importamos e inicializamos Accelerator</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>',
      '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>',
      '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
      '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
      '<span class="w"> </span>',
      '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>',
      '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>',
      '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
      '<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="p">}</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>',
      '<span class="w"> </span>',
      '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
      '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
      '<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="p">}</span>',
      '<span class="w"> </span>',
      '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
      '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
      '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
      '<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>',
      '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
      '<span class="w"> </span>',
      '<span class="c1"># model.to(device)</span>',
      '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>',
      '<span class="w"> </span>',
      '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">print_in_one_process</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_main_process</span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">print_in_all_processes</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_process</span><span class="p">(</span><span class="n">process_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">print_in_process_0</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Process 0: &quot;</span> <span class="o">+</span> <span class="n">something</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_process</span><span class="p">(</span><span class="n">local_process_index</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">print_in_process_1</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Process 1: &quot;</span> <span class="o">+</span> <span class="n">something</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="c1"># loss.backward()</span>',
      '<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
      '<span class="w">        </span><span class="k">break</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
      '<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
      '<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
      '<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
      '<span class="w">    </span>',
      '<span class="n">print_in_one_process</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">:</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">print_in_all_processes</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;All process: Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">:</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;All process: End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">print_in_one_process</span><span class="p">(</span><span class="s2">&quot;Printing with delay in process 0&quot;</span><span class="p">)</span>',
      '<span class="n">print_in_process_0</span><span class="p">(</span><span class="s2">&quot;End of process 0&quot;</span><span class="p">)</span>',
      '<span class="n">print_in_process_1</span><span class="p">(</span><span class="s2">&quot;End of process 1&quot;</span><span class="p">)</span>',
      '<span class="n">accelerator</span><span class="o">.</span><span class="n">wait_for_everyone</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="n">print_in_one_process</span><span class="p">(</span><span class="s2">&quot;End of script&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/08_accelerate_base_code_sync_all_process.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We run it</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">09</span><span class="n">_accelerate_base_code_sync_all_process</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Map: 100%|████████████████████████| 5000/5000 [00:00&amp;lt;00:00, 14218.23 examples/s]',
          'Map: 100%|████████████████████████| 5000/5000 [00:00&amp;lt;00:00, 14666.25 examples/s]',
          '&#x20;&#x20;0%|                                                   | 0/176 [00:00&amp;lt;?, ?it/s]',
          '100%|███████████████████████████████████████████| 20/20 [00:05&amp;lt;00:00,  3.58it/s]',
          'Process 1: End of process 1',
          'Accuracy = 0.212',
          'End of script with 0.212 accuracy',
          'All process: Accuracy = 0.212',
          'All process: End of script with 0.212 accuracy',
          'Printing with delay in process 0',
          'Process 0: End of process 0',
          'End of script',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>As can be seen, first <code>Process 1: End of process 1</code> is printed and then the rest. This is because the remaining prints are either done in process 0 or in all processes, so until the 2-second delay we set is over, the rest of the code does not execute.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Save and load the state dict">Save and load the state dict<a class="anchor-link" href="#Save and load the state dict"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 38" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>When we train, sometimes we save the state so we can continue at another time.</p>
      <p>To save the state, we will have to use the methods <code>save_state()</code> and <code>load_state()</code></p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">10</span><span class="n">_accelerate_save_and_load_checkpoints</span><span class="o">.</span><span class="n">py</span>',
      '<span class="w"> </span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">tqdm</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Importamos e inicializamos Accelerator</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>',
      '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>',
      '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
      '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
      '<span class="w"> </span>',
      '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>',
      '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>',
      '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
      '<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="p">}</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>',
      '<span class="w"> </span>',
      '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
      '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
      '<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="p">}</span>',
      '<span class="w"> </span>',
      '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
      '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
      '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">print_something</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
      '<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>',
      '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
      '<span class="w"> </span>',
      '<span class="c1"># model.to(device)</span>',
      '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>',
      '<span class="w"> </span>',
      '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="c1"># loss.backward()</span>',
      '<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
      '<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
      '<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
      '<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="c1"># Guardamos los pesos</span>',
      '<span class="w">    </span><span class="n">accelerator</span><span class="o">.</span><span class="n">save_state</span><span class="p">(</span><span class="s2">&quot;accelerate_scripts/checkpoints&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">print_something</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Cargamos los pesos</span>',
      '<span class="n">accelerator</span><span class="o">.</span><span class="n">load_state</span><span class="p">(</span><span class="s2">&quot;accelerate_scripts/checkpoints&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/09_accelerate_save_and_load_checkpoints.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We run it</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">10</span><span class="n">_accelerate_save_and_load_checkpoints</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '100%|█████████████████████████████████████████| 176/176 [01:58&amp;lt;00:00,  1.48it/s]',
          '100%|███████████████████████████████████████████| 20/20 [00:05&amp;lt;00:00,  3.40it/s]',
          'Accuracy = 0.2142',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Save the model">Save the model<a class="anchor-link" href="#Save the model"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 39" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>When the <code>prepare</code> method was used, the model was wrapped to be able to save it to the necessary devices. Therefore, when saving it, we need to use the <code>save_model</code> method, which first unwraps it and then saves it. Additionally, if we use the parameter <code>safe_serialization=True</code>, the model will be saved as a <code>safe tensor</code>.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">11</span><span class="n">_accelerate_save_model</span><span class="o">.</span><span class="n">py</span>',
      '<span class="w"> </span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">tqdm</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Importamos e inicializamos Accelerator</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>',
      '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>',
      '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
      '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
      '<span class="w"> </span>',
      '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>',
      '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>',
      '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
      '<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="p">}</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>',
      '<span class="w"> </span>',
      '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
      '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
      '<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="p">}</span>',
      '<span class="w"> </span>',
      '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
      '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
      '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">print_something</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
      '<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>',
      '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
      '<span class="w"> </span>',
      '<span class="c1"># model.to(device)</span>',
      '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>',
      '<span class="w"> </span>',
      '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="c1"># loss.backward()</span>',
      '<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
      '<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
      '<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
      '<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="c1"># Guardamos el modelo</span>',
      '<span class="w">    </span><span class="n">accelerator</span><span class="o">.</span><span class="n">wait_for_everyone</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">accelerator</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;accelerate_scripts/model&quot;</span><span class="p">,</span> <span class="n">safe_serialization</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">print_something</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Writing accelerate_scripts/11_accelerate_save_model.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We run it</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">11</span><span class="n">_accelerate_save_model</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '100%|█████████████████████████████████████████| 176/176 [01:58&amp;lt;00:00,  1.48it/s]',
          '100%|███████████████████████████████████████████| 20/20 [00:05&amp;lt;00:00,  3.35it/s]',
          'Accuracy = 0.214',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3>Save the <code>pretrained</code> model</h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>In models that use the <code>transformers</code> library, we must save the model using the <code>save_pretrained</code> method to be able to load it with the <code>from_pretrained</code> method. Before saving it, you need to unwrap it using the <code>unwrap_model</code> method.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">12</span><span class="n">_accelerate_save_pretrained</span><span class="o">.</span><span class="n">py</span>',
      '<span class="w"> </span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">tqdm</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Importamos e inicializamos Accelerator</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>',
      '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>',
      '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
      '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
      '<span class="w"> </span>',
      '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>',
      '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>',
      '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
      '<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="p">}</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>',
      '<span class="w"> </span>',
      '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
      '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
      '<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="p">}</span>',
      '<span class="w"> </span>',
      '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
      '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
      '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">print_something</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
      '<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>',
      '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
      '<span class="w"> </span>',
      '<span class="c1"># model.to(device)</span>',
      '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>',
      '<span class="w"> </span>',
      '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="c1"># loss.backward()</span>',
      '<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
      '<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
      '<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
      '<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="c1"># Guardamos el modelo pretrained</span>',
      '<span class="w">    </span><span class="n">unwrapped_model</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">unwrap_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">unwrapped_model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span>',
      '<span class="w">        </span><span class="s2">&quot;accelerate_scripts/model_pretrained&quot;</span><span class="p">,</span>',
      '<span class="w">        </span><span class="n">is_main_process</span><span class="o">=</span><span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">,</span>',
      '<span class="w">        </span><span class="n">save_function</span><span class="o">=</span><span class="n">accelerator</span><span class="o">.</span><span class="n">save</span><span class="p">,</span>',
      '<span class="w">    </span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">print_something</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Writing accelerate_scripts/11_accelerate_save_pretrained.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We run it</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">12</span><span class="n">_accelerate_save_pretrained</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Map: 100%|██████████████████████| 45000/45000 [00:02&amp;lt;00:00, 15152.47 examples/s]',
          'Map: 100%|██████████████████████| 45000/45000 [00:02&amp;lt;00:00, 15119.13 examples/s]',
          'Map: 100%|████████████████████████| 5000/5000 [00:00&amp;lt;00:00, 12724.70 examples/s]',
          'Map: 100%|████████████████████████| 5000/5000 [00:00&amp;lt;00:00, 12397.49 examples/s]',
          'Map: 100%|██████████████████████| 50000/50000 [00:03&amp;lt;00:00, 15247.21 examples/s]',
          'Map: 100%|██████████████████████| 50000/50000 [00:03&amp;lt;00:00, 15138.03 examples/s]',
          '100%|█████████████████████████████████████████| 176/176 [01:59&amp;lt;00:00,  1.48it/s]',
          '100%|███████████████████████████████████████████| 20/20 [00:05&amp;lt;00:00,  3.37it/s]',
          'Accuracy = 0.21',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Now we could load it</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModel</span>',
      '<span class="w"> </span>',
      '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;accelerate_scripts/model_pretrained&quot;</span>',
      '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Some weights of RobertaModel were not initialized from the model checkpoint at accelerate_scripts/model_pretrained and are newly initialized: [&#x27;roberta.pooler.dense.bias&#x27;, &#x27;roberta.pooler.dense.weight&#x27;]',
          'You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Training in notebooks">Training in notebooks<a class="anchor-link" href="#Training in notebooks"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 40" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>So far we have seen how to run scripts, but if you want to run the code in a notebook, we can write the same code as before, but encapsulated in a function</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>First we import the libraries</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">tqdm</span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>',
      '<span class="c1"># from accelerate import Accelerator</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Now we create the function</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">def</span><span class="w"> </span><span class="nf">train_code</span><span class="p">(</span><span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span><span class="p">):</span>',
      '<span class="w">    </span><span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>',
      '<span class="w">    </span><span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>',
      '<span class="w">    </span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
      '<span class="w">        </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
      '<span class="w">        </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="w">        </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="w">        </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="w">    </span><span class="p">}</span>',
      '<span class="w">    </span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>',
      '<span class="w">    </span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>',
      '<span class="w">    </span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="n">BS</span> <span class="o">=</span> <span class="n">batch_size</span>',
      '<span class="w">    </span><span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
      '<span class="w">        </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="w">        </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="w">        </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="w">    </span><span class="p">}</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
      '<span class="w">    </span><span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>',
      '<span class="w">    </span><span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="c1"># model.to(device)</span>',
      '<span class="w">    </span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
      '<span class="w">        </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span class="w">        </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
      '<span class="w">        </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
      '<span class="w">            </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="w">            </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">            </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">            </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w"> </span>',
      '<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '<span class="w">            </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">            </span><span class="c1"># loss.backward()</span>',
      '<span class="w">            </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
      '<span class="w">            </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
      '<span class="w">        </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
      '<span class="w">        </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
      '<span class="w">            </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">            </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">            </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w"> </span>',
      '<span class="w">            </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
      '<span class="w">                </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '<span class="w">            </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
      '<span class="w">            </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
      '<span class="w">            </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
      '<span class="w">            </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">            </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
      '<span class="w">        </span>',
      '<span class="w">    </span><span class="n">accelerator</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>To run the training in the notebook, we use the <code>notebook_launcher</code> function, to which we pass the function we want to execute, the arguments of that function, and the number of GPUs on which we will train using the <code>num_processes</code> variable.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">notebook_launcher</span>',
      '<span class="w"> </span>',
      '<span class="n">args</span> <span class="o">=</span> <span class="p">(</span><span class="mi">128</span><span class="p">,)</span>',
      '<span class="n">notebook_launcher</span><span class="p">(</span><span class="n">train_code</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">num_processes</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Launching training on 2 GPUs.',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockOutputCell
        text={[
          '100%|██████████| 176/176 [02:01&amp;lt;00:00,  1.45it/s]',
          '100%|██████████| 20/20 [00:06&amp;lt;00:00,  3.31it/s]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockOutputCell
        text={[
          'Accuracy = 0.2112',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Training in FP16">Training in FP16<a class="anchor-link" href="#Training in FP16"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 41" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>When we first set up <code>accelerate</code>, it asked us <code>Do you wish to use FP16 or BF16 (mixed precision)?</code> and we said no, so now we are going to tell it yes, that we want FP16.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>So far we have trained in FP32, which means that each weight of the model is a 32-bit floating-point number, and now we are going to use a 16-bit floating-point number, meaning the model will take up less space. As a result, two things will happen: we will be able to use a larger batch size, and it will also be faster.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>First we run <code>accelerate config</code> again and tell it that we want FP16</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="err">!</span><span class="n">accelerate</span> <span class="n">config</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '--------------------------------------------------------------------------------',
          'In which compute environment are you running?',
          'This machine',
          '--------------------------------------------------------------------------------',
          'multi-GPU',
          'How many different machines will you use (use more than 1 for multi-node training)? [1]: 1',
          'Should distributed operations be checked while running for errors? This can avoid timeout issues but will be slower. [yes/NO]: no',
          'Do you wish to optimize your script with torch dynamo?[yes/NO]:no',
          'Do you want to use DeepSpeed? [yes/NO]: no',
          'Do you want to use FullyShardedDataParallel? [yes/NO]: no',
          'Do you want to use Megatron-LM ? [yes/NO]: no',
          'How many GPU(s) should be used for distributed training? [1]:2',
          'What GPU(s) (by id) should be used for training on this machine as a comma-seperated list? [all]:0,1',
          '--------------------------------------------------------------------------------',
          'Do you wish to use FP16 or BF16 (mixed precision)?',
          'fp16',
          'accelerate configuration saved at ~/.cache/huggingface/accelerate/default_config.yaml',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Now we create a script to train, with the same batch size as before, to see if it takes less time to train</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">13</span><span class="n">_accelerate_base_code_fp16_bs128</span><span class="o">.</span><span class="n">py</span>',
      '<span class="w"> </span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">tqdm</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Importamos e inicializamos Accelerator</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>',
      '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>',
      '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
      '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
      '<span class="w"> </span>',
      '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>',
      '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>',
      '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
      '<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="p">}</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>',
      '<span class="w"> </span>',
      '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
      '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
      '<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="p">}</span>',
      '<span class="w"> </span>',
      '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
      '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
      '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
      '<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>',
      '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
      '<span class="w"> </span>',
      '<span class="c1"># model.to(device)</span>',
      '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>',
      '<span class="w"> </span>',
      '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="c1"># loss.backward()</span>',
      '<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
      '<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
      '<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
      '<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
      '<span class="w">    </span>',
      '<span class="n">accelerator</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/12_accelerate_base_code_fp16_bs128.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Let's run it to see how long it takes</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="o">%%</span><span class="n">time</span>',
      '<span class="w"> </span>',
      '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">13</span><span class="n">_accelerate_base_code_fp16_bs128</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Map: 100%|████████████████████████| 5000/5000 [00:00&amp;lt;00:00, 14983.76 examples/s]',
          'Map: 100%|██████████████████████| 50000/50000 [00:03&amp;lt;00:00, 14315.47 examples/s]',
          '100%|█████████████████████████████████████████| 176/176 [01:01&amp;lt;00:00,  2.88it/s]',
          '100%|███████████████████████████████████████████| 20/20 [00:02&amp;lt;00:00,  6.84it/s]',
          'Accuracy = 0.2094',
          'CPU times: user 812 ms, sys: 163 ms, total: 976 ms',
          'Wall time: 1min 27s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>When we ran this training in FP32 it took about 2 and a half minutes, and now roughly 1 and a half minutes. Let's see if instead of training with a batch size of 128, we do it with one of 256.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">14</span><span class="n">_accelerate_base_code_fp16_bs256</span><span class="o">.</span><span class="n">py</span>',
      '<span class="w"> </span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">tqdm</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Importamos e inicializamos Accelerator</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>',
      '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>',
      '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
      '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
      '<span class="w"> </span>',
      '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>',
      '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>',
      '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
      '<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="p">}</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>',
      '<span class="w"> </span>',
      '<span class="n">BS</span> <span class="o">=</span> <span class="mi">256</span>',
      '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
      '<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="p">}</span>',
      '<span class="w"> </span>',
      '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
      '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
      '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
      '<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>',
      '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
      '<span class="w"> </span>',
      '<span class="c1"># model.to(device)</span>',
      '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>',
      '<span class="w"> </span>',
      '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="c1"># loss.backward()</span>',
      '<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
      '<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
      '<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
      '<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
      '<span class="w">    </span>',
      '<span class="n">accelerator</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/13_accelerate_base_code_fp16_bs256.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We run it</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="o">%%</span><span class="n">time</span>',
      '<span class="w"> </span>',
      '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">14</span><span class="n">_accelerate_base_code_fp16_bs256</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Map: 100%|████████████████████████| 5000/5000 [00:00&amp;lt;00:00, 15390.30 examples/s]',
          'Map: 100%|████████████████████████| 5000/5000 [00:00&amp;lt;00:00, 14990.92 examples/s]',
          '100%|███████████████████████████████████████████| 88/88 [00:54&amp;lt;00:00,  1.62it/s]',
          '100%|███████████████████████████████████████████| 10/10 [00:02&amp;lt;00:00,  3.45it/s]',
          'Accuracy = 0.2236',
          'CPU times: user 670 ms, sys: 91.6 ms, total: 761 ms',
          'Wall time: 1min 12s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>It has only dropped by about 15 seconds</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Training in BF16">Training in BF16<a class="anchor-link" href="#Training in BF16"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 42" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>We have previously trained in FP16 and now we are going to do it in BF16, what is the difference?</p>
      <img decoding="async" onerror="this.parentNode.removeChild(this)" src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/FP32_FP16_BF16.webp" alt="FP32_FP16_BF16">
      <p>As we can see in the image, while FP16 compared to FP32 has fewer bits in the mantissa and the exponent, which makes its range much smaller, BF16 compared to FP32 has the same number of bits for the exponent but fewer in the mantissa, which means that BF16 has the same range of numbers as FP32, but is less precise.</p>
      <p>This is beneficial because in FP16 some calculations could result in very high numbers, which cannot be represented in the FP16 format. Additionally, there are certain HW devices that are optimized for this format.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Just like before, we run <code>accelerate config</code> and indicate that we want BF16</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="err">!</span><span class="n">accelerate</span> <span class="n">config</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '--------------------------------------------------------------------------------',
          'In which compute environment are you running?',
          'This machine',
          '--------------------------------------------------------------------------------',
          'multi-GPU',
          'How many different machines will you use (use more than 1 for multi-node training)? [1]: 1',
          'Should distributed operations be checked while running for errors? This can avoid timeout issues but will be slower. [yes/NO]: no',
          'Do you wish to optimize your script with torch dynamo?[yes/NO]:no',
          'Do you want to use DeepSpeed? [yes/NO]: no',
          'Do you want to use FullyShardedDataParallel? [yes/NO]: no',
          'Do you want to use Megatron-LM ? [yes/NO]: no',
          'How many GPU(s) should be used for distributed training? [1]:2',
          'What GPU(s) (by id) should be used for training on this machine as a comma-seperated list? [all]:0,1',
          '--------------------------------------------------------------------------------',
          'Do you wish to use FP16 or BF16 (mixed precision)?',
          'bf16',
          'accelerate configuration saved at ~/.cache/huggingface/accelerate/default_config.yaml',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Now we run the last script we created, that is, with a batch size of 256</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="o">%%</span><span class="n">time</span>',
      '<span class="w"> </span>',
      '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">14</span><span class="n">_accelerate_base_code_fp16_bs256</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Map: 100%|██████████████████████| 50000/50000 [00:03&amp;lt;00:00, 14814.95 examples/s]',
          'Map: 100%|██████████████████████| 50000/50000 [00:03&amp;lt;00:00, 14506.83 examples/s]',
          '100%|███████████████████████████████████████████| 88/88 [00:51&amp;lt;00:00,  1.70it/s]',
          '100%|███████████████████████████████████████████| 10/10 [00:03&amp;lt;00:00,  3.21it/s]',
          'Accuracy = 0.2112',
          'CPU times: user 688 ms, sys: 144 ms, total: 832 ms',
          'Wall time: 1min 17s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>It took a similar amount of time as before, which is normal since we trained a model with 16-bit weights, just like before.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Training in FP8">Training in FP8<a class="anchor-link" href="#Training in FP8"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 43" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Now we are going to train in FP8 format, which, as the name suggests, is a floating-point format where each weight has 8 bits, so we run <code>accelerate config</code> to tell it that we want FP8</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="err">!</span><span class="n">accelerate</span> <span class="n">config</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '--------------------------------------------------------------------------------',
          'In which compute environment are you running?',
          'This machine',
          '--------------------------------------------------------------------------------',
          'multi-GPU',
          'How many different machines will you use (use more than 1 for multi-node training)? [1]: 1',
          'Should distributed operations be checked while running for errors? This can avoid timeout issues but will be slower. [yes/NO]: no',
          'Do you wish to optimize your script with torch dynamo?[yes/NO]:no',
          'Do you want to use DeepSpeed? [yes/NO]: no',
          'Do you want to use FullyShardedDataParallel? [yes/NO]: no',
          'Do you want to use Megatron-LM ? [yes/NO]: no',
          'How many GPU(s) should be used for distributed training? [1]:2',
          'What GPU(s) (by id) should be used for training on this machine as a comma-seperated list? [all]:0,1',
          '--------------------------------------------------------------------------------',
          'Do you wish to use FP16 or BF16 (mixed precision)?',
          'fp8',
          'accelerate configuration saved at ~/.cache/huggingface/accelerate/default_config.yaml',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Now we run the last script, the one with a batch size of 256</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="o">%%</span><span class="n">time</span>',
      '<span class="w"> </span>',
      '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">14</span><span class="n">_accelerate_base_code_fp16_bs256</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Traceback (most recent call last):',
          '&#x20;&#x20;File &quot;/home/wallabot/Documentos/web/portafolio/posts/accelerate_scripts/13_accelerate_base_code_fp16_bs256.py&quot;, line 12, in &amp;lt;module&amp;gt;',
          '&#x20;&#x20;&#x20;&#x20;accelerator = Accelerator()',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;^^^^^^^^^^^^^',
          '&#x20;&#x20;File &quot;/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/accelerator.py&quot;, line 371, in __init__',
          '&#x20;&#x20;&#x20;&#x20;self.state = AcceleratorState(',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;^^^^^^^^^^^^^^^^^',
          '&#x20;&#x20;File &quot;/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/state.py&quot;, line 790, in __init__',
          '&#x20;&#x20;&#x20;&#x20;raise ValueError(',
          'ValueError: Using `fp8` precision requires `transformer_engine` or `MS-AMP` to be installed.',
          'Traceback (most recent call last):',
          '&#x20;&#x20;File &quot;/home/wallabot/Documentos/web/portafolio/posts/accelerate_scripts/13_accelerate_base_code_fp16_bs256.py&quot;, line 12, in &amp;lt;module&amp;gt;',
          '&#x20;&#x20;&#x20;&#x20;accelerator = Accelerator()',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;^^^^^^^^^^^^^',
          '&#x20;&#x20;File &quot;/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/accelerator.py&quot;, line 371, in __init__',
          '&#x20;&#x20;&#x20;&#x20;self.state = AcceleratorState(',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;^^^^^^^^^^^^^^^^^',
          '&#x20;&#x20;File &quot;/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/state.py&quot;, line 790, in __init__',
          '&#x20;&#x20;&#x20;&#x20;raise ValueError(',
          'ValueError: Using `fp8` precision requires `transformer_engine` or `MS-AMP` to be installed.',
          '[2024-05-13 21:40:56,455] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 501480) of binary: /home/wallabot/miniconda3/envs/nlp/bin/python',
          'Traceback (most recent call last):',
          '&#x20;&#x20;File &quot;/home/wallabot/miniconda3/envs/nlp/bin/accelerate&quot;, line 8, in &amp;lt;module&amp;gt;',
          '&#x20;&#x20;&#x20;&#x20;sys.exit(main())',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;^^^^^^',
          '&#x20;&#x20;File &quot;/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/commands/accelerate_cli.py&quot;, line 46, in main',
          '&#x20;&#x20;&#x20;&#x20;args.func(args)',
          '&#x20;&#x20;File &quot;/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/commands/launch.py&quot;, line 1048, in launch_command',
          '&#x20;&#x20;&#x20;&#x20;multi_gpu_launcher(args)',
          '&#x20;&#x20;File &quot;/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/commands/launch.py&quot;, line 702, in multi_gpu_launcher',
          '&#x20;&#x20;&#x20;&#x20;distrib_run.run(args)',
          '&#x20;&#x20;File &quot;/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/distributed/run.py&quot;, line 803, in run',
          '&#x20;&#x20;&#x20;&#x20;elastic_launch(',
          '&#x20;&#x20;File &quot;/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/distributed/launcher/api.py&quot;, line 135, in __call__',
          '&#x20;&#x20;&#x20;&#x20;return launch_agent(self._config, self._entrypoint, list(args))',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^',
          '&#x20;&#x20;File &quot;/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/distributed/launcher/api.py&quot;, line 268, in launch_agent',
          '&#x20;&#x20;&#x20;&#x20;raise ChildFailedError(',
          'torch.distributed.elastic.multiprocessing.errors.ChildFailedError:',
          '============================================================',
          'accelerate_scripts/13_accelerate_base_code_fp16_bs256.py FAILED',
          '------------------------------------------------------------',
          'Failures:',
          '[1]:',
          '&#x20;&#x20;time      : 2024-05-13_21:40:56',
          '&#x20;&#x20;host      : wallabot',
          '&#x20;&#x20;rank      : 1 (local_rank: 1)',
          '&#x20;&#x20;exitcode  : 1 (pid: 501481)',
          '&#x20;&#x20;error_file: &amp;lt;N/A&amp;gt;',
          '&#x20;&#x20;traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html',
          '------------------------------------------------------------',
          'Root Cause (first observed failure):',
          '[0]:',
          '&#x20;&#x20;time      : 2024-05-13_21:40:56',
          '&#x20;&#x20;host      : wallabot',
          '&#x20;&#x20;rank      : 0 (local_rank: 0)',
          '&#x20;&#x20;exitcode  : 1 (pid: 501480)',
          '&#x20;&#x20;error_file: &amp;lt;N/A&amp;gt;',
          '&#x20;&#x20;traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html',
          '============================================================',
          'CPU times: user 65.1 ms, sys: 14.5 ms, total: 79.6 ms',
          'Wall time: 7.24 s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Since the weights are now 8-bit and take up half the memory, we will increase the batch size to 512.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">15</span><span class="n">_accelerate_base_code_fp8_bs512</span><span class="o">.</span><span class="n">py</span>',
      '<span class="w"> </span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">tqdm</span>',
      '<span class="w"> </span>',
      '<span class="c1"># Importamos e inicializamos Accelerator</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>',
      '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>',
      '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
      '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
      '<span class="w"> </span>',
      '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>',
      '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>',
      '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
      '<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>',
      '<span class="p">}</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>',
      '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>',
      '<span class="w"> </span>',
      '<span class="n">BS</span> <span class="o">=</span> <span class="mi">512</span>',
      '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
      '<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '<span class="p">}</span>',
      '<span class="w"> </span>',
      '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
      '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
      '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
      '<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>',
      '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
      '<span class="w"> </span>',
      '<span class="c1"># model.to(device)</span>',
      '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>',
      '<span class="w"> </span>',
      '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="c1"># loss.backward()</span>',
      '<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
      '<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
      '<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
      '<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
      '<span class="w">    </span>',
      '<span class="n">accelerator</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Writing accelerate_scripts/15_accelerate_base_code_fp8_bs512.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We run it</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="o">%%</span><span class="n">time</span>',
      '<span class="w"> </span>',
      '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">15</span><span class="n">_accelerate_base_code_fp8_bs512</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <h2 id="Model Inference">Model Inference<a class="anchor-link" href="#Model Inference"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 44" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Usage of the Hugging Face Ecosystem">Usage of the Hugging Face Ecosystem<a class="anchor-link" href="#Usage of the Hugging Face Ecosystem"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 45" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Let's see how to perform inference with large models using the <code>transformers</code> library from Hugging Face.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h4>Inference with <code>pipeline</code></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>If we use the Hugging Face ecosystem, it's very simple, as everything happens under the hood without us having to do much. In the case of using <code>pipeline</code>, which is the easiest way to perform inference with the <code>transformers</code> library, we just need to specify the model we want to use and, importantly, pass <code>device_map=&quot;auto&quot;</code>. This will make <code>accelerate</code> distribute the model across different GPUs, CPU RAM, or hard drive if necessary.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>There are more possible values for <code>device_map</code>, which we will see later, but for now stick with <code>&quot;auto&quot;</code>.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>We are going to use the <code>Llama3 8B</code> model, which, as its name suggests, is a model with around 8 billion parameters. Since each parameter by default is in FP32 format, which corresponds to 4 bytes (32 bits), this means that if we multiply 8 billion parameters by 4 bytes, we get that it would require a GPU with around 32 GB of VRAM.</p>
      <p>In my case, I have 2 GPUs with 24 GB of VRAM each, so it wouldn't fit into a single GPU. But thanks to setting <code>device_map=&quot;auto&quot;</code>, accelerate will distribute the model across both GPUs and I will be able to perform inference.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">16</span><span class="n">_inference_with_pipeline</span><span class="o">.</span><span class="n">py</span>',
      '<span class="w"> </span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">pipeline</span>',
      '<span class="w"> </span>',
      '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;meta-llama/Meta-Llama-3-8B-Instruct&quot;</span>',
      '<span class="n">generator</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">checkpoints</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;Conoces accelerate de hugging face?&quot;</span>',
      '<span class="n">output</span> <span class="o">=</span> <span class="n">generator</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>',
      '<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/09_inference_with_pipeline.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Now we run it, only as the pipeline uses accelerate under the hood, we don't need to run it with <code>accelerate launch script.py</code> but instead with <code>python script.py</code>.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="err">!</span><span class="n">python</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">16</span><span class="n">_inference_with_pipeline</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Loading checkpoint shards: 100%|██████████████████| 4/4 [00:09&amp;lt;00:00,  2.27s/it]',
          'Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.',
          'Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.',
          '[&#x7B;&#x27;generated_text&#x27;: &#x27;Conoces accelerate de hugging face? ¿Qué es el modelo de lenguaje de transformers y cómo se utiliza en el marco de hugging face? ¿Cómo puedo utilizar modelos de lenguaje de transformers en mi aplicación? ¿Qué son los tokenizers y cómo se utilizan en el marco de hugging face? ¿Cómo puedo crear un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los datasets y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar datasets para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning&#x27;&#x7D;]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>As can be seen, it has not responded, but has continued to ask questions. This is because Llama3 is a language model that predicts the next token, so with the prompt I passed it, it considered that the next best tokens were ones that correspond to more questions. This makes sense because sometimes people have doubts about a topic and generate many questions, so to get it to answer the question, we need to condition it a bit.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">17</span><span class="n">_inference_with_pipeline_condition</span><span class="o">.</span><span class="n">py</span>',
      '<span class="w"> </span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">pipeline</span>',
      '<span class="w"> </span>',
      '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;meta-llama/Meta-Llama-3-8B-Instruct&quot;</span>',
      '<span class="n">generator</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">checkpoints</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;Conoces accelerate de hugging face?&quot;</span>',
      '<span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>',
      '<span class="w">    </span><span class="p">{</span>',
      '<span class="w">        </span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span>',
      '<span class="w">        </span><span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;Eres un chatbot amigable que siempre intenta solucionar las dudas&quot;</span><span class="p">,</span>',
      '<span class="w">    </span><span class="p">},</span>',
      '<span class="w">    </span><span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prompt</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">},</span>',
      '<span class="p">]</span>',
      '<span class="n">output</span> <span class="o">=</span> <span class="n">generator</span><span class="p">(</span><span class="n">messages</span><span class="p">)</span>',
      '<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;generated_text&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/10_inference_with_pipeline_condition.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>As you can see, a message has been generated with roles, conditioning the model and with the prompt</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="err">!</span><span class="n">python</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">17</span><span class="n">_inference_with_pipeline_condition</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Loading checkpoint shards: 100%|██████████████████| 4/4 [00:09&amp;lt;00:00,  2.41s/it]',
          'Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.',
          'Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.',
          '&#x7B;&#x27;role&#x27;: &#x27;assistant&#x27;, &#x27;content&#x27;: &#x27;¡Hola!\n\nSí, conozco Accelerate de Hugging Face. Accelerate es una biblioteca de Python desarrollada por Hugging Face que se enfoca en simplificar y acelerar el entrenamiento y la evaluación de modelos de lenguaje en diferentes dispositivos y entornos.\n\nCon Accelerate, puedes entrenar modelos de lenguaje en diferentes plataformas y dispositivos, como GPUs, TPUs, CPUs y servidores, sin necesidad de cambiar el código de tu modelo. Esto te permite aprovechar al máximo la potencia de cálculo de tus dispositivos y reducir el tiempo de entrenamiento.\n\nAccelerate también ofrece varias características adicionales, como:\n\n* Soporte para diferentes frameworks de machine learning, como TensorFlow, PyTorch y JAX.\n* Integración con diferentes sistemas de almacenamiento y procesamiento de datos, como Amazon S3 y Google Cloud Storage.\n* Soporte para diferentes protocolos de comunicación, como HTTP y gRPC.\n* Herramientas para monitorear y depurar tus modelos en tiempo real.\n\nEn resumen, Accelerate es una herramienta muy útil para desarrolladores de modelos de lenguaje que buscan simplificar y acelerar el proceso de entrenamiento y evaluación de sus modelos.\n\n¿Tienes alguna pregunta específica sobre Accelerate o necesitas ayuda para implementarlo en tu proyecto?&#x27;&#x7D;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Now the response does answer our prompt</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h4>Inference with <code>AutoClass</code></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Lastly, we will see how to perform inference using only <code>AutoClass</code>.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">18</span><span class="n">_inference_with_autoclass</span><span class="o">.</span><span class="n">py</span>',
      '<span class="w"> </span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">TextStreamer</span>',
      '<span class="w"> </span>',
      '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;meta-llama/Meta-Llama-3-8B-Instruct&quot;</span>',
      '<span class="w"> </span>',
      '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>',
      '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>',
      '<span class="n">streamer</span> <span class="o">=</span> <span class="n">TextStreamer</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;Conoces accelerate de hugging face?&quot;</span>',
      '<span class="n">tokens_input</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">([</span><span class="n">prompt</span><span class="p">],</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="o">**</span><span class="n">tokens_input</span><span class="p">,</span> <span class="n">streamer</span><span class="o">=</span><span class="n">streamer</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">do_sample</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">top_p</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/11_inference_with_autoclass.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>As can be seen, the <code>streamer</code> object has been created and is then passed to the model's <code>generate</code> method. This is useful for printing each word as it is generated, rather than waiting for the entire output to be generated before printing it.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="err">!</span><span class="n">python</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">18</span><span class="n">_inference_with_autoclass</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.',
          'Loading checkpoint shards: 100%|██████████████████| 4/4 [00:09&amp;lt;00:00,  2.28s/it]',
          'Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.',
          '&amp;lt;|begin_of_text|&amp;gt;Conoces accelerate de hugging face? Si es así, puedes utilizar la biblioteca `transformers` de Hugging Face para crear un modelo de lenguaje que pueda predecir la siguiente palabra en una secuencia de texto.',
          'Aquí te muestro un ejemplo de cómo hacerlo:',
          '```',
          'import pandas as pd',
          'import torch',
          'from transformers import AutoModelForSequenceClassification, AutoTokenizer',
          '# Cargar el modelo y el tokenizador',
          'model_name = &quot;bert-base-uncased&quot;',
          'model = AutoModelForSequenceClassification.from_pretrained(model_name)',
          'tokenizer = AutoTokenizer.from_pretrained(model_name)',
          '# Cargar el conjunto de datos',
          'train_df = pd.read_csv(&quot;train.csv&quot;)',
          'test_df = pd.read_csv(&quot;test.csv&quot;)',
          '# Preprocesar los datos',
          'train_texts = train_df[&quot;text&quot;]',
          'train_labels = train_df[&quot;label&quot;]',
          'test_texts = test_df[&quot;text&quot;]',
          '# Convertir los textos en entradas para el modelo',
          'train_encodings = tokenizer.batch_encode_plus(train_texts,',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;add_special_tokens=True,',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;max_length=512,',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;return_attention_mask=True,',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;return_tensors=&#x27;pt&#x27;)',
          'test_encodings = tokenizer.batch_encode_plus(test_texts,',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;add_special_tokens=True,',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;max_length=512,',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;return_attention_mask=True,',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;return_tensors=&#x27;pt&#x27;)',
          '# Crear un dataloader para entrenar el modelo',
          'train_dataset = torch.utils.data.TensorDataset(train_encodings[&quot;input_ids&quot;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;train_encodings[&quot;attention_mask&quot;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;torch.tensor(train_labels))',
          'train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)',
          '# Entrenar el modelo',
          'device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)',
          'model.to(device)',
          'criterion = torch.nn.CrossEntropyLoss()',
          'optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)',
          'for epoch in range(5):',
          '&#x20;&#x20;&#x20;&#x20;model.train()',
          '&#x20;&#x20;&#x20;&#x20;total_loss = 0',
          '&#x20;&#x20;&#x20;&#x20;for batch in train_loader:',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;input_ids = batch[0].to(device)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;attention_mask = batch[1].to(device)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;labels = batch[2].to(device)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;optimizer.zero_grad()',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;outputs = model(input_ids, attention_mask=attention_mask, labels=labels)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;loss = criterion(outputs, labels)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;loss.backward()',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;optimizer.step()',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;total_loss += loss.item()',
          '&#x20;&#x20;&#x20;&#x20;print(f&quot;Epoch &#x7B;epoch+1&#x7D;, Loss: &#x7B;total',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Use PyTorch">Use PyTorch<a class="anchor-link" href="#Use PyTorch"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 46" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Normally, the way to make inferences with PyTorch is to create a model with randomly initialized weights and then load a <code>state dict</code> with the pretrained model's weights. So, to get that <code>state dict</code>, we'll first take a small shortcut and download it.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">torchvision.models</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">models</span>',
      '<span class="w"> </span>',
      '<span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet152</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">models</span><span class="o">.</span><span class="n">ResNet152_Weights</span><span class="o">.</span><span class="n">IMAGENET1K_V1</span><span class="p">)</span>',
      '<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">&#39;accelerate_scripts/resnet152_pretrained.pth&#39;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Downloading: &quot;https://download.pytorch.org/models/resnet152-394f9c45.pth&quot; to /home/maximo.fernandez/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth',
          '100%|██████████| 230M/230M [02:48&amp;lt;00:00, 1.43MB/s]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Now that we have the <code>state dict</code>, we are going to perform inference as it is typically done in PyTorch.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">torchvision.models</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">models</span>',
      '<span class="w"> </span>',
      '<span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>     <span class="c1"># Set device</span>',
      '<span class="w"> </span>',
      '<span class="n">resnet152</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet152</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="c1"># Create model with random weights and move to device</span>',
      '<span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;accelerate_scripts/resnet152_pretrained.pth&#39;</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="c1"># Load pretrained weights into device memory</span>',
      '<span class="n">resnet152</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span> <span class="c1"># Load this weights into the model</span>',
      '<span class="w"> </span>',
      '<span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Random image with batch size 1</span>',
      '<span class="n">output</span> <span class="o">=</span> <span class="n">resnet152</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>',
      '<span class="n">output</span><span class="o">.</span><span class="n">shape</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'torch.Size([1, 1000])',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Let's explain what has happened</p>
      <ul>
        <li>When we did <code>resnet152 = models.resnet152().to(device)</code>, a ResNet152 with random weights was loaded into the GPU memory.</li>
        <li>When we did <code>state_dict = torch.load('accelerate_scripts/resnet152_pretrained.pth', map_location=device)</code>, a dictionary with the trained weights was loaded into the GPU memory.</li>
        <li>When we did <code>resnet152.load_state_dict(state_dict)</code>, those pretrained weights were assigned to the model.</li>
      </ul>
      <p>That is, the model has been loaded twice into the GPU memory.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>You might be wondering why we did first</p>
      
      <section class="section-block-markdown-cell">
            <div class='highlight'><pre><code class="language-python">model = models.resnet152(weights=models.ResNet152_Weights.IMAGENET1K_V1)<br>torch.save(model.state_dict(), &#39;accelerate_scripts/resnet152_pretrained.pth&#39;)</code></pre></div>
            </section>
      <p>To do later</p>
      
      <section class="section-block-markdown-cell">
            <div class='highlight'><pre><code class="language-python">resnet152 = models.resnet152().to(device)<br>state_dict = torch.load(&#39;accelerate_scripts/resnet152_pretrained.pth&#39;, map_location=device)<br>resnet152.load_state_dict(state_dict)</code></pre></div>
            </section>
      <p>And why don't we use directly</p>
      <div class='highlight'><pre><code class="language-text">model = models.resnet152(weights=models.ResNet152_Weights.IMAGENET1K_V1)</code></pre></div>
      <p>And we stop saving the <code>state dict</code> to load it later. Well, because Pytorch does the same thing under the hood. So, to see the whole process, we have broken down into several lines what Pytorch does in one.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>This way of working has been effective so far, while models were manageable by user GPUs. But since the arrival of LLMs, this approach no longer makes sense.</p>
      <p>For example, a 6B parameter model would occupy 24 GB in memory, and since it is loaded twice with this way of working, you would need a 48 GB GPU.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>So to fix this, the way to load a pretrained model in PyTorch is:</p>
      <ul>
        <li>Create an empty model with <code>init_empty_weights</code> that will not occupy RAM memory* Then load the weights with <code>load_checkpoint_and_dispatch</code> which will load a checkpoint into the empty model and distribute the weights for each layer across all available devices (GPU, CPU, RAM, and hard drive), thanks to setting <code>device_map="auto"</code></li>
      </ul>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">torchvision.models</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">models</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">init_empty_weights</span><span class="p">,</span> <span class="n">load_checkpoint_and_dispatch</span>',
      '<span class="w"> </span>',
      '<span class="k">with</span> <span class="n">init_empty_weights</span><span class="p">():</span>',
      '<span class="w">    </span><span class="n">resnet152</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet152</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="n">resnet152</span> <span class="o">=</span> <span class="n">load_checkpoint_and_dispatch</span><span class="p">(</span><span class="n">resnet152</span><span class="p">,</span> <span class="n">checkpoint</span><span class="o">=</span><span class="s1">&#39;accelerate_scripts/resnet152_pretrained.pth&#39;</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>',
      '<span class="w"> </span>',
      '<span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Random image with batch size 1</span>',
      '<span class="n">output</span> <span class="o">=</span> <span class="n">resnet152</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>',
      '<span class="n">output</span><span class="o">.</span><span class="n">shape</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'torch.Size([1, 1000])',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="How accelerate works under the hood">How accelerate works under the hood<a class="anchor-link" href="#How accelerate works under the hood"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 47" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>In this video you can see graphically how accelerate works under the hood</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <iframe width="1280" height="720" src="https://www.youtube.com/embed/MWCSGj9jEAo" title="Accelerate Big Model Inference: How Does it Work?" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
      </section>
      
      <section class="section-block-markdown-cell">
      <h4 id="Initialization of an empty model">Initialization of an empty model<a class="anchor-link" href="#Initialization of an empty model"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 48" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p><code>Accelerate</code> creates the skeleton of an empty model using <code>init_empty_weights</code> so that it occupies as little memory as possible.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>For example, let's see how much RAM I have available on my computer now.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">psutil</span>',
      '<span class="w"> </span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">get_ram_info</span><span class="p">():</span>',
      '<span class="w">    </span><span class="n">ram</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">psutil</span><span class="o">.</span><span class="n">virtual_memory</span><span class="p">()</span><span class="o">.</span><span class="n">_asdict</span><span class="p">())</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total RAM: </span><span class="si">{</span><span class="p">(</span><span class="n">ram</span><span class="p">[</span><span class="s1">&#39;total&#39;</span><span class="p">]</span><span class="o">/</span><span class="mi">1024</span><span class="o">/</span><span class="mi">1024</span><span class="o">/</span><span class="mi">1024</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> GB, Available RAM: </span><span class="si">{</span><span class="p">(</span><span class="n">ram</span><span class="p">[</span><span class="s1">&#39;available&#39;</span><span class="p">]</span><span class="o">/</span><span class="mi">1024</span><span class="o">/</span><span class="mi">1024</span><span class="o">/</span><span class="mi">1024</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> GB, Used RAM: </span><span class="si">{</span><span class="p">(</span><span class="n">ram</span><span class="p">[</span><span class="s1">&#39;used&#39;</span><span class="p">]</span><span class="o">/</span><span class="mi">1024</span><span class="o">/</span><span class="mi">1024</span><span class="o">/</span><span class="mi">1024</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> GB&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">get_ram_info</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Total RAM: 31.24 GB, Available RAM: 22.62 GB, Used RAM: 7.82 GB',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>I have about 22 GB of RAM available.</p>
      <p>Now let's try to create a model with 5000x1000x1000 parameters, that is, 5B parameters. If each parameter is in FP32, it would require 20 GB of RAM.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span>',
      '<span class="w"> </span>',
      '<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">)])</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>If we look at the RAM again</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">get_ram_info</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Total RAM: 31.24 GB, Available RAM: 3.77 GB, Used RAM: 26.70 GB',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>As we can see, now we only have 3 GB of RAM available</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Now we are going to delete the model to free up RAM</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">del</span> <span class="n">model</span>',
      '<span class="n">get_ram_info</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Total RAM: 31.24 GB, Available RAM: 22.44 GB, Used RAM: 8.03 GB',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We have about 22 GB of RAM available again.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Let's now use <code>init_empty_weights</code> from <code>accelerate</code> and then check the RAM</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">init_empty_weights</span>',
      '<span class="w"> </span>',
      '<span class="k">with</span> <span class="n">init_empty_weights</span><span class="p">():</span>',
      '<span class="w">    </span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">)])</span>',
      '<span class="w"> </span>',
      '<span class="n">get_ram_info</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Total RAM: 31.24 GB, Available RAM: 22.32 GB, Used RAM: 8.16 GB',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We previously had exactly 22.44 GB free, and after creating the model with <code>init_empty_weights</code> we have 22.32 GB. The RAM savings are huge! Almost no RAM was used to create the model.</p>
      <p>This is based on the meta-device introduced in PyTorch 1.9, so it is important that to use <code>accelerate</code> we have a version of Pytorch later than that.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h4 id="Loading the weights">Loading the weights<a class="anchor-link" href="#Loading the weights"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 49" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Once we have initialized the model, we need to load its weights, which we do through <code>load_checkpoint_and_dispatch</code>, which, as its name suggests, loads the weights and dispatches them to the necessary device or devices.</p>
      </section>







    </div>

  </section>

</PostLayout>
