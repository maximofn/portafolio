---
import PostLayout from '@layouts/PostLayout.astro';
import CodeBlockInputCell from '@components/CodeBlockInputCell.astro';
import CodeBlockOutputCell from '@components/CodeBlockOutputCell.astro';

const { metadata_page } = await import('@portfolio/consts.json');
const { colors } = await import('@portfolio/consts.json');
const { svg_paths } = await import('@portfolio/consts.json');

const page_title = 'Generate videos with Wan2.1-T2V-14B and Inference Providers';
const end_url = 'inference-providers-wan21-t2v-14b';
const description = 'Do you want to have your own Sora, but also generate good videos? In this post I explain how to do it with HuggingFace Inference Providers and Replicate.';
const keywords = 'hugging face, inference providers, replicate, wan21, t2v, 14b';
const languaje = 'EN';
const image_path = 'https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/inference-providers-wan21-thumbnail.webp';
const opening_brace = '{';
const closing_brace = '}';
---

<PostLayout 
    title={page_title}
    languaje={languaje}
    description={description}
    keywords={keywords}
    author={metadata_page.author}
    theme_color={colors.background_color}
    end_url={end_url}
    image_path={image_path}
    image_width=960
    image_height=720
    image_extension=webp
    article_date=2025-03-06+T00:00:00Z
>

  <section class="post-body">


    <aside class="post-index">
      <a class="anchor-link" href="#Inference-providers"><h2>Inference providers</h2></a>
      <a class="anchor-link" href="#Inference-with-Replicate"><h2>Inference with Replicate</h2></a>
      <a class="anchor-link" href="#Reading-the-API-Keys"><h3>Reading the API Keys</h3></a>
      <a class="anchor-link" href="#Logging-in-the-Hugging-Face-hub"><h3>Logging in the Hugging Face hub</h3></a>
      <a class="anchor-link" href="#Inference-Client"><h3>Inference Client</h3></a>
      <a class="anchor-link" href="#Video-Generation"><h3>Video Generation</h3></a>
      <a class="anchor-link" href="#Saving-the-video"><h3>Saving the video</h3></a>
      <a class="anchor-link" href="#Generated-video"><h2>Generated video</h2></a>
    </aside>


    <div class="post-body-content">
      
      <section class="section-block-markdown-cell">
      <h1 id="Hugging-Face-Inference-Providers">Hugging Face Inference Providers<a class="anchor-link" href="#Hugging-Face-Inference-Providers"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 9" src={svg_paths.link_svg_path}/></a></h1>
      </section>
      
      <section class="section-block-markdown-cell">
      <blockquote>
      <p>Disclaimer: This post has been translated to English using a machine translation model. Please, let me know if you find any mistakes.</p>
      </blockquote>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>It is clear that the largest hub of AI models is Hugging Face. And now they are offering the possibility to perform inference on some of their models using serverless GPU providers.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>One of those models is <a href="https://huggingface.co/Wan-AI/Wan2.1-T2V-14B" target="_blank" rel="nofollow noreferrer">Wan-AI/Wan2.1-T2V-14B</a>, which as of writing this post is the best open-source video generation model, as can be seen in the <a href="https://artificialanalysis.ai/text-to-video/arena?tab=Leaderboard">Artificial Analysis Video Generation Arena Leaderboard</a>
      <img decoding="async" onerror="this.parentNode.removeChild(this)" alt="video generation arena leaderboard" src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/Video-arena-leaderboard-wan21.webp" width="2180" height="1316"/></p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>If we look at its <a href="https://huggingface.co/Wan-AI/Wan2.1-T2V-14B" target="_blank" rel="nofollow noreferrer">modelcard</a> we can see on the right a button that says <code>Replicate</code>.
      <img decoding="async" onerror="this.parentNode.removeChild(this)" alt="Wan2.1-T2V-14B modelcard" src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/Wan2.1-T2V-14B.webp" width="2688" height="1150"/></p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Inference-providers">Inference providers<a class="anchor-link" href="#Inference-providers"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 10" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>If we go to the <a href="https://huggingface.co/settings/inference-providers" target="_blank" rel="nofollow noreferrer">Inference providers</a> settings page, we will see something like this
      <img decoding="async" onerror="this.parentNode.removeChild(this)" alt="Inference Providers" src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/Inference%20Providers.webp" width="1876" height="938"/>
      Where we can press the button with a key to enter the API KEY of the provider we want to use, or leave selected the path with two dots. If we choose the first option, it will be the provider who charges us for the inference, while in the second option, it will be Hugging Face who charges us for the inference. So do what suits you best.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Inference-with-Replicate">Inference with Replicate<a class="anchor-link" href="#Inference-with-Replicate"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 11" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>In my case, I obtained an API KEY from Replicate and added it to a file called <code>.env</code>, which is where I will store the API KEYS and which you should not upload to GitHub, GitLab, or your project repository.
      The <code>.env</code> must have this format</p>
<div class="highlight"><pre><span></span><span class="n">HUGGINGFACE_TOKEN_INFERENCE_PROVIDERS</span><span class="o">=</span><span class="s2">"hf_aL...AY"</span>
<span class="n">REPLICATE_API_KEY</span><span class="o">=</span><span class="s2">"r8_Sh...UD"</span><span class="err">```</span>
</pre></div>
      <span class="n">Where</span> <span class="err">`</span><span class="n">HUGGINGFACE_TOKEN_INFERENCE_PROVIDERS</span><span class="err">`</span> <span class="ow">is</span> <span class="n">a</span> <span class="n">token</span> <span class="n">you</span> <span class="n">need</span> <span class="n">to</span> <span class="n">obtain</span> <span class="kn">from</span> <span class="p">[</span><span class="n">Hugging</span> <span class="n">Face</span><span class="p">](</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">huggingface</span><span class="o">.</span><span class="n">co</span><span class="o">/</span><span class="n">settings</span><span class="o">/</span><span class="n">tokens</span><span class="p">)</span> <span class="ow">and</span> <span class="err">`</span><span class="n">REPLICATE_API_KEY</span><span class="err">`</span> <span class="ow">is</span> <span class="n">the</span> <span class="n">API</span> <span class="n">KEY</span> <span class="n">of</span> <span class="n">Replicate</span> <span class="n">which</span> <span class="n">you</span> <span class="n">can</span> <span class="n">obtain</span> <span class="kn">from</span> <span class="p">[</span><span class="n">Replicate</span><span class="p">](</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">replicate</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">account</span><span class="o">/</span><span class="n">api</span><span class="o">-</span><span class="n">tokens</span><span class="p">)</span><span class="o">.</span>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Reading-the-API-Keys">Reading the API Keys<a class="anchor-link" href="#Reading-the-API-Keys"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 12" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>The first thing we need to do is read the API KEYS from the <code>.env</code> file</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span> <span class="nn">os</span>',
      '<span class="kn">import</span> <span class="nn">dotenv</span>',
      '<span class="n">dotenv</span><span class="o">.</span><span class="n">load_dotenv</span><span class="p">()</span>',
      '',
      '<span class="n">REPLICATE_API_KEY</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">"REPLICATE_API_KEY"</span><span class="p">)</span>',
      '<span class="n">HUGGINGFACE_TOKEN_INFERENCE_PROVIDERS</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">"HUGGINGFACE_TOKEN_INFERENCE_PROVIDERS"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>











      
      <section class="section-block-markdown-cell">
      <h3 id="Logging-in-the-Hugging-Face-hub">Logging in the Hugging Face hub<a class="anchor-link" href="#Logging-in-the-Hugging-Face-hub"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 13" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>To be able to use the Wan-AI/Wan2.1-T2V-14B model, as it is on the Hugging Face hub, we need to log in.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">huggingface_hub</span> <span class="kn">import</span> <span class="n">login</span>',
      '<span class="n">login</span><span class="p">(</span><span class="n">HUGGINGFACE_TOKEN_INFERENCE_PROVIDERS</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>







      
      <section class="section-block-markdown-cell">
      <h3 id="Inference-Client">Inference Client<a class="anchor-link" href="#Inference-Client"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 14" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Now we create an inference client, we have to specify the provider, the API KEY and in this case, additionally, we are going to set a <code>timeout</code> of 1000 seconds, because by default it is 60 seconds and the model takes quite a while to generate the video.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">huggingface_hub</span> <span class="kn">import</span> <span class="n">InferenceClient</span>',
      '',
      '<span class="n">client</span> <span class="o">=</span> <span class="n">InferenceClient</span><span class="p">(</span>',
      '	<span class="n">provider</span><span class="o">=</span><span class="s2">"replicate"</span><span class="p">,</span>',
      '	<span class="n">api_key</span><span class="o">=</span><span class="n">REPLICATE_API_KEY</span><span class="p">,</span>',
      '	<span class="n">timeout</span><span class="o">=</span><span class="mi">1000</span>',
      '<span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>












      
      <section class="section-block-markdown-cell">
      <h3 id="Video-Generation">Video Generation<a class="anchor-link" href="#Video-Generation"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 15" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>We already have everything to generate our video. We use the <code>text_to_video</code> method of the client, pass it the prompt, and tell it which model from the hub we want to use; if not, it will use the default one.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">video</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">text_to_video</span><span class="p">(</span>',
      '	<span class="s2">"Funky dancer, dancing in a rehearsal room. She wears long hair that moves to the rhythm of her dance."</span><span class="p">,</span>',
      '	<span class="n">model</span><span class="o">=</span><span class="s2">"Wan-AI/Wan2.1-T2V-14B"</span><span class="p">,</span>',
      '<span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>









      
      <section class="section-block-markdown-cell">
      <h3 id="Saving-the-video">Saving the video<a class="anchor-link" href="#Saving-the-video"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 16" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Finally, we save the video, which is of type <code>bytes</code>, to a file on our disk.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">output_path</span> <span class="o">=</span> <span class="s2">"output_video.mp4"</span>',
          '<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="s2">"wb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>',
          '    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">video</span><span class="p">)</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Video saved to: </span><span class="si">{</span><span class="n">output_path</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Video saved to: output_video.mp4',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h2 id="Generated-video">Generated video<a class="anchor-link" href="#Generated-video"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 17" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>This is the video generated by the model</p>
      <p><video controls="" src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/wan2_1_video.webm"></video></p>
      </section>
      






    </div>

  </section>

</PostLayout>
