---
import PostLayout from '@layouts/PostLayout.astro';
import CodeBlockInputCell from '@components/CodeBlockInputCell.astro';
import CodeBlockOutputCell from '@components/CodeBlockOutputCell.astro';

const { metadata_page } = await import('@portfolio/consts.json');
const { colors } = await import('@portfolio/consts.json');
const { svg_paths } = await import('@portfolio/consts.json');

const page_title = 'Tokens';
const end_url = 'tokens';
const description = 'Discover what tokens are and how words are divided into minimum units of word representation';
const keywords = 'tokens, token, openai, tiktoken, gpt-4, gpt-3.5-turbo, text-embedding-ada-002';
const languaje = 'EN';
const image_path = 'https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/tokens.webp';
const opening_brace = '{';
const closing_brace = '}';
---

<PostLayout 
    title={page_title}
    languaje={languaje}
    description={description}
    keywords={keywords}
    author={metadata_page.author}
    theme_color={colors.background_color}
    end_url={end_url}
    image_path={image_path}
    image_width=1024
    image_height=1024
    image_extension=webp
    article_date=2023-12-08+T00:00:00Z
>

  <section class="post-body">


    <aside class="post-index">
    </aside>


    <div class="post-body-content">
      
      <section class="section-block-markdown-cell">
      </section>
      
      <section class="section-block-markdown-cell">
      <blockquote>
      <p>Disclaimer: This post has been translated to English using a machine translation model. Please, let me know if you find any mistakes.</p>
      </blockquote>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Now that <code>LLM</code>s are on the rise, we keep hearing about the number of <code>token</code>s each model supports, but what are <code>token</code>s? They are the smallest units of representation of words.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>To explain what <code>tokens</code> are, let's first look at a practical example using the <code>OpenAI</code> tokenizer, called <a href="https://github.com/openai/tiktoken" target="_blank" rel="nofollow noreferrer">tiktoken</a>.</p>
      <p>So, first we install the package:</p>
      <div class='highlight'><pre><code class="language-bash">pip install tiktoken</code></pre></div>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Once installed, we create a tokenizer using the <code>cl100k_base</code> model, which in the example notebook <a href="https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb" target="_blank" rel="nofollow noreferrer">How to count tokens with tiktoken</a> explains is used by the models <code>gpt-4</code>, <code>gpt-3.5-turbo</code> and <code>text-embedding-ada-002</code></p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">tiktoken</span>',
      '<span class="w"> </span>',
      '<span class="n">encoder</span> <span class="o">=</span> <span class="n">tiktoken</span><span class="o">.</span><span class="n">get_encoding</span><span class="p">(</span><span class="s2">&quot;cl100k_base&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Now we create an example word to tokenize it</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">example_word</span> <span class="o">=</span> <span class="s2">&quot;breakdown&quot;</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>And we tokenize it</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">tokens</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">example_word</span><span class="p">)</span>',
      '<span class="n">tokens</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '[9137, 2996]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>The word has been split into 2 <code>token</code>s, the <code>9137</code> and the <code>2996</code>. Let's see which words they correspond to.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">word1</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">decode</span><span class="p">([</span><span class="n">tokens</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>',
      '<span class="n">word2</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">decode</span><span class="p">([</span><span class="n">tokens</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>',
      '<span class="n">word1</span><span class="p">,</span> <span class="n">word2</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '(&#x27;break&#x27;, &#x27;down&#x27;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>The <code>OpenAI</code> tokenizer has split the word <code>breakdown</code> into the words <code>break</code> and <code>down</code>. That is, it has divided the word into 2 simpler ones.</p>
      <p>This is important, as when it is said that an <code>LLM</code> supports x <code>tokens</code>, it does not mean that it supports x words, but rather that it supports x minimal units of word representation.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>If you have a text and want to see the number of <code>token</code>s it has for the <code>OpenAI</code> tokenizer, you can check it on the <a href="https://platform.openai.com/tokenizer" target="_blank" rel="nofollow noreferrer">Tokenizer</a> page, which displays each <code>token</code> in a different color.</p>
      <img decoding="async" onerror="this.parentNode.removeChild(this)" src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/tokenizer.webp" alt="tokenizer">
      </section>
      
      <section class="section-block-markdown-cell">
      <p>We have seen the tokenizer of <code>OpenAI</code>, but each <code>LLM</code> may use a different one.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>As we have said, the <code>token</code>s are the minimal units of representation of words, so let's see how many distinct tokens <code>tiktoken</code> has.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">n_vocab</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">n_vocab</span>',
      '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Vocab size: </span><span class="si">{</span><span class="n">n_vocab</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Vocab size: 100277',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Let's see how it tokenizes another type of words</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">def</span><span class="w"> </span><span class="nf">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">tokens</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">decode_tokens</span> <span class="o">=</span> <span class="p">[]</span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">decode_tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">decode</span><span class="p">([</span><span class="n">token</span><span class="p">]))</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">word</span> <span class="o">=</span> <span class="s2">&quot;dog&quot;</span>',
      '<span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span> <span class="o">=</span> <span class="n">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>',
      '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Word: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2"> ==&amp;gt; tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">, decode_tokens: </span><span class="si">{</span><span class="n">decode_tokens</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">word</span> <span class="o">=</span> <span class="s2">&quot;tomorrow...&quot;</span>',
      '<span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span> <span class="o">=</span> <span class="n">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>',
      '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Word: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2"> ==&amp;gt; tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">, decode_tokens: </span><span class="si">{</span><span class="n">decode_tokens</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">word</span> <span class="o">=</span> <span class="s2">&quot;artificial intelligence&quot;</span>',
      '<span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span> <span class="o">=</span> <span class="n">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>',
      '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Word: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2"> ==&amp;gt; tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">, decode_tokens: </span><span class="si">{</span><span class="n">decode_tokens</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">word</span> <span class="o">=</span> <span class="s2">&quot;Python&quot;</span>',
      '<span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span> <span class="o">=</span> <span class="n">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>',
      '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Word: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2"> ==&amp;gt; tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">, decode_tokens: </span><span class="si">{</span><span class="n">decode_tokens</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">word</span> <span class="o">=</span> <span class="s2">&quot;12/25/2023&quot;</span>',
      '<span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span> <span class="o">=</span> <span class="n">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>',
      '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Word: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2"> ==&amp;gt; tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">, decode_tokens: </span><span class="si">{</span><span class="n">decode_tokens</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">word</span> <span class="o">=</span> <span class="s2">&quot;😊&quot;</span>',
      '<span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span> <span class="o">=</span> <span class="n">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>',
      '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Word: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2"> ==&amp;gt; tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">, decode_tokens: </span><span class="si">{</span><span class="n">decode_tokens</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Word: dog ==&amp;gt; tokens: [18964], decode_tokens: [&#x27;dog&#x27;]',
          'Word: tomorrow... ==&amp;gt; tokens: [38501, 7924, 1131], decode_tokens: [&#x27;tom&#x27;, &#x27;orrow&#x27;, &#x27;...&#x27;]',
          'Word: artificial intelligence ==&amp;gt; tokens: [472, 16895, 11478], decode_tokens: [&#x27;art&#x27;, &#x27;ificial&#x27;, &#x27; intelligence&#x27;]',
          'Word: Python ==&amp;gt; tokens: [31380], decode_tokens: [&#x27;Python&#x27;]',
          'Word: 12/25/2023 ==&amp;gt; tokens: [717, 14, 914, 14, 2366, 18], decode_tokens: [&#x27;12&#x27;, &#x27;/&#x27;, &#x27;25&#x27;, &#x27;/&#x27;, &#x27;202&#x27;, &#x27;3&#x27;]',
          'Word: 😊 ==&amp;gt; tokens: [76460, 232], decode_tokens: [&#x27;�&#x27;, &#x27;�&#x27;]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Finally, we will see it with words in another language</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">word</span> <span class="o">=</span> <span class="s2">&quot;perro&quot;</span>',
      '<span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span> <span class="o">=</span> <span class="n">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>',
      '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Word: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2"> ==&amp;gt; tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">, decode_tokens: </span><span class="si">{</span><span class="n">decode_tokens</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">word</span> <span class="o">=</span> <span class="s2">&quot;perra&quot;</span>',
      '<span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span> <span class="o">=</span> <span class="n">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>',
      '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Word: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2"> ==&amp;gt; tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">, decode_tokens: </span><span class="si">{</span><span class="n">decode_tokens</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">word</span> <span class="o">=</span> <span class="s2">&quot;mañana...&quot;</span>',
      '<span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span> <span class="o">=</span> <span class="n">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>',
      '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Word: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2"> ==&amp;gt; tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">, decode_tokens: </span><span class="si">{</span><span class="n">decode_tokens</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">word</span> <span class="o">=</span> <span class="s2">&quot;inteligencia artificial&quot;</span>',
      '<span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span> <span class="o">=</span> <span class="n">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>',
      '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Word: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2"> ==&amp;gt; tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">, decode_tokens: </span><span class="si">{</span><span class="n">decode_tokens</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">word</span> <span class="o">=</span> <span class="s2">&quot;Python&quot;</span>',
      '<span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span> <span class="o">=</span> <span class="n">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>',
      '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Word: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2"> ==&amp;gt; tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">, decode_tokens: </span><span class="si">{</span><span class="n">decode_tokens</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">word</span> <span class="o">=</span> <span class="s2">&quot;12/25/2023&quot;</span>',
      '<span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span> <span class="o">=</span> <span class="n">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>',
      '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Word: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2"> ==&amp;gt; tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">, decode_tokens: </span><span class="si">{</span><span class="n">decode_tokens</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">word</span> <span class="o">=</span> <span class="s2">&quot;😊&quot;</span>',
      '<span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span> <span class="o">=</span> <span class="n">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>',
      '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Word: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2"> ==&amp;gt; tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">, decode_tokens: </span><span class="si">{</span><span class="n">decode_tokens</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Word: perro ==&amp;gt; tokens: [716, 299], decode_tokens: [&#x27;per&#x27;, &#x27;ro&#x27;]',
          'Word: perra ==&amp;gt; tokens: [79, 14210], decode_tokens: [&#x27;p&#x27;, &#x27;erra&#x27;]',
          'Word: mañana... ==&amp;gt; tokens: [1764, 88184, 1131], decode_tokens: [&#x27;ma&#x27;, &#x27;ñana&#x27;, &#x27;...&#x27;]',
          'Word: inteligencia artificial ==&amp;gt; tokens: [396, 39567, 8968, 21075], decode_tokens: [&#x27;int&#x27;, &#x27;elig&#x27;, &#x27;encia&#x27;, &#x27; artificial&#x27;]',
          'Word: Python ==&amp;gt; tokens: [31380], decode_tokens: [&#x27;Python&#x27;]',
          'Word: 12/25/2023 ==&amp;gt; tokens: [717, 14, 914, 14, 2366, 18], decode_tokens: [&#x27;12&#x27;, &#x27;/&#x27;, &#x27;25&#x27;, &#x27;/&#x27;, &#x27;202&#x27;, &#x27;3&#x27;]',
          'Word: 😊 ==&amp;gt; tokens: [76460, 232], decode_tokens: [&#x27;�&#x27;, &#x27;�&#x27;]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>We can see that for similar words, Spanish generates more <code>token</code>s than English, so for the same text, with a similar number of words, the number of <code>token</code>s will be greater in Spanish than in English.</p>
      </section>







    </div>

  </section>

</PostLayout>
