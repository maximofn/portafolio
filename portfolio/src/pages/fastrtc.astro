---
import PostLayout from '@layouts/PostLayout.astro';
import CodeBlockInputCell from '@components/CodeBlockInputCell.astro';
import CodeBlockOutputCell from '@components/CodeBlockOutputCell.astro';

const { metadata_page } = await import('@portfolio/consts.json');
const { colors } = await import('@portfolio/consts.json');
const { svg_paths } = await import('@portfolio/consts.json');

const page_title = 'Hacer una aplicaci√≥n de IA en tiempo real con FastRTC';
const end_url = 'fastrtc';
const description = 'Si tienes problemas para hacer una aplicaci√≥n de IA en tiempo real, FastRTC es una biblioteca que te puede ayudar. En este post te explico c√≥mo usarla.';
const keywords = 'fastrtc, real-time, ai, aplicaci√≥n, tel√©fono';
const languaje = 'ES';
const image_path = 'https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/fastrtc-thumbnail.webp';
const opening_brace = '{';
const closing_brace = '}';
---

<PostLayout 
    title={page_title}
    languaje={languaje}
    description={description}
    keywords={keywords}
    author={metadata_page.author}
    theme_color={colors.background_color}
    end_url={end_url}
    image_path={image_path}
    image_width=960
    image_height=720
    image_extension=webp
    article_date=2025-03-08+T00:00:00Z
>

  <section class="post-body">


    <aside class="post-index">
      <a class="anchor-link" href="#Caracter%C3%ADsticas-principales-de-FastRTC"><h2>Caracter√≠sticas principales de FastRTC</h2></a>
      <a class="anchor-link" href="#Instalaci%C3%B3n"><h2>Instalaci√≥n</h2></a>
      <a class="anchor-link" href="#Primeros-pasos"><h2>Primeros pasos</h2></a>
      <a class="anchor-link" href="#Subiendo-de-nivel:-Chat-de-voz-con-LLM"><h2>Subiendo de nivel: Chat de voz con LLM</h2></a>
      <a class="anchor-link" href="#Llamada-por-tel%C3%A9fono"><h2>Llamada por tel√©fono</h2></a>
    </aside>


    <div class="post-body-content">
      
      <section class="section-block-markdown-cell">
      <h1 id="FastRTC:-La-Biblioteca-de-Comunicaci%C3%B3n-en-Tiempo-Real-para-Python">FastRTC: La Biblioteca de Comunicaci√≥n en Tiempo Real para Python<a class="anchor-link" href="#FastRTC:-La-Biblioteca-de-Comunicaci%C3%B3n-en-Tiempo-Real-para-Python"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 0" src={svg_paths.link_svg_path}/></a></h1>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>En los √∫ltimos meses, hemos visto un gran avance en modelos de voz en tiempo real, con empresas enteras fundadas alrededor de modelos tanto de c√≥digo abierto como cerrado. Algunos hitos importantes incluyen:</p>
      <ul>
      <li><code>OpenAI</code> y <code>Google</code> lanzaron sus APIs multimodales en vivo para ChatGPT y Gemini. ¬°OpenAI incluso lanz√≥ un n√∫mero de tel√©fono <code>1-800-ChatGPT</code>!</li>
      <li><code>Kyutai</code> lanz√≥ <a href="https://huggingface.co/kyutai" target="_blank" rel="nofollow noreferrer">Moshi</a>, un LLM de audio a audio completamente de c√≥digo abierto.</li>
      <li><code>Alibaba</code> lanz√≥ <a href="https://huggingface.co/Qwen/Qwen2-Audio-7B-Instruct" target="_blank" rel="nofollow noreferrer">Qwen2-Audio</a>, un LLM de c√≥digo abierto que entiende audio de forma nativa.</li>
      <li><code>Fixie.ai</code> lanz√≥ <a href="https://huggingface.co/fixie-ai/ultravox-v0_5-llama-3_3-70b" target="_blank" rel="nofollow noreferrer">Ultravox</a>, otro LLM de c√≥digo abierto que tambi√©n entiende audio de forma nativa.</li>
      <li><code>ElevenLabs</code> recaud√≥ 180 millones de d√≥lares en su Serie C.</li>
      </ul>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>A pesar de esta explosi√≥n en modelos y financiaci√≥n, sigue siendo dif√≠cil construir aplicaciones de IA en tiempo real que transmitan audio y video, especialmente en Python.</p>
      <ul>
      <li>Los ingenieros de ML pueden no tener experiencia con las tecnolog√≠as necesarias para construir aplicaciones en tiempo real, como <code>WebRTC</code>.</li>
      <li>Incluso herramientas de asistencia de c√≥digo como <code>Cursor</code> y <code>Copilot</code> tienen dificultades para escribir c√≥digo Python que soporte aplicaciones de audio/video en tiempo real.</li>
      </ul>
      <p>Por eso es emocionante el anuncio de <code>FastRTC</code>, la biblioteca de comunicaci√≥n en tiempo real para Python. ¬°La biblioteca est√° dise√±ada para facilitar la construcci√≥n de aplicaciones de IA de audio y video en tiempo real completamente en Python!</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Caracter%C3%ADsticas-principales-de-FastRTC">Caracter√≠sticas principales de FastRTC<a class="anchor-link" href="#Caracter%C3%ADsticas-principales-de-FastRTC"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 1" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <ul>
      <li>üó£Ô∏è Detecci√≥n de voz autom√°tica y toma de turnos incorporada, para que solo tengas que preocuparte por la l√≥gica de respuesta al usuario.</li>
      <li>üíª UI autom√°tica - UI de Gradio habilitada para WebRTC incorporada para pruebas (¬°o despliegue a producci√≥n!).</li>
      <li>üìû Llamada por tel√©fono - Usa <code>fastphone()</code> para obtener un n√∫mero de tel√©fono <strong>gratuito</strong> para llamar a tu stream de audio (se requiere un token HF).</li>
      <li>‚ö°Ô∏è Soporte para <code>WebRTC</code> y <code>Websocket</code>.</li>
      <li>üí™ Personalizable - Puedes montar el stream en cualquier aplicaci√≥n <code>FastAPI</code> para servir una UI personalizada y desplegar m√°s all√° de <code>Gradio</code>.</li>
      <li>üß∞ Muchas utilidades para <code>text-to-speech</code>, <code>speech-to-text</code>, <code>detecci√≥n de parada</code> para ayudarte a comenzar.</li>
      </ul>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Instalaci%C3%B3n">Instalaci√≥n<a class="anchor-link" href="#Instalaci%C3%B3n"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 2" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Para poder usar <code>FastRTC</code>, primero necesitas instalar la biblioteca:</p>
      <div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>fastrtc</pre></div>
      <p>Pero si queremos instalar las funcionalidades de detecci√≥n de pausa, speech-to-text y text-to-speech, necesitamos instalar algunas dependencias adicionales:</p>
      <div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span><span class="s2">"fastrtc[vad, stt, tts]"</span></pre></div>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Primeros-pasos">Primeros pasos<a class="anchor-link" href="#Primeros-pasos"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 3" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Empezaremos construyendo el <code>hola mundo</code> del audio en tiempo real: hacer eco de lo que dice el usuario. En <code>FastRTC</code>, esto es tan simple como:</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">fastrtc</span> <span class="kn">import</span> <span class="n">Stream</span><span class="p">,</span> <span class="n">ReplyOnPause</span>',
          '<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>',
          '',
          '<span class="k">def</span> <span class="nf">echo</span><span class="p">(</span><span class="n">audio</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>',
          '    <span class="k">yield</span> <span class="n">audio</span>',
          '',
          '<span class="n">stream</span> <span class="o">=</span> <span class="n">Stream</span><span class="p">(</span><span class="n">ReplyOnPause</span><span class="p">(</span><span class="n">echo</span><span class="p">),</span> <span class="n">modality</span><span class="o">=</span><span class="s2">"audio"</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">"send-receive"</span><span class="p">)</span>',
          '<span class="n">stream</span><span class="o">.</span><span class="n">ui</span><span class="o">.</span><span class="n">launch</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '* Running on local URL:  http://127.0.0.1:7872',
          'To create a public link, set `share=True` in `launch()`.',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Cuando vamos al enlace que nos sugiere Gradio, primero tenemos que dar permisos al navegador para acceder al micr√≥fono. A continuaci√≥n nos aparecer√° esto</p>
      <p><img decoding="async" onerror="this.parentNode.removeChild(this)" alt="fastrct - hello world - init" src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/fastRTC%20-%20hello%20world%20-%20init.webp" width="550" height="361"/></p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Si pinchamos en la pesta√±a de la derecha de la palabra <code>Record</code> podemos seleccionar el micr√≥fono que queremos usar.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>A continuaci√≥n si pulsamos en el bot√≥n de <code>Record</code>, todo lo que digamos, la aplicaci√≥n lo repetir√°. Es decir captura el audio, detecta cuando hemos dejado de hablar y lo repite.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a desglosarlo:</p>
      <ul>
      <li><code>ReplyOnPause</code> manejar√° la detecci√≥n de voz y la toma de turnos por ti. Solo tienes que preocuparte por la l√≥gica para responder al usuario. Hay que pasarle la funci√≥n que se encargar√° de gestionar el audio de entrada. En nuestro caso es la funci√≥n <code>echo</code>, que captura el audio de entrada y lo devuelve en stream mediante el uso de <code>yield</code>, que mucha gente no conoce, pero es un generador, es decir, es un m√©todo de python para crear iteradores. Si quieres saber m√°s sobre <code>yield</code> puedes leer mi post de <a href="https://www.maximofn.com/python#6.5.-Generadores">Python</a>. Cualquier generador que devuelva una tupla de audio (representada como <code>(sample_rate, audio_data)</code>) funcionar√°.</li>
      <li>La clase <code>Stream</code> construir√° una UI de Gradio para que puedas probar r√°pidamente tu stream. Una vez que hayas terminado de prototipar, puedes desplegar tu Stream como una aplicaci√≥n FastAPI lista para producci√≥n en una sola l√≠nea de c√≥digo</li>
      </ul>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Aqu√≠ podemos ver un ejemplo de los creadores de <code>FastRTC</code></p>
      <p><video controls="" src="https://github.com/user-attachments/assets/fcf2d30e-3e98-47c9-8dc3-23340784c441"></video></p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Subiendo-de-nivel:-Chat-de-voz-con-LLM">Subiendo de nivel: Chat de voz con LLM<a class="anchor-link" href="#Subiendo-de-nivel:-Chat-de-voz-con-LLM"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 4" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>El siguiente nivel es usar un LLM para responder al usuario. <code>FastRTC</code> viene con capacidades de <code>speech-to-text</code> y <code>text-to-speech</code> incorporadas, por lo que trabajar con LLMs es realmente f√°cil. Vamos a cambiar nuestra funci√≥n <code>echo</code> en consecuencia:</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">fastrtc</span> <span class="kn">import</span> <span class="n">ReplyOnPause</span><span class="p">,</span> <span class="n">Stream</span><span class="p">,</span> <span class="n">get_stt_model</span><span class="p">,</span> <span class="n">get_tts_model</span>',
          '<span class="kn">from</span> <span class="nn">gradio_client</span> <span class="kn">import</span> <span class="n">Client</span>',
          '',
          '<span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="s2">"Maximofn/SmolLM2_localModel"</span><span class="p">)</span>',
          '<span class="n">stt_model</span> <span class="o">=</span> <span class="n">get_stt_model</span><span class="p">()</span>',
          '<span class="n">tts_model</span> <span class="o">=</span> <span class="n">get_tts_model</span><span class="p">()</span>',
          '',
          '<span class="k">def</span> <span class="nf">echo</span><span class="p">(</span><span class="n">audio</span><span class="p">):</span>',
          '    <span class="n">prompt</span> <span class="o">=</span> <span class="n">stt_model</span><span class="o">.</span><span class="n">stt</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>',
          '    <span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>',
          '            <span class="n">message</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>',
          '            <span class="n">system_message</span><span class="o">=</span><span class="s2">"You are a friendly Chatbot. Always reply in the language in which the user is writing to you."</span><span class="p">,</span>',
          '            <span class="n">max_tokens</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>',
          '            <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>',
          '            <span class="n">top_p</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span>',
          '            <span class="n">api_name</span><span class="o">=</span><span class="s2">"/chat"</span>',
          '    <span class="p">)</span>',
          '    <span class="n">prompt</span> <span class="o">=</span> <span class="n">response</span>',
          '    <span class="k">for</span> <span class="n">audio_chunk</span> <span class="ow">in</span> <span class="n">tts_model</span><span class="o">.</span><span class="n">stream_tts_sync</span><span class="p">(</span><span class="n">prompt</span><span class="p">):</span>',
          '        <span class="k">yield</span> <span class="n">audio_chunk</span>',
          '',
          '<span class="n">stream</span> <span class="o">=</span> <span class="n">Stream</span><span class="p">(</span><span class="n">ReplyOnPause</span><span class="p">(</span><span class="n">echo</span><span class="p">),</span> <span class="n">modality</span><span class="o">=</span><span class="s2">"audio"</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">"send-receive"</span><span class="p">)</span>',
          '<span class="n">stream</span><span class="o">.</span><span class="n">ui</span><span class="o">.</span><span class="n">launch</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Loaded as API: https://maximofn-smollm2-localmodel.hf.space ‚úî',
          '* Running on local URL:  http://127.0.0.1:7871',
          'To create a public link, set `share=True` in `launch()`.',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Como modelo de <code>speech-to-text</code> usa <code>Moonshine</code> que supuestamente solo soporta ingl√©s, pero lo he probado en espa√±ol y me entiende bien.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Como modelo de lenguaje vamos a usar el modelo que desplegu√© en un backend en Hugging Face y que escrib√≠ en el post <a href="https://www.maximofn.com/deploy-backend-with-llm-in-huggingface">Desplegar backend con LLM en HuggingFace</a>. Utiliza el LLM <code>HuggingFaceTB/SmolLM2-1.7B-Instruct</code> que es un modelo peque√±o, ya que est√° corriendo en un backend con CPU, pero que funciona bastante bien.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Como modelo de <code>text-to-speech</code> usa <code>Kokoro</code> que s√≠ tiene opciones de hablar en otros idiomas, pero que de momento en la librer√≠a de <code>FastRTC</code> de momento no est√° implementado.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Si nos interesa mucho usar modelos de <code>speech-to-speech</code> y <code>text-to-speech</code> en otros idiomas, podr√≠amos implementarlos nosotros mismos, porque el mayor potencial de <code>FastRTC</code> est√° en la capa de comunicaci√≥n en tiempo real, pero no me voy a meter en eso ahora.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Ahora s√≠ probamos el c√≥digo que acabamos de escribir podemos tener un chatbot, por voz en tiempo real.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Llamada-por-tel%C3%A9fono">Llamada por tel√©fono<a class="anchor-link" href="#Subiendo-de-nivel:-Chat-de-voz-con-LLM"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 4" src={svg_paths.link_svg_path}/></a></h2>
      <p>Generamos un script, porque en un Jupyter Notebook no siempre funciona</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="o">%%writefile</span> fastrtc_phone_demo.py',
      '',
      '<span class="kn">from</span> <span class="nn">fastrtc</span> <span class="kn">import</span> <span class="n">ReplyOnPause</span><span class="p">,</span> <span class="n">Stream</span><span class="p">,</span> <span class="n">get_stt_model</span><span class="p">,</span> <span class="n">get_tts_model</span>',
      '<span class="kn">import</span> <span class="nn">gradio</span>',
      '<span class="kn">from</span> <span class="nn">gradio_client</span> <span class="kn">import</span> <span class="n">Client</span>',
      '<span class="kn">import</span> <span class="nn">os</span>',
      '<span class="kn">from</span> <span class="nn">gradio.networking</span> <span class="kn">import</span> <span class="n">setup_tunnel</span> <span class="k">as</span> <span class="n">original_setup_tunnel</span>',
      '<span class="kn">import</span> <span class="nn">socket</span>',
      '',
      '<span class="c1"># Monkey patch setup_tunnel para que acepte el par√°metro adicional</span>',
      '<span class="k">def</span> <span class="nf">patched_setup_tunnel</span><span class="p">(</span><span class="n">host</span><span class="p">,</span> <span class="n">port</span><span class="p">,</span> <span class="n">share_token</span><span class="p">,</span> <span class="n">share_server_address</span><span class="p">,</span> <span class="n">share_server_tls_certificate</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>',
      '    <span class="k">return</span> <span class="n">original_setup_tunnel</span><span class="p">(</span><span class="n">host</span><span class="p">,</span> <span class="n">port</span><span class="p">,</span> <span class="n">share_token</span><span class="p">,</span> <span class="n">share_server_address</span><span class="p">,</span> <span class="n">share_server_tls_certificate</span><span class="p">)</span>',
      '',
      '<span class="c1"># Replace the original function with our patched version</span>',
      '<span class="n">gradio</span><span class="o">.</span><span class="n">networking</span><span class="o">.</span><span class="n">setup_tunnel</span> <span class="o">=</span> <span class="n">patched_setup_tunnel</span>',
      '',
      '<span class="c1"># Get the token from the environment variable</span>',
      '<span class="n">HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">"HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN"</span><span class="p">)</span>',
      '',
      '<span class="c1"># Initialize the LLM client</span>',
      '<span class="n">llm_client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="s2">"Maximofn/SmolLM2_localModel"</span><span class="p">)</span>',
      '',
      '<span class="c1"># Initialize the STT and TTS models</span>',
      '<span class="n">stt_model</span> <span class="o">=</span> <span class="n">get_stt_model</span><span class="p">()</span>',
      '<span class="n">tts_model</span> <span class="o">=</span> <span class="n">get_tts_model</span><span class="p">()</span>',
      '',
      '<span class="c1"># Define the echo function</span>',
      '<span class="k">def</span> <span class="nf">echo</span><span class="p">(</span><span class="n">audio</span><span class="p">):</span>',
      '    <span class="c1"># Convert the audio to text</span>',
      '    <span class="n">prompt</span> <span class="o">=</span> <span class="n">stt_model</span><span class="o">.</span><span class="n">stt</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>',
      '',
      '    <span class="c1"># Generate the response</span>',
      '    <span class="n">response</span> <span class="o">=</span> <span class="n">llm_client</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>',
      '            <span class="n">message</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>',
      '            <span class="n">system_message</span><span class="o">=</span><span class="s2">"You are a friendly Chatbot. Always reply in the language in which the user is writing to you."</span><span class="p">,</span>',
      '            <span class="n">max_tokens</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>',
      '            <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>',
      '            <span class="n">top_p</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span>',
      '            <span class="n">api_name</span><span class="o">=</span><span class="s2">"/chat"</span>',
      '    <span class="p">)</span>',
      '    ',
      '    <span class="c1"># Convert the response to audio</span>',
      '    <span class="n">prompt</span> <span class="o">=</span> <span class="n">response</span>',
      '',
      '    <span class="c1"># Stream the audio</span>',
      '    <span class="k">for</span> <span class="n">audio_chunk</span> <span class="ow">in</span> <span class="n">tts_model</span><span class="o">.</span><span class="n">stream_tts_sync</span><span class="p">(</span><span class="n">prompt</span><span class="p">):</span>',
      '        <span class="k">yield</span> <span class="n">audio_chunk</span>',
      '',
      '<span class="k">def</span> <span class="nf">find_free_port</span><span class="p">(</span><span class="n">start_port</span><span class="o">=</span><span class="mi">8000</span><span class="p">,</span> <span class="n">max_port</span><span class="o">=</span><span class="mi">9000</span><span class="p">):</span>',
      '<span class="w">    </span><span class="sd">"""Find the first free port starting from start_port."""</span>',
      '    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Searching for a free port starting from </span><span class="si">{</span><span class="n">start_port</span><span class="si">}</span><span class="s2">..."</span><span class="p">)</span>',
      '    <span class="k">for</span> <span class="n">port</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_port</span><span class="p">,</span> <span class="n">max_port</span><span class="p">):</span>',
      '        <span class="k">with</span> <span class="n">socket</span><span class="o">.</span><span class="n">socket</span><span class="p">(</span><span class="n">socket</span><span class="o">.</span><span class="n">AF_INET</span><span class="p">,</span> <span class="n">socket</span><span class="o">.</span><span class="n">SOCK_STREAM</span><span class="p">)</span> <span class="k">as</span> <span class="n">sock</span><span class="p">:</span>',
      '            <span class="n">result</span> <span class="o">=</span> <span class="n">sock</span><span class="o">.</span><span class="n">connect_ex</span><span class="p">((</span><span class="s1">\'127.0.0.1\'</span><span class="p">,</span> <span class="n">port</span><span class="p">))</span>',
      '            <span class="k">if</span> <span class="n">result</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># If result != 0, the port is free</span>',
      '                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Free port found: </span><span class="si">{</span><span class="n">port</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
      '                <span class="k">return</span> <span class="n">port</span>',
      '    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"No free port found between </span><span class="si">{</span><span class="n">start_port</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="n">max_port</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
      '    ',
      '<span class="n">free_port</span> <span class="o">=</span> <span class="n">find_free_port</span><span class="p">()</span>    <span class="c1"># Search for a free port</span>',
      '',
      '<span class="n">stream</span> <span class="o">=</span> <span class="n">Stream</span><span class="p">(</span><span class="n">ReplyOnPause</span><span class="p">(</span><span class="n">echo</span><span class="p">),</span> <span class="n">modality</span><span class="o">=</span><span class="s2">"audio"</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">"send-receive"</span><span class="p">)</span>',
      '<span class="n">stream</span><span class="o">.</span><span class="n">fastphone</span><span class="p">(</span><span class="n">token</span><span class="o">=</span><span class="n">HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN</span><span class="p">,</span> <span class="n">port</span><span class="o">=</span><span class="n">free_port</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>




































































      
      <section class="section-block-markdown-cell">
      <p>Explicamos el c√≥digo</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>La parte</p>
<div class="highlight"><pre><span></span><span class="c1"># Monkey patch setup_tunnel para que acepte el par√°metro adicional</span>
<span class="k">def</span> <span class="nf">patched_setup_tunnel</span><span class="p">(</span><span class="n">host, port, share_token, share_server_address, share_server_tls_certificate=None</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">original_setup_tunnel</span><span class="p">(</span><span class="n">host, port, share_token, share_server_address, share_server_tls_certificate</span><span class="p">)</span>
<span class="n">    </span>
<span class="c1"># Replace the original function with our patched version</span>
<span class="n">gradio.networking.setup_tunnel</span> <span class="c1">=</span> <span class="n">patched_setup_tunnel</span>
</pre></div>
      <p>Es necesario porque <code>FastRTC</code> est√° escrito para una versi√≥n antigua de <code>gradio</code> que no soporta el par√°metro <code>share_server_address</code> en el m√©todo <code>setup_tunnel</code>. As√≠ que lo parcheamos para que acepte el par√°metro adicional.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Como es necesario un token de Hugging Face, lo obtenemos de la variable de entorno <code>HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN</code>.</p>
<div class="highlight"><pre><span></span><span class="c1"># Get the token from the environment variable</span>
<span class="n">HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">"HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN"</span><span class="p">)</span>
</pre></div>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>A continuaci√≥n se crean los modelos de lenguaje, de <code>speech-to-text</code> y de <code>text-to-speech</code>, y creamos la funci√≥n <code>echo</code> que se encargar√° de gestionar el audio de entrada y salida.</p>
<div class="highlight"><pre><span></span><span class="c1"># Initialize the LLM client</span>
<span class="n">llm_client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="s2">"Maximofn/SmolLM2_localModel"</span><span class="p">)</span>

<span class="c1"># Initialize the STT and TTS models</span>
<span class="n">stt_model</span> <span class="o">=</span> <span class="n">get_stt_model</span><span class="p">()</span>
<span class="n">tts_model</span> <span class="o">=</span> <span class="n">get_tts_model</span><span class="p">()</span>

<span class="c1"># Define the echo function</span>
<span class="k">def</span> <span class="nf">echo</span><span class="p">(</span><span class="n">audio</span><span class="p">):</span>
    <span class="c1"># Convert the audio to text</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="n">stt_model</span><span class="o">.</span><span class="n">stt</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>

    <span class="c1"># Generate the response</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">llm_client</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
            <span class="n">message</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
            <span class="n">system_message</span><span class="o">=</span><span class="s2">"You are a friendly Chatbot. Always reply in the language in which the user is writing to you."</span><span class="p">,</span>
            <span class="n">max_tokens</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
            <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
            <span class="n">top_p</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span>
            <span class="n">api_name</span><span class="o">=</span><span class="s2">"/chat"</span>
    <span class="p">)</span>

    <span class="c1"># Convert the response to audio</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="n">response</span>

    <span class="c1"># Stream the audio</span>
    <span class="k">for</span> <span class="n">audio_chunk</span> <span class="ow">in</span> <span class="n">tts_model</span><span class="o">.</span><span class="n">stream_tts_sync</span><span class="p">(</span><span class="n">prompt</span><span class="p">):</span>
        <span class="k">yield</span> <span class="n">audio_chunk</span>
</pre></div>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Como antes hemos usado el puerto <code>8000</code>, por si os dice que est√° ocupado, creamos una funci√≥n para encontrar un puerto libre y encontramos uno</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">find_free_port</span><span class="p">(</span><span class="n">start_port</span><span class="o">=</span><span class="mi">8000</span><span class="p">,</span> <span class="n">max_port</span><span class="o">=</span><span class="mi">9000</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Find the first free port starting from start_port."""</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Searching for a free port starting from </span><span class="si">{opening_brace}</span><span class="n">start_port</span><span class="si">{closing_brace}</span><span class="s2">..."</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">port</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_port</span><span class="p">,</span> <span class="n">max_port</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">socket</span><span class="o">.</span><span class="n">socket</span><span class="p">(</span><span class="n">socket</span><span class="o">.</span><span class="n">AF_INET</span><span class="p">,</span> <span class="n">socket</span><span class="o">.</span><span class="n">SOCK_STREAM</span><span class="p">)</span> <span class="k">as</span> <span class="n">sock</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">sock</span><span class="o">.</span><span class="n">connect_ex</span><span class="p">((</span><span class="s1">'127.0.0.1'</span><span class="p">,</span> <span class="n">port</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">result</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># If result != 0, the port is free</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Free port found: </span><span class="si">{opening_brace}</span><span class="n">port</span><span class="si">{closing_brace}</span><span class="s2">"</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">port</span>
    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"No free port found between </span><span class="si">{opening_brace}</span><span class="n">start_port</span><span class="si">{closing_brace}</span><span class="s2"> and </span><span class="si">{opening_brace}</span><span class="n">max_port</span><span class="si">{closing_brace}</span><span class="s2">"</span><span class="p">)</span>

<span class="n">free_port</span> <span class="o">=</span> <span class="n">find_free_port</span><span class="p">()</span>    <span class="c1"># Search for a free port</span>
</pre></div>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Se crea el stream y ahora se usa <code>stream.fastphone()</code> para obtener un n√∫mero de tel√©fono gratuito para llamar a tu stream, en vez de <code>stream.ui.launch()</code> que usamos antes para crear la interfaz gr√°fica.</p>
<div class="highlight"><pre><span></span><span class="n">stream</span> <span class="o">=</span> <span class="n">Stream</span><span class="p">(</span><span class="n">ReplyOnPause</span><span class="p">(</span><span class="n">echo</span><span class="p">),</span> <span class="n">modality</span><span class="o">=</span><span class="s2">"audio"</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">"send-receive"</span><span class="p">)</span>
<span class="n">stream</span><span class="o">.</span><span class="n">fastphone</span><span class="p">(</span><span class="n">token</span><span class="o">=</span><span class="n">HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN</span><span class="p">,</span> <span class="n">port</span><span class="o">=</span><span class="n">free_port</span><span class="p">)</span>
</pre></div>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Si lo ejecutamos, veremos algo como esto:</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">!</span>python<span class="w"> </span>fastrtc_phone_demo.py',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Loaded as API: https://maximofn-smollm2-localmodel.hf.space ‚úî',
          '<span class="ansi-green-fg">INFO</span>:	  Warming up STT model.',
          '<span class="ansi-green-fg">INFO</span>:	  STT model warmed up.',
          '<span class="ansi-green-fg">INFO</span>:	  Warming up VAD model.',
          '<span class="ansi-green-fg">INFO</span>:	  VAD model warmed up.',
          'Searching for a free port starting from 8000...',
          'Free port found: 8004',
          '<span class="ansi-green-fg">INFO</span>:     Started server process [<span class="ansi-cyan-fg">24029</span>]',
          '<span class="ansi-green-fg">INFO</span>:     Waiting for application startup.',
          '<span class="ansi-green-fg">INFO</span>:	  Visit <span class="ansi-cyan-fg">https://fastrtc.org/userguide/api/</span> for WebRTC or Websocket API docs.',
          '<span class="ansi-green-fg">INFO</span>:     Application startup complete.',
          '<span class="ansi-green-fg">INFO</span>:     Uvicorn running on <span class="ansi-bold">http://127.0.0.1:8004</span> (Press CTRL+C to quit)',
          '<span class="ansi-green-fg">INFO</span>:	  Your FastPhone is now live! Call <span class="ansi-cyan-fg">+1 877-713-4471</span> and use code <span class="ansi-cyan-fg">994514</span> to connect to your stream.',
          '<span class="ansi-green-fg">INFO</span>:	  You have <span class="ansi-cyan-fg">30:00</span> minutes remaining in your quota (Resetting on <span class="ansi-cyan-fg">2025-04-07</span>)',
          '<span class="ansi-green-fg">INFO</span>:	  Visit <span class="ansi-cyan-fg">https://fastrtc.org/userguide/audio/#telephone-integration</span> for information on making your handler compatible with phone usage.',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos que aparece</p>
<div class="highlight"><pre><span></span>INFO:<span class="w">	  </span>Your<span class="w"> </span>FastPhone<span class="w"> </span>is<span class="w"> </span>now<span class="w"> </span>live!<span class="w"> </span>Call<span class="w"> </span>+1<span class="w"> </span><span class="m">877</span>-713-4471<span class="w"> </span>and<span class="w"> </span>use<span class="w"> </span>code<span class="w"> </span><span class="m">994514</span><span class="w"> </span>to<span class="w"> </span>connect<span class="w"> </span>to<span class="w"> </span>your<span class="w"> </span>stream.
INFO:<span class="w">	  </span>You<span class="w"> </span>have<span class="w"> </span><span class="m">30</span>:00<span class="w"> </span>minutes<span class="w"> </span>remaining<span class="w"> </span><span class="k">in</span><span class="w"> </span>your<span class="w"> </span>quota<span class="w"> </span><span class="o">(</span>Resetting<span class="w"> </span>on<span class="w"> </span><span class="m">2025</span>-04-07<span class="o">)</span>
</pre></div>
      <p>Es decir, si llamamos al n√∫mero <code>+1 877-713-4471</code> y usamos el c√≥digo <code>994514</code> nos conectar√° a nuestro stream.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Si nos vamos a <a href="https://fastrtc.org/userguide/audio/#telephone-integration" target="_blank" rel="nofollow noreferrer">Telephone Integration</a> de la documentaci√≥n de <code>FastRTC</code> veremos que usa <a href="https://www.twilio.com/">twilio</a> para hacer la llamada. Tiene opci√≥n para configurar un n√∫mero local desde estados unidos, Dublin, Frankfurt, Tokio, Singapur, Sidney y Sao Paulo.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>He probado a hacer la llamada desde Espa√±a (que me va a costar bastante) y funciona, pero es lento. He llamado, he metido el c√≥digo y he estado esperando a que conectara con el agente, pero como estaba tardando mucho, he colgado.</p>
      </section>
      






    </div>

  </section>

</PostLayout>
