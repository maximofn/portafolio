---
import PostLayout from '@layouts/PostLayout.astro';
import CodeBlockInputCell from '@components/CodeBlockInputCell.astro';
import CodeBlockOutputCell from '@components/CodeBlockOutputCell.astro';

const { metadata_page } = await import('@portfolio/consts.json');
const { colors } = await import('@portfolio/consts.json');
const { svg_paths } = await import('@portfolio/consts.json');

const page_title = 'Fine tuning SMLs';
const end_url = 'fine-tuning-sml';
const description = '😂 Afinar modelos de lenguaje pequeños? Por favor, no estás \'afinando\', solo estás desesperadamente intentando sacar algo de sentido de un modelo que es tan útil como una tetera de chocolate 🍫🚽. Pero hey, ¿quién no ama un buen desafío? Adelante, desperdicia tus horas de GPU, y quizás, solo quizás, obtendrás un modelo que pueda distinguir entre \'hola\' y \'adiós\' 🤖. Buena suerte, y no digas que no te advertí 😜';
const keywords = 'slm, modelos de lenguaje pequeños, afinar, chistes, humor, gpt2, openai, transformers, huggingface';
const languaje = 'ES';
const image_path = 'https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/SLM_thumnail.webp';
const opening_brace = '{';
const closing_brace = '}';
---

<PostLayout 
    title={page_title}
    languaje={languaje}
    description={description}
    keywords={keywords}
    author={metadata_page.author}
    theme_color={colors.background_color}
    end_url={end_url}
    image_path={image_path}
    image_width=900
    image_height=450
    image_extension=webp
    article_date=2024-07-14+T00:00:00Z
>

  <section class="post-body">


    <aside class="post-index">
      <a class="anchor-link" href="#Fine tuning para clasificacion de texto con Hugging Face"><h2>Fine tuning para clasificación de texto con Hugging Face</h2></a>
      <a class="anchor-link" href="#Login"><h3>Login</h3></a>
      <a class="anchor-link" href="#Dataset"><h3>Dataset</h3></a>
      <a class="anchor-link" href="#Tokenizador"><h3>Tokenizador</h3></a>
      <a class="anchor-link" href="#Modelo"><h3>Modelo</h3></a>
      <a class="anchor-link" href="#Trainer"><h3>Trainer</h3></a>
      <a class="anchor-link" href="#Evaluacion"><h3>Evaluación</h3></a>
      <a class="anchor-link" href="#Publicar el modelo"><h3>Publicar el modelo</h3></a>
      <a class="anchor-link" href="#Uso del modelo"><h3>Uso del modelo</h3></a>
      <a class="anchor-link" href="#Fine tuning para generacion de texto con Hugging Face"><h2>Fine tuning para generación de texto con Hugging Face</h2></a>
      <a class="anchor-link" href="#Login"><h3>Login</h3></a>
      <a class="anchor-link" href="#Dataset"><h3>Dataset</h3></a>
      <a class="anchor-link" href="#Tokenizador"><h3>Tokenizador</h3></a>
      <a class="anchor-link" href="#Modelo"><h3>Modelo</h3></a>
      <a class="anchor-link" href="#Entrenamiento"><h3>Entrenamiento</h3></a>
      <a class="anchor-link" href="#Evaluacion"><h3>Evaluación</h3></a>
      <a class="anchor-link" href="#Publicar el modelo"><h3>Publicar el modelo</h3></a>
      <a class="anchor-link" href="#Uso del modelo"><h3>Uso del modelo</h3></a>
      <a class="anchor-link" href="#Fine tuning para clasificacion de texto con Pytorch"><h2>Fine tuning para clasificación de texto con Pytorch</h2></a>
      <a class="anchor-link" href="#Dataset"><h3>Dataset</h3></a>
      <a class="anchor-link" href="#Tokenizador"><h3>Tokenizador</h3></a>
      <a class="anchor-link" href="#Modelo"><h3>Modelo</h3></a>
      <a class="anchor-link" href="#Device"><h3>Device</h3></a>
      <a class="anchor-link" href="#Pytorch Dataset"><h3>Pytorch Dataset</h3></a>
      <a class="anchor-link" href="#Pytorch Dataloader"><h3>Pytorch Dataloader</h3></a>
      <a class="anchor-link" href="#Metrica"><h3>Métrica</h3></a>
      <a class="anchor-link" href="#Optimizador"><h3>Optimizador</h3></a>
      <a class="anchor-link" href="#Entrenamiento"><h3>Entrenamiento</h3></a>
      <a class="anchor-link" href="#Uso del modelo"><h3>Uso del modelo</h3></a>
      <a class="anchor-link" href="#Fine tuning para generacion de texto con Pytorch"><h2>Fine tuning para generación de texto con Pytorch</h2></a>
      <a class="anchor-link" href="#Dataset"><h3>Dataset</h3></a>
      <a class="anchor-link" href="#Tokenizador"><h3>Tokenizador</h3></a>
      <a class="anchor-link" href="#Modelo"><h3>Modelo</h3></a>
      <a class="anchor-link" href="#Device"><h3>Device</h3></a>
      <a class="anchor-link" href="#Pytorch Dataset"><h3>Pytorch Dataset</h3></a>
      <a class="anchor-link" href="#Pytorch Dataloader"><h3>Pytorch Dataloader</h3></a>
      <a class="anchor-link" href="#Optimizador"><h3>Optimizador</h3></a>
      <a class="anchor-link" href="#Entrenamiento"><h3>Entrenamiento</h3></a>
      <a class="anchor-link" href="#Uso del modelo"><h3>Uso del modelo</h3></a>
    </aside>


    <div class="post-body-content">
      
      <section class="section-block-markdown-cell">
      </section>
      
      <section class="section-block-markdown-cell">
      <p>En este post vamos a ver cómo hacer fine tuning a pequeños modelos de lenguaje, vamos a ver cómo hacer fine tuning para clasificación de texto y para generación de texto. Primero vamos a ver cómo hacerlo con las librerías de Hugging Face, ya que Hugging Face se ha convertido en un actor muy importante en el ecosistema de IA en estos momentos.</p>
      <p>Pero aunque las librerías de Hugging Face son muy importantes y útiles, es muy importante saber cómo se hace realmente el entrenamiento y qué está pasando por debajo, así que vamos a repetir el entrenamiento para clasificación y generación de texto pero con Pytorch</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Fine tuning para clasificacion de texto con Hugging Face">Fine tuning para clasificación de texto con Hugging Face<a class="anchor-link" href="#Fine tuning para clasificacion de texto con Hugging Face"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 1" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Login">Login<a class="anchor-link" href="#Login"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 2" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Para poder subir el resultado del entrenamiento al hub debemos logearnos primero, para ello necesitamos un token</p>
      <p>Para crear un token hay que ir a la página de <a href="https://huggingface.co/settings/tokens" target="_blank" rel="nofollow noreferrer">settings/tokens</a> de nuestra cuenta, nos aparecerá algo así</p>
      <img decoding="async" onerror="this.parentNode.removeChild(this)" src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/User-Access-Token-dark.webp" alt="User-Access-Token-dark">
      <p>Le damos a <code>New token</code> y nos aparecerá una ventana para crear un nuevo token</p>
      <img decoding="async" onerror="this.parentNode.removeChild(this)" src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/new-token-dark.webp" alt="new-token-dark">
      <p>Le damos un nombre al token y lo creamos con el rol <code>write</code>, o con el rol <code>Fine-grained</code>, que nos permite seleccionar exactamente cuáles permisos tendrá el token</p>
      <p>Una vez creado lo copiamos y lo pegamos a continuación</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">huggingface_hub</span><span class="w"> </span><span class="kn">import</span> <span class="n">notebook_login</span>',
      '<span class="n">notebook_login</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Dataset">Dataset<a class="anchor-link" href="#Dataset"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 3" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Ahora nos descargamos un dataset, en este caso nos vamos a descargar uno de reviews de <a href="https://huggingface.co/datasets/mteb/amazon_reviews_multi" target="_blank" rel="nofollow noreferrer">Amazon</a></p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>',
      '<span class="w"> </span>',
      '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;mteb/amazon_reviews_multi&quot;</span><span class="p">,</span> <span class="s2">&quot;en&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a verlo un poco</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">dataset</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'DatasetDict(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;train: Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;id&#x27;, &#x27;text&#x27;, &#x27;label&#x27;, &#x27;label_text&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 200000',
          '&#x20;&#x20;&#x20;&#x20;&#x7D;)',
          '&#x20;&#x20;&#x20;&#x20;validation: Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;id&#x27;, &#x27;text&#x27;, &#x27;label&#x27;, &#x27;label_text&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 5000',
          '&#x20;&#x20;&#x20;&#x20;&#x7D;)',
          '&#x20;&#x20;&#x20;&#x20;test: Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;id&#x27;, &#x27;text&#x27;, &#x27;label&#x27;, &#x27;label_text&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 5000',
          '&#x20;&#x20;&#x20;&#x20;&#x7D;)',
          '&#x7D;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos que tiene un conjunto de entrenamiento con 200.000 muestras, uno de validación con 5.000 muestras y uno de test de 5.000 muestras</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a ver un ejemplo del conjunto de entrenamiento</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">random</span><span class="w"> </span><span class="kn">import</span> <span class="n">randint</span>',
      '<span class="w"> </span>',
      '<span class="n">idx</span> <span class="o">=</span> <span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>',
      '<span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '&#x7B;&#x27;id&#x27;: &#x27;en_0907914&#x27;,',
          '&#x27;text&#x27;: &#x27;Mixed with fir it’s passable\n\nNot the scent I had hoped for . Love the scent of cedar, but this one missed&#x27;,',
          '&#x27;label&#x27;: 3,',
          '&#x27;label_text&#x27;: &#x27;3&#x27;&#x7D;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos que tiene la review en el campo <code>text</code> y la puntuación que le ha dado el usuario en el campo <code>label</code></p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Como vamos a hacer un modelo de clasificación de textos, necesitamos saber cuántas clases vamos a tener</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="s1">&#39;label&#39;</span><span class="p">))</span>',
      '<span class="n">num_classes</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '5',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a tener 5 clases, ahora vamos a ver el valor mínimo de estas clases para saber si la puntuación comienza en 0 o en 1. Para ello usamos el método <code>unique</code></p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">dataset</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="s1">&#39;label&#39;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '&#x7B;&#x27;train&#x27;: [0, 1, 2, 3, 4],',
          '&#x27;validation&#x27;: [0, 1, 2, 3, 4],',
          '&#x27;test&#x27;: [0, 1, 2, 3, 4]&#x7D;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>El mínimo valor va a ser 0</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Para entrenar, las etiquetas tienen que estar en un campo llamado <code>labels</code>, mientras que en nuestro dataset está en un campo que se llama <code>label</code>, por lo que creamos el nuevo campo <code>labels</code> con el mismo valor que <code>label</code></p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Creamos una función que haga lo que queramos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">def</span><span class="w"> </span><span class="nf">set_labels</span><span class="p">(</span><span class="n">example</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">example</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">example</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">example</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Aplicamos la función al dataset</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">set_labels</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a ver cómo queda el dataset</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '&#x7B;&#x27;id&#x27;: &#x27;en_0907914&#x27;,',
          '&#x27;text&#x27;: &#x27;Mixed with fir it’s passable\n\nNot the scent I had hoped for . Love the scent of cedar, but this one missed&#x27;,',
          '&#x27;label&#x27;: 3,',
          '&#x27;label_text&#x27;: &#x27;3&#x27;,',
          '&#x27;labels&#x27;: 3&#x7D;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Tokenizador">Tokenizador<a class="anchor-link" href="#Tokenizador"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 4" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Como en el dataset tenemos las reviews en texto, necesitamos tokenizarlas para poder meter los tokens al modelo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>',
      '<span class="w"> </span>',
      '<span class="n">checkpoint</span> <span class="o">=</span> <span class="s2">&quot;openai-community/gpt2&quot;</span>',
      '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Ahora creamos una función para tokenizar el texto. Lo vamos a hacer de manera que todas las sentencias tengan la misma longitud, de manera que el tokenizador truncará cuando sea necesario y añadirá tokens de padding cuando sea necesario. Además le indicamos que devuelva tensores de pytorch</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Hacemos que la longitud de cada sentencia sea de 768 tokens porque estamos usando el modelo pequeño de GPT2, que como vimos en el post de <a href="https://maximofn.com/gpt2/#Arquitectura">GPT2</a> tiene una dimensión de embedding de 768 tokens</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a probar a tokenizar un texto</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">][</span><span class="n">idx</span><span class="p">])</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '---------------------------------------------------------------------------ValueError                                Traceback (most recent call last)Cell In[11], line 1',
          '----&amp;gt; 1 tokens = tokenize_function(dataset[&#x27;train&#x27;][idx])',
          'Cell In[10], line 2, in tokenize_function(examples)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;1 def tokenize_function(examples):',
          '----&amp;gt; 2     return tokenizer(examples[&quot;text&quot;], padding=&quot;max_length&quot;, truncation=True, max_length=768, return_tensors=&quot;pt&quot;)',
          'File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2883, in PreTrainedTokenizerBase.__call__(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)',
          '&#x20;&#x20;&#x20;2881     if not self._in_target_context_manager:',
          '&#x20;&#x20;&#x20;2882         self._switch_to_input_mode()',
          '-&amp;gt; 2883     encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)',
          '&#x20;&#x20;&#x20;2884 if text_target is not None:',
          '&#x20;&#x20;&#x20;2885     self._switch_to_target_mode()',
          'File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2989, in PreTrainedTokenizerBase._call_one(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)',
          '&#x20;&#x20;&#x20;2969     return self.batch_encode_plus(',
          '&#x20;&#x20;&#x20;2970         batch_text_or_text_pairs=batch_text_or_text_pairs,',
          '&#x20;&#x20;&#x20;2971         add_special_tokens=add_special_tokens,',
          '&#x20;&#x20;&#x20;(...)',
          '&#x20;&#x20;&#x20;2986         **kwargs,',
          '&#x20;&#x20;&#x20;2987     )',
          '&#x20;&#x20;&#x20;2988 else:',
          '-&amp;gt; 2989     return self.encode_plus(',
          '&#x20;&#x20;&#x20;2990         text=text,',
          '&#x20;&#x20;&#x20;2991         text_pair=text_pair,',
          '&#x20;&#x20;&#x20;2992         add_special_tokens=add_special_tokens,',
          '&#x20;&#x20;&#x20;2993         padding=padding,',
          '&#x20;&#x20;&#x20;2994         truncation=truncation,',
          '&#x20;&#x20;&#x20;2995         max_length=max_length,',
          '&#x20;&#x20;&#x20;2996         stride=stride,',
          '&#x20;&#x20;&#x20;2997         is_split_into_words=is_split_into_words,',
          '&#x20;&#x20;&#x20;2998         pad_to_multiple_of=pad_to_multiple_of,',
          '&#x20;&#x20;&#x20;2999         return_tensors=return_tensors,',
          '&#x20;&#x20;&#x20;3000         return_token_type_ids=return_token_type_ids,',
          '&#x20;&#x20;&#x20;3001         return_attention_mask=return_attention_mask,',
          '&#x20;&#x20;&#x20;3002         return_overflowing_tokens=return_overflowing_tokens,',
          '&#x20;&#x20;&#x20;3003         return_special_tokens_mask=return_special_tokens_mask,',
          '&#x20;&#x20;&#x20;3004         return_offsets_mapping=return_offsets_mapping,',
          '&#x20;&#x20;&#x20;3005         return_length=return_length,',
          '&#x20;&#x20;&#x20;3006         verbose=verbose,',
          '&#x20;&#x20;&#x20;3007         **kwargs,',
          '&#x20;&#x20;&#x20;3008     )',
          'File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3053, in PreTrainedTokenizerBase.encode_plus(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)',
          '&#x20;&#x20;&#x20;3032 &quot;&quot;&quot;',
          '&#x20;&#x20;&#x20;3033 Tokenize and prepare for the model a sequence or a pair of sequences.',
          '&#x20;&#x20;&#x20;3034',
          '&#x20;&#x20;&#x20;(...)',
          '&#x20;&#x20;&#x20;3049         method).',
          '&#x20;&#x20;&#x20;3050 &quot;&quot;&quot;',
          '&#x20;&#x20;&#x20;3052 # Backward compatibility for &#x27;truncation_strategy&#x27;, &#x27;pad_to_max_length&#x27;',
          '-&amp;gt; 3053 padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(',
          '&#x20;&#x20;&#x20;3054     padding=padding,',
          '&#x20;&#x20;&#x20;3055     truncation=truncation,',
          '&#x20;&#x20;&#x20;3056     max_length=max_length,',
          '&#x20;&#x20;&#x20;3057     pad_to_multiple_of=pad_to_multiple_of,',
          '&#x20;&#x20;&#x20;3058     verbose=verbose,',
          '&#x20;&#x20;&#x20;3059     **kwargs,',
          '&#x20;&#x20;&#x20;3060 )',
          '&#x20;&#x20;&#x20;3062 return self._encode_plus(',
          '&#x20;&#x20;&#x20;3063     text=text,',
          '&#x20;&#x20;&#x20;3064     text_pair=text_pair,',
          '&#x20;&#x20;&#x20;(...)',
          '&#x20;&#x20;&#x20;3080     **kwargs,',
          '&#x20;&#x20;&#x20;3081 )',
          'File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2788, in PreTrainedTokenizerBase._get_padding_truncation_strategies(self, padding, truncation, max_length, pad_to_multiple_of, verbose, **kwargs)',
          '&#x20;&#x20;&#x20;2786 # Test if we have a padding token',
          '&#x20;&#x20;&#x20;2787 if padding_strategy != PaddingStrategy.DO_NOT_PAD and (self.pad_token is None or self.pad_token_id &amp;lt; 0):',
          '-&amp;gt; 2788     raise ValueError(',
          '&#x20;&#x20;&#x20;2789         &quot;Asking to pad but the tokenizer does not have a padding token. &quot;',
          '&#x20;&#x20;&#x20;2790         &quot;Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` &quot;',
          '&#x20;&#x20;&#x20;2791         &quot;or add a new pad token via `tokenizer.add_special_tokens(&#x7B;&#x27;pad_token&#x27;: &#x27;[PAD]&#x27;&#x7D;)`.&quot;',
          '&#x20;&#x20;&#x20;2792     )',
          '&#x20;&#x20;&#x20;2794 # Check that we will truncate to a multiple of pad_to_multiple_of if both are provided',
          '&#x20;&#x20;&#x20;2795 if (',
          '&#x20;&#x20;&#x20;2796     truncation_strategy != TruncationStrategy.DO_NOT_TRUNCATE',
          '&#x20;&#x20;&#x20;2797     and padding_strategy != PaddingStrategy.DO_NOT_PAD',
          '&#x20;&#x20;&#x20;(...)',
          '&#x20;&#x20;&#x20;2800     and (max_length % pad_to_multiple_of != 0)',
          '&#x20;&#x20;&#x20;2801 ):',
          'ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens(&#x7B;&#x27;pad_token&#x27;: &#x27;[PAD]&#x27;&#x7D;)`.',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Nos da un error porque el tokenizador de GPT2 no tiene un token para padding y nos pide que asignemos uno, además nos sugiere hacer <code>tokenizer.pad_token = tokenizer.eos_token</code>, así que lo hacemos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Volvemos a probar la función de tokenización</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">][</span><span class="n">idx</span><span class="p">])</span>',
      '<span class="n">tokens</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">tokens</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '(torch.Size([1, 768]), torch.Size([1, 768]))',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Ahora que hemos comprobado que la función tokeniza bien, aplicamos esta función al dataset, pero además la aplicamos por batches para que se ejecute más rápido</p>
      <p>Además, aprovechamos y eliminamos las columnas que no vamos a necesitar</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="s1">&#39;label_text&#39;</span><span class="p">])</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos ahora cómo queda el dataset</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">dataset</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'DatasetDict(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;train: Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;id&#x27;, &#x27;text&#x27;, &#x27;label&#x27;, &#x27;label_text&#x27;, &#x27;labels&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 200000',
          '&#x20;&#x20;&#x20;&#x20;&#x7D;)',
          '&#x20;&#x20;&#x20;&#x20;validation: Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;id&#x27;, &#x27;text&#x27;, &#x27;label&#x27;, &#x27;label_text&#x27;, &#x27;labels&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 5000',
          '&#x20;&#x20;&#x20;&#x20;&#x7D;)',
          '&#x20;&#x20;&#x20;&#x20;test: Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;id&#x27;, &#x27;text&#x27;, &#x27;label&#x27;, &#x27;label_text&#x27;, &#x27;labels&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 5000',
          '&#x20;&#x20;&#x20;&#x20;&#x7D;)',
          '&#x7D;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos que tenemos los campos 'labels', 'input_ids' y 'attention_mask', que es lo que nos interesa para entrenar</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Modelo">Modelo<a class="anchor-link" href="#Modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 5" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Instanciamos un modelo para clasificación de secuencias y le indicamos el número de clases que tenemos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span>',
      '<span class="w"> </span>',
      '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="n">num_classes</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: [&#x27;score.weight&#x27;]',
          'You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Nos dice que los pesos de la capa <code>score</code> han sido inicializados de manera aleatoria y que tenemos que reentrenarlos, vamos a ver por qué pasa esto</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>El modelo de GPT2 sería este</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span>',
      '<span class="w"> </span>',
      '<span class="n">casual_model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Mientras que el modelo de GPT2 para generar texto es este</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a ver su arquitectura</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">casual_model</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'GPT2LMHeadModel(',
          '&#x20;&#x20;(transformer): GPT2Model(',
          '&#x20;&#x20;&#x20;&#x20;(wte): Embedding(50257, 768)',
          '&#x20;&#x20;&#x20;&#x20;(wpe): Embedding(1024, 768)',
          '&#x20;&#x20;&#x20;&#x20;(drop): Dropout(p=0.1, inplace=False)',
          '&#x20;&#x20;&#x20;&#x20;(h): ModuleList(',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(0-11): 12 x GPT2Block(',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(attn): GPT2Attention(',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(c_attn): Conv1D()',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(c_proj): Conv1D()',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(attn_dropout): Dropout(p=0.1, inplace=False)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(resid_dropout): Dropout(p=0.1, inplace=False)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(mlp): GPT2MLP(',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(c_fc): Conv1D()',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(c_proj): Conv1D()',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(act): NewGELUActivation()',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(dropout): Dropout(p=0.1, inplace=False)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)',
          '&#x20;&#x20;&#x20;&#x20;)',
          '&#x20;&#x20;&#x20;&#x20;(ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)',
          '&#x20;&#x20;)',
          '&#x20;&#x20;(lm_head): Linear(in_features=768, out_features=50257, bias=False)',
          ')',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Y ahora la arquitectura del modelo que vamos a usar para clasificar las reviews</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">model</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'GPT2ForSequenceClassification(',
          '&#x20;&#x20;(transformer): GPT2Model(',
          '&#x20;&#x20;&#x20;&#x20;(wte): Embedding(50257, 768)',
          '&#x20;&#x20;&#x20;&#x20;(wpe): Embedding(1024, 768)',
          '&#x20;&#x20;&#x20;&#x20;(drop): Dropout(p=0.1, inplace=False)',
          '&#x20;&#x20;&#x20;&#x20;(h): ModuleList(',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(0-11): 12 x GPT2Block(',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(attn): GPT2Attention(',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(c_attn): Conv1D()',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(c_proj): Conv1D()',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(attn_dropout): Dropout(p=0.1, inplace=False)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(resid_dropout): Dropout(p=0.1, inplace=False)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(mlp): GPT2MLP(',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(c_fc): Conv1D()',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(c_proj): Conv1D()',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(act): NewGELUActivation()',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(dropout): Dropout(p=0.1, inplace=False)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)',
          '&#x20;&#x20;&#x20;&#x20;)',
          '&#x20;&#x20;&#x20;&#x20;(ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)',
          '&#x20;&#x20;)',
          '&#x20;&#x20;(score): Linear(in_features=768, out_features=5, bias=False)',
          ')',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>De aquí hay dos cosas que mencionar</p>
      <ul>
        <li>La primera es que en ambos, la primera capa tiene dimensiones de 50257x768, que corresponde a 50257 posibles tokens del vocabulario de GPT2 y a 768 dimensiones del embedding, por lo que hemos hecho bien en tokenizar las reviews con un tamaño de 768 tokens</li>
        <li>La segunda es que el modelo <code>casual</code> (el de generación de texto) tiene al final una capa <code>Linear</code> que genera 50257 valores, es decir, es la encargada de predecir el siguiente token y a posible token le da un valor. Mientras que el modelo de clasificación tiene una capa <code>Linear</code> que solo genera 5 valores, uno por cada clase, lo que nos dará la probabilidad de que la review pertenezca a cada clase</li>
      </ul>
      <p>Por eso nos salía el mensaje de que los pesos de la capa <code>score</code> habían sido inicializados de manera aleatoria, porque la librería transformers ha eliminado la capa <code>Linear</code> de 768x50257 y ha añadido una capa <code>Linear</code> de 768x5, la ha inicializado con valores aleatorios y nosotros la tenemos que entrenar para nuestro problema en particular</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Borramos el modelo casual, porque no lo vamos a usar</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">del</span> <span class="n">casual_model</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Trainer">Trainer<a class="anchor-link" href="#Trainer"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 6" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos ahora a configurar los argumentos del entrenamiento</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">TrainingArguments</span>',
      '<span class="w"> </span>',
      '<span class="n">metric_name</span> <span class="o">=</span> <span class="s2">&quot;accuracy&quot;</span>',
      '<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;GPT2-small-finetuned-amazon-reviews-en-classification&quot;</span>',
      '<span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>',
      '<span class="n">BS_TRAIN</span> <span class="o">=</span> <span class="mi">28</span>',
      '<span class="n">BS_EVAL</span> <span class="o">=</span> <span class="mi">40</span>',
      '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>',
      '<span class="n">WEIGHT_DECAY</span> <span class="o">=</span> <span class="mf">0.01</span>',
      '<span class="w"> </span>',
      '<span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
      '<span class="w">    </span><span class="n">model_name</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">eval_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">save_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">&quot;cosine&quot;</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '<span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Definimos una métrica para el dataloader de validación</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">evaluate</span><span class="w"> </span><span class="kn">import</span> <span class="n">load</span>',
      '<span class="w"> </span>',
      '<span class="n">metric</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">compute_metrics</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">):</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">eval_pred</span>',
      '<span class="w">    </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Definimos ahora el trainer</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Trainer</span>',
      '<span class="w"> </span>',
      '<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
      '<span class="w">    </span><span class="n">model</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">training_args</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">],</span>',
      '<span class="w">    </span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;validation&#39;</span><span class="p">],</span>',
      '<span class="w">    </span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>',
      '<span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Entrenamos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '&#x20;&#x20;0%|          | 0/600000 [00:00&amp;lt;?, ?it/s]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockOutputCell
        text={[
          '---------------------------------------------------------------------------ValueError                                Traceback (most recent call last)Cell In[21], line 1',
          '----&amp;gt; 1 trainer.train()',
          'File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/trainer.py:1876, in Trainer.train(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)',
          '&#x20;&#x20;&#x20;1873 try:',
          '&#x20;&#x20;&#x20;1874     # Disable progress bars when uploading models during checkpoints to avoid polluting stdout',
          '&#x20;&#x20;&#x20;1875     hf_hub_utils.disable_progress_bars()',
          '-&amp;gt; 1876     return inner_training_loop(',
          '&#x20;&#x20;&#x20;1877         args=args,',
          '&#x20;&#x20;&#x20;1878         resume_from_checkpoint=resume_from_checkpoint,',
          '&#x20;&#x20;&#x20;1879         trial=trial,',
          '&#x20;&#x20;&#x20;1880         ignore_keys_for_eval=ignore_keys_for_eval,',
          '&#x20;&#x20;&#x20;1881     )',
          '&#x20;&#x20;&#x20;1882 finally:',
          '&#x20;&#x20;&#x20;1883     hf_hub_utils.enable_progress_bars()',
          'File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/trainer.py:2178, in Trainer._inner_training_loop(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)',
          '&#x20;&#x20;&#x20;2175     rng_to_sync = True',
          '&#x20;&#x20;&#x20;2177 step = -1',
          '-&amp;gt; 2178 for step, inputs in enumerate(epoch_iterator):',
          '&#x20;&#x20;&#x20;2179     total_batched_samples += 1',
          '&#x20;&#x20;&#x20;2181     if self.args.include_num_input_tokens_seen:',
          'File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/accelerate/data_loader.py:454, in DataLoaderShard.__iter__(self)',
          '&#x20;&#x20;&#x20;&#x20;452 # We iterate one batch ahead to check when we are at the end',
          '&#x20;&#x20;&#x20;&#x20;453 try:',
          '--&amp;gt; 454     current_batch = next(dataloader_iter)',
          '&#x20;&#x20;&#x20;&#x20;455 except StopIteration:',
          '&#x20;&#x20;&#x20;&#x20;456     yield',
          'File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631, in _BaseDataLoaderIter.__next__(self)',
          '&#x20;&#x20;&#x20;&#x20;628 if self._sampler_iter is None:',
          '&#x20;&#x20;&#x20;&#x20;629     # TODO(https://github.com/pytorch/pytorch/issues/76750)',
          '&#x20;&#x20;&#x20;&#x20;630     self._reset()  # type: ignore[call-arg]',
          '--&amp;gt; 631 data = self._next_data()',
          '&#x20;&#x20;&#x20;&#x20;632 self._num_yielded += 1',
          '&#x20;&#x20;&#x20;&#x20;633 if self._dataset_kind == _DatasetKind.Iterable and \\',
          '&#x20;&#x20;&#x20;&#x20;634         self._IterableDataset_len_called is not None and \\',
          '&#x20;&#x20;&#x20;&#x20;635         self._num_yielded &amp;gt; self._IterableDataset_len_called:',
          'File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675, in _SingleProcessDataLoaderIter._next_data(self)',
          '&#x20;&#x20;&#x20;&#x20;673 def _next_data(self):',
          '&#x20;&#x20;&#x20;&#x20;674     index = self._next_index()  # may raise StopIteration',
          '--&amp;gt; 675     data = self._dataset_fetcher.fetch(index)  # may raise StopIteration',
          '&#x20;&#x20;&#x20;&#x20;676     if self._pin_memory:',
          '&#x20;&#x20;&#x20;&#x20;677         data = _utils.pin_memory.pin_memory(data, self._pin_memory_device)',
          'File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:54, in _MapDatasetFetcher.fetch(self, possibly_batched_index)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;52 else:',
          '&#x20;&#x20;&#x20;&#x20;&#x20;53     data = self.dataset[possibly_batched_index]',
          '---&amp;gt; 54 return self.collate_fn(data)',
          'File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/data/data_collator.py:271, in DataCollatorWithPadding.__call__(self, features)',
          '&#x20;&#x20;&#x20;&#x20;270 def __call__(self, features: List[Dict[str, Any]]) -&amp;gt; Dict[str, Any]:',
          '--&amp;gt; 271     batch = pad_without_fast_tokenizer_warning(',
          '&#x20;&#x20;&#x20;&#x20;272         self.tokenizer,',
          '&#x20;&#x20;&#x20;&#x20;273         features,',
          '&#x20;&#x20;&#x20;&#x20;274         padding=self.padding,',
          '&#x20;&#x20;&#x20;&#x20;275         max_length=self.max_length,',
          '&#x20;&#x20;&#x20;&#x20;276         pad_to_multiple_of=self.pad_to_multiple_of,',
          '&#x20;&#x20;&#x20;&#x20;277         return_tensors=self.return_tensors,',
          '&#x20;&#x20;&#x20;&#x20;278     )',
          '&#x20;&#x20;&#x20;&#x20;279     if &quot;label&quot; in batch:',
          '&#x20;&#x20;&#x20;&#x20;280         batch[&quot;labels&quot;] = batch[&quot;label&quot;]',
          'File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/data/data_collator.py:66, in pad_without_fast_tokenizer_warning(tokenizer, *pad_args, **pad_kwargs)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;63 tokenizer.deprecation_warnings[&quot;Asking-to-pad-a-fast-tokenizer&quot;] = True',
          '&#x20;&#x20;&#x20;&#x20;&#x20;65 try:',
          '---&amp;gt; 66     padded = tokenizer.pad(*pad_args, **pad_kwargs)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;67 finally:',
          '&#x20;&#x20;&#x20;&#x20;&#x20;68     # Restore the state of the warning.',
          '&#x20;&#x20;&#x20;&#x20;&#x20;69     tokenizer.deprecation_warnings[&quot;Asking-to-pad-a-fast-tokenizer&quot;] = warning_state',
          'File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3299, in PreTrainedTokenizerBase.pad(self, encoded_inputs, padding, max_length, pad_to_multiple_of, return_attention_mask, return_tensors, verbose)',
          '&#x20;&#x20;&#x20;3297 # The model&#x27;s main input name, usually `input_ids`, has be passed for padding',
          '&#x20;&#x20;&#x20;3298 if self.model_input_names[0] not in encoded_inputs:',
          '-&amp;gt; 3299     raise ValueError(',
          '&#x20;&#x20;&#x20;3300         &quot;You should supply an encoding or a list of encodings to this method &quot;',
          '&#x20;&#x20;&#x20;3301         f&quot;that includes &#x7B;self.model_input_names[0]&#x7D;, but you provided &#x7B;list(encoded_inputs.keys())&#x7D;&quot;',
          '&#x20;&#x20;&#x20;3302     )',
          '&#x20;&#x20;&#x20;3304 required_input = encoded_inputs[self.model_input_names[0]]',
          '&#x20;&#x20;&#x20;3306 if required_input is None or (isinstance(required_input, Sized) and len(required_input) == 0):',
          'ValueError: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided [&#x27;label&#x27;, &#x27;labels&#x27;]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Nos vuelve a salir un error porque el modelo no tiene asignado un token de padding, así que al igual que con el tokenizador se lo asignamos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Volvemos a crear los argumentos del trainer con el nuevo modelo, que ahora sí tiene token de padding, el trainer y volvemos a entrenar</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
      '<span class="w">    </span><span class="n">model_name</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">eval_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">save_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">&quot;cosine&quot;</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">logging_dir</span><span class="o">=</span><span class="s2">&quot;./runs&quot;</span><span class="p">,</span>',
      '<span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
      '<span class="w">    </span><span class="n">model</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">training_args</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">],</span>',
      '<span class="w">    </span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;validation&#39;</span><span class="p">],</span>',
      '<span class="w">    </span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>',
      '<span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Ahora que hemos visto que está todo bien, podemos entrenar</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '&amp;lt;IPython.core.display.HTML object&amp;gt;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockOutputCell
        text={[
          '&amp;lt;IPython.core.display.HTML object&amp;gt;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockOutputCell
        text={[
          '&amp;lt;transformers.trainer_utils.EvalPrediction object at 0x782767ea1450&amp;gt;',
          '&amp;lt;transformers.trainer_utils.EvalPrediction object at 0x782767eeefe0&amp;gt;',
          '&amp;lt;transformers.trainer_utils.EvalPrediction object at 0x782767eecfd0&amp;gt;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockOutputCell
        text={[
          'TrainOutput(global_step=21429, training_loss=0.7846888848762739, metrics=&#x7B;&#x27;train_runtime&#x27;: 26367.7801, &#x27;train_samples_per_second&#x27;: 22.755, &#x27;train_steps_per_second&#x27;: 0.813, &#x27;total_flos&#x27;: 2.35173445632e+17, &#x27;train_loss&#x27;: 0.7846888848762739, &#x27;epoch&#x27;: 3.0&#x7D;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Evaluacion">Evaluación<a class="anchor-link" href="#Evaluacion"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 7" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Una vez entrenado, evaluamos sobre el dataset de test</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">])</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '&amp;lt;IPython.core.display.HTML object&amp;gt;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockOutputCell
        text={[
          '&amp;lt;transformers.trainer_utils.EvalPrediction object at 0x7826ddfded40&amp;gt;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockOutputCell
        text={[
          '&#x7B;&#x27;eval_loss&#x27;: 0.7973636984825134,',
          '&#x27;eval_accuracy&#x27;: 0.6626,',
          '&#x27;eval_runtime&#x27;: 76.3016,',
          '&#x27;eval_samples_per_second&#x27;: 65.529,',
          '&#x27;eval_steps_per_second&#x27;: 1.638,',
          '&#x27;epoch&#x27;: 3.0&#x7D;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Publicar el modelo">Publicar el modelo<a class="anchor-link" href="#Publicar el modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 8" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Ya tenemos nuestro modelo entrenado, ya podemos compartirlo con el mundo, así que primero creamos una **model card**</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">create_model_card</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Y ya lo podemos publicar. Como lo primero que hemos hecho ha sido loguearnos con el hub de huggingface, lo podremos subir a nuestro hub sin ningún problema</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">push_to_hub</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Uso del modelo">Uso del modelo<a class="anchor-link" href="#Uso del modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 9" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Limpiamos todo lo posible</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">gc</span>',
      '<span class="w"> </span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">clear_hardwares</span><span class="p">():</span>',
      '<span class="w">    </span><span class="n">torch</span><span class="o">.</span><span class="n">clear_autocast_cache</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">ipc_collect</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="n">clear_hardwares</span><span class="p">()</span>',
      '<span class="n">clear_hardwares</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Como hemos subido el modelo a nuestro hub, podemos descargarlo y usarlo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">pipeline</span>',
      '<span class="w"> </span>',
      '<span class="n">user</span> <span class="o">=</span> <span class="s2">&quot;maximofn&quot;</span>',
      '<span class="n">checkpoints</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">user</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span>',
      '<span class="n">task</span> <span class="o">=</span> <span class="s2">&quot;text-classification&quot;</span>',
      '<span class="n">classifier</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">checkpoints</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">checkpoints</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Ahora si queremos que nos devuelva la probabilidad de todas las clases, simplemente usamos el clasificador que acabamos de instanciar, con el parámetro <code>top_k=None</code></p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">labels</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="s2">&quot;I love this product&quot;</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>',
      '<span class="n">labels</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '[&#x7B;&#x27;label&#x27;: &#x27;LABEL_4&#x27;, &#x27;score&#x27;: 0.8253807425498962&#x7D;,',
          '&#x7B;&#x27;label&#x27;: &#x27;LABEL_3&#x27;, &#x27;score&#x27;: 0.15411493182182312&#x7D;,',
          '&#x7B;&#x27;label&#x27;: &#x27;LABEL_2&#x27;, &#x27;score&#x27;: 0.013907806016504765&#x7D;,',
          '&#x7B;&#x27;label&#x27;: &#x27;LABEL_0&#x27;, &#x27;score&#x27;: 0.003939222544431686&#x7D;,',
          '&#x7B;&#x27;label&#x27;: &#x27;LABEL_1&#x27;, &#x27;score&#x27;: 0.0026572425849735737&#x7D;]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Si solo queremos la clase con la mayor probabilidad, hacemos lo mismo pero con el parámetro <code>top_k=1</code></p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">label</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="s2">&quot;I love this product&quot;</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
      '<span class="n">label</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '[&#x7B;&#x27;label&#x27;: &#x27;LABEL_4&#x27;, &#x27;score&#x27;: 0.8253807425498962&#x7D;]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Y si queremos n clases, hacemos lo mismo pero con el parámetro <code>top_k=n</code></p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">two_labels</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="s2">&quot;I love this product&quot;</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>',
      '<span class="n">two_labels</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '[&#x7B;&#x27;label&#x27;: &#x27;LABEL_4&#x27;, &#x27;score&#x27;: 0.8253807425498962&#x7D;,',
          '&#x7B;&#x27;label&#x27;: &#x27;LABEL_3&#x27;, &#x27;score&#x27;: 0.15411493182182312&#x7D;]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>También podemos probar el modelo con Automodel y AutoTokenizer</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>',
      '<span class="w"> </span>',
      '<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;GPT2-small-finetuned-amazon-reviews-en-classification&quot;</span>',
      '<span class="n">user</span> <span class="o">=</span> <span class="s2">&quot;maximofn&quot;</span>',
      '<span class="n">checkpoint</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">user</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span>',
      '<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">5</span>',
      '<span class="w"> </span>',
      '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>',
      '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="n">num_classes</span><span class="p">)</span><span class="o">.</span><span class="n">half</span><span class="p">()</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">&quot;I love this product&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>',
      '<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
      '<span class="w">    </span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>',
      '<span class="n">logits</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">logits</span>',
      '<span class="n">lables</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>',
      '<span class="n">lables</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '[0.003963470458984375,',
          '0.0026721954345703125,',
          '0.01397705078125,',
          '0.154541015625,',
          '0.82470703125]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Si quieres probar más el modelo puedes verlo en <a href="https://huggingface.co/Maximofn/GPT2-small-finetuned-amazon-reviews-en-classification" target="_blank" rel="nofollow noreferrer">Maximofn/GPT2-small-finetuned-amazon-reviews-en-classification</a></p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Fine tuning para generacion de texto con Hugging Face">Fine tuning para generación de texto con Hugging Face<a class="anchor-link" href="#Fine tuning para generacion de texto con Hugging Face"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 10" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Para asegurarme de no tener problemas de memoria VRAM, reinicio el notebook</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Login">Login<a class="anchor-link" href="#Login"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 11" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Para poder subir el resultado del entrenamiento al hub debemos logearnos primero, para ello necesitamos un token</p>
      <p>Para crear un token hay que ir a la página de <a href="https://huggingface.co/settings/tokens" target="_blank" rel="nofollow noreferrer">settings/tokens</a> de nuestra cuenta, nos aparecerá algo así</p>
      <img decoding="async" onerror="this.parentNode.removeChild(this)" src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/User-Access-Token-dark.webp" alt="User-Access-Token-dark">
      <p>Le damos a <code>New token</code> y nos aparecerá una ventana para crear un nuevo token</p>
      <img decoding="async" onerror="this.parentNode.removeChild(this)" src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/new-token-dark.webp" alt="new-token-dark">
      <p>Le damos un nombre al token y lo creamos con el rol <code>write</code>, o con el rol <code>Fine-grained</code>, que nos permite seleccionar exactamente cuáles permisos tendrá el token</p>
      <p>Una vez creado lo copiamos y lo pegamos a continuación</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">huggingface_hub</span><span class="w"> </span><span class="kn">import</span> <span class="n">notebook_login</span>',
      '<span class="n">notebook_login</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Dataset">Dataset<a class="anchor-link" href="#Dataset"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 12" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a usar un dataset de <a href="https://huggingface.co/datasets/Maximofn/short-jokes-dataset" target="_blank" rel="nofollow noreferrer">chistes en inglés</a></p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>',
      '<span class="w"> </span>',
      '<span class="n">jokes</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;Maximofn/short-jokes-dataset&quot;</span><span class="p">)</span>',
      '<span class="n">jokes</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'DatasetDict(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;train: Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;ID&#x27;, &#x27;Joke&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 231657',
          '&#x20;&#x20;&#x20;&#x20;&#x7D;)',
          '&#x7D;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a verlo un poco</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">jokes</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'DatasetDict(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;train: Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;ID&#x27;, &#x27;Joke&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 231657',
          '&#x20;&#x20;&#x20;&#x20;&#x7D;)',
          '&#x7D;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos que es un único set de entrenamiento de más de 200 mil chistes. Así que más adelante lo tendremos que dividir en train y evaluación</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a ver una muestra</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">random</span><span class="w"> </span><span class="kn">import</span> <span class="n">randint</span>',
      '<span class="w"> </span>',
      '<span class="n">idx</span> <span class="o">=</span> <span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">jokes</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>',
      '<span class="n">jokes</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '&#x7B;&#x27;ID&#x27;: 198387,',
          '&#x27;Joke&#x27;: &#x27;My hot dislexic co-worker said she had an important massage to give me in her office... When I got there, she told me it can wait until I put on some clothes.&#x27;&#x7D;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos que tiene una ID del chiste que no nos interesa para nada y el propio chiste</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Por si tienes poca memoria en la GPU voy a hacer un subset del dataset, elije el porcentaje de chistes que quieres usar</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">percent_of_train_dataset</span> <span class="o">=</span> <span class="mi">1</span>    <span class="c1"># If you want 50% of the dataset, set this to 0.5</span>',
      '<span class="w"> </span>',
      '<span class="n">subset_dataset</span> <span class="o">=</span> <span class="n">jokes</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">jokes</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">])</span> <span class="o">*</span> <span class="n">percent_of_train_dataset</span><span class="p">)))</span>',
      '<span class="n">subset_dataset</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;features: [&#x27;ID&#x27;, &#x27;Joke&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;num_rows: 231657',
          '&#x7D;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Ahora dividimos el subset en un conjunto de entrenamiento y otro de validación</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">percent_of_train_dataset</span> <span class="o">=</span> <span class="mf">0.90</span>',
      '<span class="w"> </span>',
      '<span class="n">split_dataset</span> <span class="o">=</span> <span class="n">subset_dataset</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">train_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">subset_dataset</span><span class="o">.</span><span class="n">num_rows</span> <span class="o">*</span> <span class="n">percent_of_train_dataset</span><span class="p">),</span> <span class="n">seed</span><span class="o">=</span><span class="mi">19</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>',
      '<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span>',
      '<span class="n">validation_test_dataset</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span>',
      '<span class="w"> </span>',
      '<span class="n">split_dataset</span> <span class="o">=</span> <span class="n">validation_test_dataset</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">train_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">validation_test_dataset</span><span class="o">.</span><span class="n">num_rows</span> <span class="o">*</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">seed</span><span class="o">=</span><span class="mi">19</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>',
      '<span class="n">validation_dataset</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span>',
      '<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span>',
      '<span class="w"> </span>',
      '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Size of the train set: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">. Size of the validation set: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">validation_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">. Size of the test set: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Size of the train set: 208491. Size of the validation set: 11583. Size of the test set: 11583',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Tokenizador">Tokenizador<a class="anchor-link" href="#Tokenizador"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 13" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Instanciamos el tokenizador. Instanciamos el token de padding del tokenizador para que no nos dé error como antes</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>',
      '<span class="w"> </span>',
      '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;openai-community/gpt2&quot;</span>',
      '<span class="w"> </span>',
      '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>',
      '<span class="n">tokenizer</span><span class="o">.</span><span class="n">padding_side</span> <span class="o">=</span> <span class="s2">&quot;right&quot;</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a añadir dos nuevos tokens de inicio de chiste y final de chiste para tener más control</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">new_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;&amp;lt;SJ&amp;gt;&#39;</span><span class="p">,</span> <span class="s1">&#39;&amp;lt;EJ&amp;gt;&#39;</span><span class="p">]</span>   <span class="c1"># Start and end of joke tokens</span>',
      '<span class="w"> </span>',
      '<span class="n">num_added_tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">add_tokens</span><span class="p">(</span><span class="n">new_tokens</span><span class="p">)</span>',
      '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Added </span><span class="si">{</span><span class="n">num_added_tokens</span><span class="si">}</span><span class="s2"> tokens&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Added 2 tokens',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Creamos una función para añadir los nuevos tokens a las sentencias</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">joke_column</span> <span class="o">=</span> <span class="s2">&quot;Joke&quot;</span>',
      '<span class="w"> </span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">format_joke</span><span class="p">(</span><span class="n">example</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">example</span><span class="p">[</span><span class="n">joke_column</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;&amp;lt;SJ&amp;gt; &#39;</span> <span class="o">+</span> <span class="n">example</span><span class="p">[</span><span class="s1">&#39;Joke&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39; &amp;lt;EJ&amp;gt;&#39;</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">example</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Seleccionamos las columnas que no necesitamos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">remove_columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">column</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">column_names</span> <span class="k">if</span> <span class="n">column</span> <span class="o">!=</span> <span class="n">joke_column</span><span class="p">]</span>',
      '<span class="n">remove_columns</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '[&#x27;ID&#x27;]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Formateamos el dataset y eliminamos las columnas que no necesitamos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">format_joke</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="n">remove_columns</span><span class="p">)</span>',
      '<span class="n">validation_dataset</span> <span class="o">=</span> <span class="n">validation_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">format_joke</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="n">remove_columns</span><span class="p">)</span>',
      '<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">format_joke</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="n">remove_columns</span><span class="p">)</span>',
      '<span class="n">train_dataset</span><span class="p">,</span> <span class="n">validation_dataset</span><span class="p">,</span> <span class="n">test_dataset</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '(Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;Joke&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 208491',
          '&#x7D;),',
          'Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;Joke&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 11583',
          '&#x7D;),',
          'Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;Joke&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 11583',
          '&#x7D;))',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Ahora creamos una función para tokenizar los chistes</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="n">joke_column</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Tokenizamos el dataset y eliminamos la columna con el texto</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="n">joke_column</span><span class="p">])</span>',
      '<span class="n">validation_dataset</span> <span class="o">=</span> <span class="n">validation_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="n">joke_column</span><span class="p">])</span>',
      '<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="n">joke_column</span><span class="p">])</span>',
      '<span class="n">train_dataset</span><span class="p">,</span> <span class="n">validation_dataset</span><span class="p">,</span> <span class="n">test_dataset</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '(Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;input_ids&#x27;, &#x27;attention_mask&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 208491',
          '&#x7D;),',
          'Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;input_ids&#x27;, &#x27;attention_mask&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 11583',
          '&#x7D;),',
          'Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;input_ids&#x27;, &#x27;attention_mask&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 11583',
          '&#x7D;))',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Modelo">Modelo<a class="anchor-link" href="#Modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 14" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Ahora instanciamos el modelo para generación de texto y le asignamos al token de padding el token de end of string</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span>',
      '<span class="w"> </span>',
      '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos el tamaño del vocabulario del modelo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span>',
      '<span class="n">vocab_size</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '50257',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Tiene 50257 tokens, que es el tamaño del vocabulario de GPT2. Pero como hemos dicho que íbamos a crear dos tokens nuevos con el inicio de chiste y el final de chiste, los añadimos al modelo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">model</span><span class="o">.</span><span class="n">resize_token_embeddings</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">))</span>',
      '<span class="w"> </span>',
      '<span class="n">new_vocab_size</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span>',
      '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Old vocab size: </span><span class="si">{</span><span class="n">vocab_size</span><span class="si">}</span><span class="s2">. New vocab size: </span><span class="si">{</span><span class="n">new_vocab_size</span><span class="si">}</span><span class="s2">. Added </span><span class="si">{</span><span class="n">new_vocab_size</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">vocab_size</span><span class="si">}</span><span class="s2"> tokens&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Old vocab size: 50257. New vocab size: 50259. Added 2 tokens',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Se han añadido los dos nuevos tokens</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Entrenamiento">Entrenamiento<a class="anchor-link" href="#Entrenamiento"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 15" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Configuramos los parámetros de entrenamiento</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">TrainingArguments</span>',
      '<span class="w"> </span>',
      '<span class="n">metric_name</span> <span class="o">=</span> <span class="s2">&quot;accuracy&quot;</span>',
      '<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;GPT2-small-finetuned-Maximofn-short-jokes-dataset-casualLM&quot;</span>',
      '<span class="n">output_dir</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;./training_results&quot;</span>',
      '<span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>',
      '<span class="n">BS_TRAIN</span> <span class="o">=</span> <span class="mi">28</span>',
      '<span class="n">BS_EVAL</span> <span class="o">=</span> <span class="mi">32</span>',
      '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>',
      '<span class="n">WEIGHT_DECAY</span> <span class="o">=</span> <span class="mf">0.01</span>',
      '<span class="n">WARMUP_STEPS</span> <span class="o">=</span> <span class="mi">100</span>',
      '<span class="w"> </span>',
      '<span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
      '<span class="w">    </span><span class="n">model_name</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">eval_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">save_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">warmup_steps</span><span class="o">=</span><span class="n">WARMUP_STEPS</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">&quot;cosine&quot;</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '<span class="w">    </span><span class="c1"># metric_for_best_model=metric_name,</span>',
      '<span class="w">    </span><span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '<span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Ahora no usamos <code>metric_for_best_model</code>, después de definir el trainer explicamos por qué</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Definimos el trainer</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Trainer</span>',
      '<span class="w"> </span>',
      '<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
      '<span class="w">    </span><span class="n">model</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">training_args</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">validation_dataset</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
      '<span class="w">    </span><span class="c1"># compute_metrics=compute_metrics,</span>',
      '<span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>En este caso no le pasamos una función <code>compute_metrics</code>, sino se le pasa, durante la evaluación se usará la <code>loss</code> para evaluar el modelo. Por eso al definir los argumentos no definimos <code>metric_for_best_model</code>, porque no vamos a usar una métrica para evaluar el modelo, sino la <code>loss</code></p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Entrenamos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '&#x20;&#x20;0%|          | 0/625473 [00:00&amp;lt;?, ?it/s]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockOutputCell
        text={[
          '---------------------------------------------------------------------------ValueError                                Traceback (most recent call last)Cell In[19], line 1',
          '----&amp;gt; 1 trainer.train()',
          'File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/trainer.py:1885, in Trainer.train(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)',
          '&#x20;&#x20;&#x20;1883         hf_hub_utils.enable_progress_bars()',
          '&#x20;&#x20;&#x20;1884 else:',
          '-&amp;gt; 1885     return inner_training_loop(',
          '&#x20;&#x20;&#x20;1886         args=args,',
          '&#x20;&#x20;&#x20;1887         resume_from_checkpoint=resume_from_checkpoint,',
          '&#x20;&#x20;&#x20;1888         trial=trial,',
          '&#x20;&#x20;&#x20;1889         ignore_keys_for_eval=ignore_keys_for_eval,',
          '&#x20;&#x20;&#x20;1890     )',
          'File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/trainer.py:2216, in Trainer._inner_training_loop(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)',
          '&#x20;&#x20;&#x20;2213     self.control = self.callback_handler.on_step_begin(args, self.state, self.control)',
          '&#x20;&#x20;&#x20;2215 with self.accelerator.accumulate(model):',
          '-&amp;gt; 2216     tr_loss_step = self.training_step(model, inputs)',
          '&#x20;&#x20;&#x20;2218 if (',
          '&#x20;&#x20;&#x20;2219     args.logging_nan_inf_filter',
          '&#x20;&#x20;&#x20;2220     and not is_torch_xla_available()',
          '&#x20;&#x20;&#x20;2221     and (torch.isnan(tr_loss_step) or torch.isinf(tr_loss_step))',
          '&#x20;&#x20;&#x20;2222 ):',
          '&#x20;&#x20;&#x20;2223     # if loss is nan or inf simply add the average of previous logged losses',
          '&#x20;&#x20;&#x20;2224     tr_loss += tr_loss / (1 + self.state.global_step - self._globalstep_last_logged)',
          'File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/trainer.py:3238, in Trainer.training_step(self, model, inputs)',
          '&#x20;&#x20;&#x20;3235     return loss_mb.reduce_mean().detach().to(self.args.device)',
          '&#x20;&#x20;&#x20;3237 with self.compute_loss_context_manager():',
          '-&amp;gt; 3238     loss = self.compute_loss(model, inputs)',
          '&#x20;&#x20;&#x20;3240 del inputs',
          '&#x20;&#x20;&#x20;3241 torch.cuda.empty_cache()',
          'File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/trainer.py:3282, in Trainer.compute_loss(self, model, inputs, return_outputs)',
          '&#x20;&#x20;&#x20;3280 else:',
          '&#x20;&#x20;&#x20;3281     if isinstance(outputs, dict) and &quot;loss&quot; not in outputs:',
          '-&amp;gt; 3282         raise ValueError(',
          '&#x20;&#x20;&#x20;3283             &quot;The model did not return a loss from the inputs, only the following keys: &quot;',
          '&#x20;&#x20;&#x20;3284             f&quot;&#x7B;&#x27;,&#x27;.join(outputs.keys())&#x7D;. For reference, the inputs it received are &#x7B;&#x27;,&#x27;.join(inputs.keys())&#x7D;.&quot;',
          '&#x20;&#x20;&#x20;3285         )',
          '&#x20;&#x20;&#x20;3286     # We don&#x27;t use .loss here since the model may return tuples instead of ModelOutput.',
          '&#x20;&#x20;&#x20;3287     loss = outputs[&quot;loss&quot;] if isinstance(outputs, dict) else outputs[0]',
          'ValueError: The model did not return a loss from the inputs, only the following keys: logits,past_key_values. For reference, the inputs it received are input_ids,attention_mask.',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Como vemos, nos da un error, nos dice que el modelo no devuelve el valor del loss, que es clave para poder entrenar, vamos a ver por qué</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Primero veamos cómo es un ejemplo del dataset</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">idx</span> <span class="o">=</span> <span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>',
      '<span class="n">sample</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>',
      '<span class="n">sample</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '&#x7B;&#x27;input_ids&#x27;: [50257,',
          '&#x20;&#x20;4162,',
          '&#x20;&#x20;750,',
          '&#x20;&#x20;262,',
          '&#x20;&#x20;18757,',
          '&#x20;&#x20;6451,',
          '&#x20;&#x20;2245,',
          '&#x20;&#x20;2491,',
          '&#x20;&#x20;30,',
          '&#x20;&#x20;4362,',
          '&#x20;&#x20;340,',
          '&#x20;&#x20;373,',
          '&#x20;&#x20;734,',
          '&#x20;&#x20;10032,',
          '&#x20;&#x20;13,',
          '&#x20;&#x20;220,',
          '&#x20;&#x20;50258,',
          '&#x20;&#x20;50256,',
          '&#x20;&#x20;50256,',
          '&#x20;&#x20;...,',
          '&#x20;&#x20;50256,',
          '&#x20;&#x20;50256,',
          '&#x20;&#x20;50256],',
          '&#x27;attention_mask&#x27;: [1,',
          '&#x20;&#x20;1,',
          '&#x20;&#x20;1,',
          '&#x20;&#x20;1,',
          '&#x20;&#x20;1,',
          '&#x20;&#x20;1,',
          '&#x20;&#x20;1,',
          '&#x20;&#x20;1,',
          '&#x20;&#x20;1,',
          '&#x20;&#x20;1,',
          '&#x20;&#x20;1,',
          '&#x20;&#x20;1,',
          '&#x20;&#x20;1,',
          '&#x20;&#x20;1,',
          '&#x20;&#x20;1,',
          '&#x20;&#x20;1,',
          '&#x20;&#x20;1,',
          '&#x20;&#x20;0,',
          '&#x20;&#x20;0,',
          '&#x20;&#x20;0,',
          '&#x20;&#x20;...,',
          '&#x20;&#x20;0,',
          '&#x20;&#x20;0,',
          '&#x20;&#x20;0]&#x7D;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Como vemos, tenemos un diccionario con los <code>input_ids</code> y las <code>attention_mask</code>. Si se lo pasamos al modelo obtenemos esto</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>',
      '<span class="w"> </span>',
      '<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span>',
      '<span class="w">    </span><span class="n">input_ids</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>',
      '<span class="w">    </span><span class="n">attention_mask</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>',
      '<span class="p">)</span>',
      '<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">loss</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'None',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Como vemos no devuelve el valor de la loss porque está esperando un valor para <code>labels</code>, que no se lo hemos pasado. En el ejemplo anterior, en el que hacíamos fine tuning para clasificación de texto, dijimos que las etiquetas había que pasarlas a un campo del dataset llamado <code>labels</code>, pero en este caso no tenemos ese campo en el dataset</p>
      <p>Si ahora asignamos las <code>labels</code> a los <code>input_ids</code> y volvemos a ver la loss</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>',
      '<span class="w"> </span>',
      '<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span>',
      '<span class="w">    </span><span class="n">input_ids</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>',
      '<span class="w">    </span><span class="n">attention_mask</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>',
      '<span class="w">    </span><span class="n">labels</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>',
      '<span class="p">)</span>',
      '<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">loss</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'tensor(102.1873, device=&#x27;cuda:0&#x27;, grad_fn=&amp;lt;NllLossBackward0&amp;gt;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Ahora sí obtenemos una <code>loss</code></p>
      <p>Por tanto tenemos dos opciones, añadir un campo <code>labels</code> al dataset, con los valores de <code>input_ids</code> o utilizar una función de la librería <code>transformers</code> llamada <code>data_collator</code>, en este caso usaremos <code>DataCollatorForLanguageModeling</code>. Vamos a verlo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataCollatorForLanguageModeling</span>',
      '<span class="w"> </span>',
      '<span class="n">my_data_collator</span><span class="o">=</span><span class="n">DataCollatorForLanguageModeling</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">mlm</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Pasamos la muestra <code>sample</code> por este <code>data_collator</code></p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">collated_sample</span> <span class="o">=</span> <span class="n">my_data_collator</span><span class="p">([</span><span class="n">sample</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos cómo es la salida</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">collated_sample</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">): </span><span class="si">{</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'input_ids (torch.Size([1, 768])): tensor([[50257,  4162,   750,   262, 18757,  6451,  2245,  2491,    30,  4362,',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;340,   373,   734, 10032,    13,   220, 50258, 50256, ..., 50256, 50256]],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;device=&#x27;cuda:0&#x27;)',
          'attention_mask (torch.Size([1, 768])): tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, ..., 0, 0]],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;device=&#x27;cuda:0&#x27;)',
          'labels (torch.Size([1, 768])): tensor([[50257,  4162,   750,   262, 18757,  6451,  2245,  2491,    30,  4362,',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;340,   373,   734, 10032,    13,   220, 50258,  -100,  ...,  -100,  -100]],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;device=&#x27;cuda:0&#x27;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Como se puede ver, el <code>data_collator</code> ha creado un campo <code>labels</code> y le ha asignado los valores de <code>input_ids</code>. Los tokens que están enmascarados les ha asignado el valor -100. Esto es porque cuando definimos el <code>data_collator</code> le pasamos el parámetro <code>mlm=False</code>, que significa que no estamos haciendo <code>Masked Language Modeling</code>, sino <code>Language Modeling</code>, por eso no enmascara ningún token original</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a ver si ahora obtenemos una <code>loss</code> con este <code>data_collator</code></p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">collated_sample</span><span class="p">)</span>',
      '<span class="n">output</span><span class="o">.</span><span class="n">loss</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'tensor(102.7181, device=&#x27;cuda:0&#x27;, grad_fn=&amp;lt;NllLossBackward0&amp;gt;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Así que volvemos a definir el <code>trainer</code> con el <code>data_collator</code> y volvemos a entrenar</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataCollatorForLanguageModeling</span>',
      '<span class="w"> </span>',
      '<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
      '<span class="w">    </span><span class="n">model</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">training_args</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">validation_dataset</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">data_collator</span><span class="o">=</span><span class="n">DataCollatorForLanguageModeling</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">mlm</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>',
      '<span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '&amp;lt;IPython.core.display.HTML object&amp;gt;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockOutputCell
        text={[
          'There were missing keys in the checkpoint model loaded: [&#x27;lm_head.weight&#x27;].',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockOutputCell
        text={[
          'TrainOutput(global_step=22341, training_loss=3.505178199598342, metrics=&#x7B;&#x27;train_runtime&#x27;: 9209.5353, &#x27;train_samples_per_second&#x27;: 67.916, &#x27;train_steps_per_second&#x27;: 2.426, &#x27;total_flos&#x27;: 2.45146666696704e+17, &#x27;train_loss&#x27;: 3.505178199598342, &#x27;epoch&#x27;: 3.0&#x7D;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Evaluacion">Evaluación<a class="anchor-link" href="#Evaluacion"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 16" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Una vez entrenado, evaluamos el modelo sobre el dataset de test</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '&amp;lt;IPython.core.display.HTML object&amp;gt;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockOutputCell
        text={[
          '&#x7B;&#x27;eval_loss&#x27;: 3.201305866241455,',
          '&#x27;eval_runtime&#x27;: 65.0033,',
          '&#x27;eval_samples_per_second&#x27;: 178.191,',
          '&#x27;eval_steps_per_second&#x27;: 5.569,',
          '&#x27;epoch&#x27;: 3.0&#x7D;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Publicar el modelo">Publicar el modelo<a class="anchor-link" href="#Publicar el modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 17" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Creamos la model card</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">create_model_card</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Lo publicamos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">push_to_hub</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'events.out.tfevents.1720875425.8de3af1b431d.6946.1:   0%|          | 0.00/364 [00:00&amp;lt;?, ?B/s]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockOutputCell
        text={[
          'CommitInfo(commit_url=&#x27;https://huggingface.co/Maximofn/GPT2-small-finetuned-Maximofn-short-jokes-dataset-casualLM/commit/d107b3bb0e02076483238f9975697761015ec390&#x27;, commit_message=&#x27;End of training&#x27;, commit_description=&#x27;&#x27;, oid=&#x27;d107b3bb0e02076483238f9975697761015ec390&#x27;, pr_url=None, pr_revision=None, pr_num=None)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Uso del modelo">Uso del modelo<a class="anchor-link" href="#Uso del modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 18" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Limpiamos todo lo posible</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">gc</span>',
      '<span class="w"> </span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">clear_hardwares</span><span class="p">():</span>',
      '<span class="w">    </span><span class="n">torch</span><span class="o">.</span><span class="n">clear_autocast_cache</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">ipc_collect</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="n">clear_hardwares</span><span class="p">()</span>',
      '<span class="n">clear_hardwares</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Descargamos el modelo y el tokenizador</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForCausalLM</span>',
      '<span class="w"> </span>',
      '<span class="n">user</span> <span class="o">=</span> <span class="s2">&quot;maximofn&quot;</span>',
      '<span class="n">checkpoints</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">user</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span>',
      '<span class="w"> </span>',
      '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>',
      '<span class="n">tokenizer</span><span class="o">.</span><span class="n">padding_side</span> <span class="o">=</span> <span class="s2">&quot;right&quot;</span>',
      '<span class="w"> </span>',
      '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Comprobamos que el tokenizador y el modelo tienen los 2 tokens extra que hemos añadido</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">tokenizer_vocab</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">get_vocab</span><span class="p">()</span>',
      '<span class="n">model_vocab</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span>',
      '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;tokenizer_vocab: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">tokenizer_vocab</span><span class="p">)</span><span class="si">}</span><span class="s2">. model_vocab: </span><span class="si">{</span><span class="n">model_vocab</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'tokenizer_vocab: 50259. model_vocab: 50259',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos que tienen 50259 tokens, es decir, los 50257 tokens de GPT2 más los 2 que hemos añadido</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Creamos una función para generar chistes</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">def</span><span class="w"> </span><span class="nf">generate_joke</span><span class="p">(</span><span class="n">prompt_text</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">text</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&amp;lt;SJ&amp;gt; </span><span class="si">{</span><span class="n">prompt_text</span><span class="si">}</span><span class="s2">&quot;</span>',
      '<span class="w">    </span><span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
      '<span class="w">        </span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="o">**</span><span class="n">tokens</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">eos_token_id</span><span class="o">=</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">&quot;&amp;lt;EJ&amp;gt;&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Generamos un chiste</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">generate_joke</span><span class="p">(</span><span class="s2">&quot;Why didn&#39;t the frog cross the road?&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Setting `pad_token_id` to `eos_token_id`:50258 for open-end generation.',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockOutputCell
        text={[
          '&quot;&amp;lt;SJ&amp;gt; Why didn&#x27;t the frog cross the road? Because he was frog-in-the-face. &amp;lt;EJ&amp;gt;&quot;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Si quieres probar más el modelo puedes verlo en <a href="https://huggingface.co/Maximofn/GPT2-small-finetuned-Maximofn-short-jokes-dataset-casualLM" target="_blank" rel="nofollow noreferrer">Maximofn/GPT2-small-finetuned-Maximofn-short-jokes-dataset-casualLM</a></p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Fine tuning para clasificacion de texto con Pytorch">Fine tuning para clasificación de texto con Pytorch<a class="anchor-link" href="#Fine tuning para clasificacion de texto con Pytorch"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 19" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Repetimos el entrenamiento con Pytorch</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Reiniciamos el notebook para asegurarnos</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Dataset">Dataset<a class="anchor-link" href="#Dataset"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 20" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Descargamos el mismo dataset que cuando hicimos el entrenamiento con las librerías de Hugging Face</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>',
      '<span class="w"> </span>',
      '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;mteb/amazon_reviews_multi&quot;</span><span class="p">,</span> <span class="s2">&quot;en&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Creamos una variable con el número de clases</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="s1">&#39;label&#39;</span><span class="p">))</span>',
      '<span class="n">num_classes</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '5',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Antes procesamos todo el dataset para crear un campo llamado <code>labels</code>, pero ahora no hace falta porque, como vamos a programar nosotros todo, nos adaptamos a cómo es el dataset</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Tokenizador">Tokenizador<a class="anchor-link" href="#Tokenizador"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 21" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Creamos el tokenizador. Le asignamos el token de padding para que no nos de error como antes</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>',
      '<span class="w"> </span>',
      '<span class="n">checkpoint</span> <span class="o">=</span> <span class="s2">&quot;openai-community/gpt2&quot;</span>',
      '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>',
      '<span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Creamos una función para tokenizar el dataset</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Lo tokenizamos. Eliminamos columnas que no nos hagan falta, pero ahora dejamos la de texto</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="s1">&#39;label_text&#39;</span><span class="p">])</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">dataset</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'DatasetDict(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;train: Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;text&#x27;, &#x27;label&#x27;, &#x27;input_ids&#x27;, &#x27;attention_mask&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 200000',
          '&#x20;&#x20;&#x20;&#x20;&#x7D;)',
          '&#x20;&#x20;&#x20;&#x20;validation: Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;text&#x27;, &#x27;label&#x27;, &#x27;input_ids&#x27;, &#x27;attention_mask&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 5000',
          '&#x20;&#x20;&#x20;&#x20;&#x7D;)',
          '&#x20;&#x20;&#x20;&#x20;test: Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;text&#x27;, &#x27;label&#x27;, &#x27;input_ids&#x27;, &#x27;attention_mask&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 5000',
          '&#x20;&#x20;&#x20;&#x20;&#x7D;)',
          '&#x7D;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">percentage</span> <span class="o">=</span> <span class="mi">1</span>',
      '<span class="n">subset_train</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">])</span> <span class="o">*</span> <span class="n">percentage</span><span class="p">)))</span>',
      '<span class="n">percentage</span> <span class="o">=</span> <span class="mi">1</span>',
      '<span class="n">subset_validation</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;validation&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;validation&#39;</span><span class="p">])</span> <span class="o">*</span> <span class="n">percentage</span><span class="p">)))</span>',
      '<span class="n">subset_test</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">])</span> <span class="o">*</span> <span class="n">percentage</span><span class="p">)))</span>',
      '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;len subset_train: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">subset_train</span><span class="p">)</span><span class="si">}</span><span class="s2">, len subset_validation: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">subset_validation</span><span class="p">)</span><span class="si">}</span><span class="s2">, len subset_test: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">subset_test</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'len subset_train: 200000, len subset_validation: 5000, len subset_test: 5000',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Modelo">Modelo<a class="anchor-link" href="#Modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 22" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Importamos los pesos y asignamos el token de padding</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span>',
      '<span class="w"> </span>',
      '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="n">num_classes</span><span class="p">)</span>',
      '<span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: [&#x27;score.weight&#x27;]',
          'You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Device">Device<a class="anchor-link" href="#Device"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 23" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Creamos el dispositivo donde se va a ejecutar todo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>',
      '<span class="w"> </span>',
      '<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>De paso, pasamos el modelo al dispositivo y, de paso, lo pasamos a FP16 para que ocupe menos memoria</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">model</span><span class="o">.</span><span class="n">half</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '<span class="nb">print</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[

        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Pytorch Dataset">Pytorch Dataset<a class="anchor-link" href="#Pytorch Dataset"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 24" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Creamos un dataset de pytorch</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dataset</span>',
      '<span class="w"> </span>',
      '<span class="k">class</span><span class="w"> </span><span class="nc">ReviewsDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>',
      '<span class="w">    </span><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">huggingface_dataset</span><span class="p">):</span>',
      '<span class="w">        </span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">huggingface_dataset</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>',
      '<span class="w">        </span><span class="n">label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">&#39;label&#39;</span><span class="p">]</span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">&#39;input_ids&#39;</span><span class="p">])</span>',
      '<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>',
      '<span class="w">        </span><span class="k">return</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">label</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="k">def</span><span class="w"> </span><span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>',
      '<span class="w">        </span><span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Instanciamos los datasets</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">ReviewsDataset</span><span class="p">(</span><span class="n">subset_train</span><span class="p">)</span>',
      '<span class="n">validatation_dataset</span> <span class="o">=</span> <span class="n">ReviewsDataset</span><span class="p">(</span><span class="n">subset_validation</span><span class="p">)</span>',
      '<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">ReviewsDataset</span><span class="p">(</span><span class="n">subset_test</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a ver una muestra</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">input_ids</span><span class="p">,</span> <span class="n">at_mask</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>',
      '<span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">at_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">label</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '(torch.Size([768]), torch.Size([768]), 0)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Pytorch Dataloader">Pytorch Dataloader<a class="anchor-link" href="#Pytorch Dataloader"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 25" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Creamos ahora un DataLoader de PyTorch</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>',
      '<span class="w"> </span>',
      '<span class="n">BS</span> <span class="o">=</span> <span class="mi">12</span>',
      '<span class="w"> </span>',
      '<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
      '<span class="n">validation_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">validatation_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">)</span>',
      '<span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a ver una muestra</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">input_ids</span><span class="p">,</span> <span class="n">at_mask</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_loader</span><span class="p">))</span>',
      '<span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">at_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">labels</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '(torch.Size([12, 768]),',
          'torch.Size([12, 768]),',
          'tensor([2, 1, 2, 0, 3, 3, 0, 4, 3, 3, 4, 2]))',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Para ver que esté todo bien, pasamos la muestra al modelo para ver qué salga todo bien. Primero pasamos los tokens al dispositivo.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '<span class="n">at_mask</span> <span class="o">=</span> <span class="n">at_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '<span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Ahora se los pasamos al modelo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">at_mask</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
      '<span class="n">output</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'odict_keys([&#x27;loss&#x27;, &#x27;logits&#x27;, &#x27;past_key_values&#x27;])',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Como vemos, nos da la loss y los logits</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'tensor(5.9414, device=&#x27;cuda:0&#x27;, dtype=torch.float16,',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;grad_fn=&amp;lt;NllLossBackward0&amp;gt;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">]</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'tensor([[ 6.1953e+00, -1.2275e+00, -2.4824e+00,  5.8867e+00, -1.4734e+01],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;[ 5.4062e+00, -8.4570e-01, -2.3203e+00,  5.1055e+00, -1.1555e+01],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;[ 6.1641e+00, -9.3066e-01, -2.5664e+00,  6.0039e+00, -1.4570e+01],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;[ 5.2266e+00, -4.2358e-01, -2.0801e+00,  4.7461e+00, -1.1570e+01],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;[ 3.8184e+00, -2.3460e-03, -1.7666e+00,  3.4160e+00, -7.7969e+00],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;[ 4.1641e+00, -4.8169e-01, -1.6914e+00,  3.9941e+00, -8.7734e+00],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;[ 4.6758e+00, -3.0298e-01, -2.1641e+00,  4.1055e+00, -9.3359e+00],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;[ 4.1953e+00, -3.2471e-01, -2.1875e+00,  3.9375e+00, -8.3438e+00],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;[-1.1650e+00,  1.3564e+00, -6.2158e-01, -6.8115e-01,  4.8672e+00],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;[ 4.4961e+00, -8.7891e-02, -2.2793e+00,  4.2812e+00, -9.3359e+00],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;[ 4.9336e+00, -2.6627e-03, -2.1543e+00,  4.3711e+00, -1.0742e+01],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;[ 5.9727e+00, -4.3152e-02, -1.4551e+00,  4.3438e+00, -1.2117e+01]],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;device=&#x27;cuda:0&#x27;, dtype=torch.float16, grad_fn=&amp;lt;IndexBackward0&amp;gt;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Metrica">Métrica<a class="anchor-link" href="#Metrica"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 26" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a crear una función para obtener la métrica, que en este caso va a ser el accuracy</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">def</span><span class="w"> </span><span class="nf">predicted_labels</span><span class="p">(</span><span class="n">logits</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">percent</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">percent</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">predictions</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">def</span><span class="w"> </span><span class="nf">compute_accuracy</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">predicted_labels</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">correct</span> <span class="o">=</span> <span class="p">(</span><span class="n">predictions</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">correct</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a ver si lo calcula bien</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">compute_accuracy</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '0.1666666716337204',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Optimizador">Optimizador<a class="anchor-link" href="#Optimizador"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 27" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Como vamos a necesitar un optimizador, creamos uno</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AdamW</span>',
      '<span class="w"> </span>',
      '<span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>',
      '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">LR</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning',
          '&#x20;&#x20;warnings.warn(',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Entrenamiento">Entrenamiento<a class="anchor-link" href="#Entrenamiento"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 28" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Creamos el bucle de entrenamiento</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>',
      '<span class="w"> </span>',
      '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>',
      '<span class="w"> </span>',
      '<span class="n">accuracy</span> <span class="o">=</span> <span class="mi">0</span>',
      '<span class="w"> </span>',
      '<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">train_loss</span> <span class="o">=</span> <span class="mi">0</span>',
      '<span class="w">    </span><span class="n">progresbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">at_mask</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">progresbar</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">at_mask</span> <span class="o">=</span> <span class="n">at_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">label</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">at_mask</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>',
      '<span class="w">        </span><span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>',
      '<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
      '<span class="w">        </span><span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>',
      '<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
      '<span class="w">        </span><span class="n">progresbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">({</span><span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()})</span>',
      '<span class="w">    </span><span class="n">train_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">progresbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">({</span><span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="n">train_loss</span><span class="p">})</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">valid_loss</span> <span class="o">=</span> <span class="mi">0</span>',
      '<span class="w">    </span><span class="n">progresbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">validation_loader</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">validation_loader</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">at_mask</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">progresbar</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">at_mask</span> <span class="o">=</span> <span class="n">at_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">at_mask</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>',
      '<span class="w">        </span><span class="n">valid_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">step_accuracy</span> <span class="o">=</span> <span class="n">compute_accuracy</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">accuracy</span> <span class="o">+=</span> <span class="n">step_accuracy</span>',
      '<span class="w">        </span><span class="n">progresbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">({</span><span class="s1">&#39;valid_loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="s1">&#39;accuracy&#39;</span><span class="p">:</span> <span class="n">step_accuracy</span><span class="o">.</span><span class="n">item</span><span class="p">()})</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="n">valid_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">validation_loader</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">accuracy</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">validation_loader</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">progresbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">({</span><span class="s1">&#39;valid_loss&#39;</span><span class="p">:</span> <span class="n">valid_loss</span><span class="p">,</span> <span class="s1">&#39;accuracy&#39;</span><span class="p">:</span> <span class="n">accuracy</span><span class="p">})</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Epoch 1: 100%|██████████| 16667/16667 [44:13&amp;lt;00:00,  6.28it/s, train_loss=nan]',
          'Epoch 1: 100%|██████████| 417/417 [00:32&amp;lt;00:00, 12.72it/s, valid_loss=nan, accuracy=0]',
          'Epoch 2: 100%|██████████| 16667/16667 [44:06&amp;lt;00:00,  6.30it/s, train_loss=nan]',
          'Epoch 2: 100%|██████████| 417/417 [00:32&amp;lt;00:00, 12.77it/s, valid_loss=nan, accuracy=0]',
          'Epoch 3: 100%|██████████| 16667/16667 [44:03&amp;lt;00:00,  6.30it/s, train_loss=nan]',
          'Epoch 3: 100%|██████████| 417/417 [00:32&amp;lt;00:00, 12.86it/s, valid_loss=nan, accuracy=0]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Uso del modelo">Uso del modelo<a class="anchor-link" href="#Uso del modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 29" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a probar el modelo que hemos entrenado</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Primero tokenizamos un texto</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">input_tokens</span> <span class="o">=</span> <span class="n">tokenize_function</span><span class="p">({</span><span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="s2">&quot;I love this product. It is amazing.&quot;</span><span class="p">})</span>',
      '<span class="n">input_tokens</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">input_tokens</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '(torch.Size([1, 768]), torch.Size([1, 768]))',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Ahora se lo pasamos al modelo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_tokens</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">input_tokens</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>',
      '<span class="n">output</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">]</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'tensor([[nan, nan, nan, nan, nan]], device=&#x27;cuda:0&#x27;, dtype=torch.float16,',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;grad_fn=&amp;lt;IndexBackward0&amp;gt;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos las predicciones de esos logits</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">predicted</span> <span class="o">=</span> <span class="n">predicted_labels</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">])</span>',
      '<span class="n">predicted</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'tensor([0], device=&#x27;cuda:0&#x27;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h2 id="Fine tuning para generacion de texto con Pytorch">Fine tuning para generación de texto con Pytorch<a class="anchor-link" href="#Fine tuning para generacion de texto con Pytorch"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 30" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Repetimos el entrenamiento con Pytorch</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Reiniciamos el notebook para asegurarnos</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Dataset">Dataset<a class="anchor-link" href="#Dataset"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 31" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Volvemos a descargar el dataset de chistes</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>',
      '<span class="w"> </span>',
      '<span class="n">jokes</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;Maximofn/short-jokes-dataset&quot;</span><span class="p">)</span>',
      '<span class="n">jokes</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'DatasetDict(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;train: Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;ID&#x27;, &#x27;Joke&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 231657',
          '&#x20;&#x20;&#x20;&#x20;&#x7D;)',
          '&#x7D;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Creamos un subset por si se tiene poca memoria</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">percent_of_train_dataset</span> <span class="o">=</span> <span class="mi">1</span>    <span class="c1"># If you want 50% of the dataset, set this to 0.5</span>',
      '<span class="w"> </span>',
      '<span class="n">subset_dataset</span> <span class="o">=</span> <span class="n">jokes</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">jokes</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">])</span> <span class="o">*</span> <span class="n">percent_of_train_dataset</span><span class="p">)))</span>',
      '<span class="n">subset_dataset</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;features: [&#x27;ID&#x27;, &#x27;Joke&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;num_rows: 231657',
          '&#x7D;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Dividimos el dataset en subsets de entrenamiento, validación y test</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">percent_of_train_dataset</span> <span class="o">=</span> <span class="mf">0.90</span>',
      '<span class="w"> </span>',
      '<span class="n">split_dataset</span> <span class="o">=</span> <span class="n">subset_dataset</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">train_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">subset_dataset</span><span class="o">.</span><span class="n">num_rows</span> <span class="o">*</span> <span class="n">percent_of_train_dataset</span><span class="p">),</span> <span class="n">seed</span><span class="o">=</span><span class="mi">19</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>',
      '<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span>',
      '<span class="n">validation_test_dataset</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span>',
      '<span class="w"> </span>',
      '<span class="n">split_dataset</span> <span class="o">=</span> <span class="n">validation_test_dataset</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">train_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">validation_test_dataset</span><span class="o">.</span><span class="n">num_rows</span> <span class="o">*</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">seed</span><span class="o">=</span><span class="mi">19</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>',
      '<span class="n">validation_dataset</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span>',
      '<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span>',
      '<span class="w"> </span>',
      '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Size of the train set: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">. Size of the validation set: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">validation_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">. Size of the test set: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Size of the train set: 208491. Size of the validation set: 11583. Size of the test set: 11583',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Tokenizador">Tokenizador<a class="anchor-link" href="#Tokenizador"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 32" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Iniciamos el tokenizador y asignamos al token de padding el de end of string</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>',
      '<span class="w"> </span>',
      '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;openai-community/gpt2&quot;</span>',
      '<span class="w"> </span>',
      '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>',
      '<span class="n">tokenizer</span><span class="o">.</span><span class="n">padding_side</span> <span class="o">=</span> <span class="s2">&quot;right&quot;</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Añadimos los tokens especiales de inicio de chiste y fin de chiste</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">new_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;&amp;lt;SJ&amp;gt;&#39;</span><span class="p">,</span> <span class="s1">&#39;&amp;lt;EJ&amp;gt;&#39;</span><span class="p">]</span>   <span class="c1"># Start and end of joke tokens</span>',
      '<span class="w"> </span>',
      '<span class="n">num_added_tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">add_tokens</span><span class="p">(</span><span class="n">new_tokens</span><span class="p">)</span>',
      '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Added </span><span class="si">{</span><span class="n">num_added_tokens</span><span class="si">}</span><span class="s2"> tokens&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Added 2 tokens',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Los añadimos al dataset</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">joke_column</span> <span class="o">=</span> <span class="s2">&quot;Joke&quot;</span>',
      '<span class="w"> </span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">format_joke</span><span class="p">(</span><span class="n">example</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">example</span><span class="p">[</span><span class="n">joke_column</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;&amp;lt;SJ&amp;gt; &#39;</span> <span class="o">+</span> <span class="n">example</span><span class="p">[</span><span class="s1">&#39;Joke&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39; &amp;lt;EJ&amp;gt;&#39;</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">example</span>',
      '<span class="w"> </span>',
      '<span class="n">remove_columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">column</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">column_names</span> <span class="k">if</span> <span class="n">column</span> <span class="o">!=</span> <span class="n">joke_column</span><span class="p">]</span>',
      '<span class="w"> </span>',
      '<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">format_joke</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="n">remove_columns</span><span class="p">)</span>',
      '<span class="n">validation_dataset</span> <span class="o">=</span> <span class="n">validation_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">format_joke</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="n">remove_columns</span><span class="p">)</span>',
      '<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">format_joke</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="n">remove_columns</span><span class="p">)</span>',
      '<span class="n">train_dataset</span><span class="p">,</span> <span class="n">validation_dataset</span><span class="p">,</span> <span class="n">test_dataset</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '(Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;Joke&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 208491',
          '&#x7D;),',
          'Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;Joke&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 11583',
          '&#x7D;),',
          'Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;Joke&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 11583',
          '&#x7D;))',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Tokenizamos el dataset</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="n">joke_column</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="n">joke_column</span><span class="p">])</span>',
      '<span class="n">validation_dataset</span> <span class="o">=</span> <span class="n">validation_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="n">joke_column</span><span class="p">])</span>',
      '<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="n">joke_column</span><span class="p">])</span>',
      '<span class="n">train_dataset</span><span class="p">,</span> <span class="n">validation_dataset</span><span class="p">,</span> <span class="n">test_dataset</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '(Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;input_ids&#x27;, &#x27;attention_mask&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 208491',
          '&#x7D;),',
          'Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;input_ids&#x27;, &#x27;attention_mask&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 11583',
          '&#x7D;),',
          'Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;input_ids&#x27;, &#x27;attention_mask&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 11583',
          '&#x7D;))',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Modelo">Modelo<a class="anchor-link" href="#Modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 33" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Instanciamos el modelo, asignamos el token de padding y añadimos los nuevos tokens de inicio de chiste y fin de chiste</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span>',
      '<span class="w"> </span>',
      '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>',
      '<span class="n">model</span><span class="o">.</span><span class="n">resize_token_embeddings</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">))</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Embedding(50259, 768)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Device">Device<a class="anchor-link" href="#Device"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 34" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Creamos el dispositivo y pasamos el modelo al dispositivo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>',
      '<span class="w"> </span>',
      '<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>',
      '<span class="n">model</span><span class="o">.</span><span class="n">half</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '<span class="nb">print</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[

        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Pytorch Dataset">Pytorch Dataset<a class="anchor-link" href="#Pytorch Dataset"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 35" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Creamos un dataset de PyTorch</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dataset</span>',
      '<span class="w"> </span>',
      '<span class="k">class</span><span class="w"> </span><span class="nc">JokesDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>',
      '<span class="w">    </span><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">huggingface_dataset</span><span class="p">):</span>',
      '<span class="w">        </span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">huggingface_dataset</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">&#39;input_ids&#39;</span><span class="p">])</span>',
      '<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>',
      '<span class="w">        </span><span class="k">return</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="k">def</span><span class="w"> </span><span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>',
      '<span class="w">        </span><span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Instanciamos los datasets de entrenamiento, validación y test</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">train_pytorch_dataset</span> <span class="o">=</span> <span class="n">JokesDataset</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span>',
      '<span class="n">validation_pytorch_dataset</span> <span class="o">=</span> <span class="n">JokesDataset</span><span class="p">(</span><span class="n">validation_dataset</span><span class="p">)</span>',
      '<span class="n">test_pytorch_dataset</span> <span class="o">=</span> <span class="n">JokesDataset</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Veamos una muestra</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">train_pytorch_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>',
      '<span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">shape</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '(torch.Size([768]), torch.Size([768]))',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Pytorch Dataloader">Pytorch Dataloader<a class="anchor-link" href="#Pytorch Dataloader"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 36" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Creamos los dataloaders</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>',
      '<span class="w"> </span>',
      '<span class="n">BS</span> <span class="o">=</span> <span class="mi">28</span>',
      '<span class="w"> </span>',
      '<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_pytorch_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
      '<span class="n">validation_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">validation_pytorch_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">)</span>',
      '<span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_pytorch_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos una muestra</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_loader</span><span class="p">))</span>',
      '<span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">shape</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '(torch.Size([28, 768]), torch.Size([28, 768]))',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Se lo pasamos al modelo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>',
      '<span class="n">output</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'odict_keys([&#x27;logits&#x27;, &#x27;past_key_values&#x27;])',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Como vemos, no tenemos valor de <code>loss</code>. Como hemos visto, tenemos que pasarle el <code>input_ids</code> y el <code>labels</code>.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">=</span><span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>',
      '<span class="n">output</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'odict_keys([&#x27;loss&#x27;, &#x27;logits&#x27;, &#x27;past_key_values&#x27;])',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Ahora sí tenemos <code>loss</code></p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '80.5625',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Optimizador">Optimizador<a class="anchor-link" href="#Optimizador"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 37" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Creamos un optimizador</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AdamW</span>',
      '<span class="w"> </span>',
      '<span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>',
      '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-5</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning',
          '&#x20;&#x20;warnings.warn(',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Entrenamiento">Entrenamiento<a class="anchor-link" href="#Entrenamiento"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 38" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Creamos el bucle de entrenamiento</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>',
      '<span class="w"> </span>',
      '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>',
      '<span class="w"> </span>',
      '<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">train_loss</span> <span class="o">=</span> <span class="mi">0</span>',
      '<span class="w">    </span><span class="n">progresbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">at_mask</span> <span class="ow">in</span> <span class="n">progresbar</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">at_mask</span> <span class="o">=</span> <span class="n">at_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">at_mask</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">input_ids</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>',
      '<span class="w">        </span><span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>',
      '<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
      '<span class="w">        </span><span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>',
      '<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
      '<span class="w">        </span><span class="n">progresbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">({</span><span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()})</span>',
      '<span class="w">    </span><span class="n">train_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">progresbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">({</span><span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="n">train_loss</span><span class="p">})</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Epoch 1: 100%|██████████| 7447/7447 [51:07&amp;lt;00:00,  2.43it/s, train_loss=nan]',
          'Epoch 2: 100%|██████████| 7447/7447 [51:06&amp;lt;00:00,  2.43it/s, train_loss=nan]',
          'Epoch 3: 100%|██████████| 7447/7447 [51:07&amp;lt;00:00,  2.43it/s, train_loss=nan]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Uso del modelo">Uso del modelo<a class="anchor-link" href="#Uso del modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 39" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Probamos el modelo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">def</span><span class="w"> </span><span class="nf">generate_text</span><span class="p">(</span><span class="n">decoded_joke</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">stop_token</span><span class="o">=</span><span class="s1">&#39;&amp;lt;EJ&amp;gt;&#39;</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">input_tokens</span> <span class="o">=</span> <span class="n">tokenize_function</span><span class="p">({</span><span class="s1">&#39;Joke&#39;</span><span class="p">:</span> <span class="n">decoded_joke</span><span class="p">})</span>',
      '<span class="w">    </span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_tokens</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">input_tokens</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>',
      '<span class="w">    </span><span class="n">nex_token</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">][:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">nex_token_decoded</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">nex_token</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">decoded_joke</span> <span class="o">=</span> <span class="n">decoded_joke</span> <span class="o">+</span> <span class="n">nex_token_decoded</span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_new_tokens</span><span class="p">):</span>',
      '<span class="w">        </span><span class="n">nex_token</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">][:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>',
      '<span class="w">        </span><span class="n">nex_token_decoded</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">nex_token</span><span class="p">)</span>',
      '<span class="w">        </span><span class="k">if</span> <span class="n">nex_token_decoded</span> <span class="o">==</span> <span class="n">stop_token</span><span class="p">:</span>',
      '<span class="w">            </span><span class="k">break</span>',
      '<span class="w">        </span><span class="n">decoded_joke</span> <span class="o">=</span> <span class="n">decoded_joke</span> <span class="o">+</span> <span class="n">nex_token_decoded</span>',
      '<span class="w">        </span><span class="n">input_tokens</span> <span class="o">=</span> <span class="n">tokenize_function</span><span class="p">({</span><span class="s1">&#39;Joke&#39;</span><span class="p">:</span> <span class="n">decoded_joke</span><span class="p">})</span>',
      '<span class="w">        </span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_tokens</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">input_tokens</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">decoded_joke</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">generated_text</span> <span class="o">=</span> <span class="n">generate_text</span><span class="p">(</span><span class="s2">&quot;&amp;lt;SJ&amp;gt; Why didn&#39;t the frog cross the road&quot;</span><span class="p">)</span>',
      '<span class="n">generated_text</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '&quot;&amp;lt;SJ&amp;gt; Why didn&#x27;t the frog cross the road!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!&quot;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
















    </div>

  </section>

</PostLayout>
