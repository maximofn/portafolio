---
import PostLayout from '@layouts/PostLayout.astro';
import CodeBlockInputCell from '@components/CodeBlockInputCell.astro';
import CodeBlockOutputCell from '@components/CodeBlockOutputCell.astro';

const { metadata_page } = await import('@portfolio/consts.json');
const { colors } = await import('@portfolio/consts.json');
const { svg_paths } = await import('@portfolio/consts.json');

const page_title = 'Fine tuning SMLs';
const end_url = 'fine-tuning-sml';
const description = ' Afinar modelos de lenguaje peque帽os? Por favor, no est谩s \'afinando\', solo est谩s desesperadamente intentando sacar algo de sentido de un modelo que es tan 煤til como una tetera de chocolate . Pero hey, 驴qui茅n no ama un buen desaf铆o? Adelante, desperdicia tus horas de GPU, y quiz谩s, solo quiz谩s, obtendr谩s un modelo que pueda distinguir entre \'hola\' y \'adi贸s\' . Buena suerte, y no digas que no te advert铆 ';
const keywords = 'slm, modelos de lenguaje peque帽os, afinar, chistes, humor, gpt2, openai, transformers, huggingface';
const languaje = 'ES';
const image_path = 'https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/SLM_thumnail.webp';
const opening_brace = '{';
const closing_brace = '}';
---

<PostLayout 
    title={page_title}
    languaje={languaje}
    description={description}
    keywords={keywords}
    author={metadata_page.author}
    theme_color={colors.background_color}
    end_url={end_url}
    image_path={image_path}
    image_width=900
    image_height=450
    image_extension=webp
    article_date=2024-07-14+T00:00:00Z
>

  <section class="post-body">


    <aside class="post-index">
      <a class="anchor-link" href="#Fine-tuning-para-clasificaci%C3%B3n-de-texto-con-Hugging-Face"><h2>Fine tuning para clasificaci贸n de texto con Hugging Face</h2></a>
      <a class="anchor-link" href="#Login"><h3>Login</h3></a>
      <a class="anchor-link" href="#Dataset"><h3>Dataset</h3></a>
      <a class="anchor-link" href="#Tokenizador"><h3>Tokenizador</h3></a>
      <a class="anchor-link" href="#Modelo"><h3>Modelo</h3></a>
      <a class="anchor-link" href="#Trainer"><h3>Trainer</h3></a>
      <a class="anchor-link" href="#Evaluaci%C3%B3n"><h3>Evaluaci贸n</h3></a>
      <a class="anchor-link" href="#Publicar-el-modelo"><h3>Publicar el modelo</h3></a>
      <a class="anchor-link" href="#Uso-del-modelo"><h3>Uso del modelo</h3></a>
      <a class="anchor-link" href="#Fine-tuning-para-generaci%C3%B3n-de-texto-con-Hugging-Face"><h2>Fine tuning para generaci贸n de texto con Hugging Face</h2></a>
      <a class="anchor-link" href="#Login"><h3>Login</h3></a>
      <a class="anchor-link" href="#Dataset"><h3>Dataset</h3></a>
      <a class="anchor-link" href="#Tokenizador"><h3>Tokenizador</h3></a>
      <a class="anchor-link" href="#Modelo"><h3>Modelo</h3></a>
      <a class="anchor-link" href="#Entrenamiento"><h3>Entrenamiento</h3></a>
      <a class="anchor-link" href="#Evaluaci%C3%B3n"><h3>Evaluaci贸n</h3></a>
      <a class="anchor-link" href="#Publicar-el-modelo"><h3>Publicar el modelo</h3></a>
      <a class="anchor-link" href="#Uso-del-modelo"><h3>Uso del modelo</h3></a>
      <a class="anchor-link" href="#Fine-tuning-para-clasificaci%C3%B3n-de-texto-con-Pytorch"><h2>Fine tuning para clasificaci贸n de texto con Pytorch</h2></a>
      <a class="anchor-link" href="#Dataset"><h3>Dataset</h3></a>
      <a class="anchor-link" href="#Tokenizador"><h3>Tokenizador</h3></a>
      <a class="anchor-link" href="#Modelo"><h3>Modelo</h3></a>
      <a class="anchor-link" href="#Device"><h3>Device</h3></a>
      <a class="anchor-link" href="#Pytorch-Dataset"><h3>Pytorch Dataset</h3></a>
      <a class="anchor-link" href="#Pytorch-Dataloader"><h3>Pytorch Dataloader</h3></a>
      <a class="anchor-link" href="#M%C3%A9trica"><h3>M茅trica</h3></a>
      <a class="anchor-link" href="#Optimizador"><h3>Optimizador</h3></a>
      <a class="anchor-link" href="#Entrenamiento"><h3>Entrenamiento</h3></a>
      <a class="anchor-link" href="#Uso-del-modelo"><h3>Uso del modelo</h3></a>
      <a class="anchor-link" href="#Fine-tuning-para-generaci%C3%B3n-de-texto-con-Pytorch"><h2>Fine tuning para generaci贸n de texto con Pytorch</h2></a>
      <a class="anchor-link" href="#Dataset"><h3>Dataset</h3></a>
      <a class="anchor-link" href="#Tokenizador"><h3>Tokenizador</h3></a>
      <a class="anchor-link" href="#Modelo"><h3>Modelo</h3></a>
      <a class="anchor-link" href="#Device"><h3>Device</h3></a>
      <a class="anchor-link" href="#Pytorch-Dataset"><h3>Pytorch Dataset</h3></a>
      <a class="anchor-link" href="#Pytorch-Dataloader"><h3>Pytorch Dataloader</h3></a>
      <a class="anchor-link" href="#Optimizador"><h3>Optimizador</h3></a>
      <a class="anchor-link" href="#Entrenamiento"><h3>Entrenamiento</h3></a>
      <a class="anchor-link" href="#Uso-del-modelo"><h3>Uso del modelo</h3></a>
    </aside>


    <div class="post-body-content">
      
      <section class="section-block-markdown-cell">
      <h1 id="Fine-tuning-SMLs-con-Hugging-Face">Fine tuning SMLs con Hugging Face<a class="anchor-link" href="#Fine-tuning-SMLs-con-Hugging-Face"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 0" src={svg_paths.link_svg_path}/></a></h1>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>En este post vamos a ver c贸mo hacer fine tuning a peque帽os modelos de lenguaje, vamos a ver c贸mo hacer fine tuning para clasificaci贸n de texto y para generaci贸n de texto. Primero vamos a ver c贸mo hacerlo con las librer铆as de Hugging Face, ya que se Hugging Face se ha convertido en un actor muy importante en el ecosistema de IA en estos momentos.</p>
      <p>Pero aunque las librer铆as de Hugging Face son muy importantes y 煤tiles, es muy importante saber c贸mo se hace realmente el entrenamiento y qu茅 est谩 pasando por debajo, as铆 que vamos a repetir el entrenamiento para clasificaci贸n y generaci贸n de texto pero con Pytorch</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Fine-tuning-para-clasificaci%C3%B3n-de-texto-con-Hugging-Face">Fine tuning para clasificaci贸n de texto con Hugging Face<a class="anchor-link" href="#Fine-tuning-para-clasificaci%C3%B3n-de-texto-con-Hugging-Face"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 1" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Login">Login<a class="anchor-link" href="#Login"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 2" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Para poder subir el resultado del entrenamiento al hub debemos logearnos primero, para ello necesitamos un token</p>
      <p>Para crear un token hay que ir a la p谩gina de <a href="https://huggingface.co/settings/tokens" target="_blank" rel="nofollow noreferrer">setings/tokens</a> de nuestra cuenta, nos aparecer谩 algo as铆</p>
      <p><img decoding="async" onerror="this.parentNode.removeChild(this)" alt="User-Access-Token-dark" src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/User-Access-Token-dark.webp" width="1200" height="615"/></p>
      <p>Le damos a <code>New token</code> y nos aparecer谩 una ventana para crear un nuevo token</p>
      <p><img decoding="async" onerror="this.parentNode.removeChild(this)" alt="new-token-dark" src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/new-token-dark.webp" width="1200" height="660"/></p>
      <p>Le damos un nombre al token y lo creamos con el rol <code>write</code>, o con el rol <code>Fine-grained</code>, que nos permite seleccionar exactamente qu茅 permisos tendr谩 el token</p>
      <p>Una vez creado lo copiamos y lo pegamos a continuaci贸n</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">huggingface_hub</span> <span class="kn">import</span> <span class="n">notebook_login</span>',
      '      <span class="n">notebook_login</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>







      
      <section class="section-block-markdown-cell">
      <h3 id="Dataset">Dataset<a class="anchor-link" href="#Dataset"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 3" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Ahora nos descargamos un dataset, en este caso nos vamos a descargar uno de reviews de <a href="https://huggingface.co/datasets/mteb/amazon_reviews_multi" target="_blank" rel="nofollow noreferrer">Amazon</a></p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">huggingface_hub</span> <span class="kn">import</span> <span class="n">notebook_login</span>',
      '      <span class="n">notebook_login</span><span class="p">()</span>',
      '<span></span><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
      '      ',
      '      <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"mteb/amazon_reviews_multi"</span><span class="p">,</span> <span class="s2">"en"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>








      
      <section class="section-block-markdown-cell">
      <p>Vamos a verlo un poco</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">huggingface_hub</span> <span class="kn">import</span> <span class="n">notebook_login</span>',
          '<span class="n">notebook_login</span><span class="p">()</span>',
          '</span><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"mteb/amazon_reviews_multi"</span><span class="p">,</span> <span class="s2">"en"</span><span class="p">)</span>',
          '</span><span class="n">dataset</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'DatasetDict({',
          '    train: Dataset({',
          '        features: [\'id\', \'text\', \'label\', \'label_text\'],',
          '        num_rows: 200000',
          '    })',
          '    validation: Dataset({',
          '        features: [\'id\', \'text\', \'label\', \'label_text\'],',
          '        num_rows: 5000',
          '    })',
          '    test: Dataset({',
          '        features: [\'id\', \'text\', \'label\', \'label_text\'],',
          '        num_rows: 5000',
          '    })',
          '})',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos que tiene un conjunto de entrenamiento con 200.000 muestras, uno de validaci贸n con 5.000 muestras y uno de test de 5.000 muestras</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a ver un ejemplo del conjunto de entrenamiento</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">random</span> <span class="kn">import</span> <span class="n">randint</span>',
          '',
          '<span class="n">idx</span> <span class="o">=</span> <span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>',
          '<span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '{\'id\': \'en_0907914\',',
          ' \'text\': \'Mixed with fir its passable\n\nNot the scent I had hoped for . Love the scent of cedar, but this one missed\',',
          ' \'label\': 3,',
          ' \'label_text\': \'3\'}',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos que tiene la review en el campo <code>text</code> y la puntuaci贸n que le ha dado el usuario en el campo <code>label</code></p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Como vamos a hacer un modelo de clasificaci贸n de textos, necesitamos saber cuantas clases vamos a tener</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="s1">\'label\'</span><span class="p">))</span>',
          '<span class="n">num_classes</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '5',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a tener 5 clases, ahora vamos a ver el valor m铆nimo de estas clases para saber si la puntuaci贸n comienza en 0 o en 1. Para ello usamos el m茅todo <code>unique</code></p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">dataset</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="s1">\'label\'</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '{\'train\': [0, 1, 2, 3, 4],',
          ' \'validation\': [0, 1, 2, 3, 4],',
          ' \'test\': [0, 1, 2, 3, 4]}',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>El m铆nimo valor va a ser 0</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Para entrenar, las etiquetas tienen que estar en un campo llamado <code>labels</code>, mientras que en nuestro dataset est谩 en un campo que se llama <code>label</code>, por lo que creamos el nuevo campo <code>lables</code> con el mismo valor que <code>label</code></p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Creamos una funci贸n que haga lo que queremos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">def</span> <span class="nf">set_labels</span><span class="p">(</span><span class="n">example</span><span class="p">):</span>',
      '          <span class="n">example</span><span class="p">[</span><span class="s1">\'labels\'</span><span class="p">]</span> <span class="o">=</span> <span class="n">example</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">]</span>',
      '          <span class="k">return</span> <span class="n">example</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>








      
      <section class="section-block-markdown-cell">
      <p>Aplicamos la funci贸n al dataset</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">def</span> <span class="nf">set_labels</span><span class="p">(</span><span class="n">example</span><span class="p">):</span>',
      '          <span class="n">example</span><span class="p">[</span><span class="s1">\'labels\'</span><span class="p">]</span> <span class="o">=</span> <span class="n">example</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">]</span>',
      '          <span class="k">return</span> <span class="n">example</span>',
      '<span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">set_labels</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>






      
      <section class="section-block-markdown-cell">
      <p>Vamos a ver c贸mo queda el dataset</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="k">def</span> <span class="nf">set_labels</span><span class="p">(</span><span class="n">example</span><span class="p">):</span>',
          '    <span class="n">example</span><span class="p">[</span><span class="s1">\'labels\'</span><span class="p">]</span> <span class="o">=</span> <span class="n">example</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">]</span>',
          '    <span class="k">return</span> <span class="n">example</span>',
          '</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">set_labels</span><span class="p">)</span>',
          '</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '{\'id\': \'en_0907914\',',
          ' \'text\': \'Mixed with fir its passable\n\nNot the scent I had hoped for . Love the scent of cedar, but this one missed\',',
          ' \'label\': 3,',
          ' \'label_text\': \'3\',',
          ' \'labels\': 3}',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Tokenizador">Tokenizador<a class="anchor-link" href="#Tokenizador"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 4" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Como en el dataset tenemos las reviews en texto, necesitamos tokenizarlas para poder meter los tokens al modelo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>',
      '      ',
      '      <span class="n">checkpoint</span> <span class="o">=</span> <span class="s2">"openai-community/gpt2"</span>',
      '      <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>









      
      <section class="section-block-markdown-cell">
      <p>Ahora creamos una funci贸n para tokenizar el texto. Lo vamos a hacer de manera que todas las sentencias tenan la mismas longitud, de manera que el tokenizador truncar谩 cuando sea necesario y a帽adir谩 tokens de padding cuando sea necesario. Adem谩s le indicamos que devuelva tensores de pytorch</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Hacemos que la longitud de cada sentencia sea de 768 tokens porque estamos usando el modelo peque帽o de GPT2, que como vimos en el post de <a href="https://maximofn.com/gpt2/#Arquitectura">GPT2</a> tiene una dimensi贸n de embedding de 768 tokens</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>',
      '      ',
      '      <span class="n">checkpoint</span> <span class="o">=</span> <span class="s2">"openai-community/gpt2"</span>',
      '      <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>',
      '<span></span><span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>',
      '          <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>







      
      <section class="section-block-markdown-cell">
      <p>Vamos a probar a tokenizar un texto</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>',
          '',
          '<span class="n">checkpoint</span> <span class="o">=</span> <span class="s2">"openai-community/gpt2"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>',
          '</span><span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '</span><span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">][</span><span class="n">idx</span><span class="p">])</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '<span class="ansi-red-fg">---------------------------------------------------------------------------</span>',
          '<span class="ansi-red-fg">ValueError</span>                                Traceback (most recent call last)',
          'Cell <span class="ansi-green-fg">In[11], line 1</span>',
          '<span class="ansi-green-fg">----&gt; 1</span> tokens <span style="color: rgb(98,98,98)">=</span> tokenize_function(dataset[<span style="color: rgb(175,0,0)">\'</span><span style="color: rgb(175,0,0)">train</span><span style="color: rgb(175,0,0)">\'</span>][idx])',
          'Cell <span class="ansi-green-fg">In[10], line 2</span>, in <span class="ansi-cyan-fg">tokenize_function</span><span class="ansi-blue-fg">(examples)</span>',
          '<span class="ansi-green-intense-fg ansi-bold">      1</span> <span class="ansi-bold" style="color: rgb(0,135,0)">def</span> <span style="color: rgb(0,0,255)">tokenize_function</span>(examples):',
          '<span class="ansi-green-fg">----&gt; 2</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> tokenizer(examples[<span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">text</span><span style="color: rgb(175,0,0)">"</span>], padding<span style="color: rgb(98,98,98)">=</span><span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">max_length</span><span style="color: rgb(175,0,0)">"</span>, truncation<span style="color: rgb(98,98,98)">=</span><span class="ansi-bold" style="color: rgb(0,135,0)">True</span>, max_length<span style="color: rgb(98,98,98)">=</span><span style="color: rgb(98,98,98)">768</span>, return_tensors<span style="color: rgb(98,98,98)">=</span><span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">pt</span><span style="color: rgb(175,0,0)">"</span>)',
          'File <span class="ansi-green-fg">~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2883</span>, in <span class="ansi-cyan-fg">PreTrainedTokenizerBase.__call__</span><span class="ansi-blue-fg">(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)</span>',
          '<span class="ansi-green-intense-fg ansi-bold">   2881</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> <span class="ansi-bold" style="color: rgb(175,0,255)">not</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_in_target_context_manager:',
          '<span class="ansi-green-intense-fg ansi-bold">   2882</span>         <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_switch_to_input_mode()',
          '<span class="ansi-green-fg">-&gt; 2883</span>     encodings <span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_call_one(text<span style="color: rgb(98,98,98)">=</span>text, text_pair<span style="color: rgb(98,98,98)">=</span>text_pair, <span style="color: rgb(98,98,98)">*</span><span style="color: rgb(98,98,98)">*</span>all_kwargs)',
          '<span class="ansi-green-intense-fg ansi-bold">   2884</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> text_target <span class="ansi-bold" style="color: rgb(175,0,255)">is</span> <span class="ansi-bold" style="color: rgb(175,0,255)">not</span> <span class="ansi-bold" style="color: rgb(0,135,0)">None</span>:',
          '<span class="ansi-green-intense-fg ansi-bold">   2885</span>     <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_switch_to_target_mode()',
          'File <span class="ansi-green-fg">~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2989</span>, in <span class="ansi-cyan-fg">PreTrainedTokenizerBase._call_one</span><span class="ansi-blue-fg">(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)</span>',
          '<span class="ansi-green-intense-fg ansi-bold">   2969</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>batch_encode_plus(',
          '<span class="ansi-green-intense-fg ansi-bold">   2970</span>         batch_text_or_text_pairs<span style="color: rgb(98,98,98)">=</span>batch_text_or_text_pairs,',
          '<span class="ansi-green-intense-fg ansi-bold">   2971</span>         add_special_tokens<span style="color: rgb(98,98,98)">=</span>add_special_tokens,',
          '<span class="ansi-green-fg">   (...)</span>',
          '<span class="ansi-green-intense-fg ansi-bold">   2986</span>         <span style="color: rgb(98,98,98)">*</span><span style="color: rgb(98,98,98)">*</span>kwargs,',
          '<span class="ansi-green-intense-fg ansi-bold">   2987</span>     )',
          '<span class="ansi-green-intense-fg ansi-bold">   2988</span> <span class="ansi-bold" style="color: rgb(0,135,0)">else</span>:',
          '<span class="ansi-green-fg">-&gt; 2989</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>encode_plus(',
          '<span class="ansi-green-intense-fg ansi-bold">   2990</span>         text<span style="color: rgb(98,98,98)">=</span>text,',
          '<span class="ansi-green-intense-fg ansi-bold">   2991</span>         text_pair<span style="color: rgb(98,98,98)">=</span>text_pair,',
          '<span class="ansi-green-intense-fg ansi-bold">   2992</span>         add_special_tokens<span style="color: rgb(98,98,98)">=</span>add_special_tokens,',
          '<span class="ansi-green-intense-fg ansi-bold">   2993</span>         padding<span style="color: rgb(98,98,98)">=</span>padding,',
          '<span class="ansi-green-intense-fg ansi-bold">   2994</span>         truncation<span style="color: rgb(98,98,98)">=</span>truncation,',
          '<span class="ansi-green-intense-fg ansi-bold">   2995</span>         max_length<span style="color: rgb(98,98,98)">=</span>max_length,',
          '<span class="ansi-green-intense-fg ansi-bold">   2996</span>         stride<span style="color: rgb(98,98,98)">=</span>stride,',
          '<span class="ansi-green-intense-fg ansi-bold">   2997</span>         is_split_into_words<span style="color: rgb(98,98,98)">=</span>is_split_into_words,',
          '<span class="ansi-green-intense-fg ansi-bold">   2998</span>         pad_to_multiple_of<span style="color: rgb(98,98,98)">=</span>pad_to_multiple_of,',
          '<span class="ansi-green-intense-fg ansi-bold">   2999</span>         return_tensors<span style="color: rgb(98,98,98)">=</span>return_tensors,',
          '<span class="ansi-green-intense-fg ansi-bold">   3000</span>         return_token_type_ids<span style="color: rgb(98,98,98)">=</span>return_token_type_ids,',
          '<span class="ansi-green-intense-fg ansi-bold">   3001</span>         return_attention_mask<span style="color: rgb(98,98,98)">=</span>return_attention_mask,',
          '<span class="ansi-green-intense-fg ansi-bold">   3002</span>         return_overflowing_tokens<span style="color: rgb(98,98,98)">=</span>return_overflowing_tokens,',
          '<span class="ansi-green-intense-fg ansi-bold">   3003</span>         return_special_tokens_mask<span style="color: rgb(98,98,98)">=</span>return_special_tokens_mask,',
          '<span class="ansi-green-intense-fg ansi-bold">   3004</span>         return_offsets_mapping<span style="color: rgb(98,98,98)">=</span>return_offsets_mapping,',
          '<span class="ansi-green-intense-fg ansi-bold">   3005</span>         return_length<span style="color: rgb(98,98,98)">=</span>return_length,',
          '<span class="ansi-green-intense-fg ansi-bold">   3006</span>         verbose<span style="color: rgb(98,98,98)">=</span>verbose,',
          '<span class="ansi-green-intense-fg ansi-bold">   3007</span>         <span style="color: rgb(98,98,98)">*</span><span style="color: rgb(98,98,98)">*</span>kwargs,',
          '<span class="ansi-green-intense-fg ansi-bold">   3008</span>     )',
          'File <span class="ansi-green-fg">~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3053</span>, in <span class="ansi-cyan-fg">PreTrainedTokenizerBase.encode_plus</span><span class="ansi-blue-fg">(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)</span>',
          '<span class="ansi-green-intense-fg ansi-bold">   3032</span> <span style="color: rgb(175,0,0)">"""</span>',
          '<span class="ansi-green-intense-fg ansi-bold">   3033</span> <span style="color: rgb(175,0,0)">Tokenize and prepare for the model a sequence or a pair of sequences.</span>',
          '<span class="ansi-green-intense-fg ansi-bold">   3034</span> ',
          '<span class="ansi-green-fg">   (...)</span>',
          '<span class="ansi-green-intense-fg ansi-bold">   3049</span> <span style="color: rgb(175,0,0)">        method).</span>',
          '<span class="ansi-green-intense-fg ansi-bold">   3050</span> <span style="color: rgb(175,0,0)">"""</span>',
          '<span class="ansi-green-intense-fg ansi-bold">   3052</span> <span style="color: rgb(95,135,135)"># Backward compatibility for \'truncation_strategy\', \'pad_to_max_length\'</span>',
          '<span class="ansi-green-fg">-&gt; 3053</span> padding_strategy, truncation_strategy, max_length, kwargs <span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_get_padding_truncation_strategies(',
          '<span class="ansi-green-intense-fg ansi-bold">   3054</span>     padding<span style="color: rgb(98,98,98)">=</span>padding,',
          '<span class="ansi-green-intense-fg ansi-bold">   3055</span>     truncation<span style="color: rgb(98,98,98)">=</span>truncation,',
          '<span class="ansi-green-intense-fg ansi-bold">   3056</span>     max_length<span style="color: rgb(98,98,98)">=</span>max_length,',
          '<span class="ansi-green-intense-fg ansi-bold">   3057</span>     pad_to_multiple_of<span style="color: rgb(98,98,98)">=</span>pad_to_multiple_of,',
          '<span class="ansi-green-intense-fg ansi-bold">   3058</span>     verbose<span style="color: rgb(98,98,98)">=</span>verbose,',
          '<span class="ansi-green-intense-fg ansi-bold">   3059</span>     <span style="color: rgb(98,98,98)">*</span><span style="color: rgb(98,98,98)">*</span>kwargs,',
          '<span class="ansi-green-intense-fg ansi-bold">   3060</span> )',
          '<span class="ansi-green-intense-fg ansi-bold">   3062</span> <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_encode_plus(',
          '<span class="ansi-green-intense-fg ansi-bold">   3063</span>     text<span style="color: rgb(98,98,98)">=</span>text,',
          '<span class="ansi-green-intense-fg ansi-bold">   3064</span>     text_pair<span style="color: rgb(98,98,98)">=</span>text_pair,',
          '<span class="ansi-green-fg">   (...)</span>',
          '<span class="ansi-green-intense-fg ansi-bold">   3080</span>     <span style="color: rgb(98,98,98)">*</span><span style="color: rgb(98,98,98)">*</span>kwargs,',
          '<span class="ansi-green-intense-fg ansi-bold">   3081</span> )',
          'File <span class="ansi-green-fg">~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2788</span>, in <span class="ansi-cyan-fg">PreTrainedTokenizerBase._get_padding_truncation_strategies</span><span class="ansi-blue-fg">(self, padding, truncation, max_length, pad_to_multiple_of, verbose, **kwargs)</span>',
          '<span class="ansi-green-intense-fg ansi-bold">   2786</span> <span style="color: rgb(95,135,135)"># Test if we have a padding token</span>',
          '<span class="ansi-green-intense-fg ansi-bold">   2787</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> padding_strategy <span style="color: rgb(98,98,98)">!=</span> PaddingStrategy<span style="color: rgb(98,98,98)">.</span>DO_NOT_PAD <span class="ansi-bold" style="color: rgb(175,0,255)">and</span> (<span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>pad_token <span class="ansi-bold" style="color: rgb(175,0,255)">is</span> <span class="ansi-bold" style="color: rgb(0,135,0)">None</span> <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>pad_token_id <span style="color: rgb(98,98,98)">&lt;</span> <span style="color: rgb(98,98,98)">0</span>):',
          '<span class="ansi-green-fg">-&gt; 2788</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">raise</span> <span class="ansi-bold" style="color: rgb(215,95,95)">ValueError</span>(',
          '<span class="ansi-green-intense-fg ansi-bold">   2789</span>         <span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">Asking to pad but the tokenizer does not have a padding token. </span><span style="color: rgb(175,0,0)">"</span>',
          '<span class="ansi-green-intense-fg ansi-bold">   2790</span>         <span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` </span><span style="color: rgb(175,0,0)">"</span>',
          '<span class="ansi-green-intense-fg ansi-bold">   2791</span>         <span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">or add a new pad token via `tokenizer.add_special_tokens(</span><span style="color: rgb(175,0,0)">{</span><span style="color: rgb(175,0,0)">\'</span><span style="color: rgb(175,0,0)">pad_token</span><span style="color: rgb(175,0,0)">\'</span><span style="color: rgb(175,0,0)">: </span><span style="color: rgb(175,0,0)">\'</span><span style="color: rgb(175,0,0)">[PAD]</span><span style="color: rgb(175,0,0)">\'</span><span style="color: rgb(175,0,0)">})`.</span><span style="color: rgb(175,0,0)">"</span>',
          '<span class="ansi-green-intense-fg ansi-bold">   2792</span>     )',
          '<span class="ansi-green-intense-fg ansi-bold">   2794</span> <span style="color: rgb(95,135,135)"># Check that we will truncate to a multiple of pad_to_multiple_of if both are provided</span>',
          '<span class="ansi-green-intense-fg ansi-bold">   2795</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> (',
          '<span class="ansi-green-intense-fg ansi-bold">   2796</span>     truncation_strategy <span style="color: rgb(98,98,98)">!=</span> TruncationStrategy<span style="color: rgb(98,98,98)">.</span>DO_NOT_TRUNCATE',
          '<span class="ansi-green-intense-fg ansi-bold">   2797</span>     <span class="ansi-bold" style="color: rgb(175,0,255)">and</span> padding_strategy <span style="color: rgb(98,98,98)">!=</span> PaddingStrategy<span style="color: rgb(98,98,98)">.</span>DO_NOT_PAD',
          '<span class="ansi-green-fg">   (...)</span>',
          '<span class="ansi-green-intense-fg ansi-bold">   2800</span>     <span class="ansi-bold" style="color: rgb(175,0,255)">and</span> (max_length <span style="color: rgb(98,98,98)">%</span> pad_to_multiple_of <span style="color: rgb(98,98,98)">!=</span> <span style="color: rgb(98,98,98)">0</span>)',
          '<span class="ansi-green-intense-fg ansi-bold">   2801</span> ):',
          '<span class="ansi-red-fg">ValueError</span>: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({\'pad_token\': \'[PAD]\'})`.',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Nos da un error porque el tokenizador de GPT2 no tiene un token para padding y nos pide que asignemos uno, adem谩s nos sugiere hacer <code>tokenizer.pad_token = tokenizer.eos_token</code>, as铆 que lo hacemos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>






      
      <section class="section-block-markdown-cell">
      <p>Volvemos a probar la funci贸n de tokenizaci贸n</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>',
          '</span><span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">][</span><span class="n">idx</span><span class="p">])</span>',
          '<span class="n">tokens</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">tokens</span><span class="p">[</span><span class="s1">\'attention_mask\'</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '(torch.Size([1, 768]), torch.Size([1, 768]))',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Ahora que hemos comprobado que la funci贸n tokeniza bien, aplicamos esta funci贸n al dataset, pero adem谩s la aplicamos por batches para que se ejecute m谩s r谩pido</p>
      <p>Adem谩s aprovechamos y eliminamos las columnas que no vamos a necesitar</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'text\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'id\'</span><span class="p">,</span> <span class="s1">\'label_text\'</span><span class="p">])</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>






      
      <section class="section-block-markdown-cell">
      <p>Vemos ahora c贸mo queda el dataset</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'text\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'id\'</span><span class="p">,</span> <span class="s1">\'label_text\'</span><span class="p">])</span>',
          '</span><span class="n">dataset</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'DatasetDict({',
          '    train: Dataset({',
          '        features: [\'id\', \'text\', \'label\', \'label_text\', \'labels\'],',
          '        num_rows: 200000',
          '    })',
          '    validation: Dataset({',
          '        features: [\'id\', \'text\', \'label\', \'label_text\', \'labels\'],',
          '        num_rows: 5000',
          '    })',
          '    test: Dataset({',
          '        features: [\'id\', \'text\', \'label\', \'label_text\', \'labels\'],',
          '        num_rows: 5000',
          '    })',
          '})',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos que tenemos los campos 'labels', 'input_ids' y 'attention_mask', que es lo que nos interesa para entrenar</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Modelo">Modelo<a class="anchor-link" href="#Modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 5" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Instanciamos un modelo para clasificaci贸n de secuencias y le indicamos el n煤mero de clases que tenemos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="n">num_classes</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: [\'score.weight\']',
          'You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Nos dice que los pesos de la capa <code>score</code> han sido inicializados de manera aleatoria y que tenemos que reentrenarlos, vamos a ver por qu茅 pasa esto</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>El modelo de GPT2 ser铆a este</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForCausalLM</span>',
      '      ',
      '      <span class="n">casual_model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>








      
      <section class="section-block-markdown-cell">
      <p>Mientras que el modelo de GPT2 para generar texto es este</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a ver su arquitectura</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForCausalLM</span>',
          '',
          '<span class="n">casual_model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>',
          '</span><span class="n">casual_model</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'GPT2LMHeadModel(',
          '  (transformer): GPT2Model(',
          '    (wte): Embedding(50257, 768)',
          '    (wpe): Embedding(1024, 768)',
          '    (drop): Dropout(p=0.1, inplace=False)',
          '    (h): ModuleList(',
          '      (0-11): 12 x GPT2Block(',
          '        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)',
          '        (attn): GPT2Attention(',
          '          (c_attn): Conv1D()',
          '          (c_proj): Conv1D()',
          '          (attn_dropout): Dropout(p=0.1, inplace=False)',
          '          (resid_dropout): Dropout(p=0.1, inplace=False)',
          '        )',
          '        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)',
          '        (mlp): GPT2MLP(',
          '          (c_fc): Conv1D()',
          '          (c_proj): Conv1D()',
          '          (act): NewGELUActivation()',
          '          (dropout): Dropout(p=0.1, inplace=False)',
          '        )',
          '      )',
          '    )',
          '    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)',
          '  )',
          '  (lm_head): Linear(in_features=768, out_features=50257, bias=False)',
          ')',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Y ahora la arquitectura del modelo que vamos a usar para clasificar las reviews</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">model</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'GPT2ForSequenceClassification(',
          '  (transformer): GPT2Model(',
          '    (wte): Embedding(50257, 768)',
          '    (wpe): Embedding(1024, 768)',
          '    (drop): Dropout(p=0.1, inplace=False)',
          '    (h): ModuleList(',
          '      (0-11): 12 x GPT2Block(',
          '        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)',
          '        (attn): GPT2Attention(',
          '          (c_attn): Conv1D()',
          '          (c_proj): Conv1D()',
          '          (attn_dropout): Dropout(p=0.1, inplace=False)',
          '          (resid_dropout): Dropout(p=0.1, inplace=False)',
          '        )',
          '        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)',
          '        (mlp): GPT2MLP(',
          '          (c_fc): Conv1D()',
          '          (c_proj): Conv1D()',
          '          (act): NewGELUActivation()',
          '          (dropout): Dropout(p=0.1, inplace=False)',
          '        )',
          '      )',
          '    )',
          '    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)',
          '  )',
          '  (score): Linear(in_features=768, out_features=5, bias=False)',
          ')',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>De aqu铆 hay dos cosas que mencionar</p>
      <ul>
      <li>La primera es que en ambos, la primera capa tiene dimensiones de 50257x768, que corresponde a 50257 posibles tokens del vocabulario de GPT2 y a 768 dimensiones del embedding, por lo que hemos hecho bien en tokenizar las reviews con un tama帽o de 768 tokens</li>
      <li>La segunda es que el modelo <code>casual</code> (el de generaci贸n de texto) tiene al final una capa <code>Linear</code> que genera 50257 valores, es decir, es la encargada de predecir el siguiente token y a posible token le da un valor. Mientras que el modelo de clasificaci贸n tiene una capa <code>Linear</code> que solo genera 5 valores, uno por cada clase, lo que nos dar谩 la probabilidad de que la review pertenezca a cada clase</li>
      </ul>
      <p>Por eso nos sal铆a el mensaje de que los pesos de la capa <code>score</code> hab铆an sido inicializados de manera aleatoria, porque la librer铆a transformers ha eliminado la capa <code>Linear</code> de 768x50257 y ha a帽adido una capa <code>Linear</code> de 768x5, la ha inicializado con valores aleatorios y nosotros la tenemos que entrenar para nuestro problema en particular</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Borramos el modelo casual, porque no lo vamos a usar</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">del</span> <span class="n">casual_model</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>






      
      <section class="section-block-markdown-cell">
      <h3 id="Trainer">Trainer<a class="anchor-link" href="#Trainer"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 6" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos ahora a configurar los argumentos del entrenamiento</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">del</span> <span class="n">casual_model</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>',
      '      ',
      '      <span class="n">metric_name</span> <span class="o">=</span> <span class="s2">"accuracy"</span>',
      '      <span class="n">model_name</span> <span class="o">=</span> <span class="s2">"GPT2-small-finetuned-amazon-reviews-en-classification"</span>',
      '      <span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>',
      '      <span class="n">BS_TRAIN</span> <span class="o">=</span> <span class="mi">28</span>',
      '      <span class="n">BS_EVAL</span> <span class="o">=</span> <span class="mi">40</span>',
      '      <span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>',
      '      <span class="n">WEIGHT_DECAY</span> <span class="o">=</span> <span class="mf">0.01</span>',
      '      ',
      '      <span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
      '          <span class="n">model_name</span><span class="p">,</span>',
      '          <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">save_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
      '          <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
      '          <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
      '          <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
      '          <span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
      '          <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">"cosine"</span><span class="p">,</span>',
      '          <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
      '          <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span>',
      '          <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '      <span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>































      
      <section class="section-block-markdown-cell">
      <p>Definimos una m茅trica para el dataloader de validaci贸n</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">del</span> <span class="n">casual_model</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>',
      '      ',
      '      <span class="n">metric_name</span> <span class="o">=</span> <span class="s2">"accuracy"</span>',
      '      <span class="n">model_name</span> <span class="o">=</span> <span class="s2">"GPT2-small-finetuned-amazon-reviews-en-classification"</span>',
      '      <span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>',
      '      <span class="n">BS_TRAIN</span> <span class="o">=</span> <span class="mi">28</span>',
      '      <span class="n">BS_EVAL</span> <span class="o">=</span> <span class="mi">40</span>',
      '      <span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>',
      '      <span class="n">WEIGHT_DECAY</span> <span class="o">=</span> <span class="mf">0.01</span>',
      '      ',
      '      <span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
      '          <span class="n">model_name</span><span class="p">,</span>',
      '          <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">save_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
      '          <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
      '          <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
      '          <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
      '          <span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
      '          <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">"cosine"</span><span class="p">,</span>',
      '          <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
      '          <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span>',
      '          <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>',
      '      <span class="kn">from</span> <span class="nn">evaluate</span> <span class="kn">import</span> <span class="n">load</span>',
      '      ',
      '      <span class="n">metric</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
      '      ',
      '      <span class="k">def</span> <span class="nf">compute_metrics</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">):</span>',
      '          <span class="nb">print</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">)</span>',
      '          <span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">eval_pred</span>',
      '          <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
      '          <span class="k">return</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>















      
      <section class="section-block-markdown-cell">
      <p>Definimos ahora el trainer</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">del</span> <span class="n">casual_model</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>',
      '      ',
      '      <span class="n">metric_name</span> <span class="o">=</span> <span class="s2">"accuracy"</span>',
      '      <span class="n">model_name</span> <span class="o">=</span> <span class="s2">"GPT2-small-finetuned-amazon-reviews-en-classification"</span>',
      '      <span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>',
      '      <span class="n">BS_TRAIN</span> <span class="o">=</span> <span class="mi">28</span>',
      '      <span class="n">BS_EVAL</span> <span class="o">=</span> <span class="mi">40</span>',
      '      <span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>',
      '      <span class="n">WEIGHT_DECAY</span> <span class="o">=</span> <span class="mf">0.01</span>',
      '      ',
      '      <span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
      '          <span class="n">model_name</span><span class="p">,</span>',
      '          <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">save_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
      '          <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
      '          <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
      '          <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
      '          <span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
      '          <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">"cosine"</span><span class="p">,</span>',
      '          <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
      '          <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span>',
      '          <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>',
      '      <span class="kn">from</span> <span class="nn">evaluate</span> <span class="kn">import</span> <span class="n">load</span>',
      '      ',
      '      <span class="n">metric</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
      '      ',
      '      <span class="k">def</span> <span class="nf">compute_metrics</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">):</span>',
      '          <span class="nb">print</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">)</span>',
      '          <span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">eval_pred</span>',
      '          <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
      '          <span class="k">return</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">Trainer</span>',
      '      ',
      '      <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
      '          <span class="n">model</span><span class="p">,</span>',
      '          <span class="n">training_args</span><span class="p">,</span>',
      '          <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">],</span>',
      '          <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'validation\'</span><span class="p">],</span>',
      '          <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
      '          <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>',
      '      <span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>















      
      <section class="section-block-markdown-cell">
      <p>Entrenamos</p>
      </section>
      
      <section class="section-block-code-cell-">
      <div class="input-code">
      <div class="highlight hl-ipython3">
<pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
      </pre></div>
      </div>
      <div class="output-wrapper">
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-text-output-subarea">
      <pre>  0%|          | 0/600000 [00:00&lt;?, ?it/s]</pre>
      </div>
      </div>
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-subarea-output-text-output-error">
      <pre>
      <span class="ansi-red-fg">---------------------------------------------------------------------------</span>
      <span class="ansi-red-fg">ValueError</span>                                Traceback (most recent call last)
      Cell <span class="ansi-green-fg">In[21], line 1</span>
      <span class="ansi-green-fg">----&gt; 1</span> trainer<span style="color: rgb(98,98,98)">.</span>train()
      
      File <span class="ansi-green-fg">~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/trainer.py:1876</span>, in <span class="ansi-cyan-fg">Trainer.train</span><span class="ansi-blue-fg">(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)</span>
      <span class="ansi-green-intense-fg ansi-bold">   1873</span> <span class="ansi-bold" style="color: rgb(0,135,0)">try</span>:
      <span class="ansi-green-intense-fg ansi-bold">   1874</span>     <span style="color: rgb(95,135,135)"># Disable progress bars when uploading models during checkpoints to avoid polluting stdout</span>
      <span class="ansi-green-intense-fg ansi-bold">   1875</span>     hf_hub_utils<span style="color: rgb(98,98,98)">.</span>disable_progress_bars()
      <span class="ansi-green-fg">-&gt; 1876</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> inner_training_loop(
      <span class="ansi-green-intense-fg ansi-bold">   1877</span>         args<span style="color: rgb(98,98,98)">=</span>args,
      <span class="ansi-green-intense-fg ansi-bold">   1878</span>         resume_from_checkpoint<span style="color: rgb(98,98,98)">=</span>resume_from_checkpoint,
      <span class="ansi-green-intense-fg ansi-bold">   1879</span>         trial<span style="color: rgb(98,98,98)">=</span>trial,
      <span class="ansi-green-intense-fg ansi-bold">   1880</span>         ignore_keys_for_eval<span style="color: rgb(98,98,98)">=</span>ignore_keys_for_eval,
      <span class="ansi-green-intense-fg ansi-bold">   1881</span>     )
      <span class="ansi-green-intense-fg ansi-bold">   1882</span> <span class="ansi-bold" style="color: rgb(0,135,0)">finally</span>:
      <span class="ansi-green-intense-fg ansi-bold">   1883</span>     hf_hub_utils<span style="color: rgb(98,98,98)">.</span>enable_progress_bars()
      
      File <span class="ansi-green-fg">~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/trainer.py:2178</span>, in <span class="ansi-cyan-fg">Trainer._inner_training_loop</span><span class="ansi-blue-fg">(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)</span>
      <span class="ansi-green-intense-fg ansi-bold">   2175</span>     rng_to_sync <span style="color: rgb(98,98,98)">=</span> <span class="ansi-bold" style="color: rgb(0,135,0)">True</span>
      <span class="ansi-green-intense-fg ansi-bold">   2177</span> step <span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(98,98,98)">-</span><span style="color: rgb(98,98,98)">1</span>
      <span class="ansi-green-fg">-&gt; 2178</span> <span class="ansi-bold" style="color: rgb(0,135,0)">for</span> step, inputs <span class="ansi-bold" style="color: rgb(175,0,255)">in</span> <span style="color: rgb(0,135,0)">enumerate</span>(epoch_iterator):
      <span class="ansi-green-intense-fg ansi-bold">   2179</span>     total_batched_samples <span style="color: rgb(98,98,98)">+</span><span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(98,98,98)">1</span>
      <span class="ansi-green-intense-fg ansi-bold">   2181</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>args<span style="color: rgb(98,98,98)">.</span>include_num_input_tokens_seen:
      
      File <span class="ansi-green-fg">~/miniconda3/envs/nlp_/lib/python3.11/site-packages/accelerate/data_loader.py:454</span>, in <span class="ansi-cyan-fg">DataLoaderShard.__iter__</span><span class="ansi-blue-fg">(self)</span>
      <span class="ansi-green-intense-fg ansi-bold">    452</span> <span style="color: rgb(95,135,135)"># We iterate one batch ahead to check when we are at the end</span>
      <span class="ansi-green-intense-fg ansi-bold">    453</span> <span class="ansi-bold" style="color: rgb(0,135,0)">try</span>:
      <span class="ansi-green-fg">--&gt; 454</span>     current_batch <span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(0,135,0)">next</span>(dataloader_iter)
      <span class="ansi-green-intense-fg ansi-bold">    455</span> <span class="ansi-bold" style="color: rgb(0,135,0)">except</span> <span class="ansi-bold" style="color: rgb(215,95,95)">StopIteration</span>:
      <span class="ansi-green-intense-fg ansi-bold">    456</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">yield</span>
      
      File <span class="ansi-green-fg">~/miniconda3/envs/nlp_/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631</span>, in <span class="ansi-cyan-fg">_BaseDataLoaderIter.__next__</span><span class="ansi-blue-fg">(self)</span>
      <span class="ansi-green-intense-fg ansi-bold">    628</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_sampler_iter <span class="ansi-bold" style="color: rgb(175,0,255)">is</span> <span class="ansi-bold" style="color: rgb(0,135,0)">None</span>:
      <span class="ansi-green-intense-fg ansi-bold">    629</span>     <span style="color: rgb(95,135,135)"># TODO(https://github.com/pytorch/pytorch/issues/76750)</span>
      <span class="ansi-green-intense-fg ansi-bold">    630</span>     <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_reset()  <span style="color: rgb(95,135,135)"># type: ignore[call-arg]</span>
      <span class="ansi-green-fg">--&gt; 631</span> data <span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_next_data()
      <span class="ansi-green-intense-fg ansi-bold">    632</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_num_yielded <span style="color: rgb(98,98,98)">+</span><span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(98,98,98)">1</span>
      <span class="ansi-green-intense-fg ansi-bold">    633</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_dataset_kind <span style="color: rgb(98,98,98)">==</span> _DatasetKind<span style="color: rgb(98,98,98)">.</span>Iterable <span class="ansi-bold" style="color: rgb(175,0,255)">and</span> \
      <span class="ansi-green-intense-fg ansi-bold">    634</span>         <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_IterableDataset_len_called <span class="ansi-bold" style="color: rgb(175,0,255)">is</span> <span class="ansi-bold" style="color: rgb(175,0,255)">not</span> <span class="ansi-bold" style="color: rgb(0,135,0)">None</span> <span class="ansi-bold" style="color: rgb(175,0,255)">and</span> \
      <span class="ansi-green-intense-fg ansi-bold">    635</span>         <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_num_yielded <span style="color: rgb(98,98,98)">&gt;</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_IterableDataset_len_called:
      
      File <span class="ansi-green-fg">~/miniconda3/envs/nlp_/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675</span>, in <span class="ansi-cyan-fg">_SingleProcessDataLoaderIter._next_data</span><span class="ansi-blue-fg">(self)</span>
      <span class="ansi-green-intense-fg ansi-bold">    673</span> <span class="ansi-bold" style="color: rgb(0,135,0)">def</span> <span style="color: rgb(0,0,255)">_next_data</span>(<span style="color: rgb(0,135,0)">self</span>):
      <span class="ansi-green-intense-fg ansi-bold">    674</span>     index <span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_next_index()  <span style="color: rgb(95,135,135)"># may raise StopIteration</span>
      <span class="ansi-green-fg">--&gt; 675</span>     data <span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_dataset_fetcher<span style="color: rgb(98,98,98)">.</span>fetch(index)  <span style="color: rgb(95,135,135)"># may raise StopIteration</span>
      <span class="ansi-green-intense-fg ansi-bold">    676</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_pin_memory:
      <span class="ansi-green-intense-fg ansi-bold">    677</span>         data <span style="color: rgb(98,98,98)">=</span> _utils<span style="color: rgb(98,98,98)">.</span>pin_memory<span style="color: rgb(98,98,98)">.</span>pin_memory(data, <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_pin_memory_device)
      
      File <span class="ansi-green-fg">~/miniconda3/envs/nlp_/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:54</span>, in <span class="ansi-cyan-fg">_MapDatasetFetcher.fetch</span><span class="ansi-blue-fg">(self, possibly_batched_index)</span>
      <span class="ansi-green-intense-fg ansi-bold">     52</span> <span class="ansi-bold" style="color: rgb(0,135,0)">else</span>:
      <span class="ansi-green-intense-fg ansi-bold">     53</span>     data <span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>dataset[possibly_batched_index]
      <span class="ansi-green-fg">---&gt; 54</span> <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>collate_fn(data)
      
      File <span class="ansi-green-fg">~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/data/data_collator.py:271</span>, in <span class="ansi-cyan-fg">DataCollatorWithPadding.__call__</span><span class="ansi-blue-fg">(self, features)</span>
      <span class="ansi-green-intense-fg ansi-bold">    270</span> <span class="ansi-bold" style="color: rgb(0,135,0)">def</span> <span style="color: rgb(0,0,255)">__call__</span>(<span style="color: rgb(0,135,0)">self</span>, features: List[Dict[<span style="color: rgb(0,135,0)">str</span>, Any]]) <span style="color: rgb(98,98,98)">-</span><span style="color: rgb(98,98,98)">&gt;</span> Dict[<span style="color: rgb(0,135,0)">str</span>, Any]:
      <span class="ansi-green-fg">--&gt; 271</span>     batch <span style="color: rgb(98,98,98)">=</span> pad_without_fast_tokenizer_warning(
      <span class="ansi-green-intense-fg ansi-bold">    272</span>         <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>tokenizer,
      <span class="ansi-green-intense-fg ansi-bold">    273</span>         features,
      <span class="ansi-green-intense-fg ansi-bold">    274</span>         padding<span style="color: rgb(98,98,98)">=</span><span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>padding,
      <span class="ansi-green-intense-fg ansi-bold">    275</span>         max_length<span style="color: rgb(98,98,98)">=</span><span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>max_length,
      <span class="ansi-green-intense-fg ansi-bold">    276</span>         pad_to_multiple_of<span style="color: rgb(98,98,98)">=</span><span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>pad_to_multiple_of,
      <span class="ansi-green-intense-fg ansi-bold">    277</span>         return_tensors<span style="color: rgb(98,98,98)">=</span><span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>return_tensors,
      <span class="ansi-green-intense-fg ansi-bold">    278</span>     )
      <span class="ansi-green-intense-fg ansi-bold">    279</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> <span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">label</span><span style="color: rgb(175,0,0)">"</span> <span class="ansi-bold" style="color: rgb(175,0,255)">in</span> batch:
      <span class="ansi-green-intense-fg ansi-bold">    280</span>         batch[<span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">labels</span><span style="color: rgb(175,0,0)">"</span>] <span style="color: rgb(98,98,98)">=</span> batch[<span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">label</span><span style="color: rgb(175,0,0)">"</span>]
      
      File <span class="ansi-green-fg">~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/data/data_collator.py:66</span>, in <span class="ansi-cyan-fg">pad_without_fast_tokenizer_warning</span><span class="ansi-blue-fg">(tokenizer, *pad_args, **pad_kwargs)</span>
      <span class="ansi-green-intense-fg ansi-bold">     63</span> tokenizer<span style="color: rgb(98,98,98)">.</span>deprecation_warnings[<span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">Asking-to-pad-a-fast-tokenizer</span><span style="color: rgb(175,0,0)">"</span>] <span style="color: rgb(98,98,98)">=</span> <span class="ansi-bold" style="color: rgb(0,135,0)">True</span>
      <span class="ansi-green-intense-fg ansi-bold">     65</span> <span class="ansi-bold" style="color: rgb(0,135,0)">try</span>:
      <span class="ansi-green-fg">---&gt; 66</span>     padded <span style="color: rgb(98,98,98)">=</span> tokenizer<span style="color: rgb(98,98,98)">.</span>pad(<span style="color: rgb(98,98,98)">*</span>pad_args, <span style="color: rgb(98,98,98)">*</span><span style="color: rgb(98,98,98)">*</span>pad_kwargs)
      <span class="ansi-green-intense-fg ansi-bold">     67</span> <span class="ansi-bold" style="color: rgb(0,135,0)">finally</span>:
      <span class="ansi-green-intense-fg ansi-bold">     68</span>     <span style="color: rgb(95,135,135)"># Restore the state of the warning.</span>
      <span class="ansi-green-intense-fg ansi-bold">     69</span>     tokenizer<span style="color: rgb(98,98,98)">.</span>deprecation_warnings[<span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">Asking-to-pad-a-fast-tokenizer</span><span style="color: rgb(175,0,0)">"</span>] <span style="color: rgb(98,98,98)">=</span> warning_state
      
      File <span class="ansi-green-fg">~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3299</span>, in <span class="ansi-cyan-fg">PreTrainedTokenizerBase.pad</span><span class="ansi-blue-fg">(self, encoded_inputs, padding, max_length, pad_to_multiple_of, return_attention_mask, return_tensors, verbose)</span>
      <span class="ansi-green-intense-fg ansi-bold">   3297</span> <span style="color: rgb(95,135,135)"># The model's main input name, usually `input_ids`, has be passed for padding</span>
      <span class="ansi-green-intense-fg ansi-bold">   3298</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>model_input_names[<span style="color: rgb(98,98,98)">0</span>] <span class="ansi-bold" style="color: rgb(175,0,255)">not</span> <span class="ansi-bold" style="color: rgb(175,0,255)">in</span> encoded_inputs:
      <span class="ansi-green-fg">-&gt; 3299</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">raise</span> <span class="ansi-bold" style="color: rgb(215,95,95)">ValueError</span>(
      <span class="ansi-green-intense-fg ansi-bold">   3300</span>         <span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">You should supply an encoding or a list of encodings to this method </span><span style="color: rgb(175,0,0)">"</span>
      <span class="ansi-green-intense-fg ansi-bold">   3301</span>         <span style="color: rgb(175,0,0)">f</span><span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">that includes </span><span class="ansi-bold" style="color: rgb(175,95,135)">{opening_brace}</span><span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>model_input_names[<span style="color: rgb(98,98,98)">0</span>]<span class="ansi-bold" style="color: rgb(175,95,135)">{closing_brace}</span><span style="color: rgb(175,0,0)">, but you provided </span><span class="ansi-bold" style="color: rgb(175,95,135)">{opening_brace}</span><span style="color: rgb(0,135,0)">list</span>(encoded_inputs<span style="color: rgb(98,98,98)">.</span>keys())<span class="ansi-bold" style="color: rgb(175,95,135)">{closing_brace}</span><span style="color: rgb(175,0,0)">"</span>
      <span class="ansi-green-intense-fg ansi-bold">   3302</span>     )
      <span class="ansi-green-intense-fg ansi-bold">   3304</span> required_input <span style="color: rgb(98,98,98)">=</span> encoded_inputs[<span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>model_input_names[<span style="color: rgb(98,98,98)">0</span>]]
      <span class="ansi-green-intense-fg ansi-bold">   3306</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> required_input <span class="ansi-bold" style="color: rgb(175,0,255)">is</span> <span class="ansi-bold" style="color: rgb(0,135,0)">None</span> <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> (<span style="color: rgb(0,135,0)">isinstance</span>(required_input, Sized) <span class="ansi-bold" style="color: rgb(175,0,255)">and</span> <span style="color: rgb(0,135,0)">len</span>(required_input) <span style="color: rgb(98,98,98)">==</span> <span style="color: rgb(98,98,98)">0</span>):
      
      <span class="ansi-red-fg">ValueError</span>: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided ['label', 'labels']</pre>
      </div>
      </div>
      </div>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Nos vuelve a salir un error porque el modelo no tiene asignado un token de padding, as铆 que al igual que con el tokenizador se lo asignamos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">del</span> <span class="n">casual_model</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>',
      '      ',
      '      <span class="n">metric_name</span> <span class="o">=</span> <span class="s2">"accuracy"</span>',
      '      <span class="n">model_name</span> <span class="o">=</span> <span class="s2">"GPT2-small-finetuned-amazon-reviews-en-classification"</span>',
      '      <span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>',
      '      <span class="n">BS_TRAIN</span> <span class="o">=</span> <span class="mi">28</span>',
      '      <span class="n">BS_EVAL</span> <span class="o">=</span> <span class="mi">40</span>',
      '      <span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>',
      '      <span class="n">WEIGHT_DECAY</span> <span class="o">=</span> <span class="mf">0.01</span>',
      '      ',
      '      <span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
      '          <span class="n">model_name</span><span class="p">,</span>',
      '          <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">save_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
      '          <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
      '          <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
      '          <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
      '          <span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
      '          <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">"cosine"</span><span class="p">,</span>',
      '          <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
      '          <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span>',
      '          <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>',
      '      <span class="kn">from</span> <span class="nn">evaluate</span> <span class="kn">import</span> <span class="n">load</span>',
      '      ',
      '      <span class="n">metric</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
      '      ',
      '      <span class="k">def</span> <span class="nf">compute_metrics</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">):</span>',
      '          <span class="nb">print</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">)</span>',
      '          <span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">eval_pred</span>',
      '          <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
      '          <span class="k">return</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">Trainer</span>',
      '      ',
      '      <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
      '          <span class="n">model</span><span class="p">,</span>',
      '          <span class="n">training_args</span><span class="p">,</span>',
      '          <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">],</span>',
      '          <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'validation\'</span><span class="p">],</span>',
      '          <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
      '          <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span></span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>






      
      <section class="section-block-markdown-cell">
      <p>Volvemos a crear los argumentos del trainer con el nuevo modelo, que ahora si tiene token de padding, el trainer y volvemos a entrenar</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">del</span> <span class="n">casual_model</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>',
      '      ',
      '      <span class="n">metric_name</span> <span class="o">=</span> <span class="s2">"accuracy"</span>',
      '      <span class="n">model_name</span> <span class="o">=</span> <span class="s2">"GPT2-small-finetuned-amazon-reviews-en-classification"</span>',
      '      <span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>',
      '      <span class="n">BS_TRAIN</span> <span class="o">=</span> <span class="mi">28</span>',
      '      <span class="n">BS_EVAL</span> <span class="o">=</span> <span class="mi">40</span>',
      '      <span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>',
      '      <span class="n">WEIGHT_DECAY</span> <span class="o">=</span> <span class="mf">0.01</span>',
      '      ',
      '      <span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
      '          <span class="n">model_name</span><span class="p">,</span>',
      '          <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">save_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
      '          <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
      '          <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
      '          <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
      '          <span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
      '          <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">"cosine"</span><span class="p">,</span>',
      '          <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
      '          <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span>',
      '          <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>',
      '      <span class="kn">from</span> <span class="nn">evaluate</span> <span class="kn">import</span> <span class="n">load</span>',
      '      ',
      '      <span class="n">metric</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
      '      ',
      '      <span class="k">def</span> <span class="nf">compute_metrics</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">):</span>',
      '          <span class="nb">print</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">)</span>',
      '          <span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">eval_pred</span>',
      '          <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
      '          <span class="k">return</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">Trainer</span>',
      '      ',
      '      <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
      '          <span class="n">model</span><span class="p">,</span>',
      '          <span class="n">training_args</span><span class="p">,</span>',
      '          <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">],</span>',
      '          <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'validation\'</span><span class="p">],</span>',
      '          <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
      '          <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span></span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>',
      '<span></span><span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
      '          <span class="n">model_name</span><span class="p">,</span>',
      '          <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">save_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
      '          <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
      '          <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
      '          <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
      '          <span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
      '          <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">"cosine"</span><span class="p">,</span>',
      '          <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
      '          <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span>',
      '          <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">logging_dir</span><span class="o">=</span><span class="s2">"./runs"</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '      ',
      '      <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
      '          <span class="n">model</span><span class="p">,</span>',
      '          <span class="n">training_args</span><span class="p">,</span>',
      '          <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">],</span>',
      '          <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'validation\'</span><span class="p">],</span>',
      '          <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
      '          <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>',
      '      <span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>































      
      <section class="section-block-markdown-cell">
      <p>Ahora que hemos visto que est谩 todo bien podemos entrenar</p>
      </section>
      
      <section class="section-block-code-cell-">
      <div class="input-code">
      <div class="highlight hl-ipython3">
<pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
      </pre></div>
      </div>
      <div class="output-wrapper">
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-html-rendered-html-output-subarea">
      <div>
      <progress max="21429" style="width:300px; height:20px; vertical-align: middle;" value="2250"></progress>
            [ 2250/21429 45:38 &lt; 6:29:27, 0.82 it/s, Epoch 0.31/3]
          </div>
      <table border="1" class="dataframe">
      <thead>
      <tr style="text-align: left;">
      <th>Epoch</th>
      <th>Training Loss</th>
      <th>Validation Loss</th>
      </tr>
      </thead>
      <tbody>
      </tbody>
      </table><p></p></div>
      </div>
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-html-rendered-html-output-subarea">
      <div>
      <progress max="21429" style="width:300px; height:20px; vertical-align: middle;" value="21429"></progress>
            [21429/21429 7:19:25, Epoch 3/3]
          </div>
      <table border="1" class="dataframe">
      <thead>
      <tr style="text-align: left;">
      <th>Epoch</th>
      <th>Training Loss</th>
      <th>Validation Loss</th>
      <th>Accuracy</th>
      </tr>
      </thead>
      <tbody>
      <tr>
      <td>1</td>
      <td>0.807400</td>
      <td>0.820341</td>
      <td>0.652000</td>
      </tr>
      <tr>
      <td>2</td>
      <td>0.751900</td>
      <td>0.802189</td>
      <td>0.654600</td>
      </tr>
      <tr>
      <td>3</td>
      <td>0.718100</td>
      <td>0.810221</td>
      <td>0.657800</td>
      </tr>
      </tbody>
      </table><p></p></div>
      </div>
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-subarea-output-stream-output-stdout-output-text">
      <pre>&lt;transformers.trainer_utils.EvalPrediction object at 0x782767ea1450&gt;
      &lt;transformers.trainer_utils.EvalPrediction object at 0x782767eeefe0&gt;
      &lt;transformers.trainer_utils.EvalPrediction object at 0x782767eecfd0&gt;
      </pre>
      </div>
      </div>
      <div class="output-area">
      <div class="prompt-output-prompt">Out[28]:</div>
      <div class="output-text-output-subareaoutput_execute_result">
      <pre>TrainOutput(global_step=21429, training_loss=0.7846888848762739, metrics={opening_brace}'train_runtime': 26367.7801, 'train_samples_per_second': 22.755, 'train_steps_per_second': 0.813, 'total_flos': 2.35173445632e+17, 'train_loss': 0.7846888848762739, 'epoch': 3.0{closing_brace})</pre>
      </div>
      </div>
      </div>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Evaluaci%C3%B3n">Evaluaci贸n<a class="anchor-link" href="#Evaluaci%C3%B3n"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 7" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Una vez entrenado evaluamos sobre el dataset de test</p>
      </section>
      
      <section class="section-block-code-cell-">
      <div class="input-code">
      <div class="highlight hl-ipython3">
<pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">'test'</span><span class="p">])</span>
      </pre></div>
      </div>
      <div class="output-wrapper">
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-html-rendered-html-output-subarea">
      <div>
      <progress max="125" style="width:300px; height:20px; vertical-align: middle;" value="125"></progress>
            [125/125 01:15]
          </div>
      </div>
      </div>
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-subarea-output-stream-output-stdout-output-text">
      <pre>&lt;transformers.trainer_utils.EvalPrediction object at 0x7826ddfded40&gt;
      </pre>
      </div>
      </div>
      <div class="output-area">
      <div class="prompt-output-prompt">Out[29]:</div>
      <div class="output-text-output-subareaoutput_execute_result">
      <pre>{opening_brace}'eval_loss': 0.7973636984825134,
       'eval_accuracy': 0.6626,
       'eval_runtime': 76.3016,
       'eval_samples_per_second': 65.529,
       'eval_steps_per_second': 1.638,
       'epoch': 3.0}</pre>
      </div>
      </div>
      </div>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Publicar-el-modelo">Publicar el modelo<a class="anchor-link" href="#Publicar-el-modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 8" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Ya tenemos nuestro modelo entrenado, ya podemos compartirlo con el mundo, as铆 que primero creamos una model card</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">del</span> <span class="n">casual_model</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>',
      '      ',
      '      <span class="n">metric_name</span> <span class="o">=</span> <span class="s2">"accuracy"</span>',
      '      <span class="n">model_name</span> <span class="o">=</span> <span class="s2">"GPT2-small-finetuned-amazon-reviews-en-classification"</span>',
      '      <span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>',
      '      <span class="n">BS_TRAIN</span> <span class="o">=</span> <span class="mi">28</span>',
      '      <span class="n">BS_EVAL</span> <span class="o">=</span> <span class="mi">40</span>',
      '      <span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>',
      '      <span class="n">WEIGHT_DECAY</span> <span class="o">=</span> <span class="mf">0.01</span>',
      '      ',
      '      <span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
      '          <span class="n">model_name</span><span class="p">,</span>',
      '          <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">save_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
      '          <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
      '          <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
      '          <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
      '          <span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
      '          <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">"cosine"</span><span class="p">,</span>',
      '          <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
      '          <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span>',
      '          <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>',
      '      <span class="kn">from</span> <span class="nn">evaluate</span> <span class="kn">import</span> <span class="n">load</span>',
      '      ',
      '      <span class="n">metric</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
      '      ',
      '      <span class="k">def</span> <span class="nf">compute_metrics</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">):</span>',
      '          <span class="nb">print</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">)</span>',
      '          <span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">eval_pred</span>',
      '          <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
      '          <span class="k">return</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">Trainer</span>',
      '      ',
      '      <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
      '          <span class="n">model</span><span class="p">,</span>',
      '          <span class="n">training_args</span><span class="p">,</span>',
      '          <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">],</span>',
      '          <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'validation\'</span><span class="p">],</span>',
      '          <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
      '          <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span></span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>',
      '<span></span><span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
      '          <span class="n">model_name</span><span class="p">,</span>',
      '          <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">save_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
      '          <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
      '          <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
      '          <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
      '          <span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
      '          <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">"cosine"</span><span class="p">,</span>',
      '          <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
      '          <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span>',
      '          <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">logging_dir</span><span class="o">=</span><span class="s2">"./runs"</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '      ',
      '      <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
      '          <span class="n">model</span><span class="p">,</span>',
      '          <span class="n">training_args</span><span class="p">,</span>',
      '          <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">],</span>',
      '          <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'validation\'</span><span class="p">],</span>',
      '          <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
      '          <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'test\'</span><span class="p">])</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">create_model_card</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>






      
      <section class="section-block-markdown-cell">
      <p>Y ya lo podemos publicar. Como lo primero que hemos hecho ha sido loguearnos con el hub de huggingface, lo podremos subir a nuestro hub sin ning煤n problema</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">del</span> <span class="n">casual_model</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>',
      '      ',
      '      <span class="n">metric_name</span> <span class="o">=</span> <span class="s2">"accuracy"</span>',
      '      <span class="n">model_name</span> <span class="o">=</span> <span class="s2">"GPT2-small-finetuned-amazon-reviews-en-classification"</span>',
      '      <span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>',
      '      <span class="n">BS_TRAIN</span> <span class="o">=</span> <span class="mi">28</span>',
      '      <span class="n">BS_EVAL</span> <span class="o">=</span> <span class="mi">40</span>',
      '      <span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>',
      '      <span class="n">WEIGHT_DECAY</span> <span class="o">=</span> <span class="mf">0.01</span>',
      '      ',
      '      <span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
      '          <span class="n">model_name</span><span class="p">,</span>',
      '          <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">save_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
      '          <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
      '          <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
      '          <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
      '          <span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
      '          <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">"cosine"</span><span class="p">,</span>',
      '          <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
      '          <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span>',
      '          <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>',
      '      <span class="kn">from</span> <span class="nn">evaluate</span> <span class="kn">import</span> <span class="n">load</span>',
      '      ',
      '      <span class="n">metric</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
      '      ',
      '      <span class="k">def</span> <span class="nf">compute_metrics</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">):</span>',
      '          <span class="nb">print</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">)</span>',
      '          <span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">eval_pred</span>',
      '          <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
      '          <span class="k">return</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">Trainer</span>',
      '      ',
      '      <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
      '          <span class="n">model</span><span class="p">,</span>',
      '          <span class="n">training_args</span><span class="p">,</span>',
      '          <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">],</span>',
      '          <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'validation\'</span><span class="p">],</span>',
      '          <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
      '          <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span></span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>',
      '<span></span><span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
      '          <span class="n">model_name</span><span class="p">,</span>',
      '          <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">save_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
      '          <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
      '          <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
      '          <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
      '          <span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
      '          <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">"cosine"</span><span class="p">,</span>',
      '          <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
      '          <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span>',
      '          <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">logging_dir</span><span class="o">=</span><span class="s2">"./runs"</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '      ',
      '      <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
      '          <span class="n">model</span><span class="p">,</span>',
      '          <span class="n">training_args</span><span class="p">,</span>',
      '          <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">],</span>',
      '          <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'validation\'</span><span class="p">],</span>',
      '          <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
      '          <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'test\'</span><span class="p">])</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">create_model_card</span><span class="p">()</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">push_to_hub</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>






      
      <section class="section-block-markdown-cell">
      <h3 id="Uso-del-modelo">Uso del modelo<a class="anchor-link" href="#Uso-del-modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 9" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Limpiamos todo lo posible</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">del</span> <span class="n">casual_model</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>',
      '      ',
      '      <span class="n">metric_name</span> <span class="o">=</span> <span class="s2">"accuracy"</span>',
      '      <span class="n">model_name</span> <span class="o">=</span> <span class="s2">"GPT2-small-finetuned-amazon-reviews-en-classification"</span>',
      '      <span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>',
      '      <span class="n">BS_TRAIN</span> <span class="o">=</span> <span class="mi">28</span>',
      '      <span class="n">BS_EVAL</span> <span class="o">=</span> <span class="mi">40</span>',
      '      <span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>',
      '      <span class="n">WEIGHT_DECAY</span> <span class="o">=</span> <span class="mf">0.01</span>',
      '      ',
      '      <span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
      '          <span class="n">model_name</span><span class="p">,</span>',
      '          <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">save_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
      '          <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
      '          <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
      '          <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
      '          <span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
      '          <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">"cosine"</span><span class="p">,</span>',
      '          <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
      '          <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span>',
      '          <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>',
      '      <span class="kn">from</span> <span class="nn">evaluate</span> <span class="kn">import</span> <span class="n">load</span>',
      '      ',
      '      <span class="n">metric</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
      '      ',
      '      <span class="k">def</span> <span class="nf">compute_metrics</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">):</span>',
      '          <span class="nb">print</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">)</span>',
      '          <span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">eval_pred</span>',
      '          <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
      '          <span class="k">return</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">Trainer</span>',
      '      ',
      '      <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
      '          <span class="n">model</span><span class="p">,</span>',
      '          <span class="n">training_args</span><span class="p">,</span>',
      '          <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">],</span>',
      '          <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'validation\'</span><span class="p">],</span>',
      '          <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
      '          <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span></span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>',
      '<span></span><span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
      '          <span class="n">model_name</span><span class="p">,</span>',
      '          <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">save_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
      '          <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
      '          <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
      '          <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
      '          <span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
      '          <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">"cosine"</span><span class="p">,</span>',
      '          <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
      '          <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span>',
      '          <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">logging_dir</span><span class="o">=</span><span class="s2">"./runs"</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '      ',
      '      <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
      '          <span class="n">model</span><span class="p">,</span>',
      '          <span class="n">training_args</span><span class="p">,</span>',
      '          <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">],</span>',
      '          <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'validation\'</span><span class="p">],</span>',
      '          <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
      '          <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'test\'</span><span class="p">])</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">create_model_card</span><span class="p">()</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">push_to_hub</span><span class="p">()</span>',
      '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
      '      <span class="kn">import</span> <span class="nn">gc</span>',
      '      ',
      '      ',
      '      <span class="k">def</span> <span class="nf">clear_hardwares</span><span class="p">():</span>',
      '          <span class="n">torch</span><span class="o">.</span><span class="n">clear_autocast_cache</span><span class="p">()</span>',
      '          <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">ipc_collect</span><span class="p">()</span>',
      '          <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>',
      '          <span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>',
      '      ',
      '      ',
      '      <span class="n">clear_hardwares</span><span class="p">()</span>',
      '      <span class="n">clear_hardwares</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>


















      
      <section class="section-block-markdown-cell">
      <p>Como hemos subido el modelo a nuestro hub podemos descargarlo y usarlo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">del</span> <span class="n">casual_model</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>',
      '      ',
      '      <span class="n">metric_name</span> <span class="o">=</span> <span class="s2">"accuracy"</span>',
      '      <span class="n">model_name</span> <span class="o">=</span> <span class="s2">"GPT2-small-finetuned-amazon-reviews-en-classification"</span>',
      '      <span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>',
      '      <span class="n">BS_TRAIN</span> <span class="o">=</span> <span class="mi">28</span>',
      '      <span class="n">BS_EVAL</span> <span class="o">=</span> <span class="mi">40</span>',
      '      <span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>',
      '      <span class="n">WEIGHT_DECAY</span> <span class="o">=</span> <span class="mf">0.01</span>',
      '      ',
      '      <span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
      '          <span class="n">model_name</span><span class="p">,</span>',
      '          <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">save_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
      '          <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
      '          <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
      '          <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
      '          <span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
      '          <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">"cosine"</span><span class="p">,</span>',
      '          <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
      '          <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span>',
      '          <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>',
      '      <span class="kn">from</span> <span class="nn">evaluate</span> <span class="kn">import</span> <span class="n">load</span>',
      '      ',
      '      <span class="n">metric</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
      '      ',
      '      <span class="k">def</span> <span class="nf">compute_metrics</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">):</span>',
      '          <span class="nb">print</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">)</span>',
      '          <span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">eval_pred</span>',
      '          <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
      '          <span class="k">return</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">Trainer</span>',
      '      ',
      '      <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
      '          <span class="n">model</span><span class="p">,</span>',
      '          <span class="n">training_args</span><span class="p">,</span>',
      '          <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">],</span>',
      '          <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'validation\'</span><span class="p">],</span>',
      '          <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
      '          <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span></span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>',
      '<span></span><span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
      '          <span class="n">model_name</span><span class="p">,</span>',
      '          <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">save_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
      '          <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
      '          <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
      '          <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
      '          <span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
      '          <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">"cosine"</span><span class="p">,</span>',
      '          <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
      '          <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span>',
      '          <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">logging_dir</span><span class="o">=</span><span class="s2">"./runs"</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '      ',
      '      <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
      '          <span class="n">model</span><span class="p">,</span>',
      '          <span class="n">training_args</span><span class="p">,</span>',
      '          <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">],</span>',
      '          <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'validation\'</span><span class="p">],</span>',
      '          <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
      '          <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'test\'</span><span class="p">])</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">create_model_card</span><span class="p">()</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">push_to_hub</span><span class="p">()</span>',
      '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
      '      <span class="kn">import</span> <span class="nn">gc</span>',
      '      ',
      '      ',
      '      <span class="k">def</span> <span class="nf">clear_hardwares</span><span class="p">():</span>',
      '          <span class="n">torch</span><span class="o">.</span><span class="n">clear_autocast_cache</span><span class="p">()</span>',
      '          <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">ipc_collect</span><span class="p">()</span>',
      '          <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>',
      '          <span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>',
      '      ',
      '      ',
      '      <span class="n">clear_hardwares</span><span class="p">()</span>',
      '      <span class="n">clear_hardwares</span><span class="p">()</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">pipeline</span>',
      '      ',
      '      <span class="n">user</span> <span class="o">=</span> <span class="s2">"maximofn"</span>',
      '      <span class="n">checkpoints</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">user</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">"</span>',
      '      <span class="n">task</span> <span class="o">=</span> <span class="s2">"text-classification"</span>',
      '      <span class="n">classifier</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">checkpoints</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">checkpoints</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>











      
      <section class="section-block-markdown-cell">
      <p>Ahora si queremos que nos devuelva la probabilidad de todas las clases, simplemente usamos el clasificador que acabamos de instanciar, con el par谩metro <code>top_k=None</code></p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="k">del</span> <span class="n">casual_model</span>',
          '</span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>',
          '',
          '<span class="n">metric_name</span> <span class="o">=</span> <span class="s2">"accuracy"</span>',
          '<span class="n">model_name</span> <span class="o">=</span> <span class="s2">"GPT2-small-finetuned-amazon-reviews-en-classification"</span>',
          '<span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>',
          '<span class="n">BS_TRAIN</span> <span class="o">=</span> <span class="mi">28</span>',
          '<span class="n">BS_EVAL</span> <span class="o">=</span> <span class="mi">40</span>',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>',
          '<span class="n">WEIGHT_DECAY</span> <span class="o">=</span> <span class="mf">0.01</span>',
          '',
          '<span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
          '    <span class="n">model_name</span><span class="p">,</span>',
          '    <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
          '    <span class="n">save_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
          '    <span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
          '    <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
          '    <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
          '    <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
          '    <span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
          '    <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">"cosine"</span><span class="p">,</span>',
          '    <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
          '    <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
          '    <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
          '    <span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span>',
          '    <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
          '<span class="p">)</span>',
          '</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>',
          '<span class="kn">from</span> <span class="nn">evaluate</span> <span class="kn">import</span> <span class="n">load</span>',
          '',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">compute_metrics</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">)</span>',
          '    <span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">eval_pred</span>',
          '    <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
          '    <span class="k">return</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '</span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">Trainer</span>',
          '',
          '<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
          '    <span class="n">model</span><span class="p">,</span>',
          '    <span class="n">training_args</span><span class="p">,</span>',
          '    <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">],</span>',
          '    <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'validation\'</span><span class="p">],</span>',
          '    <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
          '    <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>',
          '<span class="p">)</span>',
          '</span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>',
          '</span><span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
          '    <span class="n">model_name</span><span class="p">,</span>',
          '    <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
          '    <span class="n">save_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
          '    <span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
          '    <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
          '    <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
          '    <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
          '    <span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
          '    <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">"cosine"</span><span class="p">,</span>',
          '    <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
          '    <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
          '    <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
          '    <span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span>',
          '    <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
          '    <span class="n">logging_dir</span><span class="o">=</span><span class="s2">"./runs"</span><span class="p">,</span>',
          '<span class="p">)</span>',
          '',
          '<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
          '    <span class="n">model</span><span class="p">,</span>',
          '    <span class="n">training_args</span><span class="p">,</span>',
          '    <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">],</span>',
          '    <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'validation\'</span><span class="p">],</span>',
          '    <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
          '    <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>',
          '<span class="p">)</span>',
          '</span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '</span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'test\'</span><span class="p">])</span>',
          '</span><span class="n">trainer</span><span class="o">.</span><span class="n">create_model_card</span><span class="p">()</span>',
          '</span><span class="n">trainer</span><span class="o">.</span><span class="n">push_to_hub</span><span class="p">()</span>',
          '</span><span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">import</span> <span class="nn">gc</span>',
          '',
          '',
          '<span class="k">def</span> <span class="nf">clear_hardwares</span><span class="p">():</span>',
          '    <span class="n">torch</span><span class="o">.</span><span class="n">clear_autocast_cache</span><span class="p">()</span>',
          '    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">ipc_collect</span><span class="p">()</span>',
          '    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>',
          '    <span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>',
          '',
          '',
          '<span class="n">clear_hardwares</span><span class="p">()</span>',
          '<span class="n">clear_hardwares</span><span class="p">()</span>',
          '</span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">pipeline</span>',
          '',
          '<span class="n">user</span> <span class="o">=</span> <span class="s2">"maximofn"</span>',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">user</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">"</span>',
          '<span class="n">task</span> <span class="o">=</span> <span class="s2">"text-classification"</span>',
          '<span class="n">classifier</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">checkpoints</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">checkpoints</span><span class="p">)</span>',
          '</span><span class="n">labels</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="s2">"I love this product"</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>',
          '<span class="n">labels</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '  0%|          | 0/600000 [00:00&lt;?, ?it/s]',
          '[{\'label\': \'LABEL_4\', \'score\': 0.8253807425498962},',
          ' {\'label\': \'LABEL_3\', \'score\': 0.15411493182182312},',
          ' {\'label\': \'LABEL_2\', \'score\': 0.013907806016504765},',
          ' {\'label\': \'LABEL_0\', \'score\': 0.003939222544431686},',
          ' {\'label\': \'LABEL_1\', \'score\': 0.0026572425849735737}]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Si solo queremos la clase con la mayor probabilidad hacemos lo mismo pero con el par谩metro <code>top_k=1</code></p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">label</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="s2">"I love this product"</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
          '<span class="n">label</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '[{\'label\': \'LABEL_4\', \'score\': 0.8253807425498962}]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Y si queremos n clases hacemos lo mismo pero con el par谩metro <code>top_k=n</code></p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">two_labels</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="s2">"I love this product"</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>',
          '<span class="n">two_labels</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '[{\'label\': \'LABEL_4\', \'score\': 0.8253807425498962},',
          ' {\'label\': \'LABEL_3\', \'score\': 0.15411493182182312}]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Tambi茅n podemo probar el modelo con Automodel y AutoTokenizer</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
      '      <span class="kn">import</span> <span class="nn">torch</span>',
      '      ',
      '      <span class="n">model_name</span> <span class="o">=</span> <span class="s2">"GPT2-small-finetuned-amazon-reviews-en-classification"</span>',
      '      <span class="n">user</span> <span class="o">=</span> <span class="s2">"maximofn"</span>',
      '      <span class="n">checkpoint</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">user</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">"</span>',
      '      <span class="n">num_classes</span> <span class="o">=</span> <span class="mi">5</span>',
      '      ',
      '      <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>',
      '      <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="n">num_classes</span><span class="p">)</span><span class="o">.</span><span class="n">half</span><span class="p">()</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">"cuda"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>















      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '',
          '<span class="n">model_name</span> <span class="o">=</span> <span class="s2">"GPT2-small-finetuned-amazon-reviews-en-classification"</span>',
          '<span class="n">user</span> <span class="o">=</span> <span class="s2">"maximofn"</span>',
          '<span class="n">checkpoint</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">user</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">"</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">5</span>',
          '',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="n">num_classes</span><span class="p">)</span><span class="o">.</span><span class="n">half</span><span class="p">()</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">"cuda"</span><span class="p">)</span>',
          '</span><span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">"I love this product"</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>',
          '<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>',
          '<span class="n">logits</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">logits</span>',
          '<span class="n">lables</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>',
          '<span class="n">lables</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '[0.003963470458984375,',
          ' 0.0026721954345703125,',
          ' 0.01397705078125,',
          ' 0.154541015625,',
          ' 0.82470703125]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Si quires probar m谩s el modelo puedes verlo en <a href="https://huggingface.co/Maximofn/GPT2-small-finetuned-amazon-reviews-en-classification" target="_blank" rel="nofollow noreferrer">Maximofn/GPT2-small-finetuned-amazon-reviews-en-classification</a></p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Fine-tuning-para-generaci%C3%B3n-de-texto-con-Hugging-Face">Fine tuning para generaci贸n de texto con Hugging Face<a class="anchor-link" href="#Fine-tuning-para-generaci%C3%B3n-de-texto-con-Hugging-Face"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 10" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Para asegurarme no tener problemas de memoria VRAM reinicio el notebook</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Login">Login<a class="anchor-link" href="#Login"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 11" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Para poder subir el resultado del entrenamiento al hub debemos logearnos primero, para ello necesitamos un token</p>
      <p>Para crear un token hay que ir a la p谩gina de <a href="https://huggingface.co/settings/tokens" target="_blank" rel="nofollow noreferrer">setings/tokens</a> de nuestra cuenta, nos aparecer谩 algo as铆</p>
      <p><img decoding="async" onerror="this.parentNode.removeChild(this)" alt="User-Access-Token-dark" src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/User-Access-Token-dark.webp" width="1200" height="615"/></p>
      <p>Le damos a <code>New token</code> y nos aparecer谩 una ventana para crear un nuevo token</p>
      <p><img decoding="async" onerror="this.parentNode.removeChild(this)" alt="new-token-dark" src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/new-token-dark.webp" width="1200" height="660"/></p>
      <p>Le damos un nombre al token y lo creamos con el rol <code>write</code>, o con el rol <code>Fine-grained</code>, que nos permite seleccionar exactamente qu茅 permisos tendr谩 el token</p>
      <p>Una vez creado lo copiamos y lo pegamos a continuaci贸n</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">huggingface_hub</span> <span class="kn">import</span> <span class="n">notebook_login</span>',
      '      <span class="n">notebook_login</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>







      
      <section class="section-block-markdown-cell">
      <h3 id="Dataset">Dataset<a class="anchor-link" href="#Dataset"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 12" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a usar un dataset de <a href="https://huggingface.co/datasets/Maximofn/short-jokes-dataset" target="_blank" rel="nofollow noreferrer">chistes en ingl茅s</a></p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">huggingface_hub</span> <span class="kn">import</span> <span class="n">notebook_login</span>',
          '<span class="n">notebook_login</span><span class="p">()</span>',
          '</span><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '',
          '<span class="n">jokes</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"Maximofn/short-jokes-dataset"</span><span class="p">)</span>',
          '<span class="n">jokes</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'DatasetDict({',
          '    train: Dataset({',
          '        features: [\'ID\', \'Joke\'],',
          '        num_rows: 231657',
          '    })',
          '})',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a verlo un poco</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">jokes</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'DatasetDict({',
          '    train: Dataset({',
          '        features: [\'ID\', \'Joke\'],',
          '        num_rows: 231657',
          '    })',
          '})',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos que es un 煤nico set de entrenamiento de m谩s de 200 mil chistes. As铆 que m谩s adelante lo tendremos que dividir en train y evaluaci贸n</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a ver una muestra</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">random</span> <span class="kn">import</span> <span class="n">randint</span>',
          '',
          '<span class="n">idx</span> <span class="o">=</span> <span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">jokes</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>',
          '<span class="n">jokes</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '{\'ID\': 198387,',
          ' \'Joke\': \'My hot dislexic co-worker said she had an important massage to give me in her office... When I got there, she told me it can wait until I put on some clothes.\'}',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos que tiene una ID del chiste que no nos interesa para nada y el propio chiste</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Por si tienes poca memoria en la GPU voy a hacer un subset del dataset, elije el porcentaje de chistes que quieres usar</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">percent_of_train_dataset</span> <span class="o">=</span> <span class="mi">1</span>    <span class="c1"># If you want 50% of the dataset, set this to 0.5</span>',
          '',
          '<span class="n">subset_dataset</span> <span class="o">=</span> <span class="n">jokes</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">jokes</span><span class="p">[</span><span class="s2">"train"</span><span class="p">])</span> <span class="o">*</span> <span class="n">percent_of_train_dataset</span><span class="p">)))</span>',
          '<span class="n">subset_dataset</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Dataset({',
          '    features: [\'ID\', \'Joke\'],',
          '    num_rows: 231657',
          '})',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Ahora dividimos el subset en un conjunto de entrenamiento y otro de validaci贸n</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">percent_of_train_dataset</span> <span class="o">=</span> <span class="mf">0.90</span>',
          '',
          '<span class="n">split_dataset</span> <span class="o">=</span> <span class="n">subset_dataset</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">train_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">subset_dataset</span><span class="o">.</span><span class="n">num_rows</span> <span class="o">*</span> <span class="n">percent_of_train_dataset</span><span class="p">),</span> <span class="n">seed</span><span class="o">=</span><span class="mi">19</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>',
          '<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span>',
          '<span class="n">validation_test_dataset</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span>',
          '',
          '<span class="n">split_dataset</span> <span class="o">=</span> <span class="n">validation_test_dataset</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">train_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">validation_test_dataset</span><span class="o">.</span><span class="n">num_rows</span> <span class="o">*</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">seed</span><span class="o">=</span><span class="mi">19</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>',
          '<span class="n">validation_dataset</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span>',
          '<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span>',
          '',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Size of the train set: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">. Size of the validation set: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">validation_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">. Size of the test set: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Size of the train set: 208491. Size of the validation set: 11583. Size of the test set: 11583',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Tokenizador">Tokenizador<a class="anchor-link" href="#Tokenizador"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 13" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Instanciamos el tokenizador. Instanciamos el token de padding del tokenizador para que no nos de error como antes</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>',
      '      ',
      '      <span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"openai-community/gpt2"</span>',
      '      ',
      '      <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '      <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>',
      '      <span class="n">tokenizer</span><span class="o">.</span><span class="n">padding_side</span> <span class="o">=</span> <span class="s2">"right"</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>












      
      <section class="section-block-markdown-cell">
      <p>Vamos a a帽adir dos nuevos tokens de inicio de chiste y final de chiste para tener m谩s control</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"openai-community/gpt2"</span>',
          '',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>',
          '<span class="n">tokenizer</span><span class="o">.</span><span class="n">padding_side</span> <span class="o">=</span> <span class="s2">"right"</span>',
          '</span><span class="n">new_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="s1">\'&lt;SJ&gt;\'</span><span class="p">,</span> <span class="s1">\'&lt;EJ&gt;\'</span><span class="p">]</span>   <span class="c1"># Start and end of joke tokens</span>',
          '',
          '<span class="n">num_added_tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">add_tokens</span><span class="p">(</span><span class="n">new_tokens</span><span class="p">)</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Added </span><span class="si">{</span><span class="n">num_added_tokens</span><span class="si">}</span><span class="s2"> tokens"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Added 2 tokens',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Creamos una funci贸n para a帽adir los nuevos tokens a las sentencias</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">joke_column</span> <span class="o">=</span> <span class="s2">"Joke"</span>',
      '      ',
      '      <span class="k">def</span> <span class="nf">format_joke</span><span class="p">(</span><span class="n">example</span><span class="p">):</span>',
      '          <span class="n">example</span><span class="p">[</span><span class="n">joke_column</span><span class="p">]</span> <span class="o">=</span> <span class="s1">\'&lt;SJ&gt; \'</span> <span class="o">+</span> <span class="n">example</span><span class="p">[</span><span class="s1">\'Joke\'</span><span class="p">]</span> <span class="o">+</span> <span class="s1">\' &lt;EJ&gt;\'</span>',
      '          <span class="k">return</span> <span class="n">example</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>










      
      <section class="section-block-markdown-cell">
      <p>Seleccionamos las columnas que no necesitamos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">joke_column</span> <span class="o">=</span> <span class="s2">"Joke"</span>',
          '',
          '<span class="k">def</span> <span class="nf">format_joke</span><span class="p">(</span><span class="n">example</span><span class="p">):</span>',
          '    <span class="n">example</span><span class="p">[</span><span class="n">joke_column</span><span class="p">]</span> <span class="o">=</span> <span class="s1">\'&lt;SJ&gt; \'</span> <span class="o">+</span> <span class="n">example</span><span class="p">[</span><span class="s1">\'Joke\'</span><span class="p">]</span> <span class="o">+</span> <span class="s1">\' &lt;EJ&gt;\'</span>',
          '    <span class="k">return</span> <span class="n">example</span>',
          '</span><span class="n">remove_columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">column</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">column_names</span> <span class="k">if</span> <span class="n">column</span> <span class="o">!=</span> <span class="n">joke_column</span><span class="p">]</span>',
          '<span class="n">remove_columns</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '[\'ID\']',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Formateamos el dataset y eliminamos las columnas que no necesitamos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">format_joke</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="n">remove_columns</span><span class="p">)</span>',
          '<span class="n">validation_dataset</span> <span class="o">=</span> <span class="n">validation_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">format_joke</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="n">remove_columns</span><span class="p">)</span>',
          '<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">format_joke</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="n">remove_columns</span><span class="p">)</span>',
          '<span class="n">train_dataset</span><span class="p">,</span> <span class="n">validation_dataset</span><span class="p">,</span> <span class="n">test_dataset</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '(Dataset({',
          '     features: [\'Joke\'],',
          '     num_rows: 208491',
          ' }),',
          ' Dataset({',
          '     features: [\'Joke\'],',
          '     num_rows: 11583',
          ' }),',
          ' Dataset({',
          '     features: [\'Joke\'],',
          '     num_rows: 11583',
          ' }))',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Ahora creamos una funci贸n para tokenizar los chistes</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>',
      '          <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="n">joke_column</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>







      
      <section class="section-block-markdown-cell">
      <p>Tokenizamos el dataset y eliminamos la columna con el texto</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="n">joke_column</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="n">joke_column</span><span class="p">])</span>',
          '<span class="n">validation_dataset</span> <span class="o">=</span> <span class="n">validation_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="n">joke_column</span><span class="p">])</span>',
          '<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="n">joke_column</span><span class="p">])</span>',
          '<span class="n">train_dataset</span><span class="p">,</span> <span class="n">validation_dataset</span><span class="p">,</span> <span class="n">test_dataset</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '(Dataset({',
          '     features: [\'input_ids\', \'attention_mask\'],',
          '     num_rows: 208491',
          ' }),',
          ' Dataset({',
          '     features: [\'input_ids\', \'attention_mask\'],',
          '     num_rows: 11583',
          ' }),',
          ' Dataset({',
          '     features: [\'input_ids\', \'attention_mask\'],',
          '     num_rows: 11583',
          ' }))',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Modelo">Modelo<a class="anchor-link" href="#Modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 14" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Ahora instanciamos el modelo para generaci贸n de texto y le asignamos al token de pading el token de end of string</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForCausalLM</span>',
      '      ',
      '      <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '      <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>









      
      <section class="section-block-markdown-cell">
      <p>Vemos el tama帽o del vocabulario del modelo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForCausalLM</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>',
          '</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span>',
          '<span class="n">vocab_size</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '50257',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Tiene 50257 tokens, que es el tama帽o del vocabulario de GPT2. Pero como hemos dicho que 铆bamos a crear dos tokens nuevos con el inicio de chiste y el final de chiste, los a帽adimos al modelo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">model</span><span class="o">.</span><span class="n">resize_token_embeddings</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">))</span>',
          '',
          '<span class="n">new_vocab_size</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Old vocab size: </span><span class="si">{</span><span class="n">vocab_size</span><span class="si">}</span><span class="s2">. New vocab size: </span><span class="si">{</span><span class="n">new_vocab_size</span><span class="si">}</span><span class="s2">. Added </span><span class="si">{</span><span class="n">new_vocab_size</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">vocab_size</span><span class="si">}</span><span class="s2"> tokens"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Old vocab size: 50257. New vocab size: 50259. Added 2 tokens',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Se han a帽adido los dos nuevos tokens</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Entrenamiento">Entrenamiento<a class="anchor-link" href="#Entrenamiento"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 15" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Configuramos los par谩metros de entrenamiento</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>',
      '      ',
      '      <span class="n">metric_name</span> <span class="o">=</span> <span class="s2">"accuracy"</span>',
      '      <span class="n">model_name</span> <span class="o">=</span> <span class="s2">"GPT2-small-finetuned-Maximofn-short-jokes-dataset-casualLM"</span>',
      '      <span class="n">output_dir</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"./training_results"</span>',
      '      <span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>',
      '      <span class="n">BS_TRAIN</span> <span class="o">=</span> <span class="mi">28</span>',
      '      <span class="n">BS_EVAL</span> <span class="o">=</span> <span class="mi">32</span>',
      '      <span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>',
      '      <span class="n">WEIGHT_DECAY</span> <span class="o">=</span> <span class="mf">0.01</span>',
      '      <span class="n">WARMUP_STEPS</span> <span class="o">=</span> <span class="mi">100</span>',
      '      ',
      '      <span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
      '          <span class="n">model_name</span><span class="p">,</span>',
      '          <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">save_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
      '          <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
      '          <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
      '          <span class="n">warmup_steps</span><span class="o">=</span><span class="n">WARMUP_STEPS</span><span class="p">,</span>',
      '          <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
      '          <span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
      '          <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">"cosine"</span><span class="p">,</span>',
      '          <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
      '          <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="c1"># metric_for_best_model=metric_name,</span>',
      '          <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '      <span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>


































      
      <section class="section-block-markdown-cell">
      <p>Ahora no usamos <code>metric_for_best_model</code>, despu茅s de definir el trainer explicamos por qu茅</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Definimos el trainer</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>',
      '      ',
      '      <span class="n">metric_name</span> <span class="o">=</span> <span class="s2">"accuracy"</span>',
      '      <span class="n">model_name</span> <span class="o">=</span> <span class="s2">"GPT2-small-finetuned-Maximofn-short-jokes-dataset-casualLM"</span>',
      '      <span class="n">output_dir</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"./training_results"</span>',
      '      <span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>',
      '      <span class="n">BS_TRAIN</span> <span class="o">=</span> <span class="mi">28</span>',
      '      <span class="n">BS_EVAL</span> <span class="o">=</span> <span class="mi">32</span>',
      '      <span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>',
      '      <span class="n">WEIGHT_DECAY</span> <span class="o">=</span> <span class="mf">0.01</span>',
      '      <span class="n">WARMUP_STEPS</span> <span class="o">=</span> <span class="mi">100</span>',
      '      ',
      '      <span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
      '          <span class="n">model_name</span><span class="p">,</span>',
      '          <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">save_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
      '          <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
      '          <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
      '          <span class="n">warmup_steps</span><span class="o">=</span><span class="n">WARMUP_STEPS</span><span class="p">,</span>',
      '          <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
      '          <span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
      '          <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">"cosine"</span><span class="p">,</span>',
      '          <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
      '          <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="c1"># metric_for_best_model=metric_name,</span>',
      '          <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">Trainer</span>',
      '      ',
      '      <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
      '          <span class="n">model</span><span class="p">,</span>',
      '          <span class="n">training_args</span><span class="p">,</span>',
      '          <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>',
      '          <span class="n">eval_dataset</span><span class="o">=</span><span class="n">validation_dataset</span><span class="p">,</span>',
      '          <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
      '          <span class="c1"># compute_metrics=compute_metrics,</span>',
      '      <span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>















      
      <section class="section-block-markdown-cell">
      <p>En este caso no le pasamos una funci贸n <code>compute_metrics</code>, si no se le pasa, durante la evaluaci贸n se usar谩 la <code>loss</code> para evaluar el modelo. Por eso al definir los argumentos no definimos <code>metric_for_best_model</code>, porque no vamos a usar una m茅trica para evaluar el modelo, si no la <code>loss</code></p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Entrenamos</p>
      </section>
      
      <section class="section-block-code-cell-">
      <div class="input-code">
      <div class="highlight hl-ipython3">
<pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
      </pre></div>
      </div>
      <div class="output-wrapper">
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-text-output-subarea">
      <pre>  0%|          | 0/625473 [00:00&lt;?, ?it/s]</pre>
      </div>
      </div>
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-subarea-output-text-output-error">
      <pre>
      <span class="ansi-red-fg">---------------------------------------------------------------------------</span>
      <span class="ansi-red-fg">ValueError</span>                                Traceback (most recent call last)
      Cell <span class="ansi-green-fg">In[19], line 1</span>
      <span class="ansi-green-fg">----&gt; 1</span> trainer<span style="color: rgb(98,98,98)">.</span>train()
      
      File <span class="ansi-green-fg">~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/trainer.py:1885</span>, in <span class="ansi-cyan-fg">Trainer.train</span><span class="ansi-blue-fg">(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)</span>
      <span class="ansi-green-intense-fg ansi-bold">   1883</span>         hf_hub_utils<span style="color: rgb(98,98,98)">.</span>enable_progress_bars()
      <span class="ansi-green-intense-fg ansi-bold">   1884</span> <span class="ansi-bold" style="color: rgb(0,135,0)">else</span>:
      <span class="ansi-green-fg">-&gt; 1885</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> inner_training_loop(
      <span class="ansi-green-intense-fg ansi-bold">   1886</span>         args<span style="color: rgb(98,98,98)">=</span>args,
      <span class="ansi-green-intense-fg ansi-bold">   1887</span>         resume_from_checkpoint<span style="color: rgb(98,98,98)">=</span>resume_from_checkpoint,
      <span class="ansi-green-intense-fg ansi-bold">   1888</span>         trial<span style="color: rgb(98,98,98)">=</span>trial,
      <span class="ansi-green-intense-fg ansi-bold">   1889</span>         ignore_keys_for_eval<span style="color: rgb(98,98,98)">=</span>ignore_keys_for_eval,
      <span class="ansi-green-intense-fg ansi-bold">   1890</span>     )
      
      File <span class="ansi-green-fg">~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/trainer.py:2216</span>, in <span class="ansi-cyan-fg">Trainer._inner_training_loop</span><span class="ansi-blue-fg">(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)</span>
      <span class="ansi-green-intense-fg ansi-bold">   2213</span>     <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>control <span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>callback_handler<span style="color: rgb(98,98,98)">.</span>on_step_begin(args, <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>state, <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>control)
      <span class="ansi-green-intense-fg ansi-bold">   2215</span> <span class="ansi-bold" style="color: rgb(0,135,0)">with</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>accelerator<span style="color: rgb(98,98,98)">.</span>accumulate(model):
      <span class="ansi-green-fg">-&gt; 2216</span>     tr_loss_step <span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>training_step(model, inputs)
      <span class="ansi-green-intense-fg ansi-bold">   2218</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> (
      <span class="ansi-green-intense-fg ansi-bold">   2219</span>     args<span style="color: rgb(98,98,98)">.</span>logging_nan_inf_filter
      <span class="ansi-green-intense-fg ansi-bold">   2220</span>     <span class="ansi-bold" style="color: rgb(175,0,255)">and</span> <span class="ansi-bold" style="color: rgb(175,0,255)">not</span> is_torch_xla_available()
      <span class="ansi-green-intense-fg ansi-bold">   2221</span>     <span class="ansi-bold" style="color: rgb(175,0,255)">and</span> (torch<span style="color: rgb(98,98,98)">.</span>isnan(tr_loss_step) <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> torch<span style="color: rgb(98,98,98)">.</span>isinf(tr_loss_step))
      <span class="ansi-green-intense-fg ansi-bold">   2222</span> ):
      <span class="ansi-green-intense-fg ansi-bold">   2223</span>     <span style="color: rgb(95,135,135)"># if loss is nan or inf simply add the average of previous logged losses</span>
      <span class="ansi-green-intense-fg ansi-bold">   2224</span>     tr_loss <span style="color: rgb(98,98,98)">+</span><span style="color: rgb(98,98,98)">=</span> tr_loss <span style="color: rgb(98,98,98)">/</span> (<span style="color: rgb(98,98,98)">1</span> <span style="color: rgb(98,98,98)">+</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>state<span style="color: rgb(98,98,98)">.</span>global_step <span style="color: rgb(98,98,98)">-</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_globalstep_last_logged)
      
      File <span class="ansi-green-fg">~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/trainer.py:3238</span>, in <span class="ansi-cyan-fg">Trainer.training_step</span><span class="ansi-blue-fg">(self, model, inputs)</span>
      <span class="ansi-green-intense-fg ansi-bold">   3235</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> loss_mb<span style="color: rgb(98,98,98)">.</span>reduce_mean()<span style="color: rgb(98,98,98)">.</span>detach()<span style="color: rgb(98,98,98)">.</span>to(<span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>args<span style="color: rgb(98,98,98)">.</span>device)
      <span class="ansi-green-intense-fg ansi-bold">   3237</span> <span class="ansi-bold" style="color: rgb(0,135,0)">with</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>compute_loss_context_manager():
      <span class="ansi-green-fg">-&gt; 3238</span>     loss <span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>compute_loss(model, inputs)
      <span class="ansi-green-intense-fg ansi-bold">   3240</span> <span class="ansi-bold" style="color: rgb(0,135,0)">del</span> inputs
      <span class="ansi-green-intense-fg ansi-bold">   3241</span> torch<span style="color: rgb(98,98,98)">.</span>cuda<span style="color: rgb(98,98,98)">.</span>empty_cache()
      
      File <span class="ansi-green-fg">~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/trainer.py:3282</span>, in <span class="ansi-cyan-fg">Trainer.compute_loss</span><span class="ansi-blue-fg">(self, model, inputs, return_outputs)</span>
      <span class="ansi-green-intense-fg ansi-bold">   3280</span> <span class="ansi-bold" style="color: rgb(0,135,0)">else</span>:
      <span class="ansi-green-intense-fg ansi-bold">   3281</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> <span style="color: rgb(0,135,0)">isinstance</span>(outputs, <span style="color: rgb(0,135,0)">dict</span>) <span class="ansi-bold" style="color: rgb(175,0,255)">and</span> <span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">loss</span><span style="color: rgb(175,0,0)">"</span> <span class="ansi-bold" style="color: rgb(175,0,255)">not</span> <span class="ansi-bold" style="color: rgb(175,0,255)">in</span> outputs:
      <span class="ansi-green-fg">-&gt; 3282</span>         <span class="ansi-bold" style="color: rgb(0,135,0)">raise</span> <span class="ansi-bold" style="color: rgb(215,95,95)">ValueError</span>(
      <span class="ansi-green-intense-fg ansi-bold">   3283</span>             <span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">The model did not return a loss from the inputs, only the following keys: </span><span style="color: rgb(175,0,0)">"</span>
      <span class="ansi-green-intense-fg ansi-bold">   3284</span>             <span style="color: rgb(175,0,0)">f</span><span style="color: rgb(175,0,0)">"</span><span class="ansi-bold" style="color: rgb(175,95,135)">{opening_brace}</span><span style="color: rgb(175,0,0)">'</span><span style="color: rgb(175,0,0)">,</span><span style="color: rgb(175,0,0)">'</span><span style="color: rgb(98,98,98)">.</span>join(outputs<span style="color: rgb(98,98,98)">.</span>keys())<span class="ansi-bold" style="color: rgb(175,95,135)">{closing_brace}</span><span style="color: rgb(175,0,0)">. For reference, the inputs it received are </span><span class="ansi-bold" style="color: rgb(175,95,135)">{opening_brace}</span><span style="color: rgb(175,0,0)">'</span><span style="color: rgb(175,0,0)">,</span><span style="color: rgb(175,0,0)">'</span><span style="color: rgb(98,98,98)">.</span>join(inputs<span style="color: rgb(98,98,98)">.</span>keys())<span class="ansi-bold" style="color: rgb(175,95,135)">{closing_brace}</span><span style="color: rgb(175,0,0)">.</span><span style="color: rgb(175,0,0)">"</span>
      <span class="ansi-green-intense-fg ansi-bold">   3285</span>         )
      <span class="ansi-green-intense-fg ansi-bold">   3286</span>     <span style="color: rgb(95,135,135)"># We don't use .loss here since the model may return tuples instead of ModelOutput.</span>
      <span class="ansi-green-intense-fg ansi-bold">   3287</span>     loss <span style="color: rgb(98,98,98)">=</span> outputs[<span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">loss</span><span style="color: rgb(175,0,0)">"</span>] <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> <span style="color: rgb(0,135,0)">isinstance</span>(outputs, <span style="color: rgb(0,135,0)">dict</span>) <span class="ansi-bold" style="color: rgb(0,135,0)">else</span> outputs[<span style="color: rgb(98,98,98)">0</span>]
      
      <span class="ansi-red-fg">ValueError</span>: The model did not return a loss from the inputs, only the following keys: logits,past_key_values. For reference, the inputs it received are input_ids,attention_mask.</pre>
      </div>
      </div>
      </div>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Como vemos, nos da un error, nos dice que el modelo no devuelve el valor del loss, que es clave para poder entrenar, vamos a ver por qu茅</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Primero veamos c贸mo es un ejemplo del dataset</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>',
          '',
          '<span class="n">metric_name</span> <span class="o">=</span> <span class="s2">"accuracy"</span>',
          '<span class="n">model_name</span> <span class="o">=</span> <span class="s2">"GPT2-small-finetuned-Maximofn-short-jokes-dataset-casualLM"</span>',
          '<span class="n">output_dir</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"./training_results"</span>',
          '<span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>',
          '<span class="n">BS_TRAIN</span> <span class="o">=</span> <span class="mi">28</span>',
          '<span class="n">BS_EVAL</span> <span class="o">=</span> <span class="mi">32</span>',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>',
          '<span class="n">WEIGHT_DECAY</span> <span class="o">=</span> <span class="mf">0.01</span>',
          '<span class="n">WARMUP_STEPS</span> <span class="o">=</span> <span class="mi">100</span>',
          '',
          '<span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
          '    <span class="n">model_name</span><span class="p">,</span>',
          '    <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
          '    <span class="n">save_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
          '    <span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
          '    <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
          '    <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
          '    <span class="n">warmup_steps</span><span class="o">=</span><span class="n">WARMUP_STEPS</span><span class="p">,</span>',
          '    <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
          '    <span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
          '    <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">"cosine"</span><span class="p">,</span>',
          '    <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
          '    <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
          '    <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
          '    <span class="c1"># metric_for_best_model=metric_name,</span>',
          '    <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
          '<span class="p">)</span>',
          '</span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">Trainer</span>',
          '',
          '<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
          '    <span class="n">model</span><span class="p">,</span>',
          '    <span class="n">training_args</span><span class="p">,</span>',
          '    <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>',
          '    <span class="n">eval_dataset</span><span class="o">=</span><span class="n">validation_dataset</span><span class="p">,</span>',
          '    <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
          '    <span class="c1"># compute_metrics=compute_metrics,</span>',
          '<span class="p">)</span>',
          '</span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '</span><span class="n">idx</span> <span class="o">=</span> <span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>',
          '<span class="n">sample</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>',
          '<span class="n">sample</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '  0%|          | 0/625473 [00:00&lt;?, ?it/s]',
          '{\'input_ids\': [50257,',
          '  4162,',
          '  750,',
          '  262,',
          '  18757,',
          '  6451,',
          '  2245,',
          '  2491,',
          '  30,',
          '  4362,',
          '  340,',
          '  373,',
          '  734,',
          '  10032,',
          '  13,',
          '  220,',
          '  50258,',
          '  50256,',
          '  50256,',
          '  ...,',
          '  50256,',
          '  50256,',
          '  50256],',
          ' \'attention_mask\': [1,',
          '  1,',
          '  1,',
          '  1,',
          '  1,',
          '  1,',
          '  1,',
          '  1,',
          '  1,',
          '  1,',
          '  1,',
          '  1,',
          '  1,',
          '  1,',
          '  1,',
          '  1,',
          '  1,',
          '  0,',
          '  0,',
          '  0,',
          '  ...,',
          '  0,',
          '  0,',
          '  0]}',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Como vemos, tenemos un diccionario con los <code>input_ids</code> y las <code>attention_mask</code>, si se lo pasamos al modelo obtenemos esto</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
          '',
          '<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span>',
          '    <span class="n">input_ids</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">])</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>',
          '    <span class="n">attention_mask</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">])</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>',
          '<span class="p">)</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">loss</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'None',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Como vemos no devuelve el valor de la loss porque est谩 esperando un valor para <code>labels</code>, que no se lo hemos pasado. En el ejemplo anterior, en el que hac铆amos fine tuning para clasificaci贸n de texto, dijimos que las etiquetas hab铆a que pasarlas a un campo del dataset llamado <code>labels</code>, pero en este caso no tenemos ese campo en el dataset</p>
      <p>Si ahora asignamos las <code>lables</code> a los <code>input_ids</code> y volvemos a ver la loss</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
          '',
          '<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span>',
          '    <span class="n">input_ids</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">])</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>',
          '    <span class="n">attention_mask</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">])</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>',
          '    <span class="n">labels</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">])</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>',
          '<span class="p">)</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">loss</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'tensor(102.1873, device=\'cuda:0\', grad_fn=&lt;NllLossBackward0&gt;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Ahora s铆 obtenemos una <code>loss</code></p>
      <p>Por tanto tenemos dos opciones, a帽adir un campo <code>labels</code> al dataset, con los valores de <code>input_ids</code> o utilizar una funci贸n de la librer铆a <code>transformers</code> llamada <code>data_collator</code>, en este caso usaremos <code>DataCollatorForLanguageModeling</code>. Vamos a verlo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">DataCollatorForLanguageModeling</span>',
      '      ',
      '      <span class="n">my_data_collator</span><span class="o">=</span><span class="n">DataCollatorForLanguageModeling</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">mlm</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>








      
      <section class="section-block-markdown-cell">
      <p>Pasamos la muestra <code>sample</code> por este <code>data_collator</code></p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">DataCollatorForLanguageModeling</span>',
      '      ',
      '      <span class="n">my_data_collator</span><span class="o">=</span><span class="n">DataCollatorForLanguageModeling</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">mlm</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>',
      '<span></span><span class="n">collated_sample</span> <span class="o">=</span> <span class="n">my_data_collator</span><span class="p">([</span><span class="n">sample</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>






      
      <section class="section-block-markdown-cell">
      <p>Vemos c贸mo es la salida</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">DataCollatorForLanguageModeling</span>',
          '',
          '<span class="n">my_data_collator</span><span class="o">=</span><span class="n">DataCollatorForLanguageModeling</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">mlm</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>',
          '</span><span class="n">collated_sample</span> <span class="o">=</span> <span class="n">my_data_collator</span><span class="p">([</span><span class="n">sample</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>',
          '</span><span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">collated_sample</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">): </span><span class="si">{</span><span class="n">value</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'input_ids (torch.Size([1, 768])): tensor([[50257,  4162,   750,   262, 18757,  6451,  2245,  2491,    30,  4362,',
          '           340,   373,   734, 10032,    13,   220, 50258, 50256, ..., 50256, 50256]],',
          '       device=\'cuda:0\')',
          'attention_mask (torch.Size([1, 768])): tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, ..., 0, 0]],',
          '       device=\'cuda:0\')',
          'labels (torch.Size([1, 768])): tensor([[50257,  4162,   750,   262, 18757,  6451,  2245,  2491,    30,  4362,',
          '           340,   373,   734, 10032,    13,   220, 50258,  -100,  ...,  -100,  -100]],',
          '       device=\'cuda:0\')',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Como se puede ver, el <code>data_collator</code> ha creado un campo <code>labels</code> y le ha asignado los valores de <code>input_ids</code>. Los tokens que est谩n enmascarados le ha asignado el valor -100. Esto es porque cuando definimos el <code>data_collator</code> le pasamos el par谩metro <code>mlm=False</code>, que significa que no estamos haciendo <code>Masked Language Modeling</code>, si no <code>Language Modeling</code>, por eso no enmascara ning煤n token original</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a ver si ahora obtenemos una <code>loss</code> con este <code>data_collator</code></p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">collated_sample</span><span class="p">)</span>',
          '<span class="n">output</span><span class="o">.</span><span class="n">loss</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'tensor(102.7181, device=\'cuda:0\', grad_fn=&lt;NllLossBackward0&gt;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>As铆 que volvemos a definir el <code>trainer</code> con el <code>data_collator</code> y volvemos a entrenar</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">DataCollatorForLanguageModeling</span>',
      '      ',
      '      <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
      '          <span class="n">model</span><span class="p">,</span>',
      '          <span class="n">training_args</span><span class="p">,</span>',
      '          <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>',
      '          <span class="n">eval_dataset</span><span class="o">=</span><span class="n">validation_dataset</span><span class="p">,</span>',
      '          <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
      '          <span class="n">data_collator</span><span class="o">=</span><span class="n">DataCollatorForLanguageModeling</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">mlm</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>',
      '      <span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>















      
      <section class="section-block-code-cell-">
      <div class="input-code">
      <div class="highlight hl-ipython3">
<pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
      </pre></div>
      </div>
      <div class="output-wrapper">
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-html-rendered-html-output-subarea">
      <div>
      <progress max="22341" style="width:300px; height:20px; vertical-align: middle;" value="22341"></progress>
            [22341/22341 2:33:28, Epoch 3/3]
          </div>
      <table border="1" class="dataframe">
      <thead>
      <tr style="text-align: left;">
      <th>Epoch</th>
      <th>Training Loss</th>
      <th>Validation Loss</th>
      </tr>
      </thead>
      <tbody>
      <tr>
      <td>1</td>
      <td>3.386600</td>
      <td>3.258979</td>
      </tr>
      <tr>
      <td>2</td>
      <td>3.259900</td>
      <td>3.199673</td>
      </tr>
      <tr>
      <td>3</td>
      <td>3.212600</td>
      <td>3.192009</td>
      </tr>
      </tbody>
      </table><p></p></div>
      </div>
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-subarea-output-stream-output-stderr-output-text">
      <pre>There were missing keys in the checkpoint model loaded: ['lm_head.weight'].
      </pre>
      </div>
      </div>
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-text-output-subarea">
      <pre>TrainOutput(global_step=22341, training_loss=3.505178199598342, metrics={opening_brace}'train_runtime': 9209.5353, 'train_samples_per_second': 67.916, 'train_steps_per_second': 2.426, 'total_flos': 2.45146666696704e+17, 'train_loss': 3.505178199598342, 'epoch': 3.0{closing_brace})</pre>
      </div>
      </div>
      </div>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Evaluaci%C3%B3n">Evaluaci贸n<a class="anchor-link" href="#Evaluaci%C3%B3n"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 16" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Una vez entrenado evaluamos el modelo sobre el dataset de test</p>
      </section>
      
      <section class="section-block-code-cell-">
      <div class="input-code">
      <div class="highlight hl-ipython3">
<pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">)</span>
      </pre></div>
      </div>
      <div class="output-wrapper">
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-html-rendered-html-output-subarea">
      <div>
      <progress max="362" style="width:300px; height:20px; vertical-align: middle;" value="362"></progress>
            [362/362 01:04]
          </div>
      </div>
      </div>
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-text-output-subarea">
      <pre>{opening_brace}'eval_loss': 3.201305866241455,
       'eval_runtime': 65.0033,
       'eval_samples_per_second': 178.191,
       'eval_steps_per_second': 5.569,
       'epoch': 3.0}</pre>
      </div>
      </div>
      </div>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Publicar-el-modelo">Publicar el modelo<a class="anchor-link" href="#Publicar-el-modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 17" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Creamos la model card</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">DataCollatorForLanguageModeling</span>',
      '      ',
      '      <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
      '          <span class="n">model</span><span class="p">,</span>',
      '          <span class="n">training_args</span><span class="p">,</span>',
      '          <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>',
      '          <span class="n">eval_dataset</span><span class="o">=</span><span class="n">validation_dataset</span><span class="p">,</span>',
      '          <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
      '          <span class="n">data_collator</span><span class="o">=</span><span class="n">DataCollatorForLanguageModeling</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">mlm</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">)</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">create_model_card</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>






      
      <section class="section-block-markdown-cell">
      <p>Lo publicamos</p>
      </section>
      
      <section class="section-block-code-cell-">
      <div class="input-code">
      <div class="highlight hl-ipython3">
<pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">push_to_hub</span><span class="p">()</span>
      </pre></div>
      </div>
      <div class="output-wrapper">
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-text-output-subarea">
      <pre>events.out.tfevents.1720875425.8de3af1b431d.6946.1:   0%|          | 0.00/364 [00:00&lt;?, ?B/s]</pre>
      </div>
      </div>
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-text-output-subarea">
      <pre>CommitInfo(commit_url='https://huggingface.co/Maximofn/GPT2-small-finetuned-Maximofn-short-jokes-dataset-casualLM/commit/d107b3bb0e02076483238f9975697761015ec390', commit_message='End of training', commit_description='', oid='d107b3bb0e02076483238f9975697761015ec390', pr_url=None, pr_revision=None, pr_num=None)</pre>
      </div>
      </div>
      </div>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Uso-del-modelo">Uso del modelo<a class="anchor-link" href="#Uso-del-modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 18" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Limpiamos todo lo posible</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">DataCollatorForLanguageModeling</span>',
      '      ',
      '      <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
      '          <span class="n">model</span><span class="p">,</span>',
      '          <span class="n">training_args</span><span class="p">,</span>',
      '          <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>',
      '          <span class="n">eval_dataset</span><span class="o">=</span><span class="n">validation_dataset</span><span class="p">,</span>',
      '          <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
      '          <span class="n">data_collator</span><span class="o">=</span><span class="n">DataCollatorForLanguageModeling</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">mlm</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">)</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">create_model_card</span><span class="p">()</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">push_to_hub</span><span class="p">()</span>',
      '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
      '      <span class="kn">import</span> <span class="nn">gc</span>',
      '      ',
      '      ',
      '      <span class="k">def</span> <span class="nf">clear_hardwares</span><span class="p">():</span>',
      '          <span class="n">torch</span><span class="o">.</span><span class="n">clear_autocast_cache</span><span class="p">()</span>',
      '          <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">ipc_collect</span><span class="p">()</span>',
      '          <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>',
      '          <span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>',
      '      ',
      '      ',
      '      <span class="n">clear_hardwares</span><span class="p">()</span>',
      '      <span class="n">clear_hardwares</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>


















      
      <section class="section-block-markdown-cell">
      <p>Descargamos el modelo y el tokenizador</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">DataCollatorForLanguageModeling</span>',
          '',
          '<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
          '    <span class="n">model</span><span class="p">,</span>',
          '    <span class="n">training_args</span><span class="p">,</span>',
          '    <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>',
          '    <span class="n">eval_dataset</span><span class="o">=</span><span class="n">validation_dataset</span><span class="p">,</span>',
          '    <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
          '    <span class="n">data_collator</span><span class="o">=</span><span class="n">DataCollatorForLanguageModeling</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">mlm</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>',
          '<span class="p">)</span>',
          '</span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '</span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">)</span>',
          '</span><span class="n">trainer</span><span class="o">.</span><span class="n">create_model_card</span><span class="p">()</span>',
          '</span><span class="n">trainer</span><span class="o">.</span><span class="n">push_to_hub</span><span class="p">()</span>',
          '</span><span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">import</span> <span class="nn">gc</span>',
          '',
          '',
          '<span class="k">def</span> <span class="nf">clear_hardwares</span><span class="p">():</span>',
          '    <span class="n">torch</span><span class="o">.</span><span class="n">clear_autocast_cache</span><span class="p">()</span>',
          '    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">ipc_collect</span><span class="p">()</span>',
          '    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>',
          '    <span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>',
          '',
          '',
          '<span class="n">clear_hardwares</span><span class="p">()</span>',
          '<span class="n">clear_hardwares</span><span class="p">()</span>',
          '</span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForCausalLM</span>',
          '',
          '<span class="n">user</span> <span class="o">=</span> <span class="s2">"maximofn"</span>',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">user</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">"</span>',
          '',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>',
          '<span class="n">tokenizer</span><span class="o">.</span><span class="n">padding_side</span> <span class="o">=</span> <span class="s2">"right"</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'events.out.tfevents.1720875425.8de3af1b431d.6946.1:   0%|          | 0.00/364 [00:00&lt;?, ?B/s]',
          'Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Comprobamos que el tokenizador y el modelo tienen los 2 tokens extra que hemos a帽adido</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">tokenizer_vocab</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">get_vocab</span><span class="p">()</span>',
          '<span class="n">model_vocab</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"tokenizer_vocab: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">tokenizer_vocab</span><span class="p">)</span><span class="si">}</span><span class="s2">. model_vocab: </span><span class="si">{</span><span class="n">model_vocab</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'tokenizer_vocab: 50259. model_vocab: 50259',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos que tienen 50259 tokens, es decir, los 50257 tokens de GPT2 m谩s los 2 que hemos a帽adido</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Creamos una funci贸n para generar chistes</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">def</span> <span class="nf">generate_joke</span><span class="p">(</span><span class="n">prompt_text</span><span class="p">):</span>',
      '          <span class="n">text</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"&lt;SJ&gt; </span><span class="si">{</span><span class="n">prompt_text</span><span class="si">}</span><span class="s2">"</span>',
      '          <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>',
      '          <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
      '              <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="o">**</span><span class="n">tokens</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">eos_token_id</span><span class="o">=</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">"&lt;EJ&gt;"</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>',
      '          <span class="k">return</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>











      
      <section class="section-block-markdown-cell">
      <p>Generamos un chiste</p>
      </section>
      
      <section class="section-block-code-cell-">
      <div class="input-code">
      <div class="highlight hl-ipython3">
<pre><span></span><span class="n">generate_joke</span><span class="p">(</span><span class="s2">"Why didn't the frog cross the road?"</span><span class="p">)</span>
      </pre></div>
      </div>
      <div class="output-wrapper">
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-subarea-output-stream-output-stderr-output-text">
      <pre>Setting `pad_token_id` to `eos_token_id`:50258 for open-end generation.
      </pre>
      </div>
      </div>
      <div class="output-area">
      <div class="prompt-output-prompt">Out[15]:</div>
      <div class="output-text-output-subareaoutput_execute_result">
      <pre>"&lt;SJ&gt; Why didn't the frog cross the road? Because he was frog-in-the-face. &lt;EJ&gt;"</pre>
      </div>
      </div>
      </div>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Si quires probar m谩s el modelo puedes verlo en <a href="https://huggingface.co/Maximofn/GPT2-small-finetuned-Maximofn-short-jokes-dataset-casualLM" target="_blank" rel="nofollow noreferrer">Maximofn/GPT2-small-finetuned-Maximofn-short-jokes-dataset-casualLM</a></p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Fine-tuning-para-clasificaci%C3%B3n-de-texto-con-Pytorch">Fine tuning para clasificaci贸n de texto con Pytorch<a class="anchor-link" href="#Fine-tuning-para-clasificaci%C3%B3n-de-texto-con-Pytorch"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 19" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Repetimos el entrenamiento con Pytorch</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Reiniciamos el notebook para asegurarnos</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Dataset">Dataset<a class="anchor-link" href="#Dataset"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 20" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Descargamos el mismo dataset que cuando hicimos el entrnemiento con las librer铆as de Hugging Face</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">def</span> <span class="nf">generate_joke</span><span class="p">(</span><span class="n">prompt_text</span><span class="p">):</span>',
      '          <span class="n">text</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"&lt;SJ&gt; </span><span class="si">{</span><span class="n">prompt_text</span><span class="si">}</span><span class="s2">"</span>',
      '          <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>',
      '          <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
      '              <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="o">**</span><span class="n">tokens</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">eos_token_id</span><span class="o">=</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">"&lt;EJ&gt;"</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>',
      '          <span class="k">return</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>',
      '<span></span><span class="n">generate_joke</span><span class="p">(</span><span class="s2">"Why didn\'t the frog cross the road?"</span><span class="p">)</span>',
      '<span></span><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
      '      ',
      '      <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"mteb/amazon_reviews_multi"</span><span class="p">,</span> <span class="s2">"en"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>








      
      <section class="section-block-markdown-cell">
      <p>Creamos una variable con el n煤mero de clases</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="k">def</span> <span class="nf">generate_joke</span><span class="p">(</span><span class="n">prompt_text</span><span class="p">):</span>',
          '    <span class="n">text</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"&lt;SJ&gt; </span><span class="si">{</span><span class="n">prompt_text</span><span class="si">}</span><span class="s2">"</span>',
          '    <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>',
          '    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="o">**</span><span class="n">tokens</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">eos_token_id</span><span class="o">=</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">"&lt;EJ&gt;"</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>',
          '</span><span class="n">generate_joke</span><span class="p">(</span><span class="s2">"Why didn\'t the frog cross the road?"</span><span class="p">)</span>',
          '</span><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"mteb/amazon_reviews_multi"</span><span class="p">,</span> <span class="s2">"en"</span><span class="p">)</span>',
          '</span><span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="s1">\'label\'</span><span class="p">))</span>',
          '<span class="n">num_classes</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Setting `pad_token_id` to `eos_token_id`:50258 for open-end generation.',
          '5',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Antes procesamos todo el dataset para crear un campo llamado <code>labels</code>, pero ahora no hace falta porque como vamos a programar nosotros todo, nos adaptamos a c贸mo es el dataset</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Tokenizador">Tokenizador<a class="anchor-link" href="#Tokenizador"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 21" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Creamos el tokenizador. Le asignamos el token de padding para que no nos de error como antes</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>',
      '      ',
      '      <span class="n">checkpoint</span> <span class="o">=</span> <span class="s2">"openai-community/gpt2"</span>',
      '      <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>',
      '      <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>










      
      <section class="section-block-markdown-cell">
      <p>Creamos una funci贸n para tokenizar el dataset</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>',
      '      ',
      '      <span class="n">checkpoint</span> <span class="o">=</span> <span class="s2">"openai-community/gpt2"</span>',
      '      <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>',
      '      <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>',
      '<span></span><span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>',
      '          <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>







      
      <section class="section-block-markdown-cell">
      <p>Lo tokenizamos. Eliminamos columnas que no nos hagan falta, pero ahora dejamos la del texto</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>',
      '      ',
      '      <span class="n">checkpoint</span> <span class="o">=</span> <span class="s2">"openai-community/gpt2"</span>',
      '      <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>',
      '      <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>',
      '<span></span><span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>',
      '          <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
      '<span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'id\'</span><span class="p">,</span> <span class="s1">\'label_text\'</span><span class="p">])</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>






      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>',
          '',
          '<span class="n">checkpoint</span> <span class="o">=</span> <span class="s2">"openai-community/gpt2"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>',
          '<span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>',
          '</span><span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'id\'</span><span class="p">,</span> <span class="s1">\'label_text\'</span><span class="p">])</span>',
          '</span><span class="n">dataset</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'DatasetDict({',
          '    train: Dataset({',
          '        features: [\'text\', \'label\', \'input_ids\', \'attention_mask\'],',
          '        num_rows: 200000',
          '    })',
          '    validation: Dataset({',
          '        features: [\'text\', \'label\', \'input_ids\', \'attention_mask\'],',
          '        num_rows: 5000',
          '    })',
          '    test: Dataset({',
          '        features: [\'text\', \'label\', \'input_ids\', \'attention_mask\'],',
          '        num_rows: 5000',
          '    })',
          '})',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">percentage</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="n">subset_train</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">])</span> <span class="o">*</span> <span class="n">percentage</span><span class="p">)))</span>',
          '<span class="n">percentage</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="n">subset_validation</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s1">\'validation\'</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'validation\'</span><span class="p">])</span> <span class="o">*</span> <span class="n">percentage</span><span class="p">)))</span>',
          '<span class="n">subset_test</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s1">\'test\'</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'test\'</span><span class="p">])</span> <span class="o">*</span> <span class="n">percentage</span><span class="p">)))</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"len subset_train: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">subset_train</span><span class="p">)</span><span class="si">}</span><span class="s2">, len subset_validation: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">subset_validation</span><span class="p">)</span><span class="si">}</span><span class="s2">, len subset_test: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">subset_test</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'len subset_train: 200000, len subset_validation: 5000, len subset_test: 5000',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Modelo">Modelo<a class="anchor-link" href="#Modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 22" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Importamos los pesos y asignamos el token de padding</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="n">num_classes</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: [\'score.weight\']',
          'You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Device">Device<a class="anchor-link" href="#Device"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 23" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Creamos el dispositivo donde se va a ejecutar todo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
      '      ',
      '      <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">\'cuda\'</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">\'cpu\'</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>








      
      <section class="section-block-markdown-cell">
      <p>De paso pasamos el modelo al dispositivo y de paso lo pasamos a FP16 para que ocupe menos memoria</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
          '',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">\'cuda\'</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">\'cpu\'</span><span class="p">)</span>',
          '</span><span class="n">model</span><span class="o">.</span><span class="n">half</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '<span class="nb">print</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Pytorch-Dataset">Pytorch Dataset<a class="anchor-link" href="#Pytorch-Dataset"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 24" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Creamos un dataset de pytorch</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>',
      '      ',
      '      <span class="k">class</span> <span class="nc">ReviewsDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>',
      '          <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">huggingface_dataset</span><span class="p">):</span>',
      '              <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">huggingface_dataset</span>',
      '      ',
      '          <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>',
      '              <span class="n">label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">\'label\'</span><span class="p">]</span>',
      '              <span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">\'input_ids\'</span><span class="p">])</span>',
      '              <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">\'attention_mask\'</span><span class="p">])</span>',
      '              <span class="k">return</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">label</span>',
      '      ',
      '          <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>',
      '              <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>



















      
      <section class="section-block-markdown-cell">
      <p>Instanciamos los datasets</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>',
      '      ',
      '      <span class="k">class</span> <span class="nc">ReviewsDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>',
      '          <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">huggingface_dataset</span><span class="p">):</span>',
      '              <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">huggingface_dataset</span>',
      '      ',
      '          <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>',
      '              <span class="n">label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">\'label\'</span><span class="p">]</span>',
      '              <span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">\'input_ids\'</span><span class="p">])</span>',
      '              <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">\'attention_mask\'</span><span class="p">])</span>',
      '              <span class="k">return</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">label</span>',
      '      ',
      '          <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>',
      '              <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>',
      '<span></span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">ReviewsDataset</span><span class="p">(</span><span class="n">subset_train</span><span class="p">)</span>',
      '      <span class="n">validatation_dataset</span> <span class="o">=</span> <span class="n">ReviewsDataset</span><span class="p">(</span><span class="n">subset_validation</span><span class="p">)</span>',
      '      <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">ReviewsDataset</span><span class="p">(</span><span class="n">subset_test</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>








      
      <section class="section-block-markdown-cell">
      <p>Vamos a ver una muestra</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>',
          '',
          '<span class="k">class</span> <span class="nc">ReviewsDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>',
          '    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">huggingface_dataset</span><span class="p">):</span>',
          '        <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">huggingface_dataset</span>',
          '',
          '    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>',
          '        <span class="n">label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">\'label\'</span><span class="p">]</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">\'input_ids\'</span><span class="p">])</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '        <span class="k">return</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">label</span>',
          '',
          '    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>',
          '        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>',
          '</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">ReviewsDataset</span><span class="p">(</span><span class="n">subset_train</span><span class="p">)</span>',
          '<span class="n">validatation_dataset</span> <span class="o">=</span> <span class="n">ReviewsDataset</span><span class="p">(</span><span class="n">subset_validation</span><span class="p">)</span>',
          '<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">ReviewsDataset</span><span class="p">(</span><span class="n">subset_test</span><span class="p">)</span>',
          '</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">at_mask</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>',
          '<span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">at_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">label</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '(torch.Size([768]), torch.Size([768]), 0)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Pytorch-Dataloader">Pytorch Dataloader<a class="anchor-link" href="#Pytorch-Dataloader"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 25" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Creamos ahora un dataloader de pytorch</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
      '      ',
      '      <span class="n">BS</span> <span class="o">=</span> <span class="mi">12</span>',
      '      ',
      '      <span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
      '      <span class="n">validation_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">validatation_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">)</span>',
      '      <span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>












      
      <section class="section-block-markdown-cell">
      <p>Vamos a ver una muestra</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">12</span>',
          '',
          '<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '<span class="n">validation_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">validatation_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">)</span>',
          '<span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">)</span>',
          '</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">at_mask</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_loader</span><span class="p">))</span>',
          '<span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">at_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">labels</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '(torch.Size([12, 768]),',
          ' torch.Size([12, 768]),',
          ' tensor([2, 1, 2, 0, 3, 3, 0, 4, 3, 3, 4, 2]))',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Para ver que est谩 todo bien pasamos la muestra al modelo para ver qu茅 sale todo bien. Primero pasamos los tokens al dispositivo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '      <span class="n">at_mask</span> <span class="o">=</span> <span class="n">at_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '      <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>








      
      <section class="section-block-markdown-cell">
      <p>Ahora se los pasamos al modelo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '<span class="n">at_mask</span> <span class="o">=</span> <span class="n">at_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '<span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '</span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">at_mask</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '<span class="n">output</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'odict_keys([\'loss\', \'logits\', \'past_key_values\'])',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Como vemos nos da la loss y los logits</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">output</span><span class="p">[</span><span class="s1">\'loss\'</span><span class="p">]</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'tensor(5.9414, device=\'cuda:0\', dtype=torch.float16,',
          '       grad_fn=&lt;NllLossBackward0&gt;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">output</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">]</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'tensor([[ 6.1953e+00, -1.2275e+00, -2.4824e+00,  5.8867e+00, -1.4734e+01],',
          '        [ 5.4062e+00, -8.4570e-01, -2.3203e+00,  5.1055e+00, -1.1555e+01],',
          '        [ 6.1641e+00, -9.3066e-01, -2.5664e+00,  6.0039e+00, -1.4570e+01],',
          '        [ 5.2266e+00, -4.2358e-01, -2.0801e+00,  4.7461e+00, -1.1570e+01],',
          '        [ 3.8184e+00, -2.3460e-03, -1.7666e+00,  3.4160e+00, -7.7969e+00],',
          '        [ 4.1641e+00, -4.8169e-01, -1.6914e+00,  3.9941e+00, -8.7734e+00],',
          '        [ 4.6758e+00, -3.0298e-01, -2.1641e+00,  4.1055e+00, -9.3359e+00],',
          '        [ 4.1953e+00, -3.2471e-01, -2.1875e+00,  3.9375e+00, -8.3438e+00],',
          '        [-1.1650e+00,  1.3564e+00, -6.2158e-01, -6.8115e-01,  4.8672e+00],',
          '        [ 4.4961e+00, -8.7891e-02, -2.2793e+00,  4.2812e+00, -9.3359e+00],',
          '        [ 4.9336e+00, -2.6627e-03, -2.1543e+00,  4.3711e+00, -1.0742e+01],',
          '        [ 5.9727e+00, -4.3152e-02, -1.4551e+00,  4.3438e+00, -1.2117e+01]],',
          '       device=\'cuda:0\', dtype=torch.float16, grad_fn=&lt;IndexBackward0&gt;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="M%C3%A9trica">M茅trica<a class="anchor-link" href="#M%C3%A9trica"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 26" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a crear una funci贸n para obtener la m茅trica, que en este c谩so va a ser el accuracy</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">def</span> <span class="nf">predicted_labels</span><span class="p">(</span><span class="n">logits</span><span class="p">):</span>',
      '          <span class="n">percent</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
      '          <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">percent</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
      '          <span class="k">return</span> <span class="n">predictions</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>









      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">def</span> <span class="nf">predicted_labels</span><span class="p">(</span><span class="n">logits</span><span class="p">):</span>',
      '          <span class="n">percent</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
      '          <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">percent</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
      '          <span class="k">return</span> <span class="n">predictions</span>',
      '<span></span><span class="k">def</span> <span class="nf">compute_accuracy</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>',
      '          <span class="n">predictions</span> <span class="o">=</span> <span class="n">predicted_labels</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>',
      '          <span class="n">correct</span> <span class="o">=</span> <span class="p">(</span><span class="n">predictions</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>',
      '          <span class="k">return</span> <span class="n">correct</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>









      
      <section class="section-block-markdown-cell">
      <p>Vamos a ver si lo calcula bien</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="k">def</span> <span class="nf">predicted_labels</span><span class="p">(</span><span class="n">logits</span><span class="p">):</span>',
          '    <span class="n">percent</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
          '    <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">percent</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
          '    <span class="k">return</span> <span class="n">predictions</span>',
          '</span><span class="k">def</span> <span class="nf">compute_accuracy</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>',
          '    <span class="n">predictions</span> <span class="o">=</span> <span class="n">predicted_labels</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>',
          '    <span class="n">correct</span> <span class="o">=</span> <span class="p">(</span><span class="n">predictions</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>',
          '    <span class="k">return</span> <span class="n">correct</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>',
          '</span><span class="n">compute_accuracy</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '0.1666666716337204',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Optimizador">Optimizador<a class="anchor-link" href="#Optimizador"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 27" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Como vamos a necesitar un optimizador, creamos uno</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AdamW</span>',
          '',
          '<span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">LR</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning',
          '  warnings.warn(',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Entrenamiento">Entrenamiento<a class="anchor-link" href="#Entrenamiento"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 28" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Creamos el bucle de entrenamiento</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>',
          '',
          '<span class="n">accuracy</span> <span class="o">=</span> <span class="mi">0</span>',
          '',
          '<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">train_loss</span> <span class="o">=</span> <span class="mi">0</span>',
          '    <span class="n">progresbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s1">\'Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s1">\'</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">at_mask</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">progresbar</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '        <span class="n">at_mask</span> <span class="o">=</span> <span class="n">at_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '        <span class="n">label</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '',
          '        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">at_mask</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>',
          '',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="s1">\'loss\'</span><span class="p">]</span>',
          '        <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '        <span class="n">progresbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">({</span><span class="s1">\'train_loss\'</span><span class="p">:</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()})</span>',
          '    <span class="n">train_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>',
          '    <span class="n">progresbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">({</span><span class="s1">\'train_loss\'</span><span class="p">:</span> <span class="n">train_loss</span><span class="p">})</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">valid_loss</span> <span class="o">=</span> <span class="mi">0</span>',
          '    <span class="n">progresbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">validation_loader</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">validation_loader</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s1">\'Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s1">\'</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">at_mask</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">progresbar</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '        <span class="n">at_mask</span> <span class="o">=</span> <span class="n">at_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '',
          '        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">at_mask</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="s1">\'loss\'</span><span class="p">]</span>',
          '        <span class="n">valid_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>',
          '',
          '        <span class="n">step_accuracy</span> <span class="o">=</span> <span class="n">compute_accuracy</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '        <span class="n">accuracy</span> <span class="o">+=</span> <span class="n">step_accuracy</span>',
          '        <span class="n">progresbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">({</span><span class="s1">\'valid_loss\'</span><span class="p">:</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="s1">\'accuracy\'</span><span class="p">:</span> <span class="n">step_accuracy</span><span class="o">.</span><span class="n">item</span><span class="p">()})</span>',
          '',
          '    <span class="n">valid_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">validation_loader</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">validation_loader</span><span class="p">)</span>',
          '    <span class="n">progresbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">({</span><span class="s1">\'valid_loss\'</span><span class="p">:</span> <span class="n">valid_loss</span><span class="p">,</span> <span class="s1">\'accuracy\'</span><span class="p">:</span> <span class="n">accuracy</span><span class="p">})</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Epoch 1: 100%|| 16667/16667 [44:13&lt;00:00,  6.28it/s, train_loss=nan]',
          'Epoch 1: 100%|| 417/417 [00:32&lt;00:00, 12.72it/s, valid_loss=nan, accuracy=0]',
          'Epoch 2: 100%|| 16667/16667 [44:06&lt;00:00,  6.30it/s, train_loss=nan]',
          'Epoch 2: 100%|| 417/417 [00:32&lt;00:00, 12.77it/s, valid_loss=nan, accuracy=0]',
          'Epoch 3: 100%|| 16667/16667 [44:03&lt;00:00,  6.30it/s, train_loss=nan]',
          'Epoch 3: 100%|| 417/417 [00:32&lt;00:00, 12.86it/s, valid_loss=nan, accuracy=0]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Uso-del-modelo">Uso del modelo<a class="anchor-link" href="#Uso-del-modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 29" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a probar el modelo que hemos entrenado</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Primero tokenizamos un texto</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">input_tokens</span> <span class="o">=</span> <span class="n">tokenize_function</span><span class="p">({</span><span class="s2">"text"</span><span class="p">:</span> <span class="s2">"I love this product. It is amazing."</span><span class="p">})</span>',
          '<span class="n">input_tokens</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">input_tokens</span><span class="p">[</span><span class="s1">\'attention_mask\'</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '(torch.Size([1, 768]), torch.Size([1, 768]))',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Ahora se lo pasamos al modelo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_tokens</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">input_tokens</span><span class="p">[</span><span class="s1">\'attention_mask\'</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>',
          '<span class="n">output</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">]</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'tensor([[nan, nan, nan, nan, nan]], device=\'cuda:0\', dtype=torch.float16,',
          '       grad_fn=&lt;IndexBackward0&gt;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos las predicciones de esos logits</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">predicted</span> <span class="o">=</span> <span class="n">predicted_labels</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">])</span>',
          '<span class="n">predicted</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'tensor([0], device=\'cuda:0\')',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h2 id="Fine-tuning-para-generaci%C3%B3n-de-texto-con-Pytorch">Fine tuning para generaci贸n de texto con Pytorch<a class="anchor-link" href="#Fine-tuning-para-generaci%C3%B3n-de-texto-con-Pytorch"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 30" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Repetimos el entrenamiento con Pytorch</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Reiniciamos el notebook para asegurarnos</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Dataset">Dataset<a class="anchor-link" href="#Dataset"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 31" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Volvemos a descargar el dataset de chistes</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '',
          '<span class="n">jokes</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"Maximofn/short-jokes-dataset"</span><span class="p">)</span>',
          '<span class="n">jokes</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'DatasetDict({',
          '    train: Dataset({',
          '        features: [\'ID\', \'Joke\'],',
          '        num_rows: 231657',
          '    })',
          '})',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Creamos un subset por si se tiene poca memoria</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">percent_of_train_dataset</span> <span class="o">=</span> <span class="mi">1</span>    <span class="c1"># If you want 50% of the dataset, set this to 0.5</span>',
          '',
          '<span class="n">subset_dataset</span> <span class="o">=</span> <span class="n">jokes</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">jokes</span><span class="p">[</span><span class="s2">"train"</span><span class="p">])</span> <span class="o">*</span> <span class="n">percent_of_train_dataset</span><span class="p">)))</span>',
          '<span class="n">subset_dataset</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Dataset({',
          '    features: [\'ID\', \'Joke\'],',
          '    num_rows: 231657',
          '})',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Dividimos el dataset en subsets de entrenamiento, validaci贸n y test</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">percent_of_train_dataset</span> <span class="o">=</span> <span class="mf">0.90</span>',
          '',
          '<span class="n">split_dataset</span> <span class="o">=</span> <span class="n">subset_dataset</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">train_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">subset_dataset</span><span class="o">.</span><span class="n">num_rows</span> <span class="o">*</span> <span class="n">percent_of_train_dataset</span><span class="p">),</span> <span class="n">seed</span><span class="o">=</span><span class="mi">19</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>',
          '<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span>',
          '<span class="n">validation_test_dataset</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span>',
          '',
          '<span class="n">split_dataset</span> <span class="o">=</span> <span class="n">validation_test_dataset</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">train_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">validation_test_dataset</span><span class="o">.</span><span class="n">num_rows</span> <span class="o">*</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">seed</span><span class="o">=</span><span class="mi">19</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>',
          '<span class="n">validation_dataset</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span>',
          '<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span>',
          '',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Size of the train set: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">. Size of the validation set: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">validation_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">. Size of the test set: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Size of the train set: 208491. Size of the validation set: 11583. Size of the test set: 11583',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Tokenizador">Tokenizador<a class="anchor-link" href="#Tokenizador"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 32" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Iniciamos el tokenizador y asignamos al token de padding el de end of string</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>',
      '      ',
      '      <span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"openai-community/gpt2"</span>',
      '      ',
      '      <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '      <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>',
      '      <span class="n">tokenizer</span><span class="o">.</span><span class="n">padding_side</span> <span class="o">=</span> <span class="s2">"right"</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>












      
      <section class="section-block-markdown-cell">
      <p>A帽adimos los tokens especiales de inicio de chiste y fin de chiste</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"openai-community/gpt2"</span>',
          '',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>',
          '<span class="n">tokenizer</span><span class="o">.</span><span class="n">padding_side</span> <span class="o">=</span> <span class="s2">"right"</span>',
          '</span><span class="n">new_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="s1">\'&lt;SJ&gt;\'</span><span class="p">,</span> <span class="s1">\'&lt;EJ&gt;\'</span><span class="p">]</span>   <span class="c1"># Start and end of joke tokens</span>',
          '',
          '<span class="n">num_added_tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">add_tokens</span><span class="p">(</span><span class="n">new_tokens</span><span class="p">)</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Added </span><span class="si">{</span><span class="n">num_added_tokens</span><span class="si">}</span><span class="s2"> tokens"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Added 2 tokens',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Los a帽adimos al dataset</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">joke_column</span> <span class="o">=</span> <span class="s2">"Joke"</span>',
          '',
          '<span class="k">def</span> <span class="nf">format_joke</span><span class="p">(</span><span class="n">example</span><span class="p">):</span>',
          '    <span class="n">example</span><span class="p">[</span><span class="n">joke_column</span><span class="p">]</span> <span class="o">=</span> <span class="s1">\'&lt;SJ&gt; \'</span> <span class="o">+</span> <span class="n">example</span><span class="p">[</span><span class="s1">\'Joke\'</span><span class="p">]</span> <span class="o">+</span> <span class="s1">\' &lt;EJ&gt;\'</span>',
          '    <span class="k">return</span> <span class="n">example</span>',
          '',
          '<span class="n">remove_columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">column</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">column_names</span> <span class="k">if</span> <span class="n">column</span> <span class="o">!=</span> <span class="n">joke_column</span><span class="p">]</span>',
          '',
          '<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">format_joke</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="n">remove_columns</span><span class="p">)</span>',
          '<span class="n">validation_dataset</span> <span class="o">=</span> <span class="n">validation_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">format_joke</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="n">remove_columns</span><span class="p">)</span>',
          '<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">format_joke</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="n">remove_columns</span><span class="p">)</span>',
          '<span class="n">train_dataset</span><span class="p">,</span> <span class="n">validation_dataset</span><span class="p">,</span> <span class="n">test_dataset</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '(Dataset({',
          '     features: [\'Joke\'],',
          '     num_rows: 208491',
          ' }),',
          ' Dataset({',
          '     features: [\'Joke\'],',
          '     num_rows: 11583',
          ' }),',
          ' Dataset({',
          '     features: [\'Joke\'],',
          '     num_rows: 11583',
          ' }))',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Tokenizamos el dataset</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="n">joke_column</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '',
          '<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="n">joke_column</span><span class="p">])</span>',
          '<span class="n">validation_dataset</span> <span class="o">=</span> <span class="n">validation_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="n">joke_column</span><span class="p">])</span>',
          '<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="n">joke_column</span><span class="p">])</span>',
          '<span class="n">train_dataset</span><span class="p">,</span> <span class="n">validation_dataset</span><span class="p">,</span> <span class="n">test_dataset</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '(Dataset({',
          '     features: [\'input_ids\', \'attention_mask\'],',
          '     num_rows: 208491',
          ' }),',
          ' Dataset({',
          '     features: [\'input_ids\', \'attention_mask\'],',
          '     num_rows: 11583',
          ' }),',
          ' Dataset({',
          '     features: [\'input_ids\', \'attention_mask\'],',
          '     num_rows: 11583',
          ' }))',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Modelo">Modelo<a class="anchor-link" href="#Modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 33" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Instanciamos el modelo, asignamos el token de padding y a帽adimos los nuevos tokens de inicion de chiste y fin de chiste</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForCausalLM</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">resize_token_embeddings</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">))</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Embedding(50259, 768)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Device">Device<a class="anchor-link" href="#Device"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 34" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Creamos el dispositivo y pasamos el modelo al dispositivo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
          '',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">\'cuda\'</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">\'cpu\'</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">half</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '<span class="nb">print</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Pytorch-Dataset">Pytorch Dataset<a class="anchor-link" href="#Pytorch-Dataset"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 35" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Creamos un dataset de pytorch</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>',
      '      ',
      '      <span class="k">class</span> <span class="nc">JokesDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>',
      '          <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">huggingface_dataset</span><span class="p">):</span>',
      '              <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">huggingface_dataset</span>',
      '      ',
      '          <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>',
      '              <span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">\'input_ids\'</span><span class="p">])</span>',
      '              <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">\'attention_mask\'</span><span class="p">])</span>',
      '              <span class="k">return</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span>',
      '      ',
      '          <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>',
      '              <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>


















      
      <section class="section-block-markdown-cell">
      <p>Instanciamos los datasets de entrenamiento, validaci贸n y test</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>',
      '      ',
      '      <span class="k">class</span> <span class="nc">JokesDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>',
      '          <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">huggingface_dataset</span><span class="p">):</span>',
      '              <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">huggingface_dataset</span>',
      '      ',
      '          <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>',
      '              <span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">\'input_ids\'</span><span class="p">])</span>',
      '              <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">\'attention_mask\'</span><span class="p">])</span>',
      '              <span class="k">return</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span>',
      '      ',
      '          <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>',
      '              <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>',
      '<span></span><span class="n">train_pytorch_dataset</span> <span class="o">=</span> <span class="n">JokesDataset</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span>',
      '      <span class="n">validation_pytorch_dataset</span> <span class="o">=</span> <span class="n">JokesDataset</span><span class="p">(</span><span class="n">validation_dataset</span><span class="p">)</span>',
      '      <span class="n">test_pytorch_dataset</span> <span class="o">=</span> <span class="n">JokesDataset</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>








      
      <section class="section-block-markdown-cell">
      <p>Veamos una muestra</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>',
          '',
          '<span class="k">class</span> <span class="nc">JokesDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>',
          '    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">huggingface_dataset</span><span class="p">):</span>',
          '        <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">huggingface_dataset</span>',
          '',
          '    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">\'input_ids\'</span><span class="p">])</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '        <span class="k">return</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span>',
          '',
          '    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>',
          '        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>',
          '</span><span class="n">train_pytorch_dataset</span> <span class="o">=</span> <span class="n">JokesDataset</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span>',
          '<span class="n">validation_pytorch_dataset</span> <span class="o">=</span> <span class="n">JokesDataset</span><span class="p">(</span><span class="n">validation_dataset</span><span class="p">)</span>',
          '<span class="n">test_pytorch_dataset</span> <span class="o">=</span> <span class="n">JokesDataset</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span>',
          '</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">train_pytorch_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>',
          '<span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">shape</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '(torch.Size([768]), torch.Size([768]))',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Pytorch-Dataloader">Pytorch Dataloader<a class="anchor-link" href="#Pytorch-Dataloader"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 36" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Creamos los dataloaders</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
      '      ',
      '      <span class="n">BS</span> <span class="o">=</span> <span class="mi">28</span>',
      '      ',
      '      <span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_pytorch_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
      '      <span class="n">validation_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">validation_pytorch_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">)</span>',
      '      <span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_pytorch_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>












      
      <section class="section-block-markdown-cell">
      <p>Vemos una muestra</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">28</span>',
          '',
          '<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_pytorch_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '<span class="n">validation_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">validation_pytorch_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">)</span>',
          '<span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_pytorch_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">)</span>',
          '</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_loader</span><span class="p">))</span>',
          '<span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">shape</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '(torch.Size([28, 768]), torch.Size([28, 768]))',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Se lo pasamos al modelo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>',
          '<span class="n">output</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'odict_keys([\'logits\', \'past_key_values\'])',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Como vemos no tenemos valor de <code>loss</code>, como hemos visto tenemos que pasarle el <code>input_ids</code> y el <code>labels</code></p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">=</span><span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>',
          '<span class="n">output</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'odict_keys([\'loss\', \'logits\', \'past_key_values\'])',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Ahora s铆 tenemos <code>loss</code></p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">output</span><span class="p">[</span><span class="s1">\'loss\'</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '80.5625',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Optimizador">Optimizador<a class="anchor-link" href="#Optimizador"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 37" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Creamos un optimizador</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AdamW</span>',
          '',
          '<span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-5</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning',
          '  warnings.warn(',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Entrenamiento">Entrenamiento<a class="anchor-link" href="#Entrenamiento"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 38" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Creamos el bucle de entrenamiento</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>',
          '',
          '<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">train_loss</span> <span class="o">=</span> <span class="mi">0</span>',
          '    <span class="n">progresbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s1">\'Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s1">\'</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">at_mask</span> <span class="ow">in</span> <span class="n">progresbar</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '        <span class="n">at_mask</span> <span class="o">=</span> <span class="n">at_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '',
          '        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">at_mask</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">input_ids</span><span class="p">)</span>',
          '',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="s1">\'loss\'</span><span class="p">]</span>',
          '        <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '        <span class="n">progresbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">({</span><span class="s1">\'train_loss\'</span><span class="p">:</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()})</span>',
          '    <span class="n">train_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>',
          '    <span class="n">progresbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">({</span><span class="s1">\'train_loss\'</span><span class="p">:</span> <span class="n">train_loss</span><span class="p">})</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Epoch 1: 100%|| 7447/7447 [51:07&lt;00:00,  2.43it/s, train_loss=nan]',
          'Epoch 2: 100%|| 7447/7447 [51:06&lt;00:00,  2.43it/s, train_loss=nan]',
          'Epoch 3: 100%|| 7447/7447 [51:07&lt;00:00,  2.43it/s, train_loss=nan]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Uso-del-modelo">Uso del modelo<a class="anchor-link" href="#Uso-del-modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 39" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Probamos el modelo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">def</span> <span class="nf">generate_text</span><span class="p">(</span><span class="n">decoded_joke</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">stop_token</span><span class="o">=</span><span class="s1">\'&lt;EJ&gt;\'</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>',
      '          <span class="n">input_tokens</span> <span class="o">=</span> <span class="n">tokenize_function</span><span class="p">({</span><span class="s1">\'Joke\'</span><span class="p">:</span> <span class="n">decoded_joke</span><span class="p">})</span>',
      '          <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_tokens</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">input_tokens</span><span class="p">[</span><span class="s1">\'attention_mask\'</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>',
      '          <span class="n">nex_token</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">][:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>',
      '          <span class="n">nex_token_decoded</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">nex_token</span><span class="p">)</span>',
      '          <span class="n">decoded_joke</span> <span class="o">=</span> <span class="n">decoded_joke</span> <span class="o">+</span> <span class="n">nex_token_decoded</span>',
      '          <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_new_tokens</span><span class="p">):</span>',
      '              <span class="n">nex_token</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">][:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>',
      '              <span class="n">nex_token_decoded</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">nex_token</span><span class="p">)</span>',
      '              <span class="k">if</span> <span class="n">nex_token_decoded</span> <span class="o">==</span> <span class="n">stop_token</span><span class="p">:</span>',
      '                  <span class="k">break</span>',
      '              <span class="n">decoded_joke</span> <span class="o">=</span> <span class="n">decoded_joke</span> <span class="o">+</span> <span class="n">nex_token_decoded</span>',
      '              <span class="n">input_tokens</span> <span class="o">=</span> <span class="n">tokenize_function</span><span class="p">({</span><span class="s1">\'Joke\'</span><span class="p">:</span> <span class="n">decoded_joke</span><span class="p">})</span>',
      '              <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_tokens</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">input_tokens</span><span class="p">[</span><span class="s1">\'attention_mask\'</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>',
      '          <span class="k">return</span> <span class="n">decoded_joke</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>




















      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="k">def</span> <span class="nf">generate_text</span><span class="p">(</span><span class="n">decoded_joke</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">stop_token</span><span class="o">=</span><span class="s1">\'&lt;EJ&gt;\'</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>',
          '    <span class="n">input_tokens</span> <span class="o">=</span> <span class="n">tokenize_function</span><span class="p">({</span><span class="s1">\'Joke\'</span><span class="p">:</span> <span class="n">decoded_joke</span><span class="p">})</span>',
          '    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_tokens</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">input_tokens</span><span class="p">[</span><span class="s1">\'attention_mask\'</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>',
          '    <span class="n">nex_token</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">][:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>',
          '    <span class="n">nex_token_decoded</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">nex_token</span><span class="p">)</span>',
          '    <span class="n">decoded_joke</span> <span class="o">=</span> <span class="n">decoded_joke</span> <span class="o">+</span> <span class="n">nex_token_decoded</span>',
          '    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_new_tokens</span><span class="p">):</span>',
          '        <span class="n">nex_token</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">][:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>',
          '        <span class="n">nex_token_decoded</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">nex_token</span><span class="p">)</span>',
          '        <span class="k">if</span> <span class="n">nex_token_decoded</span> <span class="o">==</span> <span class="n">stop_token</span><span class="p">:</span>',
          '            <span class="k">break</span>',
          '        <span class="n">decoded_joke</span> <span class="o">=</span> <span class="n">decoded_joke</span> <span class="o">+</span> <span class="n">nex_token_decoded</span>',
          '        <span class="n">input_tokens</span> <span class="o">=</span> <span class="n">tokenize_function</span><span class="p">({</span><span class="s1">\'Joke\'</span><span class="p">:</span> <span class="n">decoded_joke</span><span class="p">})</span>',
          '        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_tokens</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">input_tokens</span><span class="p">[</span><span class="s1">\'attention_mask\'</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>',
          '    <span class="k">return</span> <span class="n">decoded_joke</span>',
          '</span><span class="n">generated_text</span> <span class="o">=</span> <span class="n">generate_text</span><span class="p">(</span><span class="s2">"&lt;SJ&gt; Why didn\'t the frog cross the road"</span><span class="p">)</span>',
          '<span class="n">generated_text</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '"&lt;SJ&gt; Why didn\'t the frog cross the road!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      






    </div>

  </section>

</PostLayout>
