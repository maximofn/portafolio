---
import PostLayout from '@layouts/PostLayout.astro';
import CodeBlockInputCell from '@components/CodeBlockInputCell.astro';
import CodeBlockOutputCell from '@components/CodeBlockOutputCell.astro';

const { metadata_page } = await import('@portfolio/consts.json');
const { colors } = await import('@portfolio/consts.json');
const { svg_paths } = await import('@portfolio/consts.json');

const page_title = 'HuggingFace Accelerate';
const end_url = 'hugging-face-accelerate/';
const description = 'Acelera tus entrenos con HuggingFace Accelerate';
const keywords = 'hugging face, accelerate, pytorch, deep learning, machine learning, transformers';
const languaje = 'ES';
const image_path = 'https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/huggingface_accelerate.webp';
const opening_brace = '{';
const closing_brace = '}';
---

<PostLayout 
    title={page_title}
    languaje={languaje}
    description={description}
    keywords={keywords}
    author={metadata_page.author}
    theme_color={colors.background_color}
    end_url={end_url}
    image_path={image_path}
    image_width=1280
    image_height=670
    image_extension=webp
    article_date=2024-05-16+T00:00:00Z
>

  <section class="post-body">


    <aside class="post-index">
      <a class="anchor-link" href="#Instalaci%C3%B3n"><h2>Instalaci贸n</h2></a>
      <a class="anchor-link" href="#Configuraci%C3%B3n"><h2>Configuraci贸n</h2></a>
      <a class="anchor-link" href="#Entrenamiento"><h2>Entrenamiento</h2></a>
      <a class="anchor-link" href="#Optimizaci%C3%B3n-del-entrenamiento"><h3>Optimizaci贸n del entrenamiento</h3></a>
      <a class="anchor-link" href="#C%C3%B3digo-base"><h4>C贸digo base</h4></a>
      <a class="anchor-link" href="#Script-con-el-c%C3%B3digo-base"><h4>Script con el c贸digo base</h4></a>
      <a class="anchor-link" href="#C%C3%B3digo-con-accelerate"><h4>C贸digo con accelerate</h4></a>
      <a class="anchor-link" href="#Ejecuci%C3%B3n-de-procesos"><h3>Ejecuci贸n de procesos</h3></a>
      <a class="anchor-link" href="#Ejecuci%C3%B3n-de-c%C3%B3digo-en-un-%C3%BAnico-proceso"><h4>Ejecuci贸n de c贸digo en un 煤nico proceso</h4></a>
      <a class="anchor-link" href="#Ejecuci%C3%B3n-de-c%C3%B3digo-en-todos-los-procesos"><h4>Ejecuci贸n de c贸digo en todos los procesos</h4></a>
      <a class="anchor-link" href="#Ejecuci%C3%B3n-de-c%C3%B3digo-en-el-proceso-X"><h4>Ejecuci贸n de c贸digo en el proceso X</h4></a>
      <a class="anchor-link" href="#Sincronizar-procesos"><h4>Sincronizar procesos</h4></a>
      <a class="anchor-link" href="#Guardar-y-cargar-el-state-dict"><h3>Guardar y cargar el state dict</h3></a>
      <a class="anchor-link" href="#Guardar-el-modelo"><h3>Guardar el modelo</h3></a>
      <a class="anchor-link" href="#Guardar-el-modelo-pretrained"><h3>Guardar el modelo <code>pretrained</code></h3></a>
      <a class="anchor-link" href="#Entrenamiento-en-notebooks"><h3>Entrenamiento en notebooks</h3></a>
      <a class="anchor-link" href="#Entrenamiento-en-FP16"><h3>Entrenamiento en FP16</h3></a>
      <a class="anchor-link" href="#Entrenamiento-en-BF16"><h3>Entrenamiento en BF16</h3></a>
      <a class="anchor-link" href="#Entrenamiento-en-FP8"><h3>Entrenamiento en FP8</h3></a>
      <a class="anchor-link" href="#Inferencia-de-modelos"><h2>Inferencia de modelos</h2></a>
      <a class="anchor-link" href="#Uso-del-ecosistema-de-Hugging-Face"><h3>Uso del ecosistema de Hugging Face</h3></a>
      <a class="anchor-link" href="#Inferencia-con-pipeline"><h4>Inferencia con <code>pipeline</code></h4></a>
      <a class="anchor-link" href="#Inferencia-con-AutoClass"><h4>Inferencia con <code>AutoClass</code></h4></a>
      <a class="anchor-link" href="#Uso-pytorch"><h3>Uso pytorch</h3></a>
      <a class="anchor-link" href="#C%C3%B3mo-funciona-accelerate-por-debajo"><h3>C贸mo funciona accelerate por debajo</h3></a>
      <a class="anchor-link" href="#Inicializaci%C3%B3n-de-un-modelo-vac%C3%ADo"><h4>Inicializaci贸n de un modelo vac铆o</h4></a>
      <a class="anchor-link" href="#Carga-de-los-pesos"><h4>Carga de los pesos</h4></a>
    </aside>


    <div class="post-body-content">
      
      <section class="section-block-markdown-cell">
      <h1 id="Hugging-Face-Accelerate">Hugging Face Accelerate<a class="anchor-link" href="#Hugging-Face-Accelerate"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 0" src={svg_paths.link_svg_path}/></a></h1>
      </section>
      
      <section class="section-block-markdown-cell">
      <p><code>Accelerate</code> es una biblioteca de Hugging Face que permite ejecutar el mismo c贸digo PyTorch en cualquier configuraci贸n distribuida a帽adiendo s贸lo cuatro l铆neas de c贸digo.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Instalaci%C3%B3n">Instalaci贸n<a class="anchor-link" href="#Instalaci%C3%B3n"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 1" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Para instalar <code>accelerate</code> con <code>pip</code> simplemente ejecuta:</p>
      <div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>accelerate
      </pre></div>
      <p>Y con <code>conda</code>:</p>
      <div class="highlight"><pre><span></span>conda<span class="w"> </span>install<span class="w"> </span>-c<span class="w"> </span>conda-forge<span class="w"> </span>accelerate
      </pre></div>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Configuraci%C3%B3n">Configuraci贸n<a class="anchor-link" href="#Configuraci%C3%B3n"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 2" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>En cada entorno en el que se intale <code>accelerate</code> lo primero que se tiene que hacer es configurarlo, para ello ejecutamos en una terminal:</p>
      <div class="highlight"><pre><span></span>accelerate<span class="w"> </span>config
      </pre></div>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">!</span>accelerate<span class="w"> </span>config',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '--------------------------------------------------------------------------------',
          'In which compute environment are you running?',
          'This machine',
          '--------------------------------------------------------------------------------',
          'multi-GPU',
          'How many different machines will you use (use more than 1 for multi-node training)? [1]: 1',
          'Should distributed operations be checked while running for errors? This can avoid timeout issues but will be slower. [yes/NO]: no',
          'Do you wish to optimize your script with torch dynamo?[yes/NO]:no',
          'Do you want to use DeepSpeed? [yes/NO]: no',
          'Do you want to use FullyShardedDataParallel? [yes/NO]: no',
          'Do you want to use Megatron-LM ? [yes/NO]: no',
          'How many GPU(s) should be used for distributed training? [1]:2',
          'What GPU(s) (by id) should be used for training on this machine as a comma-seperated list? [all]:0,1',
          '--------------------------------------------------------------------------------',
          'Do you wish to use FP16 or BF16 (mixed precision)?',
          'no',
          'accelerate configuration saved at ~/.cache/huggingface/accelerate/default_config.yaml',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>En mi caso las respuestas han sido</p>
      <ul>
      <li>In which compute environment are you running?<ul>
      <li class="task-list-item"><input checked="" class="task-list-item-checkbox" disabled="" type="checkbox"/>"This machine"</li>
      <li>[_] "AWS (Amazon SageMaker)"</li>
      </ul>
      </li>
      </ul>
      <blockquote>
      <p>Quiero configurarlo en mi ordenador</p>
      </blockquote>
      <ul>
      <li>Which type of machine are you using?<ul>
      <li>[_] multi-CPU</li>
      <li>[_] multi-XPU</li>
      <li class="task-list-item"><input checked="" class="task-list-item-checkbox" disabled="" type="checkbox"/>multi-GPU</li>
      <li>[_] multi-NPU</li>
      <li>[_] TPU</li>
      </ul>
      </li>
      </ul>
      <blockquote>
      <p>Como tengo 2 GPUs y quiero ejecutar c贸digos distribuidos en ellas elijo <code>multi-GPU</code></p>
      </blockquote>
      <ul>
      <li>How many different machines will you use (use more than 1 for multi-node training)? [1]:<ul>
      <li>1</li>
      </ul>
      </li>
      </ul>
      <blockquote>
      <p>Elijo <code>1</code> porque solo voy a ejecutar en mi ordenador</p>
      </blockquote>
      <ul>
      <li>Should distributed operations be checked while running for errors? This can avoid timeout issues but will be slower. [yes/NO]:<ul>
      <li>no</li>
      </ul>
      </li>
      </ul>
      <blockquote>
      <p>Con esta opci贸n, se puede elegir que <code>accelerate</code> chequee errores en la ejecuci贸n, pero har铆a que vaya m谩s lento, as铆 que elijo <code>no</code>, y en caso de que haya errores lo cambio a <code>yes</code></p>
      </blockquote>
      <ul>
      <li><p>Do you wish to optimize your script with torch dynamo?[yes/NO]:</p>
      <ul>
      <li>no</li>
      </ul>
      </li>
      <li><p>Do you want to use FullyShardedDataParallel? [yes/NO]:</p>
      <ul>
      <li>no</li>
      </ul>
      </li>
      <li><p>Do you want to use Megatron-LM ? [yes/NO]:</p>
      <ul>
      <li>no</li>
      </ul>
      </li>
      <li><p>How many GPU(s) should be used for distributed training? [1]:</p>
      <ul>
      <li>2</li>
      </ul>
      </li>
      </ul>
      <blockquote>
      <p>Elijo <code>2</code> porque tengo 2 GPUs</p>
      </blockquote>
      <ul>
      <li>What GPU(s) (by id) should be used for training on this machine as a comma-seperated list? [all]:<ul>
      <li>0,1</li>
      </ul>
      </li>
      </ul>
      <blockquote>
      <p>Elijo <code>0,1</code> porque quiero usar las dos GPUs</p>
      </blockquote>
      <ul>
      <li>Do you wish to use FP16 or BF16 (mixed precision)?<ul>
      <li class="task-list-item"><input checked="" class="task-list-item-checkbox" disabled="" type="checkbox"/>no</li>
      <li>[_] fp16</li>
      <li>[_] bf16</li>
      <li>[_] fp8</li>
      </ul>
      </li>
      </ul>
      <blockquote>
      <p>De momento elijo <code>no</code>, porque para simplificar el c贸digo cuando no uso <code>acelerate</code> vamos a entrenar en fp32, pero lo ideal ser铆a usar fp16</p>
      </blockquote>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>La configuraci贸n se guardar谩 en <code>~/.cache/huggingface/accelerate/default_config.yaml</code> y se puede modificar en cualquier momento. Vamos a ver qu茅 hay dentro</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">!</span>cat<span class="w"> </span>~/.cache/huggingface/accelerate/default_config.yaml',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'compute_environment: LOCAL_MACHINE',
          'debug: false',
          'distributed_type: MULTI_GPU',
          'downcast_bf16: \'no\'',
          'gpu_ids: 0,1',
          'machine_rank: 0',
          'main_training_function: main',
          'mixed_precision: fp16',
          'num_machines: 1',
          'num_processes: 2',
          'rdzv_backend: static',
          'same_network: true',
          'tpu_env: []',
          'tpu_use_cluster: false',
          'tpu_use_sudo: false',
          'use_cpu: false',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Otra forma de ver la configuraci贸n que tenemos es ejecutando en una terminal:</p>
      <div class="highlight"><pre><span></span>accelerate<span class="w"> </span>env
      </pre></div>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">!</span>accelerate<span class="w"> </span>env',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Copy-and-paste the text below in your GitHub issue',
          '- `Accelerate` version: 0.28.0',
          '- Platform: Linux-5.15.0-105-generic-x86_64-with-glibc2.31',
          '- Python version: 3.11.8',
          '- Numpy version: 1.26.4',
          '- PyTorch version (GPU?): 2.2.1+cu121 (True)',
          '- PyTorch XPU available: False',
          '- PyTorch NPU available: False',
          '- System RAM: 31.24 GB',
          '- GPU type: NVIDIA GeForce RTX 3090',
          '- `Accelerate` default config:',
          '	- compute_environment: LOCAL_MACHINE',
          '	- distributed_type: MULTI_GPU',
          '	- mixed_precision: fp16',
          '	- use_cpu: False',
          '	- debug: False',
          '	- num_processes: 2',
          '	- machine_rank: 0',
          '	- num_machines: 1',
          '	- gpu_ids: 0,1',
          '	- rdzv_backend: static',
          '	- same_network: True',
          '	- main_training_function: main',
          '	- downcast_bf16: no',
          '	- tpu_use_cluster: False',
          '	- tpu_use_sudo: False',
          '	- tpu_env: []',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Una vez hemos configurado <code>accelerate</code> podemos probar si lo hemos hecho bien ejecutando en una terminal:</p>
      <div class="highlight"><pre><span></span>accelerate<span class="w"> </span><span class="nb">test</span>
      </pre></div>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">!</span>accelerate<span class="w"> </span>test',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Running:  accelerate-launch ~/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/test_utils/scripts/test_script.py',
          'stdout: **Initialization**',
          'stdout: Testing, testing. 1, 2, 3.',
          'stdout: Distributed environment: DistributedType.MULTI_GPU  Backend: nccl',
          'stdout: Num processes: 2',
          'stdout: Process index: 0',
          'stdout: Local process index: 0',
          'stdout: Device: cuda:0',
          'stdout: ',
          'stdout: Mixed precision type: fp16',
          'stdout: ',
          'stdout: Distributed environment: DistributedType.MULTI_GPU  Backend: nccl',
          'stdout: Num processes: 2',
          'stdout: Process index: 1',
          'stdout: Local process index: 1',
          'stdout: Device: cuda:1',
          'stdout: ',
          'stdout: Mixed precision type: fp16',
          'stdout: ',
          'stdout: ',
          'stdout: **Test process execution**',
          'stdout: ',
          'stdout: **Test split between processes as a list**',
          'stdout: ',
          'stdout: **Test split between processes as a dict**',
          'stdout: ',
          'stdout: **Test split between processes as a tensor**',
          'stdout: ',
          'stdout: **Test random number generator synchronization**',
          'stdout: All rng are properly synched.',
          'stdout: ',
          'stdout: **DataLoader integration test**',
          'stdout: 0 1 tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,',
          'stdout:         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,',
          'stdout:         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,',
          'stdout:         54, 55, 56, 57, 58, 59, 60, 61, 62, 63], device=\'cuda:1\') &lt;class \'accelerate.data_loader.DataLoaderShard\'&gt;',
          'stdout: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,',
          'stdout:         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,',
          'stdout:         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,',
          'stdout:         54, 55, 56, 57, 58, 59, 60, 61, 62, 63], device=\'cuda:0\') &lt;class \'accelerate.data_loader.DataLoaderShard\'&gt;',
          'stdout: Non-shuffled dataloader passing.',
          'stdout: Shuffled dataloader passing.',
          'stdout: Non-shuffled central dataloader passing.',
          'stdout: Shuffled central dataloader passing.',
          'stdout: ',
          'stdout: **Training integration test**',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Training yielded the same results on one CPU or distributed setup with no batch split.',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Training yielded the same results on one CPU or distributes setup with batch split.',
          'stdout: FP16 training check.',
          'stdout: FP16 training check.',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Keep fp32 wrapper check.',
          'stdout: Keep fp32 wrapper check.',
          'stdout: BF16 training check.',
          'stdout: BF16 training check.',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: ',
          'stdout: Training yielded the same results on one CPU or distributed setup with no batch split.',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: FP16 training check.',
          'stdout: Training yielded the same results on one CPU or distributes setup with batch split.',
          'stdout: FP16 training check.',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Keep fp32 wrapper check.',
          'stdout: Keep fp32 wrapper check.',
          'stdout: BF16 training check.',
          'stdout: BF16 training check.',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: ',
          'stdout: **Breakpoint trigger test**',
          'Test is a success! You are ready for your distributed training!',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos que termina diciendo <code>Test is a success! You are ready for your distributed training!</code> por lo que todo est谩 correcto.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Entrenamiento">Entrenamiento<a class="anchor-link" href="#Entrenamiento"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 3" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Optimizaci%C3%B3n-del-entrenamiento">Optimizaci贸n del entrenamiento<a class="anchor-link" href="#Optimizaci%C3%B3n-del-entrenamiento"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 4" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <h4 id="C%C3%B3digo-base">C贸digo base<a class="anchor-link" href="#C%C3%B3digo-base"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 5" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a hacer primero un c贸digo de entrenamiento base y luego lo optimizaremos  para ver c贸mo se hace y c贸mo mejora</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Primero vamos a buscar un dataset, en mi caso voy a usar el dataset <a href="https://huggingface.co/datasets/tweet_eval" target="_blank" rel="nofollow noreferrer">tweet_eval</a>, que es un dataset de clasificaci贸n de tweets, en concreto voy a descargar el subset <code>emoji</code> que clasifica los tweets con emoticonos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">dataset</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'DatasetDict({',
          '    train: Dataset({',
          '        features: [\'text\', \'label\'],',
          '        num_rows: 45000',
          '    })',
          '    test: Dataset({',
          '        features: [\'text\', \'label\'],',
          '        num_rows: 50000',
          '    })',
          '    validation: Dataset({',
          '        features: [\'text\', \'label\'],',
          '        num_rows: 5000',
          '    })',
          '})',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'DatasetInfo(description=\'\', citation=\'\', homepage=\'\', license=\'\', features={\'text\': Value(dtype=\'string\', id=None), \'label\': ClassLabel(names=[\'\', \'\', \'\', \'\', \'\', \'\', \'\', \'\', \'\', \'\', \'\', \'吼\', \'\', \'\', \'\', \'\', \'\', \'\', \'\', \'\'], id=None)}, post_processed=None, supervised_keys=None, task_templates=None, builder_name=\'parquet\', dataset_name=\'tweet_eval\', config_name=\'emoji\', version=0.0.0, splits={\'train\': SplitInfo(name=\'train\', num_bytes=3808792, num_examples=45000, shard_lengths=None, dataset_name=\'tweet_eval\'), \'test\': SplitInfo(name=\'test\', num_bytes=4262151, num_examples=50000, shard_lengths=None, dataset_name=\'tweet_eval\'), \'validation\': SplitInfo(name=\'validation\', num_bytes=396704, num_examples=5000, shard_lengths=None, dataset_name=\'tweet_eval\')}, download_checksums={\'hf://datasets/tweet_eval@b3a375baf0f409c77e6bc7aa35102b7b3534f8be/emoji/train-00000-of-00001.parquet\': {\'num_bytes\': 2609973, \'checksum\': None}, \'hf://datasets/tweet_eval@b3a375baf0f409c77e6bc7aa35102b7b3534f8be/emoji/test-00000-of-00001.parquet\': {\'num_bytes\': 3047341, \'checksum\': None}, \'hf://datasets/tweet_eval@b3a375baf0f409c77e6bc7aa35102b7b3534f8be/emoji/validation-00000-of-00001.parquet\': {\'num_bytes\': 281994, \'checksum\': None}}, download_size=5939308, post_processing_size=None, dataset_size=8467647, size_in_bytes=14406955)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a ver las clases</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="nb">print</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '[\'\', \'\', \'\', \'\', \'\', \'\', \'\', \'\', \'\', \'\', \'\', \'吼\', \'\', \'\', \'\', \'\', \'\', \'\', \'\', \'\']',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Y el n煤mero de clases</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">num_classes</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '20',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos que el dataset tiene 20 clases</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a ver la secuencia m谩xima de cada split</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">max_len_train</span> <span class="o">=</span> <span class="mi">0</span>',
          '<span class="n">max_len_val</span> <span class="o">=</span> <span class="mi">0</span>',
          '<span class="n">max_len_test</span> <span class="o">=</span> <span class="mi">0</span>',
          '',
          '<span class="n">split</span> <span class="o">=</span> <span class="s2">"train"</span>',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">])):</span>',
          '    <span class="n">len_i</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s2">"text"</span><span class="p">])</span>',
          '    <span class="k">if</span> <span class="n">len_i</span> <span class="o">&gt;</span> <span class="n">max_len_train</span><span class="p">:</span>',
          '        <span class="n">max_len_train</span> <span class="o">=</span> <span class="n">len_i</span>',
          '<span class="n">split</span> <span class="o">=</span> <span class="s2">"validation"</span>',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">])):</span>',
          '    <span class="n">len_i</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s2">"text"</span><span class="p">])</span>',
          '    <span class="k">if</span> <span class="n">len_i</span> <span class="o">&gt;</span> <span class="n">max_len_val</span><span class="p">:</span>',
          '        <span class="n">max_len_val</span> <span class="o">=</span> <span class="n">len_i</span>',
          '<span class="n">split</span> <span class="o">=</span> <span class="s2">"test"</span>',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">])):</span>',
          '    <span class="n">len_i</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s2">"text"</span><span class="p">])</span>',
          '    <span class="k">if</span> <span class="n">len_i</span> <span class="o">&gt;</span> <span class="n">max_len_test</span><span class="p">:</span>',
          '        <span class="n">max_len_test</span> <span class="o">=</span> <span class="n">len_i</span>',
          '',
          '<span class="n">max_len_train</span><span class="p">,</span> <span class="n">max_len_val</span><span class="p">,</span> <span class="n">max_len_test</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '(142, 139, 167)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>As铆 que definimos la secuencia m谩ximo en general como 130 para la tokeniazci贸n</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>






      
      <section class="section-block-markdown-cell">
      <p>A nosotros nos interesa el dataset tokenizado, no las secuencias en crudo, as铆 que creamos un tokenizador</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>',
      '      ',
      '      <span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
      '      <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>









      
      <section class="section-block-markdown-cell">
      <p>Creamos una funci贸n de tokenizaci贸n</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>',
      '      ',
      '      <span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
      '      <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span></span><span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
      '          <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>







      
      <section class="section-block-markdown-cell">
      <p>Y ahora tokenizamos el dataset</p>
      </section>
      
      <section class="section-block-code-cell-">
      <div class="input-code">
      <div class="highlight hl-ipython3">
<pre><span></span><span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{opening_brace}</span>
          <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>
          <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>
          <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>
      <span class="p">{closing_brace}</span>
      </pre></div>
      </div>
      <div class="output-wrapper">
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-text-output-subarea">
      <pre>Map:   0%|          | 0/45000 [00:00&lt;?, ? examples/s]</pre>
      </div>
      </div>
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-text-output-subarea">
      <pre>Map:   0%|          | 0/5000 [00:00&lt;?, ? examples/s]</pre>
      </div>
      </div>
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-text-output-subarea">
      <pre>Map:   0%|          | 0/50000 [00:00&lt;?, ? examples/s]</pre>
      </div>
      </div>
      </div>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Como vemos ahora tenemos los tokens (<code>input_ids</code>) y las m谩scaras de atenci贸n (<code>attention_mask</code>), pero vamos a ver qu茅 tipo de datos tenemos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '</span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '</span><span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '</span><span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '</span><span class="nb">type</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">"input_ids"</span><span class="p">]),</span> <span class="nb">type</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">"attention_mask"</span><span class="p">]),</span> <span class="nb">type</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">"label"</span><span class="p">])</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Map:   0%|          | 0/45000 [00:00&lt;?, ? examples/s]',
          '(list, list, int)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="nb">type</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">"label"</span><span class="p">]),</span> <span class="nb">type</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">"input_ids"</span><span class="p">]),</span> <span class="nb">type</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">"attention_mask"</span><span class="p">])</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '(torch.Tensor, torch.Tensor, torch.Tensor)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Creamos un dataloader</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
      '      <span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
      '      <span class="n">BS</span> <span class="o">=</span> <span class="mi">64</span>',
      '      ',
      '      <span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
      '          <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '          <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '          <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '      <span class="p">}</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>














      
      <section class="section-block-markdown-cell">
      <p>Cargamos el modelo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
      '      <span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
      '      <span class="n">BS</span> <span class="o">=</span> <span class="mi">64</span>',
      '      ',
      '      <span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
      '          <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '          <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '          <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '      <span class="p">}</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span>',
      '      ',
      '      <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>








      
      <section class="section-block-markdown-cell">
      <p>Vamos a ver c贸mo es el modelo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">64</span>',
          '',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '</span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '</span><span class="n">model</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'RobertaForSequenceClassification(',
          '  (roberta): RobertaModel(',
          '    (embeddings): RobertaEmbeddings(',
          '      (word_embeddings): Embedding(50265, 768, padding_idx=1)',
          '      (position_embeddings): Embedding(514, 768, padding_idx=1)',
          '      (token_type_embeddings): Embedding(1, 768)',
          '      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)',
          '      (dropout): Dropout(p=0.1, inplace=False)',
          '    )',
          '    (encoder): RobertaEncoder(',
          '      (layer): ModuleList(',
          '        (0-11): 12 x RobertaLayer(',
          '          (attention): RobertaAttention(',
          '            (self): RobertaSelfAttention(',
          '              (query): Linear(in_features=768, out_features=768, bias=True)',
          '              (key): Linear(in_features=768, out_features=768, bias=True)',
          '              (value): Linear(in_features=768, out_features=768, bias=True)',
          '              (dropout): Dropout(p=0.1, inplace=False)',
          '            )',
          '            (output): RobertaSelfOutput(',
          '              (dense): Linear(in_features=768, out_features=768, bias=True)',
          '              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)',
          '              (dropout): Dropout(p=0.1, inplace=False)',
          '            )',
          '          )',
          '          (intermediate): RobertaIntermediate(',
          '            (dense): Linear(in_features=768, out_features=3072, bias=True)',
          '            (intermediate_act_fn): GELUActivation()',
          '          )',
          '          (output): RobertaOutput(',
          '            (dense): Linear(in_features=3072, out_features=768, bias=True)',
          '            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)',
          '            (dropout): Dropout(p=0.1, inplace=False)',
          '          )',
          '        )',
          '      )',
          '    )',
          '  )',
          '  (classifier): RobertaClassificationHead(',
          '    (dense): Linear(in_features=768, out_features=768, bias=True)',
          '    (dropout): Dropout(p=0.1, inplace=False)',
          '    (out_proj): Linear(in_features=768, out_features=2, bias=True)',
          '  )',
          ')',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a ver su 煤ltima capa</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Linear(in_features=768, out_features=2, bias=True)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">out_features</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '(768, 2)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Hemos visto que nuestro dataset tiene 20 clases, pero este modelo est谩 entrenado para 2 clases, as铆 que tenemos que modificar la 煤ltima capa</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Linear(in_features=768, out_features=20, bias=True)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Ahora s铆</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Ahora creamos una funci贸n de loss</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>






      
      <section class="section-block-markdown-cell">
      <p>Un optimizador</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
      '<span></span><span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
      '      ',
      '      <span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>








      
      <section class="section-block-markdown-cell">
      <p>Y por 煤ltimo una m茅trica</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
      '<span></span><span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
      '      ',
      '      <span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
      '<span></span><span class="kn">import</span> <span class="nn">evaluate</span>',
      '      ',
      '      <span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>








      
      <section class="section-block-markdown-cell">
      <p>Vamos a comprobar que est谩 todo bien con una muestra</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
      '<span></span><span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
      '      ',
      '      <span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
      '<span></span><span class="kn">import</span> <span class="nn">evaluate</span>',
      '      ',
      '      <span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
      '<span></span><span class="n">sample</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]))</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>






      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '</span><span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '</span><span class="kn">import</span> <span class="nn">evaluate</span>',
          '',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '</span><span class="n">sample</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]))</span>',
          '</span><span class="n">sample</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">sample</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '(torch.Size([64, 130]), torch.Size([64, 130]))',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Ahora esa muestra se la metemos al modelo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">"cuda"</span><span class="p">)</span>',
          '<span class="n">ouputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">sample</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">"cuda"</span><span class="p">),</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">sample</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">"cuda"</span><span class="p">))</span>',
          '<span class="n">ouputs</span><span class="o">.</span><span class="n">logits</span><span class="o">.</span><span class="n">shape</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'torch.Size([64, 20])',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos que el modelo saca 64 batches, lo cual est谩 bien, porque configuramos <code>BS = 20</code> y cada una con 20 salidas, lo cual est谩 bien porque cambiamos el modelo para que a la salida de 20 valores</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Obtenemos la de mayor valor</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">ouputs</span><span class="o">.</span><span class="n">logits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '<span class="n">predictions</span><span class="o">.</span><span class="n">shape</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'torch.Size([64])',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Obtenemos la loss</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">ouputs</span><span class="o">.</span><span class="n">logits</span><span class="p">,</span> <span class="n">sample</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">"cuda"</span><span class="p">))</span>',
          '<span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '2.9990389347076416',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Y el accuracy</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">sample</span><span class="p">[</span><span class="s2">"label"</span><span class="p">])[</span><span class="s2">"accuracy"</span><span class="p">]</span>',
          '<span class="n">accuracy</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '0.015625',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Ya podemos crear un peque帽o bucle de entrenamiento</p>
      </section>
      
      <section class="section-block-code-cell-">
      <div class="input-code">
      <div class="highlight hl-ipython3">
<pre><span></span><span class="kn">from</span> <span class="nn">fastprogress.fastprogress</span> <span class="kn">import</span> <span class="n">master_bar</span><span class="p">,</span> <span class="n">progress_bar</span>
      
      <span class="n">epochs</span> <span class="o">=</span> <span class="mi">1</span>
      <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>
      <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
      
      <span class="n">master_progress_bar</span> <span class="o">=</span> <span class="n">master_bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">))</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">master_progress_bar</span><span class="p">:</span>
          <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
          <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>
          <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>
              <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
      
              <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
              <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
              <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
      
              <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
              <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">'logits'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
              <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">'loss: </span><span class="si">{opening_brace}</span><span class="n">loss</span><span class="si">{closing_brace}</span><span class="s1">'</span>
      
              <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
              <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
      
          <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
          <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>
          <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>
              <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
              <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
              <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
      
              <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                  <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
              <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">'logits'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
      
              <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
          <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
          
          <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">main_bar</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"Validation accuracy: </span><span class="si">{opening_brace}</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">]</span><span class="si">{closing_brace}</span><span class="se">\n</span><span class="s2">"</span>
      </pre></div>
      </div>
      <div class="output-wrapper">
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-html-rendered-html-output-subarea">
      <style>
          /* Turns off some styling */
          progress {
              /* gets rid of default border in Firefox and Opera. */
              border: none;
              /* Needs to be in here for Safari polyfill so background images work as expected. */
              background-size: auto;
          }
          progress:not([value]), progress:not([value])::-webkit-progress-bar {
              background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
          }
          .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
              background: #F44336;
          }
      </style>
      </div>
      </div>
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-html-rendered-html-output-subarea"></div>
      </div>
      </div>
      </section>
      
      <section class="section-block-markdown-cell">
      <h4 id="Script-con-el-c%C3%B3digo-base">Script con el c贸digo base<a class="anchor-link" href="#Script-con-el-c%C3%B3digo-base"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 6" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>En la mayor铆a de la documentaci贸n de <code>accelerate</code> se explica c贸mo usar <code>accelerate</code> con scripts, as铆 que de momento vamos a hacerlo as铆 y al final explicaremos c贸mo hacerlo con un notebook</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Primero vamos a crear una carpeta en la que vamos a guardar los scripts</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">fastprogress.fastprogress</span> <span class="kn">import</span> <span class="n">master_bar</span><span class="p">,</span> <span class="n">progress_bar</span>',
      '      ',
      '      <span class="n">epochs</span> <span class="o">=</span> <span class="mi">1</span>',
      '      <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>',
      '      <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '      ',
      '      <span class="n">master_progress_bar</span> <span class="o">=</span> <span class="n">master_bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">))</span>',
      '      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">master_progress_bar</span><span class="p">:</span>',
      '          <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '          <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
      '          <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
      '              <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
      '      ',
      '              <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '              <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '              <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '      ',
      '              <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '              <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
      '              <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">\'loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s1">\'</span>',
      '      ',
      '              <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>',
      '              <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
      '      ',
      '          <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
      '          <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
      '          <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
      '              <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '              <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '              <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '      ',
      '              <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
      '                  <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '              <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
      '      ',
      '              <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
      '          <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
      '          ',
      '          <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">main_bar</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"Validation accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span>',
      '<span></span><span class="o">!</span>mkdir<span class="w"> </span>accelerate_scripts',
        ]}
        languaje='python'
      ></CodeBlockInputCell>






      
      <section class="section-block-markdown-cell">
      <p>Ahora escribimos el c贸digo base en un script</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">fastprogress.fastprogress</span> <span class="kn">import</span> <span class="n">master_bar</span><span class="p">,</span> <span class="n">progress_bar</span>',
          '',
          '<span class="n">epochs</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '',
          '<span class="n">master_progress_bar</span> <span class="o">=</span> <span class="n">master_bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">))</span>',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">master_progress_bar</span><span class="p">:</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '        <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">\'loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s1">\'</span>',
          '',
          '        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '    ',
          '    <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">main_bar</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"Validation accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="se">\\n</span><span class="s2">"</span>',
          '</span><span class="o">!</span>mkdir<span class="w"> </span>accelerate_scripts',
          '</span><span class="o">%%writefile</span> accelerate_scripts/01_code_base.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">from</span> <span class="nn">fastprogress.fastprogress</span> <span class="kn">import</span> <span class="n">master_bar</span><span class="p">,</span> <span class="n">progress_bar</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">64</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '',
          '<span class="n">master_progress_bar</span> <span class="o">=</span> <span class="n">master_bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">))</span>',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">master_progress_bar</span><span class="p">:</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '        <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">\'loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s1">\'</span>',
          '',
          '        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '    ',
          '    <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">main_bar</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"Validation accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="se">\\n</span><span class="s2">"</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/01_code_base.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Y ahora lo ejecutamos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%time</span>',
          '',
          '<span class="err">!</span><span class="n">python</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">01</span><span class="n">_code_base</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Accuracy = 0.2112                                                               ',
          'CPU times: user 2.12 s, sys: 391 ms, total: 2.51 s',
          'Wall time: 3min 36s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos que en mi ordenador ha tardado unos 3 minutos y medio</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h4 id="C%C3%B3digo-con-accelerate">C贸digo con accelerate<a class="anchor-link" href="#C%C3%B3digo-con-accelerate"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 7" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Ahora reemplazamos algunas cosas</p>
      <ul>
      <li>En primer lugar importamos <code>Accelerator</code> y lo inicializamos</li>
      </ul>
      <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>
      <span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>
      </pre></div>
      <ul>
      <li>Ya no hacemos el t铆pico</li>
      </ul>
      <div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>
      </pre></div>
      <ul>
      <li>Sino que dejamos que sea <code>acelerate</code> el que elija el dispositivo mediante</li>
      </ul>
      <div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>
      </pre></div>
      <ul>
      <li>Pasamos los elementos relevantes para el entrenamiento por el m茅todo <code>prepare</code> y ya no hacemos <code>model.to(device)</code></li>
      </ul>
      <div class="highlight"><pre><span></span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">preprare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>
      </pre></div>
      <ul>
      <li><p>Ya no mandamos los datos y el modelo a la GPU con <code>.to(device)</code> ya que <code>accelerate</code> se ha encargado de ello con el m茅todo <code>prepare</code></p>
      </li>
      <li><p>En vez de hacer el backpropagation con <code>loss.backward()</code> dejamos que lo haga <code>accelerate</code> con</p>
      </li>
      </ul>
      <div class="highlight"><pre><span></span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
      </pre></div>
      <ul>
      <li>A la hora de calcular la m茅trica en el bucle de validaci贸n, necesitamos recopilar los valores de todos los puntos, en caso de estar haciendo un entrenamiento distribuido, para ello hacemos</li>
      </ul>
      <div class="highlight"><pre><span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
      </pre></div>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/02_accelerate_base_code.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">from</span> <span class="nn">fastprogress.fastprogress</span> <span class="kn">import</span> <span class="n">master_bar</span><span class="p">,</span> <span class="n">progress_bar</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">64</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="n">master_progress_bar</span> <span class="o">=</span> <span class="n">master_bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">))</span>',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">master_progress_bar</span><span class="p">:</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '        <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">\'loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s1">\'</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"End of training epoch </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">, outputs[\'logits\'].shape: </span><span class="si">{</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, labels.shape: </span><span class="si">{</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"End of validation epoch </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">, outputs[\'logits\'].shape: </span><span class="si">{</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, labels.shape: </span><span class="si">{</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '    ',
          '    <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">main_bar</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"Validation accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="se">\\n</span><span class="s2">"</span>',
          '',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/02_accelerate_base_code.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Si te fijas he a帽adido estas dos l铆neas <code>print(f"End of training epoch {opening_brace}i{closing_brace}, outputs['logits'].shape: {opening_brace}outputs['logits'].shape{closing_brace}, labels.shape: {opening_brace}labels.shape{closing_brace}")</code> y la l铆nea <code>print(f"End of validation epoch {opening_brace}i{closing_brace}, outputs['logits'].shape: {opening_brace}outputs['logits'].shape{closing_brace}, labels.shape: {opening_brace}labels.shape{closing_brace}")</code>, las he a帽adido aposta porque nos van a revelar algo muy importante</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Ahora lo ejecutamos, para ejecutar los scripts de <code>accelerate</code> se hace con el comando <code>accelerate launch</code></p>
      <div class="highlight"><pre><span></span>accelerate<span class="w"> </span>launch<span class="w"> </span>script.py
      </pre></div>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%time</span>',
          '',
          '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">02</span><span class="n">_accelerate_base_code</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'End of training epoch 0, outputs[\'logits\'].shape: torch.Size([64, 20]), labels.shape: torch.Size([64])',
          'End of training epoch 0, outputs[\'logits\'].shape: torch.Size([64, 20]), labels.shape: torch.Size([64])',
          'End of validation epoch 0, outputs[\'logits\'].shape: torch.Size([64, 20]), labels.shape: torch.Size([8])',
          'Accuracy = 0.206',
          'End of validation epoch 0, outputs[\'logits\'].shape: torch.Size([64, 20]), labels.shape: torch.Size([8])',
          'Accuracy = 0.206',
          'CPU times: user 1.6 s, sys: 272 ms, total: 1.88 s',
          'Wall time: 2min 37s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos que antes tard贸 unos 3 minutos y medio y ahora tarda m谩s o menos 2 minutos y medio. Bastante mejora. Adem谩s si vemos los <code>print</code>s podemos ver que se han impreso dos veces.</p>
      <p>驴Y esto c贸mo puede ser? pues porque <code>accelerate</code> ha paralelizado el entrenamiento en las dos GPUs que tengo, por lo que ha sido mucho m谩s r谩pido.</p>
      <p>Adem谩s, cuando ejecut茅 el primer script, esd ecir, cuando no us茅 <code>accelerate</code>, la GPU estaba casi llena, mientras que cuando he ejecutado el segundo, es decir, el que usa <code>accelerate</code>, las dos GPUs estaban muy poco utilizadas, por lo que podemos aumentar el batch size para intentar llenar las dos, vamos a ello!</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/03_accelerate_base_code_more_bs.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">from</span> <span class="nn">fastprogress.fastprogress</span> <span class="kn">import</span> <span class="n">master_bar</span><span class="p">,</span> <span class="n">progress_bar</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="n">master_progress_bar</span> <span class="o">=</span> <span class="n">master_bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">))</span>',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">master_progress_bar</span><span class="p">:</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '        <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">\'loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s1">\'</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '    ',
          '    <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">main_bar</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"Validation accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="se">\\n</span><span class="s2">"</span>',
          '',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/03_accelerate_base_code_more_bs.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>He quitado los prints extra, porque ya hemos visto que el c贸digo se est谩 ejecutando en las dos GPUs y he aunmentado el batch size de 64 a 128. Lo ejecutamos a ver</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%time</span>',
          '',
          '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">03</span><span class="n">_accelerate_base_code_more_bs</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Accuracy = 0.1052                                                               ',
          'Accuracy = 0.1052',
          'CPU times: user 1.41 s, sys: 180 ms, total: 1.59 s',
          'Wall time: 2min 22s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Aumentando el batch size ha bajado unos segundos el tiempo de ejecuci贸n</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Ejecuci%C3%B3n-de-procesos">Ejecuci贸n de procesos<a class="anchor-link" href="#Ejecuci%C3%B3n-de-procesos"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 8" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <h4 id="Ejecuci%C3%B3n-de-c%C3%B3digo-en-un-%C3%BAnico-proceso">Ejecuci贸n de c贸digo en un 煤nico proceso<a class="anchor-link" href="#Ejecuci%C3%B3n-de-c%C3%B3digo-en-un-%C3%BAnico-proceso"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 9" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Antes hemos visto que los <code>print</code>s se imprim铆an dos veces, esto es porque <code>accelerate</code> crea tantos procesos como dispositivos donde se ejecuta el c贸digo, en mi caso crea dos procesos por tener dos GPUs.</p>
      <p>Sin embargo no todo el c贸digo deber铆a ejecutarse en todos los procesos, por ejemplo los <code>print</code>s, ralentizan mucho el c贸digo, como para ejecutarlo varias veces, si se guardan los checkpoints, se guardar铆an dos veces, etc.</p>
      <p>Para poder ejecutar parte de un c贸digo en un 煤nico proceso se tiene que encapsular en una funci贸n y decorarla con <code>accelerator.on_local_main_process</code>, por ejemplo en el siguiente c贸digo vas a ver que he creado la siguiente funci贸n</p>
      <div class="highlight"><pre><span></span><span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>
      <span class="k">def</span> <span class="nf">print_something</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>
          <span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>
      </pre></div>
      <p>Otra opci贸n es meter el c贸digo dentro de un <code>if accelerator.is_local_main_process</code> como en el siguiente c贸digo</p>
      <div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">:</span>
          <span class="nb">print</span><span class="p">(</span><span class="s2">"Something"</span><span class="p">)</span>
      </pre></div>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/04_accelerate_base_code_some_code_in_one_process.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">from</span> <span class="nn">fastprogress.fastprogress</span> <span class="kn">import</span> <span class="n">master_bar</span><span class="p">,</span> <span class="n">progress_bar</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>',
          '<span class="k">def</span> <span class="nf">print_something</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="n">master_progress_bar</span> <span class="o">=</span> <span class="n">master_bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">))</span>',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">master_progress_bar</span><span class="p">:</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '        <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">\'loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s1">\'</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '    ',
          '    <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">main_bar</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"Validation accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="se">\\n</span><span class="s2">"</span>',
          '',
          '<span class="c1"># print(f"Accuracy = {accuracy[\'accuracy\']}")</span>',
          '<span class="n">print_something</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">:</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/04_accelerate_base_code_some_code_in_one_process.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a ejecutarlo a ver</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%time</span>',
          '',
          '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">04</span><span class="n">_accelerate_base_code_some_code_in_one_process</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Accuracy = 0.2098                                                               ',
          'End of script with 0.2098 accuracy',
          'CPU times: user 1.38 s, sys: 197 ms, total: 1.58 s',
          'Wall time: 2min 22s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Ahora solo se ha impreso el print una vez</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Sin embargo, aunque no se ve mucho, las barras de progreso se ejecutan en cada proceso.</p>
      <p>No he encontrado una manera de evitar esto con las barras de progreso de <code>fastprogress</code>, pero s铆 con las de <code>tqdm</code>, as铆 que voy a sustituir las barras de progreso de <code>fastprogress</code> por las de <code>tqdm</code> y para que se ejecuten en un 煤nico proceso hay que a帽adirle el argumento <code>disable=not accelerator.is_local_main_process</code></p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/05_accelerate_base_code_some_code_in_one_process.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">import</span> <span class="nn">tqdm</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>',
          '<span class="k">def</span> <span class="nf">print_something</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="c1"># progress_bar_train = progress_bar(dataloader["train"], parent=master_progress_bar)</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '        <span class="c1"># master_progress_bar.child.comment = f\'loss: {loss}\'</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="c1"># progress_bar_validation = progress_bar(dataloader["validation"], parent=master_progress_bar)</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '    ',
          '<span class="c1"># print(f"Accuracy = {accuracy[\'accuracy\']}")</span>',
          '<span class="n">print_something</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">:</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/05_accelerate_base_code_some_code_in_one_process.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%time</span>',
          '',
          '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">05</span><span class="n">_accelerate_base_code_some_code_in_one_process</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '100%|| 176/176 [02:01&lt;00:00,  1.45it/s]',
          '100%|| 20/20 [00:06&lt;00:00,  3.30it/s]',
          'Accuracy = 0.2166',
          'End of script with 0.2166 accuracy',
          'CPU times: user 1.33 s, sys: 195 ms, total: 1.52 s',
          'Wall time: 2min 22s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Hemos mostrado un ejemplo de c贸mo imprimir en un solo proceso, y esto ha sido una manera de ejecutar procesos en un solo proceso. Pero si lo que quieres es solo imprimir en un solo proceso se puede usar el m茅todo <code>print</code> de <code>accelerate</code>. Vamos a ver el mismo ejemplo de antes con este m茅todo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/06_accelerate_base_code_print_one_process.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">import</span> <span class="nn">tqdm</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="c1"># progress_bar_train = progress_bar(dataloader["train"], parent=master_progress_bar)</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '        <span class="c1"># master_progress_bar.child.comment = f\'loss: {loss}\'</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="c1"># progress_bar_validation = progress_bar(dataloader["validation"], parent=master_progress_bar)</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '    ',
          '<span class="c1"># print(f"Accuracy = {accuracy[\'accuracy\']}")</span>',
          '<span class="n">accelerator</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">:</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Writing accelerate_scripts/06_accelerate_base_code_print_one_process.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Lo ejecutamos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%time</span>',
          '',
          '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">06</span><span class="n">_accelerate_base_code_print_one_process</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Map: 100%|| 45000/45000 [00:02&lt;00:00, 15433.52 examples/s]',
          'Map: 100%|| 5000/5000 [00:00&lt;00:00, 11406.61 examples/s]',
          'Map: 100%|| 45000/45000 [00:02&lt;00:00, 15036.87 examples/s]',
          'Map: 100%|| 50000/50000 [00:03&lt;00:00, 14932.76 examples/s]',
          'Map: 100%|| 50000/50000 [00:03&lt;00:00, 14956.60 examples/s]',
          '100%|| 176/176 [02:00&lt;00:00,  1.46it/s]',
          '100%|| 20/20 [00:05&lt;00:00,  3.33it/s]',
          'Accuracy = 0.2134',
          'End of script with 0.2134 accuracy',
          'CPU times: user 1.4 s, sys: 189 ms, total: 1.59 s',
          'Wall time: 2min 27s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h4 id="Ejecuci%C3%B3n-de-c%C3%B3digo-en-todos-los-procesos">Ejecuci贸n de c贸digo en todos los procesos<a class="anchor-link" href="#Ejecuci%C3%B3n-de-c%C3%B3digo-en-todos-los-procesos"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 10" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Sin embargo hay c贸digo que debe ejecutarse en todos los procesos, por ejemplo si subimos los checkpoints al hub, as铆 que aqu铆 tenemos dos opciones, encapsular el c贸digo en una funci贸n y decorarla con <code>accelerator.on_main_process</code></p>
      <div class="highlight"><pre><span></span><span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_main_process</span>
      <span class="k">def</span> <span class="nf">do_my_thing</span><span class="p">():</span>
          <span class="s2">"Something done once per server"</span>
          <span class="n">do_thing_once</span><span class="p">()</span>
      </pre></div>
      <p>o meter el c贸digo dentro de un <code>if accelerator.is_main_process</code></p>
      <div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">:</span>
          <span class="n">repo</span><span class="o">.</span><span class="n">push_to_hub</span><span class="p">()</span>
      </pre></div>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Como estamos haciendo entrenamientos solo para mostrar la librer铆a <code>accelerate</code> y el modelo que estamos entrenando no es bueno, no tiene sentido ahora subir los checkpoints al hub, as铆 que voy a hacer un ejemplo con <code>print</code>s</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/07_accelerate_base_code_some_code_in_all_process.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">import</span> <span class="nn">tqdm</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>',
          '<span class="k">def</span> <span class="nf">print_in_one_process</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_main_process</span>',
          '<span class="k">def</span> <span class="nf">print_in_all_processes</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '    ',
          '<span class="n">print_in_one_process</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">:</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">print_in_all_processes</span><span class="p">(</span><span class="sa">f</span><span class="s2">"All process: Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">:</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"All process: End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/06_accelerate_base_code_some_code_in_all_process.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Lo ejecutamos a ver</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%time</span>',
          '',
          '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">07</span><span class="n">_accelerate_base_code_some_code_in_all_process</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Map: 100%|| 45000/45000 [00:03&lt;00:00, 14518.44 examples/s]',
          'Map: 100%|| 45000/45000 [00:03&lt;00:00, 14368.77 examples/s]',
          'Map: 100%|| 5000/5000 [00:00&lt;00:00, 16466.33 examples/s]',
          'Map: 100%|| 5000/5000 [00:00&lt;00:00, 14806.14 examples/s]',
          'Map: 100%|| 50000/50000 [00:03&lt;00:00, 14253.33 examples/s]',
          'Map: 100%|| 50000/50000 [00:03&lt;00:00, 14337.07 examples/s]',
          '100%|| 176/176 [02:00&lt;00:00,  1.46it/s]',
          '100%|| 20/20 [00:05&lt;00:00,  3.34it/s]',
          'Accuracy = 0.2092',
          'End of script with 0.2092 accuracy',
          'All process: Accuracy = 0.2092',
          'All process: End of script with 0.2092 accuracy',
          'CPU times: user 1.42 s, sys: 216 ms, total: 1.64 s',
          'Wall time: 2min 27s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h4 id="Ejecuci%C3%B3n-de-c%C3%B3digo-en-el-proceso-X">Ejecuci贸n de c贸digo en el proceso X<a class="anchor-link" href="#Ejecuci%C3%B3n-de-c%C3%B3digo-en-el-proceso-X"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 11" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Por 煤ltimo podemos especificar en qu茅 proceso queremos ejecutar c贸digo, para esto hay que crear una funci贸n y decorarla con <code>@accelerator.on_process(process_index=0)</code></p>
      <div class="highlight"><pre><span></span><span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_process</span><span class="p">(</span><span class="n">process_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
      <span class="k">def</span> <span class="nf">do_my_thing</span><span class="p">():</span>
          <span class="s2">"Something done on process index 0"</span>
          <span class="n">do_thing_on_index_zero</span><span class="p">()</span>
      </pre></div>
      <p>o decorarla con <code>@accelerator.on_local_process(local_process_idx=0)</code></p>
      <div class="highlight"><pre><span></span><span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_process</span><span class="p">(</span><span class="n">local_process_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
      <span class="k">def</span> <span class="nf">do_my_thing</span><span class="p">():</span>
          <span class="s2">"Something done on process index 0 on each server"</span>
          <span class="n">do_thing_on_index_zero_on_each_server</span><span class="p">()</span>
      </pre></div>
      <p>Aqu铆 he puesto el proceso 0, pero se puede poner cualquier n煤mero</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/08_accelerate_base_code_some_code_in_some_process.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">import</span> <span class="nn">tqdm</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>',
          '<span class="k">def</span> <span class="nf">print_in_one_process</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_main_process</span>',
          '<span class="k">def</span> <span class="nf">print_in_all_processes</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_process</span><span class="p">(</span><span class="n">process_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>',
          '<span class="k">def</span> <span class="nf">print_in_process_0</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="s2">"Process 0: "</span> <span class="o">+</span> <span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_process</span><span class="p">(</span><span class="n">local_process_index</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
          '<span class="k">def</span> <span class="nf">print_in_process_1</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="s2">"Process 1: "</span> <span class="o">+</span> <span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '    ',
          '<span class="n">print_in_one_process</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">:</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">print_in_all_processes</span><span class="p">(</span><span class="sa">f</span><span class="s2">"All process: Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">:</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"All process: End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">print_in_process_0</span><span class="p">(</span><span class="s2">"End of process 0"</span><span class="p">)</span>',
          '<span class="n">print_in_process_1</span><span class="p">(</span><span class="s2">"End of process 1"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/07_accelerate_base_code_some_code_in_some_process.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Lo ejecutamos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%time</span>',
          '',
          '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">08</span><span class="n">_accelerate_base_code_some_code_in_some_process</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Map: 100%|| 5000/5000 [00:00&lt;00:00, 15735.58 examples/s]',
          'Map: 100%|| 50000/50000 [00:03&lt;00:00, 14906.20 examples/s]',
          '100%|| 176/176 [02:02&lt;00:00,  1.44it/s]',
          '100%|| 20/20 [00:06&lt;00:00,  3.27it/s]',
          'Process 1: End of process 1',
          'Accuracy = 0.2128',
          'End of script with 0.2128 accuracy',
          'All process: Accuracy = 0.2128',
          'All process: End of script with 0.2128 accuracy',
          'Process 0: End of process 0',
          'CPU times: user 1.42 s, sys: 295 ms, total: 1.71 s',
          'Wall time: 2min 37s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h4 id="Sincronizar-procesos">Sincronizar procesos<a class="anchor-link" href="#Sincronizar-procesos"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 12" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Si tenemos c贸digo que debe ejecutarse en todos los procesos, es interesante esperar a que termine en todos los procesos antes de hacer otra tarea, as铆 que para ello usamos <code>accelerator.wait_for_everyone()</code></p>
      <p>Para verlo vamos a meter un retardo en una de las funciones de imprimir en un proceso</p>
      <p>Adem谩s he puesto un break en el bucle de entrenamiento para que no est茅 mucho tiempo entrenando, que no es lo que ahora nos interesa</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/09_accelerate_base_code_sync_all_process.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">import</span> <span class="nn">tqdm</span>',
          '<span class="kn">import</span> <span class="nn">time</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>',
          '<span class="k">def</span> <span class="nf">print_in_one_process</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_main_process</span>',
          '<span class="k">def</span> <span class="nf">print_in_all_processes</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_process</span><span class="p">(</span><span class="n">process_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>',
          '<span class="k">def</span> <span class="nf">print_in_process_0</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="s2">"Process 0: "</span> <span class="o">+</span> <span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_process</span><span class="p">(</span><span class="n">local_process_index</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
          '<span class="k">def</span> <span class="nf">print_in_process_1</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="s2">"Process 1: "</span> <span class="o">+</span> <span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '        <span class="k">break</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '    ',
          '<span class="n">print_in_one_process</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">:</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">print_in_all_processes</span><span class="p">(</span><span class="sa">f</span><span class="s2">"All process: Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">:</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"All process: End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">print_in_one_process</span><span class="p">(</span><span class="s2">"Printing with delay in process 0"</span><span class="p">)</span>',
          '<span class="n">print_in_process_0</span><span class="p">(</span><span class="s2">"End of process 0"</span><span class="p">)</span>',
          '<span class="n">print_in_process_1</span><span class="p">(</span><span class="s2">"End of process 1"</span><span class="p">)</span>',
          '<span class="n">accelerator</span><span class="o">.</span><span class="n">wait_for_everyone</span><span class="p">()</span>',
          '',
          '<span class="n">print_in_one_process</span><span class="p">(</span><span class="s2">"End of script"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/08_accelerate_base_code_sync_all_process.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Lo ejecutamos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">!</span>accelerate<span class="w"> </span>launch<span class="w"> </span>accelerate_scripts/09_accelerate_base_code_sync_all_process.py',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Map: 100%|| 5000/5000 [00:00&lt;00:00, 14218.23 examples/s]',
          'Map: 100%|| 5000/5000 [00:00&lt;00:00, 14666.25 examples/s]',
          '  0%|                                                   | 0/176 [00:00&lt;?, ?it/s]',
          '100%|| 20/20 [00:05&lt;00:00,  3.58it/s]',
          'Process 1: End of process 1',
          'Accuracy = 0.212',
          'End of script with 0.212 accuracy',
          'All process: Accuracy = 0.212',
          'All process: End of script with 0.212 accuracy',
          'Printing with delay in process 0',
          'Process 0: End of process 0',
          'End of script',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Como se puede ver primero se ha impreso <code>Process 1: End of process 1</code> y luego el resto, esto es porque el resto de prints se hacen o en el proceso 0 o en todos los procesos, as铆 que hasta que no termine el delay de 2 segundos que hemos puesto no se ejecuta el resto de c贸digo</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Guardar-y-cargar-el-state-dict">Guardar y cargar el state dict<a class="anchor-link" href="#Guardar-y-cargar-el-state-dict"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 13" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Cuando entrenamos, a veces guardamos el estado para poder seguir en otro momento</p>
      <p>Para guardar el estado tendremos que usar los m茅todos <code>save_state()</code> y <code>load_state()</code></p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/10_accelerate_save_and_load_checkpoints.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">import</span> <span class="nn">tqdm</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>',
          '<span class="k">def</span> <span class="nf">print_something</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '',
          '    <span class="c1"># Guardamos los pesos</span>',
          '    <span class="n">accelerator</span><span class="o">.</span><span class="n">save_state</span><span class="p">(</span><span class="s2">"accelerate_scripts/checkpoints"</span><span class="p">)</span>',
          '',
          '<span class="n">print_something</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '<span class="c1"># Cargamos los pesos</span>',
          '<span class="n">accelerator</span><span class="o">.</span><span class="n">load_state</span><span class="p">(</span><span class="s2">"accelerate_scripts/checkpoints"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/09_accelerate_save_and_load_checkpoints.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Lo ejecutamos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">!</span>accelerate<span class="w"> </span>launch<span class="w"> </span>accelerate_scripts/10_accelerate_save_and_load_checkpoints.py',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '100%|| 176/176 [01:58&lt;00:00,  1.48it/s]',
          '100%|| 20/20 [00:05&lt;00:00,  3.40it/s]',
          'Accuracy = 0.2142',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Guardar-el-modelo">Guardar el modelo<a class="anchor-link" href="#Guardar-el-modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 14" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Cuando se us贸 el m茅todo <code>prepare</code> se envolvi贸 el modelo para poder guardarlo en los dispositivos necesarios. Por lo que a la hora de guardarlo tenemos que usar el m茅todo <code>save_model</code> que primero lo desenvuelve y luego lo guarda. Adem谩s si usamos el par谩metro <code>safe_serialization=True</code> se guardar谩 el modelo como un <code>safe tensor</code></p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/11_accelerate_save_model.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">import</span> <span class="nn">tqdm</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>',
          '<span class="k">def</span> <span class="nf">print_something</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '',
          '    <span class="c1"># Guardamos el modelo</span>',
          '    <span class="n">accelerator</span><span class="o">.</span><span class="n">wait_for_everyone</span><span class="p">()</span>',
          '    <span class="n">accelerator</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">"accelerate_scripts/model"</span><span class="p">,</span> <span class="n">safe_serialization</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">print_something</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Writing accelerate_scripts/11_accelerate_save_model.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Lo ejecutamos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">!</span>accelerate<span class="w"> </span>launch<span class="w"> </span>accelerate_scripts/11_accelerate_save_model.py',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '100%|| 176/176 [01:58&lt;00:00,  1.48it/s]',
          '100%|| 20/20 [00:05&lt;00:00,  3.35it/s]',
          'Accuracy = 0.214',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Guardar-el-modelo-pretrained">Guardar el modelo <code>pretrained</code><a class="anchor-link" href="#Guardar-el-modelo-pretrained"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 15" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>En modelos que usan la librer铆a <code>transformers</code> debemos guardar el modelo con el m茅todo <code>save_pretrained</code> para poder cargarlo con el m茅todo <code>from_pretrained</code>. Antes de guardarlo hay que desenvolverlo con el m茅todo <code>unwrap_model</code></p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/12_accelerate_save_pretrained.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">import</span> <span class="nn">tqdm</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>',
          '<span class="k">def</span> <span class="nf">print_something</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '',
          '    <span class="c1"># Guardamos el modelo pretrained</span>',
          '    <span class="n">unwrapped_model</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">unwrap_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>',
          '    <span class="n">unwrapped_model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span>',
          '        <span class="s2">"accelerate_scripts/model_pretrained"</span><span class="p">,</span>',
          '        <span class="n">is_main_process</span><span class="o">=</span><span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">,</span>',
          '        <span class="n">save_function</span><span class="o">=</span><span class="n">accelerator</span><span class="o">.</span><span class="n">save</span><span class="p">,</span>',
          '    <span class="p">)</span>',
          '',
          '<span class="n">print_something</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Writing accelerate_scripts/11_accelerate_save_pretrained.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Lo ejecutamos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">!</span>accelerate<span class="w"> </span>launch<span class="w"> </span>accelerate_scripts/12_accelerate_save_pretrained.py',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Map: 100%|| 45000/45000 [00:02&lt;00:00, 15152.47 examples/s]',
          'Map: 100%|| 45000/45000 [00:02&lt;00:00, 15119.13 examples/s]',
          'Map: 100%|| 5000/5000 [00:00&lt;00:00, 12724.70 examples/s]',
          'Map: 100%|| 5000/5000 [00:00&lt;00:00, 12397.49 examples/s]',
          'Map: 100%|| 50000/50000 [00:03&lt;00:00, 15247.21 examples/s]',
          'Map: 100%|| 50000/50000 [00:03&lt;00:00, 15138.03 examples/s]',
          '100%|| 176/176 [01:59&lt;00:00,  1.48it/s]',
          '100%|| 20/20 [00:05&lt;00:00,  3.37it/s]',
          'Accuracy = 0.21',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Ahora lo podr铆amos cargar</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModel</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"accelerate_scripts/model_pretrained"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Some weights of RobertaModel were not initialized from the model checkpoint at accelerate_scripts/model_pretrained and are newly initialized: [\'roberta.pooler.dense.bias\', \'roberta.pooler.dense.weight\']',
          'You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Entrenamiento-en-notebooks">Entrenamiento en notebooks<a class="anchor-link" href="#Entrenamiento-en-notebooks"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 16" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Hasta ahora hemos visto c贸mo ejecutar scripts, pero si quieres ejecutar el c贸digo en un notebook, podemos escribir el mismo c贸digo de antes, pero encapsulado en una funci贸n</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Primero importamos las librer谩s</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
      '      <span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
      '      <span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
      '      <span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
      '      <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
      '      <span class="kn">import</span> <span class="nn">evaluate</span>',
      '      <span class="kn">import</span> <span class="nn">tqdm</span>',
      '      <span class="kn">import</span> <span class="nn">time</span>',
      '      <span class="c1"># from accelerate import Accelerator</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>














      
      <section class="section-block-markdown-cell">
      <p>Ahora creamos la funci贸n</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
      '      <span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
      '      <span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
      '      <span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
      '      <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
      '      <span class="kn">import</span> <span class="nn">evaluate</span>',
      '      <span class="kn">import</span> <span class="nn">tqdm</span>',
      '      <span class="kn">import</span> <span class="nn">time</span>',
      '      <span class="c1"># from accelerate import Accelerator</span>',
      '<span></span><span class="k">def</span> <span class="nf">train_code</span><span class="p">(</span><span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span><span class="p">):</span>',
      '          <span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
      '          <span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
      '      ',
      '          <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
      '          <span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
      '          <span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
      '      ',
      '          <span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
      '          <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '      ',
      '          <span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
      '              <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
      '          <span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
      '              <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
      '              <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
      '              <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
      '          <span class="p">}</span>',
      '          <span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
      '          <span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
      '          <span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
      '      ',
      '          <span class="n">BS</span> <span class="o">=</span> <span class="n">batch_size</span>',
      '          <span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
      '              <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '              <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '              <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '          <span class="p">}</span>',
      '      ',
      '          <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '          <span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
      '      ',
      '          <span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
      '          <span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
      '          <span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
      '      ',
      '          <span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
      '          <span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
      '          <span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
      '      ',
      '          <span class="c1"># model.to(device)</span>',
      '          <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
      '      ',
      '          <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
      '              <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '              <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
      '              <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
      '                  <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
      '      ',
      '                  <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '                  <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '                  <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '      ',
      '                  <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '                  <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
      '      ',
      '                  <span class="c1"># loss.backward()</span>',
      '                  <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
      '                  <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
      '      ',
      '              <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
      '              <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
      '              <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
      '                  <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '                  <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '                  <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '      ',
      '                  <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
      '                      <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '                  <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
      '                  <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
      '                  <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
      '                  <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
      '      ',
      '                  <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
      '              <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
      '              ',
      '          <span class="n">accelerator</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>



















































































      
      <section class="section-block-markdown-cell">
      <p>Para poder ejecutar el entrenamiento en el notebook usamos la funcion <code>notebook_launcher</code>, al que le pasamos la funci贸n que queremos ejecutar, los argumentos de esa funci贸n y el n煤mero de GPUs en las que vamos a entrenar con la variable <code>num_processes</code></p>
      </section>
      
      <section class="section-block-code-cell-">
      <div class="input-code">
      <div class="highlight hl-ipython3">
<pre><span></span><span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">notebook_launcher</span>
      
      <span class="n">args</span> <span class="o">=</span> <span class="p">(</span><span class="mi">128</span><span class="p">,)</span>
      <span class="n">notebook_launcher</span><span class="p">(</span><span class="n">train_code</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">num_processes</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
      </pre></div>
      </div>
      <div class="output-wrapper">
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-subarea-output-stream-output-stdout-output-text">
      <pre>Launching training on 2 GPUs.
      </pre>
      </div>
      </div>
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-subarea-output-stream-output-stderr-output-text">
      <pre>100%|| 176/176 [02:01&lt;00:00,  1.45it/s]
      100%|| 20/20 [00:06&lt;00:00,  3.31it/s]
      </pre>
      </div>
      </div>
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-subarea-output-stream-output-stdout-output-text">
      <pre>Accuracy = 0.2112
      </pre>
      </div>
      </div>
      </div>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Entrenamiento-en-FP16">Entrenamiento en FP16<a class="anchor-link" href="#Entrenamiento-en-FP16"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 17" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Cuando al principio configuramos <code>accelerate</code> nos pregunt贸 <code>Do you wish to use FP16 or BF16 (mixed precision)?</code> y dijimos que no, as铆 que ahora vamos a decirle que s铆, que queremos en FP16</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Hasta ahora hemos entrenado en FP32, lo que quiere decir que cada peso del modelo es un n煤mero en coma flotante de 32 bits, y ahora vamos a usar un n煤mero en coma flotante de 16 bits, es decir, el modelo va a ocupar menos. Por lo que van a pasar dos cosas, podremos usar un batch size mayor y adem谩s ser谩 m谩s r谩pido</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Primero volvemos a lanzar <code>accelerate config</code> y le vamos a decir que queremos FP16</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">import</span> <span class="nn">tqdm</span>',
          '<span class="kn">import</span> <span class="nn">time</span>',
          '<span class="c1"># from accelerate import Accelerator</span>',
          '</span><span class="k">def</span> <span class="nf">train_code</span><span class="p">(</span><span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span><span class="p">):</span>',
          '    <span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '    <span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '    <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '    <span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '    <span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '    <span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '    <span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '        <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '    <span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '        <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '        <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '        <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="p">}</span>',
          '    <span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '    <span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '    <span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '    <span class="n">BS</span> <span class="o">=</span> <span class="n">batch_size</span>',
          '    <span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '        <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '        <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '        <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="p">}</span>',
          '',
          '    <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '    <span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '    <span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '    <span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '    <span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '    <span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '    <span class="c1"># model.to(device)</span>',
          '    <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
          '        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '        <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '            <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '            <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '',
          '            <span class="c1"># loss.backward()</span>',
          '            <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '        <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '            <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '            <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '                <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '            <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '            <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '            <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '            <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '            <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '        ',
          '    <span class="n">accelerator</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '</span><span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">notebook_launcher</span>',
          '',
          '<span class="n">args</span> <span class="o">=</span> <span class="p">(</span><span class="mi">128</span><span class="p">,)</span>',
          '<span class="n">notebook_launcher</span><span class="p">(</span><span class="n">train_code</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">num_processes</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>',
          '</span><span class="o">!</span>accelerate<span class="w"> </span>config',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Launching training on 2 GPUs.',
          '--------------------------------------------------------------------------------',
          'In which compute environment are you running?',
          'This machine',
          '--------------------------------------------------------------------------------',
          'multi-GPU',
          'How many different machines will you use (use more than 1 for multi-node training)? [1]: 1',
          'Should distributed operations be checked while running for errors? This can avoid timeout issues but will be slower. [yes/NO]: no',
          'Do you wish to optimize your script with torch dynamo?[yes/NO]:no',
          'Do you want to use DeepSpeed? [yes/NO]: no',
          'Do you want to use FullyShardedDataParallel? [yes/NO]: no',
          'Do you want to use Megatron-LM ? [yes/NO]: no',
          'How many GPU(s) should be used for distributed training? [1]:2',
          'What GPU(s) (by id) should be used for training on this machine as a comma-seperated list? [all]:0,1',
          '--------------------------------------------------------------------------------',
          'Do you wish to use FP16 or BF16 (mixed precision)?',
          'fp16',
          'accelerate configuration saved at ~/.cache/huggingface/accelerate/default_config.yaml',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Ahora creamos un script para entrenar, con el mismo batch size de antes, para ver si tarda menos en entrenar</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/13_accelerate_base_code_fp16_bs128.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">import</span> <span class="nn">tqdm</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '    ',
          '<span class="n">accelerator</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/12_accelerate_base_code_fp16_bs128.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Lo ejecutamos a ver cuanto tarda</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%time</span>',
          '',
          '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">13</span><span class="n">_accelerate_base_code_fp16_bs128</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Map: 100%|| 5000/5000 [00:00&lt;00:00, 14983.76 examples/s]',
          'Map: 100%|| 50000/50000 [00:03&lt;00:00, 14315.47 examples/s]',
          '100%|| 176/176 [01:01&lt;00:00,  2.88it/s]',
          '100%|| 20/20 [00:02&lt;00:00,  6.84it/s]',
          'Accuracy = 0.2094',
          'CPU times: user 812 ms, sys: 163 ms, total: 976 ms',
          'Wall time: 1min 27s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Cuando ejecutamos este entrenamiento en FP32 tard贸 unos 2 minutos y medio, y ahora m谩s o menos 1 minuto y medio. Vamos a ver si ahora en vez de entrenar con un batch size de 128, lo hacemos con uno de 256</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/14_accelerate_base_code_fp16_bs256.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">import</span> <span class="nn">tqdm</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">256</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '    ',
          '<span class="n">accelerator</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/13_accelerate_base_code_fp16_bs256.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Lo ejecutamos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%time</span>',
          '',
          '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">14</span><span class="n">_accelerate_base_code_fp16_bs256</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Map: 100%|| 5000/5000 [00:00&lt;00:00, 15390.30 examples/s]',
          'Map: 100%|| 5000/5000 [00:00&lt;00:00, 14990.92 examples/s]',
          '100%|| 88/88 [00:54&lt;00:00,  1.62it/s]',
          '100%|| 10/10 [00:02&lt;00:00,  3.45it/s]',
          'Accuracy = 0.2236',
          'CPU times: user 670 ms, sys: 91.6 ms, total: 761 ms',
          'Wall time: 1min 12s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Ha bajado solo unos 15 segundos</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Entrenamiento-en-BF16">Entrenamiento en BF16<a class="anchor-link" href="#Entrenamiento-en-BF16"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 18" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Antes hemos entrenado en FP16 y ahora lo vamos a hacer en BF16, 驴Cu谩l es la diferencia?</p>
      <p><img decoding="async" onerror="this.parentNode.removeChild(this)" alt="FP32_FP16_BF16" src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/FP32_FP16_BF16.webp" width="894" height="253"/></p>
      <p>Como podemos ver en la imagen, mientras que FP16 en comparaci贸n con FP32 tiene menos bits en la mantisa y el exponente, lo que hace que su rango sea mucho menor, BF16 en comparaci贸n con FP32 tiene el mismo n煤mero de bits del exponente pero menos en la mantisa, lo que hace que BF16 tenga el mismo rango de n煤meros que FP32, pero es menos preciso</p>
      <p>Esto es beneficioso porque en FP16 algunos c谩lculos podr铆an dar n煤meros muy altos, que en formato FP16 no se podr铆an representar. Adem谩s hay ciertos dispositivos HW que est谩n optimizados para este formato</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Al igual que antes ejecutamos <code>accelerate config</code> y le indicamos que queremos BF16</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">!</span>accelerate<span class="w"> </span>config',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '--------------------------------------------------------------------------------',
          'In which compute environment are you running?',
          'This machine',
          '--------------------------------------------------------------------------------',
          'multi-GPU',
          'How many different machines will you use (use more than 1 for multi-node training)? [1]: 1',
          'Should distributed operations be checked while running for errors? This can avoid timeout issues but will be slower. [yes/NO]: no',
          'Do you wish to optimize your script with torch dynamo?[yes/NO]:no',
          'Do you want to use DeepSpeed? [yes/NO]: no',
          'Do you want to use FullyShardedDataParallel? [yes/NO]: no',
          'Do you want to use Megatron-LM ? [yes/NO]: no',
          'How many GPU(s) should be used for distributed training? [1]:2',
          'What GPU(s) (by id) should be used for training on this machine as a comma-seperated list? [all]:0,1',
          '--------------------------------------------------------------------------------',
          'Do you wish to use FP16 or BF16 (mixed precision)?',
          'bf16',
          'accelerate configuration saved at ~/.cache/huggingface/accelerate/default_config.yaml',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Ahora ejecutamos el 煤ltimo script que hab铆amos creado, es decir con un batch size de 256</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%time</span>',
          '',
          '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">14</span><span class="n">_accelerate_base_code_fp16_bs256</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Map: 100%|| 50000/50000 [00:03&lt;00:00, 14814.95 examples/s]',
          'Map: 100%|| 50000/50000 [00:03&lt;00:00, 14506.83 examples/s]',
          '100%|| 88/88 [00:51&lt;00:00,  1.70it/s]',
          '100%|| 10/10 [00:03&lt;00:00,  3.21it/s]',
          'Accuracy = 0.2112',
          'CPU times: user 688 ms, sys: 144 ms, total: 832 ms',
          'Wall time: 1min 17s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Ha tardado un tiempo similar a lo que tard贸 antes, lo cual es normal, ya que hemos entrenado un modelo con pesos de 16 bits, al igual que antes</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Entrenamiento-en-FP8">Entrenamiento en FP8<a class="anchor-link" href="#Entrenamiento-en-FP8"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 19" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Ahora vamos a entrenar en formato FP8, que como su nombre indica, es un formato de coma flotante, donde cada peso tiene 8 bits, por lo que ejecutamos <code>accelerate config</code> para decirle que queremos FP8</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">!</span>accelerate<span class="w"> </span>config',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '--------------------------------------------------------------------------------',
          'In which compute environment are you running?',
          'This machine',
          '--------------------------------------------------------------------------------',
          'multi-GPU',
          'How many different machines will you use (use more than 1 for multi-node training)? [1]: 1',
          'Should distributed operations be checked while running for errors? This can avoid timeout issues but will be slower. [yes/NO]: no',
          'Do you wish to optimize your script with torch dynamo?[yes/NO]:no',
          'Do you want to use DeepSpeed? [yes/NO]: no',
          'Do you want to use FullyShardedDataParallel? [yes/NO]: no',
          'Do you want to use Megatron-LM ? [yes/NO]: no',
          'How many GPU(s) should be used for distributed training? [1]:2',
          'What GPU(s) (by id) should be used for training on this machine as a comma-seperated list? [all]:0,1',
          '--------------------------------------------------------------------------------',
          'Do you wish to use FP16 or BF16 (mixed precision)?',
          'fp8',
          'accelerate configuration saved at ~/.cache/huggingface/accelerate/default_config.yaml',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Ahora ejecutamos el 煤ltimo script, el de batch size de 256</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%time</span>',
          '',
          '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">14</span><span class="n">_accelerate_base_code_fp16_bs256</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Traceback (most recent call last):',
          '  File "/home/wallabot/Documentos/web/portafolio/posts/accelerate_scripts/13_accelerate_base_code_fp16_bs256.py", line 12, in &lt;module&gt;',
          '    accelerator = Accelerator()',
          '                  ^^^^^^^^^^^^^',
          '  File "/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/accelerator.py", line 371, in __init__',
          '    self.state = AcceleratorState(',
          '                 ^^^^^^^^^^^^^^^^^',
          '  File "/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/state.py", line 790, in __init__',
          '    raise ValueError(',
          'ValueError: Using `fp8` precision requires `transformer_engine` or `MS-AMP` to be installed.',
          'Traceback (most recent call last):',
          '  File "/home/wallabot/Documentos/web/portafolio/posts/accelerate_scripts/13_accelerate_base_code_fp16_bs256.py", line 12, in &lt;module&gt;',
          '    accelerator = Accelerator()',
          '                  ^^^^^^^^^^^^^',
          '  File "/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/accelerator.py", line 371, in __init__',
          '    self.state = AcceleratorState(',
          '                 ^^^^^^^^^^^^^^^^^',
          '  File "/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/state.py", line 790, in __init__',
          '    raise ValueError(',
          'ValueError: Using `fp8` precision requires `transformer_engine` or `MS-AMP` to be installed.',
          '[2024-05-13 21:40:56,455] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 501480) of binary: /home/wallabot/miniconda3/envs/nlp/bin/python',
          'Traceback (most recent call last):',
          '  File "/home/wallabot/miniconda3/envs/nlp/bin/accelerate", line 8, in &lt;module&gt;',
          '    sys.exit(main())',
          '             ^^^^^^',
          '  File "/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/commands/accelerate_cli.py", line 46, in main',
          '    args.func(args)',
          '  File "/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/commands/launch.py", line 1048, in launch_command',
          '    multi_gpu_launcher(args)',
          '  File "/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/commands/launch.py", line 702, in multi_gpu_launcher',
          '    distrib_run.run(args)',
          '  File "/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/distributed/run.py", line 803, in run',
          '    elastic_launch(',
          '  File "/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 135, in __call__',
          '    return launch_agent(self._config, self._entrypoint, list(args))',
          '           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^',
          '  File "/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent',
          '    raise ChildFailedError(',
          'torch.distributed.elastic.multiprocessing.errors.ChildFailedError: ',
          '============================================================',
          'accelerate_scripts/13_accelerate_base_code_fp16_bs256.py FAILED',
          '------------------------------------------------------------',
          'Failures:',
          '[1]:',
          '  time      : 2024-05-13_21:40:56',
          '  host      : wallabot',
          '  rank      : 1 (local_rank: 1)',
          '  exitcode  : 1 (pid: 501481)',
          '  error_file: &lt;N/A&gt;',
          '  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html',
          '------------------------------------------------------------',
          'Root Cause (first observed failure):',
          '[0]:',
          '  time      : 2024-05-13_21:40:56',
          '  host      : wallabot',
          '  rank      : 0 (local_rank: 0)',
          '  exitcode  : 1 (pid: 501480)',
          '  error_file: &lt;N/A&gt;',
          '  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html',
          '============================================================',
          'CPU times: user 65.1 ms, sys: 14.5 ms, total: 79.6 ms',
          'Wall time: 7.24 s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Como los pesos ahora son de 8 bits y ocupan la mitad de memoria vamos a subir el batch size a 512</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/15_accelerate_base_code_fp8_bs512.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">import</span> <span class="nn">tqdm</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">512</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '    ',
          '<span class="n">accelerator</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Writing accelerate_scripts/15_accelerate_base_code_fp8_bs512.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Lo ejecutamos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="o">%%time</span>',
      '      ',
      '      <span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">15</span><span class="n">_accelerate_base_code_fp8_bs512</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>








      
      <section class="section-block-markdown-cell">
      <h2 id="Inferencia-de-modelos">Inferencia de modelos<a class="anchor-link" href="#Inferencia-de-modelos"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 20" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Uso-del-ecosistema-de-Hugging-Face">Uso del ecosistema de Hugging Face<a class="anchor-link" href="#Uso-del-ecosistema-de-Hugging-Face"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 21" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a ver c贸mo hacer inferencia de grandes modelos con la librer铆a <code>transformers</code> de hugging face.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h4 id="Inferencia-con-pipeline">Inferencia con <code>pipeline</code><a class="anchor-link" href="#Inferencia-con-pipeline"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 22" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Si usamos el ecosistema de Hugging Face es muy sencillo, ya que todo se produce por debajo sin tener que hacer nosotros mucho. En el caso de usar <code>pipeline</code>, que es la manera m谩s sencilla de hacer inferencia con la librer铆a <code>transformers</code>, simplemente tenemos que decirle el modelo que queremos usar y muy importante, pasarle <code>device_map="auto"</code>. Esto har谩 que por debajo <code>accelerate</code> distribuya el modelo entre las distintas GPUs, RAM de la CPU o disco duro si es necesario</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Hay m谩s posibles valores para <code>device_map</code>, que los veremos m谩s adelante, pero de momento qu茅date con <code>"auto"</code>.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a usar el modelo <code>Llama3 8B</code>, que como su nombre indica es un modelo de unos 8 mil millones de par谩metros, como cada par谩metro por defecto est谩 en formato FP32, que corresponde a 4 bytes (32 bits), eso quiere decir que si multiplicamos 8 mil millones de par谩metros por 4 bytes, nos queda que necesitar铆a una GPU con unos 32 GB de VRAM.</p>
      <p>En mi caso tengo 2 GPUs de 24 GB de VRAM, por lo que no entrar铆a en una sola GPU. Pero gracias a poner <code>device_map="auto"</code>, accelerate desitribuir谩 el modelo entre las dos GPUs y podr茅 realizar la inferencia</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%time</span>',
          '',
          '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">15</span><span class="n">_accelerate_base_code_fp8_bs512</span><span class="o">.</span><span class="n">py</span>',
          '</span><span class="o">%%writefile</span> accelerate_scripts/16_inference_with_pipeline.py',
          '',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">pipeline</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"meta-llama/Meta-Llama-3-8B-Instruct"</span>',
          '<span class="n">generator</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">checkpoints</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s2">"auto"</span><span class="p">)</span>',
          '',
          '<span class="n">prompt</span> <span class="o">=</span> <span class="s2">"Conoces accelerate de hugging face?"</span>',
          '<span class="n">output</span> <span class="o">=</span> <span class="n">generator</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/09_inference_with_pipeline.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Ahora lo ejecutamos, solo que como pipeline usa por debajo accelerate, no necesitamos ejecutarlo con <code>acelerate launch script.py</code> sino que con <code>python script.py</code> vale</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">!</span>python<span class="w"> </span>accelerate_scripts/16_inference_with_pipeline.py',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Loading checkpoint shards: 100%|| 4/4 [00:09&lt;00:00,  2.27s/it]',
          'Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.',
          'Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.',
          '[{\'generated_text\': \'Conoces accelerate de hugging face? 驴Qu茅 es el modelo de lenguaje de transformers y c贸mo se utiliza en el marco de hugging face? 驴C贸mo puedo utilizar modelos de lenguaje de transformers en mi aplicaci贸n? 驴Qu茅 son los tokenizers y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo crear un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los datasets y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar datasets para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los evaluadores y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los pre-trainados y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los finetuning y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los checkpoints y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los evaluadores y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los pre-trainados y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los finetuning y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los checkpoints y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los evaluadores y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los pre-trainados y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los finetuning y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los checkpoints y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los evaluadores y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los pre-trainados y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los finetuning y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los checkpoints y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los evaluadores y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los pre-trainados y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los finetuning y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los checkpoints y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los evaluadores y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los pre-trainados y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los finetuning y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los checkpoints y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los evaluadores y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los pre-trainados y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los finetuning y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los checkpoints y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los evaluadores y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los pre-trainados y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los finetuning y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los checkpoints y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los evaluadores y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los pre-trainados y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los finetuning y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los checkpoints y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los evaluadores y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los pre-trainados y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los finetuning y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los checkpoints y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los evaluadores y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los pre-trainados y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los finetuning y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los checkpoints y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los evaluadores y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los pre-trainados y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los finetuning y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los checkpoints y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los evaluadores y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los pre-trainados y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los finetuning y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los checkpoints y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los evaluadores y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los pre-trainados y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los finetuning y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los checkpoints y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los evaluadores y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los pre-trainados y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los finetuning y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los checkpoints y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los evaluadores y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los pre-trainados y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los finetuning y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los checkpoints y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los evaluadores y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los pre-trainados y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los finetuning y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los checkpoints y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los evaluadores y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los pre-trainados y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los finetuning y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los checkpoints y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los evaluadores y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los pre-trainados y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los finetuning y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los checkpoints y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los evaluadores y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los pre-trainados y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los finetuning y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los checkpoints y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los evaluadores y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los pre-trainados y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los finetuning y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los checkpoints y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los evaluadores y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los pre-trainados y c贸mo se utilizan en el marco de hugging face? 驴C贸mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? 驴Qu茅 son los finetuning\'}]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Como se puede ver, no ha respondido, sino que ha seguido haciendo preguntas. Esto es porque Llama3 es un modelo de lenguaje que lo que hace es predecir el siguiente token, as铆 que con el prompt que le he pasado, ha considerado que los siguientes mejores tokens son unos que corresponden a m谩s preguntas. Lo cual tiene sentido, porque hay veces que la gente tiene dudas sobre un tema y genera muchas preguntas, as铆 que para que nos conteste a la pregunta hay que condicionarle un poco</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/17_inference_with_pipeline_condition.py',
          '',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">pipeline</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"meta-llama/Meta-Llama-3-8B-Instruct"</span>',
          '<span class="n">generator</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">checkpoints</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s2">"auto"</span><span class="p">)</span>',
          '',
          '<span class="n">prompt</span> <span class="o">=</span> <span class="s2">"Conoces accelerate de hugging face?"</span>',
          '<span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>',
          '    <span class="p">{</span>',
          '        <span class="s2">"role"</span><span class="p">:</span> <span class="s2">"system"</span><span class="p">,</span>',
          '        <span class="s2">"content"</span><span class="p">:</span> <span class="s2">"Eres un chatbot amigable que siempre intenta solucionar las dudas"</span><span class="p">,</span>',
          '    <span class="p">},</span>',
          '    <span class="p">{</span><span class="s2">"role"</span><span class="p">:</span> <span class="s2">"user"</span><span class="p">,</span> <span class="s2">"content"</span><span class="p">:</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">prompt</span><span class="si">}</span><span class="s2">"</span><span class="p">},</span>',
          '<span class="p">]</span>',
          '<span class="n">output</span> <span class="o">=</span> <span class="n">generator</span><span class="p">(</span><span class="n">messages</span><span class="p">)</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">\'generated_text\'</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/10_inference_with_pipeline_condition.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Como ves se ha generado un mensaje con roles, condicionando el modelo y con el prompt</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">!</span>python<span class="w"> </span>accelerate_scripts/17_inference_with_pipeline_condition.py',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Loading checkpoint shards: 100%|| 4/4 [00:09&lt;00:00,  2.41s/it]',
          'Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.',
          'Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.',
          '{\'role\': \'assistant\', \'content\': \'隆Hola!\n\nS铆, conozco Accelerate de Hugging Face. Accelerate es una biblioteca de Python desarrollada por Hugging Face que se enfoca en simplificar y acelerar el entrenamiento y la evaluaci贸n de modelos de lenguaje en diferentes dispositivos y entornos.\n\nCon Accelerate, puedes entrenar modelos de lenguaje en diferentes plataformas y dispositivos, como GPUs, TPUs, CPUs y servidores, sin necesidad de cambiar el c贸digo de tu modelo. Esto te permite aprovechar al m谩ximo la potencia de c谩lculo de tus dispositivos y reducir el tiempo de entrenamiento.\n\nAccelerate tambi茅n ofrece varias caracter铆sticas adicionales, como:\n\n* Soporte para diferentes frameworks de machine learning, como TensorFlow, PyTorch y JAX.\n* Integraci贸n con diferentes sistemas de almacenamiento y procesamiento de datos, como Amazon S3 y Google Cloud Storage.\n* Soporte para diferentes protocolos de comunicaci贸n, como HTTP y gRPC.\n* Herramientas para monitorear y depurar tus modelos en tiempo real.\n\nEn resumen, Accelerate es una herramienta muy 煤til para desarrolladores de modelos de lenguaje que buscan simplificar y acelerar el proceso de entrenamiento y evaluaci贸n de sus modelos.\n\n驴Tienes alguna pregunta espec铆fica sobre Accelerate o necesitas ayuda para implementarlo en tu proyecto?\'}',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Ahora la respuesta si responde nuestro prompt</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h4 id="Inferencia-con-AutoClass">Inferencia con <code>AutoClass</code><a class="anchor-link" href="#Inferencia-con-AutoClass"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 23" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Por 煤ltimo vamos a ver c贸mo hacer la inferencia solo con <code>AutoClass</code>.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/18_inference_with_autoclass.py',
          '',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">TextStreamer</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"meta-llama/Meta-Llama-3-8B-Instruct"</span>',
          '',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s2">"auto"</span><span class="p">)</span>',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s2">"auto"</span><span class="p">)</span>',
          '<span class="n">streamer</span> <span class="o">=</span> <span class="n">TextStreamer</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">)</span>',
          '',
          '<span class="n">prompt</span> <span class="o">=</span> <span class="s2">"Conoces accelerate de hugging face?"</span>',
          '<span class="n">tokens_input</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">([</span><span class="n">prompt</span><span class="p">],</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>',
          '',
          '<span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="o">**</span><span class="n">tokens_input</span><span class="p">,</span> <span class="n">streamer</span><span class="o">=</span><span class="n">streamer</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">do_sample</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">top_p</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/11_inference_with_autoclass.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Como se puede ver, se ha creado el objeto <code>streamer</code> que luego se le pasa al m茅todo <code>generate</code> del modelo. Esto es 煤til para que se vaya imprimiendo cada palabra a medida que se va generando y no haya que esperar a que se genere toda la salida para imprimirla</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">!</span>python<span class="w"> </span>accelerate_scripts/18_inference_with_autoclass.py',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.',
          'Loading checkpoint shards: 100%|| 4/4 [00:09&lt;00:00,  2.28s/it]',
          'Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.',
          '&lt;|begin_of_text|&gt;Conoces accelerate de hugging face? Si es as铆, puedes utilizar la biblioteca `transformers` de Hugging Face para crear un modelo de lenguaje que pueda predecir la siguiente palabra en una secuencia de texto.',
          'Aqu铆 te muestro un ejemplo de c贸mo hacerlo:',
          '```',
          'import pandas as pd',
          'import torch',
          'from transformers import AutoModelForSequenceClassification, AutoTokenizer',
          '# Cargar el modelo y el tokenizador',
          'model_name = "bert-base-uncased"',
          'model = AutoModelForSequenceClassification.from_pretrained(model_name)',
          'tokenizer = AutoTokenizer.from_pretrained(model_name)',
          '# Cargar el conjunto de datos',
          'train_df = pd.read_csv("train.csv")',
          'test_df = pd.read_csv("test.csv")',
          '# Preprocesar los datos',
          'train_texts = train_df["text"]',
          'train_labels = train_df["label"]',
          'test_texts = test_df["text"]',
          '# Convertir los textos en entradas para el modelo',
          'train_encodings = tokenizer.batch_encode_plus(train_texts, ',
          '                                              add_special_tokens=True, ',
          '                                              max_length=512, ',
          '                                              return_attention_mask=True, ',
          '                                              return_tensors=\'pt\')',
          'test_encodings = tokenizer.batch_encode_plus(test_texts, ',
          '                                             add_special_tokens=True, ',
          '                                             max_length=512, ',
          '                                             return_attention_mask=True, ',
          '                                             return_tensors=\'pt\')',
          '# Crear un dataloader para entrenar el modelo',
          'train_dataset = torch.utils.data.TensorDataset(train_encodings["input_ids"], ',
          '                                               train_encodings["attention_mask"], ',
          '                                               torch.tensor(train_labels))',
          'train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)',
          '# Entrenar el modelo',
          'device = torch.device("cuda" if torch.cuda.is_available() else "cpu")',
          'model.to(device)',
          'criterion = torch.nn.CrossEntropyLoss()',
          'optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)',
          'for epoch in range(5):',
          '    model.train()',
          '    total_loss = 0',
          '    for batch in train_loader:',
          '        input_ids = batch[0].to(device)',
          '        attention_mask = batch[1].to(device)',
          '        labels = batch[2].to(device)',
          '        optimizer.zero_grad()',
          '        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)',
          '        loss = criterion(outputs, labels)',
          '        loss.backward()',
          '        optimizer.step()',
          '        total_loss += loss.item()',
          '    print(f"Epoch {epoch+1}, Loss: {total',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Uso-pytorch">Uso pytorch<a class="anchor-link" href="#Uso-pytorch"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 24" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Normalmente la manera de hacer inferencias con pytorch es crear un modelo con los pesos inicializados aleatoriamente y a continuaci贸n cargar un <code>state dict</code> con los pesos del modelo preentrenado, as铆 que para obtener ese <code>state dict</code> vamos a hacer primero una peque帽a trampa y nos los vamos a descargar</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">import</span> <span class="nn">torchvision.models</span> <span class="k">as</span> <span class="nn">models</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet152</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">models</span><span class="o">.</span><span class="n">ResNet152_Weights</span><span class="o">.</span><span class="n">IMAGENET1K_V1</span><span class="p">)</span>',
          '<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">\'accelerate_scripts/resnet152_pretrained.pth\'</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Downloading: "https://download.pytorch.org/models/resnet152-394f9c45.pth" to /home/maximo.fernandez/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth',
          '100%|| 230M/230M [02:48&lt;00:00, 1.43MB/s] ',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Ahora que tenemos el <code>state dict</code> vamos a hacer inferencia como se hace normalmente en pytorch</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">import</span> <span class="nn">torchvision.models</span> <span class="k">as</span> <span class="nn">models</span>',
          '',
          '<span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span>     <span class="c1"># Set device</span>',
          '',
          '<span class="n">resnet152</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet152</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="c1"># Create model with random weights and move to device</span>',
          '<span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">\'accelerate_scripts/resnet152_pretrained.pth\'</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="c1"># Load pretrained weights into device memory</span>',
          '<span class="n">resnet152</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span> <span class="c1"># Load this weights into the model</span>',
          '',
          '<span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Random image with batch size 1</span>',
          '<span class="n">output</span> <span class="o">=</span> <span class="n">resnet152</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>',
          '<span class="n">output</span><span class="o">.</span><span class="n">shape</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'torch.Size([1, 1000])',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a explicar qu茅 ha pasado</p>
      <ul>
      <li>Cuando hemos hecho <code>resnet152 = models.resnet152().to(device)</code> se ha cargado una resnet152 con pesos aleatorios en la memoria de la GPU</li>
      <li>Cuando hemos hecho <code>state_dict = torch.load('accelerate_scripts/resnet152_pretrained.pth', map_location=device)</code> se ha cargado un diccionario con los pesos entrenados en la memoria de la GPU</li>
      <li>Cuando hemos hecho <code>resnet152.load_state_dict(state_dict)</code> se han asignado esos pesos preentrenados al modelo</li>
      </ul>
      <p>Es decir se ha cargado dos veces el modelo en la memoria de la GPU</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Te puedes estar preguntando por qu茅 hemos hecho primero</p>
      <div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet152</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">models</span><span class="o">.</span><span class="n">ResNet152_Weights</span><span class="o">.</span><span class="n">IMAGENET1K_V1</span><span class="p">)</span>
      <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">'accelerate_scripts/resnet152_pretrained.pth'</span><span class="p">)</span>
      </pre></div>
      <p>Para luego hacer</p>
      <div class="highlight"><pre><span></span><span class="n">resnet152</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet152</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
      <span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">'accelerate_scripts/resnet152_pretrained.pth'</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
      <span class="n">resnet152</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span>
      </pre></div>
      <p>Y por que no usamos directamente</p>
      <pre><code>model = models.resnet152(weights=models.ResNet152_Weights.IMAGENET1K_V1)</code></pre>
      <p>Y nos dejamos de guardar el <code>state dict</code> para luego cargarlo. Bueno, pues porque Pytorch, por edbajo hace lo mismo que hemos hecho. As铆 que para poder ver todo el proceso hemos hecho en varias lineas lo que Pytorch hace en una</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Esta manera de trabajar ha funcionado bien hasta ahora, mientras que los modelos ten铆an un tama帽o manejable por las GPUs de usuario. Pero desde la llegada de los LLMs este enfoque no tiene sentido</p>
      <p>Por ejemplo un modelo de 6B de par谩metros ocupar铆a en la memoria 24 GB, y como se carga dos veces con esta manera de trabajar har铆a falta tener una GPU de 48 GB.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>As铆 que para arreglar esto, la manera de cargar un modelo preentrenado de Pytorch es:</p>
      <ul>
      <li>Crear un modelo vac铆o con <code>init_empty_weights</code> que no ocupar谩 RAM</li>
      <li>Luego cargar los pesos con <code>load_checkpoint_and_dispatch</code> que cargar谩 un punto de control dentro del modelo vac铆o y distribuir谩 los pesos para cada capa en todos los dispositivos que se tenga disponibles (GPU, CPU RAM y disco duro), gracias a poner <code>device_map="auto"</code></li>
      </ul>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">import</span> <span class="nn">torchvision.models</span> <span class="k">as</span> <span class="nn">models</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">init_empty_weights</span><span class="p">,</span> <span class="n">load_checkpoint_and_dispatch</span>',
          '',
          '<span class="k">with</span> <span class="n">init_empty_weights</span><span class="p">():</span>',
          '    <span class="n">resnet152</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet152</span><span class="p">()</span>',
          '',
          '<span class="n">resnet152</span> <span class="o">=</span> <span class="n">load_checkpoint_and_dispatch</span><span class="p">(</span><span class="n">resnet152</span><span class="p">,</span> <span class="n">checkpoint</span><span class="o">=</span><span class="s1">\'accelerate_scripts/resnet152_pretrained.pth\'</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s2">"auto"</span><span class="p">)</span>',
          '',
          '<span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span>',
          '',
          '<span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Random image with batch size 1</span>',
          '<span class="n">output</span> <span class="o">=</span> <span class="n">resnet152</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>',
          '<span class="n">output</span><span class="o">.</span><span class="n">shape</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'torch.Size([1, 1000])',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="C%C3%B3mo-funciona-accelerate-por-debajo">C贸mo funciona accelerate por debajo<a class="anchor-link" href="#C%C3%B3mo-funciona-accelerate-por-debajo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 25" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>En este v铆deo se puede ver gr谩ficamente c贸mo funciona accelerate por debajo</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" frameborder="0" height="720" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/MWCSGj9jEAo" title="Accelerate Big Model Inference: How Does it Work?" width="1280"></iframe>
      </section>
      
      <section class="section-block-markdown-cell">
      <h4 id="Inicializaci%C3%B3n-de-un-modelo-vac%C3%ADo">Inicializaci贸n de un modelo vac铆o<a class="anchor-link" href="#Inicializaci%C3%B3n-de-un-modelo-vac%C3%ADo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 26" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p><code>Accelerate</code> crea el esqueleto de un modelo vac铆o mediante <code>init_empty_weights</code> para que ocupe la menor cantidad de memoria posible</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Por ejemplo, veamos cuanta RAM tengo ahora disponible en mi ordenador</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">import</span> <span class="nn">psutil</span>',
          '',
          '<span class="k">def</span> <span class="nf">get_ram_info</span><span class="p">():</span>',
          '    <span class="n">ram</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">psutil</span><span class="o">.</span><span class="n">virtual_memory</span><span class="p">()</span><span class="o">.</span><span class="n">_asdict</span><span class="p">())</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Total RAM: </span><span class="si">{</span><span class="p">(</span><span class="n">ram</span><span class="p">[</span><span class="s1">\'total\'</span><span class="p">]</span><span class="o">/</span><span class="mi">1024</span><span class="o">/</span><span class="mi">1024</span><span class="o">/</span><span class="mi">1024</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> GB, Available RAM: </span><span class="si">{</span><span class="p">(</span><span class="n">ram</span><span class="p">[</span><span class="s1">\'available\'</span><span class="p">]</span><span class="o">/</span><span class="mi">1024</span><span class="o">/</span><span class="mi">1024</span><span class="o">/</span><span class="mi">1024</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> GB, Used RAM: </span><span class="si">{</span><span class="p">(</span><span class="n">ram</span><span class="p">[</span><span class="s1">\'used\'</span><span class="p">]</span><span class="o">/</span><span class="mi">1024</span><span class="o">/</span><span class="mi">1024</span><span class="o">/</span><span class="mi">1024</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> GB"</span><span class="p">)</span>',
          '',
          '<span class="n">get_ram_info</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Total RAM: 31.24 GB, Available RAM: 22.62 GB, Used RAM: 7.82 GB',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Tengo unos 22 GB de RAM disponibles</p>
      <p>Ahora vamos a intentar crear un modelo 5000x1000x1000 par谩metros, es decir de 5B de par谩metros, si cada par谩metro est谩 en FP32, supone 20 GB de RAM</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
      '      <span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>',
      '      ',
      '      <span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">)])</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>









      
      <section class="section-block-markdown-cell">
      <p>Si volvemos a ver la RAM</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">)])</span>',
          '</span><span class="n">get_ram_info</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Total RAM: 31.24 GB, Available RAM: 3.77 GB, Used RAM: 26.70 GB',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Como vemos ahora solo tenemos 3 GB de RAM disponibles</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Ahora vamos a eliminar el modelo para liberar RAM</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="k">del</span> <span class="n">model</span>',
          '<span class="n">get_ram_info</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Total RAM: 31.24 GB, Available RAM: 22.44 GB, Used RAM: 8.03 GB',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Volvemos a tener unos 22 GB de RAM disponibles</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos ahora a usar <code>init_empty_weights</code> de <code>accelerate</code> y luego vemos la RAM</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">init_empty_weights</span>',
          '',
          '<span class="k">with</span> <span class="n">init_empty_weights</span><span class="p">():</span>',
          '    <span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">)])</span>',
          '',
          '<span class="n">get_ram_info</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Total RAM: 31.24 GB, Available RAM: 22.32 GB, Used RAM: 8.16 GB',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Antes ten铆amos exactamente 22.44 GB libres y tras crear el modelo con <code>init_empty_weights</code> tenemos 22.32 GB. El ahorro en RAM es enorme! Casi no se ha ocupado RAM para crear el modelo.</p>
      <p>Esto se basa en el metadispositivo introducido en PyTorch 1.9, por lo que es importante que para usar <code>accelerate</code> tengamos una versi贸n de Pytorch posterior</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h4 id="Carga-de-los-pesos">Carga de los pesos<a class="anchor-link" href="#Carga-de-los-pesos"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 27" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Una vez hemos inicializado el modelo tenemos que cargarle los pesos que lo hacemos mediante <code>load_checkpoint_and_dispatch</code> que como su nombre indica carga los pesos y los env铆a al dispositivo o dispositivos que sea necesario</p>
      </section>
      






    </div>

  </section>

</PostLayout>
