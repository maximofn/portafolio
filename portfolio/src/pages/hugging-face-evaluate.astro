---
import PostLayout from '@layouts/PostLayout.astro';
import CodeBlockInputCell from '@components/CodeBlockInputCell.astro';
import CodeBlockOutputCell from '@components/CodeBlockOutputCell.astro';

const { metadata_page } = await import('@portfolio/consts.json');
const { colors } = await import('@portfolio/consts.json');
const { svg_paths } = await import('@portfolio/consts.json');

const page_title = 'Hugging Face Evaluate';
const end_url = 'hugging-face-evaluate';
const description = '隆Olvida las noches en vela calculando m茅tricas y perdiendo la cabeza con la evaluaci贸n de tus modelos de NLP!  La librer铆a evaluate de Hugging Face es la respuesta a tus plegarias, permiti茅ndote evaluar el rendimiento de tus modelos con facilidad y rapidez . Con evaluate, puedes decir adi贸s a los c谩lculos manuales y hola a la automatizaci贸n total , lo que te deja m谩s tiempo para enfocarte en lo que realmente importa : mejorar tus modelos y revolucionar el mundo de la IA ';
const keywords = 'hugging face, evaluate, nlp, evaluaci贸n, m茅tricas, rendimiento, automatizaci贸n';
const languaje = 'ES';
const image_path = 'https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/evaluate_logo_mockup.webp';
const opening_brace = '{';
const closing_brace = '}';
---

<PostLayout 
    title={page_title}
    languaje={languaje}
    description={description}
    keywords={keywords}
    author={metadata_page.author}
    theme_color={colors.background_color}
    end_url={end_url}
    image_path={image_path}
    image_width=960
    image_height=720
    image_extension=png
    article_date=2021-04-29+T00:00:00Z
>

  <section class="post-body">


    <aside class="post-index">
      <a class="anchor-link" href="#Instalaci%C3%B3n"><h2>Instalaci贸n</h2></a>
      <a class="anchor-link" href="#Tipo-de-evaluaciones"><h2>Tipo de evaluaciones</h2></a>
      <a class="anchor-link" href="#Carga"><h2>Carga</h2></a>
      <a class="anchor-link" href="#Carga-de-m%C3%B3dulos-de-la-comunidad"><h3>Carga de m贸dulos de la comunidad</h3></a>
      <a class="anchor-link" href="#Lista-de-m%C3%B3dulos-disponibles"><h3>Lista de m贸dulos disponibles</h3></a>
      <a class="anchor-link" href="#Atributos-del-m%C3%B3dulo"><h2>Atributos del m贸dulo</h2></a>
      <a class="anchor-link" href="#Ejecuci%C3%B3n"><h2>Ejecuci贸n</h2></a>
      <a class="anchor-link" href="#Todo-en-uno"><h3>Todo en uno</h3></a>
      <a class="anchor-link" href="#Incremental"><h3>Incremental</h3></a>
      <a class="anchor-link" href="#Combinaci%C3%B3n-de-varias-evaluaciones"><h2>Combinaci贸n de varias evaluaciones</h2></a>
      <a class="anchor-link" href="#Guardar-los-resultados"><h2>Guardar los resultados</h2></a>
      <a class="anchor-link" href="#Subir-los-resultados-al-hub"><h2>Subir los resultados al hub</h2></a>
      <a class="anchor-link" href="#Evaluador"><h2>Evaluador</h2></a>
      <a class="anchor-link" href="#Visualizaci%C3%B3n"><h2>Visualizaci贸n</h2></a>
      <a class="anchor-link" href="#Evaluar-el-modelo-en-un-conjunto-de-tareas"><h2>Evaluar el modelo en un conjunto de tareas</h2></a>
    </aside>


    <div class="post-body-content">
      
      <section class="section-block-markdown-cell">
      <h1 id="Hugging-Face-evaluate">Hugging Face evaluate<a class="anchor-link" href="#Hugging-Face-evaluate"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 0" src={svg_paths.link_svg_path}/></a></h1>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>La librer铆a <code>Evaluate</code> de <code>Hugging Face</code> es una librer铆a para evaluar f谩cilmente modelos y datasets.</p>
      <p>Con una sola l铆nea de c贸digo, se tiene acceso a docenas de m茅todos de evaluaci贸n para diferentes dominios (NLP, computer vision, reinforcement learning y m谩s). Ya sea en tu m谩quina local, o en una configuraci贸n de entrenamiento distribuida, puedes evaluar modelos de manera consistente y reproducible</p>
      <p>En la p谩gina de <a href="https://huggingface.co/evaluate-metric" target="_blank" rel="nofollow noreferrer">evaluate</a> en Hugging Face se puede obtener una lista completa de las m茅tricas disponibles. Cada m茅trica tiene un <code>Space</code> de Hugging Face dedicado con una demostraci贸n interactiva sobre c贸mo usar la m茅trica y una tarjeta de documentaci贸n que detalla las limitaciones y el uso de las m茅tricas.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Instalaci%C3%B3n">Instalaci贸n<a class="anchor-link" href="#Instalaci%C3%B3n"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 1" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Para instalar la librer铆a es necesario hacer</p>
      <div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>evaluate
      </pre></div>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Tipo-de-evaluaciones">Tipo de evaluaciones<a class="anchor-link" href="#Tipo-de-evaluaciones"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 2" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Hay varios tipos de evaluaciones disponibles</p>
      <ul>
      <li><code>metric</code>: Una m茅trica se utiliza para evaluar el rendimiento de un modelo y, por lo general, incluye las predicciones del modelo y las etiquetas ground truth.</li>
      <li><code>comparison</code>: Se utiliza para comparar dos modelos. Esto se puede hacer, por ejemplo, comparando sus predicciones con etiquetas ground truth.</li>
      <li><code>measurement</code>: El dataset es tan importante como el modelo entrenado en 茅l. Con las mediciones se pueden investigar las propiedades de un dataset.</li>
      </ul>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Carga">Carga<a class="anchor-link" href="#Carga"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 3" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Cada <code>metric</code>, <code>comparison</code> o <code>measurement</code> se puede cargar con el m茅todo load</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">import</span> <span class="nn">evaluate</span>',
          '',
          '<span class="n">accuracy</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '<span class="n">accuracy</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'EvaluationModule(name: "accuracy", module_type: "metric", features: {\'predictions\': Value(dtype=\'int32\', id=None), \'references\': Value(dtype=\'int32\', id=None)}, usage: """',
          'Args:',
          '    predictions (`list` of `int`): Predicted labels.',
          '    references (`list` of `int`): Ground truth labels.',
          '    normalize (`boolean`): If set to False, returns the number of correctly classified samples. Otherwise, returns the fraction of correctly classified samples. Defaults to True.',
          '    sample_weight (`list` of `float`): Sample weights Defaults to None.',
          'Returns:',
          '    accuracy (`float` or `int`): Accuracy score. Minimum possible value is 0. Maximum possible value is 1.0, or the number of examples input, if `normalize` is set to `True`.. A higher score means higher accuracy.',
          'Examples:',
          '    Example 1-A simple example',
          '        &gt;&gt;&gt; accuracy_metric = evaluate.load("accuracy")',
          '        &gt;&gt;&gt; results = accuracy_metric.compute(references=[0, 1, 2, 0, 1, 2], predictions=[0, 1, 1, 2, 1, 0])',
          '        &gt;&gt;&gt; print(results)',
          '        {\'accuracy\': 0.5}',
          '    Example 2-The same as Example 1, except with `normalize` set to `False`.',
          '        &gt;&gt;&gt; accuracy_metric = evaluate.load("accuracy")',
          '        &gt;&gt;&gt; results = accuracy_metric.compute(references=[0, 1, 2, 0, 1, 2], predictions=[0, 1, 1, 2, 1, 0], normalize=False)',
          '        &gt;&gt;&gt; print(results)',
          '        {\'accuracy\': 3.0}',
          '    Example 3-The same as Example 1, except with `sample_weight` set.',
          '        &gt;&gt;&gt; accuracy_metric = evaluate.load("accuracy")',
          '        &gt;&gt;&gt; results = accuracy_metric.compute(references=[0, 1, 2, 0, 1, 2], predictions=[0, 1, 1, 2, 1, 0], sample_weight=[0.5, 2, 0.7, 0.5, 9, 0.4])',
          '        &gt;&gt;&gt; print(results)',
          '        {\'accuracy\': 0.8778625954198473}',
          '""", stored examples: 0)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Si quieres estar seguro de cargar el tipo de m茅trica que deseas, si tipo <code>metric</code>, <code>comparison</code> o <code>measurement</code>, puedes hacerlo a帽adiendo el par谩metro <code>module_type</code></p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">import</span> <span class="nn">evaluate</span>',
          '',
          '<span class="n">accuracy</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">,</span> <span class="n">module_type</span><span class="o">=</span><span class="s2">"metric"</span><span class="p">)</span>',
          '<span class="n">word_length</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"word_length"</span><span class="p">,</span> <span class="n">module_type</span><span class="o">=</span><span class="s2">"measurement"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '[nltk_data] Downloading package punkt to',
          '[nltk_data]     /home/maximo.fernandez/nltk_data...',
          '[nltk_data]   Package punkt is already up-to-date!',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Carga-de-m%C3%B3dulos-de-la-comunidad">Carga de m贸dulos de la comunidad<a class="anchor-link" href="#Carga-de-m%C3%B3dulos-de-la-comunidad"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 4" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>A parte de los propios m贸dulos que ofrece la librer铆a, tambi茅n puedes cargar modelos que haya subido algui茅n al hub de Hugging Face</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">element_count</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"lvwerra/element_count"</span><span class="p">,</span> <span class="n">module_type</span><span class="o">=</span><span class="s2">"measurement"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>






      
      <section class="section-block-markdown-cell">
      <h3 id="Lista-de-m%C3%B3dulos-disponibles">Lista de m贸dulos disponibles<a class="anchor-link" href="#Lista-de-m%C3%B3dulos-disponibles"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 5" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Si queremos obtener una lista de todos los m贸dulos disponibles tenemos que usar el m茅todo <code>list_evaluation_modules</code>, en el podemos poner filtros de b煤squeda</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">element_count</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"lvwerra/element_count"</span><span class="p">,</span> <span class="n">module_type</span><span class="o">=</span><span class="s2">"measurement"</span><span class="p">)</span>',
          '</span><span class="n">evaluate</span><span class="o">.</span><span class="n">list_evaluation_modules</span><span class="p">(</span>',
          '  <span class="n">module_type</span><span class="o">=</span><span class="s2">"comparison"</span><span class="p">,</span>',
          '  <span class="n">include_community</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
          '  <span class="n">with_details</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '[{\'name\': \'ncoop57/levenshtein_distance\',',
          '  \'type\': \'comparison\',',
          '  \'community\': True,',
          '  \'likes\': 0},',
          ' {\'name\': \'kaleidophon/almost_stochastic_order\',',
          '  \'type\': \'comparison\',',
          '  \'community\': True,',
          '  \'likes\': 1}]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h2 id="Atributos-del-m%C3%B3dulo">Atributos del m贸dulo<a class="anchor-link" href="#Atributos-del-m%C3%B3dulo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 6" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Todos los m贸dulos de evaluaci贸n vienen con una variedad de atributos 煤tiles que ayudan a utilizar el m贸dulo, estos atributos son</p>
      <table>
      <thead>
      <tr>
      <th>Atributo</th>
      <th>Descripci贸n</th>
      </tr>
      </thead>
      <tbody>
      <tr>
      <td>description</td>
      <td>Una breve descripci贸n del m贸dulo de evaluaci贸n.</td>
      </tr>
      <tr>
      <td>citation</td>
      <td>Una cadena BibTex para citar cuando est茅 disponible.</td>
      </tr>
      <tr>
      <td>features</td>
      <td>Un objeto Features que define el formato de entrada.</td>
      </tr>
      <tr>
      <td>inputs_description</td>
      <td>Esto es equivalente a la cadena de documentaci贸n de los m贸dulos.</td>
      </tr>
      <tr>
      <td>homepage</td>
      <td>La p谩gina de inicio del m贸dulo.</td>
      </tr>
      <tr>
      <td>license</td>
      <td>La licencia del m贸dulo.</td>
      </tr>
      <tr>
      <td>codebase_urls</td>
      <td>Enlace al c贸digo detr谩s del m贸dulo.</td>
      </tr>
      <tr>
      <td>reference_urls</td>
      <td>URL de referencia adicionales.</td>
      </tr>
      </tbody>
      </table>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Veamos algunos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>






      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '</span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"description: </span><span class="si">{</span><span class="n">accuracy</span><span class="o">.</span><span class="n">description</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\\n</span><span class="s2">citation: </span><span class="si">{</span><span class="n">accuracy</span><span class="o">.</span><span class="n">citation</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\\n</span><span class="s2">features: </span><span class="si">{</span><span class="n">accuracy</span><span class="o">.</span><span class="n">features</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\\n</span><span class="s2">inputs_description: </span><span class="si">{</span><span class="n">accuracy</span><span class="o">.</span><span class="n">inputs_description</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\\n</span><span class="s2">homepage: </span><span class="si">{</span><span class="n">accuracy</span><span class="o">.</span><span class="n">homepage</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\\n</span><span class="s2">license: </span><span class="si">{</span><span class="n">accuracy</span><span class="o">.</span><span class="n">license</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\\n</span><span class="s2">codebase_urls: </span><span class="si">{</span><span class="n">accuracy</span><span class="o">.</span><span class="n">codebase_urls</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\\n</span><span class="s2">reference_urls: </span><span class="si">{</span><span class="n">accuracy</span><span class="o">.</span><span class="n">reference_urls</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'description: ',
          'Accuracy is the proportion of correct predictions among the total number of cases processed. It can be computed with:',
          'Accuracy = (TP + TN) / (TP + TN + FP + FN)',
          ' Where:',
          'TP: True positive',
          'TN: True negative',
          'FP: False positive',
          'FN: False negative',
          'citation: ',
          '@article{scikit-learn,',
          '  title={Scikit-learn: Machine Learning in {P}ython},',
          '  author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.',
          '         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.',
          '         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and',
          '         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},',
          '  journal={Journal of Machine Learning Research},',
          '  volume={12},',
          '  pages={2825--2830},',
          '  year={2011}',
          '}',
          'features: {\'predictions\': Value(dtype=\'int32\', id=None), \'references\': Value(dtype=\'int32\', id=None)}',
          'inputs_description: ',
          'Args:',
          '    predictions (`list` of `int`): Predicted labels.',
          '    references (`list` of `int`): Ground truth labels.',
          '    normalize (`boolean`): If set to False, returns the number of correctly classified samples. Otherwise, returns the fraction of correctly classified samples. Defaults to True.',
          '    sample_weight (`list` of `float`): Sample weights Defaults to None.',
          'Returns:',
          '    accuracy (`float` or `int`): Accuracy score. Minimum possible value is 0. Maximum possible value is 1.0, or the number of examples input, if `normalize` is set to `True`.. A higher score means higher accuracy.',
          'Examples:',
          '    Example 1-A simple example',
          '        &gt;&gt;&gt; accuracy_metric = evaluate.load("accuracy")',
          '        &gt;&gt;&gt; results = accuracy_metric.compute(references=[0, 1, 2, 0, 1, 2], predictions=[0, 1, 1, 2, 1, 0])',
          '        &gt;&gt;&gt; print(results)',
          '        {\'accuracy\': 0.5}',
          '    Example 2-The same as Example 1, except with `normalize` set to `False`.',
          '        &gt;&gt;&gt; accuracy_metric = evaluate.load("accuracy")',
          '        &gt;&gt;&gt; results = accuracy_metric.compute(references=[0, 1, 2, 0, 1, 2], predictions=[0, 1, 1, 2, 1, 0], normalize=False)',
          '        &gt;&gt;&gt; print(results)',
          '        {\'accuracy\': 3.0}',
          '    Example 3-The same as Example 1, except with `sample_weight` set.',
          '        &gt;&gt;&gt; accuracy_metric = evaluate.load("accuracy")',
          '        &gt;&gt;&gt; results = accuracy_metric.compute(references=[0, 1, 2, 0, 1, 2], predictions=[0, 1, 1, 2, 1, 0], sample_weight=[0.5, 2, 0.7, 0.5, 9, 0.4])',
          '        &gt;&gt;&gt; print(results)',
          '        {\'accuracy\': 0.8778625954198473}',
          'homepage: ',
          'license: ',
          'codebase_urls: []',
          'reference_urls: [\'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html']',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h2 id="Ejecuci%C3%B3n">Ejecuci贸n<a class="anchor-link" href="#Ejecuci%C3%B3n"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 7" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Ahora que sabemos c贸mo funciona el m贸dulo de evaluaci贸n y qu茅 debe contener, vamos a usarlo. Cuando se trata de calcular la evaluaci贸n, hay dos formas principales de hacerlo:</p>
      <ul>
      <li>Todo en uno</li>
      <li>Incremental</li>
      </ul>
      <p>En el enfoque incremental, las entradas necesarias se agregan al m贸dulo con <code>EvaluationModule.add()</code> o <code>EvaluationModule.add_batch()</code> y la puntuaci贸n se calcula al final con <code>EvaluationModule.compute()</code>. Alternativamente, se pueden pasar todas las entradas a la vez a <code>compute()</code>.</p>
      <p>Veamos estos dos enfoques.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Todo-en-uno">Todo en uno<a class="anchor-link" href="#Todo-en-uno"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 8" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Una vez tenemos todas las predicciones y ground truth podemos calcular la m茅trica. Una vez que tenemos un m贸dulo definido, le pasamos las predicciones y los ground truth mediante el m茅todo <code>compute()</code></p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>






      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '</span><span class="n">predictions</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>',
          '<span class="n">targets</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>',
          '',
          '<span class="n">accuracy_value</span> <span class="o">=</span> <span class="n">accuracy</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">targets</span><span class="p">)</span>',
          '<span class="n">accuracy_value</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '{\'accuracy\': 0.5}',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Incremental">Incremental<a class="anchor-link" href="#Incremental"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 9" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>En muchos procesos de evaluaci贸n, las predicciones se construyen de forma iterativa, como en un bucle for. En ese caso, podr铆as almacenar las predicciones y ground truth en una lista y al final pasarlas a <code>compute()</code>.</p>
      <p>Sin embargo con los m茅todos <code>add()</code> y <code>add_batch()</code> puedes evitar el paso de almacenar las predicciones.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Si tienes todas las predicciones de un solo batch hay que usar el m茅todo <code>add()</code></p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="k">for</span> <span class="n">ref</span><span class="p">,</span> <span class="n">pred</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]):</span>',
          '    <span class="n">accuracy</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">references</span><span class="o">=</span><span class="n">ref</span><span class="p">,</span> <span class="n">predictions</span><span class="o">=</span><span class="n">pred</span><span class="p">)</span>',
          '<span class="n">accuracy_value</span> <span class="o">=</span> <span class="n">accuracy</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '<span class="n">accuracy_value</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '{\'accuracy\': 0.5}',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Sin embargo, cuando se tienen predicciones de varios batches se tiene que usar el m茅todo <code>add_batch()</code></p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="k">for</span> <span class="n">refs</span><span class="p">,</span> <span class="n">preds</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]]):</span>',
          '    <span class="n">accuracy</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">references</span><span class="o">=</span><span class="n">refs</span><span class="p">,</span> <span class="n">predictions</span><span class="o">=</span><span class="n">preds</span><span class="p">)</span>',
          '<span class="n">accuracy_value</span> <span class="o">=</span> <span class="n">accuracy</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '<span class="n">accuracy_value</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '{\'accuracy\': 0.5}',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h2 id="Combinaci%C3%B3n-de-varias-evaluaciones">Combinaci贸n de varias evaluaciones<a class="anchor-link" href="#Combinaci%C3%B3n-de-varias-evaluaciones"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 10" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>A menudo, uno quiere no solo evaluar una 煤nica m茅trica, sino tambi茅n una variedad de m茅tricas diferentes que capturan diferentes aspectos de un modelo. Por ejemplo, para la clasificaci贸n suele ser una buena idea calcular el <code>F1</code>, el <code>recall</code> y la <code>precisi贸n</code> adem谩s del <code>accuracy</code> para obtener una mejor imagen del rendimiento del modelo. <code>Evaluate</code> permite cargar un mont贸n de m茅tricas y llamarlas secuencialmente. Sin embargo, la forma m谩s conveniente es usar la funci贸n <code>combine()</code> para agruparlas</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">clasification_metrics</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">combine</span><span class="p">([</span><span class="s2">"accuracy"</span><span class="p">,</span> <span class="s2">"f1"</span><span class="p">,</span> <span class="s2">"precision"</span><span class="p">,</span> <span class="s2">"recall"</span><span class="p">])</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>






      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">clasification_metrics</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">combine</span><span class="p">([</span><span class="s2">"accuracy"</span><span class="p">,</span> <span class="s2">"f1"</span><span class="p">,</span> <span class="s2">"precision"</span><span class="p">,</span> <span class="s2">"recall"</span><span class="p">])</span>',
          '</span><span class="n">predictions</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>',
          '<span class="n">targets</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>',
          '',
          '<span class="n">clasification_metrics</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">targets</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '{\'accuracy\': 0.6666666666666666,',
          ' \'f1\': 0.6666666666666666,',
          ' \'precision\': 1.0,',
          ' \'recall\': 0.5}',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h2 id="Guardar-los-resultados">Guardar los resultados<a class="anchor-link" href="#Guardar-los-resultados"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 11" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Podemos guardar los resultados de la evaluaci贸n en un archivo con el m茅todo <code>save()</code>, para ello le pasamos un nombre de archivo. Podemos pasarle par谩metros como el n煤mero de experimento</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">references</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>',
          '<span class="n">targets</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>',
          '',
          '<span class="n">result</span> <span class="o">=</span> <span class="n">accuracy</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">references</span><span class="o">=</span><span class="n">references</span><span class="p">,</span> <span class="n">predictions</span><span class="o">=</span><span class="n">targets</span><span class="p">)</span>',
          '',
          '<span class="n">hyperparams</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"model"</span><span class="p">:</span> <span class="s2">"bert-base-uncased"</span><span class="p">}</span>',
          '<span class="n">evaluate</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">"./results/"</span><span class="p">,</span> <span class="n">experiment</span><span class="o">=</span><span class="s2">"run 42"</span><span class="p">,</span> <span class="o">**</span><span class="n">result</span><span class="p">,</span> <span class="o">**</span><span class="n">hyperparams</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'PosixPath(\'results/result-2024_04_25-17_45_41.json\')',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Como vemos hemos tenido que crear una variable <code>hyperparams</code> para pas谩rsela al m茅todo <code>save()</code>. Esto normalmente no har谩 falta porque ya tendremos los del modelo que estemos entrenando</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Esto crear谩 un <code>json</code> con toda la informaci贸n</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">import</span> <span class="nn">pathlib</span>',
          '',
          '<span class="n">path</span> <span class="o">=</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="s2">"./results/"</span><span class="p">)</span>',
          '<span class="n">files</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">path</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s2">"*"</span><span class="p">))</span>',
          '<span class="n">files</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '[PosixPath(\'results/result-2024_04_25-17_45_41.json\')]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">import</span> <span class="nn">json</span>',
          '<span class="n">result_file</span> <span class="o">=</span> <span class="n">files</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>',
          '<span class="n">result_json</span> <span class="o">=</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="n">result_file</span><span class="p">)</span><span class="o">.</span><span class="n">read_text</span><span class="p">()</span>',
          '<span class="n">result_dict</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">result_json</span><span class="p">)</span>',
          '<span class="n">result_dict</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '{\'experiment\': \'run 42\',',
          ' \'accuracy\': 0.5,',
          ' \'model\': \'bert-base-uncased\',',
          ' \'_timestamp\': \'2024-04-25T17:45:41.218287\',',
          ' \'_git_commit_hash\': \'8725338b6bf9c97274685df41b2ee6e11319a735\',',
          ' \'_evaluate_version\': \'0.4.1\',',
          ' \'_python_version\': \'3.11.7 (main, Dec 15 2023, 18:12:31) [GCC 11.2.0]\',',
          ' \'_interpreter_path\': \'/home/maximo.fernandez/miniconda3/envs/nlp/bin/python\'}',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h2 id="Subir-los-resultados-al-hub">Subir los resultados al hub<a class="anchor-link" href="#Subir-los-resultados-al-hub"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 12" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>En caso de estar entrenando un modelo, podemos subir a la model card del modelo los resultados de la evaluaci贸n con el m茅todo <code>push_to_hub()</code>. De esta manera aparecer谩n en la p谩gina del modelo</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Evaluador">Evaluador<a class="anchor-link" href="#Evaluador"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 13" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Si tenemos un modelo, un dataset y una m茅trica, podemos hacer inferencia por todo el dataset y pasarle al evaluador las predicciones y las etiquetas reales para que nos devuelva la m茅trica y as铆 obtener las m茅tricas del modelo.</p>
      <p>O podemos darle todo a la librer铆a y que haga el trabajo por nosotros. Mediante el m茅todo <code>evaluator()</code>, le pasamos el modelo, el dataset y la m茅trica y el m茅todo se encarga de hacer todo por nosotros</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Primero definimos el modelos, el dataset y la m茅trica</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">pipeline</span>',
      '      <span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
      '      <span class="kn">from</span> <span class="nn">evaluate</span> <span class="kn">import</span> <span class="n">evaluator</span>',
      '      <span class="kn">import</span> <span class="nn">evaluate</span>',
      '      ',
      '      <span class="n">model_pipeline</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">"text-classification"</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s2">"lvwerra/distilbert-imdb"</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>',
      '      <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"imdb"</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">"test"</span><span class="p">)</span><span class="o">.</span><span class="n">shuffle</span><span class="p">()</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">))</span>',
      '      <span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>













      
      <section class="section-block-markdown-cell">
      <p>Ahora le pasamos todo a <code>evaluator()</code></p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">pipeline</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">evaluate</span> <span class="kn">import</span> <span class="n">evaluator</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '',
          '<span class="n">model_pipeline</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">"text-classification"</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s2">"lvwerra/distilbert-imdb"</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"imdb"</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">"test"</span><span class="p">)</span><span class="o">.</span><span class="n">shuffle</span><span class="p">()</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">))</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '</span><span class="n">task_evaluator</span> <span class="o">=</span> <span class="n">evaluator</span><span class="p">(</span><span class="s2">"text-classification"</span><span class="p">)</span>',
          '',
          '<span class="n">results</span> <span class="o">=</span> <span class="n">task_evaluator</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">model_or_pipeline</span><span class="o">=</span><span class="n">model_pipeline</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="n">metric</span><span class="p">,</span>',
          '                       <span class="n">label_mapping</span><span class="o">=</span><span class="p">{</span><span class="s2">"NEGATIVE"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">"POSITIVE"</span><span class="p">:</span> <span class="mi">1</span><span class="p">},)</span>',
          '<span class="n">results</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '{\'accuracy\': 0.933,',
          ' \'total_time_in_seconds\': 29.43192940400013,',
          ' \'samples_per_second\': 33.97670557962431,',
          ' \'latency_in_seconds\': 0.02943192940400013}',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Gracias al evaluador hemos podido obtener las m茅tricas del modelo sin tener que hacer nosotros la inferencia</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Visualizaci%C3%B3n">Visualizaci贸n<a class="anchor-link" href="#Visualizaci%C3%B3n"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 14" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>A veces obtenemos dist铆ntas m茅tricas para diferentes modelos, lo que hace que no sea f谩cil poder compararlos, por lo que mediante gr谩ficos se hace m谩s f谩cil.</p>
      <p>La librer铆a <code>Evaluate</code> ofrece diferentes visualizaciones mediante el m茅todo <code>visualization()</code>. Tenemos que pasarle los datos como una lista de diccionarios, donde cada diccionario tiene que tener las mismas claves</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Para poder usar esta funci贸n es necesario tener instalada la librer铆a <code>matplotlib</code></p>
      <div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>matplotlib
      </pre></div>
      </section>
      
      <section class="section-block-code-cell-">
      <div class="input-code">
      <div class="highlight hl-ipython3">
<pre><span></span><span class="kn">import</span> <span class="nn">evaluate</span>
      <span class="kn">from</span> <span class="nn">evaluate.visualization</span> <span class="kn">import</span> <span class="n">radar_plot</span>
      
      <span class="n">data</span> <span class="o">=</span> <span class="p">[</span>
         <span class="p">{opening_brace}</span><span class="s2">"accuracy"</span><span class="p">:</span> <span class="mf">0.99</span><span class="p">,</span> <span class="s2">"precision"</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">,</span> <span class="s2">"f1"</span><span class="p">:</span> <span class="mf">0.95</span><span class="p">,</span> <span class="s2">"latency_in_seconds"</span><span class="p">:</span> <span class="mf">33.6</span><span class="p">{closing_brace},</span>
         <span class="p">{opening_brace}</span><span class="s2">"accuracy"</span><span class="p">:</span> <span class="mf">0.98</span><span class="p">,</span> <span class="s2">"precision"</span><span class="p">:</span> <span class="mf">0.87</span><span class="p">,</span> <span class="s2">"f1"</span><span class="p">:</span> <span class="mf">0.91</span><span class="p">,</span> <span class="s2">"latency_in_seconds"</span><span class="p">:</span> <span class="mf">11.2</span><span class="p">{closing_brace},</span>
         <span class="p">{opening_brace}</span><span class="s2">"accuracy"</span><span class="p">:</span> <span class="mf">0.98</span><span class="p">,</span> <span class="s2">"precision"</span><span class="p">:</span> <span class="mf">0.78</span><span class="p">,</span> <span class="s2">"f1"</span><span class="p">:</span> <span class="mf">0.88</span><span class="p">,</span> <span class="s2">"latency_in_seconds"</span><span class="p">:</span> <span class="mf">87.6</span><span class="p">{closing_brace},</span> 
         <span class="p">{opening_brace}</span><span class="s2">"accuracy"</span><span class="p">:</span> <span class="mf">0.88</span><span class="p">,</span> <span class="s2">"precision"</span><span class="p">:</span> <span class="mf">0.78</span><span class="p">,</span> <span class="s2">"f1"</span><span class="p">:</span> <span class="mf">0.81</span><span class="p">,</span> <span class="s2">"latency_in_seconds"</span><span class="p">:</span> <span class="mf">101.6</span><span class="p">{closing_brace}</span>
         <span class="p">]</span>
      
      <span class="n">model_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"Model 1"</span><span class="p">,</span> <span class="s2">"Model 2"</span><span class="p">,</span> <span class="s2">"Model 3"</span><span class="p">,</span> <span class="s2">"Model 4"</span><span class="p">]</span>
      
      <span class="n">plot</span> <span class="o">=</span> <span class="n">radar_plot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">model_names</span><span class="o">=</span><span class="n">model_names</span><span class="p">)</span>
      <span class="n">plot</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
      </pre></div>
      </div>
      <div class="output-wrapper">
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-subarea-output-stream-output-stderr-output-text">
      <pre>/tmp/ipykernel_10271/263559674.py:14: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown
        plot.show()
      </pre>
      </div>
      </div>
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-png-output-subarea">
      <img src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/hugging-face-evaluate0.webp" width="1026" height="507" alt="image hugging-face-evaluate 1" loading="lazy">
      </div>
      </div>
      </div>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Ahora podemos comparar visualmente los 4 modelos y elegir el 贸ptimo, en funci贸n de una o varias m茅tricas</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Evaluar-el-modelo-en-un-conjunto-de-tareas">Evaluar el modelo en un conjunto de tareas<a class="anchor-link" href="#Evaluar-el-modelo-en-un-conjunto-de-tareas"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 15" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Podemos evaluar un modelo, por ejemplo, para diferentes datasets. Para ello podemos usar el m茅todo <code>evaluation_suite</code>. Por ejmplo vamos a crear un evaluador que evalua un modelo en los conjuntos de datos <code>imdb</code> y <code>sst2</code>. Vamos a ver estos conjuntos de datos, para eso usamos el m茅todo <code>load_dataset_builder</code> para no tener que descargar el dataset completo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">from</span> <span class="nn">evaluate.visualization</span> <span class="kn">import</span> <span class="n">radar_plot</span>',
          '',
          '<span class="n">data</span> <span class="o">=</span> <span class="p">[</span>',
          '   <span class="p">{</span><span class="s2">"accuracy"</span><span class="p">:</span> <span class="mf">0.99</span><span class="p">,</span> <span class="s2">"precision"</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">,</span> <span class="s2">"f1"</span><span class="p">:</span> <span class="mf">0.95</span><span class="p">,</span> <span class="s2">"latency_in_seconds"</span><span class="p">:</span> <span class="mf">33.6</span><span class="p">},</span>',
          '   <span class="p">{</span><span class="s2">"accuracy"</span><span class="p">:</span> <span class="mf">0.98</span><span class="p">,</span> <span class="s2">"precision"</span><span class="p">:</span> <span class="mf">0.87</span><span class="p">,</span> <span class="s2">"f1"</span><span class="p">:</span> <span class="mf">0.91</span><span class="p">,</span> <span class="s2">"latency_in_seconds"</span><span class="p">:</span> <span class="mf">11.2</span><span class="p">},</span>',
          '   <span class="p">{</span><span class="s2">"accuracy"</span><span class="p">:</span> <span class="mf">0.98</span><span class="p">,</span> <span class="s2">"precision"</span><span class="p">:</span> <span class="mf">0.78</span><span class="p">,</span> <span class="s2">"f1"</span><span class="p">:</span> <span class="mf">0.88</span><span class="p">,</span> <span class="s2">"latency_in_seconds"</span><span class="p">:</span> <span class="mf">87.6</span><span class="p">},</span> ',
          '   <span class="p">{</span><span class="s2">"accuracy"</span><span class="p">:</span> <span class="mf">0.88</span><span class="p">,</span> <span class="s2">"precision"</span><span class="p">:</span> <span class="mf">0.78</span><span class="p">,</span> <span class="s2">"f1"</span><span class="p">:</span> <span class="mf">0.81</span><span class="p">,</span> <span class="s2">"latency_in_seconds"</span><span class="p">:</span> <span class="mf">101.6</span><span class="p">}</span>',
          '   <span class="p">]</span>',
          '',
          '<span class="n">model_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"Model 1"</span><span class="p">,</span> <span class="s2">"Model 2"</span><span class="p">,</span> <span class="s2">"Model 3"</span><span class="p">,</span> <span class="s2">"Model 4"</span><span class="p">]</span>',
          '',
          '<span class="n">plot</span> <span class="o">=</span> <span class="n">radar_plot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">model_names</span><span class="o">=</span><span class="n">model_names</span><span class="p">)</span>',
          '<span class="n">plot</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>',
          '</span><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset_builder</span>',
          '<span class="n">imdb</span> <span class="o">=</span> <span class="n">load_dataset_builder</span><span class="p">(</span><span class="s2">"imdb"</span><span class="p">)</span>',
          '<span class="n">imdb</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '/tmp/ipykernel_10271/263559674.py:14: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown',
          '  plot.show()',
          '{\'text\': Value(dtype=\'string\', id=None),',
          ' \'label\': ClassLabel(names=[\'neg\', \'pos\'], id=None)}',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset_builder</span>',
          '<span class="n">sst2</span> <span class="o">=</span> <span class="n">load_dataset_builder</span><span class="p">(</span><span class="s2">"sst2"</span><span class="p">)</span>',
          '<span class="n">sst2</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '{\'idx\': Value(dtype=\'int32\', id=None),',
          ' \'sentence\': Value(dtype=\'string\', id=None),',
          ' \'label\': ClassLabel(names=[\'negative\', \'positive\'], id=None)}',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Como podemos ver, con el dataset <code>imdb</code> necesitamos coger la columna <code>text</code> para obtener el texto y la columna <code>label</code> para obtener el target. Con el dataset <code>sst2</code> necesitamos coger la columna <code>sentence</code> para obtener el texto y la columna <code>label</code> para obtener el target</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Creamos el evaluador para los dos datasets</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span> <span class="nn">evaluate</span>',
      '      <span class="kn">from</span> <span class="nn">evaluate.evaluation_suite</span> <span class="kn">import</span> <span class="n">SubTask</span>',
      '      ',
      '      <span class="k">class</span> <span class="nc">Suite</span><span class="p">(</span><span class="n">evaluate</span><span class="o">.</span><span class="n">EvaluationSuite</span><span class="p">):</span>',
      '      ',
      '          <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>',
      '              <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>',
      '      ',
      '              <span class="bp">self</span><span class="o">.</span><span class="n">suite</span> <span class="o">=</span> <span class="p">[</span>',
      '                  <span class="n">SubTask</span><span class="p">(</span>',
      '                      <span class="n">task_type</span><span class="o">=</span><span class="s2">"text-classification"</span><span class="p">,</span>',
      '                      <span class="n">data</span><span class="o">=</span><span class="s2">"imdb"</span><span class="p">,</span>',
      '                      <span class="n">split</span><span class="o">=</span><span class="s2">"test[:1]"</span><span class="p">,</span>',
      '                      <span class="n">args_for_task</span><span class="o">=</span><span class="p">{</span>',
      '                          <span class="s2">"metric"</span><span class="p">:</span> <span class="s2">"accuracy"</span><span class="p">,</span>',
      '                          <span class="s2">"input_column"</span><span class="p">:</span> <span class="s2">"text"</span><span class="p">,</span>',
      '                          <span class="s2">"label_column"</span><span class="p">:</span> <span class="s2">"label"</span><span class="p">,</span>',
      '                          <span class="s2">"label_mapping"</span><span class="p">:</span> <span class="p">{</span>',
      '                              <span class="s2">"LABEL_0"</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>',
      '                              <span class="s2">"LABEL_1"</span><span class="p">:</span> <span class="mf">1.0</span>',
      '                          <span class="p">}</span>',
      '                      <span class="p">}</span>',
      '                  <span class="p">),</span>',
      '                  <span class="n">SubTask</span><span class="p">(</span>',
      '                      <span class="n">task_type</span><span class="o">=</span><span class="s2">"text-classification"</span><span class="p">,</span>',
      '                      <span class="n">data</span><span class="o">=</span><span class="s2">"sst2"</span><span class="p">,</span>',
      '                      <span class="n">split</span><span class="o">=</span><span class="s2">"test[:1]"</span><span class="p">,</span>',
      '                      <span class="n">args_for_task</span><span class="o">=</span><span class="p">{</span>',
      '                          <span class="s2">"metric"</span><span class="p">:</span> <span class="s2">"accuracy"</span><span class="p">,</span>',
      '                          <span class="s2">"input_column"</span><span class="p">:</span> <span class="s2">"sentence"</span><span class="p">,</span>',
      '                          <span class="s2">"label_column"</span><span class="p">:</span> <span class="s2">"label"</span><span class="p">,</span>',
      '                          <span class="s2">"label_mapping"</span><span class="p">:</span> <span class="p">{</span>',
      '                              <span class="s2">"LABEL_0"</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>',
      '                              <span class="s2">"LABEL_1"</span><span class="p">:</span> <span class="mf">1.0</span>',
      '                          <span class="p">}</span>',
      '                      <span class="p">}</span>',
      '                  <span class="p">)</span>',
      '              <span class="p">]</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>











































      
      <section class="section-block-markdown-cell">
      <p>Se puede ver en <code>split="test[:1]",</code> que solo cojemos un ejemplo del subconjunto de test para este notebook y que la ejecuci贸n no lleve mucho tiempo</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Ahora evaluamos con el modelo <code>huggingface/prunebert-base-uncased-6-finepruned-w-distil-mnli</code></p>
      </section>
      
      <section class="section-block-code-cell-">
      <div class="input-code">
      <div class="highlight hl-ipython3">
<pre><span></span><span class="kn">from</span> <span class="nn">evaluate</span> <span class="kn">import</span> <span class="n">EvaluationSuite</span>
      <span class="n">suite</span> <span class="o">=</span> <span class="n">EvaluationSuite</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">'mathemakitten/sentiment-evaluation-suite'</span><span class="p">)</span>
      <span class="n">results</span> <span class="o">=</span> <span class="n">suite</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s2">"huggingface/prunebert-base-uncased-6-finepruned-w-distil-mnli"</span><span class="p">)</span>
      <span class="n">results</span>
      </pre></div>
      </div>
      <div class="output-wrapper">
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-subarea-output-stream-output-stderr-output-text">
      <pre>`data` is a preloaded Dataset! Ignoring `subset` and `split`.
      `data` is a preloaded Dataset! Ignoring `subset` and `split`.
      </pre>
      </div>
      </div>
      <div class="output-area">
      <div class="prompt-output-prompt">Out[4]:</div>
      <div class="output-text-output-subareaoutput_execute_result">
      <pre>[{opening_brace}'accuracy': 0.3,
        'total_time_in_seconds': 1.4153412349987775,
        'samples_per_second': 7.06543394110088,
        'latency_in_seconds': 0.14153412349987776,
        'task_name': 'imdb',
        'data_preprocessor': '&lt;function Suite.__init__.&lt;locals&gt;.&lt;lambda&gt; at 0x7f3ff27a5080&gt;'{closing_brace},
       {opening_brace}'accuracy': 0.0,
        'total_time_in_seconds': 0.1323430729971733,
        'samples_per_second': 75.56118936586572,
        'latency_in_seconds': 0.013234307299717328,
        'task_name': 'sst2',
        'data_preprocessor': '&lt;function Suite.__init__.&lt;locals&gt;.&lt;lambda&gt; at 0x7f3f2a9cc720&gt;'}]</pre>
      </div>
      </div>
      </div>
      </section>
      






    </div>

  </section>

</PostLayout>
