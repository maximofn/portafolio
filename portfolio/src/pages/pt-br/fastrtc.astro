---
import PostLayout from '@layouts/PostLayout.astro';
import CodeBlockInputCell from '@components/CodeBlockInputCell.astro';
import CodeBlockOutputCell from '@components/CodeBlockOutputCell.astro';

const { metadata_page } = await import('@portfolio/consts.json');
const { colors } = await import('@portfolio/consts.json');
const { svg_paths } = await import('@portfolio/consts.json');

const page_title = 'Fazer uma aplica√ß√£o de IA em tempo real com FastRTC';
const end_url = 'fastrtc';
const description = 'Se voc√™ tem problemas para fazer uma aplica√ß√£o de IA em tempo real, o FastRTC pode te ajudar. Neste post, explico como us√°-lo.';
const keywords = 'fastrtc, real-time, ai, aplica√ß√£o, telefone';
const languaje = 'PT';
const image_path = 'https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/fastrtc-thumbnail.webp';
const opening_brace = '{';
const closing_brace = '}';
---

<PostLayout 
    title={page_title}
    languaje={languaje}
    description={description}
    keywords={keywords}
    author={metadata_page.author}
    theme_color={colors.background_color}
    end_url={end_url}
    image_path={image_path}
    image_width=960
    image_height=720
    image_extension=webp
    article_date=2025-03-08+T00:00:00Z
>

  <section class="post-body">


    <aside class="post-index">
      <a class="anchor-link" href="#Principais-caracter%C3%ADsticas-de-FastRTC"><h2>Principais caracter√≠sticas de FastRTC</h2></a>
      <a class="anchor-link" href="#Instala%C3%A7%C3%A3o"><h2>Instala√ß√£o</h2></a>
      <a class="anchor-link" href="#Primeiros-passos"><h2>Primeiros passos</h2></a>
      <a class="anchor-link" href="#Subindo-de-n%C3%ADvel:-Bate-papo-de-voz-com-LLM"><h2>Subindo de n√≠vel: Bate-papo de voz com LLM</h2></a>
      <a class="anchor-link" href="#Chamada-telef%C3%B4nica"><h2>Chamada telef√¥nica</h2></a>
    </aside>


    <div class="post-body-content">
      
      <section class="section-block-markdown-cell">
      <h1 id="FastRTC:-A-Biblioteca-de-Comunica%C3%A7%C3%A3o-em-Tempo-Real-para-Python">FastRTC: A Biblioteca de Comunica√ß√£o em Tempo Real para Python<a class="anchor-link" href="#FastRTC:-A-Biblioteca-de-Comunica%C3%A7%C3%A3o-em-Tempo-Real-para-Python"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 12" src={svg_paths.link_svg_path}/></a></h1>
      </section>
      
      <section class="section-block-markdown-cell">
      <blockquote>
      <p>Aviso: Este post foi traduzido para o portugu√™s usando um modelo de tradu√ß√£o autom√°tica. Por favor, me avise se encontrar algum erro.</p>
      </blockquote>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Nos √∫ltimos meses, temos visto um grande avan√ßo em modelos de voz em tempo real, com empresas inteiras fundadas ao redor de modelos tanto de c√≥digo aberto quanto fechado. Alguns marcos importantes incluem:</p>
      <ul>
      <li><code>OpenAI</code> e <code>Google</code> lan√ßaram suas APIs multimodais ao vivo para ChatGPT e Gemini. ¬°A OpenAI at√© lan√ßou um n√∫mero de telefone <code>1-800-ChatGPT</code>!</li>
      <li><code>Kyutai</code> lan√ßou <a href="https://huggingface.co/kyutai" target="_blank" rel="nofollow noreferrer">Moshi</a>, um LLM de √°udio para √°udio totalmente de c√≥digo aberto.</li>
      <li><code>Alibaba</code> lan√ßou <a href="https://huggingface.co/Qwen/Qwen2-Audio-7B-Instruct">Qwen2-Audio</a>, um LLM de c√≥digo aberto que entende √°udio de forma nativa.</li>
      <li><code>Fixie.ai</code> lan√ßou <a href="https://huggingface.co/fixie-ai/ultravox-v0_5-llama-3_3-70b">Ultravox</a>, outro LLM de c√≥digo aberto que tamb√©m entende √°udio de forma nativa.</li>
      <li><code>ElevenLabs</code> arrecadou 180 milh√µes de d√≥lares na sua S√©rie C.</li>
      </ul>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Apesar desta explos√£o em modelos e financiamento, ainda √© dif√≠cil construir aplica√ß√µes de IA em tempo real que transmitam √°udio e v√≠deo, especialmente em Python.</p>
      <ul>
      <li>Os engenheiros de ML podem n√£o ter experi√™ncia com as tecnologias necess√°rias para construir aplica√ß√µes em tempo real, como <code>WebRTC</code>.</li>
      <li>Mesmo ferramentas de assist√™ncia de c√≥digo como <code>Cursor</code> e <code>Copilot</code> t√™m dificuldades em escrever c√≥digo Python que suporte aplica√ß√µes de √°udio/v√≠deo em tempo real.</li>
      </ul>
      <p>Por isso √© empolgante o an√∫ncio de <code>FastRTC</code>, a biblioteca de comunica√ß√£o em tempo real para Python. A biblioteca foi projetada para facilitar a constru√ß√£o de aplica√ß√µes de IA de √°udio e v√≠deo em tempo real totalmente em Python!</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Principais-caracter%C3%ADsticas-de-FastRTC">Principais caracter√≠sticas de FastRTC<a class="anchor-link" href="#Principais-caracter%C3%ADsticas-de-FastRTC"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 13" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <ul>
      <li>üó£Ô∏è Detec√ß√£o de voz autom√°tica e gerenciamento de turnos integrado, para que voc√™ s√≥ precise se preocupar com a l√≥gica de resposta ao usu√°rio.</li>
      <li>üíª UI autom√°tica - UI do Gradio habilitada para WebRTC integrada para testes (ou implanta√ß√£o em produ√ß√£o!).</li>
      <li>üìû Chamada telef√¥nica - Use <code>fastphone()</code> para obter um n√∫mero de telefone <strong>gratuito</strong> para ligar para o seu fluxo de √°udio (√© necess√°rio um token HF).</li>
      <li>‚ö°Ô∏è Suporte para <code>WebRTC</code> e <code>Websocket</code>.</li>
      <li>üí™ Personaliz√°vel - Voc√™ pode montar o stream em qualquer aplica√ß√£o <code>FastAPI</code> para servir uma UI personalizada e implantar al√©m do <code>Gradio</code>.</li>
      <li>üß∞ Muitas utilidades para <code>text-to-speech</code>, <code>speech-to-text</code>, <code>detec√ß√£o de parada</code> para te ajudar a come√ßar.</li>
      </ul>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Instala%C3%A7%C3%A3o">Instala√ß√£o<a class="anchor-link" href="#Instala%C3%A7%C3%A3o"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 14" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Para poder usar <code>FastRTC</code>, primeiro voc√™ precisa instalar a biblioteca:</p>
      <div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>fastrtc</pre></div>
      <p>Mas se quisermos instalar as funcionalidades de detec√ß√£o de pausa, speech-to-text e text-to-speech, precisamos instalar algumas depend√™ncias adicionais:</p>
      <div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span><span class="s2">"fastrtc[vad, stt, tts]"</span></pre></div>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Primeiros-passos">Primeiros passos<a class="anchor-link" href="#Primeiros-passos"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 15" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Come√ßaremos construindo o <code>ol√° mundo</code> do √°udio em tempo real: fazer eco do que o usu√°rio diz. Em <code>FastRTC</code>, isso √© t√£o simples quanto:</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">fastrtc</span> <span class="kn">import</span> <span class="n">Stream</span><span class="p">,</span> <span class="n">ReplyOnPause</span>',
          '<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>',
          '',
          '<span class="k">def</span> <span class="nf">echo</span><span class="p">(</span><span class="n">audio</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>',
          '    <span class="k">yield</span> <span class="n">audio</span>',
          '',
          '<span class="n">stream</span> <span class="o">=</span> <span class="n">Stream</span><span class="p">(</span><span class="n">ReplyOnPause</span><span class="p">(</span><span class="n">echo</span><span class="p">),</span> <span class="n">modality</span><span class="o">=</span><span class="s2">"audio"</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">"send-receive"</span><span class="p">)</span>',
          '<span class="n">stream</span><span class="o">.</span><span class="n">ui</span><span class="o">.</span><span class="n">launch</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '* Running on local URL:  http://127.0.0.1:7872',
          'To create a public link, set `share=True` in `launch()`.',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Quando vamos ao link que o Gradio sugere, primeiro temos que dar permiss√µes ao navegador para acessar o microfone. A seguir, aparecer√° isto
      <img decoding="async" onerror="this.parentNode.removeChild(this)" alt="fastrct - hello world - init" src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/fastRTC%20-%20hello%20world%20-%20init.webp" width="550" height="361"/></p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Se clicarmos na guia √† direita da palavra <code>Record</code>, podemos selecionar o microfone que queremos usar.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Ao clicar no bot√£o <code>Record</code>, tudo o que dissermos ser√° repetido pelo aplicativo. Isso significa que ele captura o √°udio, detecta quando paramos de falar e o repete.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a desmembr√°-lo:</p>
      <ul>
      <li><code>ReplyOnPause</code> ir√° tratar a detec√ß√£o de voz e a passagem de turnos para voc√™. Voc√™ s√≥ precisa se preocupar com a l√≥gica para responder ao usu√°rio. √â necess√°rio passar a fun√ß√£o que ser√° respons√°vel por gerenciar o √°udio de entrada. No nosso caso, √© a fun√ß√£o <code>echo</code>, que captura o √°udio de entrada e o retorna em stream usando <code>yield</code>, que muitas pessoas n√£o conhecem, mas √© um gerador, ou seja, √© um m√©todo do Python para criar iteradores. Se quiser saber mais sobre <code>yield</code>, pode ler meu post sobre <a href="https://www.maximofn.com/python#6.5.-Generadores">Python</a>. Qualquer gerador que retorne uma tupla de √°udio (representada como <code>(sample_rate, audio_data)</code>) funcionar√°.</li>
      <li>A classe <code>Stream</code> construir√° uma UI do Gradio para que voc√™ possa testar rapidamente seu stream. Uma vez que voc√™ tenha terminado de prototipar, voc√™ pode implantar seu Stream como um aplicativo FastAPI pronto para produ√ß√£o em uma √∫nica linha de c√≥digo</li>
      </ul>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Aqui podemos ver um exemplo dos criadores de <code>FastRTC</code>
      <video controls="" src="https://github.com/user-attachments/assets/fcf2d30e-3e98-47c9-8dc3-23340784c441"></video></p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Subindo-de-n%C3%ADvel:-Bate-papo-de-voz-com-LLM">Subindo de n√≠vel: Bate-papo de voz com LLM<a class="anchor-link" href="#Subindo-de-n%C3%ADvel:-Bate-papo-de-voz-com-LLM"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 16" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>O pr√≥ximo n√≠vel √© usar um LLM para responder ao usu√°rio. <code>FastRTC</code> vem com capacidades de <code>speech-to-text</code> e <code>text-to-speech</code> incorporadas, portanto trabalhar com LLMs √© realmente f√°cil. Vamos alterar nossa fun√ß√£o <code>echo</code> accordingly:</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">fastrtc</span> <span class="kn">import</span> <span class="n">ReplyOnPause</span><span class="p">,</span> <span class="n">Stream</span><span class="p">,</span> <span class="n">get_stt_model</span><span class="p">,</span> <span class="n">get_tts_model</span>',
          '<span class="kn">from</span> <span class="nn">gradio_client</span> <span class="kn">import</span> <span class="n">Client</span>',
          '',
          '<span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="s2">"Maximofn/SmolLM2_localModel"</span><span class="p">)</span>',
          '<span class="n">stt_model</span> <span class="o">=</span> <span class="n">get_stt_model</span><span class="p">()</span>',
          '<span class="n">tts_model</span> <span class="o">=</span> <span class="n">get_tts_model</span><span class="p">()</span>',
          '',
          '<span class="k">def</span> <span class="nf">echo</span><span class="p">(</span><span class="n">audio</span><span class="p">):</span>',
          '    <span class="n">prompt</span> <span class="o">=</span> <span class="n">stt_model</span><span class="o">.</span><span class="n">stt</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>',
          '    <span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>',
          '            <span class="n">message</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>',
          '            <span class="n">system_message</span><span class="o">=</span><span class="s2">"You are a friendly Chatbot. Always reply in the language in which the user is writing to you."</span><span class="p">,</span>',
          '            <span class="n">max_tokens</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>',
          '            <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>',
          '            <span class="n">top_p</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span>',
          '            <span class="n">api_name</span><span class="o">=</span><span class="s2">"/chat"</span>',
          '    <span class="p">)</span>',
          '    <span class="n">prompt</span> <span class="o">=</span> <span class="n">response</span>',
          '    <span class="k">for</span> <span class="n">audio_chunk</span> <span class="ow">in</span> <span class="n">tts_model</span><span class="o">.</span><span class="n">stream_tts_sync</span><span class="p">(</span><span class="n">prompt</span><span class="p">):</span>',
          '        <span class="k">yield</span> <span class="n">audio_chunk</span>',
          '',
          '<span class="n">stream</span> <span class="o">=</span> <span class="n">Stream</span><span class="p">(</span><span class="n">ReplyOnPause</span><span class="p">(</span><span class="n">echo</span><span class="p">),</span> <span class="n">modality</span><span class="o">=</span><span class="s2">"audio"</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">"send-receive"</span><span class="p">)</span>',
          '<span class="n">stream</span><span class="o">.</span><span class="n">ui</span><span class="o">.</span><span class="n">launch</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Loaded as API: https://maximofn-smollm2-localmodel.hf.space ‚úî',
          '* Running on local URL:  http://127.0.0.1:7871',
          'To create a public link, set `share=True` in `launch()`.',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Como modelo de <code>speech-to-text</code> use <code>Moonshine</code>, que supostamente s√≥ suporta ingl√™s, mas eu o testei em espanhol e ele entende bem.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Como modelo de linguagem vamos usar o modelo que desployei em um backend no Hugging Face e que escrevi no post <a href="https://www.maximofn.com/pt-br/deploy-backend-with-llm-in-huggingface">Desplegar backend com LLM em HuggingFace</a>. Utiliza o LLM <code>HuggingFaceTB/SmolLM2-1.7B-Instruct</code> que √© um modelo pequeno, j√° que est√° rodando em um backend com CPU, mas que funciona bastante bem.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Como modelo de <code>text-to-speech</code> use <code>Kokoro</code> que sim tem op√ß√µes de falar em outros idiomas, mas que por enquanto na biblioteca <code>FastRTC</code> ainda n√£o est√° implementado.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Se nos interessa muito usar modelos de <code>speech-to-speech</code> e <code>text-to-speech</code> em outros idiomas, poder√≠amos implement√°-los n√≥s mesmos, pois o maior potencial do <code>FastRTC</code> est√° na camada de comunica√ß√£o em tempo real, mas n√£o vou me aprofundar nisso agora.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Agora, se testarmos o c√≥digo que acabamos de escrever, podemos ter um chatbot, por voz em tempo real.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Chamada-telef%C3%B4nica">Chamada telef√¥nica<a class="anchor-link" href="#Subindo-de-n%C3%ADvel:-Bate-papo-de-voz-com-LLM"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 16" src={svg_paths.link_svg_path}/></a></h2>
      Geramos um script, pois nem sempre funciona em um Jupyter Notebook.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="o">%%writefile</span> fastrtc_phone_demo.py',
      '',
      '<span class="kn">from</span> <span class="nn">fastrtc</span> <span class="kn">import</span> <span class="n">ReplyOnPause</span><span class="p">,</span> <span class="n">Stream</span><span class="p">,</span> <span class="n">get_stt_model</span><span class="p">,</span> <span class="n">get_tts_model</span>',
      '<span class="kn">import</span> <span class="nn">gradio</span>',
      '<span class="kn">from</span> <span class="nn">gradio_client</span> <span class="kn">import</span> <span class="n">Client</span>',
      '<span class="kn">import</span> <span class="nn">os</span>',
      '<span class="kn">from</span> <span class="nn">gradio.networking</span> <span class="kn">import</span> <span class="n">setup_tunnel</span> <span class="k">as</span> <span class="n">original_setup_tunnel</span>',
      '<span class="kn">import</span> <span class="nn">socket</span>',
      '',
      '<span class="c1"># Monkey patch setup_tunnel para que acepte el par√°metro adicional</span>',
      '<span class="k">def</span> <span class="nf">patched_setup_tunnel</span><span class="p">(</span><span class="n">host</span><span class="p">,</span> <span class="n">port</span><span class="p">,</span> <span class="n">share_token</span><span class="p">,</span> <span class="n">share_server_address</span><span class="p">,</span> <span class="n">share_server_tls_certificate</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>',
      '    <span class="k">return</span> <span class="n">original_setup_tunnel</span><span class="p">(</span><span class="n">host</span><span class="p">,</span> <span class="n">port</span><span class="p">,</span> <span class="n">share_token</span><span class="p">,</span> <span class="n">share_server_address</span><span class="p">,</span> <span class="n">share_server_tls_certificate</span><span class="p">)</span>',
      '',
      '<span class="c1"># Replace the original function with our patched version</span>',
      '<span class="n">gradio</span><span class="o">.</span><span class="n">networking</span><span class="o">.</span><span class="n">setup_tunnel</span> <span class="o">=</span> <span class="n">patched_setup_tunnel</span>',
      '',
      '<span class="c1"># Get the token from the environment variable</span>',
      '<span class="n">HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">"HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN"</span><span class="p">)</span>',
      '',
      '<span class="c1"># Initialize the LLM client</span>',
      '<span class="n">llm_client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="s2">"Maximofn/SmolLM2_localModel"</span><span class="p">)</span>',
      '',
      '<span class="c1"># Initialize the STT and TTS models</span>',
      '<span class="n">stt_model</span> <span class="o">=</span> <span class="n">get_stt_model</span><span class="p">()</span>',
      '<span class="n">tts_model</span> <span class="o">=</span> <span class="n">get_tts_model</span><span class="p">()</span>',
      '',
      '<span class="c1"># Define the echo function</span>',
      '<span class="k">def</span> <span class="nf">echo</span><span class="p">(</span><span class="n">audio</span><span class="p">):</span>',
      '    <span class="c1"># Convert the audio to text</span>',
      '    <span class="n">prompt</span> <span class="o">=</span> <span class="n">stt_model</span><span class="o">.</span><span class="n">stt</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>',
      '',
      '    <span class="c1"># Generate the response</span>',
      '    <span class="n">response</span> <span class="o">=</span> <span class="n">llm_client</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>',
      '            <span class="n">message</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>',
      '            <span class="n">system_message</span><span class="o">=</span><span class="s2">"You are a friendly Chatbot. Always reply in the language in which the user is writing to you."</span><span class="p">,</span>',
      '            <span class="n">max_tokens</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>',
      '            <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>',
      '            <span class="n">top_p</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span>',
      '            <span class="n">api_name</span><span class="o">=</span><span class="s2">"/chat"</span>',
      '    <span class="p">)</span>',
      '    ',
      '    <span class="c1"># Convert the response to audio</span>',
      '    <span class="n">prompt</span> <span class="o">=</span> <span class="n">response</span>',
      '',
      '    <span class="c1"># Stream the audio</span>',
      '    <span class="k">for</span> <span class="n">audio_chunk</span> <span class="ow">in</span> <span class="n">tts_model</span><span class="o">.</span><span class="n">stream_tts_sync</span><span class="p">(</span><span class="n">prompt</span><span class="p">):</span>',
      '        <span class="k">yield</span> <span class="n">audio_chunk</span>',
      '',
      '<span class="k">def</span> <span class="nf">find_free_port</span><span class="p">(</span><span class="n">start_port</span><span class="o">=</span><span class="mi">8000</span><span class="p">,</span> <span class="n">max_port</span><span class="o">=</span><span class="mi">9000</span><span class="p">):</span>',
      '<span class="w">    </span><span class="sd">"""Find the first free port starting from start_port."""</span>',
      '    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Searching for a free port starting from </span><span class="si">{</span><span class="n">start_port</span><span class="si">}</span><span class="s2">..."</span><span class="p">)</span>',
      '    <span class="k">for</span> <span class="n">port</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_port</span><span class="p">,</span> <span class="n">max_port</span><span class="p">):</span>',
      '        <span class="k">with</span> <span class="n">socket</span><span class="o">.</span><span class="n">socket</span><span class="p">(</span><span class="n">socket</span><span class="o">.</span><span class="n">AF_INET</span><span class="p">,</span> <span class="n">socket</span><span class="o">.</span><span class="n">SOCK_STREAM</span><span class="p">)</span> <span class="k">as</span> <span class="n">sock</span><span class="p">:</span>',
      '            <span class="n">result</span> <span class="o">=</span> <span class="n">sock</span><span class="o">.</span><span class="n">connect_ex</span><span class="p">((</span><span class="s1">\'127.0.0.1\'</span><span class="p">,</span> <span class="n">port</span><span class="p">))</span>',
      '            <span class="k">if</span> <span class="n">result</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># If result != 0, the port is free</span>',
      '                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Free port found: </span><span class="si">{</span><span class="n">port</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
      '                <span class="k">return</span> <span class="n">port</span>',
      '    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"No free port found between </span><span class="si">{</span><span class="n">start_port</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="n">max_port</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
      '    ',
      '<span class="n">free_port</span> <span class="o">=</span> <span class="n">find_free_port</span><span class="p">()</span>    <span class="c1"># Search for a free port</span>',
      '',
      '<span class="n">stream</span> <span class="o">=</span> <span class="n">Stream</span><span class="p">(</span><span class="n">ReplyOnPause</span><span class="p">(</span><span class="n">echo</span><span class="p">),</span> <span class="n">modality</span><span class="o">=</span><span class="s2">"audio"</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">"send-receive"</span><span class="p">)</span>',
      '<span class="n">stream</span><span class="o">.</span><span class="n">fastphone</span><span class="p">(</span><span class="n">token</span><span class="o">=</span><span class="n">HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN</span><span class="p">,</span> <span class="n">port</span><span class="o">=</span><span class="n">free_port</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>




































































      
      <section class="section-block-markdown-cell">
      <p>Explicamos o c√≥digo</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>A parte</p>
<div class="highlight"><pre><span></span><span class="c1"># Monkey patch setup_tunnel para que acepte el par√°metro adicional</span>
<span class="k">def</span> <span class="nf">patched_setup_tunnel</span><span class="p">(</span><span class="n">host, port, share_token, share_server_address, share_server_tls_certificate=None</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">original_setup_tunnel</span><span class="p">(</span><span class="n">host, port, share_token, share_server_address, share_server_tls_certificate</span><span class="p">)</span>
<span class="n">    </span>
<span class="c1"># Replace the original function with our patched version</span>
<span class="n">gradio.networking.setup_tunnel</span> <span class="c1">=</span> <span class="n">patched_setup_tunnel</span>
</pre></div>
      <p>√â necess√°rio porque `FastRTC` foi escrito para uma vers√£o antiga do `gradio` que n√£o suporta o par√¢metro `share_server_address` no m√©todo `setup_tunnel`. Ent√£o, n√≥s o patcheamos para aceitar o par√¢metro adicional.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Como √© necess√°rio um token do Hugging Face, obtemos o token da vari√°vel de ambiente <code>HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN</code>.</p>
<div class="highlight"><pre><span></span><span class="c1"># Get the token from the environment variable</span>
<span class="n">HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">"HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN"</span><span class="p">)</span>
</pre></div>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>A seguir s√£o criados os modelos de linguagem, de <code>speech-to-text</code> e de <code>text-to-speech</code>, e criamos a fun√ß√£o <code>echo</code> que ser√° respons√°vel por gerenciar o √°udio de entrada e sa√≠da.</p>
<div class="highlight"><pre><span></span><span class="c1"># Initialize the LLM client</span>
<span class="n">llm_client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="s2">"Maximofn/SmolLM2_localModel"</span><span class="p">)</span>

<span class="c1"># Initialize the STT and TTS models</span>
<span class="n">stt_model</span> <span class="o">=</span> <span class="n">get_stt_model</span><span class="p">()</span>
<span class="n">tts_model</span> <span class="o">=</span> <span class="n">get_tts_model</span><span class="p">()</span>

<span class="c1"># Define the echo function</span>
<span class="k">def</span> <span class="nf">echo</span><span class="p">(</span><span class="n">audio</span><span class="p">):</span>
    <span class="c1"># Convert the audio to text</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="n">stt_model</span><span class="o">.</span><span class="n">stt</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>

    <span class="c1"># Generate the response</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">llm_client</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
            <span class="n">message</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
            <span class="n">system_message</span><span class="o">=</span><span class="s2">"You are a friendly Chatbot. Always reply in the language in which the user is writing to you."</span><span class="p">,</span>
            <span class="n">max_tokens</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
            <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
            <span class="n">top_p</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span>
            <span class="n">api_name</span><span class="o">=</span><span class="s2">"/chat"</span>
    <span class="p">)</span>

    <span class="c1"># Convert the response to audio</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="n">response</span>

    <span class="c1"># Stream the audio</span>
    <span class="k">for</span> <span class="n">audio_chunk</span> <span class="ow">in</span> <span class="n">tts_model</span><span class="o">.</span><span class="n">stream_tts_sync</span><span class="p">(</span><span class="n">prompt</span><span class="p">):</span>
        <span class="k">yield</span> <span class="n">audio_chunk</span>
</pre></div>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Como antes usamos a porta <code>8000</code>, caso voc√™s digam que ela est√° ocupada, criamos uma fun√ß√£o para encontrar uma porta livre e encontramos uma.</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">find_free_port</span><span class="p">(</span><span class="n">start_port</span><span class="o">=</span><span class="mi">8000</span><span class="p">,</span> <span class="n">max_port</span><span class="o">=</span><span class="mi">9000</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Find the first free port starting from start_port."""</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Searching for a free port starting from </span><span class="si">{opening_brace}</span><span class="n">start_port</span><span class="si">{closing_brace}</span><span class="s2">..."</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">port</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_port</span><span class="p">,</span> <span class="n">max_port</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">socket</span><span class="o">.</span><span class="n">socket</span><span class="p">(</span><span class="n">socket</span><span class="o">.</span><span class="n">AF_INET</span><span class="p">,</span> <span class="n">socket</span><span class="o">.</span><span class="n">SOCK_STREAM</span><span class="p">)</span> <span class="k">as</span> <span class="n">sock</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">sock</span><span class="o">.</span><span class="n">connect_ex</span><span class="p">((</span><span class="s1">'127.0.0.1'</span><span class="p">,</span> <span class="n">port</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">result</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># If result != 0, the port is free</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Free port found: </span><span class="si">{opening_brace}</span><span class="n">port</span><span class="si">{closing_brace}</span><span class="s2">"</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">port</span>
    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"No free port found between </span><span class="si">{opening_brace}</span><span class="n">start_port</span><span class="si">{closing_brace}</span><span class="s2"> and </span><span class="si">{opening_brace}</span><span class="n">max_port</span><span class="si">{closing_brace}</span><span class="s2">"</span><span class="p">)</span>

<span class="n">free_port</span> <span class="o">=</span> <span class="n">find_free_port</span><span class="p">()</span>    <span class="c1"># Search for a free port</span>
</pre></div>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>O fluxo √© criado e agora <code>stream.fastphone()</code> √© usado para obter um n√∫mero de telefone gratuito para ligar ao seu fluxo, em vez de <code>stream.ui.launch()</code>, que usamos anteriormente para criar a interface gr√°fica.</p>
<div class="highlight"><pre><span></span><span class="n">stream</span> <span class="o">=</span> <span class="n">Stream</span><span class="p">(</span><span class="n">ReplyOnPause</span><span class="p">(</span><span class="n">echo</span><span class="p">),</span> <span class="n">modality</span><span class="o">=</span><span class="s2">"audio"</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">"send-receive"</span><span class="p">)</span>
<span class="n">stream</span><span class="o">.</span><span class="n">fastphone</span><span class="p">(</span><span class="n">token</span><span class="o">=</span><span class="n">HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN</span><span class="p">,</span> <span class="n">port</span><span class="o">=</span><span class="n">free_port</span><span class="p">)</span>
</pre></div>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Se o executarmos, veremos algo assim:</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">!</span>python<span class="w"> </span>fastrtc_phone_demo.py',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Loaded as API: https://maximofn-smollm2-localmodel.hf.space ‚úî',
          '<span class="ansi-green-fg">INFO</span>:	  Warming up STT model.',
          '<span class="ansi-green-fg">INFO</span>:	  STT model warmed up.',
          '<span class="ansi-green-fg">INFO</span>:	  Warming up VAD model.',
          '<span class="ansi-green-fg">INFO</span>:	  VAD model warmed up.',
          'Searching for a free port starting from 8000...',
          'Free port found: 8004',
          '<span class="ansi-green-fg">INFO</span>:     Started server process [<span class="ansi-cyan-fg">24029</span>]',
          '<span class="ansi-green-fg">INFO</span>:     Waiting for application startup.',
          '<span class="ansi-green-fg">INFO</span>:	  Visit <span class="ansi-cyan-fg">https://fastrtc.org/userguide/api/</span> for WebRTC or Websocket API docs.',
          '<span class="ansi-green-fg">INFO</span>:     Application startup complete.',
          '<span class="ansi-green-fg">INFO</span>:     Uvicorn running on <span class="ansi-bold">http://127.0.0.1:8004</span> (Press CTRL+C to quit)',
          '<span class="ansi-green-fg">INFO</span>:	  Your FastPhone is now live! Call <span class="ansi-cyan-fg">+1 877-713-4471</span> and use code <span class="ansi-cyan-fg">994514</span> to connect to your stream.',
          '<span class="ansi-green-fg">INFO</span>:	  You have <span class="ansi-cyan-fg">30:00</span> minutes remaining in your quota (Resetting on <span class="ansi-cyan-fg">2025-04-07</span>)',
          '<span class="ansi-green-fg">INFO</span>:	  Visit <span class="ansi-cyan-fg">https://fastrtc.org/userguide/audio/#telephone-integration</span> for information on making your handler compatible with phone usage.',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos que aparece</p>
      <div class="highlight"><pre><span></span>INFO:<span class="w"> </span>Seu<span class="w"> </span>FastPhone<span class="w"> </span>est√°<span class="w"> </span>agora<span class="w"> </span>ativo!<span class="w"> </span>Ligue<span class="w"> </span>para<span class="w"> </span>+1<span class="w"> </span><span class="m">877</span>-713-4471<span class="w"> </span>e<span class="w"> </span>use<span class="w"> </span>o<span class="w"> </span>c√≥digo<span class="w"> </span><span class="m">994514</span><span class="w"> </span>para<span class="w"> </span>se<span class="w"> </span>conectar<span class="w"> </span>ao<span class="w"> </span>seu<span class="w"> </span>stream.INFO:<span class="w"> </span>Voc√™<span class="w"> </span>tem<span class="w"> </span><span class="m">30</span>:00<span class="w"> </span>minutos<span class="w"> </span>restantes<span class="w"> </span>em<span class="w"> </span>sua<span class="w"> </span>cota<span class="w"> </span><span class="o">(</span>Redefinindo<span class="w"> </span>em<span class="w"> </span><span class="m">2025</span>-04-07<span class="o">)</span><span class="sb">```</span>
      
      Isto<span class="w"> </span>√©,<span class="w"> </span>se<span class="w"> </span>ligarmos<span class="w"> </span>para<span class="w"> </span>o<span class="w"> </span>n√∫mero<span class="w"> </span><span class="sb">`</span>+1<span class="w"> </span><span class="m">877</span>-713-4471<span class="sb">`</span><span class="w"> </span>e<span class="w"> </span>usarmos<span class="w"> </span>o<span class="w"> </span>c√≥digo<span class="w"> </span><span class="sb">`</span><span class="m">994514</span><span class="sb">`</span>,<span class="w"> </span>seremos<span class="w"> </span>conectados<span class="w"> </span>ao<span class="w"> </span>nosso<span class="w"> </span>stream.
      </pre></div>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Se formos at√© <a href="https://fastrtc.org/userguide/audio/#telephone-integration" target="_blank" rel="nofollow noreferrer">Telephone Integration</a> da documenta√ß√£o de <code>FastRTC</code>, veremos que usa <a href="https://www.twilio.com/">twilio</a> para fazer a chamada. Tem op√ß√£o para configurar um n√∫mero local nos Estados Unidos, Dublin, Frankfurt, T√≥quio, Singapura, Sydney e S√£o Paulo.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Tente testeado fazer a chamada da Espanha (o que vai me custar bastante) e funciona, mas √© lento. Liguei, inseri o c√≥digo e fiquei esperando para ser conectado com o agente, mas como estava demorando muito, desliguei.</p>
      </section>
      






    </div>

  </section>

</PostLayout>
