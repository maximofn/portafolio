---
import PostLayout from '@layouts/PostLayout.astro';
import CodeBlockInputCell from '@components/CodeBlockInputCell.astro';
import CodeBlockOutputCell from '@components/CodeBlockOutputCell.astro';

const { metadata_page } = await import('@portfolio/consts.json');
const { colors } = await import('@portfolio/consts.json');
const { svg_paths } = await import('@portfolio/consts.json');

const page_title = 'Fine tuning SMLs';
const end_url = 'fine-tuning-sml';
const description = 'üòÇ Ajustando modelos de idiomas pequenos? Por favor, voc√™ n√£o est√° ajustando, est√° apenas tentando desesperadamente tirar algum sentido de um modelo que √© t√£o √∫til quanto um bule de chocolate üç´üöΩ. Mas quem n√£o gosta de um bom desafio? V√° em frente, gaste suas horas de GPU e talvez, apenas talvez, voc√™ consiga um modelo que consiga distinguir entre ol√° e adeus ü§ñ. Boa sorte e n√£o diga que eu n√£o o avisei üòú';
const keywords = 'slm, modelos de linguagem pequenos, ajuste fino, piadas, humor, gpt2, openai, transformers, huggingface';
const languaje = 'PT';
const image_path = 'https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/SLM_thumnail.webp';
const opening_brace = '{';
const closing_brace = '}';
---

<PostLayout 
    title={page_title}
    languaje={languaje}
    description={description}
    keywords={keywords}
    author={metadata_page.author}
    theme_color={colors.background_color}
    end_url={end_url}
    image_path={image_path}
    image_width=900
    image_height=450
    image_extension=webp
    article_date=2024-07-14+T00:00:00Z
>

  <section class="post-body">


    <aside class="post-index">
      <a class="anchor-link" href="#Ajuste-fino-para-classifica%C3%A7%C3%A3o-de-texto-com-o-Hugging-Face"><h2>Ajuste fino para classifica√ß√£o de texto com o Hugging Face</h2></a>
      <a class="anchor-link" href="#Login"><h3>Login</h3></a>
      <a class="anchor-link" href="#Conjunto-de-dados"><h3>Conjunto de dados</h3></a>
      <a class="anchor-link" href="#Tokeniser"><h3>Tokeniser</h3></a>
      <a class="anchor-link" href="#Modelo"><h3>Modelo</h3></a>
      <a class="anchor-link" href="#Treinador"><h3>Treinador</h3></a>
      <a class="anchor-link" href="#Avalia%C3%A7%C3%A3o"><h3>Avalia√ß√£o</h3></a>
      <a class="anchor-link" href="#Publicar-o-modelo"><h3>Publicar o modelo</h3></a>
      <a class="anchor-link" href="#Uso-do-modelo"><h3>Uso do modelo</h3></a>
      <a class="anchor-link" href="#Ajuste-fino-para-gera%C3%A7%C3%A3o-de-texto-com-o-Hugging-Face"><h2>Ajuste fino para gera√ß√£o de texto com o Hugging Face</h2></a>
      <a class="anchor-link" href="#Login"><h3>Login</h3></a>
      <a class="anchor-link" href="#Conjunto-de-dados"><h3>Conjunto de dados</h3></a>
      <a class="anchor-link" href="#Tokeniser"><h3>Tokeniser</h3></a>
      <a class="anchor-link" href="#Modelo"><h3>Modelo</h3></a>
      <a class="anchor-link" href="#Treinamento"><h3>Treinamento</h3></a>
      <a class="anchor-link" href="#Avalia%C3%A7%C3%A3o"><h3>Avalia√ß√£o</h3></a>
      <a class="anchor-link" href="#Publicar-o-modelo"><h3>Publicar o modelo</h3></a>
      <a class="anchor-link" href="#Uso-do-modelo"><h3>Uso do modelo</h3></a>
      <a class="anchor-link" href="#Ajuste-fino-para-classifica%C3%A7%C3%A3o-de-texto-com-o-Pytorch"><h2>Ajuste fino para classifica√ß√£o de texto com o Pytorch</h2></a>
      <a class="anchor-link" href="#Conjunto-de-dados"><h3>Conjunto de dados</h3></a>
      <a class="anchor-link" href="#Tokeniser"><h3>Tokeniser</h3></a>
      <a class="anchor-link" href="#Modelo"><h3>Modelo</h3></a>
      <a class="anchor-link" href="#Dispositivo"><h3>Dispositivo</h3></a>
      <a class="anchor-link" href="#Conjunto-de-dados-Pytorch"><h3>Conjunto de dados Pytorch</h3></a>
      <a class="anchor-link" href="#Carregador-de-dados-Pytorch"><h3>Carregador de dados Pytorch</h3></a>
      <a class="anchor-link" href="#M%C3%A9trica"><h3>M√©trica</h3></a>
      <a class="anchor-link" href="#Otimizador"><h3>Otimizador</h3></a>
      <a class="anchor-link" href="#Treinamento"><h3>Treinamento</h3></a>
      <a class="anchor-link" href="#Uso-do-modelo"><h3>Uso do modelo</h3></a>
      <a class="anchor-link" href="#Ajuste-fino-para-gera%C3%A7%C3%A3o-de-texto-com-o-Pytorch"><h2>Ajuste fino para gera√ß√£o de texto com o Pytorch</h2></a>
      <a class="anchor-link" href="#Conjunto-de-dados"><h3>Conjunto de dados</h3></a>
      <a class="anchor-link" href="#Tokeniser"><h3>Tokeniser</h3></a>
      <a class="anchor-link" href="#Modelo"><h3>Modelo</h3></a>
      <a class="anchor-link" href="#Dispositivo"><h3>Dispositivo</h3></a>
      <a class="anchor-link" href="#Conjunto-de-dados-Pytorch"><h3>Conjunto de dados Pytorch</h3></a>
      <a class="anchor-link" href="#Carregador-de-dados-Pytorch"><h3>Carregador de dados Pytorch</h3></a>
      <a class="anchor-link" href="#Otimizador"><h3>Otimizador</h3></a>
      <a class="anchor-link" href="#Treinamento"><h3>Treinamento</h3></a>
      <a class="anchor-link" href="#Uso-do-modelo"><h3>Uso do modelo</h3></a>
    </aside>


    <div class="post-body-content">
      
      <section class="section-block-markdown-cell">
      <h1 id="Ajuste-fino-de-SMLs-com-Hugging-Face">Ajuste fino de SMLs com Hugging Face<a class="anchor-link" href="#Ajuste-fino-de-SMLs-com-Hugging-Face"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 80" src={svg_paths.link_svg_path}/></a></h1>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Nesta postagem, veremos como ajustar modelos de linguagem pequenos, como ajustar a classifica√ß√£o de texto e a gera√ß√£o de texto. Primeiro, veremos como fazer isso com as bibliotecas da Hugging Face, j√° que a Hugging Face se tornou um participante muito importante no ecossistema de IA atualmente.</p>
      <p>Mas, embora as bibliotecas do Hugging Face sejam muito importantes e √∫teis, √© muito importante saber como o treinamento √© realmente feito e o que est√° acontecendo por tr√°s dele, portanto, vamos repetir o treinamento para classifica√ß√£o e gera√ß√£o de texto, mas com o Pytorch.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Este caderno foi traduzido automaticamente para torn√°-lo acess√≠vel a mais pessoas, por favor me avise se voc√™ vir algum erro de digita√ß√£o..</p>
      <h2 id="Ajuste-fino-para-classifica%C3%A7%C3%A3o-de-texto-com-o-Hugging-Face">Ajuste fino para classifica√ß√£o de texto com o Hugging Face<a class="anchor-link" href="#Ajuste-fino-para-classifica%C3%A7%C3%A3o-de-texto-com-o-Hugging-Face"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 81" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Login">Login<a class="anchor-link" href="#Login"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 82" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Para fazer upload do resultado do treinamento no hub, primeiro precisamos fazer login e, para isso, precisamos de um token.</p>
      <p>Para criar um token, acesse a p√°gina <a href="https://huggingface.co/settings/tokens" target="_blank" rel="nofollow noreferrer">setings/tokens</a> de sua conta, que ter√° a seguinte apar√™ncia</p>
      <p>User-Access-Token-dark](<a href="http://maximofn.com/wp-content/uploads/2024/03/User-Access-Token-dark.png">http://maximofn.com/wp-content/uploads/2024/03/User-Access-Token-dark.png</a>)</p>
      <p>Clique em <code>New token</code> e ser√° exibida uma janela para criar um novo token.</p>
      <p><img decoding="async" onerror="this.parentNode.removeChild(this)" alt="new-token-dark" src="http://maximofn.com/wp-content/uploads/2024/03/new-token-dark.png" width="1200" height="660"/></p>
      <p>Nomeamos o token e o criamos com a fun√ß√£o <code>write</code> ou com a fun√ß√£o <code>Fine-grained</code>, que nos permite selecionar exatamente quais permiss√µes o token ter√°.</p>
      <p>Depois de criado, copiamos e colamos o arquivo abaixo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">huggingface_hub</span> <span class="kn">import</span> <span class="n">notebook_login</span>',
      '      <span class="n">notebook_login</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>







      
      <section class="section-block-markdown-cell">
      <h3 id="Conjunto-de-dados">Conjunto de dados<a class="anchor-link" href="#Conjunto-de-dados"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 83" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Agora, faremos o download de um conjunto de dados. Neste caso, faremos o download de um conjunto de dados de avalia√ß√µes da <a href="https://huggingface.co/datasets/mteb/amazon_reviews_multi" target="_blank" rel="nofollow noreferrer">Amazon</a></p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">huggingface_hub</span> <span class="kn">import</span> <span class="n">notebook_login</span>',
      '      <span class="n">notebook_login</span><span class="p">()</span>',
      '<span></span><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
      '      ',
      '      <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"mteb/amazon_reviews_multi"</span><span class="p">,</span> <span class="s2">"en"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>








      
      <section class="section-block-markdown-cell">
      <p>Vamos dar uma olhada nisso</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">huggingface_hub</span> <span class="kn">import</span> <span class="n">notebook_login</span>',
          '<span class="n">notebook_login</span><span class="p">()</span>',
          '</span><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"mteb/amazon_reviews_multi"</span><span class="p">,</span> <span class="s2">"en"</span><span class="p">)</span>',
          '</span><span class="n">dataset</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'DatasetDict({',
          '    train: Dataset({',
          '        features: [\'id\', \'text\', \'label\', \'label_text\'],',
          '        num_rows: 200000',
          '    })',
          '    validation: Dataset({',
          '        features: [\'id\', \'text\', \'label\', \'label_text\'],',
          '        num_rows: 5000',
          '    })',
          '    test: Dataset({',
          '        features: [\'id\', \'text\', \'label\', \'label_text\'],',
          '        num_rows: 5000',
          '    })',
          '})',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos que voc√™ tem um conjunto de treinamento com 200.000 amostras, um conjunto de valida√ß√£o com 5.000 amostras e um conjunto de teste com 5.000 amostras.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos dar uma olhada em um exemplo do conjunto de treinamento</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">random</span> <span class="kn">import</span> <span class="n">randint</span>',
          '',
          '<span class="n">idx</span> <span class="o">=</span> <span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>',
          '<span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '{\'id\': \'en_0907914\',',
          ' \'text\': \'Mixed with fir it‚Äôs passable\n\nNot the scent I had hoped for . Love the scent of cedar, but this one missed\',',
          ' \'label\': 3,',
          ' \'label_text\': \'3\'}',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos que voc√™ tem a avalia√ß√£o no campo <code>text</code> e a pontua√ß√£o dada pelo usu√°rio no campo <code>label</code>.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Como vamos criar um modelo de classifica√ß√£o de texto, precisamos saber quantas classes teremos.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="s1">\'label\'</span><span class="p">))</span>',
          '<span class="n">num_classes</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '5',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Teremos 5 classes, agora vamos ver o valor m√≠nimo dessas classes para saber se a pontua√ß√£o come√ßa em 0 ou 1. Para isso, usamos o m√©todo <code>unique</code></p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">dataset</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="s1">\'label\'</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '{\'train\': [0, 1, 2, 3, 4],',
          ' \'validation\': [0, 1, 2, 3, 4],',
          ' \'test\': [0, 1, 2, 3, 4]}',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>O valor m√≠nimo ser√° 0</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Para o treinamento, os r√≥tulos precisam estar em um campo chamado <code>labels</code>, enquanto em nosso conjunto de dados eles est√£o em um campo chamado <code>label</code>, portanto, criamos o novo campo <code>lables</code> com o mesmo valor de <code>label</code>.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Criamos uma fun√ß√£o que faz o que queremos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">def</span> <span class="nf">set_labels</span><span class="p">(</span><span class="n">example</span><span class="p">):</span>',
      '          <span class="n">example</span><span class="p">[</span><span class="s1">\'labels\'</span><span class="p">]</span> <span class="o">=</span> <span class="n">example</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">]</span>',
      '          <span class="k">return</span> <span class="n">example</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>








      
      <section class="section-block-markdown-cell">
      <p>Aplicamos a fun√ß√£o ao conjunto de dados</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">def</span> <span class="nf">set_labels</span><span class="p">(</span><span class="n">example</span><span class="p">):</span>',
      '          <span class="n">example</span><span class="p">[</span><span class="s1">\'labels\'</span><span class="p">]</span> <span class="o">=</span> <span class="n">example</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">]</span>',
      '          <span class="k">return</span> <span class="n">example</span>',
      '<span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">set_labels</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>






      
      <section class="section-block-markdown-cell">
      <p>Vejamos como √© o conjunto de dados</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="k">def</span> <span class="nf">set_labels</span><span class="p">(</span><span class="n">example</span><span class="p">):</span>',
          '    <span class="n">example</span><span class="p">[</span><span class="s1">\'labels\'</span><span class="p">]</span> <span class="o">=</span> <span class="n">example</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">]</span>',
          '    <span class="k">return</span> <span class="n">example</span>',
          '</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">set_labels</span><span class="p">)</span>',
          '</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '{\'id\': \'en_0907914\',',
          ' \'text\': \'Mixed with fir it‚Äôs passable\n\nNot the scent I had hoped for . Love the scent of cedar, but this one missed\',',
          ' \'label\': 3,',
          ' \'label_text\': \'3\',',
          ' \'labels\': 3}',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Tokeniser">Tokeniser<a class="anchor-link" href="#Tokeniser"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 84" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Como temos revis√µes de texto no conjunto de dados, precisamos tokeniz√°-las para colocar os tokens no modelo.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>',
      '      ',
      '      <span class="n">checkpoint</span> <span class="o">=</span> <span class="s2">"openai-community/gpt2"</span>',
      '      <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>









      
      <section class="section-block-markdown-cell">
      <p>Agora criamos uma fun√ß√£o para tokenizar o texto. Vamos fazer com que todas as frases tenham o mesmo comprimento, de modo que o tokenizador truncar√° quando necess√°rio e adicionar√° tokens de preenchimento quando necess√°rio. Tamb√©m pedimos que ele retorne tensores pytorch.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>O comprimento de cada frase √© de 768 tokens porque estamos usando o modelo GPT2 pequeno, que, como vimos na postagem <a href="https://maximofn.com/gpt2/#Arquitectura">GPT2</a>, tem uma dimens√£o de incorpora√ß√£o de 768 tokens.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>',
      '      ',
      '      <span class="n">checkpoint</span> <span class="o">=</span> <span class="s2">"openai-community/gpt2"</span>',
      '      <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>',
      '<span></span><span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>',
      '          <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>







      
      <section class="section-block-markdown-cell">
      <p>Vamos tentar tokenizar um texto</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>',
          '',
          '<span class="n">checkpoint</span> <span class="o">=</span> <span class="s2">"openai-community/gpt2"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>',
          '</span><span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '</span><span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">][</span><span class="n">idx</span><span class="p">])</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '<span class="ansi-red-fg">---------------------------------------------------------------------------</span>',
          '<span class="ansi-red-fg">ValueError</span>                                Traceback (most recent call last)',
          'Cell <span class="ansi-green-fg">In[11], line 1</span>',
          '<span class="ansi-green-fg">----&gt; 1</span> tokens <span style="color: rgb(98,98,98)">=</span> tokenize_function(dataset[<span style="color: rgb(175,0,0)">\'</span><span style="color: rgb(175,0,0)">train</span><span style="color: rgb(175,0,0)">\'</span>][idx])',
          'Cell <span class="ansi-green-fg">In[10], line 2</span>, in <span class="ansi-cyan-fg">tokenize_function</span><span class="ansi-blue-fg">(examples)</span>',
          '<span class="ansi-green-intense-fg ansi-bold">      1</span> <span class="ansi-bold" style="color: rgb(0,135,0)">def</span> <span style="color: rgb(0,0,255)">tokenize_function</span>(examples):',
          '<span class="ansi-green-fg">----&gt; 2</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> tokenizer(examples[<span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">text</span><span style="color: rgb(175,0,0)">"</span>], padding<span style="color: rgb(98,98,98)">=</span><span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">max_length</span><span style="color: rgb(175,0,0)">"</span>, truncation<span style="color: rgb(98,98,98)">=</span><span class="ansi-bold" style="color: rgb(0,135,0)">True</span>, max_length<span style="color: rgb(98,98,98)">=</span><span style="color: rgb(98,98,98)">768</span>, return_tensors<span style="color: rgb(98,98,98)">=</span><span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">pt</span><span style="color: rgb(175,0,0)">"</span>)',
          'File <span class="ansi-green-fg">~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2883</span>, in <span class="ansi-cyan-fg">PreTrainedTokenizerBase.__call__</span><span class="ansi-blue-fg">(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)</span>',
          '<span class="ansi-green-intense-fg ansi-bold">   2881</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> <span class="ansi-bold" style="color: rgb(175,0,255)">not</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_in_target_context_manager:',
          '<span class="ansi-green-intense-fg ansi-bold">   2882</span>         <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_switch_to_input_mode()',
          '<span class="ansi-green-fg">-&gt; 2883</span>     encodings <span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_call_one(text<span style="color: rgb(98,98,98)">=</span>text, text_pair<span style="color: rgb(98,98,98)">=</span>text_pair, <span style="color: rgb(98,98,98)">*</span><span style="color: rgb(98,98,98)">*</span>all_kwargs)',
          '<span class="ansi-green-intense-fg ansi-bold">   2884</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> text_target <span class="ansi-bold" style="color: rgb(175,0,255)">is</span> <span class="ansi-bold" style="color: rgb(175,0,255)">not</span> <span class="ansi-bold" style="color: rgb(0,135,0)">None</span>:',
          '<span class="ansi-green-intense-fg ansi-bold">   2885</span>     <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_switch_to_target_mode()',
          'File <span class="ansi-green-fg">~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2989</span>, in <span class="ansi-cyan-fg">PreTrainedTokenizerBase._call_one</span><span class="ansi-blue-fg">(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)</span>',
          '<span class="ansi-green-intense-fg ansi-bold">   2969</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>batch_encode_plus(',
          '<span class="ansi-green-intense-fg ansi-bold">   2970</span>         batch_text_or_text_pairs<span style="color: rgb(98,98,98)">=</span>batch_text_or_text_pairs,',
          '<span class="ansi-green-intense-fg ansi-bold">   2971</span>         add_special_tokens<span style="color: rgb(98,98,98)">=</span>add_special_tokens,',
          '<span class="ansi-green-fg">   (...)</span>',
          '<span class="ansi-green-intense-fg ansi-bold">   2986</span>         <span style="color: rgb(98,98,98)">*</span><span style="color: rgb(98,98,98)">*</span>kwargs,',
          '<span class="ansi-green-intense-fg ansi-bold">   2987</span>     )',
          '<span class="ansi-green-intense-fg ansi-bold">   2988</span> <span class="ansi-bold" style="color: rgb(0,135,0)">else</span>:',
          '<span class="ansi-green-fg">-&gt; 2989</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>encode_plus(',
          '<span class="ansi-green-intense-fg ansi-bold">   2990</span>         text<span style="color: rgb(98,98,98)">=</span>text,',
          '<span class="ansi-green-intense-fg ansi-bold">   2991</span>         text_pair<span style="color: rgb(98,98,98)">=</span>text_pair,',
          '<span class="ansi-green-intense-fg ansi-bold">   2992</span>         add_special_tokens<span style="color: rgb(98,98,98)">=</span>add_special_tokens,',
          '<span class="ansi-green-intense-fg ansi-bold">   2993</span>         padding<span style="color: rgb(98,98,98)">=</span>padding,',
          '<span class="ansi-green-intense-fg ansi-bold">   2994</span>         truncation<span style="color: rgb(98,98,98)">=</span>truncation,',
          '<span class="ansi-green-intense-fg ansi-bold">   2995</span>         max_length<span style="color: rgb(98,98,98)">=</span>max_length,',
          '<span class="ansi-green-intense-fg ansi-bold">   2996</span>         stride<span style="color: rgb(98,98,98)">=</span>stride,',
          '<span class="ansi-green-intense-fg ansi-bold">   2997</span>         is_split_into_words<span style="color: rgb(98,98,98)">=</span>is_split_into_words,',
          '<span class="ansi-green-intense-fg ansi-bold">   2998</span>         pad_to_multiple_of<span style="color: rgb(98,98,98)">=</span>pad_to_multiple_of,',
          '<span class="ansi-green-intense-fg ansi-bold">   2999</span>         return_tensors<span style="color: rgb(98,98,98)">=</span>return_tensors,',
          '<span class="ansi-green-intense-fg ansi-bold">   3000</span>         return_token_type_ids<span style="color: rgb(98,98,98)">=</span>return_token_type_ids,',
          '<span class="ansi-green-intense-fg ansi-bold">   3001</span>         return_attention_mask<span style="color: rgb(98,98,98)">=</span>return_attention_mask,',
          '<span class="ansi-green-intense-fg ansi-bold">   3002</span>         return_overflowing_tokens<span style="color: rgb(98,98,98)">=</span>return_overflowing_tokens,',
          '<span class="ansi-green-intense-fg ansi-bold">   3003</span>         return_special_tokens_mask<span style="color: rgb(98,98,98)">=</span>return_special_tokens_mask,',
          '<span class="ansi-green-intense-fg ansi-bold">   3004</span>         return_offsets_mapping<span style="color: rgb(98,98,98)">=</span>return_offsets_mapping,',
          '<span class="ansi-green-intense-fg ansi-bold">   3005</span>         return_length<span style="color: rgb(98,98,98)">=</span>return_length,',
          '<span class="ansi-green-intense-fg ansi-bold">   3006</span>         verbose<span style="color: rgb(98,98,98)">=</span>verbose,',
          '<span class="ansi-green-intense-fg ansi-bold">   3007</span>         <span style="color: rgb(98,98,98)">*</span><span style="color: rgb(98,98,98)">*</span>kwargs,',
          '<span class="ansi-green-intense-fg ansi-bold">   3008</span>     )',
          'File <span class="ansi-green-fg">~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3053</span>, in <span class="ansi-cyan-fg">PreTrainedTokenizerBase.encode_plus</span><span class="ansi-blue-fg">(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)</span>',
          '<span class="ansi-green-intense-fg ansi-bold">   3032</span> <span style="color: rgb(175,0,0)">"""</span>',
          '<span class="ansi-green-intense-fg ansi-bold">   3033</span> <span style="color: rgb(175,0,0)">Tokenize and prepare for the model a sequence or a pair of sequences.</span>',
          '<span class="ansi-green-intense-fg ansi-bold">   3034</span> ',
          '<span class="ansi-green-fg">   (...)</span>',
          '<span class="ansi-green-intense-fg ansi-bold">   3049</span> <span style="color: rgb(175,0,0)">        method).</span>',
          '<span class="ansi-green-intense-fg ansi-bold">   3050</span> <span style="color: rgb(175,0,0)">"""</span>',
          '<span class="ansi-green-intense-fg ansi-bold">   3052</span> <span style="color: rgb(95,135,135)"># Backward compatibility for \'truncation_strategy\', \'pad_to_max_length\'</span>',
          '<span class="ansi-green-fg">-&gt; 3053</span> padding_strategy, truncation_strategy, max_length, kwargs <span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_get_padding_truncation_strategies(',
          '<span class="ansi-green-intense-fg ansi-bold">   3054</span>     padding<span style="color: rgb(98,98,98)">=</span>padding,',
          '<span class="ansi-green-intense-fg ansi-bold">   3055</span>     truncation<span style="color: rgb(98,98,98)">=</span>truncation,',
          '<span class="ansi-green-intense-fg ansi-bold">   3056</span>     max_length<span style="color: rgb(98,98,98)">=</span>max_length,',
          '<span class="ansi-green-intense-fg ansi-bold">   3057</span>     pad_to_multiple_of<span style="color: rgb(98,98,98)">=</span>pad_to_multiple_of,',
          '<span class="ansi-green-intense-fg ansi-bold">   3058</span>     verbose<span style="color: rgb(98,98,98)">=</span>verbose,',
          '<span class="ansi-green-intense-fg ansi-bold">   3059</span>     <span style="color: rgb(98,98,98)">*</span><span style="color: rgb(98,98,98)">*</span>kwargs,',
          '<span class="ansi-green-intense-fg ansi-bold">   3060</span> )',
          '<span class="ansi-green-intense-fg ansi-bold">   3062</span> <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_encode_plus(',
          '<span class="ansi-green-intense-fg ansi-bold">   3063</span>     text<span style="color: rgb(98,98,98)">=</span>text,',
          '<span class="ansi-green-intense-fg ansi-bold">   3064</span>     text_pair<span style="color: rgb(98,98,98)">=</span>text_pair,',
          '<span class="ansi-green-fg">   (...)</span>',
          '<span class="ansi-green-intense-fg ansi-bold">   3080</span>     <span style="color: rgb(98,98,98)">*</span><span style="color: rgb(98,98,98)">*</span>kwargs,',
          '<span class="ansi-green-intense-fg ansi-bold">   3081</span> )',
          'File <span class="ansi-green-fg">~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2788</span>, in <span class="ansi-cyan-fg">PreTrainedTokenizerBase._get_padding_truncation_strategies</span><span class="ansi-blue-fg">(self, padding, truncation, max_length, pad_to_multiple_of, verbose, **kwargs)</span>',
          '<span class="ansi-green-intense-fg ansi-bold">   2786</span> <span style="color: rgb(95,135,135)"># Test if we have a padding token</span>',
          '<span class="ansi-green-intense-fg ansi-bold">   2787</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> padding_strategy <span style="color: rgb(98,98,98)">!=</span> PaddingStrategy<span style="color: rgb(98,98,98)">.</span>DO_NOT_PAD <span class="ansi-bold" style="color: rgb(175,0,255)">and</span> (<span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>pad_token <span class="ansi-bold" style="color: rgb(175,0,255)">is</span> <span class="ansi-bold" style="color: rgb(0,135,0)">None</span> <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>pad_token_id <span style="color: rgb(98,98,98)">&lt;</span> <span style="color: rgb(98,98,98)">0</span>):',
          '<span class="ansi-green-fg">-&gt; 2788</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">raise</span> <span class="ansi-bold" style="color: rgb(215,95,95)">ValueError</span>(',
          '<span class="ansi-green-intense-fg ansi-bold">   2789</span>         <span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">Asking to pad but the tokenizer does not have a padding token. </span><span style="color: rgb(175,0,0)">"</span>',
          '<span class="ansi-green-intense-fg ansi-bold">   2790</span>         <span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` </span><span style="color: rgb(175,0,0)">"</span>',
          '<span class="ansi-green-intense-fg ansi-bold">   2791</span>         <span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">or add a new pad token via `tokenizer.add_special_tokens(</span><span style="color: rgb(175,0,0)">{</span><span style="color: rgb(175,0,0)">\'</span><span style="color: rgb(175,0,0)">pad_token</span><span style="color: rgb(175,0,0)">\'</span><span style="color: rgb(175,0,0)">: </span><span style="color: rgb(175,0,0)">\'</span><span style="color: rgb(175,0,0)">[PAD]</span><span style="color: rgb(175,0,0)">\'</span><span style="color: rgb(175,0,0)">})`.</span><span style="color: rgb(175,0,0)">"</span>',
          '<span class="ansi-green-intense-fg ansi-bold">   2792</span>     )',
          '<span class="ansi-green-intense-fg ansi-bold">   2794</span> <span style="color: rgb(95,135,135)"># Check that we will truncate to a multiple of pad_to_multiple_of if both are provided</span>',
          '<span class="ansi-green-intense-fg ansi-bold">   2795</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> (',
          '<span class="ansi-green-intense-fg ansi-bold">   2796</span>     truncation_strategy <span style="color: rgb(98,98,98)">!=</span> TruncationStrategy<span style="color: rgb(98,98,98)">.</span>DO_NOT_TRUNCATE',
          '<span class="ansi-green-intense-fg ansi-bold">   2797</span>     <span class="ansi-bold" style="color: rgb(175,0,255)">and</span> padding_strategy <span style="color: rgb(98,98,98)">!=</span> PaddingStrategy<span style="color: rgb(98,98,98)">.</span>DO_NOT_PAD',
          '<span class="ansi-green-fg">   (...)</span>',
          '<span class="ansi-green-intense-fg ansi-bold">   2800</span>     <span class="ansi-bold" style="color: rgb(175,0,255)">and</span> (max_length <span style="color: rgb(98,98,98)">%</span> pad_to_multiple_of <span style="color: rgb(98,98,98)">!=</span> <span style="color: rgb(98,98,98)">0</span>)',
          '<span class="ansi-green-intense-fg ansi-bold">   2801</span> ):',
          '<span class="ansi-red-fg">ValueError</span>: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({\'pad_token\': \'[PAD]\'})`.',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Recebemos um erro porque o tokenizador GPT2 n√£o tem um token para preenchimento e nos pede para atribuir um, sugerindo que fa√ßamos <code>tokenizer.pad_token = tokenizer.eos_token</code>, e assim o fazemos.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>






      
      <section class="section-block-markdown-cell">
      <p>Testamos novamente a fun√ß√£o de tokeniza√ß√£o.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>',
          '</span><span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">][</span><span class="n">idx</span><span class="p">])</span>',
          '<span class="n">tokens</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">tokens</span><span class="p">[</span><span class="s1">\'attention_mask\'</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '(torch.Size([1, 768]), torch.Size([1, 768]))',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Agora que verificamos que a fun√ß√£o tokeniza bem, aplicamos essa fun√ß√£o ao conjunto de dados, mas tamb√©m a aplicamos em lotes para que seja executada mais rapidamente.</p>
      <p>Tamb√©m tiramos proveito disso e eliminamos as colunas que n√£o s√£o necess√°rias.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'text\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'id\'</span><span class="p">,</span> <span class="s1">\'label_text\'</span><span class="p">])</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>






      
      <section class="section-block-markdown-cell">
      <p>Agora vamos ver como √© o conjunto de dados</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'text\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'id\'</span><span class="p">,</span> <span class="s1">\'label_text\'</span><span class="p">])</span>',
          '</span><span class="n">dataset</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'DatasetDict({',
          '    train: Dataset({',
          '        features: [\'id\', \'text\', \'label\', \'label_text\', \'labels\'],',
          '        num_rows: 200000',
          '    })',
          '    validation: Dataset({',
          '        features: [\'id\', \'text\', \'label\', \'label_text\', \'labels\'],',
          '        num_rows: 5000',
          '    })',
          '    test: Dataset({',
          '        features: [\'id\', \'text\', \'label\', \'label_text\', \'labels\'],',
          '        num_rows: 5000',
          '    })',
          '})',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos que temos os campos "labels" (r√≥tulos), "input_ids" (IDs de entrada) e "attention_mask" (m√°scara de aten√ß√£o), que √© o que nos interessa treinar.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Modelo">Modelo<a class="anchor-link" href="#Modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 85" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Instanciamos um modelo para classifica√ß√£o de sequ√™ncias e informamos a ele o n√∫mero de classes que temos.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="n">num_classes</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: [\'score.weight\']',
          'You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Ele nos informa que os pesos da camada <code>score</code> foram inicializados aleatoriamente e que precisamos trein√°-los novamente.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>O modelo GPT2 teria a seguinte apar√™ncia</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForCausalLM</span>',
      '      ',
      '      <span class="n">casual_model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>








      
      <section class="section-block-markdown-cell">
      <p>Enquanto o modelo GPT2 para gerar texto √© o seguinte</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos dar uma olhada em sua arquitetura</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForCausalLM</span>',
          '',
          '<span class="n">casual_model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>',
          '</span><span class="n">casual_model</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'GPT2LMHeadModel(',
          '  (transformer): GPT2Model(',
          '    (wte): Embedding(50257, 768)',
          '    (wpe): Embedding(1024, 768)',
          '    (drop): Dropout(p=0.1, inplace=False)',
          '    (h): ModuleList(',
          '      (0-11): 12 x GPT2Block(',
          '        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)',
          '        (attn): GPT2Attention(',
          '          (c_attn): Conv1D()',
          '          (c_proj): Conv1D()',
          '          (attn_dropout): Dropout(p=0.1, inplace=False)',
          '          (resid_dropout): Dropout(p=0.1, inplace=False)',
          '        )',
          '        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)',
          '        (mlp): GPT2MLP(',
          '          (c_fc): Conv1D()',
          '          (c_proj): Conv1D()',
          '          (act): NewGELUActivation()',
          '          (dropout): Dropout(p=0.1, inplace=False)',
          '        )',
          '      )',
          '    )',
          '    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)',
          '  )',
          '  (lm_head): Linear(in_features=768, out_features=50257, bias=False)',
          ')',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>E agora a arquitetura do modelo que usaremos para classificar as avalia√ß√µes.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">model</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'GPT2ForSequenceClassification(',
          '  (transformer): GPT2Model(',
          '    (wte): Embedding(50257, 768)',
          '    (wpe): Embedding(1024, 768)',
          '    (drop): Dropout(p=0.1, inplace=False)',
          '    (h): ModuleList(',
          '      (0-11): 12 x GPT2Block(',
          '        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)',
          '        (attn): GPT2Attention(',
          '          (c_attn): Conv1D()',
          '          (c_proj): Conv1D()',
          '          (attn_dropout): Dropout(p=0.1, inplace=False)',
          '          (resid_dropout): Dropout(p=0.1, inplace=False)',
          '        )',
          '        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)',
          '        (mlp): GPT2MLP(',
          '          (c_fc): Conv1D()',
          '          (c_proj): Conv1D()',
          '          (act): NewGELUActivation()',
          '          (dropout): Dropout(p=0.1, inplace=False)',
          '        )',
          '      )',
          '    )',
          '    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)',
          '  )',
          '  (score): Linear(in_features=768, out_features=5, bias=False)',
          ')',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>H√° dois aspectos a serem mencionados aqui</p>
      <ul>
      <li>A primeira √© que, em ambas, a primeira camada tem dimens√µes de 50257x768, o que corresponde a 50257 tokens poss√≠veis do vocabul√°rio GPT2 e 768 dimens√µes da incorpora√ß√£o, portanto, fizemos bem em tokenizar as avalia√ß√µes com um tamanho de 768 tokens.</li>
      <li>A segunda √© que o modelo <code>casual</code> (o modelo de gera√ß√£o de texto) tem, no final, uma camada <code>Linear</code> que gera 50257 valores, ou seja, √© respons√°vel por prever o pr√≥ximo token e atribui um valor a cada token poss√≠vel. J√° o modelo de classifica√ß√£o tem uma camada <code>Linear</code> que gera apenas 5 valores, um para cada classe, o que nos dar√° a probabilidade de a avalia√ß√£o pertencer a cada classe.</li>
      </ul>
      <p>√â por isso que recebemos a mensagem de que os pesos da camada <code>score</code> foram inicializados aleatoriamente, porque a biblioteca de transformadores removeu a camada <code>Linear</code> de 768x50257 e adicionou uma camada <code>Linear</code> de 768x5, inicializou-a com valores aleat√≥rios e precisamos trein√°-la para nosso problema espec√≠fico.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Exclu√≠mos o modelo casual, porque n√£o vamos us√°-lo.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">del</span> <span class="n">casual_model</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>






      
      <section class="section-block-markdown-cell">
      <h3 id="Treinador">Treinador<a class="anchor-link" href="#Treinador"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 86" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos agora configurar os argumentos de treinamento</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">del</span> <span class="n">casual_model</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>',
      '      ',
      '      <span class="n">metric_name</span> <span class="o">=</span> <span class="s2">"accuracy"</span>',
      '      <span class="n">model_name</span> <span class="o">=</span> <span class="s2">"GPT2-small-finetuned-amazon-reviews-en-classification"</span>',
      '      <span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>',
      '      <span class="n">BS_TRAIN</span> <span class="o">=</span> <span class="mi">28</span>',
      '      <span class="n">BS_EVAL</span> <span class="o">=</span> <span class="mi">40</span>',
      '      <span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>',
      '      <span class="n">WEIGHT_DECAY</span> <span class="o">=</span> <span class="mf">0.01</span>',
      '      ',
      '      <span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
      '          <span class="n">model_name</span><span class="p">,</span>',
      '          <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">save_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
      '          <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
      '          <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
      '          <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
      '          <span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
      '          <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">"cosine"</span><span class="p">,</span>',
      '          <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
      '          <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span>',
      '          <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '      <span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>































      
      <section class="section-block-markdown-cell">
      <p>Definir uma m√©trica para o carregador de dados de valida√ß√£o</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">del</span> <span class="n">casual_model</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>',
      '      ',
      '      <span class="n">metric_name</span> <span class="o">=</span> <span class="s2">"accuracy"</span>',
      '      <span class="n">model_name</span> <span class="o">=</span> <span class="s2">"GPT2-small-finetuned-amazon-reviews-en-classification"</span>',
      '      <span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>',
      '      <span class="n">BS_TRAIN</span> <span class="o">=</span> <span class="mi">28</span>',
      '      <span class="n">BS_EVAL</span> <span class="o">=</span> <span class="mi">40</span>',
      '      <span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>',
      '      <span class="n">WEIGHT_DECAY</span> <span class="o">=</span> <span class="mf">0.01</span>',
      '      ',
      '      <span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
      '          <span class="n">model_name</span><span class="p">,</span>',
      '          <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">save_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
      '          <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
      '          <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
      '          <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
      '          <span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
      '          <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">"cosine"</span><span class="p">,</span>',
      '          <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
      '          <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span>',
      '          <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>',
      '      <span class="kn">from</span> <span class="nn">evaluate</span> <span class="kn">import</span> <span class="n">load</span>',
      '      ',
      '      <span class="n">metric</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
      '      ',
      '      <span class="k">def</span> <span class="nf">compute_metrics</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">):</span>',
      '          <span class="nb">print</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">)</span>',
      '          <span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">eval_pred</span>',
      '          <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
      '          <span class="k">return</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>















      
      <section class="section-block-markdown-cell">
      <p>Agora definimos o treinador</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">del</span> <span class="n">casual_model</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>',
      '      ',
      '      <span class="n">metric_name</span> <span class="o">=</span> <span class="s2">"accuracy"</span>',
      '      <span class="n">model_name</span> <span class="o">=</span> <span class="s2">"GPT2-small-finetuned-amazon-reviews-en-classification"</span>',
      '      <span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>',
      '      <span class="n">BS_TRAIN</span> <span class="o">=</span> <span class="mi">28</span>',
      '      <span class="n">BS_EVAL</span> <span class="o">=</span> <span class="mi">40</span>',
      '      <span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>',
      '      <span class="n">WEIGHT_DECAY</span> <span class="o">=</span> <span class="mf">0.01</span>',
      '      ',
      '      <span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
      '          <span class="n">model_name</span><span class="p">,</span>',
      '          <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">save_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
      '          <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
      '          <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
      '          <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
      '          <span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
      '          <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">"cosine"</span><span class="p">,</span>',
      '          <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
      '          <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span>',
      '          <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>',
      '      <span class="kn">from</span> <span class="nn">evaluate</span> <span class="kn">import</span> <span class="n">load</span>',
      '      ',
      '      <span class="n">metric</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
      '      ',
      '      <span class="k">def</span> <span class="nf">compute_metrics</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">):</span>',
      '          <span class="nb">print</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">)</span>',
      '          <span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">eval_pred</span>',
      '          <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
      '          <span class="k">return</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">Trainer</span>',
      '      ',
      '      <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
      '          <span class="n">model</span><span class="p">,</span>',
      '          <span class="n">training_args</span><span class="p">,</span>',
      '          <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">],</span>',
      '          <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'validation\'</span><span class="p">],</span>',
      '          <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
      '          <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>',
      '      <span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>















      
      <section class="section-block-markdown-cell">
      <p>Treinamos</p>
      </section>
      
      <section class="section-block-code-cell-">
      <div class="input-code">
      <div class="highlight hl-ipython3">
<pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
      </pre></div>
      </div>
      <div class="output-wrapper">
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-text-output-subarea">
      <pre>  0%|          | 0/600000 [00:00&lt;?, ?it/s]</pre>
      </div>
      </div>
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-subarea-output-text-output-error">
      <pre>
      <span class="ansi-red-fg">---------------------------------------------------------------------------</span>
      <span class="ansi-red-fg">ValueError</span>                                Traceback (most recent call last)
      Cell <span class="ansi-green-fg">In[21], line 1</span>
      <span class="ansi-green-fg">----&gt; 1</span> trainer<span style="color: rgb(98,98,98)">.</span>train()
      
      File <span class="ansi-green-fg">~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/trainer.py:1876</span>, in <span class="ansi-cyan-fg">Trainer.train</span><span class="ansi-blue-fg">(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)</span>
      <span class="ansi-green-intense-fg ansi-bold">   1873</span> <span class="ansi-bold" style="color: rgb(0,135,0)">try</span>:
      <span class="ansi-green-intense-fg ansi-bold">   1874</span>     <span style="color: rgb(95,135,135)"># Disable progress bars when uploading models during checkpoints to avoid polluting stdout</span>
      <span class="ansi-green-intense-fg ansi-bold">   1875</span>     hf_hub_utils<span style="color: rgb(98,98,98)">.</span>disable_progress_bars()
      <span class="ansi-green-fg">-&gt; 1876</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> inner_training_loop(
      <span class="ansi-green-intense-fg ansi-bold">   1877</span>         args<span style="color: rgb(98,98,98)">=</span>args,
      <span class="ansi-green-intense-fg ansi-bold">   1878</span>         resume_from_checkpoint<span style="color: rgb(98,98,98)">=</span>resume_from_checkpoint,
      <span class="ansi-green-intense-fg ansi-bold">   1879</span>         trial<span style="color: rgb(98,98,98)">=</span>trial,
      <span class="ansi-green-intense-fg ansi-bold">   1880</span>         ignore_keys_for_eval<span style="color: rgb(98,98,98)">=</span>ignore_keys_for_eval,
      <span class="ansi-green-intense-fg ansi-bold">   1881</span>     )
      <span class="ansi-green-intense-fg ansi-bold">   1882</span> <span class="ansi-bold" style="color: rgb(0,135,0)">finally</span>:
      <span class="ansi-green-intense-fg ansi-bold">   1883</span>     hf_hub_utils<span style="color: rgb(98,98,98)">.</span>enable_progress_bars()
      
      File <span class="ansi-green-fg">~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/trainer.py:2178</span>, in <span class="ansi-cyan-fg">Trainer._inner_training_loop</span><span class="ansi-blue-fg">(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)</span>
      <span class="ansi-green-intense-fg ansi-bold">   2175</span>     rng_to_sync <span style="color: rgb(98,98,98)">=</span> <span class="ansi-bold" style="color: rgb(0,135,0)">True</span>
      <span class="ansi-green-intense-fg ansi-bold">   2177</span> step <span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(98,98,98)">-</span><span style="color: rgb(98,98,98)">1</span>
      <span class="ansi-green-fg">-&gt; 2178</span> <span class="ansi-bold" style="color: rgb(0,135,0)">for</span> step, inputs <span class="ansi-bold" style="color: rgb(175,0,255)">in</span> <span style="color: rgb(0,135,0)">enumerate</span>(epoch_iterator):
      <span class="ansi-green-intense-fg ansi-bold">   2179</span>     total_batched_samples <span style="color: rgb(98,98,98)">+</span><span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(98,98,98)">1</span>
      <span class="ansi-green-intense-fg ansi-bold">   2181</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>args<span style="color: rgb(98,98,98)">.</span>include_num_input_tokens_seen:
      
      File <span class="ansi-green-fg">~/miniconda3/envs/nlp_/lib/python3.11/site-packages/accelerate/data_loader.py:454</span>, in <span class="ansi-cyan-fg">DataLoaderShard.__iter__</span><span class="ansi-blue-fg">(self)</span>
      <span class="ansi-green-intense-fg ansi-bold">    452</span> <span style="color: rgb(95,135,135)"># We iterate one batch ahead to check when we are at the end</span>
      <span class="ansi-green-intense-fg ansi-bold">    453</span> <span class="ansi-bold" style="color: rgb(0,135,0)">try</span>:
      <span class="ansi-green-fg">--&gt; 454</span>     current_batch <span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(0,135,0)">next</span>(dataloader_iter)
      <span class="ansi-green-intense-fg ansi-bold">    455</span> <span class="ansi-bold" style="color: rgb(0,135,0)">except</span> <span class="ansi-bold" style="color: rgb(215,95,95)">StopIteration</span>:
      <span class="ansi-green-intense-fg ansi-bold">    456</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">yield</span>
      
      File <span class="ansi-green-fg">~/miniconda3/envs/nlp_/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631</span>, in <span class="ansi-cyan-fg">_BaseDataLoaderIter.__next__</span><span class="ansi-blue-fg">(self)</span>
      <span class="ansi-green-intense-fg ansi-bold">    628</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_sampler_iter <span class="ansi-bold" style="color: rgb(175,0,255)">is</span> <span class="ansi-bold" style="color: rgb(0,135,0)">None</span>:
      <span class="ansi-green-intense-fg ansi-bold">    629</span>     <span style="color: rgb(95,135,135)"># TODO(https://github.com/pytorch/pytorch/issues/76750)</span>
      <span class="ansi-green-intense-fg ansi-bold">    630</span>     <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_reset()  <span style="color: rgb(95,135,135)"># type: ignore[call-arg]</span>
      <span class="ansi-green-fg">--&gt; 631</span> data <span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_next_data()
      <span class="ansi-green-intense-fg ansi-bold">    632</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_num_yielded <span style="color: rgb(98,98,98)">+</span><span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(98,98,98)">1</span>
      <span class="ansi-green-intense-fg ansi-bold">    633</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_dataset_kind <span style="color: rgb(98,98,98)">==</span> _DatasetKind<span style="color: rgb(98,98,98)">.</span>Iterable <span class="ansi-bold" style="color: rgb(175,0,255)">and</span> \
      <span class="ansi-green-intense-fg ansi-bold">    634</span>         <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_IterableDataset_len_called <span class="ansi-bold" style="color: rgb(175,0,255)">is</span> <span class="ansi-bold" style="color: rgb(175,0,255)">not</span> <span class="ansi-bold" style="color: rgb(0,135,0)">None</span> <span class="ansi-bold" style="color: rgb(175,0,255)">and</span> \
      <span class="ansi-green-intense-fg ansi-bold">    635</span>         <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_num_yielded <span style="color: rgb(98,98,98)">&gt;</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_IterableDataset_len_called:
      
      File <span class="ansi-green-fg">~/miniconda3/envs/nlp_/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675</span>, in <span class="ansi-cyan-fg">_SingleProcessDataLoaderIter._next_data</span><span class="ansi-blue-fg">(self)</span>
      <span class="ansi-green-intense-fg ansi-bold">    673</span> <span class="ansi-bold" style="color: rgb(0,135,0)">def</span> <span style="color: rgb(0,0,255)">_next_data</span>(<span style="color: rgb(0,135,0)">self</span>):
      <span class="ansi-green-intense-fg ansi-bold">    674</span>     index <span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_next_index()  <span style="color: rgb(95,135,135)"># may raise StopIteration</span>
      <span class="ansi-green-fg">--&gt; 675</span>     data <span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_dataset_fetcher<span style="color: rgb(98,98,98)">.</span>fetch(index)  <span style="color: rgb(95,135,135)"># may raise StopIteration</span>
      <span class="ansi-green-intense-fg ansi-bold">    676</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_pin_memory:
      <span class="ansi-green-intense-fg ansi-bold">    677</span>         data <span style="color: rgb(98,98,98)">=</span> _utils<span style="color: rgb(98,98,98)">.</span>pin_memory<span style="color: rgb(98,98,98)">.</span>pin_memory(data, <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_pin_memory_device)
      
      File <span class="ansi-green-fg">~/miniconda3/envs/nlp_/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:54</span>, in <span class="ansi-cyan-fg">_MapDatasetFetcher.fetch</span><span class="ansi-blue-fg">(self, possibly_batched_index)</span>
      <span class="ansi-green-intense-fg ansi-bold">     52</span> <span class="ansi-bold" style="color: rgb(0,135,0)">else</span>:
      <span class="ansi-green-intense-fg ansi-bold">     53</span>     data <span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>dataset[possibly_batched_index]
      <span class="ansi-green-fg">---&gt; 54</span> <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>collate_fn(data)
      
      File <span class="ansi-green-fg">~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/data/data_collator.py:271</span>, in <span class="ansi-cyan-fg">DataCollatorWithPadding.__call__</span><span class="ansi-blue-fg">(self, features)</span>
      <span class="ansi-green-intense-fg ansi-bold">    270</span> <span class="ansi-bold" style="color: rgb(0,135,0)">def</span> <span style="color: rgb(0,0,255)">__call__</span>(<span style="color: rgb(0,135,0)">self</span>, features: List[Dict[<span style="color: rgb(0,135,0)">str</span>, Any]]) <span style="color: rgb(98,98,98)">-</span><span style="color: rgb(98,98,98)">&gt;</span> Dict[<span style="color: rgb(0,135,0)">str</span>, Any]:
      <span class="ansi-green-fg">--&gt; 271</span>     batch <span style="color: rgb(98,98,98)">=</span> pad_without_fast_tokenizer_warning(
      <span class="ansi-green-intense-fg ansi-bold">    272</span>         <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>tokenizer,
      <span class="ansi-green-intense-fg ansi-bold">    273</span>         features,
      <span class="ansi-green-intense-fg ansi-bold">    274</span>         padding<span style="color: rgb(98,98,98)">=</span><span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>padding,
      <span class="ansi-green-intense-fg ansi-bold">    275</span>         max_length<span style="color: rgb(98,98,98)">=</span><span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>max_length,
      <span class="ansi-green-intense-fg ansi-bold">    276</span>         pad_to_multiple_of<span style="color: rgb(98,98,98)">=</span><span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>pad_to_multiple_of,
      <span class="ansi-green-intense-fg ansi-bold">    277</span>         return_tensors<span style="color: rgb(98,98,98)">=</span><span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>return_tensors,
      <span class="ansi-green-intense-fg ansi-bold">    278</span>     )
      <span class="ansi-green-intense-fg ansi-bold">    279</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> <span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">label</span><span style="color: rgb(175,0,0)">"</span> <span class="ansi-bold" style="color: rgb(175,0,255)">in</span> batch:
      <span class="ansi-green-intense-fg ansi-bold">    280</span>         batch[<span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">labels</span><span style="color: rgb(175,0,0)">"</span>] <span style="color: rgb(98,98,98)">=</span> batch[<span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">label</span><span style="color: rgb(175,0,0)">"</span>]
      
      File <span class="ansi-green-fg">~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/data/data_collator.py:66</span>, in <span class="ansi-cyan-fg">pad_without_fast_tokenizer_warning</span><span class="ansi-blue-fg">(tokenizer, *pad_args, **pad_kwargs)</span>
      <span class="ansi-green-intense-fg ansi-bold">     63</span> tokenizer<span style="color: rgb(98,98,98)">.</span>deprecation_warnings[<span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">Asking-to-pad-a-fast-tokenizer</span><span style="color: rgb(175,0,0)">"</span>] <span style="color: rgb(98,98,98)">=</span> <span class="ansi-bold" style="color: rgb(0,135,0)">True</span>
      <span class="ansi-green-intense-fg ansi-bold">     65</span> <span class="ansi-bold" style="color: rgb(0,135,0)">try</span>:
      <span class="ansi-green-fg">---&gt; 66</span>     padded <span style="color: rgb(98,98,98)">=</span> tokenizer<span style="color: rgb(98,98,98)">.</span>pad(<span style="color: rgb(98,98,98)">*</span>pad_args, <span style="color: rgb(98,98,98)">*</span><span style="color: rgb(98,98,98)">*</span>pad_kwargs)
      <span class="ansi-green-intense-fg ansi-bold">     67</span> <span class="ansi-bold" style="color: rgb(0,135,0)">finally</span>:
      <span class="ansi-green-intense-fg ansi-bold">     68</span>     <span style="color: rgb(95,135,135)"># Restore the state of the warning.</span>
      <span class="ansi-green-intense-fg ansi-bold">     69</span>     tokenizer<span style="color: rgb(98,98,98)">.</span>deprecation_warnings[<span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">Asking-to-pad-a-fast-tokenizer</span><span style="color: rgb(175,0,0)">"</span>] <span style="color: rgb(98,98,98)">=</span> warning_state
      
      File <span class="ansi-green-fg">~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3299</span>, in <span class="ansi-cyan-fg">PreTrainedTokenizerBase.pad</span><span class="ansi-blue-fg">(self, encoded_inputs, padding, max_length, pad_to_multiple_of, return_attention_mask, return_tensors, verbose)</span>
      <span class="ansi-green-intense-fg ansi-bold">   3297</span> <span style="color: rgb(95,135,135)"># The model's main input name, usually `input_ids`, has be passed for padding</span>
      <span class="ansi-green-intense-fg ansi-bold">   3298</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>model_input_names[<span style="color: rgb(98,98,98)">0</span>] <span class="ansi-bold" style="color: rgb(175,0,255)">not</span> <span class="ansi-bold" style="color: rgb(175,0,255)">in</span> encoded_inputs:
      <span class="ansi-green-fg">-&gt; 3299</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">raise</span> <span class="ansi-bold" style="color: rgb(215,95,95)">ValueError</span>(
      <span class="ansi-green-intense-fg ansi-bold">   3300</span>         <span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">You should supply an encoding or a list of encodings to this method </span><span style="color: rgb(175,0,0)">"</span>
      <span class="ansi-green-intense-fg ansi-bold">   3301</span>         <span style="color: rgb(175,0,0)">f</span><span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">that includes </span><span class="ansi-bold" style="color: rgb(175,95,135)">{opening_brace}</span><span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>model_input_names[<span style="color: rgb(98,98,98)">0</span>]<span class="ansi-bold" style="color: rgb(175,95,135)">{closing_brace}</span><span style="color: rgb(175,0,0)">, but you provided </span><span class="ansi-bold" style="color: rgb(175,95,135)">{opening_brace}</span><span style="color: rgb(0,135,0)">list</span>(encoded_inputs<span style="color: rgb(98,98,98)">.</span>keys())<span class="ansi-bold" style="color: rgb(175,95,135)">{closing_brace}</span><span style="color: rgb(175,0,0)">"</span>
      <span class="ansi-green-intense-fg ansi-bold">   3302</span>     )
      <span class="ansi-green-intense-fg ansi-bold">   3304</span> required_input <span style="color: rgb(98,98,98)">=</span> encoded_inputs[<span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>model_input_names[<span style="color: rgb(98,98,98)">0</span>]]
      <span class="ansi-green-intense-fg ansi-bold">   3306</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> required_input <span class="ansi-bold" style="color: rgb(175,0,255)">is</span> <span class="ansi-bold" style="color: rgb(0,135,0)">None</span> <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> (<span style="color: rgb(0,135,0)">isinstance</span>(required_input, Sized) <span class="ansi-bold" style="color: rgb(175,0,255)">and</span> <span style="color: rgb(0,135,0)">len</span>(required_input) <span style="color: rgb(98,98,98)">==</span> <span style="color: rgb(98,98,98)">0</span>):
      
      <span class="ansi-red-fg">ValueError</span>: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided ['label', 'labels']</pre>
      </div>
      </div>
      </div>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Recebemos um erro novamente porque o modelo n√£o foi atribu√≠do a um token de preenchimento, portanto, assim como no tokenizador, n√≥s o atribu√≠mos ao modelo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">del</span> <span class="n">casual_model</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>',
      '      ',
      '      <span class="n">metric_name</span> <span class="o">=</span> <span class="s2">"accuracy"</span>',
      '      <span class="n">model_name</span> <span class="o">=</span> <span class="s2">"GPT2-small-finetuned-amazon-reviews-en-classification"</span>',
      '      <span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>',
      '      <span class="n">BS_TRAIN</span> <span class="o">=</span> <span class="mi">28</span>',
      '      <span class="n">BS_EVAL</span> <span class="o">=</span> <span class="mi">40</span>',
      '      <span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>',
      '      <span class="n">WEIGHT_DECAY</span> <span class="o">=</span> <span class="mf">0.01</span>',
      '      ',
      '      <span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
      '          <span class="n">model_name</span><span class="p">,</span>',
      '          <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">save_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
      '          <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
      '          <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
      '          <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
      '          <span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
      '          <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">"cosine"</span><span class="p">,</span>',
      '          <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
      '          <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span>',
      '          <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>',
      '      <span class="kn">from</span> <span class="nn">evaluate</span> <span class="kn">import</span> <span class="n">load</span>',
      '      ',
      '      <span class="n">metric</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
      '      ',
      '      <span class="k">def</span> <span class="nf">compute_metrics</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">):</span>',
      '          <span class="nb">print</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">)</span>',
      '          <span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">eval_pred</span>',
      '          <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
      '          <span class="k">return</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">Trainer</span>',
      '      ',
      '      <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
      '          <span class="n">model</span><span class="p">,</span>',
      '          <span class="n">training_args</span><span class="p">,</span>',
      '          <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">],</span>',
      '          <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'validation\'</span><span class="p">],</span>',
      '          <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
      '          <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span></span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>






      
      <section class="section-block-markdown-cell">
      <p>Recriamos os argumentos do instrutor com o novo modelo, que agora tem um token de preenchimento, o instrutor e treinamos novamente.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">del</span> <span class="n">casual_model</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>',
      '      ',
      '      <span class="n">metric_name</span> <span class="o">=</span> <span class="s2">"accuracy"</span>',
      '      <span class="n">model_name</span> <span class="o">=</span> <span class="s2">"GPT2-small-finetuned-amazon-reviews-en-classification"</span>',
      '      <span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>',
      '      <span class="n">BS_TRAIN</span> <span class="o">=</span> <span class="mi">28</span>',
      '      <span class="n">BS_EVAL</span> <span class="o">=</span> <span class="mi">40</span>',
      '      <span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>',
      '      <span class="n">WEIGHT_DECAY</span> <span class="o">=</span> <span class="mf">0.01</span>',
      '      ',
      '      <span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
      '          <span class="n">model_name</span><span class="p">,</span>',
      '          <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">save_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
      '          <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
      '          <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
      '          <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
      '          <span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
      '          <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">"cosine"</span><span class="p">,</span>',
      '          <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
      '          <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span>',
      '          <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>',
      '      <span class="kn">from</span> <span class="nn">evaluate</span> <span class="kn">import</span> <span class="n">load</span>',
      '      ',
      '      <span class="n">metric</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
      '      ',
      '      <span class="k">def</span> <span class="nf">compute_metrics</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">):</span>',
      '          <span class="nb">print</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">)</span>',
      '          <span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">eval_pred</span>',
      '          <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
      '          <span class="k">return</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">Trainer</span>',
      '      ',
      '      <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
      '          <span class="n">model</span><span class="p">,</span>',
      '          <span class="n">training_args</span><span class="p">,</span>',
      '          <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">],</span>',
      '          <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'validation\'</span><span class="p">],</span>',
      '          <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
      '          <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span></span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>',
      '<span></span><span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
      '          <span class="n">model_name</span><span class="p">,</span>',
      '          <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">save_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
      '          <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
      '          <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
      '          <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
      '          <span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
      '          <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">"cosine"</span><span class="p">,</span>',
      '          <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
      '          <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span>',
      '          <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">logging_dir</span><span class="o">=</span><span class="s2">"./runs"</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '      ',
      '      <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
      '          <span class="n">model</span><span class="p">,</span>',
      '          <span class="n">training_args</span><span class="p">,</span>',
      '          <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">],</span>',
      '          <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'validation\'</span><span class="p">],</span>',
      '          <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
      '          <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>',
      '      <span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>































      
      <section class="section-block-markdown-cell">
      <p>Agora que vimos que tudo est√° bem, podemos treinar.</p>
      </section>
      
      <section class="section-block-code-cell-">
      <div class="input-code">
      <div class="highlight hl-ipython3">
<pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
      </pre></div>
      </div>
      <div class="output-wrapper">
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-html-rendered-html-output-subarea">
      <div>
      <progress max="21429" style="width:300px; height:20px; vertical-align: middle;" value="2250"></progress>
            [ 2250/21429 45:38 &lt; 6:29:27, 0.82 it/s, Epoch 0.31/3]
          </div>
      <table border="1" class="dataframe">
      <thead>
      <tr style="text-align: left;">
      <th>Epoch</th>
      <th>Training Loss</th>
      <th>Validation Loss</th>
      </tr>
      </thead>
      <tbody>
      </tbody>
      </table><p></p></div>
      </div>
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-html-rendered-html-output-subarea">
      <div>
      <progress max="21429" style="width:300px; height:20px; vertical-align: middle;" value="21429"></progress>
            [21429/21429 7:19:25, Epoch 3/3]
          </div>
      <table border="1" class="dataframe">
      <thead>
      <tr style="text-align: left;">
      <th>Epoch</th>
      <th>Training Loss</th>
      <th>Validation Loss</th>
      <th>Accuracy</th>
      </tr>
      </thead>
      <tbody>
      <tr>
      <td>1</td>
      <td>0.807400</td>
      <td>0.820341</td>
      <td>0.652000</td>
      </tr>
      <tr>
      <td>2</td>
      <td>0.751900</td>
      <td>0.802189</td>
      <td>0.654600</td>
      </tr>
      <tr>
      <td>3</td>
      <td>0.718100</td>
      <td>0.810221</td>
      <td>0.657800</td>
      </tr>
      </tbody>
      </table><p></p></div>
      </div>
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-subarea-output-stream-output-stdout-output-text">
      <pre>&lt;transformers.trainer_utils.EvalPrediction object at 0x782767ea1450&gt;
      &lt;transformers.trainer_utils.EvalPrediction object at 0x782767eeefe0&gt;
      &lt;transformers.trainer_utils.EvalPrediction object at 0x782767eecfd0&gt;
      </pre>
      </div>
      </div>
      <div class="output-area">
      <div class="prompt-output-prompt">Out[28]:</div>
      <div class="output-text-output-subareaoutput_execute_result">
      <pre>TrainOutput(global_step=21429, training_loss=0.7846888848762739, metrics={opening_brace}'train_runtime': 26367.7801, 'train_samples_per_second': 22.755, 'train_steps_per_second': 0.813, 'total_flos': 2.35173445632e+17, 'train_loss': 0.7846888848762739, 'epoch': 3.0{closing_brace})</pre>
      </div>
      </div>
      </div>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Avalia%C3%A7%C3%A3o">Avalia√ß√£o<a class="anchor-link" href="#Avalia%C3%A7%C3%A3o"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 87" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Depois de treinados, avaliamos o conjunto de dados de teste</p>
      </section>
      
      <section class="section-block-code-cell-">
      <div class="input-code">
      <div class="highlight hl-ipython3">
<pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">'test'</span><span class="p">])</span>
      </pre></div>
      </div>
      <div class="output-wrapper">
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-html-rendered-html-output-subarea">
      <div>
      <progress max="125" style="width:300px; height:20px; vertical-align: middle;" value="125"></progress>
            [125/125 01:15]
          </div>
      </div>
      </div>
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-subarea-output-stream-output-stdout-output-text">
      <pre>&lt;transformers.trainer_utils.EvalPrediction object at 0x7826ddfded40&gt;
      </pre>
      </div>
      </div>
      <div class="output-area">
      <div class="prompt-output-prompt">Out[29]:</div>
      <div class="output-text-output-subareaoutput_execute_result">
      <pre>{opening_brace}'eval_loss': 0.7973636984825134,
       'eval_accuracy': 0.6626,
       'eval_runtime': 76.3016,
       'eval_samples_per_second': 65.529,
       'eval_steps_per_second': 1.638,
       'epoch': 3.0}</pre>
      </div>
      </div>
      </div>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Publicar-o-modelo">Publicar o modelo<a class="anchor-link" href="#Publicar-o-modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 88" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Agora que temos nosso modelo treinado, podemos compartilh√°-lo com o mundo, portanto, primeiro criamos um cart√£o de modelo.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">del</span> <span class="n">casual_model</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>',
      '      ',
      '      <span class="n">metric_name</span> <span class="o">=</span> <span class="s2">"accuracy"</span>',
      '      <span class="n">model_name</span> <span class="o">=</span> <span class="s2">"GPT2-small-finetuned-amazon-reviews-en-classification"</span>',
      '      <span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>',
      '      <span class="n">BS_TRAIN</span> <span class="o">=</span> <span class="mi">28</span>',
      '      <span class="n">BS_EVAL</span> <span class="o">=</span> <span class="mi">40</span>',
      '      <span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>',
      '      <span class="n">WEIGHT_DECAY</span> <span class="o">=</span> <span class="mf">0.01</span>',
      '      ',
      '      <span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
      '          <span class="n">model_name</span><span class="p">,</span>',
      '          <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">save_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
      '          <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
      '          <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
      '          <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
      '          <span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
      '          <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">"cosine"</span><span class="p">,</span>',
      '          <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
      '          <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span>',
      '          <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>',
      '      <span class="kn">from</span> <span class="nn">evaluate</span> <span class="kn">import</span> <span class="n">load</span>',
      '      ',
      '      <span class="n">metric</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
      '      ',
      '      <span class="k">def</span> <span class="nf">compute_metrics</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">):</span>',
      '          <span class="nb">print</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">)</span>',
      '          <span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">eval_pred</span>',
      '          <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
      '          <span class="k">return</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">Trainer</span>',
      '      ',
      '      <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
      '          <span class="n">model</span><span class="p">,</span>',
      '          <span class="n">training_args</span><span class="p">,</span>',
      '          <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">],</span>',
      '          <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'validation\'</span><span class="p">],</span>',
      '          <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
      '          <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span></span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>',
      '<span></span><span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
      '          <span class="n">model_name</span><span class="p">,</span>',
      '          <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">save_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
      '          <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
      '          <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
      '          <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
      '          <span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
      '          <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">"cosine"</span><span class="p">,</span>',
      '          <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
      '          <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span>',
      '          <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">logging_dir</span><span class="o">=</span><span class="s2">"./runs"</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '      ',
      '      <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
      '          <span class="n">model</span><span class="p">,</span>',
      '          <span class="n">training_args</span><span class="p">,</span>',
      '          <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">],</span>',
      '          <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'validation\'</span><span class="p">],</span>',
      '          <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
      '          <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'test\'</span><span class="p">])</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">create_model_card</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>






      
      <section class="section-block-markdown-cell">
      <p>E agora podemos public√°-lo. Como a primeira coisa que fizemos foi fazer login no hub da huggingface, poderemos fazer o upload para o nosso hub sem nenhum problema.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">del</span> <span class="n">casual_model</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>',
      '      ',
      '      <span class="n">metric_name</span> <span class="o">=</span> <span class="s2">"accuracy"</span>',
      '      <span class="n">model_name</span> <span class="o">=</span> <span class="s2">"GPT2-small-finetuned-amazon-reviews-en-classification"</span>',
      '      <span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>',
      '      <span class="n">BS_TRAIN</span> <span class="o">=</span> <span class="mi">28</span>',
      '      <span class="n">BS_EVAL</span> <span class="o">=</span> <span class="mi">40</span>',
      '      <span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>',
      '      <span class="n">WEIGHT_DECAY</span> <span class="o">=</span> <span class="mf">0.01</span>',
      '      ',
      '      <span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
      '          <span class="n">model_name</span><span class="p">,</span>',
      '          <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">save_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
      '          <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
      '          <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
      '          <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
      '          <span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
      '          <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">"cosine"</span><span class="p">,</span>',
      '          <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
      '          <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span>',
      '          <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>',
      '      <span class="kn">from</span> <span class="nn">evaluate</span> <span class="kn">import</span> <span class="n">load</span>',
      '      ',
      '      <span class="n">metric</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
      '      ',
      '      <span class="k">def</span> <span class="nf">compute_metrics</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">):</span>',
      '          <span class="nb">print</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">)</span>',
      '          <span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">eval_pred</span>',
      '          <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
      '          <span class="k">return</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">Trainer</span>',
      '      ',
      '      <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
      '          <span class="n">model</span><span class="p">,</span>',
      '          <span class="n">training_args</span><span class="p">,</span>',
      '          <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">],</span>',
      '          <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'validation\'</span><span class="p">],</span>',
      '          <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
      '          <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span></span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>',
      '<span></span><span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
      '          <span class="n">model_name</span><span class="p">,</span>',
      '          <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">save_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
      '          <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
      '          <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
      '          <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
      '          <span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
      '          <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">"cosine"</span><span class="p">,</span>',
      '          <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
      '          <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span>',
      '          <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">logging_dir</span><span class="o">=</span><span class="s2">"./runs"</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '      ',
      '      <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
      '          <span class="n">model</span><span class="p">,</span>',
      '          <span class="n">training_args</span><span class="p">,</span>',
      '          <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">],</span>',
      '          <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'validation\'</span><span class="p">],</span>',
      '          <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
      '          <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'test\'</span><span class="p">])</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">create_model_card</span><span class="p">()</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">push_to_hub</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>






      
      <section class="section-block-markdown-cell">
      <h3 id="Uso-do-modelo">Uso do modelo<a class="anchor-link" href="#Uso-do-modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 89" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Limpamos o m√°ximo poss√≠vel</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">del</span> <span class="n">casual_model</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>',
      '      ',
      '      <span class="n">metric_name</span> <span class="o">=</span> <span class="s2">"accuracy"</span>',
      '      <span class="n">model_name</span> <span class="o">=</span> <span class="s2">"GPT2-small-finetuned-amazon-reviews-en-classification"</span>',
      '      <span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>',
      '      <span class="n">BS_TRAIN</span> <span class="o">=</span> <span class="mi">28</span>',
      '      <span class="n">BS_EVAL</span> <span class="o">=</span> <span class="mi">40</span>',
      '      <span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>',
      '      <span class="n">WEIGHT_DECAY</span> <span class="o">=</span> <span class="mf">0.01</span>',
      '      ',
      '      <span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
      '          <span class="n">model_name</span><span class="p">,</span>',
      '          <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">save_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
      '          <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
      '          <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
      '          <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
      '          <span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
      '          <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">"cosine"</span><span class="p">,</span>',
      '          <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
      '          <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span>',
      '          <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>',
      '      <span class="kn">from</span> <span class="nn">evaluate</span> <span class="kn">import</span> <span class="n">load</span>',
      '      ',
      '      <span class="n">metric</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
      '      ',
      '      <span class="k">def</span> <span class="nf">compute_metrics</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">):</span>',
      '          <span class="nb">print</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">)</span>',
      '          <span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">eval_pred</span>',
      '          <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
      '          <span class="k">return</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">Trainer</span>',
      '      ',
      '      <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
      '          <span class="n">model</span><span class="p">,</span>',
      '          <span class="n">training_args</span><span class="p">,</span>',
      '          <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">],</span>',
      '          <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'validation\'</span><span class="p">],</span>',
      '          <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
      '          <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span></span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>',
      '<span></span><span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
      '          <span class="n">model_name</span><span class="p">,</span>',
      '          <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">save_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
      '          <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
      '          <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
      '          <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
      '          <span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
      '          <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">"cosine"</span><span class="p">,</span>',
      '          <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
      '          <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span>',
      '          <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">logging_dir</span><span class="o">=</span><span class="s2">"./runs"</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '      ',
      '      <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
      '          <span class="n">model</span><span class="p">,</span>',
      '          <span class="n">training_args</span><span class="p">,</span>',
      '          <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">],</span>',
      '          <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'validation\'</span><span class="p">],</span>',
      '          <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
      '          <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'test\'</span><span class="p">])</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">create_model_card</span><span class="p">()</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">push_to_hub</span><span class="p">()</span>',
      '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
      '      <span class="kn">import</span> <span class="nn">gc</span>',
      '      ',
      '      ',
      '      <span class="k">def</span> <span class="nf">clear_hardwares</span><span class="p">():</span>',
      '          <span class="n">torch</span><span class="o">.</span><span class="n">clear_autocast_cache</span><span class="p">()</span>',
      '          <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">ipc_collect</span><span class="p">()</span>',
      '          <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>',
      '          <span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>',
      '      ',
      '      ',
      '      <span class="n">clear_hardwares</span><span class="p">()</span>',
      '      <span class="n">clear_hardwares</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>


















      
      <section class="section-block-markdown-cell">
      <p>Como fizemos o upload do modelo em nosso hub, podemos baix√°-lo e us√°-lo.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">del</span> <span class="n">casual_model</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>',
      '      ',
      '      <span class="n">metric_name</span> <span class="o">=</span> <span class="s2">"accuracy"</span>',
      '      <span class="n">model_name</span> <span class="o">=</span> <span class="s2">"GPT2-small-finetuned-amazon-reviews-en-classification"</span>',
      '      <span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>',
      '      <span class="n">BS_TRAIN</span> <span class="o">=</span> <span class="mi">28</span>',
      '      <span class="n">BS_EVAL</span> <span class="o">=</span> <span class="mi">40</span>',
      '      <span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>',
      '      <span class="n">WEIGHT_DECAY</span> <span class="o">=</span> <span class="mf">0.01</span>',
      '      ',
      '      <span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
      '          <span class="n">model_name</span><span class="p">,</span>',
      '          <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">save_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
      '          <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
      '          <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
      '          <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
      '          <span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
      '          <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">"cosine"</span><span class="p">,</span>',
      '          <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
      '          <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span>',
      '          <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>',
      '      <span class="kn">from</span> <span class="nn">evaluate</span> <span class="kn">import</span> <span class="n">load</span>',
      '      ',
      '      <span class="n">metric</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
      '      ',
      '      <span class="k">def</span> <span class="nf">compute_metrics</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">):</span>',
      '          <span class="nb">print</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">)</span>',
      '          <span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">eval_pred</span>',
      '          <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
      '          <span class="k">return</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">Trainer</span>',
      '      ',
      '      <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
      '          <span class="n">model</span><span class="p">,</span>',
      '          <span class="n">training_args</span><span class="p">,</span>',
      '          <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">],</span>',
      '          <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'validation\'</span><span class="p">],</span>',
      '          <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
      '          <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span></span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>',
      '<span></span><span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
      '          <span class="n">model_name</span><span class="p">,</span>',
      '          <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">save_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
      '          <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
      '          <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
      '          <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
      '          <span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
      '          <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">"cosine"</span><span class="p">,</span>',
      '          <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
      '          <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span>',
      '          <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">logging_dir</span><span class="o">=</span><span class="s2">"./runs"</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '      ',
      '      <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
      '          <span class="n">model</span><span class="p">,</span>',
      '          <span class="n">training_args</span><span class="p">,</span>',
      '          <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">],</span>',
      '          <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'validation\'</span><span class="p">],</span>',
      '          <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
      '          <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'test\'</span><span class="p">])</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">create_model_card</span><span class="p">()</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">push_to_hub</span><span class="p">()</span>',
      '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
      '      <span class="kn">import</span> <span class="nn">gc</span>',
      '      ',
      '      ',
      '      <span class="k">def</span> <span class="nf">clear_hardwares</span><span class="p">():</span>',
      '          <span class="n">torch</span><span class="o">.</span><span class="n">clear_autocast_cache</span><span class="p">()</span>',
      '          <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">ipc_collect</span><span class="p">()</span>',
      '          <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>',
      '          <span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>',
      '      ',
      '      ',
      '      <span class="n">clear_hardwares</span><span class="p">()</span>',
      '      <span class="n">clear_hardwares</span><span class="p">()</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">pipeline</span>',
      '      ',
      '      <span class="n">user</span> <span class="o">=</span> <span class="s2">"maximofn"</span>',
      '      <span class="n">checkpoints</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">user</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">"</span>',
      '      <span class="n">task</span> <span class="o">=</span> <span class="s2">"text-classification"</span>',
      '      <span class="n">classifier</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">checkpoints</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">checkpoints</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>











      
      <section class="section-block-markdown-cell">
      <p>Agora, se quisermos retornar a probabilidade de todas as classes, basta usar o classificador que acabamos de instanciar, com o par√¢metro <code>top_k=None</code>.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="k">del</span> <span class="n">casual_model</span>',
          '</span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>',
          '',
          '<span class="n">metric_name</span> <span class="o">=</span> <span class="s2">"accuracy"</span>',
          '<span class="n">model_name</span> <span class="o">=</span> <span class="s2">"GPT2-small-finetuned-amazon-reviews-en-classification"</span>',
          '<span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>',
          '<span class="n">BS_TRAIN</span> <span class="o">=</span> <span class="mi">28</span>',
          '<span class="n">BS_EVAL</span> <span class="o">=</span> <span class="mi">40</span>',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>',
          '<span class="n">WEIGHT_DECAY</span> <span class="o">=</span> <span class="mf">0.01</span>',
          '',
          '<span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
          '    <span class="n">model_name</span><span class="p">,</span>',
          '    <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
          '    <span class="n">save_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
          '    <span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
          '    <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
          '    <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
          '    <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
          '    <span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
          '    <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">"cosine"</span><span class="p">,</span>',
          '    <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
          '    <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
          '    <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
          '    <span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span>',
          '    <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
          '<span class="p">)</span>',
          '</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>',
          '<span class="kn">from</span> <span class="nn">evaluate</span> <span class="kn">import</span> <span class="n">load</span>',
          '',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">compute_metrics</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">)</span>',
          '    <span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">eval_pred</span>',
          '    <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
          '    <span class="k">return</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '</span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">Trainer</span>',
          '',
          '<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
          '    <span class="n">model</span><span class="p">,</span>',
          '    <span class="n">training_args</span><span class="p">,</span>',
          '    <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">],</span>',
          '    <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'validation\'</span><span class="p">],</span>',
          '    <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
          '    <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>',
          '<span class="p">)</span>',
          '</span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>',
          '</span><span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
          '    <span class="n">model_name</span><span class="p">,</span>',
          '    <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
          '    <span class="n">save_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
          '    <span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
          '    <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
          '    <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
          '    <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
          '    <span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
          '    <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">"cosine"</span><span class="p">,</span>',
          '    <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
          '    <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
          '    <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
          '    <span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span>',
          '    <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
          '    <span class="n">logging_dir</span><span class="o">=</span><span class="s2">"./runs"</span><span class="p">,</span>',
          '<span class="p">)</span>',
          '',
          '<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
          '    <span class="n">model</span><span class="p">,</span>',
          '    <span class="n">training_args</span><span class="p">,</span>',
          '    <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">],</span>',
          '    <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'validation\'</span><span class="p">],</span>',
          '    <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
          '    <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>',
          '<span class="p">)</span>',
          '</span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '</span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'test\'</span><span class="p">])</span>',
          '</span><span class="n">trainer</span><span class="o">.</span><span class="n">create_model_card</span><span class="p">()</span>',
          '</span><span class="n">trainer</span><span class="o">.</span><span class="n">push_to_hub</span><span class="p">()</span>',
          '</span><span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">import</span> <span class="nn">gc</span>',
          '',
          '',
          '<span class="k">def</span> <span class="nf">clear_hardwares</span><span class="p">():</span>',
          '    <span class="n">torch</span><span class="o">.</span><span class="n">clear_autocast_cache</span><span class="p">()</span>',
          '    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">ipc_collect</span><span class="p">()</span>',
          '    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>',
          '    <span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>',
          '',
          '',
          '<span class="n">clear_hardwares</span><span class="p">()</span>',
          '<span class="n">clear_hardwares</span><span class="p">()</span>',
          '</span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">pipeline</span>',
          '',
          '<span class="n">user</span> <span class="o">=</span> <span class="s2">"maximofn"</span>',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">user</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">"</span>',
          '<span class="n">task</span> <span class="o">=</span> <span class="s2">"text-classification"</span>',
          '<span class="n">classifier</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">checkpoints</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">checkpoints</span><span class="p">)</span>',
          '</span><span class="n">labels</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="s2">"I love this product"</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>',
          '<span class="n">labels</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '  0%|          | 0/600000 [00:00&lt;?, ?it/s]',
          '[{\'label\': \'LABEL_4\', \'score\': 0.8253807425498962},',
          ' {\'label\': \'LABEL_3\', \'score\': 0.15411493182182312},',
          ' {\'label\': \'LABEL_2\', \'score\': 0.013907806016504765},',
          ' {\'label\': \'LABEL_0\', \'score\': 0.003939222544431686},',
          ' {\'label\': \'LABEL_1\', \'score\': 0.0026572425849735737}]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Se quisermos apenas a classe com a maior probabilidade, faremos o mesmo, mas com o par√¢metro <code>top_k=1</code>.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">label</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="s2">"I love this product"</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
          '<span class="n">label</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '[{\'label\': \'LABEL_4\', \'score\': 0.8253807425498962}]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>E se quisermos n classes, faremos o mesmo, mas com o par√¢metro <code>top_k=n</code>.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">two_labels</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="s2">"I love this product"</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>',
          '<span class="n">two_labels</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '[{\'label\': \'LABEL_4\', \'score\': 0.8253807425498962},',
          ' {\'label\': \'LABEL_3\', \'score\': 0.15411493182182312}]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Tamb√©m podemos testar o modelo com o Automodel e o AutoTokenizer.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
      '      <span class="kn">import</span> <span class="nn">torch</span>',
      '      ',
      '      <span class="n">model_name</span> <span class="o">=</span> <span class="s2">"GPT2-small-finetuned-amazon-reviews-en-classification"</span>',
      '      <span class="n">user</span> <span class="o">=</span> <span class="s2">"maximofn"</span>',
      '      <span class="n">checkpoint</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">user</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">"</span>',
      '      <span class="n">num_classes</span> <span class="o">=</span> <span class="mi">5</span>',
      '      ',
      '      <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>',
      '      <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="n">num_classes</span><span class="p">)</span><span class="o">.</span><span class="n">half</span><span class="p">()</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">"cuda"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>















      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '',
          '<span class="n">model_name</span> <span class="o">=</span> <span class="s2">"GPT2-small-finetuned-amazon-reviews-en-classification"</span>',
          '<span class="n">user</span> <span class="o">=</span> <span class="s2">"maximofn"</span>',
          '<span class="n">checkpoint</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">user</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">"</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">5</span>',
          '',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="n">num_classes</span><span class="p">)</span><span class="o">.</span><span class="n">half</span><span class="p">()</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">"cuda"</span><span class="p">)</span>',
          '</span><span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">"I love this product"</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>',
          '<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>',
          '<span class="n">logits</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">logits</span>',
          '<span class="n">lables</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>',
          '<span class="n">lables</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '[0.003963470458984375,',
          ' 0.0026721954345703125,',
          ' 0.01397705078125,',
          ' 0.154541015625,',
          ' 0.82470703125]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Se voc√™ quiser testar o modelo com mais detalhes, poder√° v√™-lo em <a href="https://huggingface.co/Maximofn/GPT2-small-finetuned-amazon-reviews-en-classification" target="_blank" rel="nofollow noreferrer">Maximofn/GPT2-small-finetuned-amazon-reviews-en-classification</a></p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Ajuste-fino-para-gera%C3%A7%C3%A3o-de-texto-com-o-Hugging-Face">Ajuste fino para gera√ß√£o de texto com o Hugging Face<a class="anchor-link" href="#Ajuste-fino-para-gera%C3%A7%C3%A3o-de-texto-com-o-Hugging-Face"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 90" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Para ter certeza de que n√£o tenho problemas de mem√≥ria VRAM, reiniciei o notebook.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Login">Login<a class="anchor-link" href="#Login"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 91" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Para fazer upload do resultado do treinamento no hub, primeiro precisamos fazer login e, para isso, precisamos de um token.</p>
      <p>Para criar um token, acesse a p√°gina <a href="https://huggingface.co/settings/tokens" target="_blank" rel="nofollow noreferrer">setings/tokens</a> de sua conta, que ter√° a seguinte apar√™ncia</p>
      <p>User-Access-Token-dark](<a href="http://maximofn.com/wp-content/uploads/2024/03/User-Access-Token-dark.png">http://maximofn.com/wp-content/uploads/2024/03/User-Access-Token-dark.png</a>)</p>
      <p>Clique em <code>New token</code> e ser√° exibida uma janela para criar um novo token.</p>
      <p><img decoding="async" onerror="this.parentNode.removeChild(this)" alt="new-token-dark" src="http://maximofn.com/wp-content/uploads/2024/03/new-token-dark.png" width="1200" height="660"/></p>
      <p>Nomeamos o token e o criamos com a fun√ß√£o <code>write</code> ou com a fun√ß√£o <code>Fine-grained</code>, que nos permite selecionar exatamente quais permiss√µes o token ter√°.</p>
      <p>Depois de criado, copiamos e colamos o arquivo abaixo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">huggingface_hub</span> <span class="kn">import</span> <span class="n">notebook_login</span>',
      '      <span class="n">notebook_login</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>







      
      <section class="section-block-markdown-cell">
      <h3 id="Conjunto-de-dados">Conjunto de dados<a class="anchor-link" href="#Conjunto-de-dados"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 92" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos usar um conjunto de dados de [piadas em ingl√™s] (<a href="https://huggingface.co/datasets/Maximofn/short-jokes-dataset" target="_blank" rel="nofollow noreferrer">https://huggingface.co/datasets/Maximofn/short-jokes-dataset</a>)</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">huggingface_hub</span> <span class="kn">import</span> <span class="n">notebook_login</span>',
          '<span class="n">notebook_login</span><span class="p">()</span>',
          '</span><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '',
          '<span class="n">jokes</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"Maximofn/short-jokes-dataset"</span><span class="p">)</span>',
          '<span class="n">jokes</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'DatasetDict({',
          '    train: Dataset({',
          '        features: [\'ID\', \'Joke\'],',
          '        num_rows: 231657',
          '    })',
          '})',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vamos dar uma olhada nisso</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">jokes</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'DatasetDict({',
          '    train: Dataset({',
          '        features: [\'ID\', \'Joke\'],',
          '        num_rows: 231657',
          '    })',
          '})',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos que se trata de um √∫nico conjunto de treinamento com mais de 200.000 piadas. Portanto, mais adiante, teremos de dividi-lo em treinamento e avalia√ß√£o.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos dar uma olhada em um exemplo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">random</span> <span class="kn">import</span> <span class="n">randint</span>',
          '',
          '<span class="n">idx</span> <span class="o">=</span> <span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">jokes</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>',
          '<span class="n">jokes</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '{\'ID\': 198387,',
          ' \'Joke\': \'My hot dislexic co-worker said she had an important massage to give me in her office... When I got there, she told me it can wait until I put on some clothes.\'}',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos que ela tem uma identifica√ß√£o da piada que n√£o nos interessa em absoluto e a piada em si</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Caso voc√™ tenha pouca mem√≥ria de GPU, farei um subconjunto do conjunto de dados, escolha a porcentagem de piadas que deseja usar.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">percent_of_train_dataset</span> <span class="o">=</span> <span class="mi">1</span>    <span class="c1"># If you want 50% of the dataset, set this to 0.5</span>',
          '',
          '<span class="n">subset_dataset</span> <span class="o">=</span> <span class="n">jokes</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">jokes</span><span class="p">[</span><span class="s2">"train"</span><span class="p">])</span> <span class="o">*</span> <span class="n">percent_of_train_dataset</span><span class="p">)))</span>',
          '<span class="n">subset_dataset</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Dataset({',
          '    features: [\'ID\', \'Joke\'],',
          '    num_rows: 231657',
          '})',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Agora, dividimos o subconjunto em um conjunto de treinamento e um conjunto de valida√ß√£o.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">percent_of_train_dataset</span> <span class="o">=</span> <span class="mf">0.90</span>',
          '',
          '<span class="n">split_dataset</span> <span class="o">=</span> <span class="n">subset_dataset</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">train_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">subset_dataset</span><span class="o">.</span><span class="n">num_rows</span> <span class="o">*</span> <span class="n">percent_of_train_dataset</span><span class="p">),</span> <span class="n">seed</span><span class="o">=</span><span class="mi">19</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>',
          '<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span>',
          '<span class="n">validation_test_dataset</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span>',
          '',
          '<span class="n">split_dataset</span> <span class="o">=</span> <span class="n">validation_test_dataset</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">train_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">validation_test_dataset</span><span class="o">.</span><span class="n">num_rows</span> <span class="o">*</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">seed</span><span class="o">=</span><span class="mi">19</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>',
          '<span class="n">validation_dataset</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span>',
          '<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span>',
          '',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Size of the train set: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">. Size of the validation set: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">validation_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">. Size of the test set: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Size of the train set: 208491. Size of the validation set: 11583. Size of the test set: 11583',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Tokeniser">Tokeniser<a class="anchor-link" href="#Tokeniser"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 93" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Instanciar o tokenizador. Instanciar o token de preenchimento do tokenizador para n√£o recebermos um erro como antes.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>',
      '      ',
      '      <span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"openai-community/gpt2"</span>',
      '      ',
      '      <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '      <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>',
      '      <span class="n">tokenizer</span><span class="o">.</span><span class="n">padding_side</span> <span class="o">=</span> <span class="s2">"right"</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>












      
      <section class="section-block-markdown-cell">
      <p>Para maior controle, adicionaremos dois novos tokens para o in√≠cio e o fim de uma piada.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"openai-community/gpt2"</span>',
          '',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>',
          '<span class="n">tokenizer</span><span class="o">.</span><span class="n">padding_side</span> <span class="o">=</span> <span class="s2">"right"</span>',
          '</span><span class="n">new_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="s1">\'&lt;SJ&gt;\'</span><span class="p">,</span> <span class="s1">\'&lt;EJ&gt;\'</span><span class="p">]</span>   <span class="c1"># Start and end of joke tokens</span>',
          '',
          '<span class="n">num_added_tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">add_tokens</span><span class="p">(</span><span class="n">new_tokens</span><span class="p">)</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Added </span><span class="si">{</span><span class="n">num_added_tokens</span><span class="si">}</span><span class="s2"> tokens"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Added 2 tokens',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Criamos uma fun√ß√£o para adicionar os novos tokens √†s senten√ßas</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">joke_column</span> <span class="o">=</span> <span class="s2">"Joke"</span>',
      '      ',
      '      <span class="k">def</span> <span class="nf">format_joke</span><span class="p">(</span><span class="n">example</span><span class="p">):</span>',
      '          <span class="n">example</span><span class="p">[</span><span class="n">joke_column</span><span class="p">]</span> <span class="o">=</span> <span class="s1">\'&lt;SJ&gt; \'</span> <span class="o">+</span> <span class="n">example</span><span class="p">[</span><span class="s1">\'Joke\'</span><span class="p">]</span> <span class="o">+</span> <span class="s1">\' &lt;EJ&gt;\'</span>',
      '          <span class="k">return</span> <span class="n">example</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>










      
      <section class="section-block-markdown-cell">
      <p>Selecionamos as colunas de que n√£o precisamos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">joke_column</span> <span class="o">=</span> <span class="s2">"Joke"</span>',
          '',
          '<span class="k">def</span> <span class="nf">format_joke</span><span class="p">(</span><span class="n">example</span><span class="p">):</span>',
          '    <span class="n">example</span><span class="p">[</span><span class="n">joke_column</span><span class="p">]</span> <span class="o">=</span> <span class="s1">\'&lt;SJ&gt; \'</span> <span class="o">+</span> <span class="n">example</span><span class="p">[</span><span class="s1">\'Joke\'</span><span class="p">]</span> <span class="o">+</span> <span class="s1">\' &lt;EJ&gt;\'</span>',
          '    <span class="k">return</span> <span class="n">example</span>',
          '</span><span class="n">remove_columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">column</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">column_names</span> <span class="k">if</span> <span class="n">column</span> <span class="o">!=</span> <span class="n">joke_column</span><span class="p">]</span>',
          '<span class="n">remove_columns</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '[\'ID\']',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Formatamos o conjunto de dados e exclu√≠mos as colunas de que n√£o precisamos.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">format_joke</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="n">remove_columns</span><span class="p">)</span>',
          '<span class="n">validation_dataset</span> <span class="o">=</span> <span class="n">validation_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">format_joke</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="n">remove_columns</span><span class="p">)</span>',
          '<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">format_joke</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="n">remove_columns</span><span class="p">)</span>',
          '<span class="n">train_dataset</span><span class="p">,</span> <span class="n">validation_dataset</span><span class="p">,</span> <span class="n">test_dataset</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '(Dataset({',
          '     features: [\'Joke\'],',
          '     num_rows: 208491',
          ' }),',
          ' Dataset({',
          '     features: [\'Joke\'],',
          '     num_rows: 11583',
          ' }),',
          ' Dataset({',
          '     features: [\'Joke\'],',
          '     num_rows: 11583',
          ' }))',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Agora, criamos uma fun√ß√£o para tokenizar as piadas.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>',
      '          <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="n">joke_column</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>







      
      <section class="section-block-markdown-cell">
      <p>Tokenize o conjunto de dados e exclua a coluna com o texto</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="n">joke_column</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="n">joke_column</span><span class="p">])</span>',
          '<span class="n">validation_dataset</span> <span class="o">=</span> <span class="n">validation_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="n">joke_column</span><span class="p">])</span>',
          '<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="n">joke_column</span><span class="p">])</span>',
          '<span class="n">train_dataset</span><span class="p">,</span> <span class="n">validation_dataset</span><span class="p">,</span> <span class="n">test_dataset</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '(Dataset({',
          '     features: [\'input_ids\', \'attention_mask\'],',
          '     num_rows: 208491',
          ' }),',
          ' Dataset({',
          '     features: [\'input_ids\', \'attention_mask\'],',
          '     num_rows: 11583',
          ' }),',
          ' Dataset({',
          '     features: [\'input_ids\', \'attention_mask\'],',
          '     num_rows: 11583',
          ' }))',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Modelo">Modelo<a class="anchor-link" href="#Modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 94" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Agora, instanciamos o modelo para gera√ß√£o de texto e atribu√≠mos o token de fim de cadeia ao token de carregamento.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForCausalLM</span>',
      '      ',
      '      <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '      <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>









      
      <section class="section-block-markdown-cell">
      <p>Vemos o tamanho do vocabul√°rio do modelo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForCausalLM</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>',
          '</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span>',
          '<span class="n">vocab_size</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '50257',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Ele tem 50257 tokens, que √© o tamanho do vocabul√°rio do GPT2. Mas como dissemos que criar√≠amos dois novos tokens com o in√≠cio da piada e o fim da piada, n√≥s os adicionamos ao modelo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">model</span><span class="o">.</span><span class="n">resize_token_embeddings</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">))</span>',
          '',
          '<span class="n">new_vocab_size</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Old vocab size: </span><span class="si">{</span><span class="n">vocab_size</span><span class="si">}</span><span class="s2">. New vocab size: </span><span class="si">{</span><span class="n">new_vocab_size</span><span class="si">}</span><span class="s2">. Added </span><span class="si">{</span><span class="n">new_vocab_size</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">vocab_size</span><span class="si">}</span><span class="s2"> tokens"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Old vocab size: 50257. New vocab size: 50259. Added 2 tokens',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Os dois novos tokens foram adicionados</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Treinamento">Treinamento<a class="anchor-link" href="#Treinamento"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 95" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Definimos os par√¢metros de treinamento</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>',
      '      ',
      '      <span class="n">metric_name</span> <span class="o">=</span> <span class="s2">"accuracy"</span>',
      '      <span class="n">model_name</span> <span class="o">=</span> <span class="s2">"GPT2-small-finetuned-Maximofn-short-jokes-dataset-casualLM"</span>',
      '      <span class="n">output_dir</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"./training_results"</span>',
      '      <span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>',
      '      <span class="n">BS_TRAIN</span> <span class="o">=</span> <span class="mi">28</span>',
      '      <span class="n">BS_EVAL</span> <span class="o">=</span> <span class="mi">32</span>',
      '      <span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>',
      '      <span class="n">WEIGHT_DECAY</span> <span class="o">=</span> <span class="mf">0.01</span>',
      '      <span class="n">WARMUP_STEPS</span> <span class="o">=</span> <span class="mi">100</span>',
      '      ',
      '      <span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
      '          <span class="n">model_name</span><span class="p">,</span>',
      '          <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">save_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
      '          <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
      '          <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
      '          <span class="n">warmup_steps</span><span class="o">=</span><span class="n">WARMUP_STEPS</span><span class="p">,</span>',
      '          <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
      '          <span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
      '          <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">"cosine"</span><span class="p">,</span>',
      '          <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
      '          <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="c1"># metric_for_best_model=metric_name,</span>',
      '          <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '      <span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>


































      
      <section class="section-block-markdown-cell">
      <p>Agora n√£o usamos <code>metric_for_best_model</code>, depois de definir o treinador, explicamos o motivo</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Definimos o treinador</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>',
      '      ',
      '      <span class="n">metric_name</span> <span class="o">=</span> <span class="s2">"accuracy"</span>',
      '      <span class="n">model_name</span> <span class="o">=</span> <span class="s2">"GPT2-small-finetuned-Maximofn-short-jokes-dataset-casualLM"</span>',
      '      <span class="n">output_dir</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"./training_results"</span>',
      '      <span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>',
      '      <span class="n">BS_TRAIN</span> <span class="o">=</span> <span class="mi">28</span>',
      '      <span class="n">BS_EVAL</span> <span class="o">=</span> <span class="mi">32</span>',
      '      <span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>',
      '      <span class="n">WEIGHT_DECAY</span> <span class="o">=</span> <span class="mf">0.01</span>',
      '      <span class="n">WARMUP_STEPS</span> <span class="o">=</span> <span class="mi">100</span>',
      '      ',
      '      <span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
      '          <span class="n">model_name</span><span class="p">,</span>',
      '          <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">save_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
      '          <span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
      '          <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
      '          <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
      '          <span class="n">warmup_steps</span><span class="o">=</span><span class="n">WARMUP_STEPS</span><span class="p">,</span>',
      '          <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
      '          <span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
      '          <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">"cosine"</span><span class="p">,</span>',
      '          <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
      '          <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '          <span class="c1"># metric_for_best_model=metric_name,</span>',
      '          <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">Trainer</span>',
      '      ',
      '      <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
      '          <span class="n">model</span><span class="p">,</span>',
      '          <span class="n">training_args</span><span class="p">,</span>',
      '          <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>',
      '          <span class="n">eval_dataset</span><span class="o">=</span><span class="n">validation_dataset</span><span class="p">,</span>',
      '          <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
      '          <span class="c1"># compute_metrics=compute_metrics,</span>',
      '      <span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>















      
      <section class="section-block-markdown-cell">
      <p>Nesse caso, n√£o passamos uma fun√ß√£o <code>compute_metrics</code>; se ela n√£o for passada, a <code>loss</code> ser√° usada durante a avalia√ß√£o para avaliar o modelo. √â por isso que, ao definir os argumentos, n√£o definimos <code>metric_for_best_model</code>, pois n√£o usaremos uma m√©trica para avaliar o modelo, mas a <code>loss</code>.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Treinamos</p>
      </section>
      
      <section class="section-block-code-cell-">
      <div class="input-code">
      <div class="highlight hl-ipython3">
<pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
      </pre></div>
      </div>
      <div class="output-wrapper">
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-text-output-subarea">
      <pre>  0%|          | 0/625473 [00:00&lt;?, ?it/s]</pre>
      </div>
      </div>
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-subarea-output-text-output-error">
      <pre>
      <span class="ansi-red-fg">---------------------------------------------------------------------------</span>
      <span class="ansi-red-fg">ValueError</span>                                Traceback (most recent call last)
      Cell <span class="ansi-green-fg">In[19], line 1</span>
      <span class="ansi-green-fg">----&gt; 1</span> trainer<span style="color: rgb(98,98,98)">.</span>train()
      
      File <span class="ansi-green-fg">~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/trainer.py:1885</span>, in <span class="ansi-cyan-fg">Trainer.train</span><span class="ansi-blue-fg">(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)</span>
      <span class="ansi-green-intense-fg ansi-bold">   1883</span>         hf_hub_utils<span style="color: rgb(98,98,98)">.</span>enable_progress_bars()
      <span class="ansi-green-intense-fg ansi-bold">   1884</span> <span class="ansi-bold" style="color: rgb(0,135,0)">else</span>:
      <span class="ansi-green-fg">-&gt; 1885</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> inner_training_loop(
      <span class="ansi-green-intense-fg ansi-bold">   1886</span>         args<span style="color: rgb(98,98,98)">=</span>args,
      <span class="ansi-green-intense-fg ansi-bold">   1887</span>         resume_from_checkpoint<span style="color: rgb(98,98,98)">=</span>resume_from_checkpoint,
      <span class="ansi-green-intense-fg ansi-bold">   1888</span>         trial<span style="color: rgb(98,98,98)">=</span>trial,
      <span class="ansi-green-intense-fg ansi-bold">   1889</span>         ignore_keys_for_eval<span style="color: rgb(98,98,98)">=</span>ignore_keys_for_eval,
      <span class="ansi-green-intense-fg ansi-bold">   1890</span>     )
      
      File <span class="ansi-green-fg">~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/trainer.py:2216</span>, in <span class="ansi-cyan-fg">Trainer._inner_training_loop</span><span class="ansi-blue-fg">(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)</span>
      <span class="ansi-green-intense-fg ansi-bold">   2213</span>     <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>control <span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>callback_handler<span style="color: rgb(98,98,98)">.</span>on_step_begin(args, <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>state, <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>control)
      <span class="ansi-green-intense-fg ansi-bold">   2215</span> <span class="ansi-bold" style="color: rgb(0,135,0)">with</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>accelerator<span style="color: rgb(98,98,98)">.</span>accumulate(model):
      <span class="ansi-green-fg">-&gt; 2216</span>     tr_loss_step <span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>training_step(model, inputs)
      <span class="ansi-green-intense-fg ansi-bold">   2218</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> (
      <span class="ansi-green-intense-fg ansi-bold">   2219</span>     args<span style="color: rgb(98,98,98)">.</span>logging_nan_inf_filter
      <span class="ansi-green-intense-fg ansi-bold">   2220</span>     <span class="ansi-bold" style="color: rgb(175,0,255)">and</span> <span class="ansi-bold" style="color: rgb(175,0,255)">not</span> is_torch_xla_available()
      <span class="ansi-green-intense-fg ansi-bold">   2221</span>     <span class="ansi-bold" style="color: rgb(175,0,255)">and</span> (torch<span style="color: rgb(98,98,98)">.</span>isnan(tr_loss_step) <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> torch<span style="color: rgb(98,98,98)">.</span>isinf(tr_loss_step))
      <span class="ansi-green-intense-fg ansi-bold">   2222</span> ):
      <span class="ansi-green-intense-fg ansi-bold">   2223</span>     <span style="color: rgb(95,135,135)"># if loss is nan or inf simply add the average of previous logged losses</span>
      <span class="ansi-green-intense-fg ansi-bold">   2224</span>     tr_loss <span style="color: rgb(98,98,98)">+</span><span style="color: rgb(98,98,98)">=</span> tr_loss <span style="color: rgb(98,98,98)">/</span> (<span style="color: rgb(98,98,98)">1</span> <span style="color: rgb(98,98,98)">+</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>state<span style="color: rgb(98,98,98)">.</span>global_step <span style="color: rgb(98,98,98)">-</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_globalstep_last_logged)
      
      File <span class="ansi-green-fg">~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/trainer.py:3238</span>, in <span class="ansi-cyan-fg">Trainer.training_step</span><span class="ansi-blue-fg">(self, model, inputs)</span>
      <span class="ansi-green-intense-fg ansi-bold">   3235</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> loss_mb<span style="color: rgb(98,98,98)">.</span>reduce_mean()<span style="color: rgb(98,98,98)">.</span>detach()<span style="color: rgb(98,98,98)">.</span>to(<span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>args<span style="color: rgb(98,98,98)">.</span>device)
      <span class="ansi-green-intense-fg ansi-bold">   3237</span> <span class="ansi-bold" style="color: rgb(0,135,0)">with</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>compute_loss_context_manager():
      <span class="ansi-green-fg">-&gt; 3238</span>     loss <span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>compute_loss(model, inputs)
      <span class="ansi-green-intense-fg ansi-bold">   3240</span> <span class="ansi-bold" style="color: rgb(0,135,0)">del</span> inputs
      <span class="ansi-green-intense-fg ansi-bold">   3241</span> torch<span style="color: rgb(98,98,98)">.</span>cuda<span style="color: rgb(98,98,98)">.</span>empty_cache()
      
      File <span class="ansi-green-fg">~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/trainer.py:3282</span>, in <span class="ansi-cyan-fg">Trainer.compute_loss</span><span class="ansi-blue-fg">(self, model, inputs, return_outputs)</span>
      <span class="ansi-green-intense-fg ansi-bold">   3280</span> <span class="ansi-bold" style="color: rgb(0,135,0)">else</span>:
      <span class="ansi-green-intense-fg ansi-bold">   3281</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> <span style="color: rgb(0,135,0)">isinstance</span>(outputs, <span style="color: rgb(0,135,0)">dict</span>) <span class="ansi-bold" style="color: rgb(175,0,255)">and</span> <span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">loss</span><span style="color: rgb(175,0,0)">"</span> <span class="ansi-bold" style="color: rgb(175,0,255)">not</span> <span class="ansi-bold" style="color: rgb(175,0,255)">in</span> outputs:
      <span class="ansi-green-fg">-&gt; 3282</span>         <span class="ansi-bold" style="color: rgb(0,135,0)">raise</span> <span class="ansi-bold" style="color: rgb(215,95,95)">ValueError</span>(
      <span class="ansi-green-intense-fg ansi-bold">   3283</span>             <span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">The model did not return a loss from the inputs, only the following keys: </span><span style="color: rgb(175,0,0)">"</span>
      <span class="ansi-green-intense-fg ansi-bold">   3284</span>             <span style="color: rgb(175,0,0)">f</span><span style="color: rgb(175,0,0)">"</span><span class="ansi-bold" style="color: rgb(175,95,135)">{opening_brace}</span><span style="color: rgb(175,0,0)">'</span><span style="color: rgb(175,0,0)">,</span><span style="color: rgb(175,0,0)">'</span><span style="color: rgb(98,98,98)">.</span>join(outputs<span style="color: rgb(98,98,98)">.</span>keys())<span class="ansi-bold" style="color: rgb(175,95,135)">{closing_brace}</span><span style="color: rgb(175,0,0)">. For reference, the inputs it received are </span><span class="ansi-bold" style="color: rgb(175,95,135)">{opening_brace}</span><span style="color: rgb(175,0,0)">'</span><span style="color: rgb(175,0,0)">,</span><span style="color: rgb(175,0,0)">'</span><span style="color: rgb(98,98,98)">.</span>join(inputs<span style="color: rgb(98,98,98)">.</span>keys())<span class="ansi-bold" style="color: rgb(175,95,135)">{closing_brace}</span><span style="color: rgb(175,0,0)">.</span><span style="color: rgb(175,0,0)">"</span>
      <span class="ansi-green-intense-fg ansi-bold">   3285</span>         )
      <span class="ansi-green-intense-fg ansi-bold">   3286</span>     <span style="color: rgb(95,135,135)"># We don't use .loss here since the model may return tuples instead of ModelOutput.</span>
      <span class="ansi-green-intense-fg ansi-bold">   3287</span>     loss <span style="color: rgb(98,98,98)">=</span> outputs[<span style="color: rgb(175,0,0)">"</span><span style="color: rgb(175,0,0)">loss</span><span style="color: rgb(175,0,0)">"</span>] <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> <span style="color: rgb(0,135,0)">isinstance</span>(outputs, <span style="color: rgb(0,135,0)">dict</span>) <span class="ansi-bold" style="color: rgb(0,135,0)">else</span> outputs[<span style="color: rgb(98,98,98)">0</span>]
      
      <span class="ansi-red-fg">ValueError</span>: The model did not return a loss from the inputs, only the following keys: logits,past_key_values. For reference, the inputs it received are input_ids,attention_mask.</pre>
      </div>
      </div>
      </div>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Como podemos ver, ele nos d√° um erro, diz que o modelo n√£o retorna o valor da perda, o que √© fundamental para podermos treinar.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Primeiro, vamos ver como √© um exemplo do conjunto de dados.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>',
          '',
          '<span class="n">metric_name</span> <span class="o">=</span> <span class="s2">"accuracy"</span>',
          '<span class="n">model_name</span> <span class="o">=</span> <span class="s2">"GPT2-small-finetuned-Maximofn-short-jokes-dataset-casualLM"</span>',
          '<span class="n">output_dir</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"./training_results"</span>',
          '<span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>',
          '<span class="n">BS_TRAIN</span> <span class="o">=</span> <span class="mi">28</span>',
          '<span class="n">BS_EVAL</span> <span class="o">=</span> <span class="mi">32</span>',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>',
          '<span class="n">WEIGHT_DECAY</span> <span class="o">=</span> <span class="mf">0.01</span>',
          '<span class="n">WARMUP_STEPS</span> <span class="o">=</span> <span class="mi">100</span>',
          '',
          '<span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
          '    <span class="n">model_name</span><span class="p">,</span>',
          '    <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
          '    <span class="n">save_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>',
          '    <span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
          '    <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
          '    <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
          '    <span class="n">warmup_steps</span><span class="o">=</span><span class="n">WARMUP_STEPS</span><span class="p">,</span>',
          '    <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
          '    <span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
          '    <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">"cosine"</span><span class="p">,</span>',
          '    <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
          '    <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
          '    <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
          '    <span class="c1"># metric_for_best_model=metric_name,</span>',
          '    <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
          '<span class="p">)</span>',
          '</span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">Trainer</span>',
          '',
          '<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
          '    <span class="n">model</span><span class="p">,</span>',
          '    <span class="n">training_args</span><span class="p">,</span>',
          '    <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>',
          '    <span class="n">eval_dataset</span><span class="o">=</span><span class="n">validation_dataset</span><span class="p">,</span>',
          '    <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
          '    <span class="c1"># compute_metrics=compute_metrics,</span>',
          '<span class="p">)</span>',
          '</span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '</span><span class="n">idx</span> <span class="o">=</span> <span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>',
          '<span class="n">sample</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>',
          '<span class="n">sample</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '  0%|          | 0/625473 [00:00&lt;?, ?it/s]',
          '{\'input_ids\': [50257,',
          '  4162,',
          '  750,',
          '  262,',
          '  18757,',
          '  6451,',
          '  2245,',
          '  2491,',
          '  30,',
          '  4362,',
          '  340,',
          '  373,',
          '  734,',
          '  10032,',
          '  13,',
          '  220,',
          '  50258,',
          '  50256,',
          '  50256,',
          '  ...,',
          '  50256,',
          '  50256,',
          '  50256],',
          ' \'attention_mask\': [1,',
          '  1,',
          '  1,',
          '  1,',
          '  1,',
          '  1,',
          '  1,',
          '  1,',
          '  1,',
          '  1,',
          '  1,',
          '  1,',
          '  1,',
          '  1,',
          '  1,',
          '  1,',
          '  1,',
          '  0,',
          '  0,',
          '  0,',
          '  ...,',
          '  0,',
          '  0,',
          '  0]}',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Como podemos ver, temos um dicion√°rio com <code>input_ids</code> e <code>attention_mask</code> e, se o passarmos para o modelo, obteremos o seguinte</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
          '',
          '<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span>',
          '    <span class="n">input_ids</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">])</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>',
          '    <span class="n">attention_mask</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">])</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>',
          '<span class="p">)</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">loss</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'None',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Como podemos ver, ele n√£o retorna o valor da perda porque est√° aguardando um valor para <code>labels</code>, que n√£o foi passado a ele. No exemplo anterior, em que fizemos o ajuste fino para a classifica√ß√£o de texto, dissemos que os r√≥tulos tinham de ser passados para um campo no conjunto de dados chamado <code>labels</code>, mas, nesse caso, n√£o temos esse campo no conjunto de dados.</p>
      <p>Se agora atribuirmos os <code>lables</code> aos <code>input_ids</code> e observarmos novamente a perda</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
          '',
          '<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span>',
          '    <span class="n">input_ids</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">])</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>',
          '    <span class="n">attention_mask</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">])</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>',
          '    <span class="n">labels</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">])</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>',
          '<span class="p">)</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">loss</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'tensor(102.1873, device=\'cuda:0\', grad_fn=&lt;NllLossBackward0&gt;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Agora temos uma "perda".</p>
      <p>Portanto, temos duas op√ß√µes: adicionar um campo <code>labels</code> ao conjunto de dados, com os valores de <code>input_ids</code> ou usar uma fun√ß√£o da biblioteca <code>transformers</code> chamada <code>data_collator</code>; nesse caso, usaremos <code>DataCollatorForLanguageModeling</code>. Vamos dar uma olhada nisso</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">DataCollatorForLanguageModeling</span>',
      '      ',
      '      <span class="n">my_data_collator</span><span class="o">=</span><span class="n">DataCollatorForLanguageModeling</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">mlm</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>








      
      <section class="section-block-markdown-cell">
      <p>Passamos a amostra <code>sample</code> por meio desse <code>data_collator</code>.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">DataCollatorForLanguageModeling</span>',
      '      ',
      '      <span class="n">my_data_collator</span><span class="o">=</span><span class="n">DataCollatorForLanguageModeling</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">mlm</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>',
      '<span></span><span class="n">collated_sample</span> <span class="o">=</span> <span class="n">my_data_collator</span><span class="p">([</span><span class="n">sample</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>






      
      <section class="section-block-markdown-cell">
      <p>Vemos como √© a sa√≠da</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">DataCollatorForLanguageModeling</span>',
          '',
          '<span class="n">my_data_collator</span><span class="o">=</span><span class="n">DataCollatorForLanguageModeling</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">mlm</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>',
          '</span><span class="n">collated_sample</span> <span class="o">=</span> <span class="n">my_data_collator</span><span class="p">([</span><span class="n">sample</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>',
          '</span><span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">collated_sample</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">): </span><span class="si">{</span><span class="n">value</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'input_ids (torch.Size([1, 768])): tensor([[50257,  4162,   750,   262, 18757,  6451,  2245,  2491,    30,  4362,',
          '           340,   373,   734, 10032,    13,   220, 50258, 50256, ..., 50256, 50256]],',
          '       device=\'cuda:0\')',
          'attention_mask (torch.Size([1, 768])): tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, ..., 0, 0]],',
          '       device=\'cuda:0\')',
          'labels (torch.Size([1, 768])): tensor([[50257,  4162,   750,   262, 18757,  6451,  2245,  2491,    30,  4362,',
          '           340,   373,   734, 10032,    13,   220, 50258,  -100,  ...,  -100,  -100]],',
          '       device=\'cuda:0\')',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Como voc√™ pode ver, o <code>data_collator</code> criou um campo <code>labels</code> e atribuiu a ele os valores de <code>input_ids</code>. Os tokens que s√£o mascarados receberam um valor de -100. Isso se deve ao fato de que, quando definimos o <code>data_collator</code>, passamos a ele o par√¢metro <code>mlm=False</code>, o que significa que n√£o estamos fazendo <code>Masked Language Modeling</code>, mas <code>Language Modeling</code>, portanto, ele n√£o mascara nenhum token original.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos ver se agora temos uma <code>perda</code> com esse <code>data_collator</code>.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">collated_sample</span><span class="p">)</span>',
          '<span class="n">output</span><span class="o">.</span><span class="n">loss</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'tensor(102.7181, device=\'cuda:0\', grad_fn=&lt;NllLossBackward0&gt;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Portanto, redefinimos o <code>trainer</code> com o <code>data_collator</code> e treinamos novamente.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">DataCollatorForLanguageModeling</span>',
      '      ',
      '      <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
      '          <span class="n">model</span><span class="p">,</span>',
      '          <span class="n">training_args</span><span class="p">,</span>',
      '          <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>',
      '          <span class="n">eval_dataset</span><span class="o">=</span><span class="n">validation_dataset</span><span class="p">,</span>',
      '          <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
      '          <span class="n">data_collator</span><span class="o">=</span><span class="n">DataCollatorForLanguageModeling</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">mlm</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>',
      '      <span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>















      
      <section class="section-block-code-cell-">
      <div class="input-code">
      <div class="highlight hl-ipython3">
<pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
      </pre></div>
      </div>
      <div class="output-wrapper">
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-html-rendered-html-output-subarea">
      <div>
      <progress max="22341" style="width:300px; height:20px; vertical-align: middle;" value="22341"></progress>
            [22341/22341 2:33:28, Epoch 3/3]
          </div>
      <table border="1" class="dataframe">
      <thead>
      <tr style="text-align: left;">
      <th>Epoch</th>
      <th>Training Loss</th>
      <th>Validation Loss</th>
      </tr>
      </thead>
      <tbody>
      <tr>
      <td>1</td>
      <td>3.386600</td>
      <td>3.258979</td>
      </tr>
      <tr>
      <td>2</td>
      <td>3.259900</td>
      <td>3.199673</td>
      </tr>
      <tr>
      <td>3</td>
      <td>3.212600</td>
      <td>3.192009</td>
      </tr>
      </tbody>
      </table><p></p></div>
      </div>
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-subarea-output-stream-output-stderr-output-text">
      <pre>There were missing keys in the checkpoint model loaded: ['lm_head.weight'].
      </pre>
      </div>
      </div>
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-text-output-subarea">
      <pre>TrainOutput(global_step=22341, training_loss=3.505178199598342, metrics={opening_brace}'train_runtime': 9209.5353, 'train_samples_per_second': 67.916, 'train_steps_per_second': 2.426, 'total_flos': 2.45146666696704e+17, 'train_loss': 3.505178199598342, 'epoch': 3.0{closing_brace})</pre>
      </div>
      </div>
      </div>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Avalia%C3%A7%C3%A3o">Avalia√ß√£o<a class="anchor-link" href="#Avalia%C3%A7%C3%A3o"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 96" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Depois de treinado, avaliamos o modelo no conjunto de dados de teste.</p>
      </section>
      
      <section class="section-block-code-cell-">
      <div class="input-code">
      <div class="highlight hl-ipython3">
<pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">)</span>
      </pre></div>
      </div>
      <div class="output-wrapper">
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-html-rendered-html-output-subarea">
      <div>
      <progress max="362" style="width:300px; height:20px; vertical-align: middle;" value="362"></progress>
            [362/362 01:04]
          </div>
      </div>
      </div>
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-text-output-subarea">
      <pre>{opening_brace}'eval_loss': 3.201305866241455,
       'eval_runtime': 65.0033,
       'eval_samples_per_second': 178.191,
       'eval_steps_per_second': 5.569,
       'epoch': 3.0}</pre>
      </div>
      </div>
      </div>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Publicar-o-modelo">Publicar o modelo<a class="anchor-link" href="#Publicar-o-modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 97" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Criamos o cart√£o modelo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">DataCollatorForLanguageModeling</span>',
      '      ',
      '      <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
      '          <span class="n">model</span><span class="p">,</span>',
      '          <span class="n">training_args</span><span class="p">,</span>',
      '          <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>',
      '          <span class="n">eval_dataset</span><span class="o">=</span><span class="n">validation_dataset</span><span class="p">,</span>',
      '          <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
      '          <span class="n">data_collator</span><span class="o">=</span><span class="n">DataCollatorForLanguageModeling</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">mlm</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">)</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">create_model_card</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>






      
      <section class="section-block-markdown-cell">
      <p>N√≥s o publicamos</p>
      </section>
      
      <section class="section-block-code-cell-">
      <div class="input-code">
      <div class="highlight hl-ipython3">
<pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">push_to_hub</span><span class="p">()</span>
      </pre></div>
      </div>
      <div class="output-wrapper">
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-text-output-subarea">
      <pre>events.out.tfevents.1720875425.8de3af1b431d.6946.1:   0%|          | 0.00/364 [00:00&lt;?, ?B/s]</pre>
      </div>
      </div>
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-text-output-subarea">
      <pre>CommitInfo(commit_url='https://huggingface.co/Maximofn/GPT2-small-finetuned-Maximofn-short-jokes-dataset-casualLM/commit/d107b3bb0e02076483238f9975697761015ec390', commit_message='End of training', commit_description='', oid='d107b3bb0e02076483238f9975697761015ec390', pr_url=None, pr_revision=None, pr_num=None)</pre>
      </div>
      </div>
      </div>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Uso-do-modelo">Uso do modelo<a class="anchor-link" href="#Uso-do-modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 98" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Limpamos o m√°ximo poss√≠vel</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">DataCollatorForLanguageModeling</span>',
      '      ',
      '      <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
      '          <span class="n">model</span><span class="p">,</span>',
      '          <span class="n">training_args</span><span class="p">,</span>',
      '          <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>',
      '          <span class="n">eval_dataset</span><span class="o">=</span><span class="n">validation_dataset</span><span class="p">,</span>',
      '          <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
      '          <span class="n">data_collator</span><span class="o">=</span><span class="n">DataCollatorForLanguageModeling</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">mlm</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>',
      '      <span class="p">)</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">)</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">create_model_card</span><span class="p">()</span>',
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">push_to_hub</span><span class="p">()</span>',
      '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
      '      <span class="kn">import</span> <span class="nn">gc</span>',
      '      ',
      '      ',
      '      <span class="k">def</span> <span class="nf">clear_hardwares</span><span class="p">():</span>',
      '          <span class="n">torch</span><span class="o">.</span><span class="n">clear_autocast_cache</span><span class="p">()</span>',
      '          <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">ipc_collect</span><span class="p">()</span>',
      '          <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>',
      '          <span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>',
      '      ',
      '      ',
      '      <span class="n">clear_hardwares</span><span class="p">()</span>',
      '      <span class="n">clear_hardwares</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>


















      
      <section class="section-block-markdown-cell">
      <p>Baixamos o modelo e o tokenizador</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">DataCollatorForLanguageModeling</span>',
          '',
          '<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
          '    <span class="n">model</span><span class="p">,</span>',
          '    <span class="n">training_args</span><span class="p">,</span>',
          '    <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>',
          '    <span class="n">eval_dataset</span><span class="o">=</span><span class="n">validation_dataset</span><span class="p">,</span>',
          '    <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
          '    <span class="n">data_collator</span><span class="o">=</span><span class="n">DataCollatorForLanguageModeling</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">mlm</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>',
          '<span class="p">)</span>',
          '</span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '</span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">)</span>',
          '</span><span class="n">trainer</span><span class="o">.</span><span class="n">create_model_card</span><span class="p">()</span>',
          '</span><span class="n">trainer</span><span class="o">.</span><span class="n">push_to_hub</span><span class="p">()</span>',
          '</span><span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">import</span> <span class="nn">gc</span>',
          '',
          '',
          '<span class="k">def</span> <span class="nf">clear_hardwares</span><span class="p">():</span>',
          '    <span class="n">torch</span><span class="o">.</span><span class="n">clear_autocast_cache</span><span class="p">()</span>',
          '    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">ipc_collect</span><span class="p">()</span>',
          '    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>',
          '    <span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>',
          '',
          '',
          '<span class="n">clear_hardwares</span><span class="p">()</span>',
          '<span class="n">clear_hardwares</span><span class="p">()</span>',
          '</span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForCausalLM</span>',
          '',
          '<span class="n">user</span> <span class="o">=</span> <span class="s2">"maximofn"</span>',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">user</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">"</span>',
          '',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>',
          '<span class="n">tokenizer</span><span class="o">.</span><span class="n">padding_side</span> <span class="o">=</span> <span class="s2">"right"</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'events.out.tfevents.1720875425.8de3af1b431d.6946.1:   0%|          | 0.00/364 [00:00&lt;?, ?B/s]',
          'Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Verificamos se o tokenizador e o modelo t√™m os dois tokens extras que adicionamos.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">tokenizer_vocab</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">get_vocab</span><span class="p">()</span>',
          '<span class="n">model_vocab</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"tokenizer_vocab: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">tokenizer_vocab</span><span class="p">)</span><span class="si">}</span><span class="s2">. model_vocab: </span><span class="si">{</span><span class="n">model_vocab</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'tokenizer_vocab: 50259. model_vocab: 50259',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos que eles t√™m 50259 tokens, ou seja, os 50257 tokens do GPT2 mais os 2 que adicionamos.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Criamos uma fun√ß√£o para gerar piadas</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">def</span> <span class="nf">generate_joke</span><span class="p">(</span><span class="n">prompt_text</span><span class="p">):</span>',
      '          <span class="n">text</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"&lt;SJ&gt; </span><span class="si">{</span><span class="n">prompt_text</span><span class="si">}</span><span class="s2">"</span>',
      '          <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>',
      '          <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
      '              <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="o">**</span><span class="n">tokens</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">eos_token_id</span><span class="o">=</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">"&lt;EJ&gt;"</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>',
      '          <span class="k">return</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>











      
      <section class="section-block-markdown-cell">
      <p>Geramos uma piada</p>
      </section>
      
      <section class="section-block-code-cell-">
      <div class="input-code">
      <div class="highlight hl-ipython3">
<pre><span></span><span class="n">generate_joke</span><span class="p">(</span><span class="s2">"Why didn't the frog cross the road?"</span><span class="p">)</span>
      </pre></div>
      </div>
      <div class="output-wrapper">
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-subarea-output-stream-output-stderr-output-text">
      <pre>Setting `pad_token_id` to `eos_token_id`:50258 for open-end generation.
      </pre>
      </div>
      </div>
      <div class="output-area">
      <div class="prompt-output-prompt">Out[15]:</div>
      <div class="output-text-output-subareaoutput_execute_result">
      <pre>"&lt;SJ&gt; Why didn't the frog cross the road? Because he was frog-in-the-face. &lt;EJ&gt;"</pre>
      </div>
      </div>
      </div>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Se voc√™ quiser testar o modelo com mais detalhes, poder√° v√™-lo em <a href="https://huggingface.co/Maximofn/GPT2-small-finetuned-Maximofn-short-jokes-dataset-casualLM" target="_blank" rel="nofollow noreferrer">Maximofn/GPT2-small-finetuned-Maximofn-short-jokes-dataset-casualLM</a></p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Ajuste-fino-para-classifica%C3%A7%C3%A3o-de-texto-com-o-Pytorch">Ajuste fino para classifica√ß√£o de texto com o Pytorch<a class="anchor-link" href="#Ajuste-fino-para-classifica%C3%A7%C3%A3o-de-texto-com-o-Pytorch"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 99" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Repetimos o treinamento com o Pytorch</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Reinicie o notebook para ter certeza de que</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Conjunto-de-dados">Conjunto de dados<a class="anchor-link" href="#Conjunto-de-dados"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 100" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Fizemos o download do mesmo conjunto de dados que usamos no treinamento com as bibliotecas Hugging Face.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">def</span> <span class="nf">generate_joke</span><span class="p">(</span><span class="n">prompt_text</span><span class="p">):</span>',
      '          <span class="n">text</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"&lt;SJ&gt; </span><span class="si">{</span><span class="n">prompt_text</span><span class="si">}</span><span class="s2">"</span>',
      '          <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>',
      '          <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
      '              <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="o">**</span><span class="n">tokens</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">eos_token_id</span><span class="o">=</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">"&lt;EJ&gt;"</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>',
      '          <span class="k">return</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>',
      '<span></span><span class="n">generate_joke</span><span class="p">(</span><span class="s2">"Why didn\'t the frog cross the road?"</span><span class="p">)</span>',
      '<span></span><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
      '      ',
      '      <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"mteb/amazon_reviews_multi"</span><span class="p">,</span> <span class="s2">"en"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>








      
      <section class="section-block-markdown-cell">
      <p>Criamos uma vari√°vel com o n√∫mero de classes</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="k">def</span> <span class="nf">generate_joke</span><span class="p">(</span><span class="n">prompt_text</span><span class="p">):</span>',
          '    <span class="n">text</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"&lt;SJ&gt; </span><span class="si">{</span><span class="n">prompt_text</span><span class="si">}</span><span class="s2">"</span>',
          '    <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>',
          '    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="o">**</span><span class="n">tokens</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">eos_token_id</span><span class="o">=</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">"&lt;EJ&gt;"</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>',
          '</span><span class="n">generate_joke</span><span class="p">(</span><span class="s2">"Why didn\'t the frog cross the road?"</span><span class="p">)</span>',
          '</span><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"mteb/amazon_reviews_multi"</span><span class="p">,</span> <span class="s2">"en"</span><span class="p">)</span>',
          '</span><span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="s1">\'label\'</span><span class="p">))</span>',
          '<span class="n">num_classes</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Setting `pad_token_id` to `eos_token_id`:50258 for open-end generation.',
          '5',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Antes, process√°vamos todo o conjunto de dados para criar um campo chamado <code>labels</code>, mas agora isso n√£o √© necess√°rio porque vamos programar tudo n√≥s mesmos, portanto, nos adaptamos √† apar√™ncia do conjunto de dados.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Tokeniser">Tokeniser<a class="anchor-link" href="#Tokeniser"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 101" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Criamos o tokenizador. Atribu√≠mos o token de preenchimento para n√£o recebermos um erro como antes.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>',
      '      ',
      '      <span class="n">checkpoint</span> <span class="o">=</span> <span class="s2">"openai-community/gpt2"</span>',
      '      <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>',
      '      <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>










      
      <section class="section-block-markdown-cell">
      <p>Criamos uma fun√ß√£o para tokenizar o conjunto de dados</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>',
      '      ',
      '      <span class="n">checkpoint</span> <span class="o">=</span> <span class="s2">"openai-community/gpt2"</span>',
      '      <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>',
      '      <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>',
      '<span></span><span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>',
      '          <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>







      
      <section class="section-block-markdown-cell">
      <p>N√≥s a tokenizamos. Removemos as colunas que n√£o s√£o necess√°rias, mas agora deixamos a coluna de texto.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>',
      '      ',
      '      <span class="n">checkpoint</span> <span class="o">=</span> <span class="s2">"openai-community/gpt2"</span>',
      '      <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>',
      '      <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>',
      '<span></span><span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>',
      '          <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
      '<span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'id\'</span><span class="p">,</span> <span class="s1">\'label_text\'</span><span class="p">])</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>






      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>',
          '',
          '<span class="n">checkpoint</span> <span class="o">=</span> <span class="s2">"openai-community/gpt2"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>',
          '<span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>',
          '</span><span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'id\'</span><span class="p">,</span> <span class="s1">\'label_text\'</span><span class="p">])</span>',
          '</span><span class="n">dataset</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'DatasetDict({',
          '    train: Dataset({',
          '        features: [\'text\', \'label\', \'input_ids\', \'attention_mask\'],',
          '        num_rows: 200000',
          '    })',
          '    validation: Dataset({',
          '        features: [\'text\', \'label\', \'input_ids\', \'attention_mask\'],',
          '        num_rows: 5000',
          '    })',
          '    test: Dataset({',
          '        features: [\'text\', \'label\', \'input_ids\', \'attention_mask\'],',
          '        num_rows: 5000',
          '    })',
          '})',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">percentage</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="n">subset_train</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'train\'</span><span class="p">])</span> <span class="o">*</span> <span class="n">percentage</span><span class="p">)))</span>',
          '<span class="n">percentage</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="n">subset_validation</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s1">\'validation\'</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'validation\'</span><span class="p">])</span> <span class="o">*</span> <span class="n">percentage</span><span class="p">)))</span>',
          '<span class="n">subset_test</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s1">\'test\'</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">\'test\'</span><span class="p">])</span> <span class="o">*</span> <span class="n">percentage</span><span class="p">)))</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"len subset_train: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">subset_train</span><span class="p">)</span><span class="si">}</span><span class="s2">, len subset_validation: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">subset_validation</span><span class="p">)</span><span class="si">}</span><span class="s2">, len subset_test: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">subset_test</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'len subset_train: 200000, len subset_validation: 5000, len subset_test: 5000',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Modelo">Modelo<a class="anchor-link" href="#Modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 102" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Importamos os pesos e atribu√≠mos o token de preenchimento</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="n">num_classes</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: [\'score.weight\']',
          'You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Dispositivo">Dispositivo<a class="anchor-link" href="#Dispositivo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 103" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Criamos o dispositivo onde tudo ser√° executado</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
      '      ',
      '      <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">\'cuda\'</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">\'cpu\'</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>








      
      <section class="section-block-markdown-cell">
      <p>Passamos o modelo para o dispositivo e o passamos para o FP16 para que ele ocupe menos mem√≥ria.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
          '',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">\'cuda\'</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">\'cpu\'</span><span class="p">)</span>',
          '</span><span class="n">model</span><span class="o">.</span><span class="n">half</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '<span class="nb">print</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Conjunto-de-dados-Pytorch">Conjunto de dados Pytorch<a class="anchor-link" href="#Conjunto-de-dados-Pytorch"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 104" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Criar um conjunto de dados pytorch</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>',
      '      ',
      '      <span class="k">class</span> <span class="nc">ReviewsDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>',
      '          <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">huggingface_dataset</span><span class="p">):</span>',
      '              <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">huggingface_dataset</span>',
      '      ',
      '          <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>',
      '              <span class="n">label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">\'label\'</span><span class="p">]</span>',
      '              <span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">\'input_ids\'</span><span class="p">])</span>',
      '              <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">\'attention_mask\'</span><span class="p">])</span>',
      '              <span class="k">return</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">label</span>',
      '      ',
      '          <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>',
      '              <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>



















      
      <section class="section-block-markdown-cell">
      <p>Instanciar os conjuntos de dados</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>',
      '      ',
      '      <span class="k">class</span> <span class="nc">ReviewsDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>',
      '          <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">huggingface_dataset</span><span class="p">):</span>',
      '              <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">huggingface_dataset</span>',
      '      ',
      '          <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>',
      '              <span class="n">label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">\'label\'</span><span class="p">]</span>',
      '              <span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">\'input_ids\'</span><span class="p">])</span>',
      '              <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">\'attention_mask\'</span><span class="p">])</span>',
      '              <span class="k">return</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">label</span>',
      '      ',
      '          <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>',
      '              <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>',
      '<span></span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">ReviewsDataset</span><span class="p">(</span><span class="n">subset_train</span><span class="p">)</span>',
      '      <span class="n">validatation_dataset</span> <span class="o">=</span> <span class="n">ReviewsDataset</span><span class="p">(</span><span class="n">subset_validation</span><span class="p">)</span>',
      '      <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">ReviewsDataset</span><span class="p">(</span><span class="n">subset_test</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>








      
      <section class="section-block-markdown-cell">
      <p>Vamos dar uma olhada em um exemplo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>',
          '',
          '<span class="k">class</span> <span class="nc">ReviewsDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>',
          '    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">huggingface_dataset</span><span class="p">):</span>',
          '        <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">huggingface_dataset</span>',
          '',
          '    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>',
          '        <span class="n">label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">\'label\'</span><span class="p">]</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">\'input_ids\'</span><span class="p">])</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '        <span class="k">return</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">label</span>',
          '',
          '    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>',
          '        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>',
          '</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">ReviewsDataset</span><span class="p">(</span><span class="n">subset_train</span><span class="p">)</span>',
          '<span class="n">validatation_dataset</span> <span class="o">=</span> <span class="n">ReviewsDataset</span><span class="p">(</span><span class="n">subset_validation</span><span class="p">)</span>',
          '<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">ReviewsDataset</span><span class="p">(</span><span class="n">subset_test</span><span class="p">)</span>',
          '</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">at_mask</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>',
          '<span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">at_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">label</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '(torch.Size([768]), torch.Size([768]), 0)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Carregador-de-dados-Pytorch">Carregador de dados Pytorch<a class="anchor-link" href="#Carregador-de-dados-Pytorch"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 105" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Criamos agora um carregador de dados pytorch</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
      '      ',
      '      <span class="n">BS</span> <span class="o">=</span> <span class="mi">12</span>',
      '      ',
      '      <span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
      '      <span class="n">validation_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">validatation_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">)</span>',
      '      <span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>












      
      <section class="section-block-markdown-cell">
      <p>Vamos dar uma olhada em um exemplo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">12</span>',
          '',
          '<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '<span class="n">validation_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">validatation_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">)</span>',
          '<span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">)</span>',
          '</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">at_mask</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_loader</span><span class="p">))</span>',
          '<span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">at_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">labels</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '(torch.Size([12, 768]),',
          ' torch.Size([12, 768]),',
          ' tensor([2, 1, 2, 0, 3, 3, 0, 4, 3, 3, 4, 2]))',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Para verificar se est√° tudo certo, passamos a amostra para o modelo para ver se est√° tudo certo. Primeiro, passamos os tokens para o dispositivo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '      <span class="n">at_mask</span> <span class="o">=</span> <span class="n">at_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '      <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>








      
      <section class="section-block-markdown-cell">
      <p>Agora, n√≥s os passamos para o modelo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '<span class="n">at_mask</span> <span class="o">=</span> <span class="n">at_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '<span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '</span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">at_mask</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '<span class="n">output</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'odict_keys([\'loss\', \'logits\', \'past_key_values\'])',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Como podemos ver, ele nos fornece a perda e os logits.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">output</span><span class="p">[</span><span class="s1">\'loss\'</span><span class="p">]</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'tensor(5.9414, device=\'cuda:0\', dtype=torch.float16,',
          '       grad_fn=&lt;NllLossBackward0&gt;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">output</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">]</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'tensor([[ 6.1953e+00, -1.2275e+00, -2.4824e+00,  5.8867e+00, -1.4734e+01],',
          '        [ 5.4062e+00, -8.4570e-01, -2.3203e+00,  5.1055e+00, -1.1555e+01],',
          '        [ 6.1641e+00, -9.3066e-01, -2.5664e+00,  6.0039e+00, -1.4570e+01],',
          '        [ 5.2266e+00, -4.2358e-01, -2.0801e+00,  4.7461e+00, -1.1570e+01],',
          '        [ 3.8184e+00, -2.3460e-03, -1.7666e+00,  3.4160e+00, -7.7969e+00],',
          '        [ 4.1641e+00, -4.8169e-01, -1.6914e+00,  3.9941e+00, -8.7734e+00],',
          '        [ 4.6758e+00, -3.0298e-01, -2.1641e+00,  4.1055e+00, -9.3359e+00],',
          '        [ 4.1953e+00, -3.2471e-01, -2.1875e+00,  3.9375e+00, -8.3438e+00],',
          '        [-1.1650e+00,  1.3564e+00, -6.2158e-01, -6.8115e-01,  4.8672e+00],',
          '        [ 4.4961e+00, -8.7891e-02, -2.2793e+00,  4.2812e+00, -9.3359e+00],',
          '        [ 4.9336e+00, -2.6627e-03, -2.1543e+00,  4.3711e+00, -1.0742e+01],',
          '        [ 5.9727e+00, -4.3152e-02, -1.4551e+00,  4.3438e+00, -1.2117e+01]],',
          '       device=\'cuda:0\', dtype=torch.float16, grad_fn=&lt;IndexBackward0&gt;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="M%C3%A9trica">M√©trica<a class="anchor-link" href="#M%C3%A9trica"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 106" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos criar uma fun√ß√£o para obter a m√©trica, que, neste caso, ser√° a precis√£o</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">def</span> <span class="nf">predicted_labels</span><span class="p">(</span><span class="n">logits</span><span class="p">):</span>',
      '          <span class="n">percent</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
      '          <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">percent</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
      '          <span class="k">return</span> <span class="n">predictions</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>









      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">def</span> <span class="nf">predicted_labels</span><span class="p">(</span><span class="n">logits</span><span class="p">):</span>',
      '          <span class="n">percent</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
      '          <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">percent</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
      '          <span class="k">return</span> <span class="n">predictions</span>',
      '<span></span><span class="k">def</span> <span class="nf">compute_accuracy</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>',
      '          <span class="n">predictions</span> <span class="o">=</span> <span class="n">predicted_labels</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>',
      '          <span class="n">correct</span> <span class="o">=</span> <span class="p">(</span><span class="n">predictions</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>',
      '          <span class="k">return</span> <span class="n">correct</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>









      
      <section class="section-block-markdown-cell">
      <p>Vamos ver como ele calcula bem</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="k">def</span> <span class="nf">predicted_labels</span><span class="p">(</span><span class="n">logits</span><span class="p">):</span>',
          '    <span class="n">percent</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
          '    <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">percent</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
          '    <span class="k">return</span> <span class="n">predictions</span>',
          '</span><span class="k">def</span> <span class="nf">compute_accuracy</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>',
          '    <span class="n">predictions</span> <span class="o">=</span> <span class="n">predicted_labels</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>',
          '    <span class="n">correct</span> <span class="o">=</span> <span class="p">(</span><span class="n">predictions</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>',
          '    <span class="k">return</span> <span class="n">correct</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>',
          '</span><span class="n">compute_accuracy</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '0.1666666716337204',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Otimizador">Otimizador<a class="anchor-link" href="#Otimizador"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 107" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Como precisaremos de um otimizador, criamos um.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AdamW</span>',
          '',
          '<span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">LR</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning',
          '  warnings.warn(',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Treinamento">Treinamento<a class="anchor-link" href="#Treinamento"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 108" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Criamos o loop de treinamento</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>',
          '',
          '<span class="n">accuracy</span> <span class="o">=</span> <span class="mi">0</span>',
          '',
          '<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">train_loss</span> <span class="o">=</span> <span class="mi">0</span>',
          '    <span class="n">progresbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s1">\'Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s1">\'</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">at_mask</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">progresbar</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '        <span class="n">at_mask</span> <span class="o">=</span> <span class="n">at_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '        <span class="n">label</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '',
          '        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">at_mask</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>',
          '',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="s1">\'loss\'</span><span class="p">]</span>',
          '        <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '        <span class="n">progresbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">({</span><span class="s1">\'train_loss\'</span><span class="p">:</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()})</span>',
          '    <span class="n">train_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>',
          '    <span class="n">progresbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">({</span><span class="s1">\'train_loss\'</span><span class="p">:</span> <span class="n">train_loss</span><span class="p">})</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">valid_loss</span> <span class="o">=</span> <span class="mi">0</span>',
          '    <span class="n">progresbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">validation_loader</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">validation_loader</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s1">\'Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s1">\'</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">at_mask</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">progresbar</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '        <span class="n">at_mask</span> <span class="o">=</span> <span class="n">at_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '',
          '        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">at_mask</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="s1">\'loss\'</span><span class="p">]</span>',
          '        <span class="n">valid_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>',
          '',
          '        <span class="n">step_accuracy</span> <span class="o">=</span> <span class="n">compute_accuracy</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '        <span class="n">accuracy</span> <span class="o">+=</span> <span class="n">step_accuracy</span>',
          '        <span class="n">progresbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">({</span><span class="s1">\'valid_loss\'</span><span class="p">:</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="s1">\'accuracy\'</span><span class="p">:</span> <span class="n">step_accuracy</span><span class="o">.</span><span class="n">item</span><span class="p">()})</span>',
          '',
          '    <span class="n">valid_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">validation_loader</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">validation_loader</span><span class="p">)</span>',
          '    <span class="n">progresbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">({</span><span class="s1">\'valid_loss\'</span><span class="p">:</span> <span class="n">valid_loss</span><span class="p">,</span> <span class="s1">\'accuracy\'</span><span class="p">:</span> <span class="n">accuracy</span><span class="p">})</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16667/16667 [44:13&lt;00:00,  6.28it/s, train_loss=nan]',
          'Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 417/417 [00:32&lt;00:00, 12.72it/s, valid_loss=nan, accuracy=0]',
          'Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16667/16667 [44:06&lt;00:00,  6.30it/s, train_loss=nan]',
          'Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 417/417 [00:32&lt;00:00, 12.77it/s, valid_loss=nan, accuracy=0]',
          'Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16667/16667 [44:03&lt;00:00,  6.30it/s, train_loss=nan]',
          'Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 417/417 [00:32&lt;00:00, 12.86it/s, valid_loss=nan, accuracy=0]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Uso-do-modelo">Uso do modelo<a class="anchor-link" href="#Uso-do-modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 109" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos testar o modelo que treinamos</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Primeiro, tokenizamos um texto</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">input_tokens</span> <span class="o">=</span> <span class="n">tokenize_function</span><span class="p">({</span><span class="s2">"text"</span><span class="p">:</span> <span class="s2">"I love this product. It is amazing."</span><span class="p">})</span>',
          '<span class="n">input_tokens</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">input_tokens</span><span class="p">[</span><span class="s1">\'attention_mask\'</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '(torch.Size([1, 768]), torch.Size([1, 768]))',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Agora, passamos isso para o modelo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_tokens</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">input_tokens</span><span class="p">[</span><span class="s1">\'attention_mask\'</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>',
          '<span class="n">output</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">]</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'tensor([[nan, nan, nan, nan, nan]], device=\'cuda:0\', dtype=torch.float16,',
          '       grad_fn=&lt;IndexBackward0&gt;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos as previs√µes desses logits</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">predicted</span> <span class="o">=</span> <span class="n">predicted_labels</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">])</span>',
          '<span class="n">predicted</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'tensor([0], device=\'cuda:0\')',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h2 id="Ajuste-fino-para-gera%C3%A7%C3%A3o-de-texto-com-o-Pytorch">Ajuste fino para gera√ß√£o de texto com o Pytorch<a class="anchor-link" href="#Ajuste-fino-para-gera%C3%A7%C3%A3o-de-texto-com-o-Pytorch"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 110" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Repetimos o treinamento com o Pytorch</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Reinicie o notebook para ter certeza de que</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Conjunto-de-dados">Conjunto de dados<a class="anchor-link" href="#Conjunto-de-dados"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 111" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Baixamos novamente o conjunto de dados de piadas</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '',
          '<span class="n">jokes</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"Maximofn/short-jokes-dataset"</span><span class="p">)</span>',
          '<span class="n">jokes</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'DatasetDict({',
          '    train: Dataset({',
          '        features: [\'ID\', \'Joke\'],',
          '        num_rows: 231657',
          '    })',
          '})',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Crie um subconjunto caso voc√™ esteja com pouca mem√≥ria</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">percent_of_train_dataset</span> <span class="o">=</span> <span class="mi">1</span>    <span class="c1"># If you want 50% of the dataset, set this to 0.5</span>',
          '',
          '<span class="n">subset_dataset</span> <span class="o">=</span> <span class="n">jokes</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">jokes</span><span class="p">[</span><span class="s2">"train"</span><span class="p">])</span> <span class="o">*</span> <span class="n">percent_of_train_dataset</span><span class="p">)))</span>',
          '<span class="n">subset_dataset</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Dataset({',
          '    features: [\'ID\', \'Joke\'],',
          '    num_rows: 231657',
          '})',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Dividimos o conjunto de dados em subconjuntos de treinamento, valida√ß√£o e teste.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">percent_of_train_dataset</span> <span class="o">=</span> <span class="mf">0.90</span>',
          '',
          '<span class="n">split_dataset</span> <span class="o">=</span> <span class="n">subset_dataset</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">train_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">subset_dataset</span><span class="o">.</span><span class="n">num_rows</span> <span class="o">*</span> <span class="n">percent_of_train_dataset</span><span class="p">),</span> <span class="n">seed</span><span class="o">=</span><span class="mi">19</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>',
          '<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span>',
          '<span class="n">validation_test_dataset</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span>',
          '',
          '<span class="n">split_dataset</span> <span class="o">=</span> <span class="n">validation_test_dataset</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">train_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">validation_test_dataset</span><span class="o">.</span><span class="n">num_rows</span> <span class="o">*</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">seed</span><span class="o">=</span><span class="mi">19</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>',
          '<span class="n">validation_dataset</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span>',
          '<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span>',
          '',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Size of the train set: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">. Size of the validation set: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">validation_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">. Size of the test set: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Size of the train set: 208491. Size of the validation set: 11583. Size of the test set: 11583',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Tokeniser">Tokeniser<a class="anchor-link" href="#Tokeniser"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 112" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Iniciamos o tokenizador e atribu√≠mos o token do final da string ao token de preenchimento.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>',
      '      ',
      '      <span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"openai-community/gpt2"</span>',
      '      ',
      '      <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '      <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>',
      '      <span class="n">tokenizer</span><span class="o">.</span><span class="n">padding_side</span> <span class="o">=</span> <span class="s2">"right"</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>












      
      <section class="section-block-markdown-cell">
      <p>Adicionamos os tokens especiais para o in√≠cio e o fim de uma piada.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"openai-community/gpt2"</span>',
          '',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>',
          '<span class="n">tokenizer</span><span class="o">.</span><span class="n">padding_side</span> <span class="o">=</span> <span class="s2">"right"</span>',
          '</span><span class="n">new_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="s1">\'&lt;SJ&gt;\'</span><span class="p">,</span> <span class="s1">\'&lt;EJ&gt;\'</span><span class="p">]</span>   <span class="c1"># Start and end of joke tokens</span>',
          '',
          '<span class="n">num_added_tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">add_tokens</span><span class="p">(</span><span class="n">new_tokens</span><span class="p">)</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Added </span><span class="si">{</span><span class="n">num_added_tokens</span><span class="si">}</span><span class="s2"> tokens"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Added 2 tokens',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>N√≥s os adicionamos ao conjunto de dados</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">joke_column</span> <span class="o">=</span> <span class="s2">"Joke"</span>',
          '',
          '<span class="k">def</span> <span class="nf">format_joke</span><span class="p">(</span><span class="n">example</span><span class="p">):</span>',
          '    <span class="n">example</span><span class="p">[</span><span class="n">joke_column</span><span class="p">]</span> <span class="o">=</span> <span class="s1">\'&lt;SJ&gt; \'</span> <span class="o">+</span> <span class="n">example</span><span class="p">[</span><span class="s1">\'Joke\'</span><span class="p">]</span> <span class="o">+</span> <span class="s1">\' &lt;EJ&gt;\'</span>',
          '    <span class="k">return</span> <span class="n">example</span>',
          '',
          '<span class="n">remove_columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">column</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">column_names</span> <span class="k">if</span> <span class="n">column</span> <span class="o">!=</span> <span class="n">joke_column</span><span class="p">]</span>',
          '',
          '<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">format_joke</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="n">remove_columns</span><span class="p">)</span>',
          '<span class="n">validation_dataset</span> <span class="o">=</span> <span class="n">validation_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">format_joke</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="n">remove_columns</span><span class="p">)</span>',
          '<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">format_joke</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="n">remove_columns</span><span class="p">)</span>',
          '<span class="n">train_dataset</span><span class="p">,</span> <span class="n">validation_dataset</span><span class="p">,</span> <span class="n">test_dataset</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '(Dataset({',
          '     features: [\'Joke\'],',
          '     num_rows: 208491',
          ' }),',
          ' Dataset({',
          '     features: [\'Joke\'],',
          '     num_rows: 11583',
          ' }),',
          ' Dataset({',
          '     features: [\'Joke\'],',
          '     num_rows: 11583',
          ' }))',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Tokenizamos o conjunto de dados</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="n">joke_column</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '',
          '<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="n">joke_column</span><span class="p">])</span>',
          '<span class="n">validation_dataset</span> <span class="o">=</span> <span class="n">validation_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="n">joke_column</span><span class="p">])</span>',
          '<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="n">joke_column</span><span class="p">])</span>',
          '<span class="n">train_dataset</span><span class="p">,</span> <span class="n">validation_dataset</span><span class="p">,</span> <span class="n">test_dataset</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '(Dataset({',
          '     features: [\'input_ids\', \'attention_mask\'],',
          '     num_rows: 208491',
          ' }),',
          ' Dataset({',
          '     features: [\'input_ids\', \'attention_mask\'],',
          '     num_rows: 11583',
          ' }),',
          ' Dataset({',
          '     features: [\'input_ids\', \'attention_mask\'],',
          '     num_rows: 11583',
          ' }))',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Modelo">Modelo<a class="anchor-link" href="#Modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 113" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Instanciar o modelo, atribuir o token de preenchimento e adicionar os novos tokens de in√≠cio e fim de piada.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForCausalLM</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">resize_token_embeddings</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">))</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Embedding(50259, 768)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Dispositivo">Dispositivo<a class="anchor-link" href="#Dispositivo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 114" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Criamos o dispositivo e passamos o modelo para o dispositivo.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
          '',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">\'cuda\'</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">\'cpu\'</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">half</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '<span class="nb">print</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Conjunto-de-dados-Pytorch">Conjunto de dados Pytorch<a class="anchor-link" href="#Conjunto-de-dados-Pytorch"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 115" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Criar um conjunto de dados pytorch</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>',
      '      ',
      '      <span class="k">class</span> <span class="nc">JokesDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>',
      '          <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">huggingface_dataset</span><span class="p">):</span>',
      '              <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">huggingface_dataset</span>',
      '      ',
      '          <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>',
      '              <span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">\'input_ids\'</span><span class="p">])</span>',
      '              <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">\'attention_mask\'</span><span class="p">])</span>',
      '              <span class="k">return</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span>',
      '      ',
      '          <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>',
      '              <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>


















      
      <section class="section-block-markdown-cell">
      <p>Instanciamos os conjuntos de dados de treinamento, valida√ß√£o e teste.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>',
      '      ',
      '      <span class="k">class</span> <span class="nc">JokesDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>',
      '          <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">huggingface_dataset</span><span class="p">):</span>',
      '              <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">huggingface_dataset</span>',
      '      ',
      '          <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>',
      '              <span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">\'input_ids\'</span><span class="p">])</span>',
      '              <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">\'attention_mask\'</span><span class="p">])</span>',
      '              <span class="k">return</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span>',
      '      ',
      '          <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>',
      '              <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>',
      '<span></span><span class="n">train_pytorch_dataset</span> <span class="o">=</span> <span class="n">JokesDataset</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span>',
      '      <span class="n">validation_pytorch_dataset</span> <span class="o">=</span> <span class="n">JokesDataset</span><span class="p">(</span><span class="n">validation_dataset</span><span class="p">)</span>',
      '      <span class="n">test_pytorch_dataset</span> <span class="o">=</span> <span class="n">JokesDataset</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>








      
      <section class="section-block-markdown-cell">
      <p>Aqui est√° um exemplo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>',
          '',
          '<span class="k">class</span> <span class="nc">JokesDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>',
          '    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">huggingface_dataset</span><span class="p">):</span>',
          '        <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">huggingface_dataset</span>',
          '',
          '    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">\'input_ids\'</span><span class="p">])</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '        <span class="k">return</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span>',
          '',
          '    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>',
          '        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>',
          '</span><span class="n">train_pytorch_dataset</span> <span class="o">=</span> <span class="n">JokesDataset</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span>',
          '<span class="n">validation_pytorch_dataset</span> <span class="o">=</span> <span class="n">JokesDataset</span><span class="p">(</span><span class="n">validation_dataset</span><span class="p">)</span>',
          '<span class="n">test_pytorch_dataset</span> <span class="o">=</span> <span class="n">JokesDataset</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span>',
          '</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">train_pytorch_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>',
          '<span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">shape</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '(torch.Size([768]), torch.Size([768]))',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Carregador-de-dados-Pytorch">Carregador de dados Pytorch<a class="anchor-link" href="#Carregador-de-dados-Pytorch"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 116" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Criamos os carregadores de dados</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
      '      ',
      '      <span class="n">BS</span> <span class="o">=</span> <span class="mi">28</span>',
      '      ',
      '      <span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_pytorch_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
      '      <span class="n">validation_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">validation_pytorch_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">)</span>',
      '      <span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_pytorch_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>












      
      <section class="section-block-markdown-cell">
      <p>Vemos uma amostra</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">28</span>',
          '',
          '<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_pytorch_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '<span class="n">validation_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">validation_pytorch_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">)</span>',
          '<span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_pytorch_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">)</span>',
          '</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_loader</span><span class="p">))</span>',
          '<span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">shape</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '(torch.Size([28, 768]), torch.Size([28, 768]))',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Passamos isso para o modelo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>',
          '<span class="n">output</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'odict_keys([\'logits\', \'past_key_values\'])',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Como podemos ver, n√£o temos nenhum valor de <code>perda</code>, pois, como vimos, temos que passar os <code>input_ids</code> e os <code>labels</code>.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">=</span><span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>',
          '<span class="n">output</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'odict_keys([\'loss\', \'logits\', \'past_key_values\'])',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Agora temos a "perda".</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">output</span><span class="p">[</span><span class="s1">\'loss\'</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '80.5625',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Otimizador">Otimizador<a class="anchor-link" href="#Otimizador"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 117" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Criamos um otimizador</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AdamW</span>',
          '',
          '<span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-5</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning',
          '  warnings.warn(',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Treinamento">Treinamento<a class="anchor-link" href="#Treinamento"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 118" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Criamos o loop de treinamento</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>',
          '',
          '<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">train_loss</span> <span class="o">=</span> <span class="mi">0</span>',
          '    <span class="n">progresbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s1">\'Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s1">\'</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">at_mask</span> <span class="ow">in</span> <span class="n">progresbar</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '        <span class="n">at_mask</span> <span class="o">=</span> <span class="n">at_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '',
          '        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">at_mask</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">input_ids</span><span class="p">)</span>',
          '',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="s1">\'loss\'</span><span class="p">]</span>',
          '        <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '        <span class="n">progresbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">({</span><span class="s1">\'train_loss\'</span><span class="p">:</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()})</span>',
          '    <span class="n">train_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>',
          '    <span class="n">progresbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">({</span><span class="s1">\'train_loss\'</span><span class="p">:</span> <span class="n">train_loss</span><span class="p">})</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7447/7447 [51:07&lt;00:00,  2.43it/s, train_loss=nan]',
          'Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7447/7447 [51:06&lt;00:00,  2.43it/s, train_loss=nan]',
          'Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7447/7447 [51:07&lt;00:00,  2.43it/s, train_loss=nan]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Uso-do-modelo">Uso do modelo<a class="anchor-link" href="#Uso-do-modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 119" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Testamos o modelo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">def</span> <span class="nf">generate_text</span><span class="p">(</span><span class="n">decoded_joke</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">stop_token</span><span class="o">=</span><span class="s1">\'&lt;EJ&gt;\'</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>',
      '          <span class="n">input_tokens</span> <span class="o">=</span> <span class="n">tokenize_function</span><span class="p">({</span><span class="s1">\'Joke\'</span><span class="p">:</span> <span class="n">decoded_joke</span><span class="p">})</span>',
      '          <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_tokens</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">input_tokens</span><span class="p">[</span><span class="s1">\'attention_mask\'</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>',
      '          <span class="n">nex_token</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">][:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>',
      '          <span class="n">nex_token_decoded</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">nex_token</span><span class="p">)</span>',
      '          <span class="n">decoded_joke</span> <span class="o">=</span> <span class="n">decoded_joke</span> <span class="o">+</span> <span class="n">nex_token_decoded</span>',
      '          <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_new_tokens</span><span class="p">):</span>',
      '              <span class="n">nex_token</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">][:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>',
      '              <span class="n">nex_token_decoded</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">nex_token</span><span class="p">)</span>',
      '              <span class="k">if</span> <span class="n">nex_token_decoded</span> <span class="o">==</span> <span class="n">stop_token</span><span class="p">:</span>',
      '                  <span class="k">break</span>',
      '              <span class="n">decoded_joke</span> <span class="o">=</span> <span class="n">decoded_joke</span> <span class="o">+</span> <span class="n">nex_token_decoded</span>',
      '              <span class="n">input_tokens</span> <span class="o">=</span> <span class="n">tokenize_function</span><span class="p">({</span><span class="s1">\'Joke\'</span><span class="p">:</span> <span class="n">decoded_joke</span><span class="p">})</span>',
      '              <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_tokens</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">input_tokens</span><span class="p">[</span><span class="s1">\'attention_mask\'</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>',
      '          <span class="k">return</span> <span class="n">decoded_joke</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>




















      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="k">def</span> <span class="nf">generate_text</span><span class="p">(</span><span class="n">decoded_joke</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">stop_token</span><span class="o">=</span><span class="s1">\'&lt;EJ&gt;\'</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>',
          '    <span class="n">input_tokens</span> <span class="o">=</span> <span class="n">tokenize_function</span><span class="p">({</span><span class="s1">\'Joke\'</span><span class="p">:</span> <span class="n">decoded_joke</span><span class="p">})</span>',
          '    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_tokens</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">input_tokens</span><span class="p">[</span><span class="s1">\'attention_mask\'</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>',
          '    <span class="n">nex_token</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">][:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>',
          '    <span class="n">nex_token_decoded</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">nex_token</span><span class="p">)</span>',
          '    <span class="n">decoded_joke</span> <span class="o">=</span> <span class="n">decoded_joke</span> <span class="o">+</span> <span class="n">nex_token_decoded</span>',
          '    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_new_tokens</span><span class="p">):</span>',
          '        <span class="n">nex_token</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">][:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>',
          '        <span class="n">nex_token_decoded</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">nex_token</span><span class="p">)</span>',
          '        <span class="k">if</span> <span class="n">nex_token_decoded</span> <span class="o">==</span> <span class="n">stop_token</span><span class="p">:</span>',
          '            <span class="k">break</span>',
          '        <span class="n">decoded_joke</span> <span class="o">=</span> <span class="n">decoded_joke</span> <span class="o">+</span> <span class="n">nex_token_decoded</span>',
          '        <span class="n">input_tokens</span> <span class="o">=</span> <span class="n">tokenize_function</span><span class="p">({</span><span class="s1">\'Joke\'</span><span class="p">:</span> <span class="n">decoded_joke</span><span class="p">})</span>',
          '        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_tokens</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">input_tokens</span><span class="p">[</span><span class="s1">\'attention_mask\'</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>',
          '    <span class="k">return</span> <span class="n">decoded_joke</span>',
          '</span><span class="n">generated_text</span> <span class="o">=</span> <span class="n">generate_text</span><span class="p">(</span><span class="s2">"&lt;SJ&gt; Why didn\'t the frog cross the road"</span><span class="p">)</span>',
          '<span class="n">generated_text</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '"&lt;SJ&gt; Why didn\'t the frog cross the road!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      






    </div>

  </section>

</PostLayout>
