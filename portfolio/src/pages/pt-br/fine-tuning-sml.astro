---
import PostLayout from '@layouts/PostLayout.astro';
import CodeBlockInputCell from '@components/CodeBlockInputCell.astro';
import CodeBlockOutputCell from '@components/CodeBlockOutputCell.astro';

const { metadata_page } = await import('@portfolio/consts.json');
const { colors } = await import('@portfolio/consts.json');
const { svg_paths } = await import('@portfolio/consts.json');

const page_title = 'Fine tuning SMLs';
const end_url = 'fine-tuning-sml';
const description = 'üòÇ Ajustando modelos de idiomas pequenos? Por favor, voc√™ n√£o est√° ajustando, est√° apenas tentando desesperadamente tirar algum sentido de um modelo que √© t√£o √∫til quanto um bule de chocolate üç´üöΩ. Mas quem n√£o gosta de um bom desafio? V√° em frente, gaste suas horas de GPU e talvez, apenas talvez, voc√™ consiga um modelo que consiga distinguir entre ol√° e adeus ü§ñ. Boa sorte e n√£o diga que eu n√£o o avisei üòú';
const keywords = 'slm, modelos de linguagem pequenos, ajuste fino, piadas, humor, gpt2, openai, transformers, huggingface';
const languaje = 'PT';
const image_path = 'https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/SLM_thumnail.webp';
const opening_brace = '{';
const closing_brace = '}';
---

<PostLayout 
    title={page_title}
    languaje={languaje}
    description={description}
    keywords={keywords}
    author={metadata_page.author}
    theme_color={colors.background_color}
    end_url={end_url}
    image_path={image_path}
    image_width=900
    image_height=450
    image_extension=webp
    article_date=2024-07-14+T00:00:00Z
>

  <section class="post-body">


    <aside class="post-index">
      <a class="anchor-link" href="#Ajuste fino para classificacao de texto com Hugging Face"><h2>Ajuste fino para classifica√ß√£o de texto com Hugging Face</h2></a>
      <a class="anchor-link" href="#Login"><h3>Login</h3></a>
      <a class="anchor-link" href="#Conjunto de Dados"><h3>Conjunto de Dados</h3></a>
      <a class="anchor-link" href="#Tokenizador"><h3>Tokenizador</h3></a>
      <a class="anchor-link" href="#Modelo"><h3>Modelo</h3></a>
      <a class="anchor-link" href="#Treinador"><h3>Treinador</h3></a>
      <a class="anchor-link" href="#Avaliacao"><h3>Avalia√ß√£o</h3></a>
      <a class="anchor-link" href="#Publicar o modelo"><h3>Publicar o modelo</h3></a>
      <a class="anchor-link" href="#Uso do modelo"><h3>Uso do modelo</h3></a>
      <a class="anchor-link" href="#Ajuste fino para geracao de texto com Hugging Face"><h2>Ajuste fino para gera√ß√£o de texto com Hugging Face</h2></a>
      <a class="anchor-link" href="#Login"><h3>Login</h3></a>
      <a class="anchor-link" href="#Conjunto de Dados"><h3>Conjunto de Dados</h3></a>
      <a class="anchor-link" href="#Tokenizador"><h3>Tokenizador</h3></a>
      <a class="anchor-link" href="#Modelo"><h3>Modelo</h3></a>
      <a class="anchor-link" href="#Treinamento"><h3>Treinamento</h3></a>
      <a class="anchor-link" href="#Avaliacao"><h3>Avalia√ß√£o</h3></a>
      <a class="anchor-link" href="#Publicar o modelo"><h3>Publicar o modelo</h3></a>
      <a class="anchor-link" href="#Uso do modelo"><h3>Uso do modelo</h3></a>
      <a class="anchor-link" href="#Ajuste fino para classificacao de texto com Pytorch"><h2>Ajuste fino para classifica√ß√£o de texto com Pytorch</h2></a>
      <a class="anchor-link" href="#Conjunto de Dados"><h3>Conjunto de Dados</h3></a>
      <a class="anchor-link" href="#Tokenizador"><h3>Tokenizador</h3></a>
      <a class="anchor-link" href="#Modelo"><h3>Modelo</h3></a>
      <a class="anchor-link" href="#Dispositivo"><h3>Dispositivo</h3></a>
      <a class="anchor-link" href="#Conjunto de Dados do Pytorch"><h3>Conjunto de Dados do Pytorch</h3></a>
      <a class="anchor-link" href="#Pytorch Dataloader"><h3>Pytorch Dataloader</h3></a>
      <a class="anchor-link" href="#Metrica"><h3>M√©trica</h3></a>
      <a class="anchor-link" href="#Otimizador"><h3>Otimizador</h3></a>
      <a class="anchor-link" href="#Treinamento"><h3>Treinamento</h3></a>
      <a class="anchor-link" href="#Uso do modelo"><h3>Uso do modelo</h3></a>
      <a class="anchor-link" href="#Ajuste fino para geracao de texto com Pytorch"><h2>Ajuste fino para gera√ß√£o de texto com Pytorch</h2></a>
      <a class="anchor-link" href="#Conjunto de Dados"><h3>Conjunto de Dados</h3></a>
      <a class="anchor-link" href="#Tokenizador"><h3>Tokenizador</h3></a>
      <a class="anchor-link" href="#Modelo"><h3>Modelo</h3></a>
      <a class="anchor-link" href="#Dispositivo"><h3>Dispositivo</h3></a>
      <a class="anchor-link" href="#Conjunto de Dados do Pytorch"><h3>Conjunto de Dados do Pytorch</h3></a>
      <a class="anchor-link" href="#Pytorch Dataloader"><h3>Pytorch Dataloader</h3></a>
      <a class="anchor-link" href="#Otimizador"><h3>Otimizador</h3></a>
      <a class="anchor-link" href="#Treinamento"><h3>Treinamento</h3></a>
      <a class="anchor-link" href="#Uso do modelo"><h3>Uso do modelo</h3></a>
    </aside>


    <div class="post-body-content">
      
      <section class="section-block-markdown-cell">
      </section>
      
      <section class="section-block-markdown-cell">
      <blockquote>
      <p>Aviso: Este post foi traduzido para o portugu√™s usando um modelo de tradu√ß√£o autom√°tica. Por favor, me avise se encontrar algum erro.</p>
      </blockquote>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Neste post, vamos ver como fazer fine tuning em pequenos modelos de linguagem, vamos ver como fazer fine tuning para classifica√ß√£o de texto e para gera√ß√£o de texto. Primeiro, vamos ver como fazer isso com as bibliotecas do Hugging Face, j√° que o Hugging Face se tornou um ator muito importante no ecossistema de IA neste momento.</p>
      <p>Mas embora as bibliotecas do Hugging Face sejam muito importantes e √∫teis, √© muito importante saber como o treinamento realmente acontece e o que est√° acontecendo por baixo dos panos, ent√£o vamos repetir o treinamento para classifica√ß√£o e gera√ß√£o de texto, mas com Pytorch.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Ajuste fino para classificacao de texto com Hugging Face">Ajuste fino para classifica√ß√£o de texto com Hugging Face<a class="anchor-link" href="#Ajuste fino para classificacao de texto com Hugging Face"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 81" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Login">Login<a class="anchor-link" href="#Login"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 82" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Para poder subir o resultado do treinamento ao hub devemos nos autenticar primeiro, para isso precisamos de um token</p>
      <p>Para criar um token, √© necess√°rio ir √† p√°gina de <a href="https://huggingface.co/settings/tokens" target="_blank" rel="nofollow noreferrer">settings/tokens</a> da nossa conta, onde aparecer√° algo assim</p>
      <img decoding="async" onerror="this.parentNode.removeChild(this)" src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/User-Access-Token-dark.webp" alt="User-Access-Token-dark">
      <p>Damos a <code>New token</code> e ser√° exibida uma janela para criar um novo token</p>
      <img decoding="async" onerror="this.parentNode.removeChild(this)" src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/new-token-dark.webp" alt="new-token-dark">
      <p>Damos um nome ao token e o criamos com o papel <code>write</code>, ou com o papel <code>Fine-grained</code>, que nos permite selecionar exatamente quais permiss√µes o token ter√°.</p>
      <p>Uma vez criado, copiamos e colamos a seguir.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">huggingface_hub</span><span class="w"> </span><span class="kn">import</span> <span class="n">notebook_login</span>',
      '<span class="n">notebook_login</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Conjunto de Dados">Conjunto de Dados<a class="anchor-link" href="#Conjunto de Dados"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 83" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Agora vamos baixar um dataset, neste caso vamos baixar um de avalia√ß√µes do <a href="https://huggingface.co/datasets/mteb/amazon_reviews_multi" target="_blank" rel="nofollow noreferrer">Amazon</a></p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>',
      '<span class="w"> </span>',
      '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;mteb/amazon_reviews_multi&quot;</span><span class="p">,</span> <span class="s2">&quot;en&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vamos v√™-lo um pouco</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">dataset</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'DatasetDict(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;train: Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;id&#x27;, &#x27;text&#x27;, &#x27;label&#x27;, &#x27;label_text&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 200000',
          '&#x20;&#x20;&#x20;&#x20;&#x7D;)',
          '&#x20;&#x20;&#x20;&#x20;validation: Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;id&#x27;, &#x27;text&#x27;, &#x27;label&#x27;, &#x27;label_text&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 5000',
          '&#x20;&#x20;&#x20;&#x20;&#x7D;)',
          '&#x20;&#x20;&#x20;&#x20;test: Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;id&#x27;, &#x27;text&#x27;, &#x27;label&#x27;, &#x27;label_text&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 5000',
          '&#x20;&#x20;&#x20;&#x20;&#x7D;)',
          '&#x7D;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos que tem um conjunto de treinamento com 200.000 amostras, um de valida√ß√£o com 5.000 amostras e um de teste com 5.000 amostras.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a ver um exemplo do conjunto de treinamento</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">random</span><span class="w"> </span><span class="kn">import</span> <span class="n">randint</span>',
      '<span class="w"> </span>',
      '<span class="n">idx</span> <span class="o">=</span> <span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>',
      '<span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '&#x7B;&#x27;id&#x27;: &#x27;en_0907914&#x27;,',
          '&#x27;text&#x27;: &#x27;Mixed with fir it‚Äôs passable\n\nNot the scent I had hoped for . Love the scent of cedar, but this one missed&#x27;,',
          '&#x27;label&#x27;: 3,',
          '&#x27;label_text&#x27;: &#x27;3&#x27;&#x7D;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos que tem a avalia√ß√£o no campo <code>text</code> e a pontua√ß√£o que o usu√°rio deu no campo <code>label</code></p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Como vamos a fazer um modelo de classifica√ß√£o de textos, precisamos saber quantas classes vamos ter.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="s1">&#39;label&#39;</span><span class="p">))</span>',
      '<span class="n">num_classes</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '5',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a ter 5 classes, agora vamos a ver o valor m√≠nimo dessas classes para saber se a pontua√ß√£o come√ßa em 0 ou em 1. Para isso, usamos o m√©todo <code>unique</code></p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">dataset</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="s1">&#39;label&#39;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '&#x7B;&#x27;train&#x27;: [0, 1, 2, 3, 4],',
          '&#x27;validation&#x27;: [0, 1, 2, 3, 4],',
          '&#x27;test&#x27;: [0, 1, 2, 3, 4]&#x7D;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>O valor m√≠nimo ser√° 0</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Para treinar, as etiquetas precisam estar em um campo chamado <code>labels</code>, enquanto no nosso conjunto de dados est√° em um campo chamado <code>label</code>, ent√£o criamos o novo campo <code>labels</code> com o mesmo valor que <code>label</code></p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Criamos uma fun√ß√£o que fa√ßa o que quisermos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">def</span><span class="w"> </span><span class="nf">set_labels</span><span class="p">(</span><span class="n">example</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">example</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">example</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">example</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Aplicamos a fun√ß√£o ao conjunto de dados</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">set_labels</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vamos ver como fica o dataset</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '&#x7B;&#x27;id&#x27;: &#x27;en_0907914&#x27;,',
          '&#x27;text&#x27;: &#x27;Mixed with fir it‚Äôs passable\n\nNot the scent I had hoped for . Love the scent of cedar, but this one missed&#x27;,',
          '&#x27;label&#x27;: 3,',
          '&#x27;label_text&#x27;: &#x27;3&#x27;,',
          '&#x27;labels&#x27;: 3&#x7D;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Tokenizador">Tokenizador<a class="anchor-link" href="#Tokenizador"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 84" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Como temos as avalia√ß√µes em texto no conjunto de dados, precisamos tokeniz√°-las para poder inserir os tokens no modelo.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>',
      '<span class="w"> </span>',
      '<span class="n">checkpoint</span> <span class="o">=</span> <span class="s2">&quot;openai-community/gpt2&quot;</span>',
      '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Agora criamos uma fun√ß√£o para tokenizar o texto. Vamos fazer isso de maneira que todas as frases tenham o mesmo comprimento, de modo que o tokenizador truncar√° quando necess√°rio e adicionar√° tokens de padding quando necess√°rio. Al√©m disso, indicamos que retorne tensores do pytorch.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Fazemos com que o comprimento de cada senten√ßa seja de 768 tokens porque estamos usando o modelo pequeno do GPT2, que como vimos no post de <a href="https://maximofn.com/gpt2/#Arquitectura">GPT2</a> tem uma dimens√£o de embedding de 768 tokens</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a provar a tokenizar um texto</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">][</span><span class="n">idx</span><span class="p">])</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '---------------------------------------------------------------------------ValueError                                Traceback (most recent call last)Cell In[11], line 1',
          '----&amp;gt; 1 tokens = tokenize_function(dataset[&#x27;train&#x27;][idx])',
          'Cell In[10], line 2, in tokenize_function(examples)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;1 def tokenize_function(examples):',
          '----&amp;gt; 2     return tokenizer(examples[&quot;text&quot;], padding=&quot;max_length&quot;, truncation=True, max_length=768, return_tensors=&quot;pt&quot;)',
          'File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2883, in PreTrainedTokenizerBase.__call__(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)',
          '&#x20;&#x20;&#x20;2881     if not self._in_target_context_manager:',
          '&#x20;&#x20;&#x20;2882         self._switch_to_input_mode()',
          '-&amp;gt; 2883     encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)',
          '&#x20;&#x20;&#x20;2884 if text_target is not None:',
          '&#x20;&#x20;&#x20;2885     self._switch_to_target_mode()',
          'File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2989, in PreTrainedTokenizerBase._call_one(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)',
          '&#x20;&#x20;&#x20;2969     return self.batch_encode_plus(',
          '&#x20;&#x20;&#x20;2970         batch_text_or_text_pairs=batch_text_or_text_pairs,',
          '&#x20;&#x20;&#x20;2971         add_special_tokens=add_special_tokens,',
          '&#x20;&#x20;&#x20;(...)',
          '&#x20;&#x20;&#x20;2986         **kwargs,',
          '&#x20;&#x20;&#x20;2987     )',
          '&#x20;&#x20;&#x20;2988 else:',
          '-&amp;gt; 2989     return self.encode_plus(',
          '&#x20;&#x20;&#x20;2990         text=text,',
          '&#x20;&#x20;&#x20;2991         text_pair=text_pair,',
          '&#x20;&#x20;&#x20;2992         add_special_tokens=add_special_tokens,',
          '&#x20;&#x20;&#x20;2993         padding=padding,',
          '&#x20;&#x20;&#x20;2994         truncation=truncation,',
          '&#x20;&#x20;&#x20;2995         max_length=max_length,',
          '&#x20;&#x20;&#x20;2996         stride=stride,',
          '&#x20;&#x20;&#x20;2997         is_split_into_words=is_split_into_words,',
          '&#x20;&#x20;&#x20;2998         pad_to_multiple_of=pad_to_multiple_of,',
          '&#x20;&#x20;&#x20;2999         return_tensors=return_tensors,',
          '&#x20;&#x20;&#x20;3000         return_token_type_ids=return_token_type_ids,',
          '&#x20;&#x20;&#x20;3001         return_attention_mask=return_attention_mask,',
          '&#x20;&#x20;&#x20;3002         return_overflowing_tokens=return_overflowing_tokens,',
          '&#x20;&#x20;&#x20;3003         return_special_tokens_mask=return_special_tokens_mask,',
          '&#x20;&#x20;&#x20;3004         return_offsets_mapping=return_offsets_mapping,',
          '&#x20;&#x20;&#x20;3005         return_length=return_length,',
          '&#x20;&#x20;&#x20;3006         verbose=verbose,',
          '&#x20;&#x20;&#x20;3007         **kwargs,',
          '&#x20;&#x20;&#x20;3008     )',
          'File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3053, in PreTrainedTokenizerBase.encode_plus(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)',
          '&#x20;&#x20;&#x20;3032 &quot;&quot;&quot;',
          '&#x20;&#x20;&#x20;3033 Tokenize and prepare for the model a sequence or a pair of sequences.',
          '&#x20;&#x20;&#x20;3034',
          '&#x20;&#x20;&#x20;(...)',
          '&#x20;&#x20;&#x20;3049         method).',
          '&#x20;&#x20;&#x20;3050 &quot;&quot;&quot;',
          '&#x20;&#x20;&#x20;3052 # Backward compatibility for &#x27;truncation_strategy&#x27;, &#x27;pad_to_max_length&#x27;',
          '-&amp;gt; 3053 padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(',
          '&#x20;&#x20;&#x20;3054     padding=padding,',
          '&#x20;&#x20;&#x20;3055     truncation=truncation,',
          '&#x20;&#x20;&#x20;3056     max_length=max_length,',
          '&#x20;&#x20;&#x20;3057     pad_to_multiple_of=pad_to_multiple_of,',
          '&#x20;&#x20;&#x20;3058     verbose=verbose,',
          '&#x20;&#x20;&#x20;3059     **kwargs,',
          '&#x20;&#x20;&#x20;3060 )',
          '&#x20;&#x20;&#x20;3062 return self._encode_plus(',
          '&#x20;&#x20;&#x20;3063     text=text,',
          '&#x20;&#x20;&#x20;3064     text_pair=text_pair,',
          '&#x20;&#x20;&#x20;(...)',
          '&#x20;&#x20;&#x20;3080     **kwargs,',
          '&#x20;&#x20;&#x20;3081 )',
          'File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2788, in PreTrainedTokenizerBase._get_padding_truncation_strategies(self, padding, truncation, max_length, pad_to_multiple_of, verbose, **kwargs)',
          '&#x20;&#x20;&#x20;2786 # Test if we have a padding token',
          '&#x20;&#x20;&#x20;2787 if padding_strategy != PaddingStrategy.DO_NOT_PAD and (self.pad_token is None or self.pad_token_id &amp;lt; 0):',
          '-&amp;gt; 2788     raise ValueError(',
          '&#x20;&#x20;&#x20;2789         &quot;Asking to pad but the tokenizer does not have a padding token. &quot;',
          '&#x20;&#x20;&#x20;2790         &quot;Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` &quot;',
          '&#x20;&#x20;&#x20;2791         &quot;or add a new pad token via `tokenizer.add_special_tokens(&#x7B;&#x27;pad_token&#x27;: &#x27;[PAD]&#x27;&#x7D;)`.&quot;',
          '&#x20;&#x20;&#x20;2792     )',
          '&#x20;&#x20;&#x20;2794 # Check that we will truncate to a multiple of pad_to_multiple_of if both are provided',
          '&#x20;&#x20;&#x20;2795 if (',
          '&#x20;&#x20;&#x20;2796     truncation_strategy != TruncationStrategy.DO_NOT_TRUNCATE',
          '&#x20;&#x20;&#x20;2797     and padding_strategy != PaddingStrategy.DO_NOT_PAD',
          '&#x20;&#x20;&#x20;(...)',
          '&#x20;&#x20;&#x20;2800     and (max_length % pad_to_multiple_of != 0)',
          '&#x20;&#x20;&#x20;2801 ):',
          'ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens(&#x7B;&#x27;pad_token&#x27;: &#x27;[PAD]&#x27;&#x7D;)`.',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>D√°-nos um erro porque o tokenizador do GPT2 n√£o tem um token para preenchimento e pede que atribuamos um, al√©m de sugerir fazer <code>tokenizer.pad_token = tokenizer.eos_token</code>, ent√£o fazemos isso.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Voltamos a testar a fun√ß√£o de tokeniza√ß√£o</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">][</span><span class="n">idx</span><span class="p">])</span>',
      '<span class="n">tokens</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">tokens</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '(torch.Size([1, 768]), torch.Size([1, 768]))',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Agora que verificamos que a fun√ß√£o tokeniza corretamente, aplicamos essa fun√ß√£o ao conjunto de dados, mas tamb√©m a aplicamos em lotes para que seja executada mais rapidamente.</p>
      <p>Al√©m disso, aproveitamos e eliminamos as colunas que n√£o vamos precisar.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="s1">&#39;label_text&#39;</span><span class="p">])</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vamos ver agora como fica o dataset</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">dataset</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'DatasetDict(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;train: Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;id&#x27;, &#x27;text&#x27;, &#x27;label&#x27;, &#x27;label_text&#x27;, &#x27;labels&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 200000',
          '&#x20;&#x20;&#x20;&#x20;&#x7D;)',
          '&#x20;&#x20;&#x20;&#x20;validation: Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;id&#x27;, &#x27;text&#x27;, &#x27;label&#x27;, &#x27;label_text&#x27;, &#x27;labels&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 5000',
          '&#x20;&#x20;&#x20;&#x20;&#x7D;)',
          '&#x20;&#x20;&#x20;&#x20;test: Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;id&#x27;, &#x27;text&#x27;, &#x27;label&#x27;, &#x27;label_text&#x27;, &#x27;labels&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 5000',
          '&#x20;&#x20;&#x20;&#x20;&#x7D;)',
          '&#x7D;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos que temos os campos 'labels', 'input_ids' e 'attention_mask', que √© o que nos interessa para treinar.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Modelo">Modelo<a class="anchor-link" href="#Modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 85" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Instanciamos um modelo para classifica√ß√£o de sequ√™ncias e indicamos o n√∫mero de classes que temos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span>',
      '<span class="w"> </span>',
      '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="n">num_classes</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: [&#x27;score.weight&#x27;]',
          'You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Diz que os pesos da camada <code>score</code> foram inicializados de maneira aleat√≥ria e que temos que reentrein√°-los, vamos ver por que isso acontece.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>O modelo GPT2 seria este</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span>',
      '<span class="w"> </span>',
      '<span class="n">casual_model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Enquanto o modelo do GPT2 para gerar texto √© este</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a ver sua arquitetura</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">casual_model</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'GPT2LMHeadModel(',
          '&#x20;&#x20;(transformer): GPT2Model(',
          '&#x20;&#x20;&#x20;&#x20;(wte): Embedding(50257, 768)',
          '&#x20;&#x20;&#x20;&#x20;(wpe): Embedding(1024, 768)',
          '&#x20;&#x20;&#x20;&#x20;(drop): Dropout(p=0.1, inplace=False)',
          '&#x20;&#x20;&#x20;&#x20;(h): ModuleList(',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(0-11): 12 x GPT2Block(',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(attn): GPT2Attention(',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(c_attn): Conv1D()',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(c_proj): Conv1D()',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(attn_dropout): Dropout(p=0.1, inplace=False)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(resid_dropout): Dropout(p=0.1, inplace=False)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(mlp): GPT2MLP(',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(c_fc): Conv1D()',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(c_proj): Conv1D()',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(act): NewGELUActivation()',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(dropout): Dropout(p=0.1, inplace=False)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)',
          '&#x20;&#x20;&#x20;&#x20;)',
          '&#x20;&#x20;&#x20;&#x20;(ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)',
          '&#x20;&#x20;)',
          '&#x20;&#x20;(lm_head): Linear(in_features=768, out_features=50257, bias=False)',
          ')',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>E agora a arquitetura do modelo que vamos usar para classificar as reviews</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">model</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'GPT2ForSequenceClassification(',
          '&#x20;&#x20;(transformer): GPT2Model(',
          '&#x20;&#x20;&#x20;&#x20;(wte): Embedding(50257, 768)',
          '&#x20;&#x20;&#x20;&#x20;(wpe): Embedding(1024, 768)',
          '&#x20;&#x20;&#x20;&#x20;(drop): Dropout(p=0.1, inplace=False)',
          '&#x20;&#x20;&#x20;&#x20;(h): ModuleList(',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(0-11): 12 x GPT2Block(',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(attn): GPT2Attention(',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(c_attn): Conv1D()',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(c_proj): Conv1D()',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(attn_dropout): Dropout(p=0.1, inplace=False)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(resid_dropout): Dropout(p=0.1, inplace=False)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(mlp): GPT2MLP(',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(c_fc): Conv1D()',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(c_proj): Conv1D()',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(act): NewGELUActivation()',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(dropout): Dropout(p=0.1, inplace=False)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)',
          '&#x20;&#x20;&#x20;&#x20;)',
          '&#x20;&#x20;&#x20;&#x20;(ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)',
          '&#x20;&#x20;)',
          '&#x20;&#x20;(score): Linear(in_features=768, out_features=5, bias=False)',
          ')',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Aqui h√° duas coisas para mencionar</p>
      <ul>
        <li>A primeira √© que em ambos, a primeira camada tem dimens√µes de 50257x768, o que corresponde a 50257 poss√≠veis tokens do vocabul√°rio do GPT2 e a 768 dimens√µes do embedding, por isso fizemos bem em tokenizar as avalia√ß√µes com um tamanho de 768 tokens</li>
        <li>A segunda √© que o modelo <code>casual</code> (o de gera√ß√£o de texto) tem no final uma camada <code>Linear</code> que gera 50257 valores, ou seja, √© respons√°vel por prever o pr√≥ximo token e dar um valor a um poss√≠vel token. Enquanto isso, o modelo de classifica√ß√£o tem uma camada <code>Linear</code> que gera apenas 5 valores, um para cada classe, o que nos fornecer√° a probabilidade de a review pertencer a cada classe.</li>
      </ul>
      <p>Por isso receb√≠amos a mensagem de que os pesos da camada <code>score</code> haviam sido inicializados de forma aleat√≥ria, porque a biblioteca transformers removeu a camada <code>Linear</code> de 768x50257 e adicionou uma camada <code>Linear</code> de 768x5, inicializou-a com valores aleat√≥rios e n√≥s temos que trein√°-la para o nosso problema espec√≠fico.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Apagamos o modelo casual, pois n√£o vamos us√°-lo.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">del</span> <span class="n">casual_model</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Treinador">Treinador<a class="anchor-link" href="#Treinador"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 86" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos agora a configurar os argumentos do treinamento</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">TrainingArguments</span>',
      '<span class="w"> </span>',
      '<span class="n">metric_name</span> <span class="o">=</span> <span class="s2">&quot;accuracy&quot;</span>',
      '<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;GPT2-small-finetuned-amazon-reviews-en-classification&quot;</span>',
      '<span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>',
      '<span class="n">BS_TRAIN</span> <span class="o">=</span> <span class="mi">28</span>',
      '<span class="n">BS_EVAL</span> <span class="o">=</span> <span class="mi">40</span>',
      '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>',
      '<span class="n">WEIGHT_DECAY</span> <span class="o">=</span> <span class="mf">0.01</span>',
      '<span class="w"> </span>',
      '<span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
      '<span class="w">    </span><span class="n">model_name</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">eval_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">save_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">&quot;cosine&quot;</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '<span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Definimos uma m√©trica para o dataloader de valida√ß√£o</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>',
      '<span class="kn">from</span><span class="w"> </span><span class="nn">evaluate</span><span class="w"> </span><span class="kn">import</span> <span class="n">load</span>',
      '<span class="w"> </span>',
      '<span class="n">metric</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">compute_metrics</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">):</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">eval_pred</span>',
      '<span class="w">    </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Definimos agora o treinador</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Trainer</span>',
      '<span class="w"> </span>',
      '<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
      '<span class="w">    </span><span class="n">model</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">training_args</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">],</span>',
      '<span class="w">    </span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;validation&#39;</span><span class="p">],</span>',
      '<span class="w">    </span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>',
      '<span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Treinamos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '&#x20;&#x20;0%|          | 0/600000 [00:00&amp;lt;?, ?it/s]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockOutputCell
        text={[
          '---------------------------------------------------------------------------ValueError                                Traceback (most recent call last)Cell In[21], line 1',
          '----&amp;gt; 1 trainer.train()',
          'File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/trainer.py:1876, in Trainer.train(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)',
          '&#x20;&#x20;&#x20;1873 try:',
          '&#x20;&#x20;&#x20;1874     # Disable progress bars when uploading models during checkpoints to avoid polluting stdout',
          '&#x20;&#x20;&#x20;1875     hf_hub_utils.disable_progress_bars()',
          '-&amp;gt; 1876     return inner_training_loop(',
          '&#x20;&#x20;&#x20;1877         args=args,',
          '&#x20;&#x20;&#x20;1878         resume_from_checkpoint=resume_from_checkpoint,',
          '&#x20;&#x20;&#x20;1879         trial=trial,',
          '&#x20;&#x20;&#x20;1880         ignore_keys_for_eval=ignore_keys_for_eval,',
          '&#x20;&#x20;&#x20;1881     )',
          '&#x20;&#x20;&#x20;1882 finally:',
          '&#x20;&#x20;&#x20;1883     hf_hub_utils.enable_progress_bars()',
          'File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/trainer.py:2178, in Trainer._inner_training_loop(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)',
          '&#x20;&#x20;&#x20;2175     rng_to_sync = True',
          '&#x20;&#x20;&#x20;2177 step = -1',
          '-&amp;gt; 2178 for step, inputs in enumerate(epoch_iterator):',
          '&#x20;&#x20;&#x20;2179     total_batched_samples += 1',
          '&#x20;&#x20;&#x20;2181     if self.args.include_num_input_tokens_seen:',
          'File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/accelerate/data_loader.py:454, in DataLoaderShard.__iter__(self)',
          '&#x20;&#x20;&#x20;&#x20;452 # We iterate one batch ahead to check when we are at the end',
          '&#x20;&#x20;&#x20;&#x20;453 try:',
          '--&amp;gt; 454     current_batch = next(dataloader_iter)',
          '&#x20;&#x20;&#x20;&#x20;455 except StopIteration:',
          '&#x20;&#x20;&#x20;&#x20;456     yield',
          'File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631, in _BaseDataLoaderIter.__next__(self)',
          '&#x20;&#x20;&#x20;&#x20;628 if self._sampler_iter is None:',
          '&#x20;&#x20;&#x20;&#x20;629     # TODO(https://github.com/pytorch/pytorch/issues/76750)',
          '&#x20;&#x20;&#x20;&#x20;630     self._reset()  # type: ignore[call-arg]',
          '--&amp;gt; 631 data = self._next_data()',
          '&#x20;&#x20;&#x20;&#x20;632 self._num_yielded += 1',
          '&#x20;&#x20;&#x20;&#x20;633 if self._dataset_kind == _DatasetKind.Iterable and \\',
          '&#x20;&#x20;&#x20;&#x20;634         self._IterableDataset_len_called is not None and \\',
          '&#x20;&#x20;&#x20;&#x20;635         self._num_yielded &amp;gt; self._IterableDataset_len_called:',
          'File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675, in _SingleProcessDataLoaderIter._next_data(self)',
          '&#x20;&#x20;&#x20;&#x20;673 def _next_data(self):',
          '&#x20;&#x20;&#x20;&#x20;674     index = self._next_index()  # may raise StopIteration',
          '--&amp;gt; 675     data = self._dataset_fetcher.fetch(index)  # may raise StopIteration',
          '&#x20;&#x20;&#x20;&#x20;676     if self._pin_memory:',
          '&#x20;&#x20;&#x20;&#x20;677         data = _utils.pin_memory.pin_memory(data, self._pin_memory_device)',
          'File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:54, in _MapDatasetFetcher.fetch(self, possibly_batched_index)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;52 else:',
          '&#x20;&#x20;&#x20;&#x20;&#x20;53     data = self.dataset[possibly_batched_index]',
          '---&amp;gt; 54 return self.collate_fn(data)',
          'File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/data/data_collator.py:271, in DataCollatorWithPadding.__call__(self, features)',
          '&#x20;&#x20;&#x20;&#x20;270 def __call__(self, features: List[Dict[str, Any]]) -&amp;gt; Dict[str, Any]:',
          '--&amp;gt; 271     batch = pad_without_fast_tokenizer_warning(',
          '&#x20;&#x20;&#x20;&#x20;272         self.tokenizer,',
          '&#x20;&#x20;&#x20;&#x20;273         features,',
          '&#x20;&#x20;&#x20;&#x20;274         padding=self.padding,',
          '&#x20;&#x20;&#x20;&#x20;275         max_length=self.max_length,',
          '&#x20;&#x20;&#x20;&#x20;276         pad_to_multiple_of=self.pad_to_multiple_of,',
          '&#x20;&#x20;&#x20;&#x20;277         return_tensors=self.return_tensors,',
          '&#x20;&#x20;&#x20;&#x20;278     )',
          '&#x20;&#x20;&#x20;&#x20;279     if &quot;label&quot; in batch:',
          '&#x20;&#x20;&#x20;&#x20;280         batch[&quot;labels&quot;] = batch[&quot;label&quot;]',
          'File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/data/data_collator.py:66, in pad_without_fast_tokenizer_warning(tokenizer, *pad_args, **pad_kwargs)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;63 tokenizer.deprecation_warnings[&quot;Asking-to-pad-a-fast-tokenizer&quot;] = True',
          '&#x20;&#x20;&#x20;&#x20;&#x20;65 try:',
          '---&amp;gt; 66     padded = tokenizer.pad(*pad_args, **pad_kwargs)',
          '&#x20;&#x20;&#x20;&#x20;&#x20;67 finally:',
          '&#x20;&#x20;&#x20;&#x20;&#x20;68     # Restore the state of the warning.',
          '&#x20;&#x20;&#x20;&#x20;&#x20;69     tokenizer.deprecation_warnings[&quot;Asking-to-pad-a-fast-tokenizer&quot;] = warning_state',
          'File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3299, in PreTrainedTokenizerBase.pad(self, encoded_inputs, padding, max_length, pad_to_multiple_of, return_attention_mask, return_tensors, verbose)',
          '&#x20;&#x20;&#x20;3297 # The model&#x27;s main input name, usually `input_ids`, has be passed for padding',
          '&#x20;&#x20;&#x20;3298 if self.model_input_names[0] not in encoded_inputs:',
          '-&amp;gt; 3299     raise ValueError(',
          '&#x20;&#x20;&#x20;3300         &quot;You should supply an encoding or a list of encodings to this method &quot;',
          '&#x20;&#x20;&#x20;3301         f&quot;that includes &#x7B;self.model_input_names[0]&#x7D;, but you provided &#x7B;list(encoded_inputs.keys())&#x7D;&quot;',
          '&#x20;&#x20;&#x20;3302     )',
          '&#x20;&#x20;&#x20;3304 required_input = encoded_inputs[self.model_input_names[0]]',
          '&#x20;&#x20;&#x20;3306 if required_input is None or (isinstance(required_input, Sized) and len(required_input) == 0):',
          'ValueError: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided [&#x27;label&#x27;, &#x27;labels&#x27;]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>N√≥s recebemos novamente um erro porque o modelo n√£o tem um token de padding atribu√≠do, ent√£o, assim como com o tokenizador, n√≥s o atribu√≠mos.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Recriamos os argumentos do treinador com o novo modelo, que agora tem um token de padding, o treinador e voltamos a treinar.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
      '<span class="w">    </span><span class="n">model_name</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">eval_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">save_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">&quot;cosine&quot;</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">logging_dir</span><span class="o">=</span><span class="s2">&quot;./runs&quot;</span><span class="p">,</span>',
      '<span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
      '<span class="w">    </span><span class="n">model</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">training_args</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">],</span>',
      '<span class="w">    </span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;validation&#39;</span><span class="p">],</span>',
      '<span class="w">    </span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>',
      '<span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Agora que vimos que tudo est√° bem, podemos treinar</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '&amp;lt;IPython.core.display.HTML object&amp;gt;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockOutputCell
        text={[
          '&amp;lt;IPython.core.display.HTML object&amp;gt;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockOutputCell
        text={[
          '&amp;lt;transformers.trainer_utils.EvalPrediction object at 0x782767ea1450&amp;gt;',
          '&amp;lt;transformers.trainer_utils.EvalPrediction object at 0x782767eeefe0&amp;gt;',
          '&amp;lt;transformers.trainer_utils.EvalPrediction object at 0x782767eecfd0&amp;gt;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockOutputCell
        text={[
          'TrainOutput(global_step=21429, training_loss=0.7846888848762739, metrics=&#x7B;&#x27;train_runtime&#x27;: 26367.7801, &#x27;train_samples_per_second&#x27;: 22.755, &#x27;train_steps_per_second&#x27;: 0.813, &#x27;total_flos&#x27;: 2.35173445632e+17, &#x27;train_loss&#x27;: 0.7846888848762739, &#x27;epoch&#x27;: 3.0&#x7D;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Avaliacao">Avalia√ß√£o<a class="anchor-link" href="#Avaliacao"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 87" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Uma vez treinado, avaliamos sobre o dataset de teste</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">])</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '&amp;lt;IPython.core.display.HTML object&amp;gt;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockOutputCell
        text={[
          '&amp;lt;transformers.trainer_utils.EvalPrediction object at 0x7826ddfded40&amp;gt;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockOutputCell
        text={[
          '&#x7B;&#x27;eval_loss&#x27;: 0.7973636984825134,',
          '&#x27;eval_accuracy&#x27;: 0.6626,',
          '&#x27;eval_runtime&#x27;: 76.3016,',
          '&#x27;eval_samples_per_second&#x27;: 65.529,',
          '&#x27;eval_steps_per_second&#x27;: 1.638,',
          '&#x27;epoch&#x27;: 3.0&#x7D;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Publicar o modelo">Publicar o modelo<a class="anchor-link" href="#Publicar o modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 88" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>J√° temos nosso modelo treinado, agora podemos compartilh√°-lo com o mundo, ent√£o primeiro criamos uma **ficha do modelo**</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">create_model_card</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>E j√° podemos public√°-lo. Como a primeira coisa que fizemos foi fazer login no hub do huggingface, podemos envi√°-lo para o nosso hub sem nenhum problema.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">push_to_hub</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Uso do modelo">Uso do modelo<a class="anchor-link" href="#Uso do modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 89" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Limpamos tudo o que for poss√≠vel</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">gc</span>',
      '<span class="w"> </span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">clear_hardwares</span><span class="p">():</span>',
      '<span class="w">    </span><span class="n">torch</span><span class="o">.</span><span class="n">clear_autocast_cache</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">ipc_collect</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="n">clear_hardwares</span><span class="p">()</span>',
      '<span class="n">clear_hardwares</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Como subimos o modelo ao nosso hub, podemos baix√°-lo e us√°-lo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">pipeline</span>',
      '<span class="w"> </span>',
      '<span class="n">user</span> <span class="o">=</span> <span class="s2">&quot;maximofn&quot;</span>',
      '<span class="n">checkpoints</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">user</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span>',
      '<span class="n">task</span> <span class="o">=</span> <span class="s2">&quot;text-classification&quot;</span>',
      '<span class="n">classifier</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">checkpoints</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">checkpoints</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Agora, se quisermos que nos retorne a probabilidade de todas as classes, simplesmente usamos o classificador que acabamos de instanciar, com o par√¢metro <code>top_k=None</code></p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">labels</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="s2">&quot;I love this product&quot;</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>',
      '<span class="n">labels</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '[&#x7B;&#x27;label&#x27;: &#x27;LABEL_4&#x27;, &#x27;score&#x27;: 0.8253807425498962&#x7D;,',
          '&#x7B;&#x27;label&#x27;: &#x27;LABEL_3&#x27;, &#x27;score&#x27;: 0.15411493182182312&#x7D;,',
          '&#x7B;&#x27;label&#x27;: &#x27;LABEL_2&#x27;, &#x27;score&#x27;: 0.013907806016504765&#x7D;,',
          '&#x7B;&#x27;label&#x27;: &#x27;LABEL_0&#x27;, &#x27;score&#x27;: 0.003939222544431686&#x7D;,',
          '&#x7B;&#x27;label&#x27;: &#x27;LABEL_1&#x27;, &#x27;score&#x27;: 0.0026572425849735737&#x7D;]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Se quisermos apenas a classe com a maior probabilidade, fazemos o mesmo mas com o par√¢metro <code>top_k=1</code></p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">label</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="s2">&quot;I love this product&quot;</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
      '<span class="n">label</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '[&#x7B;&#x27;label&#x27;: &#x27;LABEL_4&#x27;, &#x27;score&#x27;: 0.8253807425498962&#x7D;]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>E se quisermos n classes, fazemos o mesmo mas com o par√¢metro <code>top_k=n</code></p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">two_labels</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="s2">&quot;I love this product&quot;</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>',
      '<span class="n">two_labels</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '[&#x7B;&#x27;label&#x27;: &#x27;LABEL_4&#x27;, &#x27;score&#x27;: 0.8253807425498962&#x7D;,',
          '&#x7B;&#x27;label&#x27;: &#x27;LABEL_3&#x27;, &#x27;score&#x27;: 0.15411493182182312&#x7D;]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Tamb√©m podemos testar o modelo com Automodel e AutoTokenizer</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>',
      '<span class="w"> </span>',
      '<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;GPT2-small-finetuned-amazon-reviews-en-classification&quot;</span>',
      '<span class="n">user</span> <span class="o">=</span> <span class="s2">&quot;maximofn&quot;</span>',
      '<span class="n">checkpoint</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">user</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span>',
      '<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">5</span>',
      '<span class="w"> </span>',
      '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>',
      '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="n">num_classes</span><span class="p">)</span><span class="o">.</span><span class="n">half</span><span class="p">()</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">&quot;I love this product&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>',
      '<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
      '<span class="w">    </span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>',
      '<span class="n">logits</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">logits</span>',
      '<span class="n">lables</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>',
      '<span class="n">lables</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '[0.003963470458984375,',
          '0.0026721954345703125,',
          '0.01397705078125,',
          '0.154541015625,',
          '0.82470703125]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Se voc√™ quiser testar mais o modelo, voc√™ pode v√™-lo em <a href="https://huggingface.co/Maximofn/GPT2-small-finetuned-amazon-reviews-en-classification" target="_blank" rel="nofollow noreferrer">Maximofn/GPT2-small-finetuned-amazon-reviews-en-classification</a></p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Ajuste fino para geracao de texto com Hugging Face">Ajuste fino para gera√ß√£o de texto com Hugging Face<a class="anchor-link" href="#Ajuste fino para geracao de texto com Hugging Face"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 90" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Para garantizar que n√£o tenho problemas de mem√≥ria VRAM, reinicio o notebook</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Login">Login<a class="anchor-link" href="#Login"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 91" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Para poder fazer o upload do resultado do treinamento para o hub, devemos nos autenticar primeiro, para isso precisamos de um token</p>
      <p>Para criar um token √© necess√°rio ir √† p√°gina de <a href="https://huggingface.co/settings/tokens" target="_blank" rel="nofollow noreferrer">settings/tokens</a> da nossa conta, aparecer√° algo assim</p>
      <img decoding="async" onerror="this.parentNode.removeChild(this)" src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/User-Access-Token-dark.webp" alt="User-Access-Token-dark">
      <p>Damos a <code>New token</code> e uma janela aparecer√° para criar um novo token</p>
      <img decoding="async" onerror="this.parentNode.removeChild(this)" src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/new-token-dark.webp" alt="new-token-dark">
      <p>Damos um nome ao token e o criamos com o papel <code>write</code>, ou com o papel <code>Fine-grained</code>, que nos permite selecionar exatamente quais permiss√µes ter√° o token.</p>
      <p>Uma vez criado, copiamos e colamos a seguir.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">huggingface_hub</span><span class="w"> </span><span class="kn">import</span> <span class="n">notebook_login</span>',
      '<span class="n">notebook_login</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Conjunto de Dados">Conjunto de Dados<a class="anchor-link" href="#Conjunto de Dados"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 92" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a usar um dataset de <a href="https://huggingface.co/datasets/Maximofn/short-jokes-dataset" target="_blank" rel="nofollow noreferrer">chistes em ingl√™s</a></p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>',
      '<span class="w"> </span>',
      '<span class="n">jokes</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;Maximofn/short-jokes-dataset&quot;</span><span class="p">)</span>',
      '<span class="n">jokes</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'DatasetDict(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;train: Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;ID&#x27;, &#x27;Joke&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 231657',
          '&#x20;&#x20;&#x20;&#x20;&#x7D;)',
          '&#x7D;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vamos v√™-lo um pouco</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">jokes</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'DatasetDict(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;train: Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;ID&#x27;, &#x27;Joke&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 231657',
          '&#x20;&#x20;&#x20;&#x20;&#x7D;)',
          '&#x7D;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos que √© um conjunto de treinamento √∫nico com mais de 200 mil piadas. Ent√£o, mais tarde teremos que dividi-lo em treinamento e avalia√ß√£o.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a ver um exemplo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">random</span><span class="w"> </span><span class="kn">import</span> <span class="n">randint</span>',
      '<span class="w"> </span>',
      '<span class="n">idx</span> <span class="o">=</span> <span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">jokes</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>',
      '<span class="n">jokes</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '&#x7B;&#x27;ID&#x27;: 198387,',
          '&#x27;Joke&#x27;: &#x27;My hot dislexic co-worker said she had an important massage to give me in her office... When I got there, she told me it can wait until I put on some clothes.&#x27;&#x7D;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos que tem um ID de piada que n√£o nos interessa em absoluto e a pr√≥pria piada</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Caso voc√™ tenha pouca mem√≥ria na GPU, vou fazer um subconjunto do conjunto de dados, escolha o percentual de piadas que deseja usar</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">percent_of_train_dataset</span> <span class="o">=</span> <span class="mi">1</span>    <span class="c1"># If you want 50% of the dataset, set this to 0.5</span>',
      '<span class="w"> </span>',
      '<span class="n">subset_dataset</span> <span class="o">=</span> <span class="n">jokes</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">jokes</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">])</span> <span class="o">*</span> <span class="n">percent_of_train_dataset</span><span class="p">)))</span>',
      '<span class="n">subset_dataset</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;features: [&#x27;ID&#x27;, &#x27;Joke&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;num_rows: 231657',
          '&#x7D;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Agora dividimos o subconjunto em um conjunto de treinamento e outro de valida√ß√£o.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">percent_of_train_dataset</span> <span class="o">=</span> <span class="mf">0.90</span>',
      '<span class="w"> </span>',
      '<span class="n">split_dataset</span> <span class="o">=</span> <span class="n">subset_dataset</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">train_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">subset_dataset</span><span class="o">.</span><span class="n">num_rows</span> <span class="o">*</span> <span class="n">percent_of_train_dataset</span><span class="p">),</span> <span class="n">seed</span><span class="o">=</span><span class="mi">19</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>',
      '<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span>',
      '<span class="n">validation_test_dataset</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span>',
      '<span class="w"> </span>',
      '<span class="n">split_dataset</span> <span class="o">=</span> <span class="n">validation_test_dataset</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">train_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">validation_test_dataset</span><span class="o">.</span><span class="n">num_rows</span> <span class="o">*</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">seed</span><span class="o">=</span><span class="mi">19</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>',
      '<span class="n">validation_dataset</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span>',
      '<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span>',
      '<span class="w"> </span>',
      '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Size of the train set: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">. Size of the validation set: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">validation_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">. Size of the test set: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Size of the train set: 208491. Size of the validation set: 11583. Size of the test set: 11583',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Tokenizador">Tokenizador<a class="anchor-link" href="#Tokenizador"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 93" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Instanciamos o tokenizador. Instanciamos o token de padding do tokenizador para que n√£o nos d√™ erro como antes.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>',
      '<span class="w"> </span>',
      '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;openai-community/gpt2&quot;</span>',
      '<span class="w"> </span>',
      '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>',
      '<span class="n">tokenizer</span><span class="o">.</span><span class="n">padding_side</span> <span class="o">=</span> <span class="s2">&quot;right&quot;</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vamos adicionar dois novos tokens de in√≠cio de piada e fim de piada para ter mais controle</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">new_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;&amp;lt;SJ&amp;gt;&#39;</span><span class="p">,</span> <span class="s1">&#39;&amp;lt;EJ&amp;gt;&#39;</span><span class="p">]</span>   <span class="c1"># Start and end of joke tokens</span>',
      '<span class="w"> </span>',
      '<span class="n">num_added_tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">add_tokens</span><span class="p">(</span><span class="n">new_tokens</span><span class="p">)</span>',
      '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Added </span><span class="si">{</span><span class="n">num_added_tokens</span><span class="si">}</span><span class="s2"> tokens&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Added 2 tokens',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Criamos uma fun√ß√£o para adicionar os novos tokens √†s frases.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">joke_column</span> <span class="o">=</span> <span class="s2">&quot;Joke&quot;</span>',
      '<span class="w"> </span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">format_joke</span><span class="p">(</span><span class="n">example</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">example</span><span class="p">[</span><span class="n">joke_column</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;&amp;lt;SJ&amp;gt; &#39;</span> <span class="o">+</span> <span class="n">example</span><span class="p">[</span><span class="s1">&#39;Joke&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39; &amp;lt;EJ&amp;gt;&#39;</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">example</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Selecionamos as colunas que n√£o precisamos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">remove_columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">column</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">column_names</span> <span class="k">if</span> <span class="n">column</span> <span class="o">!=</span> <span class="n">joke_column</span><span class="p">]</span>',
      '<span class="n">remove_columns</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '[&#x27;ID&#x27;]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Formatamos o conjunto de dados e eliminamos as colunas que n√£o precisamos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">format_joke</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="n">remove_columns</span><span class="p">)</span>',
      '<span class="n">validation_dataset</span> <span class="o">=</span> <span class="n">validation_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">format_joke</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="n">remove_columns</span><span class="p">)</span>',
      '<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">format_joke</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="n">remove_columns</span><span class="p">)</span>',
      '<span class="n">train_dataset</span><span class="p">,</span> <span class="n">validation_dataset</span><span class="p">,</span> <span class="n">test_dataset</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '(Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;Joke&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 208491',
          '&#x7D;),',
          'Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;Joke&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 11583',
          '&#x7D;),',
          'Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;Joke&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 11583',
          '&#x7D;))',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Agora criamos uma fun√ß√£o para tokenizar os piadas</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="n">joke_column</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Tokenizamos o conjunto de dados e removemos a coluna com o texto</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="n">joke_column</span><span class="p">])</span>',
      '<span class="n">validation_dataset</span> <span class="o">=</span> <span class="n">validation_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="n">joke_column</span><span class="p">])</span>',
      '<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="n">joke_column</span><span class="p">])</span>',
      '<span class="n">train_dataset</span><span class="p">,</span> <span class="n">validation_dataset</span><span class="p">,</span> <span class="n">test_dataset</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '(Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;input_ids&#x27;, &#x27;attention_mask&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 208491',
          '&#x7D;),',
          'Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;input_ids&#x27;, &#x27;attention_mask&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 11583',
          '&#x7D;),',
          'Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;input_ids&#x27;, &#x27;attention_mask&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 11583',
          '&#x7D;))',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Modelo">Modelo<a class="anchor-link" href="#Modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 94" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Agora instanciamos o modelo para gera√ß√£o de texto e atribu√≠mos ao token de padding o token de end of string</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span>',
      '<span class="w"> </span>',
      '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos o tamanho do vocabul√°rio do modelo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span>',
      '<span class="n">vocab_size</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '50257',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Tem 50257 tokens, que √© o tamanho do vocabul√°rio do GPT2. Mas como dissemos que ir√≠amos criar dois novos tokens com o in√≠cio da piada e o fim da piada, os adicionamos ao modelo.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">model</span><span class="o">.</span><span class="n">resize_token_embeddings</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">))</span>',
      '<span class="w"> </span>',
      '<span class="n">new_vocab_size</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span>',
      '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Old vocab size: </span><span class="si">{</span><span class="n">vocab_size</span><span class="si">}</span><span class="s2">. New vocab size: </span><span class="si">{</span><span class="n">new_vocab_size</span><span class="si">}</span><span class="s2">. Added </span><span class="si">{</span><span class="n">new_vocab_size</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">vocab_size</span><span class="si">}</span><span class="s2"> tokens&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Old vocab size: 50257. New vocab size: 50259. Added 2 tokens',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Foram adicionados os dois novos tokens</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Treinamento">Treinamento<a class="anchor-link" href="#Treinamento"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 95" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Configuramos os par√¢metros de treinamento</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">TrainingArguments</span>',
      '<span class="w"> </span>',
      '<span class="n">metric_name</span> <span class="o">=</span> <span class="s2">&quot;accuracy&quot;</span>',
      '<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;GPT2-small-finetuned-Maximofn-short-jokes-dataset-casualLM&quot;</span>',
      '<span class="n">output_dir</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;./training_results&quot;</span>',
      '<span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>',
      '<span class="n">BS_TRAIN</span> <span class="o">=</span> <span class="mi">28</span>',
      '<span class="n">BS_EVAL</span> <span class="o">=</span> <span class="mi">32</span>',
      '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>',
      '<span class="n">WEIGHT_DECAY</span> <span class="o">=</span> <span class="mf">0.01</span>',
      '<span class="n">WARMUP_STEPS</span> <span class="o">=</span> <span class="mi">100</span>',
      '<span class="w"> </span>',
      '<span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>',
      '<span class="w">    </span><span class="n">model_name</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">eval_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">save_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">warmup_steps</span><span class="o">=</span><span class="n">WARMUP_STEPS</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">&quot;cosine&quot;</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '<span class="w">    </span><span class="c1"># metric_for_best_model=metric_name,</span>',
      '<span class="w">    </span><span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>',
      '<span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Agora n√£o usamos <code>metric_for_best_model</code>, depois de definir o treinador explicamos por que</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Definimos o treinador</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Trainer</span>',
      '<span class="w"> </span>',
      '<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
      '<span class="w">    </span><span class="n">model</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">training_args</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">validation_dataset</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
      '<span class="w">    </span><span class="c1"># compute_metrics=compute_metrics,</span>',
      '<span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Neste caso, n√£o passamos uma fun√ß√£o <code>compute_metrics</code>, mas sim, durante a avalia√ß√£o, ser√° usada a <code>loss</code> para avaliar o modelo. Por isso, ao definir os argumentos, n√£o definimos <code>metric_for_best_model</code>, pois n√£o vamos usar uma m√©trica para avaliar o modelo, mas sim a <code>loss</code>.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Treinamos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '&#x20;&#x20;0%|          | 0/625473 [00:00&amp;lt;?, ?it/s]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockOutputCell
        text={[
          '---------------------------------------------------------------------------ValueError                                Traceback (most recent call last)Cell In[19], line 1',
          '----&amp;gt; 1 trainer.train()',
          'File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/trainer.py:1885, in Trainer.train(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)',
          '&#x20;&#x20;&#x20;1883         hf_hub_utils.enable_progress_bars()',
          '&#x20;&#x20;&#x20;1884 else:',
          '-&amp;gt; 1885     return inner_training_loop(',
          '&#x20;&#x20;&#x20;1886         args=args,',
          '&#x20;&#x20;&#x20;1887         resume_from_checkpoint=resume_from_checkpoint,',
          '&#x20;&#x20;&#x20;1888         trial=trial,',
          '&#x20;&#x20;&#x20;1889         ignore_keys_for_eval=ignore_keys_for_eval,',
          '&#x20;&#x20;&#x20;1890     )',
          'File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/trainer.py:2216, in Trainer._inner_training_loop(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)',
          '&#x20;&#x20;&#x20;2213     self.control = self.callback_handler.on_step_begin(args, self.state, self.control)',
          '&#x20;&#x20;&#x20;2215 with self.accelerator.accumulate(model):',
          '-&amp;gt; 2216     tr_loss_step = self.training_step(model, inputs)',
          '&#x20;&#x20;&#x20;2218 if (',
          '&#x20;&#x20;&#x20;2219     args.logging_nan_inf_filter',
          '&#x20;&#x20;&#x20;2220     and not is_torch_xla_available()',
          '&#x20;&#x20;&#x20;2221     and (torch.isnan(tr_loss_step) or torch.isinf(tr_loss_step))',
          '&#x20;&#x20;&#x20;2222 ):',
          '&#x20;&#x20;&#x20;2223     # if loss is nan or inf simply add the average of previous logged losses',
          '&#x20;&#x20;&#x20;2224     tr_loss += tr_loss / (1 + self.state.global_step - self._globalstep_last_logged)',
          'File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/trainer.py:3238, in Trainer.training_step(self, model, inputs)',
          '&#x20;&#x20;&#x20;3235     return loss_mb.reduce_mean().detach().to(self.args.device)',
          '&#x20;&#x20;&#x20;3237 with self.compute_loss_context_manager():',
          '-&amp;gt; 3238     loss = self.compute_loss(model, inputs)',
          '&#x20;&#x20;&#x20;3240 del inputs',
          '&#x20;&#x20;&#x20;3241 torch.cuda.empty_cache()',
          'File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/trainer.py:3282, in Trainer.compute_loss(self, model, inputs, return_outputs)',
          '&#x20;&#x20;&#x20;3280 else:',
          '&#x20;&#x20;&#x20;3281     if isinstance(outputs, dict) and &quot;loss&quot; not in outputs:',
          '-&amp;gt; 3282         raise ValueError(',
          '&#x20;&#x20;&#x20;3283             &quot;The model did not return a loss from the inputs, only the following keys: &quot;',
          '&#x20;&#x20;&#x20;3284             f&quot;&#x7B;&#x27;,&#x27;.join(outputs.keys())&#x7D;. For reference, the inputs it received are &#x7B;&#x27;,&#x27;.join(inputs.keys())&#x7D;.&quot;',
          '&#x20;&#x20;&#x20;3285         )',
          '&#x20;&#x20;&#x20;3286     # We don&#x27;t use .loss here since the model may return tuples instead of ModelOutput.',
          '&#x20;&#x20;&#x20;3287     loss = outputs[&quot;loss&quot;] if isinstance(outputs, dict) else outputs[0]',
          'ValueError: The model did not return a loss from the inputs, only the following keys: logits,past_key_values. For reference, the inputs it received are input_ids,attention_mask.',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Como vemos, nos d√° um erro, dizendo que o modelo n√£o retorna o valor do loss, que √© fundamental para poder treinar, vamos ver por qu√™.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos ver como √© um exemplo do dataset</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">idx</span> <span class="o">=</span> <span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>',
      '<span class="n">sample</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>',
      '<span class="n">sample</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '&#x7B;&#x27;input_ids&#x27;: [50257,',
          '&#x20;&#x20;4162,',
          '&#x20;&#x20;750,',
          '&#x20;&#x20;262,',
          '&#x20;&#x20;18757,',
          '&#x20;&#x20;6451,',
          '&#x20;&#x20;2245,',
          '&#x20;&#x20;2491,',
          '&#x20;&#x20;30,',
          '&#x20;&#x20;4362,',
          '&#x20;&#x20;340,',
          '&#x20;&#x20;373,',
          '&#x20;&#x20;734,',
          '&#x20;&#x20;10032,',
          '&#x20;&#x20;13,',
          '&#x20;&#x20;220,',
          '&#x20;&#x20;50258,',
          '&#x20;&#x20;50256,',
          '&#x20;&#x20;50256,',
          '&#x20;&#x20;...,',
          '&#x20;&#x20;50256,',
          '&#x20;&#x20;50256,',
          '&#x20;&#x20;50256],',
          '&#x27;attention_mask&#x27;: [1,',
          '&#x20;&#x20;1,',
          '&#x20;&#x20;1,',
          '&#x20;&#x20;1,',
          '&#x20;&#x20;1,',
          '&#x20;&#x20;1,',
          '&#x20;&#x20;1,',
          '&#x20;&#x20;1,',
          '&#x20;&#x20;1,',
          '&#x20;&#x20;1,',
          '&#x20;&#x20;1,',
          '&#x20;&#x20;1,',
          '&#x20;&#x20;1,',
          '&#x20;&#x20;1,',
          '&#x20;&#x20;1,',
          '&#x20;&#x20;1,',
          '&#x20;&#x20;1,',
          '&#x20;&#x20;0,',
          '&#x20;&#x20;0,',
          '&#x20;&#x20;0,',
          '&#x20;&#x20;...,',
          '&#x20;&#x20;0,',
          '&#x20;&#x20;0,',
          '&#x20;&#x20;0]&#x7D;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Como podemos ver, temos um dicion√°rio com os <code>input_ids</code> e as <code>attention_mask</code>. Se o passarmos para o modelo, obtemos isso</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>',
      '<span class="w"> </span>',
      '<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span>',
      '<span class="w">    </span><span class="n">input_ids</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>',
      '<span class="w">    </span><span class="n">attention_mask</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>',
      '<span class="p">)</span>',
      '<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">loss</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'None',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Como vemos, n√£o retorna o valor da loss porque est√° esperando um valor para <code>labels</code>, que n√£o foi fornecido. No exemplo anterior, em que faz√≠amos fine tuning para classifica√ß√£o de texto, dissemos que as etiquetas devem ser passadas para um campo do dataset chamado <code>labels</code>, mas neste caso n√£o temos esse campo no dataset.</p>
      <p>Se agora atribuirmos as <code>labels</code> aos <code>input_ids</code> e voltarmos a ver a loss</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>',
      '<span class="w"> </span>',
      '<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span>',
      '<span class="w">    </span><span class="n">input_ids</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>',
      '<span class="w">    </span><span class="n">attention_mask</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>',
      '<span class="w">    </span><span class="n">labels</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>',
      '<span class="p">)</span>',
      '<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">loss</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'tensor(102.1873, device=&#x27;cuda:0&#x27;, grad_fn=&amp;lt;NllLossBackward0&amp;gt;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Agora sim obtemos uma <code>loss</code></p>
      <p>Portanto, temos duas op√ß√µes: adicionar um campo <code>labels</code> ao dataset, com os valores de <code>input_ids</code>, ou utilizar uma fun√ß√£o da biblioteca <code>transformers</code> chamada <code>data_collator</code>. Neste caso, usaremos <code>DataCollatorForLanguageModeling</code>. Vamos ver isso.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataCollatorForLanguageModeling</span>',
      '<span class="w"> </span>',
      '<span class="n">my_data_collator</span><span class="o">=</span><span class="n">DataCollatorForLanguageModeling</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">mlm</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Passamos a amostra <code>sample</code> por este <code>data_collator</code></p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">collated_sample</span> <span class="o">=</span> <span class="n">my_data_collator</span><span class="p">([</span><span class="n">sample</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos como √© a sa√≠da</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">collated_sample</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>',
      '<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">): </span><span class="si">{</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'input_ids (torch.Size([1, 768])): tensor([[50257,  4162,   750,   262, 18757,  6451,  2245,  2491,    30,  4362,',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;340,   373,   734, 10032,    13,   220, 50258, 50256, ..., 50256, 50256]],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;device=&#x27;cuda:0&#x27;)',
          'attention_mask (torch.Size([1, 768])): tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, ..., 0, 0]],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;device=&#x27;cuda:0&#x27;)',
          'labels (torch.Size([1, 768])): tensor([[50257,  4162,   750,   262, 18757,  6451,  2245,  2491,    30,  4362,',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;340,   373,   734, 10032,    13,   220, 50258,  -100,  ...,  -100,  -100]],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;device=&#x27;cuda:0&#x27;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Como se pode ver, o <code>data_collator</code> criou um campo <code>labels</code> e lhe atribuiu os valores de <code>input_ids</code>. Os tokens que est√£o mascarados receberam o valor -100. Isso ocorre porque quando definimos o <code>data_collator</code>, passamos o par√¢metro <code>mlm=False</code>, o que significa que n√£o estamos fazendo <code>Masked Language Modeling</code>, mas sim <code>Language Modeling</code>, por isso nenhum token original √© mascarado.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos ver se agora obtemos uma <code>loss</code> com esse <code>data_collator</code></p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">collated_sample</span><span class="p">)</span>',
      '<span class="n">output</span><span class="o">.</span><span class="n">loss</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'tensor(102.7181, device=&#x27;cuda:0&#x27;, grad_fn=&amp;lt;NllLossBackward0&amp;gt;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Ent√£o, redefinimos o <code>trainer</code> com o <code>data_collator</code> e treinamos novamente.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataCollatorForLanguageModeling</span>',
      '<span class="w"> </span>',
      '<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>',
      '<span class="w">    </span><span class="n">model</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">training_args</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">validation_dataset</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>',
      '<span class="w">    </span><span class="n">data_collator</span><span class="o">=</span><span class="n">DataCollatorForLanguageModeling</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">mlm</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>',
      '<span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '&amp;lt;IPython.core.display.HTML object&amp;gt;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockOutputCell
        text={[
          'There were missing keys in the checkpoint model loaded: [&#x27;lm_head.weight&#x27;].',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockOutputCell
        text={[
          'TrainOutput(global_step=22341, training_loss=3.505178199598342, metrics=&#x7B;&#x27;train_runtime&#x27;: 9209.5353, &#x27;train_samples_per_second&#x27;: 67.916, &#x27;train_steps_per_second&#x27;: 2.426, &#x27;total_flos&#x27;: 2.45146666696704e+17, &#x27;train_loss&#x27;: 3.505178199598342, &#x27;epoch&#x27;: 3.0&#x7D;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Avaliacao">Avalia√ß√£o<a class="anchor-link" href="#Avaliacao"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 96" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Uma vez treinado, avaliamos o modelo sobre o dataset de teste.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '&amp;lt;IPython.core.display.HTML object&amp;gt;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockOutputCell
        text={[
          '&#x7B;&#x27;eval_loss&#x27;: 3.201305866241455,',
          '&#x27;eval_runtime&#x27;: 65.0033,',
          '&#x27;eval_samples_per_second&#x27;: 178.191,',
          '&#x27;eval_steps_per_second&#x27;: 5.569,',
          '&#x27;epoch&#x27;: 3.0&#x7D;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Publicar o modelo">Publicar o modelo<a class="anchor-link" href="#Publicar o modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 97" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Criamos o cart√£o do modelo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">create_model_card</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Publicamos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">push_to_hub</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'events.out.tfevents.1720875425.8de3af1b431d.6946.1:   0%|          | 0.00/364 [00:00&amp;lt;?, ?B/s]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockOutputCell
        text={[
          'CommitInfo(commit_url=&#x27;https://huggingface.co/Maximofn/GPT2-small-finetuned-Maximofn-short-jokes-dataset-casualLM/commit/d107b3bb0e02076483238f9975697761015ec390&#x27;, commit_message=&#x27;End of training&#x27;, commit_description=&#x27;&#x27;, oid=&#x27;d107b3bb0e02076483238f9975697761015ec390&#x27;, pr_url=None, pr_revision=None, pr_num=None)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Uso do modelo">Uso do modelo<a class="anchor-link" href="#Uso do modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 98" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Limpez tudo o poss√≠vel</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">gc</span>',
      '<span class="w"> </span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">clear_hardwares</span><span class="p">():</span>',
      '<span class="w">    </span><span class="n">torch</span><span class="o">.</span><span class="n">clear_autocast_cache</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">ipc_collect</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="n">clear_hardwares</span><span class="p">()</span>',
      '<span class="n">clear_hardwares</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Baixamos o modelo e o tokenizador</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForCausalLM</span>',
      '<span class="w"> </span>',
      '<span class="n">user</span> <span class="o">=</span> <span class="s2">&quot;maximofn&quot;</span>',
      '<span class="n">checkpoints</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">user</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span>',
      '<span class="w"> </span>',
      '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>',
      '<span class="n">tokenizer</span><span class="o">.</span><span class="n">padding_side</span> <span class="o">=</span> <span class="s2">&quot;right&quot;</span>',
      '<span class="w"> </span>',
      '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Verificamos que o tokenizador e o modelo tenham os 2 tokens extras que adicionamos.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">tokenizer_vocab</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">get_vocab</span><span class="p">()</span>',
      '<span class="n">model_vocab</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span>',
      '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;tokenizer_vocab: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">tokenizer_vocab</span><span class="p">)</span><span class="si">}</span><span class="s2">. model_vocab: </span><span class="si">{</span><span class="n">model_vocab</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'tokenizer_vocab: 50259. model_vocab: 50259',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos que t√™m 50259 tokens, ou seja, os 50257 tokens do GPT2 mais os 2 que adicionamos.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Criamos uma fun√ß√£o para gerar piadas</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">def</span><span class="w"> </span><span class="nf">generate_joke</span><span class="p">(</span><span class="n">prompt_text</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">text</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&amp;lt;SJ&amp;gt; </span><span class="si">{</span><span class="n">prompt_text</span><span class="si">}</span><span class="s2">&quot;</span>',
      '<span class="w">    </span><span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
      '<span class="w">        </span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="o">**</span><span class="n">tokens</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">eos_token_id</span><span class="o">=</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">&quot;&amp;lt;EJ&amp;gt;&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Geramos uma piada</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">generate_joke</span><span class="p">(</span><span class="s2">&quot;Why didn&#39;t the frog cross the road?&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Setting `pad_token_id` to `eos_token_id`:50258 for open-end generation.',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockOutputCell
        text={[
          '&quot;&amp;lt;SJ&amp;gt; Why didn&#x27;t the frog cross the road? Because he was frog-in-the-face. &amp;lt;EJ&amp;gt;&quot;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Se quiser testar mais o modelo, voc√™ pode v√™-lo em <a href="https://huggingface.co/Maximofn/GPT2-small-finetuned-Maximofn-short-jokes-dataset-casualLM" target="_blank" rel="nofollow noreferrer">Maximofn/GPT2-small-finetuned-Maximofn-short-jokes-dataset-casualLM</a></p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Ajuste fino para classificacao de texto com Pytorch">Ajuste fino para classifica√ß√£o de texto com Pytorch<a class="anchor-link" href="#Ajuste fino para classificacao de texto com Pytorch"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 99" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Repetimos o treinamento com Pytorch</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Reiniciamos o notebook para nos assegurar</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Conjunto de Dados">Conjunto de Dados<a class="anchor-link" href="#Conjunto de Dados"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 100" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Baixamos o mesmo conjunto de dados que quando fizemos o treinamento com as bibliotecas do Hugging Face</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>',
      '<span class="w"> </span>',
      '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;mteb/amazon_reviews_multi&quot;</span><span class="p">,</span> <span class="s2">&quot;en&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Criamos uma vari√°vel com o n√∫mero de classes</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="s1">&#39;label&#39;</span><span class="p">))</span>',
      '<span class="n">num_classes</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '5',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Antes process√°vamos todo o conjunto de dados para criar um campo chamado <code>labels</code>, mas agora n√£o √© necess√°rio porque, como vamos programar tudo n√≥s mesmos, nos adaptamos a como √© o conjunto de dados.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Tokenizador">Tokenizador<a class="anchor-link" href="#Tokenizador"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 101" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Criamos o tokenizador. Atribu√≠mos o token de padding para que n√£o nos d√™ erro como antes.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>',
      '<span class="w"> </span>',
      '<span class="n">checkpoint</span> <span class="o">=</span> <span class="s2">&quot;openai-community/gpt2&quot;</span>',
      '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>',
      '<span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Criamos uma fun√ß√£o para tokenizar o dataset</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Tokenizamos. Removemos colunas que n√£o sejam necess√°rias, mas agora mantemos a de texto.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="s1">&#39;label_text&#39;</span><span class="p">])</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">dataset</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'DatasetDict(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;train: Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;text&#x27;, &#x27;label&#x27;, &#x27;input_ids&#x27;, &#x27;attention_mask&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 200000',
          '&#x20;&#x20;&#x20;&#x20;&#x7D;)',
          '&#x20;&#x20;&#x20;&#x20;validation: Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;text&#x27;, &#x27;label&#x27;, &#x27;input_ids&#x27;, &#x27;attention_mask&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 5000',
          '&#x20;&#x20;&#x20;&#x20;&#x7D;)',
          '&#x20;&#x20;&#x20;&#x20;test: Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;text&#x27;, &#x27;label&#x27;, &#x27;input_ids&#x27;, &#x27;attention_mask&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 5000',
          '&#x20;&#x20;&#x20;&#x20;&#x7D;)',
          '&#x7D;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">percentage</span> <span class="o">=</span> <span class="mi">1</span>',
      '<span class="n">subset_train</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">])</span> <span class="o">*</span> <span class="n">percentage</span><span class="p">)))</span>',
      '<span class="n">percentage</span> <span class="o">=</span> <span class="mi">1</span>',
      '<span class="n">subset_validation</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;validation&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;validation&#39;</span><span class="p">])</span> <span class="o">*</span> <span class="n">percentage</span><span class="p">)))</span>',
      '<span class="n">subset_test</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">])</span> <span class="o">*</span> <span class="n">percentage</span><span class="p">)))</span>',
      '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;len subset_train: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">subset_train</span><span class="p">)</span><span class="si">}</span><span class="s2">, len subset_validation: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">subset_validation</span><span class="p">)</span><span class="si">}</span><span class="s2">, len subset_test: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">subset_test</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'len subset_train: 200000, len subset_validation: 5000, len subset_test: 5000',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Modelo">Modelo<a class="anchor-link" href="#Modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 102" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Importamos os pesos e atribu√≠mos o token de padding</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span>',
      '<span class="w"> </span>',
      '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="n">num_classes</span><span class="p">)</span>',
      '<span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: [&#x27;score.weight&#x27;]',
          'You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Dispositivo">Dispositivo<a class="anchor-link" href="#Dispositivo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 103" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Criamos o dispositivo onde tudo ser√° executado</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>',
      '<span class="w"> </span>',
      '<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>De passagem, transferimos o modelo para o dispositivo e, de passagem, o convertemos para FP16 para ocupar menos mem√≥ria</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">model</span><span class="o">.</span><span class="n">half</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '<span class="nb">print</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[

        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Conjunto de Dados do Pytorch">Conjunto de Dados do Pytorch<a class="anchor-link" href="#Conjunto de Dados do Pytorch"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 104" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Criamos um dataset de pytorch</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dataset</span>',
      '<span class="w"> </span>',
      '<span class="k">class</span><span class="w"> </span><span class="nc">ReviewsDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>',
      '<span class="w">    </span><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">huggingface_dataset</span><span class="p">):</span>',
      '<span class="w">        </span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">huggingface_dataset</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>',
      '<span class="w">        </span><span class="n">label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">&#39;label&#39;</span><span class="p">]</span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">&#39;input_ids&#39;</span><span class="p">])</span>',
      '<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>',
      '<span class="w">        </span><span class="k">return</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">label</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="k">def</span><span class="w"> </span><span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>',
      '<span class="w">        </span><span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Instanciamos os datasets</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">ReviewsDataset</span><span class="p">(</span><span class="n">subset_train</span><span class="p">)</span>',
      '<span class="n">validatation_dataset</span> <span class="o">=</span> <span class="n">ReviewsDataset</span><span class="p">(</span><span class="n">subset_validation</span><span class="p">)</span>',
      '<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">ReviewsDataset</span><span class="p">(</span><span class="n">subset_test</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vamos dar uma olhada em um exemplo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">input_ids</span><span class="p">,</span> <span class="n">at_mask</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>',
      '<span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">at_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">label</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '(torch.Size([768]), torch.Size([768]), 0)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Pytorch Dataloader">Pytorch Dataloader<a class="anchor-link" href="#Pytorch Dataloader"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 105" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Criamos agora um DataLoader do PyTorch</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>',
      '<span class="w"> </span>',
      '<span class="n">BS</span> <span class="o">=</span> <span class="mi">12</span>',
      '<span class="w"> </span>',
      '<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
      '<span class="n">validation_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">validatation_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">)</span>',
      '<span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vamos dar uma olhada em um exemplo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">input_ids</span><span class="p">,</span> <span class="n">at_mask</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_loader</span><span class="p">))</span>',
      '<span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">at_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">labels</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '(torch.Size([12, 768]),',
          'torch.Size([12, 768]),',
          'tensor([2, 1, 2, 0, 3, 3, 0, 4, 3, 3, 4, 2]))',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Para verificar se tudo est√° bem, passamos a amostra ao modelo para ver se tudo sai bem. Primeiro passamos os tokens para o dispositivo.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '<span class="n">at_mask</span> <span class="o">=</span> <span class="n">at_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '<span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Agora passamos isso para o modelo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">at_mask</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
      '<span class="n">output</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'odict_keys([&#x27;loss&#x27;, &#x27;logits&#x27;, &#x27;past_key_values&#x27;])',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Como vemos, nos d√° a loss e os logits</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'tensor(5.9414, device=&#x27;cuda:0&#x27;, dtype=torch.float16,',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;grad_fn=&amp;lt;NllLossBackward0&amp;gt;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">]</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'tensor([[ 6.1953e+00, -1.2275e+00, -2.4824e+00,  5.8867e+00, -1.4734e+01],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;[ 5.4062e+00, -8.4570e-01, -2.3203e+00,  5.1055e+00, -1.1555e+01],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;[ 6.1641e+00, -9.3066e-01, -2.5664e+00,  6.0039e+00, -1.4570e+01],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;[ 5.2266e+00, -4.2358e-01, -2.0801e+00,  4.7461e+00, -1.1570e+01],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;[ 3.8184e+00, -2.3460e-03, -1.7666e+00,  3.4160e+00, -7.7969e+00],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;[ 4.1641e+00, -4.8169e-01, -1.6914e+00,  3.9941e+00, -8.7734e+00],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;[ 4.6758e+00, -3.0298e-01, -2.1641e+00,  4.1055e+00, -9.3359e+00],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;[ 4.1953e+00, -3.2471e-01, -2.1875e+00,  3.9375e+00, -8.3438e+00],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;[-1.1650e+00,  1.3564e+00, -6.2158e-01, -6.8115e-01,  4.8672e+00],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;[ 4.4961e+00, -8.7891e-02, -2.2793e+00,  4.2812e+00, -9.3359e+00],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;[ 4.9336e+00, -2.6627e-03, -2.1543e+00,  4.3711e+00, -1.0742e+01],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;[ 5.9727e+00, -4.3152e-02, -1.4551e+00,  4.3438e+00, -1.2117e+01]],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;device=&#x27;cuda:0&#x27;, dtype=torch.float16, grad_fn=&amp;lt;IndexBackward0&amp;gt;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Metrica">M√©trica<a class="anchor-link" href="#Metrica"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 106" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a criar uma fun√ß√£o para obter a m√©trica, que neste caso vai ser a acur√°cia.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">def</span><span class="w"> </span><span class="nf">predicted_labels</span><span class="p">(</span><span class="n">logits</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">percent</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">percent</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">predictions</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">def</span><span class="w"> </span><span class="nf">compute_accuracy</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">predicted_labels</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">correct</span> <span class="o">=</span> <span class="p">(</span><span class="n">predictions</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">correct</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a ver se ele calcula bem.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">compute_accuracy</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '0.1666666716337204',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Otimizador">Otimizador<a class="anchor-link" href="#Otimizador"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 107" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Como vamos a precisar um otimizador, criamos um</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AdamW</span>',
      '<span class="w"> </span>',
      '<span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>',
      '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">LR</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning',
          '&#x20;&#x20;warnings.warn(',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Treinamento">Treinamento<a class="anchor-link" href="#Treinamento"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 108" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Criamos o loop de treinamento</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>',
      '<span class="w"> </span>',
      '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>',
      '<span class="w"> </span>',
      '<span class="n">accuracy</span> <span class="o">=</span> <span class="mi">0</span>',
      '<span class="w"> </span>',
      '<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">train_loss</span> <span class="o">=</span> <span class="mi">0</span>',
      '<span class="w">    </span><span class="n">progresbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">at_mask</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">progresbar</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">at_mask</span> <span class="o">=</span> <span class="n">at_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">label</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">at_mask</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>',
      '<span class="w">        </span><span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>',
      '<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
      '<span class="w">        </span><span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>',
      '<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
      '<span class="w">        </span><span class="n">progresbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">({</span><span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()})</span>',
      '<span class="w">    </span><span class="n">train_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">progresbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">({</span><span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="n">train_loss</span><span class="p">})</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">valid_loss</span> <span class="o">=</span> <span class="mi">0</span>',
      '<span class="w">    </span><span class="n">progresbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">validation_loader</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">validation_loader</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">at_mask</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">progresbar</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">at_mask</span> <span class="o">=</span> <span class="n">at_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">at_mask</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>',
      '<span class="w">        </span><span class="n">valid_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">step_accuracy</span> <span class="o">=</span> <span class="n">compute_accuracy</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">accuracy</span> <span class="o">+=</span> <span class="n">step_accuracy</span>',
      '<span class="w">        </span><span class="n">progresbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">({</span><span class="s1">&#39;valid_loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="s1">&#39;accuracy&#39;</span><span class="p">:</span> <span class="n">step_accuracy</span><span class="o">.</span><span class="n">item</span><span class="p">()})</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="n">valid_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">validation_loader</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">accuracy</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">validation_loader</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">progresbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">({</span><span class="s1">&#39;valid_loss&#39;</span><span class="p">:</span> <span class="n">valid_loss</span><span class="p">,</span> <span class="s1">&#39;accuracy&#39;</span><span class="p">:</span> <span class="n">accuracy</span><span class="p">})</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16667/16667 [44:13&amp;lt;00:00,  6.28it/s, train_loss=nan]',
          'Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 417/417 [00:32&amp;lt;00:00, 12.72it/s, valid_loss=nan, accuracy=0]',
          'Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16667/16667 [44:06&amp;lt;00:00,  6.30it/s, train_loss=nan]',
          'Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 417/417 [00:32&amp;lt;00:00, 12.77it/s, valid_loss=nan, accuracy=0]',
          'Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16667/16667 [44:03&amp;lt;00:00,  6.30it/s, train_loss=nan]',
          'Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 417/417 [00:32&amp;lt;00:00, 12.86it/s, valid_loss=nan, accuracy=0]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Uso do modelo">Uso do modelo<a class="anchor-link" href="#Uso do modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 109" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos a testar o modelo que treinamos</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Primeiro tokenizamos um texto</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">input_tokens</span> <span class="o">=</span> <span class="n">tokenize_function</span><span class="p">({</span><span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="s2">&quot;I love this product. It is amazing.&quot;</span><span class="p">})</span>',
      '<span class="n">input_tokens</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">input_tokens</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '(torch.Size([1, 768]), torch.Size([1, 768]))',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Agora passamos isso para o modelo.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_tokens</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">input_tokens</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>',
      '<span class="n">output</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">]</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'tensor([[nan, nan, nan, nan, nan]], device=&#x27;cuda:0&#x27;, dtype=torch.float16,',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;grad_fn=&amp;lt;IndexBackward0&amp;gt;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos as previs√µes desses logits</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">predicted</span> <span class="o">=</span> <span class="n">predicted_labels</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">])</span>',
      '<span class="n">predicted</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'tensor([0], device=&#x27;cuda:0&#x27;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h2 id="Ajuste fino para geracao de texto com Pytorch">Ajuste fino para gera√ß√£o de texto com Pytorch<a class="anchor-link" href="#Ajuste fino para geracao de texto com Pytorch"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 110" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Repetimos o treinamento com Pytorch</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Reiniciamos o notebook para nos assegurar</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Conjunto de Dados">Conjunto de Dados<a class="anchor-link" href="#Conjunto de Dados"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 111" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Voltamos a baixar o conjunto de dados de piadas</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>',
      '<span class="w"> </span>',
      '<span class="n">jokes</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;Maximofn/short-jokes-dataset&quot;</span><span class="p">)</span>',
      '<span class="n">jokes</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'DatasetDict(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;train: Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;ID&#x27;, &#x27;Joke&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 231657',
          '&#x20;&#x20;&#x20;&#x20;&#x7D;)',
          '&#x7D;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Criamos um subconjunto caso haja pouca mem√≥ria</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">percent_of_train_dataset</span> <span class="o">=</span> <span class="mi">1</span>    <span class="c1"># If you want 50% of the dataset, set this to 0.5</span>',
      '<span class="w"> </span>',
      '<span class="n">subset_dataset</span> <span class="o">=</span> <span class="n">jokes</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">jokes</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">])</span> <span class="o">*</span> <span class="n">percent_of_train_dataset</span><span class="p">)))</span>',
      '<span class="n">subset_dataset</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;features: [&#x27;ID&#x27;, &#x27;Joke&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;num_rows: 231657',
          '&#x7D;)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Dividimos o conjunto de dados em subconjuntos de treinamento, valida√ß√£o e teste.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">percent_of_train_dataset</span> <span class="o">=</span> <span class="mf">0.90</span>',
      '<span class="w"> </span>',
      '<span class="n">split_dataset</span> <span class="o">=</span> <span class="n">subset_dataset</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">train_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">subset_dataset</span><span class="o">.</span><span class="n">num_rows</span> <span class="o">*</span> <span class="n">percent_of_train_dataset</span><span class="p">),</span> <span class="n">seed</span><span class="o">=</span><span class="mi">19</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>',
      '<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span>',
      '<span class="n">validation_test_dataset</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span>',
      '<span class="w"> </span>',
      '<span class="n">split_dataset</span> <span class="o">=</span> <span class="n">validation_test_dataset</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">train_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">validation_test_dataset</span><span class="o">.</span><span class="n">num_rows</span> <span class="o">*</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">seed</span><span class="o">=</span><span class="mi">19</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>',
      '<span class="n">validation_dataset</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span>',
      '<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span>',
      '<span class="w"> </span>',
      '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Size of the train set: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">. Size of the validation set: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">validation_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">. Size of the test set: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Size of the train set: 208491. Size of the validation set: 11583. Size of the test set: 11583',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Tokenizador">Tokenizador<a class="anchor-link" href="#Tokenizador"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 112" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Iniciamos o tokenizador e atribu√≠mos ao token de padding o de end of string</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>',
      '<span class="w"> </span>',
      '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;openai-community/gpt2&quot;</span>',
      '<span class="w"> </span>',
      '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>',
      '<span class="n">tokenizer</span><span class="o">.</span><span class="n">padding_side</span> <span class="o">=</span> <span class="s2">&quot;right&quot;</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Adicionamos os tokens especiais de in√≠cio e fim de piada</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">new_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;&amp;lt;SJ&amp;gt;&#39;</span><span class="p">,</span> <span class="s1">&#39;&amp;lt;EJ&amp;gt;&#39;</span><span class="p">]</span>   <span class="c1"># Start and end of joke tokens</span>',
      '<span class="w"> </span>',
      '<span class="n">num_added_tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">add_tokens</span><span class="p">(</span><span class="n">new_tokens</span><span class="p">)</span>',
      '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Added </span><span class="si">{</span><span class="n">num_added_tokens</span><span class="si">}</span><span class="s2"> tokens&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Added 2 tokens',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Os adicionamos ao dataset</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">joke_column</span> <span class="o">=</span> <span class="s2">&quot;Joke&quot;</span>',
      '<span class="w"> </span>',
      '<span class="k">def</span><span class="w"> </span><span class="nf">format_joke</span><span class="p">(</span><span class="n">example</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">example</span><span class="p">[</span><span class="n">joke_column</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;&amp;lt;SJ&amp;gt; &#39;</span> <span class="o">+</span> <span class="n">example</span><span class="p">[</span><span class="s1">&#39;Joke&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39; &amp;lt;EJ&amp;gt;&#39;</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">example</span>',
      '<span class="w"> </span>',
      '<span class="n">remove_columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">column</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">column_names</span> <span class="k">if</span> <span class="n">column</span> <span class="o">!=</span> <span class="n">joke_column</span><span class="p">]</span>',
      '<span class="w"> </span>',
      '<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">format_joke</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="n">remove_columns</span><span class="p">)</span>',
      '<span class="n">validation_dataset</span> <span class="o">=</span> <span class="n">validation_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">format_joke</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="n">remove_columns</span><span class="p">)</span>',
      '<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">format_joke</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="n">remove_columns</span><span class="p">)</span>',
      '<span class="n">train_dataset</span><span class="p">,</span> <span class="n">validation_dataset</span><span class="p">,</span> <span class="n">test_dataset</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '(Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;Joke&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 208491',
          '&#x7D;),',
          'Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;Joke&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 11583',
          '&#x7D;),',
          'Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;Joke&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 11583',
          '&#x7D;))',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Tokenizamos o conjunto de dados</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="n">joke_column</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="n">joke_column</span><span class="p">])</span>',
      '<span class="n">validation_dataset</span> <span class="o">=</span> <span class="n">validation_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="n">joke_column</span><span class="p">])</span>',
      '<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="n">joke_column</span><span class="p">])</span>',
      '<span class="n">train_dataset</span><span class="p">,</span> <span class="n">validation_dataset</span><span class="p">,</span> <span class="n">test_dataset</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '(Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;input_ids&#x27;, &#x27;attention_mask&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 208491',
          '&#x7D;),',
          'Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;input_ids&#x27;, &#x27;attention_mask&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 11583',
          '&#x7D;),',
          'Dataset(&#x7B;',
          '&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;input_ids&#x27;, &#x27;attention_mask&#x27;],',
          '&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 11583',
          '&#x7D;))',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Modelo">Modelo<a class="anchor-link" href="#Modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 113" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Instanciamos o modelo, atribu√≠mos o token de padding e adicionamos os novos tokens de in√≠cio de piada e fim de piada</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span>',
      '<span class="w"> </span>',
      '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>',
      '<span class="n">model</span><span class="o">.</span><span class="n">resize_token_embeddings</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">))</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Embedding(50259, 768)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Dispositivo">Dispositivo<a class="anchor-link" href="#Dispositivo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 114" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Criamos o dispositivo e passamos o modelo para o dispositivo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>',
      '<span class="w"> </span>',
      '<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>',
      '<span class="n">model</span><span class="o">.</span><span class="n">half</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '<span class="nb">print</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[

        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Conjunto de Dados do Pytorch">Conjunto de Dados do Pytorch<a class="anchor-link" href="#Conjunto de Dados do Pytorch"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 115" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Criamos um conjunto de dados do PyTorch</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dataset</span>',
      '<span class="w"> </span>',
      '<span class="k">class</span><span class="w"> </span><span class="nc">JokesDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>',
      '<span class="w">    </span><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">huggingface_dataset</span><span class="p">):</span>',
      '<span class="w">        </span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">huggingface_dataset</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">&#39;input_ids&#39;</span><span class="p">])</span>',
      '<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>',
      '<span class="w">        </span><span class="k">return</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span>',
      '<span class="w"> </span>',
      '<span class="w">    </span><span class="k">def</span><span class="w"> </span><span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>',
      '<span class="w">        </span><span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Instanciamos os conjuntos de dados de treinamento, valida√ß√£o e teste</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">train_pytorch_dataset</span> <span class="o">=</span> <span class="n">JokesDataset</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span>',
      '<span class="n">validation_pytorch_dataset</span> <span class="o">=</span> <span class="n">JokesDataset</span><span class="p">(</span><span class="n">validation_dataset</span><span class="p">)</span>',
      '<span class="n">test_pytorch_dataset</span> <span class="o">=</span> <span class="n">JokesDataset</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vamos ver um exemplo.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">train_pytorch_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>',
      '<span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">shape</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '(torch.Size([768]), torch.Size([768]))',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Pytorch Dataloader">Pytorch Dataloader<a class="anchor-link" href="#Pytorch Dataloader"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 116" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Criamos os dataloaders</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>',
      '<span class="w"> </span>',
      '<span class="n">BS</span> <span class="o">=</span> <span class="mi">28</span>',
      '<span class="w"> </span>',
      '<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_pytorch_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
      '<span class="n">validation_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">validation_pytorch_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">)</span>',
      '<span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_pytorch_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos uma amostra</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_loader</span><span class="p">))</span>',
      '<span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">shape</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '(torch.Size([28, 768]), torch.Size([28, 768]))',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Passamos isso para o modelo.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>',
      '<span class="n">output</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'odict_keys([&#x27;logits&#x27;, &#x27;past_key_values&#x27;])',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Como podemos ver, n√£o temos um valor de <code>loss</code>. Como j√° vimos, precisamos passar o <code>input_ids</code> e o <code>labels</code>.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">=</span><span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>',
      '<span class="n">output</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'odict_keys([&#x27;loss&#x27;, &#x27;logits&#x27;, &#x27;past_key_values&#x27;])',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Agora sim temos <code>loss</code></p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '80.5625',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Otimizador">Otimizador<a class="anchor-link" href="#Otimizador"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 117" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Criamos um otimizador</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AdamW</span>',
      '<span class="w"> </span>',
      '<span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>',
      '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-5</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning',
          '&#x20;&#x20;warnings.warn(',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Treinamento">Treinamento<a class="anchor-link" href="#Treinamento"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 118" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Criamos o loop de treinamento</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>',
      '<span class="w"> </span>',
      '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>',
      '<span class="w"> </span>',
      '<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">train_loss</span> <span class="o">=</span> <span class="mi">0</span>',
      '<span class="w">    </span><span class="n">progresbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">at_mask</span> <span class="ow">in</span> <span class="n">progresbar</span><span class="p">:</span>',
      '<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '<span class="w">        </span><span class="n">at_mask</span> <span class="o">=</span> <span class="n">at_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">at_mask</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">input_ids</span><span class="p">)</span>',
      '<span class="w"> </span>',
      '<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>',
      '<span class="w">        </span><span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>',
      '<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
      '<span class="w">        </span><span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>',
      '<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
      '<span class="w">        </span><span class="n">progresbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">({</span><span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()})</span>',
      '<span class="w">    </span><span class="n">train_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">progresbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">({</span><span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="n">train_loss</span><span class="p">})</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7447/7447 [51:07&amp;lt;00:00,  2.43it/s, train_loss=nan]',
          'Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7447/7447 [51:06&amp;lt;00:00,  2.43it/s, train_loss=nan]',
          'Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7447/7447 [51:07&amp;lt;00:00,  2.43it/s, train_loss=nan]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Uso do modelo">Uso do modelo<a class="anchor-link" href="#Uso do modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 119" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Testamos o modelo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">def</span><span class="w"> </span><span class="nf">generate_text</span><span class="p">(</span><span class="n">decoded_joke</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">stop_token</span><span class="o">=</span><span class="s1">&#39;&amp;lt;EJ&amp;gt;&#39;</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>',
      '<span class="w">    </span><span class="n">input_tokens</span> <span class="o">=</span> <span class="n">tokenize_function</span><span class="p">({</span><span class="s1">&#39;Joke&#39;</span><span class="p">:</span> <span class="n">decoded_joke</span><span class="p">})</span>',
      '<span class="w">    </span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_tokens</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">input_tokens</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>',
      '<span class="w">    </span><span class="n">nex_token</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">][:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>',
      '<span class="w">    </span><span class="n">nex_token_decoded</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">nex_token</span><span class="p">)</span>',
      '<span class="w">    </span><span class="n">decoded_joke</span> <span class="o">=</span> <span class="n">decoded_joke</span> <span class="o">+</span> <span class="n">nex_token_decoded</span>',
      '<span class="w">    </span><span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_new_tokens</span><span class="p">):</span>',
      '<span class="w">        </span><span class="n">nex_token</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">][:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>',
      '<span class="w">        </span><span class="n">nex_token_decoded</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">nex_token</span><span class="p">)</span>',
      '<span class="w">        </span><span class="k">if</span> <span class="n">nex_token_decoded</span> <span class="o">==</span> <span class="n">stop_token</span><span class="p">:</span>',
      '<span class="w">            </span><span class="k">break</span>',
      '<span class="w">        </span><span class="n">decoded_joke</span> <span class="o">=</span> <span class="n">decoded_joke</span> <span class="o">+</span> <span class="n">nex_token_decoded</span>',
      '<span class="w">        </span><span class="n">input_tokens</span> <span class="o">=</span> <span class="n">tokenize_function</span><span class="p">({</span><span class="s1">&#39;Joke&#39;</span><span class="p">:</span> <span class="n">decoded_joke</span><span class="p">})</span>',
      '<span class="w">        </span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_tokens</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">input_tokens</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>',
      '<span class="w">    </span><span class="k">return</span> <span class="n">decoded_joke</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">generated_text</span> <span class="o">=</span> <span class="n">generate_text</span><span class="p">(</span><span class="s2">&quot;&amp;lt;SJ&amp;gt; Why didn&#39;t the frog cross the road&quot;</span><span class="p">)</span>',
      '<span class="n">generated_text</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          '&quot;&amp;lt;SJ&amp;gt; Why didn&#x27;t the frog cross the road!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!&quot;',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
















    </div>

  </section>

</PostLayout>
