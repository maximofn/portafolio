---
import PostLayout from '@layouts/PostLayout.astro';
import CodeBlockInputCell from '@components/CodeBlockInputCell.astro';
import CodeBlockOutputCell from '@components/CodeBlockOutputCell.astro';

const { metadata_page } = await import('@portfolio/consts.json');
const { colors } = await import('@portfolio/consts.json');
const { svg_paths } = await import('@portfolio/consts.json');

const page_title = 'HuggingFace Accelerate';
const end_url = 'hugging-face-accelerate';
const description = 'Acelere seus treinamentos com HuggingFace Accelerate';
const keywords = 'hugging face, accelerate, pytorch, deep learning, machine learning, transformers';
const languaje = 'PT';
const image_path = 'https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/huggingface_accelerate.webp';
const opening_brace = '{';
const closing_brace = '}';
---

<PostLayout 
    title={page_title}
    languaje={languaje}
    description={description}
    keywords={keywords}
    author={metadata_page.author}
    theme_color={colors.background_color}
    end_url={end_url}
    image_path={image_path}
    image_width=1280
    image_height=670
    image_extension=webp
    article_date=2024-05-16+T00:00:00Z
>

  <section class="post-body">


    <aside class="post-index">
      <a class="anchor-link" href="#Instala%C3%A7%C3%A3o"><h2>Instalação</h2></a>
      <a class="anchor-link" href="#Configura%C3%A7%C3%A3o"><h2>Configuração</h2></a>
      <a class="anchor-link" href="#Treinamento"><h2>Treinamento</h2></a>
      <a class="anchor-link" href="#Otimiza%C3%A7%C3%A3o-do-treinamento"><h3>Otimização do treinamento</h3></a>
      <a class="anchor-link" href="#C%C3%B3digo-base"><h4>Código base</h4></a>
      <a class="anchor-link" href="#Script-com-a-base-de-c%C3%B3digo"><h4>Script com a base de código</h4></a>
      <a class="anchor-link" href="#C%C3%B3digo-com-acelera%C3%A7%C3%A3o"><h4>Código com aceleração</h4></a>
      <a class="anchor-link" href="#Execu%C3%A7%C3%A3o-do-processo"><h3>Execução do processo</h3></a>
      <a class="anchor-link" href="#Execu%C3%A7%C3%A3o-de-c%C3%B3digo-em-um-%C3%BAnico-processo"><h4>Execução de código em um único processo</h4></a>
      <a class="anchor-link" href="#Execu%C3%A7%C3%A3o-de-c%C3%B3digo-em-todos-os-processos"><h4>Execução de código em todos os processos</h4></a>
      <a class="anchor-link" href="#Execu%C3%A7%C3%A3o-de-c%C3%B3digo-no-processo-X"><h4>Execução de código no processo X</h4></a>
      <a class="anchor-link" href="#Sincronizar-processos"><h4>Sincronizar processos</h4></a>
      <a class="anchor-link" href="#Salvar-e-carregar-o-ditado-de-estado"><h3>Salvar e carregar o ditado de estado</h3></a>
      <a class="anchor-link" href="#Salvar-o-modelo"><h3>Salvar o modelo</h3></a>
      <a class="anchor-link" href="#Salvar-o-modelo-%22pr%C3%A9-treinado"><h3>Salvar o modelo "pré-treinado</h3></a>
      <a class="anchor-link" href="#Treinamento-em-notebooks"><h3>Treinamento em notebooks</h3></a>
      <a class="anchor-link" href="#Treinamento-em-FP16"><h3>Treinamento em FP16</h3></a>
      <a class="anchor-link" href="#Treinamento-em-BF16"><h3>Treinamento em BF16</h3></a>
      <a class="anchor-link" href="#Treinamento-em-FP8"><h3>Treinamento em FP8</h3></a>
      <a class="anchor-link" href="#Infer%C3%AAncia-de-modelo"><h2>Inferência de modelo</h2></a>
      <a class="anchor-link" href="#Uso-do-ecossistema-de-rosto-abra%C3%A7ado"><h3>Uso do ecossistema de rosto abraçado</h3></a>
      <a class="anchor-link" href="#Infer%C3%AAncia-com-pipeline."><h4>Inferência com <code>pipeline</code>.</h4></a>
      <a class="anchor-link" href="#Infer%C3%AAncia-com-AutoClass."><h4>Inferência com <code>AutoClass</code>.</h4></a>
      <a class="anchor-link" href="#Use-pytorch"><h3>Use pytorch</h3></a>
      <a class="anchor-link" href="#Como-a-acelera%C3%A7%C3%A3o-funciona-abaixo"><h3>Como a aceleração funciona abaixo</h3></a>
      <a class="anchor-link" href="#Inicializa%C3%A7%C3%A3o-de-um-modelo-vazio"><h4>Inicialização de um modelo vazio</h4></a>
      <a class="anchor-link" href="#Carregamento-de-pesos"><h4>Carregamento de pesos</h4></a>
    </aside>


    <div class="post-body-content">
      
      <section class="section-block-markdown-cell">
      <h1 id="Acelera%C3%A7%C3%A3o-do-rosto-do-abra%C3%A7o">Aceleração do rosto do abraço<a class="anchor-link" href="#Acelera%C3%A7%C3%A3o-do-rosto-do-abra%C3%A7o"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 56" src={svg_paths.link_svg_path}/></a></h1>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>O Accelerate é uma biblioteca Hugging Face que permite executar o mesmo código PyTorch em qualquer configuração distribuída, adicionando apenas quatro linhas de código.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Este caderno foi traduzido automaticamente para torná-lo acessível a mais pessoas, por favor me avise se você vir algum erro de digitação..</p>
      <h2 id="Instala%C3%A7%C3%A3o">Instalação<a class="anchor-link" href="#Instala%C3%A7%C3%A3o"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 57" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Para instalar o <code>accelerate</code> com o <code>pip</code>, basta executar:</p>
      <div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>accelerate
      </pre></div>
      <p>E com <code>conda</code>:</p>
      <div class="highlight"><pre><span></span>conda<span class="w"> </span>install<span class="w"> </span>-c<span class="w"> </span>conda-forge<span class="w"> </span>accelerate
      </pre></div>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Configura%C3%A7%C3%A3o">Configuração<a class="anchor-link" href="#Configura%C3%A7%C3%A3o"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 58" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Em todos os ambientes em que o <code>accelerate</code> está instalado, a primeira coisa a fazer é configurá-lo. Para isso, executamos em um terminal:</p>
      <div class="highlight"><pre><span></span>acelerar<span class="w"> </span>a<span class="w"> </span>configuração
      </pre></div>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">!</span>accelerate<span class="w"> </span>config',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '--------------------------------------------------------------------------------',
          'In which compute environment are you running?',
          'This machine',
          '--------------------------------------------------------------------------------',
          'multi-GPU',
          'How many different machines will you use (use more than 1 for multi-node training)? [1]: 1',
          'Should distributed operations be checked while running for errors? This can avoid timeout issues but will be slower. [yes/NO]: no',
          'Do you wish to optimize your script with torch dynamo?[yes/NO]:no',
          'Do you want to use DeepSpeed? [yes/NO]: no',
          'Do you want to use FullyShardedDataParallel? [yes/NO]: no',
          'Do you want to use Megatron-LM ? [yes/NO]: no',
          'How many GPU(s) should be used for distributed training? [1]:2',
          'What GPU(s) (by id) should be used for training on this machine as a comma-seperated list? [all]:0,1',
          '--------------------------------------------------------------------------------',
          'Do you wish to use FP16 or BF16 (mixed precision)?',
          'no',
          'accelerate configuration saved at ~/.cache/huggingface/accelerate/default_config.yaml',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>No meu caso, as respostas foram</p>
      <ul>
      <li>Em qual ambiente de computação você está executando?<ul>
      <li class="task-list-item"><input checked="" class="task-list-item-checkbox" disabled="" type="checkbox"/>"Esta máquina"</li>
      <li>[_] "AWS (Amazon SageMaker)" [_] "AWS (Amazon SageMaker)" [_] "AWS (Amazon SageMaker)"</li>
      </ul>
      </li>
      </ul>
      <blockquote>
      <p>Quero configurá-lo em meu computador</p>
      </blockquote>
      <ul>
      <li>Que tipo de máquina você está usando?<ul>
      <li>[_] multi-CPU</li>
      <li>[_] multi-XPU</li>
      <li>x] multi-GPU</li>
      <li>[_] multi-NPU</li>
      <li>[_] TPU</li>
      </ul>
      </li>
      </ul>
      <blockquote>
      <p>Como tenho 2 GPUs e quero executar código distribuído nelas, escolhi <code>multi-GPU</code>.</p>
      </blockquote>
      <ul>
      <li>Quantas máquinas diferentes você usará (use mais de uma para treinamento com vários nós)? [1]:<ul>
      <li>1</li>
      </ul>
      </li>
      </ul>
      <blockquote>
      <p>Escolhi <code>1</code> porque só vou executar em meu computador.</p>
      </blockquote>
      <ul>
      <li>As operações distribuídas devem ser verificadas durante a execução em busca de erros? Isso pode evitar problemas de tempo limite, mas será mais lento. [yes/NO]:<ul>
      <li>não</li>
      </ul>
      </li>
      </ul>
      <blockquote>
      <p>Com essa opção, você pode optar por fazer com que o <code>accelerate</code> verifique se há erros na execução, mas isso tornaria a execução mais lenta, então eu escolho <code>no</code> e, caso haja erros, altero para <code>yes</code>.</p>
      </blockquote>
      <ul>
      <li><p>Deseja otimizar seu script com o torch dynamo? [yes/NO]:</p>
      <ul>
      <li>não</li>
      </ul>
      </li>
      <li><p>Você deseja usar o FullyShardedDataParallel? [yes/NO]:</p>
      <ul>
      <li>não</li>
      </ul>
      </li>
      <li><p>Você quer usar o Megatron-LM? [sim/não]:</p>
      <ul>
      <li>não</li>
      </ul>
      </li>
      <li><p>Quantas GPUs devem ser usadas para treinamento distribuído? [1]:</p>
      </li>
      </ul>
      <blockquote>
      <p>Escolhi <code>2</code> porque tenho 2 GPUs</p>
      </blockquote>
      <ul>
      <li>Quais GPUs (por id) devem ser usadas para treinamento nesta máquina como uma lista separada por vírgulas? [all]:<ul>
      <li>0,1</li>
      </ul>
      </li>
      </ul>
      <blockquote>
      <p>Escolhi <code>0,1</code> porque quero usar as duas GPUs.</p>
      </blockquote>
      <ul>
      <li>Você deseja usar FP16 ou BF16 (precisão mista)?<ul>
      <li>x] não</li>
      <li>[_] fp16</li>
      <li>[_] bf16</li>
      <li>[_] fp8</li>
      </ul>
      </li>
      </ul>
      <blockquote>
      <p>No momento, escolhi <code>no</code>, pois, para simplificar o código, quando não estivermos usando o <code>accelerate</code>, treinaremos em fp32, mas o ideal seria usar fp16.</p>
      </blockquote>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>A configuração será armazenada em <code>~/.cache/huggingface/accelerate/default_config.yaml</code> e poderá ser modificada a qualquer momento. Vamos ver o que há dentro dele</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">!</span>cat<span class="w"> </span>~/.cache/huggingface/accelerate/default_config.yaml',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'compute_environment: LOCAL_MACHINE',
          'debug: false',
          'distributed_type: MULTI_GPU',
          'downcast_bf16: \'no\'',
          'gpu_ids: 0,1',
          'machine_rank: 0',
          'main_training_function: main',
          'mixed_precision: fp16',
          'num_machines: 1',
          'num_processes: 2',
          'rdzv_backend: static',
          'same_network: true',
          'tpu_env: []',
          'tpu_use_cluster: false',
          'tpu_use_sudo: false',
          'use_cpu: false',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Outra maneira de ver a configuração que temos é executá-la em um terminal:</p>
      <div class="highlight"><pre><span></span>acelerar<span class="w"> </span>o<span class="w"> </span>ambiente
      </pre></div>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">!</span>accelerate<span class="w"> </span>env',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Copy-and-paste the text below in your GitHub issue',
          '- `Accelerate` version: 0.28.0',
          '- Platform: Linux-5.15.0-105-generic-x86_64-with-glibc2.31',
          '- Python version: 3.11.8',
          '- Numpy version: 1.26.4',
          '- PyTorch version (GPU?): 2.2.1+cu121 (True)',
          '- PyTorch XPU available: False',
          '- PyTorch NPU available: False',
          '- System RAM: 31.24 GB',
          '- GPU type: NVIDIA GeForce RTX 3090',
          '- `Accelerate` default config:',
          '	- compute_environment: LOCAL_MACHINE',
          '	- distributed_type: MULTI_GPU',
          '	- mixed_precision: fp16',
          '	- use_cpu: False',
          '	- debug: False',
          '	- num_processes: 2',
          '	- machine_rank: 0',
          '	- num_machines: 1',
          '	- gpu_ids: 0,1',
          '	- rdzv_backend: static',
          '	- same_network: True',
          '	- main_training_function: main',
          '	- downcast_bf16: no',
          '	- tpu_use_cluster: False',
          '	- tpu_use_sudo: False',
          '	- tpu_env: []',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Depois de configurar o <code>accelerate</code>, podemos testar se fizemos tudo certo executando-o em um terminal:</p>
      <div class="highlight"><pre><span></span>teste<span class="w"> </span>de<span class="w"> </span>aceleração
      </pre></div>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">!</span>accelerate<span class="w"> </span>test',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Running:  accelerate-launch ~/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/test_utils/scripts/test_script.py',
          'stdout: **Initialization**',
          'stdout: Testing, testing. 1, 2, 3.',
          'stdout: Distributed environment: DistributedType.MULTI_GPU  Backend: nccl',
          'stdout: Num processes: 2',
          'stdout: Process index: 0',
          'stdout: Local process index: 0',
          'stdout: Device: cuda:0',
          'stdout: ',
          'stdout: Mixed precision type: fp16',
          'stdout: ',
          'stdout: Distributed environment: DistributedType.MULTI_GPU  Backend: nccl',
          'stdout: Num processes: 2',
          'stdout: Process index: 1',
          'stdout: Local process index: 1',
          'stdout: Device: cuda:1',
          'stdout: ',
          'stdout: Mixed precision type: fp16',
          'stdout: ',
          'stdout: ',
          'stdout: **Test process execution**',
          'stdout: ',
          'stdout: **Test split between processes as a list**',
          'stdout: ',
          'stdout: **Test split between processes as a dict**',
          'stdout: ',
          'stdout: **Test split between processes as a tensor**',
          'stdout: ',
          'stdout: **Test random number generator synchronization**',
          'stdout: All rng are properly synched.',
          'stdout: ',
          'stdout: **DataLoader integration test**',
          'stdout: 0 1 tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,',
          'stdout:         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,',
          'stdout:         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,',
          'stdout:         54, 55, 56, 57, 58, 59, 60, 61, 62, 63], device=\'cuda:1\') &lt;class \'accelerate.data_loader.DataLoaderShard\'&gt;',
          'stdout: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,',
          'stdout:         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,',
          'stdout:         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,',
          'stdout:         54, 55, 56, 57, 58, 59, 60, 61, 62, 63], device=\'cuda:0\') &lt;class \'accelerate.data_loader.DataLoaderShard\'&gt;',
          'stdout: Non-shuffled dataloader passing.',
          'stdout: Shuffled dataloader passing.',
          'stdout: Non-shuffled central dataloader passing.',
          'stdout: Shuffled central dataloader passing.',
          'stdout: ',
          'stdout: **Training integration test**',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Training yielded the same results on one CPU or distributed setup with no batch split.',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Training yielded the same results on one CPU or distributes setup with batch split.',
          'stdout: FP16 training check.',
          'stdout: FP16 training check.',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Keep fp32 wrapper check.',
          'stdout: Keep fp32 wrapper check.',
          'stdout: BF16 training check.',
          'stdout: BF16 training check.',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: ',
          'stdout: Training yielded the same results on one CPU or distributed setup with no batch split.',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: FP16 training check.',
          'stdout: Training yielded the same results on one CPU or distributes setup with batch split.',
          'stdout: FP16 training check.',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Keep fp32 wrapper check.',
          'stdout: Keep fp32 wrapper check.',
          'stdout: BF16 training check.',
          'stdout: BF16 training check.',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32',
          'stdout: ',
          'stdout: **Breakpoint trigger test**',
          'Test is a success! You are ready for your distributed training!',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos que ele termina dizendo `O teste foi um sucesso! Você está pronto para seu treinamento distribuído, portanto, tudo está correto.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Treinamento">Treinamento<a class="anchor-link" href="#Treinamento"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 59" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Otimiza%C3%A7%C3%A3o-do-treinamento">Otimização do treinamento<a class="anchor-link" href="#Otimiza%C3%A7%C3%A3o-do-treinamento"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 60" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <h4 id="C%C3%B3digo-base">Código base<a class="anchor-link" href="#C%C3%B3digo-base"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 61" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Primeiro, criaremos um código de treinamento básico e, em seguida, o otimizaremos para ver como ele é feito e como melhora.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Primeiro, vamos procurar um conjunto de dados; no meu caso, usarei o conjunto de dados <a href="https://huggingface.co/datasets/tweet_eval" target="_blank" rel="nofollow noreferrer">tweet_eval</a>, que é um conjunto de dados de classificação de tweets; em particular, farei o download do subconjunto <code>emoji</code>, que classifica tweets com emoticons.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">dataset</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'DatasetDict({',
          '    train: Dataset({',
          '        features: [\'text\', \'label\'],',
          '        num_rows: 45000',
          '    })',
          '    test: Dataset({',
          '        features: [\'text\', \'label\'],',
          '        num_rows: 50000',
          '    })',
          '    validation: Dataset({',
          '        features: [\'text\', \'label\'],',
          '        num_rows: 5000',
          '    })',
          '})',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'DatasetInfo(description=\'\', citation=\'\', homepage=\'\', license=\'\', features={\'text\': Value(dtype=\'string\', id=None), \'label\': ClassLabel(names=[\'❤\', \'😍\', \'😂\', \'💕\', \'🔥\', \'😊\', \'😎\', \'✨\', \'💙\', \'😘\', \'📷\', \'🇺🇸\', \'☀\', \'💜\', \'😉\', \'💯\', \'😁\', \'🎄\', \'📸\', \'😜\'], id=None)}, post_processed=None, supervised_keys=None, task_templates=None, builder_name=\'parquet\', dataset_name=\'tweet_eval\', config_name=\'emoji\', version=0.0.0, splits={\'train\': SplitInfo(name=\'train\', num_bytes=3808792, num_examples=45000, shard_lengths=None, dataset_name=\'tweet_eval\'), \'test\': SplitInfo(name=\'test\', num_bytes=4262151, num_examples=50000, shard_lengths=None, dataset_name=\'tweet_eval\'), \'validation\': SplitInfo(name=\'validation\', num_bytes=396704, num_examples=5000, shard_lengths=None, dataset_name=\'tweet_eval\')}, download_checksums={\'hf://datasets/tweet_eval@b3a375baf0f409c77e6bc7aa35102b7b3534f8be/emoji/train-00000-of-00001.parquet\': {\'num_bytes\': 2609973, \'checksum\': None}, \'hf://datasets/tweet_eval@b3a375baf0f409c77e6bc7aa35102b7b3534f8be/emoji/test-00000-of-00001.parquet\': {\'num_bytes\': 3047341, \'checksum\': None}, \'hf://datasets/tweet_eval@b3a375baf0f409c77e6bc7aa35102b7b3534f8be/emoji/validation-00000-of-00001.parquet\': {\'num_bytes\': 281994, \'checksum\': None}}, download_size=5939308, post_processing_size=None, dataset_size=8467647, size_in_bytes=14406955)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vamos dar uma olhada nas classes</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="nb">print</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '[\'❤\', \'😍\', \'😂\', \'💕\', \'🔥\', \'😊\', \'😎\', \'✨\', \'💙\', \'😘\', \'📷\', \'🇺🇸\', \'☀\', \'💜\', \'😉\', \'💯\', \'😁\', \'🎄\', \'📸\', \'😜\']',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>E o número de classes</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">num_classes</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '20',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos que o conjunto de dados tem 20 classes</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos dar uma olhada na sequência máxima de cada divisão</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">max_len_train</span> <span class="o">=</span> <span class="mi">0</span>',
          '<span class="n">max_len_val</span> <span class="o">=</span> <span class="mi">0</span>',
          '<span class="n">max_len_test</span> <span class="o">=</span> <span class="mi">0</span>',
          '',
          '<span class="n">split</span> <span class="o">=</span> <span class="s2">"train"</span>',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">])):</span>',
          '    <span class="n">len_i</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s2">"text"</span><span class="p">])</span>',
          '    <span class="k">if</span> <span class="n">len_i</span> <span class="o">&gt;</span> <span class="n">max_len_train</span><span class="p">:</span>',
          '        <span class="n">max_len_train</span> <span class="o">=</span> <span class="n">len_i</span>',
          '<span class="n">split</span> <span class="o">=</span> <span class="s2">"validation"</span>',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">])):</span>',
          '    <span class="n">len_i</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s2">"text"</span><span class="p">])</span>',
          '    <span class="k">if</span> <span class="n">len_i</span> <span class="o">&gt;</span> <span class="n">max_len_val</span><span class="p">:</span>',
          '        <span class="n">max_len_val</span> <span class="o">=</span> <span class="n">len_i</span>',
          '<span class="n">split</span> <span class="o">=</span> <span class="s2">"test"</span>',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">])):</span>',
          '    <span class="n">len_i</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s2">"text"</span><span class="p">])</span>',
          '    <span class="k">if</span> <span class="n">len_i</span> <span class="o">&gt;</span> <span class="n">max_len_test</span><span class="p">:</span>',
          '        <span class="n">max_len_test</span> <span class="o">=</span> <span class="n">len_i</span>',
          '',
          '<span class="n">max_len_train</span><span class="p">,</span> <span class="n">max_len_val</span><span class="p">,</span> <span class="n">max_len_test</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '(142, 139, 167)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Portanto, definimos a sequência máxima em geral como 130 para a tokenização.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>






      
      <section class="section-block-markdown-cell">
      <p>Estamos interessados no conjunto de dados tokenizado, não nas sequências brutas, portanto, criamos um tokenizador</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>',
      '      ',
      '      <span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
      '      <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>









      
      <section class="section-block-markdown-cell">
      <p>Criamos uma função de tokenização</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>',
      '      ',
      '      <span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
      '      <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '<span></span><span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
      '          <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>







      
      <section class="section-block-markdown-cell">
      <p>E agora vamos tokenizar o conjunto de dados</p>
      </section>
      
      <section class="section-block-code-cell-">
      <div class="input-code">
      <div class="highlight hl-ipython3">
<pre><span></span><span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{opening_brace}</span>
          <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>
          <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>
          <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>
      <span class="p">{closing_brace}</span>
      </pre></div>
      </div>
      <div class="output-wrapper">
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-text-output-subarea">
      <pre>Map:   0%|          | 0/45000 [00:00&lt;?, ? examples/s]</pre>
      </div>
      </div>
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-text-output-subarea">
      <pre>Map:   0%|          | 0/5000 [00:00&lt;?, ? examples/s]</pre>
      </div>
      </div>
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-text-output-subarea">
      <pre>Map:   0%|          | 0/50000 [00:00&lt;?, ? examples/s]</pre>
      </div>
      </div>
      </div>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Como podemos ver agora, temos os tokens (<code>input_ids</code>) e as máscaras de atenção (<code>attention_mask</code>), mas vamos ver que tipo de dados temos.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '</span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '</span><span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '</span><span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '</span><span class="nb">type</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">"input_ids"</span><span class="p">]),</span> <span class="nb">type</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">"attention_mask"</span><span class="p">]),</span> <span class="nb">type</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">"label"</span><span class="p">])</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Map:   0%|          | 0/45000 [00:00&lt;?, ? examples/s]',
          '(list, list, int)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="nb">type</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">"label"</span><span class="p">]),</span> <span class="nb">type</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">"input_ids"</span><span class="p">]),</span> <span class="nb">type</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">"attention_mask"</span><span class="p">])</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '(torch.Tensor, torch.Tensor, torch.Tensor)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Criamos um carregador de dados</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
      '      <span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
      '      <span class="n">BS</span> <span class="o">=</span> <span class="mi">64</span>',
      '      ',
      '      <span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
      '          <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '          <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '          <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '      <span class="p">}</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>














      
      <section class="section-block-markdown-cell">
      <p>Carregamos o modelo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
      '      <span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
      '      <span class="n">BS</span> <span class="o">=</span> <span class="mi">64</span>',
      '      ',
      '      <span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
      '          <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '          <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '          <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '      <span class="p">}</span>',
      '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span>',
      '      ',
      '      <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>








      
      <section class="section-block-markdown-cell">
      <p>Vamos ver como é o modelo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">64</span>',
          '',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '</span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '</span><span class="n">model</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'RobertaForSequenceClassification(',
          '  (roberta): RobertaModel(',
          '    (embeddings): RobertaEmbeddings(',
          '      (word_embeddings): Embedding(50265, 768, padding_idx=1)',
          '      (position_embeddings): Embedding(514, 768, padding_idx=1)',
          '      (token_type_embeddings): Embedding(1, 768)',
          '      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)',
          '      (dropout): Dropout(p=0.1, inplace=False)',
          '    )',
          '    (encoder): RobertaEncoder(',
          '      (layer): ModuleList(',
          '        (0-11): 12 x RobertaLayer(',
          '          (attention): RobertaAttention(',
          '            (self): RobertaSelfAttention(',
          '              (query): Linear(in_features=768, out_features=768, bias=True)',
          '              (key): Linear(in_features=768, out_features=768, bias=True)',
          '              (value): Linear(in_features=768, out_features=768, bias=True)',
          '              (dropout): Dropout(p=0.1, inplace=False)',
          '            )',
          '            (output): RobertaSelfOutput(',
          '              (dense): Linear(in_features=768, out_features=768, bias=True)',
          '              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)',
          '              (dropout): Dropout(p=0.1, inplace=False)',
          '            )',
          '          )',
          '          (intermediate): RobertaIntermediate(',
          '            (dense): Linear(in_features=768, out_features=3072, bias=True)',
          '            (intermediate_act_fn): GELUActivation()',
          '          )',
          '          (output): RobertaOutput(',
          '            (dense): Linear(in_features=3072, out_features=768, bias=True)',
          '            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)',
          '            (dropout): Dropout(p=0.1, inplace=False)',
          '          )',
          '        )',
          '      )',
          '    )',
          '  )',
          '  (classifier): RobertaClassificationHead(',
          '    (dense): Linear(in_features=768, out_features=768, bias=True)',
          '    (dropout): Dropout(p=0.1, inplace=False)',
          '    (out_proj): Linear(in_features=768, out_features=2, bias=True)',
          '  )',
          ')',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vamos dar uma olhada em sua última camada</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Linear(in_features=768, out_features=2, bias=True)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">out_features</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '(768, 2)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vimos que nosso conjunto de dados tem 20 classes, mas esse modelo foi treinado para 2 classes, portanto, temos que modificar a última camada</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Linear(in_features=768, out_features=20, bias=True)',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Agora é</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Agora criamos uma função de perda</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>






      
      <section class="section-block-markdown-cell">
      <p>Um otimizador</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
      '<span></span><span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
      '      ',
      '      <span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>








      
      <section class="section-block-markdown-cell">
      <p>E, finalmente, uma métrica</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
      '<span></span><span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
      '      ',
      '      <span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
      '<span></span><span class="kn">import</span> <span class="nn">evaluate</span>',
      '      ',
      '      <span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>








      
      <section class="section-block-markdown-cell">
      <p>Vamos verificar se está tudo certo com uma amostra</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
      '<span></span><span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
      '      ',
      '      <span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
      '<span></span><span class="kn">import</span> <span class="nn">evaluate</span>',
      '      ',
      '      <span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
      '<span></span><span class="n">sample</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]))</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>






      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '</span><span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '</span><span class="kn">import</span> <span class="nn">evaluate</span>',
          '',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '</span><span class="n">sample</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]))</span>',
          '</span><span class="n">sample</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">sample</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '(torch.Size([64, 130]), torch.Size([64, 130]))',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Agora, colocamos essa amostra no modelo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">"cuda"</span><span class="p">)</span>',
          '<span class="n">ouputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">sample</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">"cuda"</span><span class="p">),</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">sample</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">"cuda"</span><span class="p">))</span>',
          '<span class="n">ouputs</span><span class="o">.</span><span class="n">logits</span><span class="o">.</span><span class="n">shape</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'torch.Size([64, 20])',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos que o modelo produz 64 lotes, o que é bom, porque definimos <code>BS = 20</code> e cada um com 20 saídas, o que é bom porque alteramos o modelo para produzir 20 valores.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Obtemos aquele com o valor mais alto</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">ouputs</span><span class="o">.</span><span class="n">logits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '<span class="n">predictions</span><span class="o">.</span><span class="n">shape</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'torch.Size([64])',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Obtemos a perda</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">ouputs</span><span class="o">.</span><span class="n">logits</span><span class="p">,</span> <span class="n">sample</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">"cuda"</span><span class="p">))</span>',
          '<span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '2.9990389347076416',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>E a precisão</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">sample</span><span class="p">[</span><span class="s2">"label"</span><span class="p">])[</span><span class="s2">"accuracy"</span><span class="p">]</span>',
          '<span class="n">accuracy</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '0.015625',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Agora podemos criar um pequeno loop de treinamento</p>
      </section>
      
      <section class="section-block-code-cell-">
      <div class="input-code">
      <div class="highlight hl-ipython3">
<pre><span></span><span class="kn">from</span> <span class="nn">fastprogress.fastprogress</span> <span class="kn">import</span> <span class="n">master_bar</span><span class="p">,</span> <span class="n">progress_bar</span>
      
      <span class="n">epochs</span> <span class="o">=</span> <span class="mi">1</span>
      <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>
      <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
      
      <span class="n">master_progress_bar</span> <span class="o">=</span> <span class="n">master_bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">))</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">master_progress_bar</span><span class="p">:</span>
          <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
          <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>
          <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>
              <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
      
              <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
              <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
              <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
      
              <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
              <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">'logits'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
              <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">'loss: </span><span class="si">{opening_brace}</span><span class="n">loss</span><span class="si">{closing_brace}</span><span class="s1">'</span>
      
              <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
              <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
      
          <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
          <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>
          <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>
              <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
              <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
              <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
      
              <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                  <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
              <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">'logits'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
      
              <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
          <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
          
          <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">main_bar</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"Validation accuracy: </span><span class="si">{opening_brace}</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">]</span><span class="si">{closing_brace}</span><span class="se">\n</span><span class="s2">"</span>
      </pre></div>
      </div>
      <div class="output-wrapper">
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-html-rendered-html-output-subarea">
      <style>
          /* Turns off some styling */
          progress {
              /* gets rid of default border in Firefox and Opera. */
              border: none;
              /* Needs to be in here for Safari polyfill so background images work as expected. */
              background-size: auto;
          }
          progress:not([value]), progress:not([value])::-webkit-progress-bar {
              background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
          }
          .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
              background: #F44336;
          }
      </style>
      </div>
      </div>
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-html-rendered-html-output-subarea"></div>
      </div>
      </div>
      </section>
      
      <section class="section-block-markdown-cell">
      <h4 id="Script-com-a-base-de-c%C3%B3digo">Script com a base de código<a class="anchor-link" href="#Script-com-a-base-de-c%C3%B3digo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 62" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>A maior parte da documentação do <code>accelerate</code> explica como usar o <code>accelerate</code> com scripts, portanto, faremos isso por enquanto e explicaremos como fazer isso com um notebook no final.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Primeiro, vamos criar uma pasta na qual salvaremos os scripts.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span> <span class="nn">fastprogress.fastprogress</span> <span class="kn">import</span> <span class="n">master_bar</span><span class="p">,</span> <span class="n">progress_bar</span>',
      '      ',
      '      <span class="n">epochs</span> <span class="o">=</span> <span class="mi">1</span>',
      '      <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>',
      '      <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '      ',
      '      <span class="n">master_progress_bar</span> <span class="o">=</span> <span class="n">master_bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">))</span>',
      '      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">master_progress_bar</span><span class="p">:</span>',
      '          <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '          <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
      '          <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
      '              <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
      '      ',
      '              <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '              <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '              <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '      ',
      '              <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '              <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
      '              <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">\'loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s1">\'</span>',
      '      ',
      '              <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>',
      '              <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
      '      ',
      '          <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
      '          <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
      '          <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
      '              <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '              <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '              <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
      '      ',
      '              <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
      '                  <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '              <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
      '      ',
      '              <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
      '          <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
      '          ',
      '          <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">main_bar</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"Validation accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span>',
      '<span></span><span class="o">!</span>mkdir<span class="w"> </span>accelerate_scripts',
        ]}
        languaje='python'
      ></CodeBlockInputCell>






      
      <section class="section-block-markdown-cell">
      <p>Agora escrevemos o código base em um script</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">fastprogress.fastprogress</span> <span class="kn">import</span> <span class="n">master_bar</span><span class="p">,</span> <span class="n">progress_bar</span>',
          '',
          '<span class="n">epochs</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '',
          '<span class="n">master_progress_bar</span> <span class="o">=</span> <span class="n">master_bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">))</span>',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">master_progress_bar</span><span class="p">:</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '        <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">\'loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s1">\'</span>',
          '',
          '        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '    ',
          '    <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">main_bar</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"Validation accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="se">\\n</span><span class="s2">"</span>',
          '</span><span class="o">!</span>mkdir<span class="w"> </span>accelerate_scripts',
          '</span><span class="o">%%writefile</span> accelerate_scripts/01_code_base.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">from</span> <span class="nn">fastprogress.fastprogress</span> <span class="kn">import</span> <span class="n">master_bar</span><span class="p">,</span> <span class="n">progress_bar</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">64</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '',
          '<span class="n">master_progress_bar</span> <span class="o">=</span> <span class="n">master_bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">))</span>',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">master_progress_bar</span><span class="p">:</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '        <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">\'loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s1">\'</span>',
          '',
          '        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '    ',
          '    <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">main_bar</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"Validation accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="se">\\n</span><span class="s2">"</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/01_code_base.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>E agora vamos executá-lo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%time</span>',
          '',
          '<span class="err">!</span><span class="n">python</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">01</span><span class="n">_code_base</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Accuracy = 0.2112                                                               ',
          'CPU times: user 2.12 s, sys: 391 ms, total: 2.51 s',
          'Wall time: 3min 36s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Em meu computador, levou cerca de 3 minutos e meio.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h4 id="C%C3%B3digo-com-acelera%C3%A7%C3%A3o">Código com aceleração<a class="anchor-link" href="#C%C3%B3digo-com-acelera%C3%A7%C3%A3o"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 63" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Agora vamos substituir alguns itens</p>
      <ul>
      <li>Primeiro, importamos o <code>Accelerator</code> e o inicializamos.</li>
      </ul>
      <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>
      <span class="n">acelerador</span> <span class="o">=</span> <span class="n">Acelerador</span><span class="p">()</span>
      </pre></div>
      <ul>
      <li>Não fazemos mais o típico</li>
      </ul>
      <div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>
      </pre></div>
      <ul>
      <li>Em vez disso, deixamos o <code>accelerate</code> escolher o dispositivo por meio de</li>
      </ul>
      <div class="highlight"><pre><span></span><span class="n">dispositivo</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>
      </pre></div>
      <ul>
      <li>Passamos os elementos relevantes para treinamento por meio do método <code>prepare</code> e não fazemos mais <code>model.to(device)</code>.</li>
      </ul>
      <div class="highlight"><pre><span></span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">preprare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>
      </pre></div>
      <ul>
      <li><p>Não enviamos mais os dados e o modelo para a GPU com <code>.to(device)</code>, pois o <code>accelerate</code> cuidou disso com o método <code>prepare</code>.</p>
      </li>
      <li><p>Em vez de fazer a retropropagação com <code>loss.backward()</code>, deixamos que o <code>accelerate</code> faça isso com <code>loss.backward()</code>.</p>
      </li>
      </ul>
      <div class="highlight"><pre><span></span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
      </pre></div>
      <ul>
      <li>Ao calcular a métrica no loop de validação, precisamos coletar os valores de todos os pontos, caso estejamos fazendo um treinamento distribuído.</li>
      </ul>
      <div class="highlight"><pre><span></span><span class="n">previsões</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">previsões</span><span class="p">)</span>
      </pre></div>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/02_accelerate_base_code.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">from</span> <span class="nn">fastprogress.fastprogress</span> <span class="kn">import</span> <span class="n">master_bar</span><span class="p">,</span> <span class="n">progress_bar</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">64</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="n">master_progress_bar</span> <span class="o">=</span> <span class="n">master_bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">))</span>',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">master_progress_bar</span><span class="p">:</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '        <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">\'loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s1">\'</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"End of training epoch </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">, outputs[\'logits\'].shape: </span><span class="si">{</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, labels.shape: </span><span class="si">{</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"End of validation epoch </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">, outputs[\'logits\'].shape: </span><span class="si">{</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, labels.shape: </span><span class="si">{</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '    ',
          '    <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">main_bar</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"Validation accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="se">\\n</span><span class="s2">"</span>',
          '',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/02_accelerate_base_code.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Se você notar que adicionei essas duas linhas <code>print(f "End of training epoch {opening_brace}i{closing_brace}, outputs['logits'].shape: {opening_brace}outputs['logits'].shape{closing_brace}, labels.shape: {opening_brace}labels.shape{closing_brace}")</code> e a linha <code>print(f "End of validation epoch {opening_brace}i{closing_brace}, outputs['logits'].shape: {opening_brace}outputs['logits'].shape{closing_brace}, labels.shape: {opening_brace}labels.shape{closing_brace}")</code>, eu as adicionei de propósito porque elas revelarão algo muito importante</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Agora vamos executá-lo. Para executar os scripts do <code>accelerate</code>, usamos o comando <code>accelerate launch</code>.</p>
      <div class="highlight"><pre><span></span>acelerar<span class="w"> </span>o<span class="w"> </span>lançamento<span class="w"> </span><span class="k">do</span><span class="w"> </span>script.py
      </pre></div>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%time</span>',
          '',
          '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">02</span><span class="n">_accelerate_base_code</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'End of training epoch 0, outputs[\'logits\'].shape: torch.Size([64, 20]), labels.shape: torch.Size([64])',
          'End of training epoch 0, outputs[\'logits\'].shape: torch.Size([64, 20]), labels.shape: torch.Size([64])',
          'End of validation epoch 0, outputs[\'logits\'].shape: torch.Size([64, 20]), labels.shape: torch.Size([8])',
          'Accuracy = 0.206',
          'End of validation epoch 0, outputs[\'logits\'].shape: torch.Size([64, 20]), labels.shape: torch.Size([8])',
          'Accuracy = 0.206',
          'CPU times: user 1.6 s, sys: 272 ms, total: 1.88 s',
          'Wall time: 2min 37s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vemos que antes levava cerca de 3 minutos e meio e agora leva cerca de 2 minutos e meio. Uma melhora significativa. Além disso, se observarmos as impressões, veremos que elas foram impressas duas vezes.</p>
      <p>E como isso é possível? Porque o <code>accelerate</code> paralelizou o treinamento nas duas GPUs que tenho, de modo que ele ficou muito mais rápido.</p>
      <p>Além disso, quando executei o primeiro script, ou seja, quando não usei o <code>accelerate</code>, a GPU estava quase cheia, enquanto que quando executei o segundo, ou seja, o que usava o <code>accelerate</code>, as duas GPUs foram muito pouco usadas, portanto, podemos aumentar o tamanho do lote para tentar preencher ambas.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/03_accelerate_base_code_more_bs.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">from</span> <span class="nn">fastprogress.fastprogress</span> <span class="kn">import</span> <span class="n">master_bar</span><span class="p">,</span> <span class="n">progress_bar</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="n">master_progress_bar</span> <span class="o">=</span> <span class="n">master_bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">))</span>',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">master_progress_bar</span><span class="p">:</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '        <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">\'loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s1">\'</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '    ',
          '    <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">main_bar</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"Validation accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="se">\\n</span><span class="s2">"</span>',
          '',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/03_accelerate_base_code_more_bs.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Removi as impressões extras, pois já vimos que o código está sendo executado em ambas as GPUs e aumentei o tamanho do lote de 64 para 128.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%time</span>',
          '',
          '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">03</span><span class="n">_accelerate_base_code_more_bs</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Accuracy = 0.1052                                                               ',
          'Accuracy = 0.1052',
          'CPU times: user 1.41 s, sys: 180 ms, total: 1.59 s',
          'Wall time: 2min 22s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>O aumento do tamanho do lote reduziu o tempo de execução em alguns segundos.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Execu%C3%A7%C3%A3o-do-processo">Execução do processo<a class="anchor-link" href="#Execu%C3%A7%C3%A3o-do-processo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 64" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <h4 id="Execu%C3%A7%C3%A3o-de-c%C3%B3digo-em-um-%C3%BAnico-processo">Execução de código em um único processo<a class="anchor-link" href="#Execu%C3%A7%C3%A3o-de-c%C3%B3digo-em-um-%C3%BAnico-processo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 65" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Anteriormente, vimos que o <code>print</code> foi impresso duas vezes, isso ocorre porque o <code>accelerate</code> cria tantos processos quanto os dispositivos em que o código é executado; no meu caso, ele cria dois processos porque tenho duas GPUs.</p>
      <p>No entanto, nem todo código deve ser executado em todos os processos, por exemplo, o <code>print</code> torna o código muito lento para ser executado várias vezes, se os pontos de verificação forem salvos, eles serão salvos duas vezes etc.</p>
      <p>Para executar parte de um código em um único processo, é necessário encapsulá-lo em uma função e decorá-la com <code>accelerator.on_local_main_process</code>. Por exemplo, no código a seguir, você verá que criei a seguinte função</p>
      <div class="highlight"><pre><span></span><span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>
      <span class="k">def</span> <span class="nf">print_something</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>
          <span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>
      </pre></div>
      <p>Outra opção é colocar o código dentro de um <code>if accelerator.is_local_main_process</code>, como o código a seguir</p>
      <div class="highlight"><pre><span></span><span class="n">se</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">:</span>
          <span class="nb">print</span><span class="p">(</span><span class="s2">"Algo"</span><span class="p">)</span>
      </pre></div>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/04_accelerate_base_code_some_code_in_one_process.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">from</span> <span class="nn">fastprogress.fastprogress</span> <span class="kn">import</span> <span class="n">master_bar</span><span class="p">,</span> <span class="n">progress_bar</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>',
          '<span class="k">def</span> <span class="nf">print_something</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="n">master_progress_bar</span> <span class="o">=</span> <span class="n">master_bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">))</span>',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">master_progress_bar</span><span class="p">:</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '        <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">\'loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s1">\'</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '    ',
          '    <span class="n">master_progress_bar</span><span class="o">.</span><span class="n">main_bar</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"Validation accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="se">\\n</span><span class="s2">"</span>',
          '',
          '<span class="c1"># print(f"Accuracy = {accuracy[\'accuracy\']}")</span>',
          '<span class="n">print_something</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">:</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/04_accelerate_base_code_some_code_in_one_process.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vamos executá-lo e ver</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%time</span>',
          '',
          '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">04</span><span class="n">_accelerate_base_code_some_code_in_one_process</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Accuracy = 0.2098                                                               ',
          'End of script with 0.2098 accuracy',
          'CPU times: user 1.38 s, sys: 197 ms, total: 1.58 s',
          'Wall time: 2min 22s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Agora, a impressão foi feita apenas uma vez</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>No entanto, embora você não veja muito, as barras de progresso são executadas em cada processo.</p>
      <p>Não encontrei uma maneira de contornar isso com as barras de progresso <code>fastprogress</code>, mas encontrei com as barras de progresso <code>tqdm</code>, portanto, substituirei as barras de progresso <code>fastprogress</code> pelas barras de progresso <code>tqdm</code> e, para que sejam executadas em um único processo, adicionarei o argumento <code>disable=not accelerator.is_local_main_process</code>.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/05_accelerate_base_code_some_code_in_one_process.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">import</span> <span class="nn">tqdm</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>',
          '<span class="k">def</span> <span class="nf">print_something</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="c1"># progress_bar_train = progress_bar(dataloader["train"], parent=master_progress_bar)</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '        <span class="c1"># master_progress_bar.child.comment = f\'loss: {loss}\'</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="c1"># progress_bar_validation = progress_bar(dataloader["validation"], parent=master_progress_bar)</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '    ',
          '<span class="c1"># print(f"Accuracy = {accuracy[\'accuracy\']}")</span>',
          '<span class="n">print_something</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">:</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/05_accelerate_base_code_some_code_in_one_process.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%time</span>',
          '',
          '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">05</span><span class="n">_accelerate_base_code_some_code_in_one_process</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '100%|█████████████████████████████████████████| 176/176 [02:01&lt;00:00,  1.45it/s]',
          '100%|███████████████████████████████████████████| 20/20 [00:06&lt;00:00,  3.30it/s]',
          'Accuracy = 0.2166',
          'End of script with 0.2166 accuracy',
          'CPU times: user 1.33 s, sys: 195 ms, total: 1.52 s',
          'Wall time: 2min 22s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Mostramos um exemplo de como imprimir em um único processo, e essa foi uma maneira de executar processos em um único processo. Mas se você quiser imprimir em um único processo, poderá usar o método <code>print</code> do <code>accelerate</code>. Vejamos o mesmo exemplo anterior com esse método</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/06_accelerate_base_code_print_one_process.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">import</span> <span class="nn">tqdm</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="c1"># progress_bar_train = progress_bar(dataloader["train"], parent=master_progress_bar)</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '        <span class="c1"># master_progress_bar.child.comment = f\'loss: {loss}\'</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="c1"># progress_bar_validation = progress_bar(dataloader["validation"], parent=master_progress_bar)</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '    ',
          '<span class="c1"># print(f"Accuracy = {accuracy[\'accuracy\']}")</span>',
          '<span class="n">accelerator</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">:</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Writing accelerate_scripts/06_accelerate_base_code_print_one_process.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Nós o executamos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%time</span>',
          '',
          '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">06</span><span class="n">_accelerate_base_code_print_one_process</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Map: 100%|██████████████████████| 45000/45000 [00:02&lt;00:00, 15433.52 examples/s]',
          'Map: 100%|████████████████████████| 5000/5000 [00:00&lt;00:00, 11406.61 examples/s]',
          'Map: 100%|██████████████████████| 45000/45000 [00:02&lt;00:00, 15036.87 examples/s]',
          'Map: 100%|██████████████████████| 50000/50000 [00:03&lt;00:00, 14932.76 examples/s]',
          'Map: 100%|██████████████████████| 50000/50000 [00:03&lt;00:00, 14956.60 examples/s]',
          '100%|█████████████████████████████████████████| 176/176 [02:00&lt;00:00,  1.46it/s]',
          '100%|███████████████████████████████████████████| 20/20 [00:05&lt;00:00,  3.33it/s]',
          'Accuracy = 0.2134',
          'End of script with 0.2134 accuracy',
          'CPU times: user 1.4 s, sys: 189 ms, total: 1.59 s',
          'Wall time: 2min 27s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h4 id="Execu%C3%A7%C3%A3o-de-c%C3%B3digo-em-todos-os-processos">Execução de código em todos os processos<a class="anchor-link" href="#Execu%C3%A7%C3%A3o-de-c%C3%B3digo-em-todos-os-processos"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 66" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>No entanto, há um código que deve ser executado em todos os processos, por exemplo, se fizermos o upload dos pontos de verificação para o hub, portanto, temos duas opções: encapsular o código em uma função e decorá-lo com <code>accelerator.on_main_process</code>.</p>
      <div class="highlight"><pre><span></span><span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_main_process</span>
      <span class="k">def</span> <span class="nf">do_my_thing</span><span class="p">():</span>
          <span class="s2">"Algo feito uma vez por servidor</span>
          <span class="n">do_thing_once</span><span class="p">()</span>
      </pre></div>
      <p>ou colocar o código dentro de um <code>if accelerator.is_main_process</code>.</p>
      <div class="highlight"><pre><span></span><span class="n">se</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">:</span>
          <span class="n">repo</span><span class="o">.</span><span class="n">push_to_hub</span><span class="p">()</span>
      </pre></div>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Como estamos treinando apenas para mostrar a biblioteca <code>accelerate</code> e o modelo que estamos treinando não é bom, não faz sentido carregar os pontos de verificação no hub, portanto, farei um exemplo com <code>print</code>s.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/07_accelerate_base_code_some_code_in_all_process.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">import</span> <span class="nn">tqdm</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>',
          '<span class="k">def</span> <span class="nf">print_in_one_process</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_main_process</span>',
          '<span class="k">def</span> <span class="nf">print_in_all_processes</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '    ',
          '<span class="n">print_in_one_process</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">:</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">print_in_all_processes</span><span class="p">(</span><span class="sa">f</span><span class="s2">"All process: Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">:</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"All process: End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/06_accelerate_base_code_some_code_in_all_process.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Nós o executamos para ver</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%time</span>',
          '',
          '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">07</span><span class="n">_accelerate_base_code_some_code_in_all_process</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Map: 100%|██████████████████████| 45000/45000 [00:03&lt;00:00, 14518.44 examples/s]',
          'Map: 100%|██████████████████████| 45000/45000 [00:03&lt;00:00, 14368.77 examples/s]',
          'Map: 100%|████████████████████████| 5000/5000 [00:00&lt;00:00, 16466.33 examples/s]',
          'Map: 100%|████████████████████████| 5000/5000 [00:00&lt;00:00, 14806.14 examples/s]',
          'Map: 100%|██████████████████████| 50000/50000 [00:03&lt;00:00, 14253.33 examples/s]',
          'Map: 100%|██████████████████████| 50000/50000 [00:03&lt;00:00, 14337.07 examples/s]',
          '100%|█████████████████████████████████████████| 176/176 [02:00&lt;00:00,  1.46it/s]',
          '100%|███████████████████████████████████████████| 20/20 [00:05&lt;00:00,  3.34it/s]',
          'Accuracy = 0.2092',
          'End of script with 0.2092 accuracy',
          'All process: Accuracy = 0.2092',
          'All process: End of script with 0.2092 accuracy',
          'CPU times: user 1.42 s, sys: 216 ms, total: 1.64 s',
          'Wall time: 2min 27s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h4 id="Execu%C3%A7%C3%A3o-de-c%C3%B3digo-no-processo-X">Execução de código no processo X<a class="anchor-link" href="#Execu%C3%A7%C3%A3o-de-c%C3%B3digo-no-processo-X"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 67" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Por fim, podemos especificar em qual processo queremos executar o código. Para isso, precisamos criar uma função e decorá-la com <code>@accelerator.on_process(process_index=0)</code>.</p>
      <div class="highlight"><pre><span></span><span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_process</span><span class="p">(</span><span class="n">process_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
      <span class="k">def</span> <span class="nf">do_my_thing</span><span class="p">():</span>
          <span class="s2">"Algo feito no índice de processo 0"</span><span class="o">.</span>
          <span class="n">do_thing_on_index_zero</span><span class="p">()</span>
      </pre></div>
      <p>ou decorá-lo com <code>@accelerator.on_local_process(local_process_idx=0)</code>.</p>
      <div class="highlight"><pre><span></span><span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_process</span><span class="p">(</span><span class="n">local_process_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
      <span class="k">def</span> <span class="nf">do_my_thing</span><span class="p">():</span>
          <span class="s2">"Algo feito no índice de processo 0 em cada servidor"</span><span class="o">.</span>
          <span class="n">do_thing_on_index_zero_on_each_server</span><span class="p">()</span>
      </pre></div>
      <p>Aqui eu coloquei o processo 0, mas você pode colocar qualquer número.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/08_accelerate_base_code_some_code_in_some_process.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">import</span> <span class="nn">tqdm</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>',
          '<span class="k">def</span> <span class="nf">print_in_one_process</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_main_process</span>',
          '<span class="k">def</span> <span class="nf">print_in_all_processes</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_process</span><span class="p">(</span><span class="n">process_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>',
          '<span class="k">def</span> <span class="nf">print_in_process_0</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="s2">"Process 0: "</span> <span class="o">+</span> <span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_process</span><span class="p">(</span><span class="n">local_process_index</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
          '<span class="k">def</span> <span class="nf">print_in_process_1</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="s2">"Process 1: "</span> <span class="o">+</span> <span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '    ',
          '<span class="n">print_in_one_process</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">:</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">print_in_all_processes</span><span class="p">(</span><span class="sa">f</span><span class="s2">"All process: Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">:</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"All process: End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">print_in_process_0</span><span class="p">(</span><span class="s2">"End of process 0"</span><span class="p">)</span>',
          '<span class="n">print_in_process_1</span><span class="p">(</span><span class="s2">"End of process 1"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/07_accelerate_base_code_some_code_in_some_process.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Nós o executamos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%time</span>',
          '',
          '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">08</span><span class="n">_accelerate_base_code_some_code_in_some_process</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Map: 100%|████████████████████████| 5000/5000 [00:00&lt;00:00, 15735.58 examples/s]',
          'Map: 100%|██████████████████████| 50000/50000 [00:03&lt;00:00, 14906.20 examples/s]',
          '100%|█████████████████████████████████████████| 176/176 [02:02&lt;00:00,  1.44it/s]',
          '100%|███████████████████████████████████████████| 20/20 [00:06&lt;00:00,  3.27it/s]',
          'Process 1: End of process 1',
          'Accuracy = 0.2128',
          'End of script with 0.2128 accuracy',
          'All process: Accuracy = 0.2128',
          'All process: End of script with 0.2128 accuracy',
          'Process 0: End of process 0',
          'CPU times: user 1.42 s, sys: 295 ms, total: 1.71 s',
          'Wall time: 2min 37s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h4 id="Sincronizar-processos">Sincronizar processos<a class="anchor-link" href="#Sincronizar-processos"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 68" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Se tivermos um código que precisa ser executado em todos os processos, é interessante esperar que ele termine em todos os processos antes de executar outra tarefa, portanto, usamos <code>accelerator.wait_for_everyone()</code> para isso.</p>
      <p>Para ver isso, vamos colocar um atraso em uma das funções de impressão em um processo.</p>
      <p>Também coloquei um intervalo no ciclo de treinamento para que ele não passe muito tempo treinando, o que não é o que nos interessa no momento.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/09_accelerate_base_code_sync_all_process.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">import</span> <span class="nn">tqdm</span>',
          '<span class="kn">import</span> <span class="nn">time</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>',
          '<span class="k">def</span> <span class="nf">print_in_one_process</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_main_process</span>',
          '<span class="k">def</span> <span class="nf">print_in_all_processes</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_process</span><span class="p">(</span><span class="n">process_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>',
          '<span class="k">def</span> <span class="nf">print_in_process_0</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="s2">"Process 0: "</span> <span class="o">+</span> <span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_process</span><span class="p">(</span><span class="n">local_process_index</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>',
          '<span class="k">def</span> <span class="nf">print_in_process_1</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="s2">"Process 1: "</span> <span class="o">+</span> <span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '        <span class="k">break</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '    ',
          '<span class="n">print_in_one_process</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">:</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">print_in_all_processes</span><span class="p">(</span><span class="sa">f</span><span class="s2">"All process: Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">:</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"All process: End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">print_in_one_process</span><span class="p">(</span><span class="s2">"Printing with delay in process 0"</span><span class="p">)</span>',
          '<span class="n">print_in_process_0</span><span class="p">(</span><span class="s2">"End of process 0"</span><span class="p">)</span>',
          '<span class="n">print_in_process_1</span><span class="p">(</span><span class="s2">"End of process 1"</span><span class="p">)</span>',
          '<span class="n">accelerator</span><span class="o">.</span><span class="n">wait_for_everyone</span><span class="p">()</span>',
          '',
          '<span class="n">print_in_one_process</span><span class="p">(</span><span class="s2">"End of script"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/08_accelerate_base_code_sync_all_process.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Nós o executamos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">!</span>accelerate<span class="w"> </span>launch<span class="w"> </span>accelerate_scripts/09_accelerate_base_code_sync_all_process.py',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Map: 100%|████████████████████████| 5000/5000 [00:00&lt;00:00, 14218.23 examples/s]',
          'Map: 100%|████████████████████████| 5000/5000 [00:00&lt;00:00, 14666.25 examples/s]',
          '  0%|                                                   | 0/176 [00:00&lt;?, ?it/s]',
          '100%|███████████████████████████████████████████| 20/20 [00:05&lt;00:00,  3.58it/s]',
          'Process 1: End of process 1',
          'Accuracy = 0.212',
          'End of script with 0.212 accuracy',
          'All process: Accuracy = 0.212',
          'All process: End of script with 0.212 accuracy',
          'Printing with delay in process 0',
          'Process 0: End of process 0',
          'End of script',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Como você pode ver, primeiro imprimimos <code>Process 1: End of process 1</code> e depois o restante, porque o restante das impressões é feito no processo 0 ou em todos os processos, portanto, até que o atraso de 2 segundos que colocamos não seja concluído, o restante do código não é executado.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Salvar-e-carregar-o-ditado-de-estado">Salvar e carregar o ditado de estado<a class="anchor-link" href="#Salvar-e-carregar-o-ditado-de-estado"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 69" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Quando treinamos, às vezes salvamos o estado para que possamos continuar em outro momento.</p>
      <p>Para salvar o estado, teremos que usar os métodos <code>save_state()</code> e <code>load_state()</code>.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/10_accelerate_save_and_load_checkpoints.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">import</span> <span class="nn">tqdm</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>',
          '<span class="k">def</span> <span class="nf">print_something</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '',
          '    <span class="c1"># Guardamos los pesos</span>',
          '    <span class="n">accelerator</span><span class="o">.</span><span class="n">save_state</span><span class="p">(</span><span class="s2">"accelerate_scripts/checkpoints"</span><span class="p">)</span>',
          '',
          '<span class="n">print_something</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '<span class="c1"># Cargamos los pesos</span>',
          '<span class="n">accelerator</span><span class="o">.</span><span class="n">load_state</span><span class="p">(</span><span class="s2">"accelerate_scripts/checkpoints"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/09_accelerate_save_and_load_checkpoints.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Nós o executamos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">!</span>accelerate<span class="w"> </span>launch<span class="w"> </span>accelerate_scripts/10_accelerate_save_and_load_checkpoints.py',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '100%|█████████████████████████████████████████| 176/176 [01:58&lt;00:00,  1.48it/s]',
          '100%|███████████████████████████████████████████| 20/20 [00:05&lt;00:00,  3.40it/s]',
          'Accuracy = 0.2142',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Salvar-o-modelo">Salvar o modelo<a class="anchor-link" href="#Salvar-o-modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 70" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Quando o método <code>prepare</code> foi usado, o modelo foi empacotado para que pudesse ser salvo nos dispositivos necessários. Portanto, ao salvá-lo, temos que usar o método <code>save_model</code> que primeiro o desembrulha e depois o salva. Além disso, se usarmos o parâmetro <code>safe_serialization=True</code>, o modelo será salvo como um tensor <code>safe</code>.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/11_accelerate_save_model.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">import</span> <span class="nn">tqdm</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>',
          '<span class="k">def</span> <span class="nf">print_something</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '',
          '    <span class="c1"># Guardamos el modelo</span>',
          '    <span class="n">accelerator</span><span class="o">.</span><span class="n">wait_for_everyone</span><span class="p">()</span>',
          '    <span class="n">accelerator</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">"accelerate_scripts/model"</span><span class="p">,</span> <span class="n">safe_serialization</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">print_something</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Writing accelerate_scripts/11_accelerate_save_model.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Nós o executamos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">!</span>accelerate<span class="w"> </span>launch<span class="w"> </span>accelerate_scripts/11_accelerate_save_model.py',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '100%|█████████████████████████████████████████| 176/176 [01:58&lt;00:00,  1.48it/s]',
          '100%|███████████████████████████████████████████| 20/20 [00:05&lt;00:00,  3.35it/s]',
          'Accuracy = 0.214',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Salvar-o-modelo-%22pr%C3%A9-treinado">Salvar o modelo "pré-treinado<a class="anchor-link" href="#Salvar-o-modelo-%22pr%C3%A9-treinado"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 71" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Nos modelos que usam a biblioteca <code>transformers</code>, devemos salvar o modelo com o método <code>save_pretrained</code> para carregá-lo com o método <code>from_pretrained</code>. Antes de salvar, o modelo deve ser desempacotado com o método <code>unwrap_model</code>.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/12_accelerate_save_pretrained.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">import</span> <span class="nn">tqdm</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>',
          '<span class="k">def</span> <span class="nf">print_something</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '',
          '    <span class="c1"># Guardamos el modelo pretrained</span>',
          '    <span class="n">unwrapped_model</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">unwrap_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>',
          '    <span class="n">unwrapped_model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span>',
          '        <span class="s2">"accelerate_scripts/model_pretrained"</span><span class="p">,</span>',
          '        <span class="n">is_main_process</span><span class="o">=</span><span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">,</span>',
          '        <span class="n">save_function</span><span class="o">=</span><span class="n">accelerator</span><span class="o">.</span><span class="n">save</span><span class="p">,</span>',
          '    <span class="p">)</span>',
          '',
          '<span class="n">print_something</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Writing accelerate_scripts/11_accelerate_save_pretrained.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Nós o executamos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">!</span>accelerate<span class="w"> </span>launch<span class="w"> </span>accelerate_scripts/12_accelerate_save_pretrained.py',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Map: 100%|██████████████████████| 45000/45000 [00:02&lt;00:00, 15152.47 examples/s]',
          'Map: 100%|██████████████████████| 45000/45000 [00:02&lt;00:00, 15119.13 examples/s]',
          'Map: 100%|████████████████████████| 5000/5000 [00:00&lt;00:00, 12724.70 examples/s]',
          'Map: 100%|████████████████████████| 5000/5000 [00:00&lt;00:00, 12397.49 examples/s]',
          'Map: 100%|██████████████████████| 50000/50000 [00:03&lt;00:00, 15247.21 examples/s]',
          'Map: 100%|██████████████████████| 50000/50000 [00:03&lt;00:00, 15138.03 examples/s]',
          '100%|█████████████████████████████████████████| 176/176 [01:59&lt;00:00,  1.48it/s]',
          '100%|███████████████████████████████████████████| 20/20 [00:05&lt;00:00,  3.37it/s]',
          'Accuracy = 0.21',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Agora podemos carregá-lo</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModel</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"accelerate_scripts/model_pretrained"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Some weights of RobertaModel were not initialized from the model checkpoint at accelerate_scripts/model_pretrained and are newly initialized: [\'roberta.pooler.dense.bias\', \'roberta.pooler.dense.weight\']',
          'You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Treinamento-em-notebooks">Treinamento em notebooks<a class="anchor-link" href="#Treinamento-em-notebooks"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 72" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Até agora, vimos como executar scripts, mas se quiser executar o código em um notebook, podemos escrever o mesmo código de antes, mas encapsulado em uma função</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Primeiro, importamos as bibliotecas</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
      '      <span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
      '      <span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
      '      <span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
      '      <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
      '      <span class="kn">import</span> <span class="nn">evaluate</span>',
      '      <span class="kn">import</span> <span class="nn">tqdm</span>',
      '      <span class="kn">import</span> <span class="nn">time</span>',
      '      <span class="c1"># from accelerate import Accelerator</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>














      
      <section class="section-block-markdown-cell">
      <p>Agora criamos a função</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
      '      <span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
      '      <span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
      '      <span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
      '      <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
      '      <span class="kn">import</span> <span class="nn">evaluate</span>',
      '      <span class="kn">import</span> <span class="nn">tqdm</span>',
      '      <span class="kn">import</span> <span class="nn">time</span>',
      '      <span class="c1"># from accelerate import Accelerator</span>',
      '<span></span><span class="k">def</span> <span class="nf">train_code</span><span class="p">(</span><span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span><span class="p">):</span>',
      '          <span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
      '          <span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
      '      ',
      '          <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
      '          <span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
      '          <span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
      '      ',
      '          <span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
      '          <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '      ',
      '          <span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
      '              <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
      '          <span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
      '              <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
      '              <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
      '              <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
      '          <span class="p">}</span>',
      '          <span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
      '          <span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
      '          <span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
      '      ',
      '          <span class="n">BS</span> <span class="o">=</span> <span class="n">batch_size</span>',
      '          <span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
      '              <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '              <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '              <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
      '          <span class="p">}</span>',
      '      ',
      '          <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
      '          <span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
      '      ',
      '          <span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
      '          <span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
      '          <span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
      '      ',
      '          <span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
      '          <span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
      '          <span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
      '      ',
      '          <span class="c1"># model.to(device)</span>',
      '          <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
      '      ',
      '          <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
      '              <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
      '              <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
      '              <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
      '                  <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
      '      ',
      '                  <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '                  <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '                  <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '      ',
      '                  <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '                  <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
      '      ',
      '                  <span class="c1"># loss.backward()</span>',
      '                  <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
      '                  <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
      '      ',
      '              <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
      '              <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
      '              <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
      '                  <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '                  <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '                  <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
      '      ',
      '                  <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
      '                      <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
      '                  <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
      '                  <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
      '                  <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
      '                  <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
      '      ',
      '                  <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
      '              <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
      '              ',
      '          <span class="n">accelerator</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>



















































































      
      <section class="section-block-markdown-cell">
      <p>Para executar o treinamento no notebook, usamos a função <code>notebook_launcher</code>, para a qual passamos a função que queremos executar, os argumentos dessa função e o número de GPUs nas quais vamos treinar com a variável <code>num_processes</code>.</p>
      </section>
      
      <section class="section-block-code-cell-">
      <div class="input-code">
      <div class="highlight hl-ipython3">
<pre><span></span><span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">notebook_launcher</span>
      
      <span class="n">args</span> <span class="o">=</span> <span class="p">(</span><span class="mi">128</span><span class="p">,)</span>
      <span class="n">notebook_launcher</span><span class="p">(</span><span class="n">train_code</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">num_processes</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
      </pre></div>
      </div>
      <div class="output-wrapper">
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-subarea-output-stream-output-stdout-output-text">
      <pre>Launching training on 2 GPUs.
      </pre>
      </div>
      </div>
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-subarea-output-stream-output-stderr-output-text">
      <pre>100%|██████████| 176/176 [02:01&lt;00:00,  1.45it/s]
      100%|██████████| 20/20 [00:06&lt;00:00,  3.31it/s]
      </pre>
      </div>
      </div>
      <div class="output-area">
      <div class="prompt"></div>
      <div class="output-subarea-output-stream-output-stdout-output-text">
      <pre>Accuracy = 0.2112
      </pre>
      </div>
      </div>
      </div>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Treinamento-em-FP16">Treinamento em FP16<a class="anchor-link" href="#Treinamento-em-FP16"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 73" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Quando configuramos o <code>accelerate</code> pela primeira vez, ele nos perguntou <code>Do you wish to use FP16 or BF16 (mixed precision)?</code> e dissemos que não, então agora vamos dizer que sim, que queremos usar FP16.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Até agora, treinamos em FP32, o que significa que cada peso do modelo é um número de ponto flutuante de 32 bits, e agora vamos usar um número de ponto flutuante de 16 bits, ou seja, o modelo ocupará menos espaço. Portanto, duas coisas acontecerão: poderemos usar um tamanho de lote maior e ele também será mais rápido.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Primeiro, reiniciamos o <code>accelerate config</code> e informamos que queremos o FP16.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">import</span> <span class="nn">tqdm</span>',
          '<span class="kn">import</span> <span class="nn">time</span>',
          '<span class="c1"># from accelerate import Accelerator</span>',
          '</span><span class="k">def</span> <span class="nf">train_code</span><span class="p">(</span><span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span><span class="p">):</span>',
          '    <span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '    <span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '    <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '    <span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '    <span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '    <span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '    <span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '        <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '    <span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '        <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '        <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '        <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="p">}</span>',
          '    <span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '    <span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '    <span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '    <span class="n">BS</span> <span class="o">=</span> <span class="n">batch_size</span>',
          '    <span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '        <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '        <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '        <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="p">}</span>',
          '',
          '    <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '    <span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '    <span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '    <span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '    <span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '    <span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '    <span class="c1"># model.to(device)</span>',
          '    <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
          '        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '        <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '            <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '            <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '',
          '            <span class="c1"># loss.backward()</span>',
          '            <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '        <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '            <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '            <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '                <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '            <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '            <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '            <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '            <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '            <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '        ',
          '    <span class="n">accelerator</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '</span><span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">notebook_launcher</span>',
          '',
          '<span class="n">args</span> <span class="o">=</span> <span class="p">(</span><span class="mi">128</span><span class="p">,)</span>',
          '<span class="n">notebook_launcher</span><span class="p">(</span><span class="n">train_code</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">num_processes</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>',
          '</span><span class="o">!</span>accelerate<span class="w"> </span>config',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Launching training on 2 GPUs.',
          '--------------------------------------------------------------------------------',
          'In which compute environment are you running?',
          'This machine',
          '--------------------------------------------------------------------------------',
          'multi-GPU',
          'How many different machines will you use (use more than 1 for multi-node training)? [1]: 1',
          'Should distributed operations be checked while running for errors? This can avoid timeout issues but will be slower. [yes/NO]: no',
          'Do you wish to optimize your script with torch dynamo?[yes/NO]:no',
          'Do you want to use DeepSpeed? [yes/NO]: no',
          'Do you want to use FullyShardedDataParallel? [yes/NO]: no',
          'Do you want to use Megatron-LM ? [yes/NO]: no',
          'How many GPU(s) should be used for distributed training? [1]:2',
          'What GPU(s) (by id) should be used for training on this machine as a comma-seperated list? [all]:0,1',
          '--------------------------------------------------------------------------------',
          'Do you wish to use FP16 or BF16 (mixed precision)?',
          'fp16',
          'accelerate configuration saved at ~/.cache/huggingface/accelerate/default_config.yaml',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Agora, criamos um script para treinar, com o mesmo tamanho de lote de antes, para ver se o tempo de treinamento é menor.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/13_accelerate_base_code_fp16_bs128.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">import</span> <span class="nn">tqdm</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '    ',
          '<span class="n">accelerator</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/12_accelerate_base_code_fp16_bs128.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vamos executá-lo e ver quanto tempo leva</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%time</span>',
          '',
          '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">13</span><span class="n">_accelerate_base_code_fp16_bs128</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Map: 100%|████████████████████████| 5000/5000 [00:00&lt;00:00, 14983.76 examples/s]',
          'Map: 100%|██████████████████████| 50000/50000 [00:03&lt;00:00, 14315.47 examples/s]',
          '100%|█████████████████████████████████████████| 176/176 [01:01&lt;00:00,  2.88it/s]',
          '100%|███████████████████████████████████████████| 20/20 [00:02&lt;00:00,  6.84it/s]',
          'Accuracy = 0.2094',
          'CPU times: user 812 ms, sys: 163 ms, total: 976 ms',
          'Wall time: 1min 27s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Quando executamos esse treinamento em FP32, demorou cerca de 2 minutos e meio, e agora demora cerca de 1 minuto e meio. Vamos ver se agora, em vez de treinar com um tamanho de lote de 128, o fazemos com um tamanho de lote de 256.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/14_accelerate_base_code_fp16_bs256.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">import</span> <span class="nn">tqdm</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">256</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '    ',
          '<span class="n">accelerator</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/13_accelerate_base_code_fp16_bs256.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Nós o executamos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%time</span>',
          '',
          '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">14</span><span class="n">_accelerate_base_code_fp16_bs256</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Map: 100%|████████████████████████| 5000/5000 [00:00&lt;00:00, 15390.30 examples/s]',
          'Map: 100%|████████████████████████| 5000/5000 [00:00&lt;00:00, 14990.92 examples/s]',
          '100%|███████████████████████████████████████████| 88/88 [00:54&lt;00:00,  1.62it/s]',
          '100%|███████████████████████████████████████████| 10/10 [00:02&lt;00:00,  3.45it/s]',
          'Accuracy = 0.2236',
          'CPU times: user 670 ms, sys: 91.6 ms, total: 761 ms',
          'Wall time: 1min 12s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>A queda foi de apenas 15 segundos</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Treinamento-em-BF16">Treinamento em BF16<a class="anchor-link" href="#Treinamento-em-BF16"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 74" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Antes treinávamos no FP16 e agora vamos treinar no BF16, qual é a diferença?</p>
      <p><img decoding="async" onerror="this.parentNode.removeChild(this)" alt="FP32_FP16_BF16" src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/FP32_FP16_BF16.webp" width="894" height="253"/></p>
      <p>Como podemos ver na figura, enquanto o FP16 comparado ao FP32 tem menos bits na mantissa e no expoente, o que torna seu intervalo muito menor, o BF16 comparado ao FP32 tem o mesmo número de bits no expoente, mas menos na mantissa, o que faz com que o BF16 tenha o mesmo intervalo de números que o FP32, mas seja menos preciso.</p>
      <p>Isso é vantajoso porque, no FP16, alguns cálculos podem gerar números muito altos, que não poderiam ser representados no formato FP16. Além disso, há determinados dispositivos HW que são otimizados para esse formato.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Como antes, executamos o <code>accelerate config</code> e indicamos que queremos o BF16.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">!</span>accelerate<span class="w"> </span>config',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '--------------------------------------------------------------------------------',
          'In which compute environment are you running?',
          'This machine',
          '--------------------------------------------------------------------------------',
          'multi-GPU',
          'How many different machines will you use (use more than 1 for multi-node training)? [1]: 1',
          'Should distributed operations be checked while running for errors? This can avoid timeout issues but will be slower. [yes/NO]: no',
          'Do you wish to optimize your script with torch dynamo?[yes/NO]:no',
          'Do you want to use DeepSpeed? [yes/NO]: no',
          'Do you want to use FullyShardedDataParallel? [yes/NO]: no',
          'Do you want to use Megatron-LM ? [yes/NO]: no',
          'How many GPU(s) should be used for distributed training? [1]:2',
          'What GPU(s) (by id) should be used for training on this machine as a comma-seperated list? [all]:0,1',
          '--------------------------------------------------------------------------------',
          'Do you wish to use FP16 or BF16 (mixed precision)?',
          'bf16',
          'accelerate configuration saved at ~/.cache/huggingface/accelerate/default_config.yaml',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Agora, executamos o último script que criamos, ou seja, com um tamanho de lote de 256</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%time</span>',
          '',
          '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">14</span><span class="n">_accelerate_base_code_fp16_bs256</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Map: 100%|██████████████████████| 50000/50000 [00:03&lt;00:00, 14814.95 examples/s]',
          'Map: 100%|██████████████████████| 50000/50000 [00:03&lt;00:00, 14506.83 examples/s]',
          '100%|███████████████████████████████████████████| 88/88 [00:51&lt;00:00,  1.70it/s]',
          '100%|███████████████████████████████████████████| 10/10 [00:03&lt;00:00,  3.21it/s]',
          'Accuracy = 0.2112',
          'CPU times: user 688 ms, sys: 144 ms, total: 832 ms',
          'Wall time: 1min 17s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Levou um tempo semelhante ao anterior, o que é normal, pois treinamos um modelo com pesos de 16 bits, como antes.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Treinamento-em-FP8">Treinamento em FP8<a class="anchor-link" href="#Treinamento-em-FP8"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 75" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Agora vamos treinar no formato FP8, que, como o nome sugere, é um formato de ponto flutuante, em que cada peso tem 8 bits, portanto, executamos o <code>accelerate config</code> para informar que queremos o FP8.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">!</span>accelerate<span class="w"> </span>config',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '--------------------------------------------------------------------------------',
          'In which compute environment are you running?',
          'This machine',
          '--------------------------------------------------------------------------------',
          'multi-GPU',
          'How many different machines will you use (use more than 1 for multi-node training)? [1]: 1',
          'Should distributed operations be checked while running for errors? This can avoid timeout issues but will be slower. [yes/NO]: no',
          'Do you wish to optimize your script with torch dynamo?[yes/NO]:no',
          'Do you want to use DeepSpeed? [yes/NO]: no',
          'Do you want to use FullyShardedDataParallel? [yes/NO]: no',
          'Do you want to use Megatron-LM ? [yes/NO]: no',
          'How many GPU(s) should be used for distributed training? [1]:2',
          'What GPU(s) (by id) should be used for training on this machine as a comma-seperated list? [all]:0,1',
          '--------------------------------------------------------------------------------',
          'Do you wish to use FP16 or BF16 (mixed precision)?',
          'fp8',
          'accelerate configuration saved at ~/.cache/huggingface/accelerate/default_config.yaml',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Agora, executamos o último script, o script de tamanho de lote de 256.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%time</span>',
          '',
          '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">14</span><span class="n">_accelerate_base_code_fp16_bs256</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Traceback (most recent call last):',
          '  File "/home/wallabot/Documentos/web/portafolio/posts/accelerate_scripts/13_accelerate_base_code_fp16_bs256.py", line 12, in &lt;module&gt;',
          '    accelerator = Accelerator()',
          '                  ^^^^^^^^^^^^^',
          '  File "/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/accelerator.py", line 371, in __init__',
          '    self.state = AcceleratorState(',
          '                 ^^^^^^^^^^^^^^^^^',
          '  File "/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/state.py", line 790, in __init__',
          '    raise ValueError(',
          'ValueError: Using `fp8` precision requires `transformer_engine` or `MS-AMP` to be installed.',
          'Traceback (most recent call last):',
          '  File "/home/wallabot/Documentos/web/portafolio/posts/accelerate_scripts/13_accelerate_base_code_fp16_bs256.py", line 12, in &lt;module&gt;',
          '    accelerator = Accelerator()',
          '                  ^^^^^^^^^^^^^',
          '  File "/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/accelerator.py", line 371, in __init__',
          '    self.state = AcceleratorState(',
          '                 ^^^^^^^^^^^^^^^^^',
          '  File "/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/state.py", line 790, in __init__',
          '    raise ValueError(',
          'ValueError: Using `fp8` precision requires `transformer_engine` or `MS-AMP` to be installed.',
          '[2024-05-13 21:40:56,455] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 501480) of binary: /home/wallabot/miniconda3/envs/nlp/bin/python',
          'Traceback (most recent call last):',
          '  File "/home/wallabot/miniconda3/envs/nlp/bin/accelerate", line 8, in &lt;module&gt;',
          '    sys.exit(main())',
          '             ^^^^^^',
          '  File "/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/commands/accelerate_cli.py", line 46, in main',
          '    args.func(args)',
          '  File "/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/commands/launch.py", line 1048, in launch_command',
          '    multi_gpu_launcher(args)',
          '  File "/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/commands/launch.py", line 702, in multi_gpu_launcher',
          '    distrib_run.run(args)',
          '  File "/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/distributed/run.py", line 803, in run',
          '    elastic_launch(',
          '  File "/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 135, in __call__',
          '    return launch_agent(self._config, self._entrypoint, list(args))',
          '           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^',
          '  File "/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent',
          '    raise ChildFailedError(',
          'torch.distributed.elastic.multiprocessing.errors.ChildFailedError: ',
          '============================================================',
          'accelerate_scripts/13_accelerate_base_code_fp16_bs256.py FAILED',
          '------------------------------------------------------------',
          'Failures:',
          '[1]:',
          '  time      : 2024-05-13_21:40:56',
          '  host      : wallabot',
          '  rank      : 1 (local_rank: 1)',
          '  exitcode  : 1 (pid: 501481)',
          '  error_file: &lt;N/A&gt;',
          '  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html',
          '------------------------------------------------------------',
          'Root Cause (first observed failure):',
          '[0]:',
          '  time      : 2024-05-13_21:40:56',
          '  host      : wallabot',
          '  rank      : 0 (local_rank: 0)',
          '  exitcode  : 1 (pid: 501480)',
          '  error_file: &lt;N/A&gt;',
          '  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html',
          '============================================================',
          'CPU times: user 65.1 ms, sys: 14.5 ms, total: 79.6 ms',
          'Wall time: 7.24 s',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Como os pesos agora são de 8 bits e ocupam metade da memória, aumentaremos o tamanho do lote para 512.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/15_accelerate_base_code_fp8_bs512.py',
          '',
          '<span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>',
          '<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>',
          '<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>',
          '<span class="kn">import</span> <span class="nn">evaluate</span>',
          '<span class="kn">import</span> <span class="nn">tqdm</span>',
          '',
          '<span class="c1"># Importamos e inicializamos Accelerator</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>',
          '<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>',
          '',
          '<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"tweet_eval"</span><span class="p">,</span> <span class="s2">"emoji"</span><span class="p">)</span>',
          '<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>',
          '<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"cardiffnlp/twitter-roberta-base-irony"</span>',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '',
          '<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>',
          '    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>',
          '<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]),</span>',
          '<span class="p">}</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">,</span> <span class="s1">\'label\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"torch"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">\'label\'</span><span class="p">,</span> <span class="s1">\'input_ids\'</span><span class="p">,</span> <span class="s1">\'attention_mask\'</span><span class="p">])</span>',
          '',
          '<span class="n">BS</span> <span class="o">=</span> <span class="mi">512</span>',
          '<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>',
          '    <span class="s2">"train"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"validation"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '    <span class="s2">"test"</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">"test"</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>',
          '<span class="p">}</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>',
          '<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>',
          '',
          '<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>',
          '<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>',
          '<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>',
          '',
          '<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>',
          '<span class="c1"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span>',
          '<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>',
          '',
          '<span class="c1"># model.to(device)</span>',
          '<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">])</span>',
          '',
          '<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>',
          '    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>',
          '    <span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"train"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>',
          '',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="c1"># loss.backward()</span>',
          '        <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>',
          '        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>',
          '',
          '    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>',
          '    <span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">"validation"</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>',
          '    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>',
          '        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"label"</span><span class="p">]</span><span class="c1">#.to(device)</span>',
          '',
          '        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>',
          '            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">\'logits\'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>',
          '        <span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>',
          '        <span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>',
          '        <span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>',
          '',
          '        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>',
          '    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>',
          '    ',
          '<span class="n">accelerator</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">\'accuracy\'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Writing accelerate_scripts/15_accelerate_base_code_fp8_bs512.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Nós o executamos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="o">%%time</span>',
      '      ',
      '      <span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">15</span><span class="n">_accelerate_base_code_fp8_bs512</span><span class="o">.</span><span class="n">py</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>








      
      <section class="section-block-markdown-cell">
      <h2 id="Infer%C3%AAncia-de-modelo">Inferência de modelo<a class="anchor-link" href="#Infer%C3%AAncia-de-modelo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 76" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Uso-do-ecossistema-de-rosto-abra%C3%A7ado">Uso do ecossistema de rosto abraçado<a class="anchor-link" href="#Uso-do-ecossistema-de-rosto-abra%C3%A7ado"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 77" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos ver como fazer a inferência de modelos grandes com a biblioteca de faces de abraço <code>transformers</code>.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h4 id="Infer%C3%AAncia-com-pipeline.">Inferência com <code>pipeline</code>.<a class="anchor-link" href="#Infer%C3%AAncia-com-pipeline."><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 78" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Se usarmos o ecossistema Hugging Face, é muito simples, pois tudo é produzido por baixo sem que tenhamos que fazer muito. No caso de usar o <code>pipeline</code>, que é a maneira mais fácil de fazer inferência com a biblioteca <code>transformers</code>, basta informar o modelo que queremos usar e, o que é muito importante, passar <code>device_map="auto"</code>. Isso fará com que o <code>accelerate</code> distribua o modelo entre as diferentes GPUs, a RAM da CPU ou o disco rígido, se necessário.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Há mais valores possíveis para <code>device_map</code>, que veremos mais adiante, mas, por enquanto, mantenha o <code>"auto"</code>.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos usar o modelo <code>Llama3 8B</code>, que, como o nome sugere, é um modelo com cerca de 8 bilhões de parâmetros, já que cada parâmetro, por padrão, está no formato FP32, que corresponde a 4 bytes (32 bits), o que significa que, se multiplicarmos 8 bilhões de parâmetros por 4 bytes, teremos uma GPU com cerca de 32 GB de VRAM.</p>
      <p>No meu caso, tenho duas GPUs com 24 GB de VRAM, portanto, não caberia em uma única GPU. Mas ao definir <code>device_map="auto"</code>, a aceleração distribuirá o modelo entre as duas GPUs e eu poderei realizar a inferência.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%time</span>',
          '',
          '<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">15</span><span class="n">_accelerate_base_code_fp8_bs512</span><span class="o">.</span><span class="n">py</span>',
          '</span><span class="o">%%writefile</span> accelerate_scripts/16_inference_with_pipeline.py',
          '',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">pipeline</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"meta-llama/Meta-Llama-3-8B-Instruct"</span>',
          '<span class="n">generator</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">checkpoints</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s2">"auto"</span><span class="p">)</span>',
          '',
          '<span class="n">prompt</span> <span class="o">=</span> <span class="s2">"Conoces accelerate de hugging face?"</span>',
          '<span class="n">output</span> <span class="o">=</span> <span class="n">generator</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/09_inference_with_pipeline.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Agora vamos executá-lo, mas como o pipeline usa o accelerate abaixo, não precisamos executá-lo com <code>accelerate launch script.py</code>, mas com <code>python script.py</code>.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">!</span>python<span class="w"> </span>accelerate_scripts/16_inference_with_pipeline.py',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Loading checkpoint shards: 100%|██████████████████| 4/4 [00:09&lt;00:00,  2.27s/it]',
          'Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.',
          'Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.',
          '[{\'generated_text\': \'Conoces accelerate de hugging face? ¿Qué es el modelo de lenguaje de transformers y cómo se utiliza en el marco de hugging face? ¿Cómo puedo utilizar modelos de lenguaje de transformers en mi aplicación? ¿Qué son los tokenizers y cómo se utilizan en el marco de hugging face? ¿Cómo puedo crear un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los datasets y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar datasets para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning\'}]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Como você pode ver, ele não respondeu, mas continuou fazendo perguntas. Isso ocorre porque o Llama3 é um modelo de linguagem que prevê o próximo token, portanto, com o prompt que eu dei a ele, ele considerou que os próximos melhores tokens são aqueles que correspondem a mais perguntas. O que faz sentido, pois há momentos em que as pessoas têm dúvidas sobre um tópico e isso gera muitas perguntas, portanto, para que ele responda à pergunta, temos de condicioná-lo um pouco.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/17_inference_with_pipeline_condition.py',
          '',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">pipeline</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"meta-llama/Meta-Llama-3-8B-Instruct"</span>',
          '<span class="n">generator</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">checkpoints</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s2">"auto"</span><span class="p">)</span>',
          '',
          '<span class="n">prompt</span> <span class="o">=</span> <span class="s2">"Conoces accelerate de hugging face?"</span>',
          '<span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>',
          '    <span class="p">{</span>',
          '        <span class="s2">"role"</span><span class="p">:</span> <span class="s2">"system"</span><span class="p">,</span>',
          '        <span class="s2">"content"</span><span class="p">:</span> <span class="s2">"Eres un chatbot amigable que siempre intenta solucionar las dudas"</span><span class="p">,</span>',
          '    <span class="p">},</span>',
          '    <span class="p">{</span><span class="s2">"role"</span><span class="p">:</span> <span class="s2">"user"</span><span class="p">,</span> <span class="s2">"content"</span><span class="p">:</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">prompt</span><span class="si">}</span><span class="s2">"</span><span class="p">},</span>',
          '<span class="p">]</span>',
          '<span class="n">output</span> <span class="o">=</span> <span class="n">generator</span><span class="p">(</span><span class="n">messages</span><span class="p">)</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">\'generated_text\'</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/10_inference_with_pipeline_condition.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Como você pode ver, foi gerada uma mensagem com funções, condicionando o modelo e o prompt</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">!</span>python<span class="w"> </span>accelerate_scripts/17_inference_with_pipeline_condition.py',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Loading checkpoint shards: 100%|██████████████████| 4/4 [00:09&lt;00:00,  2.41s/it]',
          'Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.',
          'Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.',
          '{\'role\': \'assistant\', \'content\': \'¡Hola!\n\nSí, conozco Accelerate de Hugging Face. Accelerate es una biblioteca de Python desarrollada por Hugging Face que se enfoca en simplificar y acelerar el entrenamiento y la evaluación de modelos de lenguaje en diferentes dispositivos y entornos.\n\nCon Accelerate, puedes entrenar modelos de lenguaje en diferentes plataformas y dispositivos, como GPUs, TPUs, CPUs y servidores, sin necesidad de cambiar el código de tu modelo. Esto te permite aprovechar al máximo la potencia de cálculo de tus dispositivos y reducir el tiempo de entrenamiento.\n\nAccelerate también ofrece varias características adicionales, como:\n\n* Soporte para diferentes frameworks de machine learning, como TensorFlow, PyTorch y JAX.\n* Integración con diferentes sistemas de almacenamiento y procesamiento de datos, como Amazon S3 y Google Cloud Storage.\n* Soporte para diferentes protocolos de comunicación, como HTTP y gRPC.\n* Herramientas para monitorear y depurar tus modelos en tiempo real.\n\nEn resumen, Accelerate es una herramienta muy útil para desarrolladores de modelos de lenguaje que buscan simplificar y acelerar el proceso de entrenamiento y evaluación de sus modelos.\n\n¿Tienes alguna pregunta específica sobre Accelerate o necesitas ayuda para implementarlo en tu proyecto?\'}',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Agora a resposta, se ela responder ao nosso prompt</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h4 id="Infer%C3%AAncia-com-AutoClass.">Inferência com <code>AutoClass</code>.<a class="anchor-link" href="#Infer%C3%AAncia-com-AutoClass."><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 79" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Por fim, veremos como fazer a inferência somente com o <code>AutoClass</code>.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">%%writefile</span> accelerate_scripts/18_inference_with_autoclass.py',
          '',
          '<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">TextStreamer</span>',
          '',
          '<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">"meta-llama/Meta-Llama-3-8B-Instruct"</span>',
          '',
          '<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s2">"auto"</span><span class="p">)</span>',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s2">"auto"</span><span class="p">)</span>',
          '<span class="n">streamer</span> <span class="o">=</span> <span class="n">TextStreamer</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">)</span>',
          '',
          '<span class="n">prompt</span> <span class="o">=</span> <span class="s2">"Conoces accelerate de hugging face?"</span>',
          '<span class="n">tokens_input</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">([</span><span class="n">prompt</span><span class="p">],</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>',
          '',
          '<span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="o">**</span><span class="n">tokens_input</span><span class="p">,</span> <span class="n">streamer</span><span class="o">=</span><span class="n">streamer</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">do_sample</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">top_p</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Overwriting accelerate_scripts/11_inference_with_autoclass.py',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Como você pode ver, o objeto <code>streamer</code> foi criado e, em seguida, é passado para o método <code>generate</code> do modelo. Isso é útil para que cada palavra seja impressa à medida que é gerada e você não precise esperar que toda a saída seja gerada antes de imprimi-la.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="o">!</span>python<span class="w"> </span>accelerate_scripts/18_inference_with_autoclass.py',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.',
          'Loading checkpoint shards: 100%|██████████████████| 4/4 [00:09&lt;00:00,  2.28s/it]',
          'Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.',
          '&lt;|begin_of_text|&gt;Conoces accelerate de hugging face? Si es así, puedes utilizar la biblioteca `transformers` de Hugging Face para crear un modelo de lenguaje que pueda predecir la siguiente palabra en una secuencia de texto.',
          'Aquí te muestro un ejemplo de cómo hacerlo:',
          '```',
          'import pandas as pd',
          'import torch',
          'from transformers import AutoModelForSequenceClassification, AutoTokenizer',
          '# Cargar el modelo y el tokenizador',
          'model_name = "bert-base-uncased"',
          'model = AutoModelForSequenceClassification.from_pretrained(model_name)',
          'tokenizer = AutoTokenizer.from_pretrained(model_name)',
          '# Cargar el conjunto de datos',
          'train_df = pd.read_csv("train.csv")',
          'test_df = pd.read_csv("test.csv")',
          '# Preprocesar los datos',
          'train_texts = train_df["text"]',
          'train_labels = train_df["label"]',
          'test_texts = test_df["text"]',
          '# Convertir los textos en entradas para el modelo',
          'train_encodings = tokenizer.batch_encode_plus(train_texts, ',
          '                                              add_special_tokens=True, ',
          '                                              max_length=512, ',
          '                                              return_attention_mask=True, ',
          '                                              return_tensors=\'pt\')',
          'test_encodings = tokenizer.batch_encode_plus(test_texts, ',
          '                                             add_special_tokens=True, ',
          '                                             max_length=512, ',
          '                                             return_attention_mask=True, ',
          '                                             return_tensors=\'pt\')',
          '# Crear un dataloader para entrenar el modelo',
          'train_dataset = torch.utils.data.TensorDataset(train_encodings["input_ids"], ',
          '                                               train_encodings["attention_mask"], ',
          '                                               torch.tensor(train_labels))',
          'train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)',
          '# Entrenar el modelo',
          'device = torch.device("cuda" if torch.cuda.is_available() else "cpu")',
          'model.to(device)',
          'criterion = torch.nn.CrossEntropyLoss()',
          'optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)',
          'for epoch in range(5):',
          '    model.train()',
          '    total_loss = 0',
          '    for batch in train_loader:',
          '        input_ids = batch[0].to(device)',
          '        attention_mask = batch[1].to(device)',
          '        labels = batch[2].to(device)',
          '        optimizer.zero_grad()',
          '        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)',
          '        loss = criterion(outputs, labels)',
          '        loss.backward()',
          '        optimizer.step()',
          '        total_loss += loss.item()',
          '    print(f"Epoch {epoch+1}, Loss: {total',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Use-pytorch">Use pytorch<a class="anchor-link" href="#Use-pytorch"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 80" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Normalmente, a maneira de fazer inferências com o pytorch é criar um modelo com os pesos inicializados aleatoriamente e, em seguida, carregar um <code>state dict</code> com os pesos do modelo pré-treinado.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">import</span> <span class="nn">torchvision.models</span> <span class="k">as</span> <span class="nn">models</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet152</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">models</span><span class="o">.</span><span class="n">ResNet152_Weights</span><span class="o">.</span><span class="n">IMAGENET1K_V1</span><span class="p">)</span>',
          '<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">\'accelerate_scripts/resnet152_pretrained.pth\'</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Downloading: "https://download.pytorch.org/models/resnet152-394f9c45.pth" to /home/maximo.fernandez/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth',
          '100%|██████████| 230M/230M [02:48&lt;00:00, 1.43MB/s] ',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Agora que temos o <code>state dict</code>, vamos fazer a inferência como normalmente fazemos no pytorch.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">import</span> <span class="nn">torchvision.models</span> <span class="k">as</span> <span class="nn">models</span>',
          '',
          '<span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span>     <span class="c1"># Set device</span>',
          '',
          '<span class="n">resnet152</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet152</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="c1"># Create model with random weights and move to device</span>',
          '<span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">\'accelerate_scripts/resnet152_pretrained.pth\'</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="c1"># Load pretrained weights into device memory</span>',
          '<span class="n">resnet152</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span> <span class="c1"># Load this weights into the model</span>',
          '',
          '<span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Random image with batch size 1</span>',
          '<span class="n">output</span> <span class="o">=</span> <span class="n">resnet152</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>',
          '<span class="n">output</span><span class="o">.</span><span class="n">shape</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'torch.Size([1, 1000])',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vamos explicar o que aconteceu</p>
      <ul>
      <li>Quando usamos <code>resnet152 = models.resnet152().to(device)</code>, um resnet152 com pesos aleatórios foi carregado na memória da GPU.</li>
      <li>Quando fizemos <code>state_dict = torch.load('accelerate_scripts/resnet152_pretrained.pth', map_location=device)</code>, um dicionário com os pesos treinados foi carregado na memória da GPU.</li>
      <li>Quando fizemos <code>resnet152.load_state_dict(state_dict)</code>, esses pesos pré-treinados foram atribuídos ao modelo.</li>
      </ul>
      <p>Ou seja, o modelo foi carregado duas vezes na memória da GPU.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Você pode estar se perguntando por que fizemos primeiro</p>
      <div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet152</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">models</span><span class="o">.</span><span class="n">ResNet152_Weights</span><span class="o">.</span><span class="n">IMAGENET1K_V1</span><span class="p">)</span>
      <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">'accelerate_scripts/resnet152_pretrained.pth'</span><span class="p">)</span>
      </pre></div>
      <p>Para então fazer</p>
      <div class="highlight"><pre><span></span><span class="n">resnet152</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet152</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
      <span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">'accelerate_scripts/resnet152_pretrained.pth'</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
      <span class="n">resnet152</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span>
      </pre></div>
      <p>E por que não usamos diretamente</p>
      <pre><code>model = models.resnet152(weights=models.ResNet152_Weights.IMAGENET1K_V1)</code></pre>
      <p>E paramos de salvar o <code>state dict</code> para carregá-lo mais tarde. Bem, porque o Pytorch, por exemplo, faz a mesma coisa que nós fizemos. Portanto, para poder ver todo o processo, fizemos em várias linhas o que o Pytorch faz em uma linha</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Essa maneira de trabalhar funcionou bem até agora, desde que os modelos tivessem um tamanho gerenciável para as GPUs dos usuários. Porém, desde o advento dos LLMs, essa abordagem não faz mais sentido.</p>
      <p>Por exemplo, um modelo de 6B parâmetros ocuparia 24 GB de memória e, como é carregado duas vezes com essa forma de trabalho, seria necessária uma GPU de 48 GB.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Portanto, para corrigir isso, a maneira de carregar um modelo pré-treinado do Pytorch é:</p>
      <ul>
      <li>Crie um modelo vazio com <code>init_empty_weights</code> que não ocupará a RAM.</li>
      <li>Em seguida, carregue os pesos com <code>load_checkpoint_and_dispatch</code>, que carregará um ponto de verificação dentro do modelo vazio e distribuirá os pesos de cada camada em todos os dispositivos disponíveis (GPU, CPU, RAM e disco rígido), graças à configuração <code>device_map="auto"</code>.</li>
      </ul>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">import</span> <span class="nn">torchvision.models</span> <span class="k">as</span> <span class="nn">models</span>',
          '<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">init_empty_weights</span><span class="p">,</span> <span class="n">load_checkpoint_and_dispatch</span>',
          '',
          '<span class="k">with</span> <span class="n">init_empty_weights</span><span class="p">():</span>',
          '    <span class="n">resnet152</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet152</span><span class="p">()</span>',
          '',
          '<span class="n">resnet152</span> <span class="o">=</span> <span class="n">load_checkpoint_and_dispatch</span><span class="p">(</span><span class="n">resnet152</span><span class="p">,</span> <span class="n">checkpoint</span><span class="o">=</span><span class="s1">\'accelerate_scripts/resnet152_pretrained.pth\'</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s2">"auto"</span><span class="p">)</span>',
          '',
          '<span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span>',
          '',
          '<span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Random image with batch size 1</span>',
          '<span class="n">output</span> <span class="o">=</span> <span class="n">resnet152</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>',
          '<span class="n">output</span><span class="o">.</span><span class="n">shape</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'torch.Size([1, 1000])',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Como-a-acelera%C3%A7%C3%A3o-funciona-abaixo">Como a aceleração funciona abaixo<a class="anchor-link" href="#Como-a-acelera%C3%A7%C3%A3o-funciona-abaixo"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 81" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Neste vídeo, você pode ver graficamente como a aceleração funciona por baixo.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" frameborder="0" height="720" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/MWCSGj9jEAo" title="Accelerate Big Model Inference: How Does it Work?" width="1280"></iframe>
      </section>
      
      <section class="section-block-markdown-cell">
      <h4 id="Inicializa%C3%A7%C3%A3o-de-um-modelo-vazio">Inicialização de um modelo vazio<a class="anchor-link" href="#Inicializa%C3%A7%C3%A3o-de-um-modelo-vazio"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 82" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>O Accelerate cria o esqueleto de um modelo vazio usando <code>init_empty_weights</code> para que ele ocupe o mínimo de memória possível.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Por exemplo, vamos ver quanta RAM eu tenho disponível em meu computador.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">import</span> <span class="nn">psutil</span>',
          '',
          '<span class="k">def</span> <span class="nf">get_ram_info</span><span class="p">():</span>',
          '    <span class="n">ram</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">psutil</span><span class="o">.</span><span class="n">virtual_memory</span><span class="p">()</span><span class="o">.</span><span class="n">_asdict</span><span class="p">())</span>',
          '    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Total RAM: </span><span class="si">{</span><span class="p">(</span><span class="n">ram</span><span class="p">[</span><span class="s1">\'total\'</span><span class="p">]</span><span class="o">/</span><span class="mi">1024</span><span class="o">/</span><span class="mi">1024</span><span class="o">/</span><span class="mi">1024</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> GB, Available RAM: </span><span class="si">{</span><span class="p">(</span><span class="n">ram</span><span class="p">[</span><span class="s1">\'available\'</span><span class="p">]</span><span class="o">/</span><span class="mi">1024</span><span class="o">/</span><span class="mi">1024</span><span class="o">/</span><span class="mi">1024</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> GB, Used RAM: </span><span class="si">{</span><span class="p">(</span><span class="n">ram</span><span class="p">[</span><span class="s1">\'used\'</span><span class="p">]</span><span class="o">/</span><span class="mi">1024</span><span class="o">/</span><span class="mi">1024</span><span class="o">/</span><span class="mi">1024</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> GB"</span><span class="p">)</span>',
          '',
          '<span class="n">get_ram_info</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Total RAM: 31.24 GB, Available RAM: 22.62 GB, Used RAM: 7.82 GB',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Tenho cerca de 22 GB de RAM disponíveis</p>
      <p>Agora vamos tentar criar um modelo de 5000x1000x1000 parâmetros, ou seja, 5B parâmetros, se cada parâmetro estiver em FP32, o que significa 20 GB de RAM.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
      '      <span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>',
      '      ',
      '      <span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">)])</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>









      
      <section class="section-block-markdown-cell">
      <p>Se olharmos para a RAM novamente</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">import</span> <span class="nn">torch</span>',
          '<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>',
          '',
          '<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">)])</span>',
          '</span><span class="n">get_ram_info</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Total RAM: 31.24 GB, Available RAM: 3.77 GB, Used RAM: 26.70 GB',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Como podemos ver, agora temos apenas 3 GB de RAM disponíveis.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Agora, vamos excluir o modelo para liberar a RAM</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="k">del</span> <span class="n">model</span>',
          '<span class="n">get_ram_info</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Total RAM: 31.24 GB, Available RAM: 22.44 GB, Used RAM: 8.03 GB',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Voltamos a ter cerca de 22 GB de RAM disponíveis.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vamos agora usar o <code>init_empty_weights</code> do <code>accelerate</code> e, em seguida, examinar a RAM.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">init_empty_weights</span>',
          '',
          '<span class="k">with</span> <span class="n">init_empty_weights</span><span class="p">():</span>',
          '    <span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">)])</span>',
          '',
          '<span class="n">get_ram_info</span><span class="p">()</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Total RAM: 31.24 GB, Available RAM: 22.32 GB, Used RAM: 8.16 GB',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Antes, tínhamos exatamente 22,44 GB livres e, depois de criar o modelo com <code>init_empty_weights</code>, temos 22,32 GB. A economia de RAM é enorme! Quase nenhuma RAM foi usada para criar o modelo.</p>
      <p>Isso se baseia no metadevice introduzido no PyTorch 1.9, portanto, é importante que, para usar o <code>accelerate</code>, tenhamos uma versão mais recente do Pytorch.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h4 id="Carregamento-de-pesos">Carregamento de pesos<a class="anchor-link" href="#Carregamento-de-pesos"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 83" src={svg_paths.link_svg_path}/></a></h4>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Depois de inicializar o modelo, precisamos carregar os pesos, o que é feito pelo <code>load_checkpoint_and_dispatch</code> que, como o nome sugere, carrega os pesos e os envia para os dispositivos necessários.</p>
      </section>
      






    </div>

  </section>

</PostLayout>
