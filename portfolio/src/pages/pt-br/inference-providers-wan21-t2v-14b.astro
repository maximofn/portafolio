---
import PostLayout from '@layouts/PostLayout.astro';
import CodeBlockInputCell from '@components/CodeBlockInputCell.astro';
import CodeBlockOutputCell from '@components/CodeBlockOutputCell.astro';

const { metadata_page } = await import('@portfolio/consts.json');
const { colors } = await import('@portfolio/consts.json');
const { svg_paths } = await import('@portfolio/consts.json');

const page_title = 'Gerar vídeos com Wan2.1-T2V-14B e Provedores de Inferencia';
const end_url = 'inference-providers-wan21-t2v-14b';
const description = 'Você quer ter seu próprio Sora, mas também gerar bons vídeos? Neste post, explico como fazer isso com HuggingFace Inference Providers e Replicate.';
const keywords = 'hugging face, inference providers, replicate, wan21, t2v, 14b';
const languaje = 'PT';
const image_path = 'https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/inference-providers-wan21-thumbnail.webp';
const opening_brace = '{';
const closing_brace = '}';
---

<PostLayout 
    title={page_title}
    languaje={languaje}
    description={description}
    keywords={keywords}
    author={metadata_page.author}
    theme_color={colors.background_color}
    end_url={end_url}
    image_path={image_path}
    image_width=960
    image_height=720
    image_extension=webp
    article_date=2025-03-06+T00:00:00Z
>

  <section class="post-body">


    <aside class="post-index">
      <a class="anchor-link" href="#Inference providers"><h2>Inference providers</h2></a>
      <a class="anchor-link" href="#Inferencia con Replicate"><h2>Inferencia con Replicate</h2></a>
      <a class="anchor-link" href="#Lectura de las API KEYs"><h3>Lectura de las API KEYs</h3></a>
      <a class="anchor-link" href="#Logging en el hub de Hugging Face"><h3>Logging en el hub de Hugging Face</h3></a>
      <a class="anchor-link" href="#Cliente de Inferencia"><h3>Cliente de Inferencia</h3></a>
      <a class="anchor-link" href="#Generacion del video"><h3>Generación del vídeo</h3></a>
      <a class="anchor-link" href="#Guardando el video"><h3>Guardando el vídeo</h3></a>
      <a class="anchor-link" href="#Video generado"><h2>Video generado</h2></a>
    </aside>


    <div class="post-body-content">
      
      <section class="section-block-markdown-cell">
      <h1 id="Hugging Face Inference Providers">Hugging Face Inference Providers<a class="anchor-link" href="#Hugging Face Inference Providers"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 18" src={svg_paths.link_svg_path}/></a></h1>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Está claro que el mayor hub de modelos de inteligencia artificial es Hugging Face. Y ahora están dando la posibilidad de hacer inferencia de alguno de sus modelos en proveedores de GPUs serverless</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Uno de esos modelos es <a href="https://huggingface.co/Wan-AI/Wan2.1-T2V-14B" target="_blank" rel="nofollow noreferrer">Wan-AI/Wan2.1-T2V-14B</a> que a día de escribir este post es el mejor modelo de generación de vídeo open source, como se puede ver en la <a href="https://artificialanalysis.ai/text-to-video/arena?tab=Leaderboard">Artificial Analysis Video Generation Arena Leaderboard</a></p>
      <img decoding="async" onerror="this.parentNode.removeChild(this)" src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/Video-arena-leaderboard-wan21.webp" width="2180" height="1316" alt="video generation arena leaderboard">
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Si nos fijamos en su <a href="https://huggingface.co/Wan-AI/Wan2.1-T2V-14B" target="_blank" rel="nofollow noreferrer">modelcard</a> podemos ver a la derecha un botón que pone <code>Replicate</code>.</p>
      <img decoding="async" onerror="this.parentNode.removeChild(this)" src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/Wan2.1-T2V-14B.webp" width="2688" height="1150" alt="Wan2.1-T2V-14B modelcard">
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Inference providers">Inference providers<a class="anchor-link" href="#Inference providers"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 19" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Si vamos a la página de configuración de los <a href="https://huggingface.co/settings/inference-providers" target="_blank" rel="nofollow noreferrer">Inference providers</a> veremos algo como esto</p>
      <img decoding="async" onerror="this.parentNode.removeChild(this)" src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/Inference%20Providers.webp" width="1876" height="938" alt="Inference Providers">
      <p>Dónde podemos darle al botón con una llave para introducir la API KEY del proveedor que queramos usar, o dejar seleccionado el camino con dos puntos. Si hacemos la primera opción será el proveedor el que nos cobre por la inferencia, mientras que en el segundo será Hugging Face quien nos cobre la inferencia. Así que haz lo que mejor te convenga</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Inferencia con Replicate">Inferencia con Replicate<a class="anchor-link" href="#Inferencia con Replicate"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 20" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>En mi caso he obtenido una API KEY de Replicate y la he introducido en un archivo llamado <code>.env</code> que es donde guardaré las API KEYs y que no debes subir a GitHub, GitLab o el repositorio de tu proyecto.</p>
      <p>El <code>.env</code> tiene que tener este formato</p>
      
      <section class="section-block-markdown-cell">
            <div class='highlight'><pre><code class="language-python">HUGGINGFACE_TOKEN_INFERENCE_PROVIDERS="hf_aL...AY"<br>REPLICATE_API_KEY="r8_Sh...UD"</code></pre></div>
            </section>
      <p>Donde <code>HUGGINGFACE_TOKEN_INFERENCE_PROVIDERS</code> es un token que tienes que obtener desde <a href="https://huggingface.co/settings/tokens" target="_blank" rel="nofollow noreferrer">Hugging Face</a> y <code>REPLICATE_API_KEY</code> es la API KEY de Replicate que puedes obtener desde <a href="https://replicate.com/account/api-tokens">Replicate</a>.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Lectura de las API KEYs">Lectura de las API KEYs<a class="anchor-link" href="#Lectura de las API KEYs"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 21" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Lo primero que tenemos que hacer es leer las API KEYs desde el archivo <code>.env</code></p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">dotenv</span>',
      '<span class="n">dotenv</span><span class="o">.</span><span class="n">load_dotenv</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="n">REPLICATE_API_KEY</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;REPLICATE_API_KEY&quot;</span><span class="p">)</span>',
      '<span class="n">HUGGINGFACE_TOKEN_INFERENCE_PROVIDERS</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;HUGGINGFACE_TOKEN_INFERENCE_PROVIDERS&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Logging en el hub de Hugging Face">Logging en el hub de Hugging Face<a class="anchor-link" href="#Logging en el hub de Hugging Face"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 22" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Para poder usar el modelo de Wan-AI/Wan2.1-T2V-14B, como está en el hub de Hugging Face, necesitamos loguearnos.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">huggingface_hub</span><span class="w"> </span><span class="kn">import</span> <span class="n">login</span>',
      '<span class="n">login</span><span class="p">(</span><span class="n">HUGGINGFACE_TOKEN_INFERENCE_PROVIDERS</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Cliente de Inferencia">Cliente de Inferencia<a class="anchor-link" href="#Cliente de Inferencia"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 23" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Ahora creamos un cliente de inferencia, tenemos que especificar el proveedor, la API KEY y en este caso, además, vamos a establecer un tiempo de <code>timeout</code> de 1000 segundos, porque por defecto es de 60 segundos y el modelo tarda bastante en generar el vídeo.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">huggingface_hub</span><span class="w"> </span><span class="kn">import</span> <span class="n">InferenceClient</span>',
      '<span class="w"> </span>',
      '<span class="n">client</span> <span class="o">=</span> <span class="n">InferenceClient</span><span class="p">(</span>',
      '<span class="w">	</span><span class="n">provider</span><span class="o">=</span><span class="s2">&quot;replicate&quot;</span><span class="p">,</span>',
      '<span class="w">	</span><span class="n">api_key</span><span class="o">=</span><span class="n">REPLICATE_API_KEY</span><span class="p">,</span>',
      '<span class="w">	</span><span class="n">timeout</span><span class="o">=</span><span class="mi">1000</span>',
      '<span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Generacion del video">Generación del vídeo<a class="anchor-link" href="#Generacion del video"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 24" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Ya tenemos todo para generar nuestro video. Usamos el método <code>text_to_video</code> del cliente, le pasamos el prompt y le decimos qué modelo del hub queremos usar, si no usará el que está por defecto.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">video</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">text_to_video</span><span class="p">(</span>',
      '<span class="w">	</span><span class="s2">&quot;Funky dancer, dancing in a rehearsal room. She wears long hair that moves to the rhythm of her dance.&quot;</span><span class="p">,</span>',
      '<span class="w">	</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;Wan-AI/Wan2.1-T2V-14B&quot;</span><span class="p">,</span>',
      '<span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Guardando el video">Guardando el vídeo<a class="anchor-link" href="#Guardando el video"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 25" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Por último guardamos el video, que es de tipo <code>bytes</code>, en un fichero en nuestro disco</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">output_path</span> <span class="o">=</span> <span class="s2">&quot;output_video.mp4&quot;</span>',
      '<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>',
      '<span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">video</span><span class="p">)</span>',
      '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Video saved to: </span><span class="si">{</span><span class="n">output_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Video saved to: output_video.mp4',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h2 id="Video generado">Video generado<a class="anchor-link" href="#Video generado"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 26" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Este es el video generado por el modelo</p>
      <video src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/wan2_1_video.webm" controls></video>
      </section>







    </div>

  </section>

</PostLayout>
