---
import PostLayout from '@layouts/PostLayout.astro';
import CodeBlockInputCell from '@components/CodeBlockInputCell.astro';
import CodeBlockOutputCell from '@components/CodeBlockOutputCell.astro';

const { metadata_page } = await import('@portfolio/consts.json');
const { colors } = await import('@portfolio/consts.json');
const { svg_paths } = await import('@portfolio/consts.json');

const page_title = 'Gerar vídeos com Wan2.1-T2V-14B e Provedores de Inferencia';
const end_url = 'inference-providers-wan21-t2v-14b';
const description = 'Você quer ter seu próprio Sora, mas também gerar bons vídeos? Neste post, explico como fazer isso com HuggingFace Inference Providers e Replicate.';
const keywords = 'hugging face, inference providers, replicate, wan21, t2v, 14b';
const languaje = 'PT';
const image_path = 'https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/inference-providers-wan21-thumbnail.webp';
const opening_brace = '{';
const closing_brace = '}';
---

<PostLayout 
    title={page_title}
    languaje={languaje}
    description={description}
    keywords={keywords}
    author={metadata_page.author}
    theme_color={colors.background_color}
    end_url={end_url}
    image_path={image_path}
    image_width=960
    image_height=720
    image_extension=webp
    article_date=2025-03-06+T00:00:00Z
>

  <section class="post-body">


    <aside class="post-index">
      <a class="anchor-link" href="#Provedores de inferencia"><h2>Provedores de inferência</h2></a>
      <a class="anchor-link" href="#Inferencia com Replicate"><h2>Inferência com Replicate</h2></a>
      <a class="anchor-link" href="#Leitura das chaves API"><h3>Leitura das chaves API</h3></a>
      <a class="anchor-link" href="#Logging no hub da Hugging Face"><h3>Logging no hub da Hugging Face</h3></a>
      <a class="anchor-link" href="#Cliente de Inferencia"><h3>Cliente de Inferência</h3></a>
      <a class="anchor-link" href="#Geracao do video"><h3>Geração do vídeo</h3></a>
      <a class="anchor-link" href="#Salvando o video"><h3>Salvando o vídeo</h3></a>
      <a class="anchor-link" href="#Video gerado"><h2>Vídeo gerado</h2></a>
    </aside>


    <div class="post-body-content">
      
      <section class="section-block-markdown-cell">
      </section>
      
      <section class="section-block-markdown-cell">
      <blockquote>
      <p>Aviso: Este post foi traduzido para o português usando um modelo de tradução automática. Por favor, me avise se encontrar algum erro.</p>
      </blockquote>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Está claro que o maior hub de modelos de inteligência artificial é a Hugging Face. E agora estão oferecendo a possibilidade de fazer inferência de alguns de seus modelos em provedores de GPUs serverless</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Um desses modelos é <a href="https://huggingface.co/Wan-AI/Wan2.1-T2V-14B" target="_blank" rel="nofollow noreferrer">Wan-AI/Wan2.1-T2V-14B</a>, que no momento de escrever este post, é o melhor modelo de geração de vídeo open source, como se pode ver na <a href="https://artificialanalysis.ai/text-to-video/arena?tab=Leaderboard">Artificial Analysis Video Generation Arena Leaderboard</a></p>
      <img decoding="async" onerror="this.parentNode.removeChild(this)" src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/Video-arena-leaderboard-wan21.webp" alt="video generation arena leaderboard">
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Se nós olharmos para seu <a href="https://huggingface.co/Wan-AI/Wan2.1-T2V-14B" target="_blank" rel="nofollow noreferrer">modelcard</a>, podemos ver à direita um botão que diz <code>Replicate</code>.</p>
      <img decoding="async" onerror="this.parentNode.removeChild(this)" src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/Wan2.1-T2V-14B.webp" alt="Wan2.1-T2V-14B modelcard">
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Provedores de inferencia">Provedores de inferência<a class="anchor-link" href="#Provedores de inferencia"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 19" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Se formos na página de configuração dos <a href="https://huggingface.co/settings/inference-providers" target="_blank" rel="nofollow noreferrer">Inference providers</a> veremos algo assim:</p>
      <img decoding="async" onerror="this.parentNode.removeChild(this)" src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/Inference%20Providers.webp" alt="Provedores de Inferência">
      <p>Onde podemos clicar no botão com uma chave para inserir a API KEY do provedor que quisermos usar, ou deixar selecionada a opção com dois pontos. Se escolhermos a primeira opção, será o provedor quem nos cobrará pela inferência, enquanto na segunda opção será a Hugging Face quem nos cobrará pela inferência. Então, faça o que for melhor para você.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h2 id="Inferencia com Replicate">Inferência com Replicate<a class="anchor-link" href="#Inferencia com Replicate"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 20" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>No meu caso, obtive uma API KEY do Replicate e a adicionei a um arquivo chamado <code>.env</code>, onde armazenarei as API KEYS e que não deve ser enviado para o GitHub, GitLab ou o repositório do seu projeto.</p>
      <p>O <code>.env</code> deve ter este formato</p>
      
      <section class="section-block-markdown-cell">
            <div class='highlight'><pre><code class="language-python">HUGGINGFACE_TOKEN_INFERENCE_PROVIDERS="hf_aL...AY"<br>REPLICATE_API_KEY="r8_Sh...UD"</code></pre></div>
            </section>
      <p>Onde <code>HUGGINGFACE_TOKEN_INFERENCE_PROVIDERS</code> é um token que você precisa obter a partir do <a href="https://huggingface.co/settings/tokens" target="_blank" rel="nofollow noreferrer">Hugging Face</a> e <code>REPLICATE_API_KEY</code> é a API KEY do Replicate, que você pode obter a partir do <a href="https://replicate.com/account/api-tokens">Replicate</a>.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <h3 id="Leitura das chaves API">Leitura das chaves API<a class="anchor-link" href="#Leitura das chaves API"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 21" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>A primeira coisa que temos que fazer é ler as chaves API do arquivo <code>.env</code></p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>',
      '<span class="kn">import</span><span class="w"> </span><span class="nn">dotenv</span>',
      '<span class="n">dotenv</span><span class="o">.</span><span class="n">load_dotenv</span><span class="p">()</span>',
      '<span class="w"> </span>',
      '<span class="n">REPLICATE_API_KEY</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;REPLICATE_API_KEY&quot;</span><span class="p">)</span>',
      '<span class="n">HUGGINGFACE_TOKEN_INFERENCE_PROVIDERS</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;HUGGINGFACE_TOKEN_INFERENCE_PROVIDERS&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Logging no hub da Hugging Face">Logging no hub da Hugging Face<a class="anchor-link" href="#Logging no hub da Hugging Face"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 22" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Para poder usar o modelo de Wan-AI/Wan2.1-T2V-14B, como está no hub de Hugging Face, precisamos fazer login.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">huggingface_hub</span><span class="w"> </span><span class="kn">import</span> <span class="n">login</span>',
      '<span class="n">login</span><span class="p">(</span><span class="n">HUGGINGFACE_TOKEN_INFERENCE_PROVIDERS</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Cliente de Inferencia">Cliente de Inferência<a class="anchor-link" href="#Cliente de Inferencia"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 23" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Agora criamos um cliente de inferência, temos que especificar o provedor, a API KEY e, neste caso, além disso, vamos estabelecer um tempo de <code>timeout</code> de 1000 segundos, porque por padrão é de 60 segundos e o modelo demora bastante para gerar o vídeo.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">huggingface_hub</span><span class="w"> </span><span class="kn">import</span> <span class="n">InferenceClient</span>',
      '<span class="w"> </span>',
      '<span class="n">client</span> <span class="o">=</span> <span class="n">InferenceClient</span><span class="p">(</span>',
      '<span class="w">	</span><span class="n">provider</span><span class="o">=</span><span class="s2">&quot;replicate&quot;</span><span class="p">,</span>',
      '<span class="w">	</span><span class="n">api_key</span><span class="o">=</span><span class="n">REPLICATE_API_KEY</span><span class="p">,</span>',
      '<span class="w">	</span><span class="n">timeout</span><span class="o">=</span><span class="mi">1000</span>',
      '<span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Geracao do video">Geração do vídeo<a class="anchor-link" href="#Geracao do video"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 24" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Já temos tudo para gerar nosso vídeo. Usamos o método <code>text_to_video</code> do cliente, passamos o prompt e dizemos qual modelo do hub queremos usar, se não, ele usará o que está por padrão.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">video</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">text_to_video</span><span class="p">(</span>',
      '<span class="w">	</span><span class="s2">&quot;Funky dancer, dancing in a rehearsal room. She wears long hair that moves to the rhythm of her dance.&quot;</span><span class="p">,</span>',
      '<span class="w">	</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;Wan-AI/Wan2.1-T2V-14B&quot;</span><span class="p">,</span>',
      '<span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <section class="section-block-markdown-cell">
      <h3 id="Salvando o video">Salvando o vídeo<a class="anchor-link" href="#Salvando o video"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 25" src={svg_paths.link_svg_path}/></a></h3>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Por fim, salvamos o vídeo, que é do tipo <code>bytes</code>, em um arquivo no nosso disco.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="n">output_path</span> <span class="o">=</span> <span class="s2">&quot;output_video.mp4&quot;</span>',
      '<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>',
      '<span class="w">    </span><span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">video</span><span class="p">)</span>',
      '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Video saved to: </span><span class="si">{</span><span class="n">output_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      
      <CodeBlockOutputCell
        text={[
          'Video saved to: output_video.mp4',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <h2 id="Video gerado">Vídeo gerado<a class="anchor-link" href="#Video gerado"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 26" src={svg_paths.link_svg_path}/></a></h2>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Este é o vídeo gerado pelo modelo</p>
      <video src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/wan2_1_video.webm" controls></video>
      </section>







    </div>

  </section>

</PostLayout>
