---
import PostLayout from '@layouts/PostLayout.astro';
import CodeBlockInputCell from '@components/CodeBlockInputCell.astro';
import CodeBlockOutputCell from '@components/CodeBlockOutputCell.astro';

const { metadata_page } = await import('@portfolio/consts.json');
const { colors } = await import('@portfolio/consts.json');
const { svg_paths } = await import('@portfolio/consts.json');

const page_title = 'Tokens';
const end_url = 'tokens';
const description = 'Descubra o que são tokens e como as palavras são divididas em unidades mínimas de representação das palavras';
const keywords = 'tokens, token, openai, tiktoken, gpt-4, gpt-3.5-turbo, text-embedding-ada-002';
const languaje = 'PT';
const image_path = 'https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/tokens.webp';
const opening_brace = '{';
const closing_brace = '}';
---

<PostLayout 
    title={page_title}
    languaje={languaje}
    description={description}
    keywords={keywords}
    author={metadata_page.author}
    theme_color={colors.background_color}
    end_url={end_url}
    image_path={image_path}
    image_width=1024
    image_height=1024
    image_extension=webp
    article_date=2023-12-08+T00:00:00Z
>

  <section class="post-body">


    <aside class="post-index">
    </aside>


    <div class="post-body-content">
      
      <section class="section-block-markdown-cell">
      <h1 id="Tokens">Tokens<a class="anchor-link" href="#Tokens"><img decoding="async" class="link-img" width="24px" height="24px" alt="link image 2" src={svg_paths.link_svg_path}/></a></h1>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Agora que os <code>LLLMs</code> estão na moda, continuamos ouvindo sobre o número de <code>tokens</code> suportados por cada modelo, mas o que são <code>tokens</code>? São as unidades mínimas de representação de palavras.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Este caderno foi traduzido automaticamente para torná-lo acessível a mais pessoas, por favor me avise se você vir algum erro de digitação..</p>
      <p>Para explicar o que são <code>tokens</code>, vamos primeiro dar uma olhada em um exemplo prático: vamos usar o tokenizador da OpenAI, chamado [tiktoken] (<a href="https://github.com/openai/tiktoken" target="_blank" rel="nofollow noreferrer">https://github.com/openai/tiktoken</a>).</p>
      <p>Então, primeiro instalamos o pacote:</p>
      <div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>tiktoken
      <span class="sb">```</span>
      </pre></div>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Depois de instalado, criamos um tokenizador usando o modelo <code>cl100k_base</code>, que o notebook de exemplo [How to count tokens with tiktoken] (<a href="https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb" target="_blank" rel="nofollow noreferrer">https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb</a>) explica que é usado pelos modelos <code>gpt-4</code>, <code>gpt-3.5-turbo</code> e <code>text-embedding-ada-002</code>.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span> <span class="nn">tiktoken</span>',
      '      ',
      '      <span class="n">encoder</span> <span class="o">=</span> <span class="n">tiktoken</span><span class="o">.</span><span class="n">get_encoding</span><span class="p">(</span><span class="s2">"cl100k_base"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>








      
      <section class="section-block-markdown-cell">
      <p>Agora, criamos uma palavra de amostra tara e a tokenizamos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="kn">import</span> <span class="nn">tiktoken</span>',
      '      ',
      '      <span class="n">encoder</span> <span class="o">=</span> <span class="n">tiktoken</span><span class="o">.</span><span class="n">get_encoding</span><span class="p">(</span><span class="s2">"cl100k_base"</span><span class="p">)</span>',
      '<span></span><span class="n">example_word</span> <span class="o">=</span> <span class="s2">"breakdown"</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>






      
      <section class="section-block-markdown-cell">
      <p>E nós o simbolizamos</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="kn">import</span> <span class="nn">tiktoken</span>',
          '',
          '<span class="n">encoder</span> <span class="o">=</span> <span class="n">tiktoken</span><span class="o">.</span><span class="n">get_encoding</span><span class="p">(</span><span class="s2">"cl100k_base"</span><span class="p">)</span>',
          '</span><span class="n">example_word</span> <span class="o">=</span> <span class="s2">"breakdown"</span>',
          '</span><span class="n">tokens</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">example_word</span><span class="p">)</span>',
          '<span class="n">tokens</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '[9137, 2996]',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>A palavra foi dividida em 2 tokens, o <code>9137</code> e o <code>2996</code>. Vamos ver a quais palavras elas correspondem</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">word1</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">decode</span><span class="p">([</span><span class="n">tokens</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>',
          '<span class="n">word2</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">decode</span><span class="p">([</span><span class="n">tokens</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>',
          '<span class="n">word1</span><span class="p">,</span> <span class="n">word2</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          '(\'break\', \'down\')',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>O tokenizador <code>OpenAI</code> dividiu a palavra <code>breakdown</code> nas palavras <code>break</code> e <code>down</code>. Ou seja, ele dividiu a palavra em duas palavras mais simples.</p>
      <p>Isso é importante porque, quando se diz que um <code>LLM</code> suporta x <code>token</code>s`, não significa que ele suporta x palavras, mas que suporta x unidades mínimas de representação de palavras.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Se você tiver um texto e quiser ver o número de <code>token</code>s que ele tem para o tokenizador <code>OpenAI</code>, poderá visualizá-lo na página <a href="https://platform.openai.com/tokenizer" target="_blank" rel="nofollow noreferrer">Tokenizer</a>, que mostra cada <code>token</code> em uma cor diferente.</p>
      <p><img decoding="async" onerror="this.parentNode.removeChild(this)" alt="tokenizer" src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/tokenizer.webp" width="711" height="878"/></p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Vimos o tokenizador <code>OpenAI</code>, mas cada <code>LLM</code> poderá usar outro.</p>
      </section>
      
      <section class="section-block-markdown-cell">
      <p>Como dissemos, os <code>tokens</code> são as unidades mínimas de representação de palavras, portanto, vamos ver quantos tokens diferentes o <code>tiktoken</code> tem.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">n_vocab</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">n_vocab</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Vocab size: </span><span class="si">{</span><span class="n">n_vocab</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Vocab size: 100277',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Vamos ver como ele tokeniza outros tipos de palavras.</p>
      </section>
      
      <CodeBlockInputCell
        text={[
      '<span></span><span class="k">def</span> <span class="nf">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">):</span>',
      '          <span class="n">tokens</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>',
      '          <span class="n">decode_tokens</span> <span class="o">=</span> <span class="p">[]</span>',
      '          <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">:</span>',
      '              <span class="n">decode_tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">decode</span><span class="p">([</span><span class="n">token</span><span class="p">]))</span>',
      '          <span class="k">return</span> <span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>











      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="k">def</span> <span class="nf">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">):</span>',
          '    <span class="n">tokens</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>',
          '    <span class="n">decode_tokens</span> <span class="o">=</span> <span class="p">[]</span>',
          '    <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">:</span>',
          '        <span class="n">decode_tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">decode</span><span class="p">([</span><span class="n">token</span><span class="p">]))</span>',
          '    <span class="k">return</span> <span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span>',
          '</span><span class="n">word</span> <span class="o">=</span> <span class="s2">"dog"</span>',
          '<span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span> <span class="o">=</span> <span class="n">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Word: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2"> ==&gt; tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">, decode_tokens: </span><span class="si">{</span><span class="n">decode_tokens</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '<span class="n">word</span> <span class="o">=</span> <span class="s2">"tomorrow..."</span>',
          '<span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span> <span class="o">=</span> <span class="n">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Word: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2"> ==&gt; tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">, decode_tokens: </span><span class="si">{</span><span class="n">decode_tokens</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '<span class="n">word</span> <span class="o">=</span> <span class="s2">"artificial intelligence"</span>',
          '<span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span> <span class="o">=</span> <span class="n">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Word: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2"> ==&gt; tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">, decode_tokens: </span><span class="si">{</span><span class="n">decode_tokens</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '<span class="n">word</span> <span class="o">=</span> <span class="s2">"Python"</span>',
          '<span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span> <span class="o">=</span> <span class="n">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Word: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2"> ==&gt; tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">, decode_tokens: </span><span class="si">{</span><span class="n">decode_tokens</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '<span class="n">word</span> <span class="o">=</span> <span class="s2">"12/25/2023"</span>',
          '<span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span> <span class="o">=</span> <span class="n">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Word: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2"> ==&gt; tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">, decode_tokens: </span><span class="si">{</span><span class="n">decode_tokens</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '<span class="n">word</span> <span class="o">=</span> <span class="s2">"😊"</span>',
          '<span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span> <span class="o">=</span> <span class="n">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Word: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2"> ==&gt; tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">, decode_tokens: </span><span class="si">{</span><span class="n">decode_tokens</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Word: dog ==&gt; tokens: [18964], decode_tokens: [\'dog\']',
          'Word: tomorrow... ==&gt; tokens: [38501, 7924, 1131], decode_tokens: [\'tom\', \'orrow\', \'...\']',
          'Word: artificial intelligence ==&gt; tokens: [472, 16895, 11478], decode_tokens: [\'art\', \'ificial\', \' intelligence\']',
          'Word: Python ==&gt; tokens: [31380], decode_tokens: [\'Python\']',
          'Word: 12/25/2023 ==&gt; tokens: [717, 14, 914, 14, 2366, 18], decode_tokens: [\'12\', \'/\', \'25\', \'/\', \'202\', \'3\']',
          'Word: 😊 ==&gt; tokens: [76460, 232], decode_tokens: [\'�\', \'�\']',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Por fim, vamos dar uma olhada em palavras em outro idioma</p>
      </section>
      
      <CodeBlockInputCell
        text={[
          '<span></span><span class="n">word</span> <span class="o">=</span> <span class="s2">"perro"</span>',
          '<span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span> <span class="o">=</span> <span class="n">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Word: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2"> ==&gt; tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">, decode_tokens: </span><span class="si">{</span><span class="n">decode_tokens</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '<span class="n">word</span> <span class="o">=</span> <span class="s2">"perra"</span>',
          '<span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span> <span class="o">=</span> <span class="n">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Word: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2"> ==&gt; tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">, decode_tokens: </span><span class="si">{</span><span class="n">decode_tokens</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '<span class="n">word</span> <span class="o">=</span> <span class="s2">"mañana..."</span>',
          '<span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span> <span class="o">=</span> <span class="n">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Word: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2"> ==&gt; tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">, decode_tokens: </span><span class="si">{</span><span class="n">decode_tokens</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '<span class="n">word</span> <span class="o">=</span> <span class="s2">"inteligencia artificial"</span>',
          '<span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span> <span class="o">=</span> <span class="n">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Word: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2"> ==&gt; tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">, decode_tokens: </span><span class="si">{</span><span class="n">decode_tokens</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '<span class="n">word</span> <span class="o">=</span> <span class="s2">"Python"</span>',
          '<span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span> <span class="o">=</span> <span class="n">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Word: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2"> ==&gt; tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">, decode_tokens: </span><span class="si">{</span><span class="n">decode_tokens</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '<span class="n">word</span> <span class="o">=</span> <span class="s2">"12/25/2023"</span>',
          '<span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span> <span class="o">=</span> <span class="n">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Word: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2"> ==&gt; tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">, decode_tokens: </span><span class="si">{</span><span class="n">decode_tokens</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
          '',
          '<span class="n">word</span> <span class="o">=</span> <span class="s2">"😊"</span>',
          '<span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span> <span class="o">=</span> <span class="n">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>',
          '<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Word: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2"> ==&gt; tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">, decode_tokens: </span><span class="si">{</span><span class="n">decode_tokens</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>',
        ]}
        languaje='python'
      ></CodeBlockInputCell>
      <CodeBlockOutputCell
        text={[
          'Word: perro ==&gt; tokens: [716, 299], decode_tokens: [\'per\', \'ro\']',
          'Word: perra ==&gt; tokens: [79, 14210], decode_tokens: [\'p\', \'erra\']',
          'Word: mañana... ==&gt; tokens: [1764, 88184, 1131], decode_tokens: [\'ma\', \'ñana\', \'...\']',
          'Word: inteligencia artificial ==&gt; tokens: [396, 39567, 8968, 21075], decode_tokens: [\'int\', \'elig\', \'encia\', \' artificial\']',
          'Word: Python ==&gt; tokens: [31380], decode_tokens: [\'Python\']',
          'Word: 12/25/2023 ==&gt; tokens: [717, 14, 914, 14, 2366, 18], decode_tokens: [\'12\', \'/\', \'25\', \'/\', \'202\', \'3\']',
          'Word: 😊 ==&gt; tokens: [76460, 232], decode_tokens: [\'�\', \'�\']',
        ]}
        languaje='python'
      ></CodeBlockOutputCell>
      
      <section class="section-block-markdown-cell">
      <p>Podemos ver que, para palavras semelhantes, mais tokens são gerados em espanhol do que em inglês, portanto, para o mesmo texto, com um número semelhante de palavras, o número de tokens será maior em espanhol do que em inglês.</p>
      </section>
      






    </div>

  </section>

</PostLayout>
