{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medida de similitud entre embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que hemos visto lo que son los [embeddings](https://maximofn.com/embeddings), sabemos que podemos medir la similitud entre dos palabras midiendo la similitud entre sus embeddings. En el post de [embeddings](https://maximofn.com/embeddings) vimos el ejemplo de uso de la medida de similitud por coseno, pero existen otras medidas de similitud que podemos usar, el cuadrado L2, la similitud del producto escalar, la similitud por coseno, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este post vamos a ver estas tres que hemos nombrado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similitud por el cuadrado L2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta similitud viene derivada de la distancia euclídea, que es la distancia en línea recta entre dos puntos en un espacio multidimensional, la que se calcula con el teorema de Pitágoras.\n",
    "\n",
    "![distancia euclidiana](https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/distancia_euclidiana.webp)\n",
    "\n",
    "La distancia euclídea entre dos puntos $p$ y $q$ se calcula como:\n",
    "\n",
    "$$\n",
    "d(p,q) = \\sqrt{(p_1 - q_1)^2 + (p_2 - q_2)^2 + \\cdots + (p_n - q_n)^2} = \\sqrt{\\sum_{i=1}^n (p_i - q_i)^2}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La similitud por el cuadrado L2 es el cuadrado de la distancia euclídea, es decir:\n",
    "\n",
    "$$\n",
    "similitud(p,q) = d(p,q)^2 = \\sum_{i=1}^n (p_i - q_i)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similitud por coseno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si recordamos lo que aprendimos de senos y cosenos en la escuela, recordaremos que cuando dos vectores tienen un ángulo de 0º entre ellos, su coseno es 1, cuando el ángulo entre ellos es de 90º, su coseno es 0 y cuando el ángulo es de 180º, su coseno es -1.\n",
    "\n",
    "![cosine similarity](https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/dot-product.gif)\n",
    "\n",
    "![cosine similarity](https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/dot-product-unity.gif)\n",
    "\n",
    "Por lo tanto, podemos usar el coseno del ángulo entre dos vectores para medir su similitud. Se puede demostrar que el coseno del ángulo entre dos vectores es igual al producto escalar de los dos vectores dividido por el producto de sus módulos. No es el objetivo de este post demostrarlo, pero si queréis podéis ver la demostración [aquí](https://www.wwwinsights.com/wp-content/uploads/2023/05/image-11-1024x694.png).\n",
    "\n",
    "$$\n",
    "similitud(U,V) = \\frac{U \\cdot V}{\\|U\\| \\|V\\|}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similitud del producto escalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La similitud del producto escalar es el producto escalar de dos vectores\n",
    "\n",
    "$$\n",
    "similitud(U,V) = U \\cdot V\n",
    "$$\n",
    "\n",
    "Como hemos escrito la fórmula de la similitud por coseno, cuando la longitud de los vectores es 1, es decir, están normalizados, la similitud por coseno es igual a la similitud del producto escalar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, ¿Para qué nos sirve la similitud por el producto escalar? Pues para medir la similitud entre dos vectores que no están normalizados, es decir, que no tienen longitud 1.\n",
    "\n",
    "Por ejemplo, youtube, para crear los embeddings de sus vídeos, hace que los embeddings de los vídeos que clasifica con mayor calidad sean más largos que los de los vídeos que clasifica con menor calidad.\n",
    "\n",
    "De esta forma, cuando un usuario hace una búsqueda, la similitud por producto escalar, dará mayor similitud a los vídeos de mayor calidad, por lo que le dará al usuario los vídeos de mayor calidad en primer lugar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qué sistema de similitud usar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para elegir el sistema de similitud que vamos a usar, debemos tener en cuenta el espacio en el que estamos trabajando.\n",
    "\n",
    " * Si estamos trabajando en un espacio de alta dimensionalidad, con embeddings normalizados, la similitud por coseno es la que mejor funciona. Por ejemplo OpenAI genera embeddings normalizados, por lo que la similitud por coseno es la que mejor funciona.\n",
    " * Si estamos trabajando en un sistema de clasificación, donde la distancia entre dos clases es importante, la similitud por el cuadrado L2 es la que mejor funciona.\n",
    " * Si estamos trabajando en un sistema de recomendación, donde la longitud de los vectores es importante, la similitud del producto escalar es la que mejor funciona."
   ]
  }
 ],
 "metadata": {
  "maximofn": {
      "date": "2023-12-18",
      "description_es": "Descubre cómo se mide la similitud entre embeddings, la base del mecanismo de atención de los transformers y de los algoritmos de RAG",
      "description_en": "Discover how similarity is measured between embeddings, the basis of the attention mechanism of transformers and RAG algorithms",
      "description_pt": "Descubra como é medida a similaridade entre embeddings, a base do mecanismo de atenção dos transformers e dos algoritmos de RAG",
      "end_url": "embeddings-similarity",
      "image": "https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/embeddings-similarity.webp",
      "image_hover_path": "https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/embeddings-similarity.webp",
      "keywords_en": "embeddings, similarity, cosine similarity, L2 similarity, dot product similarity",
      "keywords_es": "embeddings, similitud, similitud por coseno, similitud L2, similitud por producto escalar",
      "keywords_pt": "embeddings, similaridade, similaridade por cosseno, similaridade L2, similaridade por produto escalar",
      "title_en": "Medida de similitud entre embeddings",
      "title_es": "Embeddings similarity measure",
      "title_pt": "Medida de similaridade entre embeddings"
    },
    "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
