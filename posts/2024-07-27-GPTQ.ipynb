{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En el paper [GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers](https://arxiv.org/abs/2210.17323) se expone la necesidad de crear un método de cuantización post entrenamiento que no degrade la calidad del modelo. En este post hemos visto el método [llm.int8()](https://maximofn.com/llm-int8/) que cuantiza a INT8 algunos vectores de las matrices de pesos, siempre y cuando ninguno de sus valores sobrepase un valor umbral, lo cual está muy bien, pero no cuantizan todos los pesos del modelo. En este paper proponen un método que cuantiza todos los pesos del modelo a 4 y 3 bits, sin degradar la calidad del modelo. Lo que supone un ahorro considerable de memoria, no solo porque se cuantizan todos los pesos, sino porque además se hace a 4, 3 bits (y hasta 1 y 2 bits en ciertas condiciones), en vez de a 8 bits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Trabajos en los que se basa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cuantización por capas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Por un lado se basan en los trabajos `Nagel et al., 2020`; `Wang et al., 2020`; `Hubara et al., 2021` y `Frantar et al., 2022`, que proponen cuantizar los pesos de las capas de una red neuronal a 4 y 3 bits, sin degradar la calidad del modelo.\n",
        "\n",
        "Teniendo un conjunto de datos `m` proveniente de un dataset, a cada capa `l` se le meten los datos y se obtiene la salida de los pesos `W` de dicha capa. Así que lo que se hace es buscar unos pesos nuevos `Ŵ` cuantizados que minimicen el error cuadrático en relación con la salida de la capa de precisión total\n",
        "\n",
        "`argmin_Ŵ||WX− ŴX||^2`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Los valores de `Ŵ` se establecen antes de realizar el proceso de cuantización y durante el proceso, cada parámetro de `Ŵ` puede cambiar de valor independientemente sin depender del valor de los demás parámetros de `Ŵ`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optimal brain quantization (OBQ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En el trabajo de `OBQ` de `Frantar et al., 2022` optimizan el proceso de cuantización por capas anterior, haciendo que llegue a ser hasta 3 veces más rápido. Esto ayuda con los modelos grandes, ya que cuantizar un modelo grande puede llevar mucho tiempo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El método `OBQ` es un enfoque para resolver el problema de cuantificación por capas en modelos de lenguaje. `OBQ` parte de la idea de que el error cuadrático se puede descomponer en la suma de errores individuales para cada fila de la matriz de pesos. Luego, el método cuantifica cada peso de manera independiente, actualizando siempre los pesos no cuantificados para compensar el error incurrido por la cuantificación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El método es capaz de cuantificar modelos de tamaño medio en tiempos razonables, pero como es un algoritmo de complejidad cúbica hace que sea extremadamente costoso aplicarlo a modelos con miles de millones de parámetros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Algoritmo de GPTQ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Paso 1: Información de orden arbitrario"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En `OBQ` se buscaba la fila de pesos que creara menor error cuadrático medio para cuantizar, pero se dieron cuenta de que al hacerlo de manera aleatoria no aumentaba mucho el error cuadrático medio final. Por lo que en vez de buscar la fila que minimiza el error cuadrático medio, que creaba una complejidad cúbica en el algoritmo, se hace siempre en el mismo orden. Gracias a esto se reduce mucho el tiempo de ejecución del algoritmo de cuantización."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Paso 2: Actualizaciones lazy batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Al hacer la actualización de los pesos fila a fila, esto provoca que sea un proceso lento y no se aproveche del todo el hardware."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Paso 3: Reformulación de Cholesky"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El problema de hacer las actualizaciones por lotes es que, debido a la gran escala de los modelos, se pueden producir errores numéricos que afectan la precisión del algoritmo. Concretamente, se pueden obtener matrices indefinidas, lo que provoca que el algoritmo actualice los pesos restantes en direcciones incorrectas, lo que resulta en una cuantización muy mala.\n",
        "\n",
        "Para solucionar esto, los autores del paper proponen utilizar una reformulación de Cholesky, que es un método más numéricamente estable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resultados de GPTQ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A continuación se muestran dos gráficas con la medida de la perplejidad (perplexity) en el dataset `WikiText2` para todos los tamaños de los modelos OPT y BLOOM. Se puede ver que con la técnica de cuantización RTN, la perplejidad en algunos tamaños aumenta mucho, mientras que con GPTQ se mantiene similar a la que se obtiene con el modelo en FP16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![GPTQ-figure1](https://images.maximofn.com/GPTQ-figure1.webp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A continuación se muestran otras gráficas, pero con la medida del accuracy en el dataset `LAMBADA`. Ocurre lo mismo, mientras que GPTQ se mantiene similar a lo obtenido con FP16, otros métodos de cuantización degradan mucho la calidad del modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![GPTQ-figure3](https://images.maximofn.com/GPTQ-figure3.webp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cuantización extrema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En las gráficas anteriores se han mostrado los resultados de cuantizar el modelo a 3 y 4 bits, pero podemos cuantizarlos a 2 bits, e incluso a 1 solo bit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Modificando el tamaño de los batches al utilizar el algoritmo, podemos obtener buenos resultados cuantizando tanto el modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "|Modelo | FP16 | g128 | g64 | g32 | 3 bits|\n",
        "|-------|-------|--------|--------|--------|---------|\n",
        "|OPT-175B | 8.34 | 9.58 | 9.18 | 8.94 | 8.68|\n",
        "|BLOOM | 8.11 | 9.55 | 9.17 | 8.83 | 8.64|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En la tabla anterior se puede ver el resultado de la perplejidad en el dataset `WikiText2` para los modelos `OPT-175B` y `BLOOM` cuantizados a 3 bits. Se puede ver que a medida que se usen batches más pequeños, la perplejidad disminuye, lo que significa que la calidad del modelo cuantizado es mejor. Pero tiene el problema de que el algoritmo tarda más en ejecutarse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Descuantificación dinámica en la inferencia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Durante la inferencia se realiza algo llamado `descuantificación dinámica` (`dynamic dequantization`) para poder realizar la inferencia. Se va descuantificando cada capa a medida que se va pasando por ellas.\n",
        "\n",
        "Para ello desarrollaron un kernel que descuantifica las matrices y realiza los productos matriciales. Si bien la descuantificación consume más cálculos, el kernel tiene que acceder a mucha menos memoria, lo que genera aceleraciones significativas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La inferencia se realiza en FP16 descuantizando los pesos a medida que se va pasando por las capas y la función de activación de cada capa también se realiza en FP16. Aunque esto hace que haya que hacer más cálculos, porque hay que descuantizar, esos cálculos hacen que el proceso total sea más rápido, porque hay que traer de la memoria menos datos. Hay que traer de la memoria los pesos en menos bits, por lo que al final, en matrices de muchos parámetros hace que se ahorren muchos datos. El cuello de botella normalmente está en traer los datos de la memoria, por lo que aunque haya que hacer más cálculos, al final la inferencia es más rápida"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Velocidad de inferencia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Los autores del paper realizaron una prueba cuantizando el modelo BLOOM-175B a 3 bits, lo que ocupaba unos 63 GB de memoria VRAM, incluidos los embeddings y la capa de salida que se mantienen en FP16. Además mantener la ventana de contexto de 2048 tokens consume unos 9 GB de memoria, lo que hace en total unos 72 GB de memoria VRAM. Cuantizaron en 3 bits y no en 4 para poder realizar este experimento y poder meter el modelo en una sola GPU Nvidia A100 de 80 GB de memoria VRAM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para comparar, la inferencia normal en FP16 requiere unos 350 GB de memoria VRAM, lo que equivale a 5 GPUs Nvidia A100 de 80 GB de memoria VRAM. Y la inferencia cuantizando en 8 bits mediante [llm.int8()](https://maximofn.com/llm-int8/) requiere 3 de dichas GPUs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A continuación, se muestra una tabla con la inferencia del modelo en FP16 y cuantizado a 3 bits en GPUs Nvidia A100 de 80 GB de memoria VRAM y Nvidia A6000 de 48 GB de memoria VRAM.\n",
        "\n",
        "|GPU (VRAM)| tiempo promedio por token en FP16 (ms) | tiempo promedio por token en 3 bit (ms) | Aceleración | Reducción de GPUs necesarias |\n",
        "|-------|---------|--------|-------------|------------------|\n",
        "|A6000 (48GB) | 589 | 130 | ×4.53 | 8→ 2|\n",
        "|A100 (80GB) | 230 | 71 | ×3.24 | 5→ 1|\n",
        "\n",
        "Por ejemplo, utilizando los kernels, el modelo OPT-175B de 3 bits se ejecuta en una sola A100 (en vez de en 5) y es aproximadamente 3,25 veces más rápido que la versión FP16 en términos de tiempo promedio por token.\n",
        "\n",
        "La GPU NVIDIA A6000 tiene un ancho de banda de memoria mucho menor, por lo que esta estrategia es aún más efectiva: ejecutar el modelo OPT-175B de 3 bits en 2 GPUs A6000 (en vez de en 8) es aproximádamente 4.53 veces más rápido que la versión FP16."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Librerías"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Los autores del paper implementaron la librería [GPTQ](https://github.com/IST-DASLab/gptq). Otras librerías fueron creadas como [GPTQ-for-LLaMa](https://github.com/qwopqwop200/GPTQ-for-LLaMa), [exllama](https://github.com/turboderp/exllama) y [llama.cpp](https://github.com/ggerganov/llama.cpp/). Sin embargo estas librerías se centran solo en la arquitectura llama, por lo que la librería [AutoGPTQ](https://github.com/AutoGPTQ/AutoGPTQ) fue la que ganó más popularidad porque tiene una cobertura más amplia de arquitecturas.\n",
        "\n",
        "Por ello dicha librería [AutoGPTQ](https://github.com/AutoGPTQ/AutoGPTQ) se integró mediante una API dentro de la librería [transformers](https://maximofn.com/hugging-face-transformers/). Para poder usarla es necesario instalarla como se indica en la seción [Installation](https://github.com/AutoGPTQ/AutoGPTQ#installation) de su repositorio y tener instalada la librería [optimun](https://maximofn.com/hugging-face-optimun/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Además de hacer lo que indican en la sección [Installation](https://github.com/AutoGPTQ/AutoGPTQ#installation) de su repositorio también conviene hacer lo siguiente:\n",
        "\n",
        "```bash\n",
        "git clone https://github.com/PanQiWei/AutoGPTQ\n",
        "cd AutoGPTQ\n",
        "pip install .\n",
        "```\n",
        "\n",
        "Para que se instalen los kernels de cuantización en la GPU que desarrollaron los autores del paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cuantización de un modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos a ver cómo cuantizar un modelo con la librería [optimun](https://maximofn.com/hugging-face-optimun/) y la API de [AutoGPTQ](https://github.com/AutoGPTQ/AutoGPTQ)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inferencia del modelo no cuantizado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos a cuantizar el modelo [meta-llama/Meta-Llama-3-8B-Instruct](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct) que, como su nombre indica, es un modelo de 8B de parámetros, por lo que en FP16 necesitaríamos 16 GB de memoria VRAM. Primero ejecutamos el modelo para ver la memoria que ocupa y la salida que genera"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como para usar este modelo hay que pedir permiso a Meta, nos logueamos en Hugging Face para poder bajar el tokenizador y el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Instanciamos el tokenizador y el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "checkpoint = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForCausalLM.from_pretrained(checkpoint).half().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos a ver la memoria que ocupa en FP16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3L2v5uu0GOrn",
        "outputId": "9954a8c6-8977-4357-f9bb-3d65e968baec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model memory: 14.96 GB\n"
          ]
        }
      ],
      "source": [
        "model_memory = model.get_memory_footprint()/(1024**3)\n",
        "print(f\"Model memory: {model_memory:.2f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vemos que ocupa casi 15 GB, más o menos los 16 GB que habíamos dicho que debería ocupar, pero ¿por qué esta diferencia? Seguramente este modelo no tenga exactamente 8B de parámetros, sino que tenga un poco menos, pero a la hora de indicar el número de parámetros se redondea a 8B."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hacemos una inferencia para ver cómo lo hace y el tiempo que tarda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyc2pxH-GOro",
        "outputId": "ec237325-7a4a-4813-cff6-ba8aca69a279"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello my name is Maximo and I am a Machine Learning Engineer at a startup in the Bay Area. I am passionate about building AI systems that can help humans make better decisions and improve their lives.\n",
            "\n",
            "I have a background in computer science and mathematics, and I have been working with machine learning for several years. I\n",
            "Inference time: 4.14 s\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "input_tokens = tokenizer(\"Hello my name is Maximo and I am a Machine Learning Engineer\", return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "t0 = time.time()\n",
        "max_new_tokens = 50\n",
        "outputs = model.generate(\n",
        "    input_ids=input_tokens.input_ids,\n",
        "    attention_mask=input_tokens.attention_mask,\n",
        "    max_length=input_tokens.input_ids.shape[1] + max_new_tokens,\n",
        ")\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
        "print(f\"Inference time: {time.time() - t0:.2f} s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cuantización del modelo a 4 bits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos a cuantizarlo a 4 bits. Reinico el notebook para no tener problemas de memoria, por lo que nos volvemos a loguear en Hugging Face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Primero creo el tokenizador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OB_8mAOcGOrp",
        "outputId": "07b37ab2-5ac0-4833-ec27-0f8075935d49"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora creamos la configuración de cuantización. Como hemos dicho, este algoritmo calcula el error de los pesos cuantizados sobre los originales en función de entradas de un dataset, por lo que en la configuración tenemos que pasarle con qué dataset queremos cuantizar el modelo.\n",
        "\n",
        "Los disponibles por defecto son `wikitext2`,`c4`,`c4-new`,`ptb` y `ptb-new`.\n",
        "\n",
        "También podemos crear nosotros un dataset a partir de una lista de strings\n",
        "\n",
        "```python\n",
        "dataset = [\"auto-gptq is an easy-to-use model quantization library with user-friendly apis, based on GPTQ algorithm.\"]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Además, le tenemos que decir el número de bits que tenga el modelo cuantizado mediante el parámetro `bits`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import GPTQConfig\n",
        "\n",
        "quantization_config = GPTQConfig(bits=4, dataset = \"c4\", tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cuantizamos el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "9c0e827b02c2460b9df6c95010d662c7",
            "accf49aab911472186388c1d1f9635c1",
            "fad3879680cd496c8be3d59c1f38b4b1",
            "568209c401504e95805ce62134918611",
            "7f885913033243158a2a858ad549842d",
            "06205a7799f0441ca8573d7d8d852241",
            "7375fba2e65943c19d72d52dfa0acab5",
            "f651a4a9afe34549a6ad5be3bea00205",
            "4fe005ce2cf44427ba3a7dc603ae0e24",
            "23df9cbc2bea4524859308a57445de7e",
            "12856fb10e95415c8201d41759f86317",
            "97872f48c3934ad1add435a93bf2f0fa",
            "40913f045f184ae0997c5ae82aebd88e",
            "463e33169a854f809b56ce145780b10f",
            "80823a6564fc4f49a417ab09a6ea654a",
            "0d85d1551b3a4dee9f034851ea137ef6",
            "bed3003eb6f44546a0fef87c9bed6611",
            "d6f404ea3e2345ceb210a017f438b31f",
            "6f97cd3342aa46a68922da35b1a44092",
            "794f9b8193c74a04aed6bf82695ab864",
            "ea30781cb15d48389b153820b6219e6a",
            "ef5cf40d4b854657b7f531aa52a1770d",
            "2170d5d5ecec4b5bad63ca01d72c00e8",
            "449720d95c964b7fb2600e4ba30874d1",
            "6520b3c130674b71a3090b38e3e80123",
            "de1fd56d05e74548a76154d912998f25",
            "ee8d487d42384cd59991d7c504dc8cb5",
            "93312313b63e40a5a409617dc5d877cb",
            "6a70a48ba4ff41e09a05305581d6e9cb",
            "09b0967b578d44a5b4f0f725f71903dd",
            "bbe331ddb7814ffd8b4069c4d9a3c62e",
            "95080198654a458eacfda097e4df7d1e",
            "75dc405cedc74bd4a046a77ccdb82471",
            "75e612250a4049198ed65b1b45a606bc",
            "9badeb33ae204b49a58004f862952f87",
            "f57bc35d4ebf4fb5969a2f9bdac4975a",
            "7fd8e43b524e4e058a3535b26f3be90d",
            "b6f6a1ce980c4474aa599803b2aa3915",
            "3c6194dc73fc462681ad33f627980179",
            "dae3c39ea6bf4d5380b825525fc8b6fd",
            "1809926b3ac340fab73dceb78e9776d6",
            "a7f34d963d5c422287ec25fc8aca1022",
            "3c87893bb9b940369633d0c684475bdb",
            "e923d1e4c68b40059235acf924bd1498",
            "2c62e1adda524c01b58b4773547fe533",
            "a1b9066144f4450a97355d4858f16082",
            "49275222eb544c51b3142eabb6907923",
            "88f93764f8f44a039edbfb1fa153ccbd",
            "5c73e6d0243e4c38958a093e7a36d2a3",
            "83e92a6f00ce46c4972d56652b28cd22",
            "7867f83436854cf59ea9aa059ae4fb86",
            "04da9a038c4245b79a708a4c3f09a30d",
            "bb1f313587bb47898acc022b92cc6f33",
            "64569c12fa3540f590f3309cbb95f244",
            "5e98810da5ff494bbdf0dc72913ca5f3",
            "3146af3f165d4fcb8bf5e36768ae3055",
            "74cfd2b002e0425ba628d4d61828a504",
            "d0b9b1f77b724a6f80862edf42f02f20",
            "2a9562aed39240208f47827e6027ee1c",
            "b3ec883f5563459e896532f0893d11c6",
            "f91da81777cd490bb675351f2d7244a4",
            "d2804652973c4c01820b6c5632f7f4ef",
            "ee230ed52f014d31b2489dea066c00b6",
            "3ab007150045450a9c4a38e0a1f7b963",
            "b6e686f50cb24c45ba930c2d03699b27",
            "96cc6501dfb9491b893f5e974a8f0e0d",
            "df024f8a2ecc4283b2d69438c0a00a75",
            "d6e964bf26b043dd94a71fed5c0f93eb",
            "7990039ae4c44ac084a4e1f0074a38c8",
            "da6006278152411292383fe5801f1138",
            "216881e739344d3aad4fb9f044801710",
            "e86e23deef7c4fc3aed7fcc740db3bc2",
            "949a339d2f9841b4a9a2d3dcc9647f1b",
            "fafa16fd7d444428a7c791c55839211a",
            "88b81ff649564cad904da2cb518c0ee1",
            "965f0187defd42da80a90991ef0cee42",
            "4f9cfd5296e24a96a3d35be5902841b4",
            "8e162ace8f4f4cb4aa38baf7de4668c1",
            "52128376ce86440f82783b39c8afff17",
            "dadc61e3fbcb4740bff70bf62325dbce",
            "9a277dc63ba44f0f97153666a8780efb",
            "e0b940d6af874cf1862aa392bb36287e",
            "91217ba18dc248508daa1abea462198c",
            "94a631e50bb74b3cbab2a0e08e8d1019",
            "1dda5b21de0d4fe78e034a9cc55e7f0a",
            "168fdbd520ec4af88004de0e0ad13a0c",
            "e0e2d3c2ae584c0e9ab21ffaf8fbf834",
            "5b9804bc4b8f47c99710b22fd64c9829",
            "bd62c762d8214ba38dcdb201968739d6",
            "b1537a9403b34516baa3b1b47fdcde55",
            "56f4b26ff5eb4cd1b7ecda83f7bae905",
            "d89751b9ad5a46629fe6f5f9cec0fa89",
            "e4b0f71584a343a88218c5ba3f20fa8f",
            "eb0fc48dfadd45009296ccf0a76c4254",
            "722b15cd185343e7bc81912d37c76642",
            "51a4c5cb2b0b4ffb9af7aa0c7d10caa8",
            "10e8e72c68834e95bfec1de6e3b2a687",
            "ffe19b76d9d7428fb523d09c664db0c9",
            "234a65edd40e48cca24bc889860a4f35",
            "575451891a3b41628e913324041ba0c0",
            "8bc51c3d08b8494f87a23e701be944f2",
            "8208164cfb994b3cbd1bdb8338c1be6d",
            "1d2b9673f4bb40ba997905a089584243",
            "216b5553a49349c1a33211fc4f80c4b8",
            "b451960baa2e4bd8826be317a5bccd33",
            "ff7f0af4d69d47b6b236c450cda1e0be",
            "8fd37529479f4850b5fb52f34773d3f8",
            "fa613ca2aa724d9681dcc1996c4bbc1e",
            "cb9d332948a64f1d987a045f662210d1",
            "7982037bc7f84532b659b3ceb0535efb",
            "c1d23a80464c424b840a7e437a8dec9b",
            "4c58a56afc5645089b9803125c69a527",
            "9581a11ffdc5472aaa361861833b7e5d",
            "17a69d7963034c5ea71c172f62132eaf",
            "f2d69558b586449cb8444f2aeaff2ca4",
            "7e6c6aa512324b54a6ea7a8bb453f347",
            "e8257d1f8bf648f8b1e8ba75760e4bc3",
            "1cce611b2360498b838ca0feaf73080a",
            "1dff6122dcc54d0095117686222c4ee0",
            "5aa5e5dd3f1042938a2d971a3678f2c7",
            "300a436b00e24512ab72acdec6e97eef",
            "f8fe5062cb364ca6935dd164e74bb8fa",
            "136ea71ba59a40d6bb867784ae19293c",
            "675a59e262184af6843f8474049874d3",
            "5afc505345274fd99201a8ab71296256",
            "05a8466e211d4a2d8a41d97231a943ff",
            "0ae15467a0f0422bb060739126de356b",
            "9d29bf60dace4543b055d859519f6a88",
            "096e12f34dd74a74a0a39aa3cda12382",
            "fd43573500264875af39656231ef23d6",
            "96eaf6b1195449cb81a9313f49f326d1",
            "161892c3f8614356bf270d763c879d5d",
            "2fc727767f6c43a9a945b990ae64135e",
            "b1eb3e8872ff4436894be0db4f85097a",
            "d8e3601800914b3aaaab50a8cdcd04d0",
            "c3af3b9260074fb4976085f61cfff5c3",
            "ef859f73ff5e406c92d5b467a57ca778",
            "4c3720762b8a42b296d224a412421143",
            "5903d2825b0d46ad9eb22a5cb16e9d16",
            "c86c1ece2c4149829dc11621e41d6689",
            "654d7038fd204751a6daf7b7405ca8b3",
            "abad00fc0ef04ef19584e9b7896dae71",
            "cdc100c05f8f4eaf85824c9d16052405",
            "c371730adafc44ef8752250a1d9da2ed",
            "880c373da6454604a0f7ff2e0fae45bb",
            "f12a2a2ccc494afbb5e59846bc3e1154",
            "7d965fe63e3f4e75abb41e8c6c37fc12",
            "0b66f7da0d0f4deba26b284c89f55aa2",
            "eb5bc073449e45549636ecdc34cd1298",
            "d100fbe2810f45218bbfc203a5466e07",
            "7ba8711a59a1407e90165dc5facbdb0e",
            "72e87e47152f4a73baa4559bbdf27e52",
            "957875f90336433da96d3ce7d975a844",
            "9b6a4957890b42aba54f19116b6bce66",
            "5f89d44512b242f6ad14c20ccf57fc12",
            "4cceaec1e8be4c269ec1820d0292bb29",
            "8aca2b1cc18e4eabbb7aafd280f5d035",
            "5a6e1e84f6dc43d9b69b593592716366",
            "ba37bb3160b843af84dd22cb6ec1cf76",
            "822134d340ed4376b907ec5f677fcd85",
            "bdf403fb3b184c31a51695302f81e57a",
            "3237d553fdc946b2bdb7d416c9dbca93",
            "9a03dfdec0964f79b3d91e83c8bbf363",
            "104e6056c5fe4cb6938482bb5fc3e65f",
            "0468ff1a0c104bb797954152c5dc4e11",
            "5e4415f8eacb48eb92ce02c21a2b2978",
            "1f5940d545e2423db31738bffe1a03f0",
            "e823f51872b14641a109b6d4c62ac0c9",
            "d0e3163229bd48a69efd233caec71964",
            "0cd7ed68ce5341ae86f383ef376daa7d",
            "c340a45ae84e4576b8d3fc9843777315",
            "22b0a4a09fa74f09bc50d33cc55b0005",
            "3c823648e08749c38ece887bc041d9aa",
            "bfc2aed435664f63b327ddbebca8c30b",
            "d1a45e672a0f4bafa6128ff8e2b4b81a",
            "11989cc314eb41868727be6fba6143c1",
            "5def5f56f0374dd2a1bad9217bdb26c4",
            "b02342a5c6f6474c99e3faa2961567cd",
            "a85ca6265c3d4c84bc3e4c717419c14f",
            "6fd7f73c9c58452ea151d59d425cfd2c",
            "4b33c5d8843e4ae1bb173115b20828db",
            "fd06d051af694665851bc497cc03ecb5",
            "b66582b9a8ee43ffb3c148d1d43a398b",
            "211261d6e2a747919ccd70665062e25a",
            "f4fb8367d138483290101984ed102c5e",
            "40146bfb5de947e0aef2495c53ad5fb6",
            "9fb4ce3bca96443db10037b06741555b",
            "96f7ff7d536d406c8aa768981d947773",
            "2152dfa52e174f0e9ec647b8f47a0bb8",
            "d173d78aad674607b27555b0502c5df4",
            "1ad4d58717314e8fa513871294564a7c",
            "e559462209bb498092bad6e7d24fb93a",
            "45ea15b9517a47f5866ef310d38463da",
            "d06661dda53c4ca18953f54f0ece8e10",
            "32b908eb756549f1a4575177d73f9da7",
            "c3502e337f9c4ee083c19a88e744cd0d",
            "c93200acd9284e3c803898a9312cbc55",
            "db6af6c67adb471c88285b1799ada3b6",
            "62f53286bf96498daa19e012087ba064",
            "3d8e96a300fc43edb7edd905bfbba67c",
            "b1e6e3635d414474b94018d0cbd3da6e",
            "2c42a8c476fb44129b0501ad5656a2c2",
            "44150b8f0aad4f9692dc57ddd989aa34",
            "023974c2116a4504a52deef55e1b515a",
            "4534d503d0ef41d1819e7311eb340a05",
            "787a3db04ba242e2a504befd25dfcbc6",
            "7b8d2494e7f24f14bd0a4cf800f7a381",
            "8c85fd1cc16143e48e8e210636da4fb8",
            "94f11ae8b8fb45c7b53f42b71b0fdb63",
            "aa599dfb176446b38cf30d2e6136e002",
            "0b87fdabead344b88c6878a044564c45",
            "2345107504eb421a97314cb011d77afa",
            "fbe40fe687b844c18c4d5c6c8cb6e436",
            "948e9b015fba478b8dbe01ba9ec15d84",
            "0968d77d26ad419cb8697fbf490989aa",
            "8f7b676da2a04137bb17e85eb7b23847",
            "636115d4c96f4387b341fdddcdd962ea",
            "62bcb3b7b3a44422ae2cc9022450208c",
            "c7e4b8ca91334db4bc08869f590cd4dc",
            "fe4791a90e4d4bc7aed81213f4f144bd",
            "f200b9fdb1c742b1a6f7cc52ac2e78cd",
            "90a99aa6f095433288f84e85a6ed14de",
            "16101c9598194508944a97885e8ad79b",
            "2c0ac8713afb4da5ad0ce5b86be3f1a7",
            "966bbaea26e74bc59fc7423b8313c261",
            "ad1b34145df1486da9891c055deca14d",
            "580e8b8d21c04fe698e893eab0ed178e",
            "9b500c04ffe74d1eb81f3c3573fdc917",
            "1b5fbb3979f14b1fa1cf8d8297a03edf",
            "d91544d4d3cb4d2fb4c0b6707fd5c992",
            "81348f875f9e4d978744592dca35dce8",
            "39b7050342da4a039fe85ed39a3cd110",
            "4ad365bd98634ac88b41712676166dc5",
            "ecf2fb9b4ddf4914b3eef4411dabed82",
            "0c82c1db491f4db6b42ff6f756a3fdbf",
            "722f4445939b4e6d8166233d7c34d82e",
            "fc4e218dac374943b2e8dd8cfe387107",
            "d002fbce75d6410c9cabd54e62f0301f",
            "659ab032d74b4dc4913fcfcc8b0ae983",
            "644dd214b960441d9e475d46f67d54bf",
            "3e128b934ee44b1497bd9501e0f6a9bf",
            "5f5cb511b00a496fbf61075a93c99cab",
            "57d601bc111848a7a54a2703fed80a53",
            "23d81281721e4b268ae57295c9009d24",
            "733f7d7097eb44e08d847acd124c6995",
            "21e1eee0cb834bf5996d06b15be50ba2",
            "a8903ec6344644a19548f0a8e1968113",
            "2b7ebfe9cac94c4f939c71758f51afdb",
            "eb4f7a0ce98b4f7cb87bd3ecbcad6154",
            "8307f71ebb0f4ad2be7e2ce18eb89041",
            "573dc16aee234539b696eab22bbc81fe",
            "279dbea69071477b907cab68f91e2e39",
            "fc6892bd5d5d4c6a979c600131e1565e",
            "6cce9ec0f7fa48e890c72e4ff71b6176",
            "0ed6f612cff74d6295460247cf3d51e9",
            "79939970bacb45eeb0e5bc8c093a710c",
            "abb0dbbaf498498bb9140e7dbfe31f63",
            "53562e716e4849ae99a5e6fa47706940",
            "a0ea9a67246842eda74840b0a41a3a11",
            "f5fb5b3975aa4152ad0733324be5de1e",
            "c04cad833f4648aaaf1695b06d3f263e",
            "c79109466c9d4be6a5d411236d5d433f",
            "ab3416137730457788e6130816d52000",
            "c82ddbd7a444446094bcb5191c1bf030",
            "04371037b80347ceaa380d4573d3aa76",
            "520c4650b9b54170bf7884accfc3f304",
            "15afb9a0965947da87f406b15accdeae",
            "575387998d464c4d9db015c58b31180e",
            "6dfc06205c6d4493b646450f383d0759",
            "cc187aa7775a47ffbe3ab32fc0356a45",
            "ee94c874edf24cc09a1e6d0313c39f17",
            "45ab9ab621a94502b5f1e0a27334cead",
            "092cd96a3c924c3e96dbe158f81dafe8",
            "a0caff03acff4f12ac2b2783fcae3bee",
            "73f04618ccec40d5b8381a149f623b99",
            "5fda8fc77e434473abaac6ebc47fc0e7",
            "1c1528e8b0864fb4be1aa15a373ade7a",
            "f3c4996001854171a65ff2e2293d8624",
            "b9b099aed4d44662bd566c8c9c2c7ccb",
            "081d3f5a97ed46cfae49d89a003a89d6",
            "bc7c7527cd1741ae86b717a41857e452",
            "4172e1bf4652407e8738098a59da8c0c",
            "da159e288a9641bb8b609818a6ecb0f9",
            "d7fab4a9d5be4d51b0a0cf3552e74ee2",
            "a55f0c861957440bb25be1bb86a23c66",
            "6219df8de7d043ed8a95673a333803d5",
            "297b491a215d44528e7150a83fad5885",
            "ae30cea5253e45dba111f1ed5b1dad69",
            "5a504ff21db349b4ac043e2692dc5350",
            "aec725068a01459b835440866d7e5544",
            "177c3b4997364a268059fc89fdca478f",
            "6c0fff4a955443a58aefe9b3c96e68a0",
            "96300d1581384069b5695043495dfb1d",
            "16adadb389e34222a40508595bc9b9e2",
            "5cb904e3040b4341bb6736fb8ab817c1",
            "ed5f6a134a344a7eb85dfa1a3f4eaf69",
            "d4a577dfca2344918ae9def52d2c7afe",
            "d1bb128301664536b58b46ae19f0de44",
            "61d76afe59b84da980692235cdac3ac8",
            "40fd08df6f774fc696adcfd5207c36e2",
            "9c0bedfd6fa546ce8ce7c082a74f4d7b",
            "d72ba458652d4ab4960ae046ff541bf8",
            "1f276bea85784121b1d1490ba9e4d694",
            "8d3d91cda0324c89a69c1c6dce1e732b",
            "4a681a4d49444fc6ad128771da82c926",
            "448933e0f1154ab4b77de6089bbc0b3c",
            "128d80b920b84d3f9b59db1cf3d7c893",
            "e810f3c120e3418fa094faa4cd4afeb2",
            "c3f338f13284442c94e0d5ff1fbf45b1",
            "2677bef15fc3473a844953e7e81891b9",
            "f3b469b0b63c454ea04058346df1f1bf",
            "b8f064731d3a4977994785d1a40f9ddf",
            "2f88a155d8d74faba1ae9d02e46c9ca5",
            "ce2a4e41a1b94a568593ea6d1b779748",
            "3cdd7b43971e4634aed999f19df2e6f5",
            "bae6a3a66f604eaeaa0c62ee137a573b",
            "f8531bb888b540d59061c2439050041f",
            "32a9dfb0b678454fbfac772660becc64",
            "b6cd00a34b7c49d7b474f9deb1fd648b",
            "ad3c3e916168492ebce84d2b00385445",
            "0f0e685cde1a4410a27f33cb4a9e4bec",
            "fc4d27573fd744408371593615072885",
            "a2305b68a3384db4bf94efc1099eba78",
            "fb92a912920f49eea4bb09d6b6d6244f",
            "09fce6ed53ca4e80a3c6deee34ae142a",
            "f7d69eb37d044d1f9ed72bbcf822c72d",
            "c07d8ac51d7a4b548693fab1177eeaca",
            "9e6625603d8549cbaafa59cf91592f72",
            "556b1bf3110e49689450e8f1a37b7414",
            "48ad2d44a11740feb04132ae1891fb1d",
            "b5ce1a91484e43d8a25040c1bf20c8a7",
            "0021403bec1145b8b66d08adc5c70bf1",
            "2b8d1b2cd5ee4698857844debd38af27",
            "cb904f123b9546c6b29e8c9c5caebbaa",
            "236587eb5106452288ec172554074d73",
            "e6db50215eba48f2b47138e03cfdd784",
            "3ffd2bb4eb9040439f36c1fc0ae92323",
            "b0eaa980b15c4bccabadbccb42daceff",
            "eaf24b8d623547b081804a5fd6b20b7a",
            "a59cfb213b1940a5a03cde86e9adbbe9",
            "9c1be759e95543a6968a416775f97faa",
            "21606c4d8b3f4a77a733322514f6089e",
            "b676cc9c76764e7d80c93dfd181b8378",
            "da7d295bcbe34681aff880fcd2b9788c",
            "3bca39ac895d49e3bb3c7d828b65ff70",
            "3aa0cbac936b43a5ada5793128f5ed18",
            "2a32497f0060422598a30e3dc8ca7163",
            "6d448ccf046d4b47b7874fe8365059b7",
            "47b93a1b6263427fb98ee155e1d3bf5f",
            "43f70c751f3348609b271d1c2cbfe521",
            "9b38648e6b3349a2abb3d232c5df79dd",
            "cedb0ee6bded4b59abfa74ca6a53bd82",
            "09584493dd4d4b91ace847cfdb68809c",
            "37042f9a05534f839451425997704a5f",
            "660401aec9584e669c3ae31eedc99e56",
            "4e3515bb726643f78b8f892db9cce160",
            "c7cc22133eda46a6899430230b03dabb",
            "1f967a3a4c034ae792179e7dd59c863a",
            "bf86eb70d92f4b3aac4898adadd03cc5",
            "d24fe6975f7c4e05bab26b041dcb7dec",
            "f202de456bac49c195195ceecde31f17",
            "7a38ae71c7b94334a8e20d43f60f37da",
            "e850adce5f8d47d3a204911c8ffb626d",
            "c67e13ecf0f24bfaa619432a3998caff",
            "eb119d50ac524de9abf791c21f3f85de",
            "9ad32386184646948a9312acf403e5cb",
            "36b78c7316934c169fa0f5511a0804a7",
            "81b93dc0237d4d2f8db86dc7f3c033e0",
            "bf96c372bc5942e380e9a6424a64f721",
            "dc30ac5db6d54c099689f8e8e6833174",
            "543dd2f5fe934c6bbfe42b9756a2c96b",
            "a8908e3d8b3f47f2b9ad2c8e4e46c546",
            "c5f0adfe610c4d1d8766358d73eabc00",
            "e1dcc3093b1f49ec95b2fc83d82fecca"
          ]
        },
        "id": "tXrc9udpGOrq",
        "outputId": "e7460160-8e38-49bd-cb24-673c66c10823"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c0e827b02c2460b9df6c95010d662c7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97872f48c3934ad1add435a93bf2f0fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing model.layers blocks : 100%|██████████|32/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2170d5d5ecec4b5bad63ca01d72c00e8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "75e612250a4049198ed65b1b45a606bc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c62e1adda524c01b58b4773547fe533",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3146af3f165d4fcb8bf5e36768ae3055",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df024f8a2ecc4283b2d69438c0a00a75",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e162ace8f4f4cb4aa38baf7de4668c1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd62c762d8214ba38dcdb201968739d6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "575451891a3b41628e913324041ba0c0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c1d23a80464c424b840a7e437a8dec9b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f8fe5062cb364ca6935dd164e74bb8fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2fc727767f6c43a9a945b990ae64135e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c371730adafc44ef8752250a1d9da2ed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5f89d44512b242f6ad14c20ccf57fc12",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e4415f8eacb48eb92ce02c21a2b2978",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5def5f56f0374dd2a1bad9217bdb26c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "96f7ff7d536d406c8aa768981d947773",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62f53286bf96498daa19e012087ba064",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa599dfb176446b38cf30d2e6136e002",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f200b9fdb1c742b1a6f7cc52ac2e78cd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "39b7050342da4a039fe85ed39a3cd110",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "57d601bc111848a7a54a2703fed80a53",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6cce9ec0f7fa48e890c72e4ff71b6176",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "04371037b80347ceaa380d4573d3aa76",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5fda8fc77e434473abaac6ebc47fc0e7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "297b491a215d44528e7150a83fad5885",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1bb128301664536b58b46ae19f0de44",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3f338f13284442c94e0d5ff1fbf45b1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad3c3e916168492ebce84d2b00385445",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b5ce1a91484e43d8a25040c1bf20c8a7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21606c4d8b3f4a77a733322514f6089e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09584493dd4d4b91ace847cfdb68809c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c67e13ecf0f24bfaa619432a3998caff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:4565: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quantization time: 1932.09 s = 32.20 min\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "import time\n",
        "\n",
        "t0 = time.time()\n",
        "model_4bits = AutoModelForCausalLM.from_pretrained(checkpoint, device_map=\"auto\", quantization_config=quantization_config)\n",
        "t_quantization = time.time() - t0\n",
        "print(f\"Quantization time: {t_quantization:.2f} s = {t_quantization/60:.2f} min\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como el proceso de cuantización calcula el menor error entre los pesos cuantizados con los originales haciendo pasar entradas por cada capa, el proceso de cuantización tarda. En este caso ha tardado una media hora"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos a ver la memoria que ocupa ahora"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-yo-5naGOrr",
        "outputId": "828073a9-9857-47d8-a994-92b872d69513"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model memory: 5.34 GB\n"
          ]
        }
      ],
      "source": [
        "model_4bits_memory = model_4bits.get_memory_footprint()/(1024**3)\n",
        "print(f\"Model memory: {model_4bits_memory:.2f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Aquí podemos ver un beneficio de la cuantización. Mientras que el modelo original ocupaba unos 15 GB de VRAM, ahora el modelo cuantizado ocupa unos 5 GB, casi un tercio del tamaño original"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hacemos la inferencia y vemos el tiempo que tarda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkme-CsOGOrr",
        "outputId": "3f4a0cdc-ced8-45ee-9494-49013ae396fd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello my name is Maximo and I am a Machine Learning Engineer. I have a strong background in computer science and mathematics, and I am passionate about developing innovative solutions that can positively impact society. I am excited to be a part of this community and to learn from and contribute to the discussions here. I am particularly\n",
            "Inference time: 2.34 s\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "input_tokens = tokenizer(\"Hello my name is Maximo and I am a Machine Learning Engineer\", return_tensors=\"pt\").to(model_4bits.device)\n",
        "\n",
        "t0 = time.time()\n",
        "max_new_tokens = 50\n",
        "outputs = model_4bits.generate(\n",
        "    input_ids=input_tokens.input_ids,\n",
        "    attention_mask=input_tokens.attention_mask,\n",
        "    max_length=input_tokens.input_ids.shape[1] + max_new_tokens,\n",
        ")\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
        "print(f\"Inference time: {time.time() - t0:.2f} s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El modelo sin cuantizar tardó 4.14 segundos, mientras que ahora cuantizado a 4 bits ha tardado 2.34 segundos y además ha generado bien el texto. Hemos conseguido reducir la inferencia casi a la mitad.\n",
        "\n",
        "Como el tamaño del modelo cuantizado es casi un tercio del modelo en FP16, podríamos pensar que la velocidad de inferencia debería ser unas tres veces más rápida con el modelo cuantizado. Pero hay que recordar que en cada capa se descuantifican los pesos y se realizan los cálculos en FP16, por eso solo hemos conseguido reducir el tiempo de inferencia a la mitad y no a un tercio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora guardamos el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGgCBlJiIymX",
        "outputId": "2eed6369-e4eb-42df-a65e-ae0be7036764"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('./model_4bits/tokenizer_config.json',\n",
              " './model_4bits/special_tokens_map.json',\n",
              " './model_4bits/tokenizer.json')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "save_folder = \"./model_4bits/\"\n",
        "model_4bits.save_pretrained(save_folder)\n",
        "tokenizer.save_pretrained(save_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Y lo subimos al hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b615761418814051b554c9d3e4ff485b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 100%|██████████| 5.17/5.17k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/Maximofn/Llama-3-8B-Instruct-GPTQ-4bits/commit/44cfdcad78db260122943d3f57858c1b840bda17', commit_message='AutoGPTQ model for meta-llama/Meta-Llama-3-8B-Instruct: 4bits, gr128, desc_act=False', commit_description='', oid='44cfdcad78db260122943d3f57858c1b840bda17', pr_url=None, pr_revision=None, pr_num=None)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "repo_id = \"Llama-3-8B-Instruct-GPTQ-4bits\"\n",
        "commit_message = f\"AutoGPTQ model for {checkpoint}: {quantization_config.bits}bits, gr{quantization_config.group_size}, desc_act={quantization_config.desc_act}\"\n",
        "model_4bits.push_to_hub(repo_id, commit_message=commit_message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Subimos también el tokenizador. Aunque no hemos cambiado el tokenizador, lo subimos porque si una persona se baja nuestro modelo del hub no tiene por qué saber qué tokenizador hemos usado, por lo que seguramente querrá bajarse el modelo y el tokenizador juntos. Podemos indicar en la model card qué tokenizador hemos usado para que se lo baje, pero lo más probable es que no se lea la model card, se intente bajar el tokenizador, obtenga un error y no sepa qué hacer. Así que lo subimos para ahorrarnos ese problema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bddd266d2955402e8480511b165a58be",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 100%|██████████| 0.00/5.17k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/Maximofn/Llama-3-8B-Instruct-GPTQ-4bits/commit/75600041ca6e38b5f1fb912ad1803b66656faae4', commit_message='Tokenizers for meta-llama/Meta-Llama-3-8B-Instruct: 4bits, gr128, desc_act=False', commit_description='', oid='75600041ca6e38b5f1fb912ad1803b66656faae4', pr_url=None, pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "repo_id = \"Llama-3-8B-Instruct-GPTQ-4bits\"\n",
        "commit_message = f\"Tokenizers for {checkpoint}: {quantization_config.bits}bits, gr{quantization_config.group_size}, desc_act={quantization_config.desc_act}\"\n",
        "tokenizer.push_to_hub(repo_id, commit_message=commit_message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cuantización del modelo a 3 bits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos a cuantizarlo a 3 bits. Reinico el notebook para no tener problemas de memoria y vuelvo a loguearme en Hugging Face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Primero creo el tokenizador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OB_8mAOcGOrp",
        "outputId": "07b37ab2-5ac0-4833-ec27-0f8075935d49"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creamos la configuración de cuantización, ahora le indicamos que queremos cuantizar a 3 bits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import GPTQConfig\n",
        "\n",
        "quantization_config = GPTQConfig(bits=3, dataset = \"c4\", tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cuantizamos el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "484f8d4e44d24bf1b08b6285a3a1f885",
            "48bf9144badd4501accb5b133fd86efe",
            "8bfe514cc4ba4f77bf6bcfc3eef5e9e9",
            "eb4dceaeb7e5413185bde9f8ee678c06",
            "ea4e6ca034474785a5fe10a20d2005ba",
            "a0628c9fab3c47e49f75fef3d13998c7",
            "21f0ae03ef794c61abda7d58b4b248e6",
            "54e04a507eba4d6b9e32302baac518c4",
            "0001ae9fef164209b814ab0ce3b5dad5",
            "dbe5c1ad9c18488eadfa8db4f1614e1e",
            "e060cf72559b4ac489f4a2db71006952",
            "c53a47f9e3b44e96ac79771602379969",
            "8ecf458eeac24217847ae2fcb0411874",
            "d0ca0bbdad514c96ad8210bff6e01873",
            "abcc94533fe248b9a17e4eca9c2a5a77",
            "84c567f82d364367b316d94af0c9fe9a",
            "6c2bc2a2b13943919e69f9e598eb8188",
            "c02f3598b61e46a9ba9215ee43af4f7c",
            "54515267b7eb44ccb04ba838706c4f77",
            "de8bf5ceae2349d8ba5263ca80a2533f",
            "338c302691234fac95d79e41d8ae2490",
            "129dc3b3494a4e77abb128b1e97ce435",
            "1387a556b38a40c08f16b3a9b447f83c",
            "b6bf82601343426ba511f89e6f477f1e",
            "678c69b04d4148f68f031ec27abafe17",
            "9efb5c161f0649e18a7dcfdcd284bf23",
            "badf451195f4470ea081d61e2e0e58a3",
            "5d739fe160064ba9b52885164e860955",
            "35710a9ba1e4436fb6fe7579b4bd389b",
            "7919dffc9c8e4256ba5257c3fa4a4640",
            "9dcde454e1c24afebca49727a9ed3f20",
            "2269b73a947b44f0a05b5d9b7b7e4658",
            "6a1a07dc673842be9023b2b07eb1a022",
            "227fcb5ac13c491c942be89bd797db08",
            "978dba0fe518456d9697c0e9c3b6fb80",
            "c52d7c3c8f96492bbe9ea80cab6f85c5",
            "4549c095882e477795a66d79f912f9e8",
            "fa3daa4e1314443289baabf57af8181f",
            "5c124003f65e4c9781e14fff9ee041bc",
            "a9381faa0e524095819bf26405cc9932",
            "48d5cc2def8240e098787d7fb17662ef",
            "2a04f1a43fb041db94fec270d0c0c9e3",
            "5cc23ef73ba640dcb6b47aee9bbbac16",
            "e623342a7bb34fef99fbea26b9881935",
            "2423bae16e9f49dbad4cefe17bce1a8a",
            "13c6eeb7937e4747a7c6f79b856b6f49",
            "6517ad3ca09443909adc9f90834e01ed",
            "727ed126ca51411c98fd64c44d7ecb3f",
            "ab4e35714c2e448cb9bf458bc53074ff",
            "eb73c5138fe449b18c82bd7b75a4f029",
            "ec4c11ff89a84e9e8e5fd81b31245a23",
            "e374281b937a4c22a1606f71e2fbcec4",
            "d2edc27e5ae543f88fb7a74f738fb561",
            "41b3f76170ab4fd3bee3ba48b4f7ed18",
            "803d9493418147b88dbd39d422425619",
            "83326199adf742d793a4a87f485e402c",
            "5abe492f391d45a5bada0a56ee3708a7",
            "20cf6ef41e3948489a0320da9dff934d",
            "0cb09cec823345f5aecad288f5b75f2e",
            "1f53635ca46e49f2a7285e3ac6ca6c05",
            "5a6e87a8a2864f99b2a33bd336d21bc3",
            "770e35d38bdf478fb7aa5f8ba650dc02",
            "279deb43f59e444b9607d874f193e2d0",
            "2687248ab4d14982b5a84aab53785e06",
            "038b13a9d016444b838a48e2f0906e56",
            "bb580a0a66254c858784a1627280b9d4",
            "64e310974be340659657183302f78eb1",
            "7cb5114e4d5b475699f23c467e3fe57a",
            "257127ddf98b41c7804e6615a90f5472",
            "26b3535257c5465488fdd509183b7bdd",
            "3d6acc25eeba4366b3aefcc2d49b66e5",
            "1611c4968d2942c78528294a255ad0d5",
            "46bb8033d8394957bf499f4f80d2a4b9",
            "20a8c5b52b4240e997c904b9702e485d",
            "4ce8c9abc8574b1c842f3767e04c143b",
            "f104e8eb65c34eb694182ca79f0da87d",
            "51046898f85a438c9f2042a8ace1fe2c",
            "63e10f785ac54cc69ae3a5a889cb582a",
            "b45b20c0a5d14d75b6e8dc57732ac402",
            "efeb4ddd5f6e4816903df77c52306db4",
            "27a1627413f4408698f1190e54a2a0ff",
            "7f88eaaa0a0b4be6a44dfb913be79fdd",
            "5da24d8452654b879a2bce09192ec617",
            "0df10cf65bda430aaf3211c7df6d55ca",
            "22c22704c451428eacb8f873802872c6",
            "aa2530e04ec74660991637880c098da2",
            "c2764560caad4a829a7bb8dd9e249389",
            "15a336d226784f31bd0f32d09943cf63",
            "da54fbbbcd8e4c6f82eb43bff233c294",
            "99428099e69443a8859b6ccee6a9202b",
            "b779a5a472384f92a497d8856ec414fd",
            "ba494fbc5b424b41b025c0fd5e3aa1df",
            "bd77b6809e6d4749a190951999e07dfb",
            "5c97256543dd44448077be720f9803af",
            "b29335bab4564accb373562d2805e847",
            "dccd58441aa544a88cbc6138ac6c0c67",
            "5241ca27efcd4ab78ff2e69c12163353",
            "81363090e81246a89d6ce7b75441ab43",
            "5f3c5981578d43608b67fa1e17e55f73",
            "dfe7c227548d44e68365fdf0621aef4f",
            "3ae60b89726f47f9814d96c4f4430f37",
            "10f2163ca7274d1b8292cf0b7fd68686",
            "2edb3a970fc54e8bb803d97fcff371da",
            "268998b7d73849aaac50a3cc7f4b38cd",
            "93d814162c194821ba1bef878f4c49f6",
            "080ec25313174e388256473bbf8eb48a",
            "28da5d6cc7584a18b08d6d3e27eaefc0",
            "bd61a5a5f6f44b54a7bb6fd666e1274f",
            "30705848be5f48258d17236e3069d5a6",
            "4797720f4f214dceaff1a4b29cb2ac99",
            "a1a9bdbe2aca4ff18641015a6e35b287",
            "3f186ef3662c447ea149aa453564d798",
            "159a489d3a6148329d7a553c83c91988",
            "a0a1a986ff2d4ae795fff6cc4fe4bf1b",
            "f22c64ad13f244f38796cfa07c2a5e82",
            "c6d6b597e155478984e00e5de95587b9",
            "ae7d9a1f1c8b4aa6adf03e4049777cff",
            "50ef9d5d0fd74ad79570db9d795aceb8",
            "90514889327e4c26bd565749e4b33d5f",
            "1dc072859d7c4efcb5ed5be578bf1a2f",
            "90b5e74d9f5d4a9a8aee7865476dfe95",
            "d007235517be4e8aa0476279565e61e5",
            "c201f658a89c42ebb54d04f93545d592",
            "44793b103a7e43ada1b8022bcd766817",
            "cc775cb1db6448699244f21b2dadf117",
            "84d3f362c42947bb88140e0eeec11402",
            "3de01b5934c44a1fb3c6167e3f917109",
            "7d4d6f873f374b72ac6ddcff3ddea9da",
            "6a15fa60f1ac4fc5a57bbdd770002c6e",
            "42ca812fe0a44da3a449906ac0e7c072",
            "ae4e4341d61b40c199c34842dc6c6bd9",
            "d5a85782e4184037905652917ecd54c0",
            "24632321ab9d42f89b41c4d00531ef74",
            "8736b04ed0394346acb8366f4f56cba6",
            "9439be481c404651a9699d47f750d532",
            "b90dec2ea34a406c980196e843beea59",
            "7cd1714f987f48d1b050f040c074ffbc",
            "0d9b75d61ed74cef89eed988bcb784eb",
            "e4eb72887f734de7bc14347c34e6c413",
            "86a646819e184f3ca21cc3e6a2b1d3ab",
            "20d44019632045079d8d003e70c6be96",
            "a7746a3a5f2543ea971f3963307eabd1",
            "8d7edc3fbfdd4bc783e4e240cbaea85e",
            "2006a5a8de1e49ad87cc6c4fc7faf8f8",
            "a68f5803fb2b4f358d6ee73bcda8ee0f",
            "9becec72b1854defb623eecf8f920852",
            "723313216a194cad8e757b9dfdbf666e",
            "517297a8eae24b2ebb8886d10c726d60",
            "25c1469be5ac4a6f8c90d7528bca2588",
            "48080f1541024306a6876138fa984655",
            "36c283dc581a473abe8d5423f467bbb8",
            "4bccec6889404805aaf98b7e72b48cc9",
            "601e231d5a64497e9db099fd361df828",
            "7e4eee820d65492188ecc446b06557a9",
            "3a38feaaff9d4d1d9120e58ec97a7536",
            "cce68808a9fc4981bf5298b21b1345d9",
            "6bd58d01ef964f12b6597dbdb8942084",
            "8e481bc1c6204f0caedf96533890fe59",
            "ea9c2e57ad864476b505c0bb4bca1d8b",
            "a987b7efe7874774ba94dc5f2dafae10",
            "4052738b2c914f27b7f76c95098dbd23",
            "c08292c4f2ab403f8ce722638be7a2da",
            "c2db204aa3ee471bbaa41c7aa7434e3b",
            "83ab6fda2b394e8cbdf73a1789e4663d",
            "b294fb2b051040c3bcf30c5e81bf6800",
            "c8942ef125da49ac94e3f4f19ec7708f",
            "378eb0214f9b4628a5e636c3e8782735",
            "39d002ed7d3d4358b4f9c0e6f1d0a6cc",
            "a6c1b21013504f4f9fa39be5ee6431b4",
            "224c5fdd57fa448b91be094f2cb541f3",
            "8a95aebfec2044e091d644b7b6bf4859",
            "ccdf10d3f61944c99d28a80bd51e27c0",
            "694f215b54e34248a51446e235b3d7b9",
            "044284bdad5e4475bfa51a57034bb36f",
            "629829ed42b94d9192d433c12607c37c",
            "0cf752c3f04442d6b01eec88a60a4975",
            "d5a84407c0cd411287e1eaab89ec3b5b",
            "0f4f36594440498aa499ff5026737355",
            "5a7615ea344f433aac76aabf640f767c",
            "341dcc43f21f4af0a847a478afccba82",
            "9854115b55fb48cfa08f5cefc43f9d07",
            "127a134f19be44f483e55611c3dd8095",
            "37601ef6ba584fff9841abd95d2f000b",
            "de9a364c5c31494eb5dc16f4b7a8a7c2",
            "ceb22b40ef76430abd84fc901b4b2d7f",
            "851e5796aee54706acaed64718fb4b28",
            "7b32b1523cae4c2db0a1e2572647f11e",
            "268649ac720c44818f08541a616608d9",
            "4469da60ac4347e98f13e1cb62923805",
            "d70b8849690e4c959ede1077e520aa5b",
            "10c90e7d0a83445ea07eab9bd43dab66",
            "9c8479aac0b7496f836e94551cf86c76",
            "a5ee4bf2765e43829643d5877b3a71db",
            "b6bf40992f3a45fb9d9a81eee66aec88",
            "f6992b6370274c08bafa59898055cf2d",
            "ad38a041c20c4040a96b402c1a7c2515",
            "e4d86bde04d74dbeb705243fac47a9f7",
            "027700e2f8a541eebf2486ccf8e7c619",
            "d10ed743a47a4c8d88eee78b14b9ee9c",
            "ea7481022acc4be6a7a22ef037645542",
            "e67daa1adfe049f690f0a92bae45769a",
            "066564e62d0b44aab3e0a42fb7ac5157",
            "0191cb128a184932b1753a1ad61dac65",
            "fcf52bba19534a36995a6a596d84d5b6",
            "bc476e73b1a4422ba53970dddf62142c",
            "bd2fd6210c1441e1b22e513e00a5f5c0",
            "1ee6be708b1441c890a57dc9bb697862",
            "2c6b5687438346fc9a66b5f35f5a1e39",
            "ff5bda60adb94cd8878b31c56122adab",
            "2ccf05adae8f44bfb9762260a639d995",
            "b3c1804feca04edd8e747d1b843cca29",
            "9777ee576a764f5eaf248896dcdbb69f",
            "52d3306225c24abdb5e7336687259d51",
            "ccfdd7c441574429bdda69227ba5f459",
            "df5a88794684444c89dfffacd584c129",
            "80af418fecea47749309ddb70128965b",
            "5fbd8c1649094d088b8614ddd9af95c4",
            "20b23b55a00b47279354fbefc27943ad",
            "f78a4ed958254bd795bf7f24be3ae450",
            "4a55c4681f6b44e5bb7823ee86071b33",
            "ae34d88eaa6f48869a5c230a791046e7",
            "99fb04206ece4cd78b46ccbafb25fe8b",
            "fb61e72020e14cada95407e4a75d87a9",
            "ac59f9ea834c400ea85045dae2441244",
            "1c36c321684742178d56bd0b49a8f0b4",
            "d2b6ad784d144fada746c809c6d93cb6",
            "156f8becbc8e4b069cccecca50786341",
            "5f9d5f708e0145f3a509af5ac9c5ad9e",
            "a36385a2ce9b44f086cdf7ec15d7e0c1",
            "1d017e64eea543fa9482995dd6592a7a",
            "dc6ca75faa174deead159c18e0d4c3b0",
            "c1c031a1d4a4450db2074c934e9048d7",
            "73082e83e0c64bd5b85240c818f2968c",
            "49f186a2dac94e55bdf78d5cc42d19d2",
            "6c7cd7d352cf43478e2fa46ecfb0d559",
            "8c160375d8ed4a3b85afef9ff3797fcb",
            "25bf7133a455409fb379d6c7b1648b6f",
            "90c0c9a585d8482ebe8b37b11f782816",
            "f4e1b77e4b2a448f9ef7d2955f948003",
            "c2e0bc47a85544a98326112d964ba231",
            "f9f55d8655d1477ca256b374d12a47b2",
            "f412d7a9142c47d5b6fa96c049dcda55",
            "b51f9f8f789c4b60a9911d938df8da99",
            "c4473149f38e4389b4400a8b3148c8f3",
            "04ccf614aa8d418f95257285400ab253",
            "e0834b9bbef04fbc9ef5b81e0c62710d",
            "020b158394a44bab96a30e989965e112",
            "2f56c16e1d694543a4d93487e53eef2e",
            "c9349864f8c3463abf9f1be725752bee",
            "2460a29617b1425da4da216032d29166",
            "a8abb802491c4940b3e6232f38fff531",
            "cf7589cf2a85434ba2729a89c2518725",
            "e1cb3791a78c49d9a6f6c23fd65e1962",
            "2c4154a955e543efb46f21f4c20f2644",
            "8842d70fc8454ad781e4a386eba9bcaa",
            "a78c8332c1dd4bfc87cd4e6ae4377732",
            "274bf06efb7b49b2900f6ae5478afd2c",
            "eaf0e4e6064b4a43b86ca25e7f2d8942",
            "f9394994270b4759a4837757e84d099c",
            "32f72d09e2a4400b969cc526bb5dfb82",
            "33175557a80e41dc895a9f5de90897b2",
            "12714b341bfe48618793eac51b710f28",
            "0dd16404a8394ca0be0724b8a8e6a863",
            "b176e8e13e614088b9277a5988e5e4eb",
            "05941958ad11474f911bb38f46e78c54",
            "aa64dccc78ff4b51b5ac90e11fd76580",
            "173cbd71f9694e58965629f22ebbb0a2",
            "6b7e208eb6a14a528df4165265bba94d",
            "c4c17243fd584a468b93fff4d186eed0",
            "554e1facc0794408ad42d5bb5f3d6a26",
            "329cabab19124c5e8f381fa2d30e20c4",
            "8d50417bcb4747b7a1ca760b46ef6e0f",
            "3a01e3aadd6547d786db2fdef61e440e",
            "115eda7db9c64c4f98a0da5ee717bf34",
            "b65c6d233023487d9f342a606d5b92f5",
            "01b4af76dfff48d4ad0ba05a363fdb25",
            "a31a51668f8c46f7b7e4c6df82343a9b",
            "dc050e952d534f4781bd78a97eafd39d",
            "efaf3d9739f240a69dab811500c1f5a3",
            "4e9aac58bdcf45278dfc1bea1f85a0fe",
            "9a4f413ebaeb458d95fb42984e0d6928",
            "86708c30e48e421daae781ee8db5d7b2",
            "b5d37fdf2326449fa5adf6473ce236ce",
            "3e027f3c37624c19a5ef2c5c1a28d32f",
            "8cf4420231d646ddbbbe60f14fcd26c2",
            "3ab812cde73e4e7998602cfde1b467e4",
            "a4c25c202b814d75bcf003ac6dc678d7",
            "b897ef7552de429cb13245fc4397f5d5",
            "edcd03a8927d463abc2ec30419f89063",
            "69a0b525a31d40f1bec3aea1c0cb6c5a",
            "63e4f77e956348cda23e769edd891b79",
            "b6a294187e354dbcb1e12b29c9c3c991",
            "d04b0f7b920f446cb9f7ca045588e817",
            "eceb0b46a5d44a86afa87183d37db269",
            "b35d4383096c41f8ae471490b1757158",
            "8216132d7934497db6ea12bc519dd073",
            "ee06bed503cb47d8a8f561f3e302af8c",
            "abf7c68a42314805911d873e55907394",
            "2c874ff62496468980e78eccda4edb1f",
            "dd18402fcd4e4be78b9316863e128ecc",
            "ef92d37da69e46a4842b46b2c15e5215",
            "8d915af99c4a466cb9d1f6746c7861bb",
            "af7102f7afca4817a285d80e6e753384",
            "b6967dd939a74ff1835045869168afe2",
            "9d0f65f8e3ec4ed18df24d71fe4dd482",
            "a1a8ce215953433496daaede15cf7821",
            "9863a356453f47969151ca29abed94dd",
            "53f924ab680d4caaa1ceb1595ba59348",
            "18cfd6901c2c4c5e9fc31633a4e83259",
            "b48bf1b271694a23a3611b7393be6dab",
            "8dba09fa174147938f81f06ea64122f0",
            "2575b4867e054462b2a95cadcd87ca28",
            "4f01c85245064f7db5e6d2bc9566ad53",
            "86db67f0be5a454796cb4bb649f38413",
            "6d4e22c5d2de4b8b8553cccc81b3834b",
            "189e71e4b89e4e81a02f2c447fc86051",
            "edbb7b66d3034179af4c0b671314f2b1",
            "f0db1626831e488794ca9f9e5094c248",
            "8e34e6f102294a4097b8e6d5feb4aa6c",
            "d1c3f589e16a4410984c5bfe7deb975c",
            "a099b0106ea14c91a2ebf48ada4a76f3",
            "129f4cd874664d6fa37523ea5e101f2c",
            "220061af385042119fd5dbd1ef40fb72",
            "2a33ca2537fd4bf3971794f8d217ed1e",
            "b89528c837a44806aca05650777dce13",
            "30191474660a472d862a06e2882176d3",
            "f758a5e384a7435aa3fa48df68db2372",
            "a5b3148d48124d1491e03a261b66498a",
            "ef4d088a9901449c9a78584e568fc69b",
            "996b6051fbcb4362bb58be9781fcc04f",
            "bc1454ccacce453995a0ffafb54943b2",
            "98597b92f6ad494198e662f00fd3439b",
            "16743424bdbd486ba95f2de469b1b1de",
            "4b11b9552e70458182a8e3e7409813dd",
            "a7cfa1172e70495290f7a5e7c510f63a",
            "8e370fe88be746cb8ce91762c906c3c7",
            "f0777e87292740e382019cc286a6801c",
            "e2b04adfdae54df99b2d93ef7497b0fa",
            "36b7d2231f2c4f2eb8408b0cd7960feb",
            "5871f43c2ff2442287d91b608571a1d2",
            "0508eff5fa3c46a4a69049d8877b854b",
            "79878308587441c5819096507457ddf0",
            "d692df77f0c34610b1229039a4d49532",
            "c90051edcafa4803b47a938ed1b9c249",
            "6037f61e862a4cdca8646e4d74fa99dd",
            "c3925af9467f4158879d3f8f2c3d289f",
            "05121e4659404381bd35cb0274934973",
            "8ae6b3645ea1437d894ec2bfdb35f852",
            "29f38223c4a14e849d2c74d5005504c6",
            "4fc984143ec64e03a291c0c6a77548b8",
            "303782b4e1ce448297bd54b39a6f525d",
            "62625775b5f44015bb18679215a7f8f7",
            "c8a4fe22d2094b0797b9a12dfe6f94f4",
            "29fee250b196440ebaf52cc65cd66ed4",
            "a062c8a6946a422db85c8c6c9ce9fa2f",
            "e481181ecd134b439dc62040c7515dd8",
            "27709ca980034e4f8d01fa7e745a5e65",
            "b7004b563a0644938562e318a2db6859",
            "de2c2c3fe3854f7f9b61679bed150219",
            "4dc26e71b0fb4b4aadac7adc66553ff7",
            "b0f567de92ac4952a880dba0ce2c9a08",
            "26f9e7e7ab91441eab7c3c25ce71c187",
            "8c001e7704644d7e96f62ddf4cffd05c",
            "2b9532b606e7452e8f17499c40f4cd0c",
            "071db921e0064796ba7f11755bea8813",
            "5497bec0adb1479588c59e6a1cdaa985",
            "acb899c94da24540ae827698ac5a47d3",
            "75dea9c8f230440e8a56984fe158c92e",
            "5cedc9082a284fc0bf15d0e9617d0d85",
            "fd5c1d5bf86249a09aea612c5d0fd67c",
            "6fcc496c41bf4de7a3a955f022ca0481",
            "ccc1b5a8a3e84a9d9d141dfa81ed7ec8",
            "c44fd27339a947ec98e8213a28f2c5ab",
            "daf948a7d4ca45b380e8a85259ffd627"
          ]
        },
        "id": "ag1wimnuGOrs",
        "outputId": "95289d8e-43b3-495a-d1b7-f64924d405b0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "484f8d4e44d24bf1b08b6285a3a1f885",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c53a47f9e3b44e96ac79771602379969",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing model.layers blocks : 100%|██████████|32/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1387a556b38a40c08f16b3a9b447f83c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "227fcb5ac13c491c942be89bd797db08",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2423bae16e9f49dbad4cefe17bce1a8a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "83326199adf742d793a4a87f485e402c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "64e310974be340659657183302f78eb1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63e10f785ac54cc69ae3a5a889cb582a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da54fbbbcd8e4c6f82eb43bff233c294",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dfe7c227548d44e68365fdf0621aef4f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a1a9bdbe2aca4ff18641015a6e35b287",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d007235517be4e8aa0476279565e61e5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "24632321ab9d42f89b41c4d00531ef74",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2006a5a8de1e49ad87cc6c4fc7faf8f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a38feaaff9d4d1d9120e58ec97a7536",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8942ef125da49ac94e3f4f19ec7708f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d5a84407c0cd411287e1eaab89ec3b5b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "268649ac720c44818f08541a616608d9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d10ed743a47a4c8d88eee78b14b9ee9c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ccf05adae8f44bfb9762260a639d995",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae34d88eaa6f48869a5c230a791046e7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c1c031a1d4a4450db2074c934e9048d7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b51f9f8f789c4b60a9911d938df8da99",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c4154a955e543efb46f21f4c20f2644",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05941958ad11474f911bb38f46e78c54",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "01b4af76dfff48d4ad0ba05a363fdb25",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4c25c202b814d75bcf003ac6dc678d7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "abf7c68a42314805911d873e55907394",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18cfd6901c2c4c5e9fc31633a4e83259",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1c3f589e16a4410984c5bfe7deb975c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bc1454ccacce453995a0ffafb54943b2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "79878308587441c5819096507457ddf0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8a4fe22d2094b0797b9a12dfe6f94f4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b9532b606e7452e8f17499c40f4cd0c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:4565: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quantization time: 1912.69 s = 31.88 min\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "import time\n",
        "\n",
        "t0 = time.time()\n",
        "model_3bits = AutoModelForCausalLM.from_pretrained(checkpoint, device_map=\"auto\", quantization_config=quantization_config)\n",
        "t_quantization = time.time() - t0\n",
        "print(f\"Quantization time: {t_quantization:.2f} s = {t_quantization/60:.2f} min\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Al igual que antes, ha tardado una media hora"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos a ver la memoria que ocupa ahora"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlbgCinRGOrt",
        "outputId": "1cf43f09-6362-49b0-8b96-d7d378918534"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model memory: 4.52 GB\n"
          ]
        }
      ],
      "source": [
        "model_3bits_memory = model_3bits.get_memory_footprint()/(1024**3)\n",
        "print(f\"Model memory: {model_3bits_memory:.2f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La memoria que ocupa el modelo en 3 bits es también casi unos 5 GB. El modelo en 4 bits ocupaba 5.34 GB, mientras que ahora en 3 bits ocupa 4.52 GB, por lo que hemos conseguido reducir un poco más el tamaño del modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hacemos la inferencia y vemos el tiempo que tarda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cW_uLdu6GOrt",
        "outputId": "2a2c7039-8d59-44d3-f493-6db74e604cc6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello my name is Maximo and I am a Machine Learning Engineer at Google. I am excited to be here today to talk about my work in the field of Machine Learning and to share some of the insights I have gained through my experiences.\n",
            "I am a Machine Learning Engineer at Google, and I am excited to be\n",
            "Inference time: 2.89 s\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "input_tokens = tokenizer(\"Hello my name is Maximo and I am a Machine Learning Engineer\", return_tensors=\"pt\").to(model_3bits.device)\n",
        "\n",
        "t0 = time.time()\n",
        "max_new_tokens = 50\n",
        "outputs = model_3bits.generate(\n",
        "    input_ids=input_tokens.input_ids,\n",
        "    attention_mask=input_tokens.attention_mask,\n",
        "    max_length=input_tokens.input_ids.shape[1] + max_new_tokens,\n",
        ")\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
        "print(f\"Inference time: {time.time() - t0:.2f} s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Aunque la salida en 3 bits es buena, ahora el tiempo de inferencia ha sido de 2.89 segundos, mientras que en 4 bits fue de 2.34 segundos. Habría que hacer más pruebas a ver si siempre tarda menos en 4 bits, o puede que la diferencia sea tan pequeña que a veces sea más rápido la inferencia en 3 bits y otras veces la inferencia en 4 bits.\n",
        "\n",
        "Además, aunque la salida tiene sentido, empieza a ser repetitiva"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Guardamos el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qIuk-daGOru",
        "outputId": "c06450a8-95b1-458e-e2e5-d7879e7cf902"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('./model_3bits/tokenizer_config.json',\n",
              " './model_3bits/special_tokens_map.json',\n",
              " './model_3bits/tokenizer.json')"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "save_folder = \"./model_3bits/\"\n",
        "model_3bits.save_pretrained(save_folder)\n",
        "tokenizer.save_pretrained(save_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Y lo subimos al Hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "23695c72923a4a54b2b25cd40d59da35",
            "d37dfe28b71f4d5c8e082f3c3c693755",
            "cfa6e6cdf8ba4b17b514a554e6b32407",
            "5497ee9503074310a3980649db85ea30",
            "5949a7ac8b3e4922a52e73e71f0b9438",
            "21b332370f6b4447946f8440e46355e1",
            "50be69913b8c4503bc358222de624121",
            "d1ff749e4be748b28e1ed20bac9e01a5",
            "5213a50906234628b8a52f7c9d4eff7f",
            "220441ef98b94d02aaab3bb3275a85b6",
            "b6482767dacd4c7ca95f6cbfea915e67"
          ]
        },
        "id": "HBqgQH7WGOru",
        "outputId": "6180e862-f4a2-4615-f4c9-a8b62d1e05ee"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "23695c72923a4a54b2b25cd40d59da35",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors: 100%|██████████| 4.85/4.85G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/Maximofn/Llama-3-8B-Instruct-GPTQ-3bits/commit/422fd94a031234c10224ddbe09c0e029a5e9c01f', commit_message='AutoGPTQ model for meta-llama/Meta-Llama-3-8B-Instruct: 3bits, gr128, desc_act=False', commit_description='', oid='422fd94a031234c10224ddbe09c0e029a5e9c01f', pr_url=None, pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "repo_id = \"Llama-3-8B-Instruct-GPTQ-3bits\"\n",
        "commit_message = f\"AutoGPTQ model for {checkpoint}: {quantization_config.bits}bits, gr{quantization_config.group_size}, desc_act={quantization_config.desc_act}\"\n",
        "model_3bits.push_to_hub(repo_id, commit_message=commit_message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Subimos también el tokenizador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bddd266d2955402e8480511b165a58be",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 100%|██████████| 0.00/5.17k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/Maximofn/Llama-3-8B-Instruct-GPTQ-4bits/commit/75600041ca6e38b5f1fb912ad1803b66656faae4', commit_message='Tokenizers for meta-llama/Meta-Llama-3-8B-Instruct: 4bits, gr128, desc_act=False', commit_description='', oid='75600041ca6e38b5f1fb912ad1803b66656faae4', pr_url=None, pr_revision=None, pr_num=None)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "repo_id = \"Llama-3-8B-Instruct-GPTQ-3bits\"\n",
        "commit_message = f\"Tokenizers for {checkpoint}: {quantization_config.bits}bits, gr{quantization_config.group_size}, desc_act={quantization_config.desc_act}\"\n",
        "tokenizer.push_to_hub(repo_id, commit_message=commit_message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cuantización del modelo a 2 bits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos a cuantizarlo a 2 bits. Reinico el notebook para no tener problemas de memoria y me vuelvo a loguear en Hugging Face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Primero creo el tokenizador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OB_8mAOcGOrp",
        "outputId": "07b37ab2-5ac0-4833-ec27-0f8075935d49"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creamos la configuración de cuantización. Ahora le decimos que cuanticemos a 2 bits. Además hay que indicarle cuántos vectores de la matriz de pesos cuantiza a la vez mediante el parámetro `group_size`, antes por defecto tenía el valor 128 y no lo tocamos, pero ahora al cuantizar a 2 bits, para tener menos error le ponemos un valor más pequeño. Si lo dejamos a 128, el modelo cuantizado funcionaría muy mal, en este caso le voy a poner un valor de 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import GPTQConfig\n",
        "\n",
        "quantization_config = GPTQConfig(bits=2, dataset = \"c4\", tokenizer=tokenizer, group_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "8e2a81da74d34ee3913ebf8d784db02f",
            "c24d8ffa95e54cacb3aea61453e9ecf0",
            "39b53e2f49de476b8e11e5c617be76c5",
            "9d666281296142f888727bc1b8db1990",
            "d98ddee92e2d4e55b67cec499e1318f2",
            "d92fc49013e04294945159d440f4cdcd",
            "adb356f5453f47b8a32975524c0d1825",
            "74c108a6f6db49ffa0d0a6048f47ad2a",
            "bb27784e47fa4010914a6e7695a0681c",
            "95409d626b4c4c8db8da26e62fa88bee",
            "e3f78e65d7ff4ad6a1c29b0e1dae65d9",
            "2cb2d1894e51436f97890f38af8dbb98",
            "f7d38301128c4d00a88132b5451265a2",
            "2bacbce140e74bcf8d9e29756bed7ff8",
            "8bd194f61daa47f7b38746419e3fe589",
            "a95b18dbef2547a3943335ef10a1bf6a",
            "1d8e916be38542a1aebe3d2b5b8a745d",
            "49fa9af79b984e1bb75c13bdd37af5a7",
            "2c6e293580c04b24b24a0fe37ab03a44",
            "30dda36c092a4e73b084f396cbfb5aaa",
            "621ca33bc0f44334ae41ec4845db4ee1",
            "d2f8cfcbba204f288ccd4121396da642",
            "66aea308e2784b42a857c3528a35bef3",
            "b48fa161c6de4b868a94bf3b0ff8fa04",
            "9e7bca7c7f1048a481dcd81aebf15165",
            "939ac284026f423fa72ce4eec4d74cca",
            "3699de3d3b4e418fa6fe7e2c0512a98c",
            "be41ba4cb8ea451286ebb4375c7ab515",
            "283f4324ae7947d7aea43b9c4160ef8e",
            "08cac418eba744cc8de62345dc79db86",
            "04da8fc2ab854b0f90b965fcc43f5313",
            "c57dfacce6044da688a3ae91cd3b4b68",
            "eb7ba48a0b5d4ad59481227fce25a820",
            "a79397924062416580f0b87ebe55fe50",
            "2e291d70da1043019d4d762ec5ffc8e3",
            "86a3dd078f8849ec80713c8f4cbaeadb",
            "fa017cc369ff4deab641576769f34e78",
            "aa944658d5ef4dc8a89af93058df4344",
            "03223bbf03c6465e9dc29c77e2239f24",
            "a7011674c4df424c8f4335248df8d85d",
            "f3f5a2dd46504289ae793a2f6522844e",
            "67fb588937cd4a18b4c2802f819fc6a7",
            "366740ca0b9f442dab2639c04c77ec2d",
            "56255823589643839dccfcf8d1f36d97",
            "0f38919d5e23419590ffa72fcfaf8e89",
            "b76bf7053d0d404492f6d4ce8676353b",
            "35936aae4f374a4f94d428a698b54a13",
            "2270dee7a439456fbd50ce6fbd5fdca5",
            "3dedf7356fe24d16a2840c09dc93430d",
            "8dfab18ce51249a0945c3193d572b6ad",
            "283a45a761a44767a8c84e994d0ae380",
            "97af0e6bd379471b88543bdd0be6676e",
            "9e7d4e96c9e8480083e3c36ce5513979",
            "d7c71268f195444cbde45c6f6c9d56ca",
            "0aa85b0b0da846f7b33e649791cff43b",
            "84325d86934943a5af050a9301f2ffb4",
            "530724b654e548c7bfa54ddb0af4de1a",
            "bbe2d0b82cbb4defb1883ec6aee63c3b",
            "a0e2b00d1d974b388facbd76ebf55082",
            "b298ea36c35b45d6a8d6af1882a9c97b",
            "c3217fc430614c0d96a7234aa95a0574",
            "6a3d379fbe474bcd992bb38293bad978",
            "9b5553ff12934322a5ad71e0de14e832",
            "e5e58393738848bf95167449d09cf855",
            "f24f589b110e47adbb83721e914eb9e4",
            "70665e4cb314481b87d00d562ffe2334",
            "342ff869127d4f83962c68d307e0981e",
            "9ba94e403db5416c97969981fa637641",
            "dfb26a21ae814bfba4a979f895821cfd",
            "7f6789814cd04c168485f1acb89317d5",
            "ff277f86754649c5ad9e162b0e89306d",
            "82497a59bfb04548b462076ccc169e05",
            "727469fd76e74a7ca178fceb5bb236e1",
            "5b1bdee3e06e48e98fb7faabff5c11f7",
            "25719710294b48b8bc73cfe8e2bd3164",
            "ca71965908c1462d99a0813e8dfab01f",
            "89db6bd2186a472187bd0a25f3e0610e",
            "49c451507c5147bbb576d405b9364bc0",
            "38f2eba540414ecc8b8d563760c251ce",
            "4870d2473aa049a3b2296d0284428371",
            "bad0f3ad51954c92ad1548da6e02c871",
            "eb4482235eb3484eb5cf19288c6d896b",
            "7698070bbb494ec1b1c404b41e54cf14",
            "4dfd3a6c53c147f0b38706e48fe21764",
            "f8fec0a83963430886928284dafb940d",
            "06070b49e6634475b9f59017269dbba5",
            "5c57aa9a4cbb43a194367455a9fa2ae8",
            "ec4507577bce4f6f83bfea25090d7228",
            "6a575ef40daa441ba8247e3ce37400db",
            "8f5715f215204246a6a0ff4c660714e1",
            "9f1a1eb365ff41eeb3f5b447c6e80604",
            "409b07ad60284774a5bfa5d999d0d56a",
            "0b62a2fd80f9407a8764c5218ead1f07",
            "140c841735be4377a19655f36b190ee7",
            "e7f568999c134104b02b2dc75d248f0b",
            "6617b97cbbf4475faf8d323f44601bbd",
            "8c58c79f94654d7ead5812df35b65265",
            "cbbee974a1274004a078aa53fd33563d",
            "7080636fef3e4a45a14a5d30228c941b",
            "6875053b7a5f4c5bac56935aeed54e31",
            "03eaf10eb1384406bbb0864451064a08",
            "dc8d12d3541b421ca5907179644b1364",
            "fe132759750a4a4a808ee4c45a01131a",
            "91bd82c40ca24c5f9edcef4d9daca9de",
            "ad1e635c1b8b4b148111eb5f41d354ed",
            "5052b020f7804af7a20a39a57b3e546b",
            "b7421398e51d4526a61efdca9fb39960",
            "1b09ae8f49cd40a29f9572b44d4e4569",
            "ac1ddb29806843ea88a07a733004f8ac",
            "a71c2bf8947f44078b8249db03fdf1e4",
            "6203846d67a446aeb03d72b711c12f29",
            "11191596984c4af49a100cf1179e6e9d",
            "b55658b3b97e4f6ba9fcc586753bc9fc",
            "f453c0e8089543dca9b7e37ef12af0e7",
            "1c440c606a5d4992807f045a29be0754",
            "af56bf23c1414c7a89e787a9d3edad65",
            "b75aa71b6a0c469aacd744bb4c0ee097",
            "72d1eb04b92240cc9d8b83b1ee0b3410",
            "3144bace811544dda2262473cda1540e",
            "d598fb46f1c44920b755a9bb07432792",
            "4a48385dd49a4847aee6645209d87b7c",
            "c2b9afeb018d4f9b90eee0964a659c25",
            "f07ba7dad26b4f02bc59fe7566b0ec3a",
            "9fd43f6a08ab45cf9a0828e1b9c10a86",
            "66f68db1faca4a639d2fd06b0bbe8d4e",
            "311a784d2ffa468789d4633b1c47c62c",
            "d8f532fac1834b14b26c56260de9e76f",
            "9bc0ae49f4794816b8f05a6d9f51c91f",
            "271700bb9f2d4aac9bf6d3744e146ebb",
            "309dac7b68f441268d8cadd4c7f94873",
            "9a1bfa4d4b0e432fa2994607ba70694c",
            "343f1f0c61e34aa682664f8a341b7e73",
            "cd0aeefa14c944ddbf2e33397e8105d7",
            "2ffeb2c1342f4f74be7485579ff3a935",
            "2253a4e2b5b14e4fb33c88d34e0c5ed4",
            "0ab1d3f8a984484c9b171f289e6a73c4",
            "20f62bdd666e448098174f9673ce2c0a",
            "cf3215e96cf0444aa980968bb120b28f",
            "f57a83dd95fe43e594d8d7f3b293bba1",
            "fa0ed29572014a0fa8b9e6f37bba392c",
            "f989bd2459604af18c03b2d1aeb39bb2",
            "963f4e9445e3474781aebdb739df3b21",
            "e8a36f70f6a0429daa5af1d4086f046f",
            "b4eb4efc103c4a9da050c56a803b1f39",
            "b2ba81dd999142409d546cf47b52877c",
            "d44026c2df44400191742ae6f9a75ada",
            "4f315a008adc4c85a20f2739cf8af14f",
            "0bd416c618694a75af3f47c00a1c7af1",
            "2c6d859f879a44d989f69fa90c554cae",
            "718844d35b9b41d69cdf9f56da8a45b9",
            "2325a4076ef44aabb630697330b97313",
            "0b1a86e4b1154972b49dcbff30c377a0",
            "72718429615642d0afbf17e0ad8b1f59",
            "334dad27b3264c6fb10216a37a13873f",
            "be30cd1d903d4f80b448d81a84bbe763",
            "0f8b0df917044d5ca82debcbbbc13216",
            "13351792e13a4ccea96af3ab78cde0b2",
            "25be7160812e43bab392965de2c6b8f5",
            "8fb02b8ef85a4df4b44807cf3ee25db9",
            "4b30fc687ce844a2942e522a2d3fbe20",
            "ecc6345f65a34d99ab6f041f75faa12d",
            "470d2cd906ec4fbdadf5fb75f1c963fa",
            "34cb57ff12a14c359741639aefa42230",
            "b6c0528f58d342639dec82aa2ae1145d",
            "460cfb3b718243d7a05648bdfaa3df54",
            "2e371c6cfce94baa80b5aefdc71edfa5",
            "d95dab1a30b94d14825b61ed10be7002",
            "f64c70c0b68246fb90840bd16231f4e5",
            "195afeaef0f94f5995c8f685213e9159",
            "6671bddd34aa418c93915a73ec8eac8c",
            "8a5f629a86a845378e7010b5198410a3",
            "7422c3bd2b724f008cd3584b1cfc4382",
            "9265703693994561a2cd845994ffba3b",
            "cd3bdae1d1514755897a66a470101049",
            "120c1e3beba54483835f10b5751ebb4d",
            "e6c146db50fd4c519a0fd0afd52b2f7d",
            "dd907dc7e15a46c9873cd63e4dec1669",
            "85cafcb68e0149479be8dac60c827794",
            "3be4c5e44bd54bf98bfe254dcdfec512",
            "37e0d4f2d95347d7b13b78e9d5cec65e",
            "7d5b7c30c73b44aba1767e5016219ff8",
            "44183f5544634a2fb5d83afc899e42b0",
            "e456fb531447422b9ae5f798ce8dac1f",
            "3ccbdfd62fbc4b26b6ec3042a3e2899e",
            "364b30e7ec6e491c8e237ef84eb09007",
            "d4d646e06da2454f84f1a2306ceaddc7",
            "6ec90d64487d41598f62cd762acb0cf9",
            "8c951329fdb74bd49bb7df103606ba91",
            "95f066896f7f44d6b2a49ea8d8f560cb",
            "1bdd76646f7d45b2a7365105fe012df5",
            "97b42409de144115b8875ce4fb977c77",
            "d1dcf6b8262349f09221cdaaebe5e7db",
            "219dbacada3d49298d8652a69fd36bde",
            "312dc8a5840e43d08c6ce4fedee72188",
            "7329279b319a4dc684e3f9f69debf01a",
            "39820cc4498f4e19953c61606b7359d9",
            "ab8a64e8ac9447ec953323c947566fd0",
            "285930569b8045c4ac6c1f1a8f4dd23e",
            "2293dd38bfd84b78af9624e7bbc9a661",
            "99c936aa6ce3451e8dda0cc095386738",
            "cb955cee3a6f431e8293dd5ccfff0fa5",
            "d6acbc96c2b94f27b0037a07f35f51f6",
            "056075d01f444252952539bfb925471a",
            "0664339f421e43a8b2073c0e2c6258e5",
            "49f01065dec147119b06899fe1905af8",
            "69ee5178e27f4c1193a198d7060e5a09",
            "234bfe0e819040dbb22c6837936e500c",
            "0c0a5d99c516471595e54dc75010488d",
            "cb34d5463fef4163a6e72cb4b083890c",
            "0f97f8fcff46443c8e0dfcf83fe81a79",
            "e2c8d95fea1e4165a1fcbd2ec82d68bb",
            "24f7f4e21c0943069fc546917ab50bb1",
            "70c72ff32798400ab1d697913307e1f9",
            "8196e89498884a68a3f6055a31ace0ed",
            "d6e9062faf424bc8992c6205249915e6",
            "f92d79c3313649f5939091d9e739e6dc",
            "e76bb211312e430ca42e7577120faec7",
            "4739e06c9a894687bbfecd3d6a72834b",
            "129098c5158742a0b715ef63dda73aae",
            "c03f6ab335c346398bfcd60489d32ec7",
            "8aaf9532107b4a3889aa9828bc360091",
            "10608a72f529464e8309445d64384ebb",
            "3a403145a02a4563a926c959db57dce2",
            "4c37a3a3f653424eb4731d531d78dd83",
            "add583ad7f0f4d8d93e2b83fb9dbe94b",
            "bd9aaa2e127b40c0b63f2d4c5c10e764",
            "d576a46702dc4baa9d5d245180a1454e",
            "5f25c7ff8ac64c1981c4547825b8aff7",
            "456ea260f43f4543a987311473c192cd",
            "5ca0c4cc3b2d48aa9503b4fdf9754d13",
            "fea52065161043d18be5c63e48870247",
            "654a3f42fe684609b6d970acbfebb2ad",
            "a93dafcc409d4d24a349afe72cc5594d",
            "eedb6428188d4892a58b2f0fdf402a8a",
            "9f050f0cbdef46da8ef68da2a3d67553",
            "4eb84e11c90048c09a618d205e77da95",
            "508f747f6bd14045be4e5841c48759e8",
            "10aec0a6d2614c8999f0aab05b25fd6f",
            "edecded86f3846aca85316f35c93632c",
            "4fd7380b7cb14d5f92e4adbee338a9a1",
            "bc01d65ac207450797c0c6b915be3fce",
            "4773c329c3de426c9474eed42c0a9770",
            "e69d485f2e6d4dd2864f4af72a29de24",
            "6a199d4a85bc44e9ab6ea54506713746",
            "3874e5d2f95344eba1d218624578dc05",
            "a6cfcade961e4d45949dbc76aafeeba4",
            "781c7568cada420f9c88f95e9185b9e9",
            "02de3bb52f2b4756a06fb194e450ca78",
            "0b2202452e964b6189a372a59c56619b",
            "115bec4e03754a669a3f03cd8de5c157",
            "382aa07a524b40caa3898640399a15de",
            "5e41e521e13a4de1a0755edf7ab49959",
            "716ceef9772a43638cca9044d2d005d4",
            "8a71912e6f254187bd921b8e7080e925",
            "a620f5c8b4b14a5dad06fc7dbadf3c30",
            "da1a8d5c4fd6443797889f964a1fb97d",
            "6e0e63d756024deda1dd76a0d5101987",
            "a93d387221a44af58fd4c0091bef22d4",
            "e092019f80734832899e7dbdb4b8362d",
            "b4ead08d09d44ee2aa068c6ac5b63986",
            "e9fc0de343544880a5bf8276b3cb6f2f",
            "66b1f11944e34254918d4eeb7edc8303",
            "334899adb3d849b6a4418f9c08782d6f",
            "ebc9971a592a415da4e8363e5213eded",
            "49c7c9ad3eb24d2e842f65b98b796ff5",
            "81481baada0847ef89007dcce2a8de31",
            "d08239f598bb4569b89b9552514b9b84",
            "8618f9160cf148a7b212bac5ef8abfaa",
            "75ae94c7dee84256bf5b56b720de2a75",
            "791d8e2adb2f460793b36f658883d6f2",
            "97af46bfd9a94f6cb0507ab832a0bb58",
            "85c04fd2f03648569027068ebd6a9da0",
            "66b6b8b285f341abbd86ba7e413918a4",
            "ae4011ebb92a433db7c2e93f4cff004d",
            "0d14fde12f3644a09e04238b4da145d7",
            "836efaff81c3489894f45d3cc49401f4",
            "ccc98e0a2a95430f88e20753de6cbcfc",
            "2d9eeaa2b8344f36b2ab5c74cbef7f8c",
            "1939f19b1113422092b9c77dc3cd8642",
            "2b2dccb361444dc68192b14a0fdd46df",
            "dabe705575874d8588a29f220b6d2047",
            "f5aaac67ab994f3bbd107e1f2c437ced",
            "376e0fd251d148259692d93fd19f51ba",
            "a5800a55d7334ef5957b2455b6317c0f",
            "cf5e050dc68540f38c0c3f43d5e1ea20",
            "d96fa8d7380b44068b078ffa449a0d19",
            "b510a20bfeb5450ca129e19659f73fe6",
            "f4850cd1e1fa4841be9221b86134b578",
            "3748e584299e4cc4a4e93bf93893ada7",
            "e803ec3738234641940f7eeed5216f01",
            "5f98a46cc0c044f8bd63c6d916a73aa1",
            "ddc708c2ef574d58b64cd2dca2e6e7bb",
            "34612179f5c643a8bd586dbe80c993f7",
            "535abb6835084729b7d835613d05b8e9",
            "46baec88945f47dba9cc5040bf9cfc5d",
            "c24b96ce054f4b8fa37c4bfe695a3490",
            "bf9388edf3c24fe58cd00914ea6e09b3",
            "1b391c4345354a1b89c91df66e0b4434",
            "9fe1e67c71f54baaa46ff5a3a7290ff2",
            "29a3283740784877953ac90871aeb110",
            "1057205119ac41c6914b8171bdc049b9",
            "fc50b06138db4e37a6297084ecacff4f",
            "beee304a90974c9295613803012ad943",
            "2768593a839243369f2d729904dad414",
            "f81e5a4c33b144f9b295a39c4ccb4ffb",
            "3f7972a5333747d0879ce929ccf35a4b",
            "28be513edf6c453e9bc9c47df18d2188",
            "2170c9df3402402da92f47910108503b",
            "7e1151ec9bbb4189956a43d4cd06eeff",
            "abc0c936680945c6beea067a1eeb3f8a",
            "9fe4b51ffc374d5585062f9184aed91b",
            "d6ae38c51e104b82bd40a7c91f6b5c05",
            "80bbd9c5394a4eed9bd97da0705d0b58",
            "a25126d042df477bb8d3de4ba2c33e25",
            "8f90ea00196941d78a1f218aef0c367d",
            "5aa3bd8fd98543a7aa4c5ae8f10065cc",
            "e2d7abcb522246d884d4a384e139582d",
            "3fb28f3d4e8449d4bfea59ebc1507a4b",
            "7c672a0c0fcb46cba1d2eb361eb05417",
            "f722a31ec1a648c998e8fec87cc23a85",
            "19868ec3136342e3840c7e672655e1ee",
            "4361957b7da547d58e4e731823470216",
            "dec8cbe7cd6941748ecf0471b610d116",
            "41140bdbeb25439c94f57e870f706474",
            "219d5b77102a428bb4fa82d2a495bfda",
            "7f9f2ed988c849b882fa0a4fae66d049",
            "90baa0dd067d4ae4ac15de015b29c7c6",
            "7a4e6df668aa485fa2954eafa14b2733",
            "a832dcb279dd47d9bcd75e0e9d9833c8",
            "0dce4d6f55d249ff98c4cedea2ff1824",
            "df20d387f0a84a448ac03a570c552443",
            "a8ca87dc2e6a4bf1a3c590db55d9b390",
            "7a170095a09e4f6e96c10a585ad97316",
            "c1294d5ae1704a5585d64dea2c17381b",
            "f2cec81b35be4c488e21396b62a94853",
            "d40a097a83814d99ba195bf746dd4892",
            "3d72536539a94ae782e2fe7c0877f371",
            "5d8f9eb33b7945f59f1f480ce45b2b0e",
            "005f08d902db46ceafd0db90355a586a",
            "6bef3b4d9cd749dcbff18479faeb4b47",
            "2924d1df95274a3a9c8d95434288ad2c",
            "b2418f32beb04d9892a2ef44a4eff93d",
            "4eb44196f200471f9d476f9de3d44053",
            "0dc6d7164ef34c58b6b9d6b97372e4ce",
            "c1d93d8d9b6c4de2b71a42b31684d62e",
            "d8822c3483ea425abd03378ed71fe9da",
            "5021105b9cb44a1eb328a7e479edb00b",
            "5a207d742c8a4aab8e4d1bec44e001c6",
            "e3df827705674709a46fe18aceba9069",
            "716c83bcb0984217a931f873d60b4efc",
            "5bbfd9517f464ebd8ec4ab0c77bc9010",
            "8ad51f8ebfc049288297609589b797cb",
            "90431f0488a647f899892e6d49abe84c",
            "2852759c54c74434861c4b8bade35b9c",
            "0722c430bccc4109821d65ed12806c8f",
            "1efd4809811f4b1c853d9550037619c2",
            "ddda2563890c467c8818cbcef05a83ea",
            "015023a97d074312890c93ec1c13c7a8",
            "ff5d158e32dd4e1eb0840e33c5d57f75",
            "cc52130e9ea347eebdd13aa558bd1e70",
            "61dcb03198934de0818ca813393ca232",
            "ec2c16e3cce5482193ad7206b290f5ae",
            "f0102130c6874f5c894731d913d2f244",
            "53a05ad483b24c06a2a80a110e0d1563",
            "bf2bff806e284d31b4d7c4cf0b66680a",
            "09f59d53a4ba425b847bab4658fd6565",
            "720e408a4df54896a93a5df2cd31c864",
            "8da9c824176f418296fb07338cca01f7",
            "d1eb89e28bf44a9da885b2df4ec8800b",
            "dd03f292ea7c41b299bbdfaede2433a5",
            "9a8725768ece4ef889aa24c385ff3640",
            "9cb4f43b34f44e1c9ce0a9fc7dc38514",
            "bd8bbbfe2027401ba4e8fc7a9a8df4d6",
            "007aeafbf1fb4d308180381a03e449ae"
          ]
        },
        "id": "XG7Hlk1BGOrw",
        "outputId": "9a8a416b-38c0-4eb4-b261-05babb39d5d3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e2a81da74d34ee3913ebf8d784db02f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2cb2d1894e51436f97890f38af8dbb98",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing model.layers blocks : 100%|██████████|32/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "66aea308e2784b42a857c3528a35bef3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a79397924062416580f0b87ebe55fe50",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f38919d5e23419590ffa72fcfaf8e89",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84325d86934943a5af050a9301f2ffb4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "342ff869127d4f83962c68d307e0981e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49c451507c5147bbb576d405b9364bc0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a575ef40daa441ba8247e3ce37400db",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6875053b7a5f4c5bac56935aeed54e31",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6203846d67a446aeb03d72b711c12f29",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c2b9afeb018d4f9b90eee0964a659c25",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd0aeefa14c944ddbf2e33397e8105d7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b4eb4efc103c4a9da050c56a803b1f39",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be30cd1d903d4f80b448d81a84bbe763",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e371c6cfce94baa80b5aefdc71edfa5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd907dc7e15a46c9873cd63e4dec1669",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c951329fdb74bd49bb7df103606ba91",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2293dd38bfd84b78af9624e7bbc9a661",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f97f8fcff46443c8e0dfcf83fe81a79",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8aaf9532107b4a3889aa9828bc360091",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "654a3f42fe684609b6d970acbfebb2ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e69d485f2e6d4dd2864f4af72a29de24",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a71912e6f254187bd921b8e7080e925",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49c7c9ad3eb24d2e842f65b98b796ff5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "836efaff81c3489894f45d3cc49401f4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b510a20bfeb5450ca129e19659f73fe6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b391c4345354a1b89c91df66e0b4434",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7e1151ec9bbb4189956a43d4cd06eeff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f722a31ec1a648c998e8fec87cc23a85",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df20d387f0a84a448ac03a570c552443",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b2418f32beb04d9892a2ef44a4eff93d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "90431f0488a647f899892e6d49abe84c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "53a05ad483b24c06a2a80a110e0d1563",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:4565: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quantization time: 1973.12 s = 32.89 min\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "import time\n",
        "\n",
        "t0 = time.time()\n",
        "model_2bits = AutoModelForCausalLM.from_pretrained(checkpoint, device_map=\"auto\", quantization_config=quantization_config)\n",
        "t_quantization = time.time() - t0\n",
        "print(f\"Quantization time: {t_quantization:.2f} s = {t_quantization/60:.2f} min\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vemos que ha tardado también una media hora"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos a ver la memoria que ocupa ahora"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01cXehrqGOrw",
        "outputId": "20f39967-2cd3-42f5-f40f-eb31f9db9004"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model memory: 4.50 GB\n"
          ]
        }
      ],
      "source": [
        "model_2bits_memory = model_2bits.get_memory_footprint()/(1024**3)\n",
        "print(f\"Model memory: {model_2bits_memory:.2f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mientras que cuantizado a 4 bits ocupaba 5.34 GB y a 3 bits ocupaba 4.52 GB, ahora cuantizado a 2 bits ocupa 4.50 GB, por lo que hemos conseguido reducir un poco más el tamaño del modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hacemos la inferencia y vemos el tiempo que tarda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nMZKcNJGOrx",
        "outputId": "1a7b8490-ca99-49ad-931a-6ea3bf6f61e3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello my name is Maximo and I am a Machine Learning Engineer.  # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
            "Inference time: 2.92 s\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "input_tokens = tokenizer(\"Hello my name is Maximo and I am a Machine Learning Engineer\", return_tensors=\"pt\").to(model_2bits.device)\n",
        "\n",
        "t0 = time.time()\n",
        "max_new_tokens = 50\n",
        "outputs = model_2bits.generate(\n",
        "    input_ids=input_tokens.input_ids,\n",
        "    attention_mask=input_tokens.attention_mask,\n",
        "    max_length=input_tokens.input_ids.shape[1] + max_new_tokens,\n",
        ")\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
        "print(f\"Inference time: {time.time() - t0:.2f} s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vemos que ya la salida no es buena, además, el tiempo de inferencia es de 2.92 segundos, más o menos lo mismo que con 3 y 4 bits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Guardamos el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sm2yaykrGOrx",
        "outputId": "355b4122-79d0-4eaa-b07c-1573d18727c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('./model_2bits/tokenizer_config.json',\n",
              " './model_2bits/special_tokens_map.json',\n",
              " './model_2bits/tokenizer.json')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "save_folder = \"./model_2bits/\"\n",
        "model_2bits.save_pretrained(save_folder)\n",
        "tokenizer.save_pretrained(save_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lo subimos al hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "057e8792bd6b4489b04ccfb5e38c5922",
            "fb77a7e61f3242f4b5b824dde57d94d4",
            "8373c2b11a6c44ebb135a86a964ab79a",
            "baa20c7006434b639e4d0880ad0dd0a4",
            "5c0f4dd3a6424ca5bf77d247c23b2f95",
            "44d0309094b6493f9a5f8f99dc3a2ca8",
            "a5b55e0547334f419f009b71550f9dd5",
            "5f134c626f16438d88f211372016d0e1",
            "a88afabeeb864a2193cc89e09bdf9fa7",
            "1a62431155144325942a97c4f72877de",
            "d3d30337b4f2497d9d0b87c9b3867b44"
          ]
        },
        "id": "Ns7Um6PGGOry",
        "outputId": "b001ffb0-c2d3-458c-cd46-211b4ff4368a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "057e8792bd6b4489b04ccfb5e38c5922",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors: 100%|██████████| 4.83/4.83G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/Maximofn/Llama-3-8B-Instruct-GPTQ-2bits/commit/13ede006ce0dbbd8aca54212e960eff98ea5ec63', commit_message='AutoGPTQ model for meta-llama/Meta-Llama-3-8B-Instruct: 2bits, gr16, desc_act=False', commit_description='', oid='13ede006ce0dbbd8aca54212e960eff98ea5ec63', pr_url=None, pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "repo_id = \"Llama-3-8B-Instruct-GPTQ-2bits\"\n",
        "commit_message = f\"AutoGPTQ model for {checkpoint}: {quantization_config.bits}bits, gr{quantization_config.group_size}, desc_act={quantization_config.desc_act}\"\n",
        "model_2bits.push_to_hub(repo_id, commit_message=commit_message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cuantización del modelo a 1 bit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos a cuantizarlo a 1 bit. Reinico el notebook para no tener problemas de memoria y me vuelvo a loguear en Hugging Face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Primero creo el tokenizador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OB_8mAOcGOrp",
        "outputId": "07b37ab2-5ac0-4833-ec27-0f8075935d49"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creamos la configuración de cuantización, ahora le decimos que cuantice a solo 1 bit y además que use un `group_size` de 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import GPTQConfig\n",
        "\n",
        "quantization_config = GPTQConfig(bits=2, dataset = \"c4\", tokenizer=tokenizer, group_size=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "8a464fbd4fc84fdf8152d903e637a129",
            "f83763b2bcd24eaeb385e7ffd1dc94b4",
            "ada67f7d5a7144bdb4361b24974ba970",
            "b8d198df7352498b85949ab15b0b55c5",
            "5782305cdbb44eb7af22c1ba92241503",
            "f2104bd4e9704294b13d7059b0e089c7",
            "66c3e7b2131645a9b1f1c5967138177d",
            "aeac0bfecc28470a867831fd31ad7c98",
            "3dcd1c98e7264e09a2e2ccd583294c58",
            "56589bde60e1450192e0940e5461c5d5",
            "9231f6657d33495e9dbf5d66d34c4d62",
            "4be9e10b9aaf480cb01f24dd55411108",
            "de8323aead3b44f396f14e3f2d0758c5",
            "e1eaca16ff4f4a4fb986180e77f6d602",
            "213b4313a33f470497d4c62d74dfa8a3",
            "f367d4131d2347ef8d8d2a649a96e716",
            "a66e7f1d21b344e79a87b0bdd1bf8547",
            "47cdb44d9016479ab1c40dba32317b6a",
            "e32099fa8d9c45d0ba372999744786a4",
            "36b714b9349a4dd3a6eb2937ed035f35",
            "c738cbda8a5a49ba8e8c6cb8a4163eb1",
            "5037cc58466c46fead04c36b17196061",
            "b1bc22e4b5884629b233b71aab3a5bc1",
            "84972ba4d2a0419d92cc1dfa70d1c7b9",
            "484ad88ff6ae4ab8b09c8eedf115505a",
            "c3edc695230d42fb9e5aad6c62f6c099",
            "a5f96ffca3a245b9bbabd9e93daf6e37",
            "f3bbf2a27e4b4f29a481012579976af0",
            "e56dd35c60b748fa8aa828693d353830",
            "8587b1da19d94756aa9596c8a9fb7829",
            "d168bc1b53624afd81dfadbe5fe47af3",
            "8bdde781a88142679df37e7c2b1b5685",
            "dd4e8a7aa8aa4b648fc921eaabde331f",
            "aec41fcf8c514ea58f8d43806ac81787",
            "e6eb996d358048079b97f2d7b42e6ea5",
            "53f69f18a5184fd69744d330e75c47d3",
            "368b2a0f177b46afa08fdd027f6877b7",
            "da61044ca87f40418f9fc52072689a04",
            "dba3766510034e6d8ec5a8479c7d4b68",
            "a09041d586a14e82bc496b34ddcc0d20",
            "6d20c67e07004afa982713b6c29bb966",
            "3afbd7fedd9e4b9ebeb9e366f83f858f",
            "78647f029ea34020a776810d0eb63b3f",
            "712de3157cd743159fdc5f73d1e37fcb",
            "9f9f20301b5848b6858ca41edb01bdc0",
            "1a88923f357a445cae30ec68e7e6619f",
            "0d4fa60cfc3e484e9b851aaa32d962d3",
            "171e0609961a467887ba49729f9ea00d",
            "73531fdf6502458e89bf72989df0128f",
            "34ce3500a43745f1a8420c04551fbc32",
            "e98ef9a16cf44957a22d8887491aa6d1",
            "d8fa6a7efa2941009a0803abbb7a145d",
            "44601e9287df400ea3a8c706af9555ff",
            "8ea9c28a92694ac7a82e90649d84c24a",
            "ac3c728ec0e341a394afb9a08cc6454f",
            "d534723b7ae145c7a2de48015f6eaa1c",
            "f7452df9d5d3451d94385d27202228d6",
            "5e31a0c3997047cb92470a3eaecc212f",
            "c8b143a6d85249c494c599ae9329045a",
            "533b4ccf44844f818f609fd56ed17bd7",
            "2856af815bee4dd3972589ba6796d80d",
            "85ad878de6114c329e6e8794fd495933",
            "68e58ab8444e4cbd9dfb4d1828a713a4",
            "52c1d689b3eb490a9dc124276b015f4f",
            "51900ab85eb84a728ba4d29d45ca90fd",
            "1a2345e657b04d34aca8070b66c3f519",
            "b77978a2d872438da03f89e8b5b31bb1",
            "8bad090070984137b968dca66da610bf",
            "6ad0cb55e8b94cfea09d9c5db1a6e25d",
            "1c5b54584f9f46529a6ee47f3783a897",
            "d94b226055a64675b09661e663bc0eec",
            "53515796114a46f6b1fa426b46cce590",
            "07ea9240f8a24b58bf9f94e3ae68fa3a",
            "2d47a84b61534043833e43ba65abde55",
            "f71dae62cb8d407a8f6ed373191d8018",
            "3443bb84165042fab341f0fba932d45b",
            "8c255af04b8c4f70a415e3726ad472ad",
            "82f60668eff04a56ae6c840026cd5d2d",
            "b166400d3534423095d147cb5561e73e",
            "26cadf4c35a1456e8ab14f28f56ec770",
            "af2d41c939a048cabcd589ad8d03c862",
            "dffaa92848444ebeb06781345d136b5f",
            "355c5dc3b60944d9ac9bce7f5ec7b8c0",
            "b8758f97a5854639988abbc1408ff812",
            "d3bf716f8b19487282069c24a901c55a",
            "1f69b2d6b4b14fa4a92b07e9c7515c76",
            "9ad8e89149fe471db16c40f4746c9638",
            "f03e44701cba4bd79ba87a92213d8c87",
            "9ce6fd88d94a4c28a1912147ce30c396",
            "a0a4f8a3c0c44e7f8144ac6b63d8b200",
            "8003a0852bb341c88071ca6f00e2e84f",
            "6d876f14100a4e33812834cb36e6cbad",
            "73b83c9b64914811bf8ad217edf2e60c",
            "bcdb3f10a29643b1b80fa26f3f71a7a8",
            "c4afaad855314189bd1d7ceb182a2014",
            "e92ce88bc5d94335a1cdf063cfb6cd68",
            "0fa75a3a6d62488ebd7ea6746da172e5",
            "f563b686ad284625b3ed5c95783e587c",
            "26fb82bb5ed14ef8a58dd15932c218d0",
            "6ce6d8200e384ea8b3cc55086dcc1168",
            "25494bf76f794127b331c3c79c49061d",
            "34a7a3b3363d4ad3b2fe88f962952259",
            "f477fc5da20e43c29c820d0c788458e9",
            "767367351bbf479ab8ce98201728b250",
            "470b422e3386461d97faa3aa5dfbb2f4",
            "2274d9cb36674d92bea43d71c0366353",
            "98a3c67166564b569284ab20ec330b53",
            "bc9e2c28a0ab4f96bee02c3b9da17a2b",
            "d601c6a6e1a04612a821631ec2a810d0",
            "5b57b9b1266849b994d34691c8aea311",
            "8801fbc2763b4424b7ec5da332f8116c",
            "4ea477f4609345deb744fefacd206623",
            "2f2f6d3a1790421c812c9f62d5a75aac",
            "24c846f909354b919ccb34f95b5aec4d",
            "59d7cd4e1b674683bb2acb5910e4f19a",
            "64458616c7b843e4990aabc8cb5dd6ed",
            "82a24bb3208e4a93909150e82a4123a2",
            "e6c206b961a343fe9c1b2bdd276c8f41",
            "7344ea2324f84071a7b3ab81f0b305dc",
            "c757c6524b034cf68a6ca058bf4478f4",
            "f4d9d589cb9c4ccca96cbca228e84fe1",
            "9a96d46428e546e9968ca5fd3bc4017d",
            "f04e280f3b814e0cb05f19c931416af1",
            "07f9f90b50064ca0878d26e0d6b864de",
            "b82e9a72a3954afcbdf8db93c3413845",
            "4daabd8fc1b04b45b81e022ef4fb553d",
            "141228b60b4c416cbb1c1b42a2c22030",
            "810d3702fe054213bb5be7a3bb20ab59",
            "a510b152179c426194ed1edc447d73a0",
            "428095125da848679f4b20b2889a9412",
            "d038a40cff3f481cae35c6275bc496b5",
            "7888b1a3f82e461291c5e6fa7b7b13e9",
            "3bc77b928b2c4b28a5303dbd9e3b1fad",
            "4f15649c98bb40fb92ca2ace158eda8c",
            "32ca4a9f7e0c457fa1c8e124a5ec627b",
            "04588e72656941d5801a9fc8d2869ffa",
            "8d27090bdb744b949a160cdf9b0667b5",
            "b0025b6574d04058a19bf5172e79ef19",
            "6865d40658a84317aac8dbff8f0da970",
            "7ce0adbff0e94b85bebdc67eeb4355c3",
            "0bbd016692f749908199007a1ab73a2d",
            "09a70429eb404532892d30c54413f05e",
            "4f99affd10dd46f39f7707cf53e03009",
            "b38117902cf84ffd8ae3b4f18a80ce31",
            "ad594df4d906496fa4043aaa860ec30a",
            "29248fefb00345e8b414fe25ab09ef93",
            "1bb31d8393db452fbb9b0963ba9f937f",
            "50b683308897401e9d8493b5bff33c99",
            "7b127bfaf5554a7b99cad59d9d9ed896",
            "8e1f9d8bcf1743db9bf446f5488eeeec",
            "4e96737122c2431a8e18f073e74bd92f",
            "546390baf6ad4172825115af861fd696",
            "b1b97f7cc105429da0a03dfe290e847e",
            "481ccc05b19d411590325fa91baeeb3f",
            "27815fc2a611492085a1e633d97d0087",
            "29c27683345a441f8d885d7c84daaba5",
            "f7dd55b6c2e04d3ea99ac612769d1b94",
            "1a22f71fed58423faac1b67c8b1d449c",
            "af49b7c5fe794dfab42689b2ceae8dc5",
            "c5d0f338fa37463e8b6443b24fd549c8",
            "40e90704eadf49eb9d7834c383973080",
            "aa1314d8c858409b85d5517d94b5f8d8",
            "de399058c16f49209cde35d6d05779af",
            "a25499a9fe7741f994df13762c4701e6",
            "998af98c34b2434387e6139def3c9d22",
            "1f5d79e8b733453ca565639a66f74981",
            "cd3e437aef33454c9382c438da277e0b",
            "933ccc55c073452fb5c92a49ef706ecd",
            "8c0737c1751c40ea9d33a841c50deab5",
            "9191d58e059047f1bff96e4f6c2376b3",
            "20bfd261d024436f8b9c5b06e7a75dd7",
            "69cc3f1103cc4cddabddbaa701ecdbe1",
            "6d5a4b418010437887a72b0cf1cfe541",
            "7f14ae5a51df4d19b07049e8c7ac533e",
            "f19feb53d4724fed9950fde9c26122ce",
            "e370c2f920014c47b145be7788d5bbf2",
            "1bcf8d896bd54b9c83a060ef8208b49b",
            "d83b956e4cde412cb62f0399ce1db1a0",
            "f3bb564c11814ba6b773092bb9c95e5f",
            "2f04a56e544b4a14a40d44c1b145b720",
            "f91b6e463640487db3d82fce42014c70",
            "2c22c7836ae743d984b408565f428557",
            "52ca170c84794d1d8ce6e8e6dd3ccfb4",
            "160f0e1f3cc74785b756cf539457ea39",
            "5693fa4433d84cc491250e611aa822e8",
            "7153298dc72949f58743424dffcf0b35",
            "d6fe8c08d6c54652b045a0257df744ff",
            "3fec611fb5bd43cfb396ef658a2097ca",
            "50f0f6d8a884405f83372c202587bea7",
            "9f86ae596ec649f28febc84e4d1d0935",
            "ae458eff463e4bc1ae08e6c2326f0841",
            "180ef17ca5e44c9b87802d5dfd613cba",
            "283ff0429b874274aef9587d55bea9d7",
            "72ce89a38a8147f5ad60224f84bf88cb",
            "f343e6493e734f5aa9ebbec50bcc1cda",
            "616640bca9fe4ac8b1d43c932c70500f",
            "a2bf5d2862994563a0c193c59791e3fa",
            "0ef47f435ab342a8adcaacff48775cac",
            "e81604fe52b1413fa8fb585960f1875e",
            "19d8c260c1d24bfa84fec63992b45849",
            "f0f7d9211d7d4f87a701fcabb95052ca",
            "ee5d64b0e91d4f5287d824a1168e646e",
            "5d4fd8999693432f86bda2c952ba965d",
            "3856d8e8b8554a169f20ac4e643455f1",
            "101e751349e24b6eb2384b9871516b27",
            "20db6da49db04ccfb033f54bca1a12e5",
            "bc6f6724bf45468bbbdcb695215bcb9f",
            "d204dc281a34451fb72c4df927c91d33",
            "455647ff20184018b37fc9dbf43d8704",
            "2545dc5ef2324dc3b37c05590738647d",
            "350c0f4c51b84b789334b01035eaa9fd",
            "70c201259df248f99fea8c14792b37ed",
            "211826df6a0f432cb6d1da0518e93b8f",
            "aefbc3fff0cb4b23a0a2d562c182eb9a",
            "66119b3e7cbc4646af8809b970ae8ae2",
            "10c8e9afae444674bc877707e65555f6",
            "5870c874468e40dd8ffd124bec8c8874",
            "56670dfb6314458f96303e6002cf75b8",
            "994525c2e6e34ab89867312ff383b751",
            "576a7f2ae6f442ca9af2925c03ce5681",
            "50a458fd18d44f6b96978600ddf193db",
            "31af8ea0608c4b168fe8b5c576c6a706",
            "c87bc31d5312449a90061cc7d8a50813",
            "fd6175253cb04b60b0adfaa1eaa48212",
            "e09b5db088c24514a92ca22515186e7e",
            "507b2236c3d14239a75866387c108555",
            "f188ea77d2cc4a5ca1230eb67bf7c44c",
            "0cbc034e4a184d43a2d8b28ba6720b1c",
            "84e55eca79dd4499b513fe9aa15b6bae",
            "ad6135e1f158419bbf6ff558c5d9ac51",
            "fc98d9c831624a53be0623d7ddafe49f",
            "55bb91fa708e4d38b0b8c5eaa607dae9",
            "0ebc9f25ef5d4361b13181ba5021fa9a",
            "c7fd774126174792ab5235686da6b45f",
            "f9988723518049c7826eb484742fccae",
            "e8df82e59b864dd995a92fe602e6823c",
            "9343d4c61f204693a083f6cd221e5ece",
            "52eeb654c7a84e2098b15e7b3fc423fe",
            "6d715014e3154a91bfe756f02be04a31",
            "cf6817247ea3461b8a3c6be4f5185179",
            "798d5f431ed846f8bc7ccbec0a5edcf1",
            "fada41ec37ac450393c2cdba73470473",
            "3e12f00056a24c7fa8eadf05b25608f0",
            "39da3c43fd11481ca4765e0ef7a18694",
            "ff7e87a4f39e4277b7821a56006de3f0",
            "153a3773f68c49409fb51cb581d74add",
            "95f5be08e5f6479db2ad0865a9c46010",
            "f8a5a58df2f644d99481666f6e8ef6ff",
            "f3889289566f42dcbe284fbdb5b74df1",
            "3e088ed54520496d84cd9e152edd6d9f",
            "6da6f13aead14e659e536ed723791728",
            "fcdf1ff484c347cc853478812d1115af",
            "152f0cbb21f2403bbfb7c42e20f39bae",
            "f9b8763ab96a498886e4d457efee757e",
            "8391cbddbe624fcbadd9f0c647d26fd6",
            "9fc291235e61473991d9c8abb6524920",
            "19ecac5530464696969cba95de9c44f6",
            "636f01fc6d324121937e2e31daba5aff",
            "2fd0a745494f49dbb50d2d7c38f5a1ba",
            "e3836b0ba0e045a39415a85f74a24666",
            "7082075554d9425fb61312773bc73c38",
            "5d43a0281bfa4fe6902cd058903176fd",
            "d62115f641e54e21a58628dd175a8700",
            "40481ae0b8424a71aa6e04eaab609f7d",
            "1fb11f4cd28e4d4b81c885bd0ef6e760",
            "625f6b26af7b4c61a907f30937f75800",
            "a7578fd96e3743a2aef29de9842cf3af",
            "6c9fbe3a9b2742faa4201a12c7528b8e",
            "a946e90c77e54ef4b189dd752c4f3032",
            "eef84cd21ba44121bdf9bb37469e2405",
            "2ecc143ee0a2493c8b0603930108a2b1",
            "33bbb535d53d4335b9d278d7fa6d1d85",
            "0add9982329842e3b82c1fe9f6c2459c",
            "721e8c15524943bcb8eea2602fea175e",
            "a51f8eeb397c408e84db6478b35e4fc2",
            "b5da4f28c5964c97968d66e3dfd4e766",
            "f5ec64e1623a46b08a1204f105bcc507",
            "beb952f9291144df923043d7a29b4aff",
            "bec957a3047540dabafff37e43ff993d",
            "7e9f1de031004a9991b24e4240e1b4ba",
            "43866601e2a5409096c84257efb83774",
            "119c4a0148744983afe1df9f00da80d5",
            "66f6171f06fd4c89802376cc0862809f",
            "89b7a2c577c743769ef224c2818530b9",
            "b6296fdc495440e79f4218350bb8a070",
            "1d3b5a984d934733b3e94edb77ab5548",
            "74735730e81740d1b93c6229951a1541",
            "eb9a2d6f3d374d5a974a0258bb09592f",
            "b811c54dae694ff39cae79da763c39fb",
            "ee8227f6168341538ae93e9b8191180a",
            "017c65d91c464474bfca816801e70c92",
            "0bef4f3e8d074d5389b56d7e7ee155f9",
            "18a676b83e3f4258902b0a3adcc90eb3",
            "c1c4f2255eee420da7f332e442d05d40",
            "5406efdaaec84b01bcdd1ac8920b1d9d",
            "eb82a8bdaf084f2bb65169300e800b77",
            "437756022a3349eabe2bf13362d16174",
            "1ab5c7dac3c543cbb3c3c6441cb012ad",
            "c55945a0e2b64227a88e52e0694daba8",
            "51fd04e1c8f145e5b167bf0e328c68ca",
            "9ab60884831848bc82c04f9cf6244758",
            "5ef3dbb27cb64d0893615b8a87d11b95",
            "eb04a921031840f787602d8c8b79f085",
            "fe97645b5883408ea3dfc42f10430938",
            "32d9863d941a4743a9764ba5fe7d16f7",
            "3e065b410894479e85fc451ec5bda643",
            "34deaf1ee2404c1ab271559e84e39ced",
            "e43ec2b670be45ecad559b7410b44221",
            "cb83386e322742989f0c72b66e6bb6e4",
            "5dd8bca60206477798a25aeaafa131f3",
            "97c93b274591451fa3fda73e3047b849",
            "c0a3d6ad3d1c4d4babb7fd6d211ac895",
            "f48413c973ba4a97b0d95306b42d2ca0",
            "8c8f1db9603c4e7fa0e717cf66975ad7",
            "bb260abb3a31456b9a2e274f768ba28d",
            "4fda5ed75ee84c00891a5917abbcdbee",
            "5c5c7a1ead2a4174a717bfaa835e935f",
            "d07157d3f6664897b52444eb5bf5a631",
            "d0d29d10aeca4566a1a47ca8cd126dd4",
            "f794b8f1c0bd40d3b9f8c518a1c2f0a4",
            "6ab4effaa4ef40ef8fc1d5ed6a9a2a9e",
            "f226c6ecb6bd4f84b013ff7fd2f263a5",
            "c758ca2849714d268b62f99c916cce8f",
            "d4edd9aeeb92435b972698cf9308d7c7",
            "7933662d26614498bbb1adae7df8ac22",
            "8ace8d8019544a3ca97a5f25493f1077",
            "ef8c7b978c624f2493feaa7bda61531e",
            "f4b8ec3f177b4208bdfbe5985afd0e14",
            "893c7369d0d247138aef346ae4b2a0b7",
            "e357d6e9cf684cd7800daa676fdfb27b",
            "e737ea72c9394a1188b19dd8a35c36de",
            "5766ef66f43b47efb51e615f56df6879",
            "1b67f464074740d7ac00b3effe4ea9b4",
            "b12dba30ae694c8587ab28bda5914cd7",
            "6485ea3e68f14053b182d11c78c656a9",
            "bfb1a24f80ac483ea2db8e6fce0d4d95",
            "e780a0c30d064372aab86cefee672b74",
            "aafec3924f16418d8476be3b7fd07ab7",
            "119c16c68eb1438688c0c2de73449b23",
            "67863cbc99fc4cf595ad5b3f0b348803",
            "1c36b169483a46b591612c7e0f4061e4",
            "bc85a2543c2444d58117f738ea07f53c",
            "8b9ba69defb0408882bad5f0bf145373",
            "602a47a6a3b247278cd9fe1062917157",
            "1ead6647ff4040289a44792ad7305a1e",
            "2b23c31ebc5c4b08adf5867e9e2665ba",
            "590f1061cdef48049c82d29f685541d0",
            "da2204dc04fa428781faf26e6b608143",
            "e2d54576ebae485b995825d227a11889",
            "18aeca64aee5463f986863d25f591daa",
            "764c403355be48b1ba618b369c88982f",
            "811ec40baea04577954175018e70587f",
            "f4f4c74bc2fb48729672c807fdcc4c1a",
            "16059b9aa5d24ffebfa9264a46b51531",
            "8285dcfe74ec4d6e9a1533ee967a536f",
            "de6bc125918e442fac7aff8d40666d9c",
            "4a06c4b7c434423bb24586f735d0c6cc",
            "c8e707720da54d07937ed13cfcda12f9",
            "b81c967fbf0a4a7291338cda1702f968",
            "561e0f17125a4607b49ac717216c3738",
            "73984820e4fe4bf9bbbe2642440f331c",
            "84f289f2612c44bdbc1e68604a59055a",
            "05cedc74730241bf8d2b48c6b31a0031",
            "f852fd3d75db48d0937a623c7b6b1a1a",
            "3e2b6095de174cbc8355a351f3f6cc13",
            "738475b2ac434dd99602ae9c581a08f4",
            "278dd867c2964179a0a022553894893f",
            "8d09decc870948d594bb0046048b4c0c",
            "6580f5d3b2e54e049baa273599fedccf",
            "90f9ba70fd204882a0eeff4c815c07e4",
            "0f5c3295775847b1bef049757a2a901d",
            "329adff777f94ad38c2a284eb31bf071",
            "802c24d041f24c13921af56291077e6a",
            "fa3b4c41c1ab44f9ab7149321940109c"
          ]
        },
        "id": "Nc4k2nprHEDS",
        "outputId": "a9e9ca81-5d65-4e75-df7b-b113d56df989"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a464fbd4fc84fdf8152d903e637a129",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4be9e10b9aaf480cb01f24dd55411108",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing model.layers blocks : 100%|██████████|32/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b1bc22e4b5884629b233b71aab3a5bc1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aec41fcf8c514ea58f8d43806ac81787",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f9f20301b5848b6858ca41edb01bdc0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d534723b7ae145c7a2de48015f6eaa1c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b77978a2d872438da03f89e8b5b31bb1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82f60668eff04a56ae6c840026cd5d2d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ce6fd88d94a4c28a1912147ce30c396",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ce6d8200e384ea8b3cc55086dcc1168",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8801fbc2763b4424b7ec5da332f8116c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a96d46428e546e9968ca5fd3bc4017d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3bc77b928b2c4b28a5303dbd9e3b1fad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b38117902cf84ffd8ae3b4f18a80ce31",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "27815fc2a611492085a1e633d97d0087",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f5d79e8b733453ca565639a66f74981",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1bcf8d896bd54b9c83a060ef8208b49b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3fec611fb5bd43cfb396ef658a2097ca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e81604fe52b1413fa8fb585960f1875e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2545dc5ef2324dc3b37c05590738647d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50a458fd18d44f6b96978600ddf193db",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55bb91fa708e4d38b0b8c5eaa607dae9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e12f00056a24c7fa8eadf05b25608f0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f9b8763ab96a498886e4d457efee757e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1fb11f4cd28e4d4b81c885bd0ef6e760",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b5da4f28c5964c97968d66e3dfd4e766",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "74735730e81740d1b93c6229951a1541",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ab5c7dac3c543cbb3c3c6441cb012ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb83386e322742989f0c72b66e6bb6e4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f794b8f1c0bd40d3b9f8c518a1c2f0a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e737ea72c9394a1188b19dd8a35c36de",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bc85a2543c2444d58117f738ea07f53c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4f4c74bc2fb48729672c807fdcc4c1a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f852fd3d75db48d0937a623c7b6b1a1a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Quantizing layers inside the block: 100%|██████████| 7/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:4565: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quantization time: 2030.38 s = 33.84 min\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "import time\n",
        "\n",
        "t0 = time.time()\n",
        "model_1bits = AutoModelForCausalLM.from_pretrained(checkpoint, device_map=\"auto\", quantization_config=quantization_config)\n",
        "t_quantization = time.time() - t0\n",
        "print(f\"Quantization time: {t_quantization:.2f} s = {t_quantization/60:.2f} min\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vemos que también tarda una media hora en cuantizar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos a ver la memoria que ocupa ahora"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZzdEZ9_HEDS",
        "outputId": "a7d5fd06-e463-4419-b38b-2b2419aaa662"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model memory: 5.42 GB\n"
          ]
        }
      ],
      "source": [
        "model_1bits_memory = model_1bits.get_memory_footprint()/(1024**3)\n",
        "print(f\"Model memory: {model_1bits_memory:.2f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vemos que en este caso ocupa incluso más que cuantizado a 2 bits, 4,52 GB."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hacemos la inferencia y vemos el tiempo que tarda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aid9ldWZHEDT",
        "outputId": "578ce6d0-923d-46fa-b670-34829b7adb39"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello my name is Maximo and I am a Machine Learning Engineerimerszuimersimerspinsimersimersingoingoimersurosimersimersimersoleningoimersingopinsimersbirpinsimersimersimersorgeingoimersiringimersimersimersimersimersimersimersンディorge_REFERER ingest羊imersorgeimersimersendetingoШАhandsingo\n",
            "Inference time: 3.12 s\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "input_tokens = tokenizer(\"Hello my name is Maximo and I am a Machine Learning Engineer\", return_tensors=\"pt\").to(model_1bits.device)\n",
        "\n",
        "t0 = time.time()\n",
        "max_new_tokens = 50\n",
        "outputs = model_1bits.generate(\n",
        "    input_ids=input_tokens.input_ids,\n",
        "    attention_mask=input_tokens.attention_mask,\n",
        "    max_length=input_tokens.input_ids.shape[1] + max_new_tokens,\n",
        ")\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
        "print(f\"Inference time: {time.time() - t0:.2f} s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vemos que la salida es muy mala y además tarda más que cuando hemos cuantizado a 2 bits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Guardamos el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DK76Ca-0HEDT",
        "outputId": "9c4389aa-af02-4ca3-9d9e-a927e26c98d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('./model_1bits/tokenizer_config.json',\n",
              " './model_1bits/special_tokens_map.json',\n",
              " './model_1bits/tokenizer.json')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "save_folder = \"./model_1bits/\"\n",
        "model_1bits.save_pretrained(save_folder)\n",
        "tokenizer.save_pretrained(save_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lo subimos al hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197,
          "referenced_widgets": [
            "c05b4dd06fa44f70a9f4ff530a66bf67",
            "ce16b6b07c13411a8742e05051f13e76",
            "59818ad42cc84688889603626304698f",
            "53808218980e498dae513420df6501ef",
            "c3ee048aab4546edbb7bd05c1c7b5ff0",
            "df8fb3e0fa7844eeb43e353f93eeaf0f",
            "c95b8cdd499d46758c08ff4bef356006",
            "f38d0d6febf645ff8c94bf7d9ed19ca8",
            "ba173f62cd98411b86e23b63510023da",
            "97449915c6944fb58a8827323d2991ea",
            "152abcc404a44248953251180f0a272f",
            "ae82b20e08f5497689974b338c9d369e",
            "4821b4dd2d084ee79d8e9f32349abc0d",
            "2f780a142ef1402b99d559efd02bbc7a",
            "84ed6370601340ea93e306f92f95e6e2",
            "0ac7cf3d02404157b9f210cd3a4e8c49",
            "b6283492f5e4445b88764a7c411c0fb3",
            "cd738cfee74f4cdfb7efa7857f723c76",
            "48d5e9fa8bbb4b03bbd3a578bda89264",
            "b07d4d7949a145e580f0c6f2de423925",
            "bad8cf989bec463e96f84ebe228d8459",
            "db4bb864b9be481b9bbbdd2bd609b80d",
            "6de5b563b621486aabe386ed45c6ff6c",
            "4f2b0f4a7db7400c96f681496662b249",
            "2c0cc902a2ab47679e6c838f59e9ad19",
            "be234bcb44fa4771958b4fcfa8db6655",
            "09096d0bfecb416cb508e9d338710337",
            "2f439786fb0c4c589921dbd251883841",
            "de928a690a4746b199383b211e8b174a",
            "f88f56aa906e4803bf2ecbefb83f2dfc",
            "3cfea192251a44059b04bab7110b565e",
            "176c4ff2c0a744a68c112e6fa73bd7bb",
            "ff1cd8faa0ba4e01883d56c825cba094",
            "78fc3db6259d454783d00604599685a7",
            "77f97c79d8c142cab72105d16af95a47",
            "1025beaec9a4407a8b083c1bd6e219fd",
            "d5937399445147bba7fb7f259d0f174c",
            "9a524dfcd6544041be52e7786cccd232",
            "550b54cede614c068cd7e1ffddfc53ef",
            "59cb213d101a46a8970514d0a8f02a0a",
            "4a373866258b46078cf153012b82edff",
            "32e150ce0f9249f884d55e8573efe28b",
            "88254285d5424b148d2ddbdb9bbb16ad",
            "e1d7ea190e3f43cf824c450a3a1abf4d"
          ]
        },
        "id": "Au9hL6urHEDU",
        "outputId": "8bcced77-295b-4e53-a3f7-b4d69acf10a7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c05b4dd06fa44f70a9f4ff530a66bf67",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 100%|██████████| 0.00/5.17k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae82b20e08f5497689974b338c9d369e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Upload 2 LFS files: 100%|██████████| 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6de5b563b621486aabe386ed45c6ff6c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00002.safetensors: 100%|██████████| 0.00/1.05G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "78fc3db6259d454783d00604599685a7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00002.safetensors: 100%|██████████| 0.00/4.76G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/Maximofn/Llama-3-8B-Instruct-GPTQ-2bits/commit/e59ccffc03247e7dcc418f98b482cc02dc7a168d', commit_message='AutoGPTQ model for meta-llama/Meta-Llama-3-8B-Instruct: 2bits, gr8, desc_act=False', commit_description='', oid='e59ccffc03247e7dcc418f98b482cc02dc7a168d', pr_url=None, pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "repo_id = \"Llama-3-8B-Instruct-GPTQ-1bits\"\n",
        "commit_message = f\"AutoGPTQ model for {checkpoint}: {quantization_config.bits}bits, gr{quantization_config.group_size}, desc_act={quantization_config.desc_act}\"\n",
        "model_1bits.push_to_hub(repo_id, commit_message=commit_message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resumen de la cuantización"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos a comprar la cuantización a 4, 3, 2 y 1 bits\n",
        "\n",
        "|Bits | Tiempo de cuantización (min) | Memoria (GB) | Tiempo de inferencia (s) | Calidad de la salida |\n",
        "|-------|---------|----------------|-----------------------------|------------------------|\n",
        "|FP16 | 0 | 14.96 | 4.14 | Buena |\n",
        "|4 | 32.20 | 5.34 | 2.34 | Buena |\n",
        "|3 | 31.88 | 4.52 | 2.89 | Buena |\n",
        "|2 | 32.89 | 4.50 | 2.92 | Mala |\n",
        "|1 | 33.84 | 5.42 | 3.12 | Mala |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Viendo esta tabla vemos que no tiene sentido, en este ejemplo, cuantizar a menos de 4 bits.\n",
        "\n",
        "Cuantizar a 1 y 2 bits claramente no tiene sentido porque la calidad de la salida es mala.\n",
        "\n",
        "Pero aunque la salida cuando cuantizamos a 3 bits es buena, empieza a ser repetitiva, por lo que a largo plazo, seguramente no sería buena idea usar ese modelo. Además ni el ahorro en tiempo de cuantización, el ahorro en VRAM ni el ahorro en tiempo de inferencia es significativo en comparación con cuantizar a 4 bits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Carga del modelo guardado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora que hemos comparado la cuantización de modelos, vamos a ver cómo se haría para cargar el modelo de 4 bits que hemos guardado, ya que como hemos visto, es la mejor opción"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Primero cargamos el tokenizador que hemos usado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "path = \"./model_4bits\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora cargamos el modelo que hemos guardado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ccbbf944dd9c422494a9c4dc8e7170e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "load_model_4bits = AutoModelForCausalLM.from_pretrained(path, device_map=\"auto\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vemos la memoria que ocupa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model memory: 5.34 GB\n"
          ]
        }
      ],
      "source": [
        "load_model_4bits_memory = load_model_4bits.get_memory_footprint()/(1024**3)\n",
        "print(f\"Model memory: {load_model_4bits_memory:.2f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vemos que ocupa la misma memoria que cuando lo habíamos cuantizado, lo cual es lógico"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hacemos la inferencia y vemos el tiempo que tarda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0WwmioY5P39",
        "outputId": "7f82e40c-cd72-42d3-c249-b703557e5404"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello my name is Maximo and I am a Machine Learning Engineer. I have a strong background in computer science and mathematics, and I have been working with machine learning models for several years. I am excited to be a part of this community and to share my knowledge and experience with others. I am particularly interested in\n",
            "Inference time: 3.82 s\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "input_tokens = tokenizer(\"Hello my name is Maximo and I am a Machine Learning Engineer\", return_tensors=\"pt\").to(load_model_4bits.device)\n",
        "\n",
        "t0 = time.time()\n",
        "max_new_tokens = 50\n",
        "outputs = load_model_4bits.generate(\n",
        "    input_ids=input_tokens.input_ids,\n",
        "    attention_mask=input_tokens.attention_mask,\n",
        "    max_length=input_tokens.input_ids.shape[1] + max_new_tokens,\n",
        ")\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
        "print(f\"Inference time: {time.time() - t0:.2f} s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vemos que la inferencia es buena y ha tardado 3.82 segundos, un poco más que cuando lo cuantizamos. Pero al igual que he dicho antes, habría que hacer esta prueba muchas veces y sacar una media."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Carga del modelo subido al hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora vemos cómo cargar el modelo de 4 bits que hemos subido al Hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Primero cargamos el tokenizador que hemos subido"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = \"Maximofn/Llama-3-8B-Instruct-GPTQ-4bits\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora cargamos el modelo que hemos guardado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "load_model_4bits = AutoModelForCausalLM.from_pretrained(checkpoint, device_map=\"auto\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vemos la memoria que ocupa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model memory: 5.34 GB\n"
          ]
        }
      ],
      "source": [
        "load_model_4bits_memory = load_model_4bits.get_memory_footprint()/(1024**3)\n",
        "print(f\"Model memory: {load_model_4bits_memory:.2f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "También ocupa la misma memoria"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hacemos la inferencia y vemos el tiempo que tarda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello my name is Maximo and I am a Machine Learning Engineer with a passion for building innovative AI solutions. I have been working in the field of AI for over 5 years, and have gained extensive experience in developing and implementing machine learning models for various industries.\n",
            "\n",
            "In my free time, I enjoy reading books on\n",
            "Inference time: 3.81 s\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "input_tokens = tokenizer(\"Hello my name is Maximo and I am a Machine Learning Engineer\", return_tensors=\"pt\").to(load_model_4bits.device)\n",
        "\n",
        "t0 = time.time()\n",
        "max_new_tokens = 50\n",
        "outputs = load_model_4bits.generate(\n",
        "    input_ids=input_tokens.input_ids,\n",
        "    attention_mask=input_tokens.attention_mask,\n",
        "    max_length=input_tokens.input_ids.shape[1] + max_new_tokens,\n",
        ")\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
        "print(f\"Inference time: {time.time() - t0:.2f} s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vemos que la inferencia también es buena y ha tardado 3.81 segundos."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "nlp_",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "maximofn": {
      "date": "2024-07-27",
      "description_en": "Attention developers! 🚨 Do you have a language model that is too big and heavy for your application? 🤯 Don't worry, GPTQ is here to help you! 🤖 This quantization algorithm is like a wizard that makes unnecessary bits and bytes disappear, reducing the size of your model without losing too much precision. 🎩 It's like compressing a file without losing quality - it's a way to make your models more efficient and faster! 🚀",
      "description_es": "¡Atención, desarrolladores! 🚨 ¿Tienes un modelo de lenguaje que es demasiado grande y pesado para tu aplicación? 🤯 ¡No te preocupes, GPTQ está aquí para ayudarte! 🤖 Este algoritmo de cuantización es como un mago que hace desaparecer los bits y bytes innecesarios, reduciendo el tamaño de tu modelo sin perder demasiada precisión. 🎩 Es como comprimir un archivo sin perder calidad. ¡Es una forma de hacer que tus modelos sean más eficientes y rápidos! 🚀",
      "description_pt": "Atenção, desenvolvedores! 🚨 Você tem um modelo de idioma que é muito grande e pesado para o seu aplicativo? 🤯 Não se preocupe, o GPTQ está aqui para ajudá-lo! 🤖 Esse algoritmo de quantização é como um assistente que faz com que bits e bytes desnecessários desapareçam, reduzindo o tamanho do seu modelo sem perder muita precisão. 🎩 É como compactar um arquivo sem perder a qualidade - é uma maneira de tornar seus modelos mais eficientes e rápidos! 🚀",
      "end_url": "gptq",
      "image": "https://images.maximofn.com/GPTQ-thumbnail.webp",
      "image_hover_path": "https://images.maximofn.com/GPTQ-thumbnail.webp",
      "keywords_en": "gptq, quantization, compression, model efficiency, model speed, model size, model optimization",
      "keywords_es": "gptq, cuantización, compresión, eficiencia del modelo, velocidad del modelo, tamaño del modelo, optimización del modelo",
      "keywords_pt": "gptq, quantização, compressão, eficiência do modelo, velocidade do modelo, tamanho do modelo, otimização do modelo",
      "title_en": "GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers",
      "title_es": "GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers",
      "title_pt": "GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
