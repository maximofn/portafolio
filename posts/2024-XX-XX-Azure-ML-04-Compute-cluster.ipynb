{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure ML - Compute Instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loguearse a Azure ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como las acciones que vamos a hacer por CLI o a través del SDK de Python necesitan una autentificación, primero vamos a loguearnos en Azure ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Login en Azure ML con el CLI de Azure ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para logearnos en Azure hacemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se nos abrirá el navegador para logearnos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear un cliente de Azure ML con el SDK de Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero creamos dos variables con la ID de la suscripción y el grupo de recursos, como estos son datos personales, no los voy a poner aquí. Lo que voy a hacer es incluirlos en un archivo `.env` que no voy a subir a GitHub\n",
    "\n",
    "```bash\n",
    "AZURE_SUSCRIPION_ID=\"xxxxx-xxxx-xxxx-xxxx-xxxxx\"\n",
    "AZURE_ML_RESOURCE_GRPU_ID=\"xxxxx-xxxx-xxxx-xxxx-xxxxx\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora para leerlos primero necesitasos tener instalado `dotenv` que lo hacemos mediante `pip install python-dotenv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "AZURE_SUSCRIPION_ID = os.getenv(\"AZURE_SUSCRIPION_ID\")\n",
    "AZURE_ML_RESOURCE_GRPU_ID = os.getenv(\"AZURE_ML_RESOURCE_GRPU_ID\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos estas variables creamos un cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "ml_client = MLClient(DefaultAzureCredential(), AZURE_SUSCRIPION_ID, AZURE_ML_RESOURCE_GRPU_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a volver a ver la arquitectura de `Azure ML`\n",
    "\n",
    "![Azure ML architecture concepts](https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/azureml-architecture-concepts.webp)\n",
    "\n",
    "Al igual que antes henmos creado un `Compute Instance`, ahora vamos a ver cómo crear un `Compute Cluster`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crear un `Compute Cluster` desde la interfaz gráfica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En `Azure ML studio` deberíamos tener el `Workspace` `Azure ML Workspace GUI`, así que entramos en él y pinchamos en el botón `New` y seleccionamos `Compute cluster`\n",
    " * En localización seleccionamos la misma que antes que el `Workspace`, en mi caso `France Central`\n",
    " * En `Virtual Machine tier` podemos seleccionar `Dedicated` para que garantice que siempre esté disponible, aunque es más caro, o `Low priority` que es más barato pero puede ser que no esté disponible\n",
    " * Seleccionamos el tipo de máquina, si `CPU` o `GPU`, en mi caso selecciono `GPU` para poder entrenar modelos\n",
    " * Seleccionamos el tipo de `GPU` que queremos, espero que cuando leas esto los filtros sean mejores y puedas filtrar por `VRAM`, pero cuando lo estoy escribiendo no está ese filtro básico. En mi caso, como no voy a hacer entrenamientos muy grandes elijo la `Standard_NC4as_T4_v3` que tiene una `Tesla T4` con `16GB` de `VRAM`\n",
    " * Pulsamos `Next`\n",
    " * Le ponemos un nombre, en mi caso le pondré `compute-cluster-GUI`\n",
    " * Ponemos el número mínimo de nodos. En mi caso pongo 0, así cuando no esté en uso no me cobrarán\n",
    " * Ponemos el número máximo de nodos. En mi caso pongo 4, aunque para el uso que le voy a dar en este post con 1 me sobra\n",
    " * Seleccionamos los segundos para que se reduzca el número de nodos, en mi caso pongo 60 segundos\n",
    " * Pulsamos `Create` para crear el cluster, tardará unos minutos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando se crea hay una zona llamada `Applications` donde podemos elegir si ejecutar el cluster en `JupyterLab`, `Jupyter`, `vscode` en la web o `vscode` en local."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por otro lado, cuando se crea el cluster, se crea con el mínimo número de nodos que hayas configurado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crear un `Compute cluster` con el CLI de Azure ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos la `Compute instance` con el siguiente comando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K{| Finished ..\n",
      "  \"enable_node_public_ip\": true,\n",
      "  \"id\": \"/subscriptions/40018f20-6173-46c6-9434-ce9df3089dce/resourceGroups/rg-azure-ml/providers/Microsoft.MachineLearningServices/workspaces/azure-ml-workspace-CLI/computes/compute-instance-CLI\",\n",
      "  \"idle_time_before_scale_down\": 60,\n",
      "  \"location\": \"francecentral\",\n",
      "  \"max_instances\": 4,\n",
      "  \"min_instances\": 0,\n",
      "  \"name\": \"compute-instance-CLI\",\n",
      "  \"network_settings\": {},\n",
      "  \"provisioning_state\": \"Succeeded\",\n",
      "  \"resourceGroup\": \"rg-azure-ml\",\n",
      "  \"size\": \"Standard_E4ds_v4\",\n",
      "  \"ssh_public_access_enabled\": true,\n",
      "  \"tier\": \"dedicated\",\n",
      "  \"type\": \"amlcompute\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!GROUP='rg-azure-ml' && \\\n",
    "LOCATION='francecentral' && \\\n",
    "WORKSPACE='azure-ml-workspace-CLI' && \\\n",
    "NAME=\"compute-instance-CLI\" && \\\n",
    "SIZE=\"Standard_E4ds_v4\" && \\\n",
    "TYPE=\"AmlCompute\" && \\\n",
    "IDLE_BEFORE_SCALE_DOWN=\"60\" && \\\n",
    "MIN_NODES=\"0\" && \\\n",
    "MAX_NODES=\"4\" && \\\n",
    "az ml compute create --name $NAME --size $SIZE --type $TYPE --workspace-name $WORKSPACE --resource-group $GROUP --idle-time-before-scale-down $IDLE_BEFORE_SCALE_DOWN --min-instances $MIN_NODES --max-instances $MAX_NODES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crear un `Compute cluster` con el SDK de Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el `Compute cluster` con el siguiente código. Lo llamo `compute-cluster-Python` y no `compute-cluster-Python-SDK` porque el nombre tienen que tener 24 caracteres como máximo. Además, este `Compute cluster` lo voy a crear con una GPU `Standard_NC8as_T4_v3` porque no me deja crear más `Compute instance`s con la GPU que he elegido antes en la misma suscripción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object.__init__() takes exactly one argument (the instance to initialize)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m min_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      9\u001b[0m max_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[0;32m---> 11\u001b[0m compute_cluster \u001b[38;5;241m=\u001b[39m \u001b[43mAmlCompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_cluster_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtype_compute\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_instances\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_instances\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43midle_idle_time_before_scale_down\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midle_time_before_scale_down\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m result \u001b[38;5;241m=\u001b[39m ml_client\u001b[38;5;241m.\u001b[39mbegin_create_or_update(compute_cluster)\u001b[38;5;241m.\u001b[39mresult()\n",
      "File \u001b[0;32m~/miniforge3/envs/azure_ml/lib/python3.11/site-packages/azure/ai/ml/entities/_compute/aml_compute.py:144\u001b[0m, in \u001b[0;36mAmlCompute.__init__\u001b[0;34m(self, name, description, size, tags, ssh_public_access_enabled, ssh_settings, min_instances, max_instances, network_settings, idle_time_before_scale_down, identity, tier, enable_node_public_ip, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    142\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     kwargs[TYPE] \u001b[38;5;241m=\u001b[39m ComputeType\u001b[38;5;241m.\u001b[39mAMLCOMPUTE\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlocation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m=\u001b[39m size\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_instances \u001b[38;5;241m=\u001b[39m min_instances \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/azure_ml/lib/python3.11/site-packages/azure/ai/ml/entities/_compute/compute.py:60\u001b[0m, in \u001b[0;36mCompute.__init__\u001b[0;34m(self, name, location, description, resource_id, tags, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_provisioning_state: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprovisioning_state\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_provisioning_errors: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprovisioning_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresource_id \u001b[38;5;241m=\u001b[39m resource_id\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocation \u001b[38;5;241m=\u001b[39m location\n",
      "File \u001b[0;32m~/miniforge3/envs/azure_ml/lib/python3.11/site-packages/azure/ai/ml/entities/_resource.py:67\u001b[0m, in \u001b[0;36mResource.__init__\u001b[0;34m(self, name, description, tags, properties, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialize \u001b[38;5;241m=\u001b[39m Serializer(client_models)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialize\u001b[38;5;241m.\u001b[39mclient_side_validation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: object.__init__() takes exactly one argument (the instance to initialize)"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "compute_cluster_name = \"compute-cluster-Python\"\n",
    "size = \"Standard_E4ds_v4\"\n",
    "idle_time_before_scale_down = \"30\"\n",
    "type_compute = \"AmlCompute\"\n",
    "location = \"francecentral\"\n",
    "min_nodes = 0\n",
    "max_nodes = 4\n",
    "\n",
    "compute_cluster = AmlCompute(\n",
    "    name=compute_cluster_name, \n",
    "    type=type_compute, \n",
    "    size=size, \n",
    "    location=location, \n",
    "    min_instances=min_nodes,\n",
    "    max_instances=max_nodes,\n",
    "    idle_idle_time_before_scale_down=idle_time_before_scale_down\n",
    ")\n",
    "\n",
    "result = ml_client.begin_create_or_update(compute_cluster).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComputeInstance({'state': 'Running', 'last_operation': {'operation_name': 'Create', 'operation_time': '2024-10-15T08:36:44.038Z', 'operation_status': 'Succeeded', 'operation_trigger': 'User'}, 'os_image_metadata': <azure.ai.ml.entities._compute._image_metadata.ImageMetadata object at 0x77963d78c510>, 'services': [{'display_name': 'Jupyter', 'endpoint_uri': 'https://compute-instance-python.francecentral.instances.azureml.ms/tree/'}, {'display_name': 'Jupyter Lab', 'endpoint_uri': 'https://compute-instance-python.francecentral.instances.azureml.ms/lab'}], 'type': 'computeinstance', 'created_on': '2024-10-15T08:36:35.730569+0000', 'provisioning_state': 'Succeeded', 'provisioning_errors': None, 'name': 'compute-instance-Python', 'description': None, 'tags': None, 'properties': {}, 'print_as_yaml': False, 'id': '/subscriptions/c1ffdd1c-ecfc-4119-bf19-e207f9a4bcaf/resourceGroups/rg-azure-ml/providers/Microsoft.MachineLearningServices/workspaces/azure-ml-workspace-Python-SDK/computes/compute-instance-Python', 'Resource__source_path': '', 'base_path': '/home/maximofernandez/Documents/web/portafolio/posts', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x77963d76f550>, 'resource_id': None, 'location': 'francecentral', 'size': 'STANDARD_E4DS_V4', 'ssh_public_access_enabled': False, 'create_on_behalf_of': None, 'network_settings': <azure.ai.ml.entities._compute.compute.NetworkSettings object at 0x77963d78d310>, 'ssh_settings': <azure.ai.ml.entities._compute.compute_instance.ComputeInstanceSshSettings object at 0x77963d78c9d0>, 'schedules': None, 'identity': None, 'idle_time_before_shutdown': 'PT30M', 'idle_time_before_shutdown_minutes': 30, 'setup_scripts': None, 'enable_node_public_ip': True, 'enable_sso': True, 'enable_root_access': True, 'release_quota_on_stop': False, 'enable_os_patching': False, 'custom_applications': None, 'subnet': None})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Administrar un `Compute instance` de Azure ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Administrar un `Compute instance` desde la interfaz gráfica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entramos en la sección `Compute` del `Workspace` y pinchamos en la `Compute instance` que queramos administrar y a través de la interfaz gráfica podemos hacer lo que queramos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Administrar un `Compute instance` con el CLI de Azure ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos realizar varias operaciones básicas en la `COmpute instance` con el CLI de Azure ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parar un `Compute instance` con el CLI de Azure ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K\u001b[0minished .."
     ]
    }
   ],
   "source": [
    "!GROUP='rg-azure-ml' && \\\n",
    "WORKSPACE='azure-ml-workspace-CLI' && \\\n",
    "NAME=\"compute-instance-CLI\" && \\\n",
    "az ml compute stop --name $NAME --workspace-name $WORKSPACE --resource-group $GROUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Iniciar un `Compute instance` con el CLI de Azure ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K / Finished ..\u001b[0m"
     ]
    }
   ],
   "source": [
    "!GROUP='rg-azure-ml' && \\\n",
    "WORKSPACE='azure-ml-workspace-CLI' && \\\n",
    "NAME=\"compute-instance-CLI\" && \\\n",
    "az ml compute start --name $NAME --workspace-name $WORKSPACE --resource-group $GROUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reiniciar un `Compute instance` con el CLI de Azure ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K / Finished ..\u001b[0m"
     ]
    }
   ],
   "source": [
    "!GROUP='rg-azure-ml' && \\\n",
    "WORKSPACE='azure-ml-workspace-CLI' && \\\n",
    "NAME=\"compute-instance-CLI\" && \\\n",
    "az ml compute restart --name $NAME --workspace-name $WORKSPACE --resource-group $GROUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Eliminar un `Compute instance` con el CLI de Azure ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are you sure you want to perform this operation? (y/n): ^C\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!GROUP='rg-azure-ml' && \\\n",
    "WORKSPACE='azure-ml-workspace-CLI' && \\\n",
    "NAME=\"compute-instance-CLI\" && \\\n",
    "az ml compute delete --name $NAME --workspace-name $WORKSPACE --resource-group $GROUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Respondo que no porque voy a seguir trabajando con el `Compute instance`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observar un `Compute instance` con el CLI de Azure ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"created_on\": \"2024-10-14T10:47:41.472829+0000\",\n",
      "  \"enable_node_public_ip\": true,\n",
      "  \"enable_os_patching\": false,\n",
      "  \"enable_root_access\": true,\n",
      "  \"enable_sso\": true,\n",
      "  \"id\": \"/subscriptions/c1ffdd1c-ecfc-4119-bf19-e207f9a4bcaf/resourceGroups/rg-azure-ml/providers/Microsoft.MachineLearningServices/workspaces/azure-ml-workspace-CLI/computes/compute-instance-CLI\",\n",
      "  \"last_operation\": {\n",
      "    \"operation_name\": \"Start\",\n",
      "    \"operation_status\": \"Succeeded\",\n",
      "    \"operation_time\": \"2024-10-14T11:12:50.323Z\",\n",
      "    \"operation_trigger\": \"User\"\n",
      "  },\n",
      "  \"location\": \"francecentral\",\n",
      "  \"name\": \"compute-instance-CLI\",\n",
      "  \"network_settings\": {\n",
      "    \"private_ip_address\": \"10.0.0.4\",\n",
      "    \"public_ip_address\": \"52.143.163.77\"\n",
      "  },\n",
      "  \"os_image_metadata\": {\n",
      "    \"current_image_version\": \"24.09.23\",\n",
      "    \"is_latest_os_image_version\": true,\n",
      "    \"latest_image_version\": \"24.09.23\"\n",
      "  },\n",
      "  \"provisioning_state\": \"Succeeded\",\n",
      "  \"release_quota_on_stop\": false,\n",
      "  \"resourceGroup\": \"rg-azure-ml\",\n",
      "  \"services\": [\n",
      "    {\n",
      "      \"display_name\": \"Jupyter\",\n",
      "      \"endpoint_uri\": \"https://compute-instance-cli.francecentral.instances.azureml.ms/tree/\"\n",
      "    },\n",
      "    {\n",
      "      \"display_name\": \"Jupyter Lab\",\n",
      "      \"endpoint_uri\": \"https://compute-instance-cli.francecentral.instances.azureml.ms/lab\"\n",
      "    }\n",
      "  ],\n",
      "  \"size\": \"Standard_E4ds_v4\",\n",
      "  \"ssh_public_access_enabled\": false,\n",
      "  \"ssh_settings\": {\n",
      "    \"admin_username\": \"azureuser\",\n",
      "    \"ssh_port\": \"50000\"\n",
      "  },\n",
      "  \"state\": \"Running\",\n",
      "  \"type\": \"computeinstance\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!GROUP='rg-azure-ml' && \\\n",
    "WORKSPACE='azure-ml-workspace-CLI' && \\\n",
    "NAME=\"compute-instance-CLI\" && \\\n",
    "az ml compute show --name $NAME --workspace-name $WORKSPACE --resource-group $GROUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > ¡Asegurate de pararlo si no vas a aseguir trabajando ahora!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Administrar un `Compute instance` con el SDK de Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Estado de un `Compute instance` con el SDK de Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created_on: 2024-10-15T08:25:33.612998+0000\n",
      "enable_node_public_ip: true\n",
      "enable_os_patching: false\n",
      "enable_root_access: true\n",
      "enable_sso: true\n",
      "id: /subscriptions/c1ffdd1c-ecfc-4119-bf19-e207f9a4bcaf/resourceGroups/rg-azure-ml/providers/Microsoft.MachineLearningServices/workspaces/azure-ml-workspace-Python-SDK/computes/compute-instance-Python\n",
      "idle_time_before_shutdown: PT30M\n",
      "idle_time_before_shutdown_minutes: 30\n",
      "last_operation:\n",
      "  operation_name: Create\n",
      "  operation_status: Succeeded\n",
      "  operation_time: '2024-10-15T08:25:41.912Z'\n",
      "  operation_trigger: User\n",
      "location: francecentral\n",
      "name: compute-instance-Python\n",
      "network_settings:\n",
      "  private_ip_address: 10.0.0.4\n",
      "  public_ip_address: 4.212.11.121\n",
      "os_image_metadata:\n",
      "  current_image_version: 24.09.23\n",
      "  is_latest_os_image_version: true\n",
      "  latest_image_version: 24.09.23\n",
      "provisioning_state: Succeeded\n",
      "release_quota_on_stop: false\n",
      "services:\n",
      "- display_name: Jupyter\n",
      "  endpoint_uri: https://compute-instance-python.francecentral.instances.azureml.ms/tree/\n",
      "- display_name: Jupyter Lab\n",
      "  endpoint_uri: https://compute-instance-python.francecentral.instances.azureml.ms/lab\n",
      "size: STANDARD_E4DS_V4\n",
      "ssh_public_access_enabled: false\n",
      "ssh_settings:\n",
      "  admin_username: azureuser\n",
      "  ssh_port: '50000'\n",
      "state: Running\n",
      "type: computeinstance\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import ComputeInstance, AmlCompute\n",
    "\n",
    "compute_instance_name = \"compute-instance-Python\"\n",
    "\n",
    "compute_instance_state = ml_client.compute.get(compute_instance_name)\n",
    "print(compute_instance_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parar un `Compute instance` con el SDK de Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import ComputeInstance, AmlCompute\n",
    "\n",
    "compute_instance_name = \"compute-instance-Python\"\n",
    "\n",
    "ml_client.compute.begin_stop(compute_instance_name).wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Iniciar un `Compute instance` con el SDK de Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import ComputeInstance, AmlCompute\n",
    "\n",
    "compute_instance_name = \"compute-instance-Python\"\n",
    "\n",
    "ml_client.compute.begin_start(compute_instance_name).wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reiniciar un `Compute instance` con el SDK de Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import ComputeInstance, AmlCompute\n",
    "\n",
    "compute_instance_name = \"compute-instance-Python\"\n",
    "\n",
    "ml_client.compute.begin_restart(compute_instance_name).wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Eliminar un `Compute instance` con el SDK de Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import ComputeInstance, AmlCompute\n",
    "\n",
    "compute_instance_name = \"compute-instance-Python\"\n",
    "\n",
    "ml_client.compute.begin_delete(compute_instance_name).wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observar un `Compute instance` con el SDK de Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<azure.ai.ml.entities._compute._image_metadata.ImageMetadata object at 0x77963d78d3d0>\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import ComputeInstance, AmlCompute\n",
    "\n",
    "compute_instance_name = \"compute-instance-Python\"\n",
    "\n",
    "instance = ml_client.compute.get(compute_instance_name)\n",
    "print(instance.os_image_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que ha devuelto un objeto de la clase `ComputeInstance`, para ver todos los parámetros de esta clase podemos entrar en [azure.ai.ml.entities.computeinstance](https://learn.microsoft.com/en-us/python/api/azure-ai-ml/azure.ai.ml.entities.computeinstance?view=azure-python). Vamos a ver por ejemplo el nombre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'compute-instance-Python'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "instance.name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azure_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
