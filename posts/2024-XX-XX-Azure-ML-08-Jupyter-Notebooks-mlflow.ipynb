{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure ML - Jupyter Notebooks - mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loguearse a Azure ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como las acciones que vamos a hacer por CLI o a trav√©s del SDK de Python necesitan una autentificaci√≥n, primero vamos a loguearnos en Azure ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Login en Azure ML con el CLI de Azure ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para logearnos en Azure hacemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se nos abrir√° el navegador para logearnos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear un cliente de Azure ML con el SDK de Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero creamos dos variables con la ID de la suscripci√≥n y el grupo de recursos, como estos son datos personales, no los voy a poner aqu√≠. Lo que voy a hacer es incluirlos en un archivo `.env` que no voy a subir a GitHub\n",
    "\n",
    "```bash\n",
    "AZURE_SUSCRIPION_ID=\"xxxxx-xxxx-xxxx-xxxx-xxxxx\"\n",
    "AZURE_ML_RESOURCE_GRPU_ID=\"xxxxx-xxxx-xxxx-xxxx-xxxxx\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora para leerlos primero necesitasos tener instalado `dotenv` que lo hacemos mediante `pip install python-dotenv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "AZURE_SUSCRIPION_ID = os.getenv(\"AZURE_SUSCRIPION_ID\")\n",
    "AZURE_ML_RESOURCE_GRPU_ID = os.getenv(\"AZURE_ML_RESOURCE_GRPU_ID\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos estas variables creamos un cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "workspace_name = \"azure-ml-workspace-Python-SDK\"\n",
    "\n",
    "ml_client = MLClient(DefaultAzureCredential(), AZURE_SUSCRIPION_ID, AZURE_ML_RESOURCE_GRPU_ID, workspace_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Notebooks mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta parte es la haremos con la interfaz gr√°fica, por lo que hazlo con el `Workspace` que quieras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos visto c√≥mo hacer un entrenamiento b√°sico con un Jupyter Notebook, ahora vamos a ver c√≥mo hacerlo con `mlflow` para poder hacer seguimiento del entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En Studio seleccionamos `Notebooks` en la parte izquierda de la interfaz. Vemos que tenemos una zona con las carpetas y otra en la que podemos darle al bot√≥n de `+ Files` para crear nuevos archivos, de modo que le damos al bot√≥n, seleccionamos `Create new file`, ponemos un nombre, en mo caso pondr√© `image-classification-mlflow.ipynb`, en `File type` seleccionamos `Notebook` y le damos a `Create`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que se nos ha creado un Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleccionar un `Compute Instance`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que tenemos que hacer es seleccionar un `Compute Instance` para ello pinchar en la zona de `Compute` de la parte superior del notebook. Nos aparecer√°n los `Compute Instance`s que hayamos creado, seleccionamos uno y le damos al bot√≥n de `Start`, tardar√° un poco en arrancar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez hemos levantado una `Compute Instance` tenemos que elegir un kernel, igual que cuando ejecutamos un Jupyter Notebook en local. Para ellos pinchamos en la zona de `Kernel` en la parte superior del notebook y seleccionamos el kernel que queramos. En mo caso voy a seleccionar `Python 3.10 - SDK v2`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este kernel es un entorno de conda, por lo que podemos crearnos nuevos si queremos. En la zona donde se ven las carpetas hay un bot√≥n con formade una terminal, si dejamos el bot√≥n encima aparece el texto `Open terminal`. Si le damos se nos abrir√° la terminal de esa `Compute Instance`, por lo que podr√≠amos crear nuevos entornos de conda si queremos. Luego podremos seleccionar esos entornos como kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En mi caso voy a usar el kernel `Python 3.10 - SDK v2`, abro la terminal e instalo las siguientes librer√≠as\n",
    "\n",
    "```bash\n",
    "conda activate azureml_py310_sdkv2\n",
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "pip install mlflow azureml-mlflow\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D√≥nde editar el Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambi√©n, cuando levantamos el `Compute Instance` se habilita una zona en la parte superior del notebook que pone `Edit in VS Code`. Si le damos se abrir√° un men√∫ en el que podemos seleccionar si editarlo en vscode en la web o en local. Haz lo que prefieras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuaci√≥n pondr√© el notebook que he usado para entrenar el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "from torchmetrics import Accuracy\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "import mlflow\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descargamos el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos una muestra del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APH/AA9oaanDJP5to8sb7Ra3MxhDDGS2/gcemR3r0DQ/EupaDZfYAnhKSBNxiSS7fEeSSR8pwRnJ9eevSud1aKXxFf3N/qlz4d8yY75rm2mIeNcAfLGCN2AAAMEk9e5rhJkSOeRI33orEK+Mbh2OK2tF16SzENk9hZXMJkxue3XzlDcNtcDdnHTOcdRzXTz2UHmOIvAV/LhiNxa7Oeayb+5Ok25li8LLYTFhGXvIXlQggnGyUFd3AweuAa5i8u5r66e5nKGR8Z2Rqg4GBhVAA4HYVEjbXVskYOcivQLmawaaVZPGd2mHPypbE4/OQVz2uyWzWSrBr1zqH70Hy5Y9oAwfm++ef8etc9RXbSeLb8vk29gzEZLNaITk/UVja3rt3qFuttNHbLGGD/uoFQ5Ge4HvWFX/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACOElEQVR4AVVSTWtTQRS989689/KdWDDFgjaoBNPWBhuEov9AxKX0D4jdCC7EX1Bc+QvaleBGETcK4sKN0JUQkYI1YiPGkJIPkrxIkvfm05l5iZJZzNyZM/ecO+cOArC5JUCN506y5Y432nf1xgwMYDBn/eyVo2HRIaULpVT3NwckAZC5Ui6uw3H3hXDc5OHji5dZUH+tUQPGrsn+hPuTzTJ8/AUpiXM9yowUwI1H9kzk3+Lt76pYacJWZe9NOptZCrxwWY6STTT8ebtfU4Cmvend2pqM+tCMk/TodJWlU+erB7gzNWApIQuNHlEqSFCgDrPXWoOAGdr8+BgQjocICSY4ZxzbtSFcqrxUpHCv8Wz3fTGhQ7C9VC4NsP/51bu9SHNte/tTdkMkbAkWqkOhU6u1TnvqamQCwFPcdYNwTDmlMa/8wNBoECEp4XqmAWNLcskQEfk6WOpMv1Mv4Oc4A0FCbWmMIznzRzMgWLnq6sDSEzhmjhxSZ7yy016RDrY44d/Ccw9NU4x9ihlOfgxGhEyEpJaDvIVMAc3qdyTZVAITmOpCNK6NV5oy8MdEpalq1c9YzNSVtB1pC+ECYjLrm5SZCZbIPyGigCzA1lcJ3v3FgjrNDvpCPeZTzGmwoKlYjk7+2K7NOWExSSPW//NmDuz54+e/Zl4t7BwyFmDVbpGkS28D85UjUBPccQU7I0hAk63VD0pVjQhUT67GfSxwSKY42cwNIhOifqpeLGcmoeq1lDYfImIS4S+m6gFxJeYrpQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "idx = randint(0, len(training_data))\n",
    "sample_img, label = training_data[idx]\n",
    "sample_img_PIL = ToPILImage()(sample_img)\n",
    "print(f\"Label: {label}\")\n",
    "sample_img_PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos la dimensi√≥n del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len_training_data = len(training_data)\n",
    "len_test_data = len(test_data)\n",
    "len_training_data, len_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos el n√∫mero de clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 10, classes: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n"
     ]
    }
   ],
   "source": [
    "set_clases = set({})\n",
    "for i in range(len_training_data):\n",
    "    _, label = training_data[i]\n",
    "    set_clases.add(label)\n",
    "num_classes = len(set_clases)\n",
    "print(f\"Number of classes: {num_classes}, classes: {set_clases}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dejamos el c√≥digo para crear un subset por si te quieres hacer un subset m√°s peque√±o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "factor = 1\n",
    "subset_training_data = torch.utils.data.Subset(training_data, range(0, len_training_data//factor))\n",
    "subset_test_data = torch.utils.data.Subset(test_data, range(0, len_test_data//factor))\n",
    "\n",
    "len(subset_training_data), len(subset_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3750, 625)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BS = 16\n",
    "train_dataloader = DataLoader(subset_training_data, batch_size=BS, shuffle=True)\n",
    "test_dataloader = DataLoader(subset_test_data, batch_size=BS, shuffle=True)\n",
    "\n",
    "len(train_dataloader), len(test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        super(ImageClassifier, self).__init__()\n",
    "        self.imageClassifier = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(self.num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.imageClassifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos el modelo con una muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 1, 28, 28]), torch.Size([16, 10]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_batch = next(iter(train_dataloader))\n",
    "image_batch, label_batch = sample_batch\n",
    "model = ImageClassifier(num_classes)\n",
    "output = model(image_batch)\n",
    "image_batch.shape, output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/09 09:42:14 WARNING mlflow.utils.autologging_utils: MLflow pytorch autologging is known to be compatible with 1.9.0 <= torch <= 2.4.0, but the installed version is 2.5.1. If you encounter errors during autologging, try upgrading / downgrading torch to a compatible version, or try upgrading MLflow.\n"
     ]
    }
   ],
   "source": [
    "mlflow.pytorch.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqu√≠ pon tus valores para `SUSCRIPTION_ID`, `RESOURCE_GROUP` y `WORKSPACE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUSCRIPTION_ID = \"\"\n",
    "RESOURCE_GROUP = \"\"\n",
    "WORKSPACE = \"\"\n",
    "mlflow.set_tracking_uri = f\"azureml://francecentral.api.azureml.ms/mlflow/v1.0/subscriptions/{SUSCRIPTION_ID}/resourceGroups/{RESOURCE_GROUP}/providers/Microsoft.MachineLearningServices/workspaces/{WORKSPACE}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azureml/mlflow/_protos/aml_service_pb2.py:10: UserWarning: google.protobuf.service module is deprecated. RPC implementations should provide code generator plugins which generate code specific to the RPC implementation. service.py will be removed in Jan 2025\n",
      "  from google.protobuf import service as _service\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='', creation_time=1731141371877, experiment_id='ba0ceff2-ddbe-4308-9a4f-6a846a2dd0c7', last_update_time=None, lifecycle_stage='active', name='image-classification', tags={}>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlflow.set_experiment(experiment_name=\"image-classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos el modelo est√° en la CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funciones de entrenamiento y evaluaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, metrics_fn, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        metric = metrics_fn(pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss = loss.item()\n",
    "            current = batch\n",
    "            step = batch // 1000 * (epoch + 1)\n",
    "            mlflow.log_metric(\"train_loss\", f\"{loss:.4f}\", step=step)\n",
    "            mlflow.log_metric(\"train_accuracy\", f\"{metric:.4f}\", step=step)\n",
    "            print(f\"train loss: {loss:.4f}, train accuracy: {metric:.4f} [{current}/{len(dataloader)}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader, model, loss_fn, metrics_fn, epoch):\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    eval_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            eval_loss += loss_fn(pred, y).item()\n",
    "            eval_accuracy += metrics_fn(pred, y).item()\n",
    "\n",
    "    eval_loss /= num_batches\n",
    "    eval_accuracy /= num_batches\n",
    "    mlflow.log_metric(\"eval_loss\", f\"{eval_loss:.4f}\", step=epoch)\n",
    "    mlflow.log_metric(\"eval_accuracy\", f\"{eval_accuracy:.4f}\", step=epoch)\n",
    "\n",
    "    print(f\"eval loss: {eval_loss:.4f}, eval accuracy: {eval_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "LR = 1e-3\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "metrics_fn = Accuracy(task=\"multiclass\", num_classes=num_classes).to(device)\n",
    "model = ImageClassifier(num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "train loss: 2.3623, train accuracy: 0.0625 [0/3750]\n",
      "train loss: 0.4929, train accuracy: 0.8750 [100/3750]\n",
      "train loss: 0.4513, train accuracy: 0.8750 [200/3750]\n",
      "train loss: 0.6159, train accuracy: 0.7500 [300/3750]\n",
      "train loss: 0.2675, train accuracy: 0.8750 [400/3750]\n",
      "train loss: 0.2816, train accuracy: 0.8750 [500/3750]\n",
      "train loss: 0.2231, train accuracy: 0.9375 [600/3750]\n",
      "train loss: 0.5147, train accuracy: 0.6875 [700/3750]\n",
      "train loss: 0.4221, train accuracy: 0.8750 [800/3750]\n",
      "train loss: 0.1267, train accuracy: 1.0000 [900/3750]\n",
      "train loss: 0.3912, train accuracy: 0.8750 [1000/3750]\n",
      "train loss: 1.0029, train accuracy: 0.6250 [1100/3750]\n",
      "train loss: 0.1412, train accuracy: 1.0000 [1200/3750]\n",
      "train loss: 0.2537, train accuracy: 0.8125 [1300/3750]\n",
      "train loss: 0.3991, train accuracy: 0.6875 [1400/3750]\n",
      "train loss: 0.2171, train accuracy: 0.9375 [1500/3750]\n",
      "train loss: 0.3148, train accuracy: 0.8750 [1600/3750]\n",
      "train loss: 0.2962, train accuracy: 0.9375 [1700/3750]\n",
      "train loss: 0.6517, train accuracy: 0.7500 [1800/3750]\n",
      "train loss: 0.4082, train accuracy: 0.8750 [1900/3750]\n",
      "train loss: 0.1639, train accuracy: 0.8750 [2000/3750]\n",
      "train loss: 0.2061, train accuracy: 0.9375 [2100/3750]\n",
      "train loss: 0.1150, train accuracy: 1.0000 [2200/3750]\n",
      "train loss: 0.2200, train accuracy: 0.8750 [2300/3750]\n",
      "train loss: 0.3156, train accuracy: 0.9375 [2400/3750]\n",
      "train loss: 0.1665, train accuracy: 0.9375 [2500/3750]\n",
      "train loss: 0.5031, train accuracy: 0.7500 [2600/3750]\n",
      "train loss: 0.4877, train accuracy: 0.8750 [2700/3750]\n",
      "train loss: 0.3961, train accuracy: 0.8750 [2800/3750]\n",
      "train loss: 0.4473, train accuracy: 0.8125 [2900/3750]\n",
      "train loss: 0.1523, train accuracy: 0.9375 [3000/3750]\n",
      "train loss: 0.2188, train accuracy: 0.8750 [3100/3750]\n",
      "train loss: 0.2436, train accuracy: 0.8750 [3200/3750]\n",
      "train loss: 0.3093, train accuracy: 0.9375 [3300/3750]\n",
      "train loss: 0.3131, train accuracy: 0.8750 [3400/3750]\n",
      "train loss: 0.3726, train accuracy: 0.8125 [3500/3750]\n",
      "train loss: 0.2582, train accuracy: 0.9375 [3600/3750]\n",
      "train loss: 0.2596, train accuracy: 0.8125 [3700/3750]\n",
      "eval loss: 0.3139, eval accuracy: 0.8884\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "train loss: 0.2148, train accuracy: 0.9375 [0/3750]\n",
      "train loss: 0.5943, train accuracy: 0.8125 [100/3750]\n",
      "train loss: 0.1100, train accuracy: 1.0000 [200/3750]\n",
      "train loss: 0.2512, train accuracy: 0.8750 [300/3750]\n",
      "train loss: 0.3152, train accuracy: 0.8750 [400/3750]\n",
      "train loss: 0.6021, train accuracy: 0.8125 [500/3750]\n",
      "train loss: 0.0645, train accuracy: 0.9375 [600/3750]\n",
      "train loss: 0.1431, train accuracy: 0.9375 [700/3750]\n",
      "train loss: 0.2588, train accuracy: 0.8750 [800/3750]\n",
      "train loss: 0.3870, train accuracy: 0.8750 [900/3750]\n",
      "train loss: 0.4990, train accuracy: 0.8750 [1000/3750]\n",
      "train loss: 0.2030, train accuracy: 0.8750 [1100/3750]\n",
      "train loss: 0.4924, train accuracy: 0.8750 [1200/3750]\n",
      "train loss: 0.2795, train accuracy: 0.9375 [1300/3750]\n",
      "train loss: 0.1306, train accuracy: 0.9375 [1400/3750]\n",
      "train loss: 0.1574, train accuracy: 0.9375 [1500/3750]\n",
      "train loss: 0.0618, train accuracy: 1.0000 [1600/3750]\n",
      "train loss: 0.2075, train accuracy: 0.9375 [1700/3750]\n",
      "train loss: 0.2181, train accuracy: 0.9375 [1800/3750]\n",
      "train loss: 0.7746, train accuracy: 0.7500 [1900/3750]\n",
      "train loss: 0.2126, train accuracy: 0.9375 [2000/3750]\n",
      "train loss: 0.3604, train accuracy: 0.8125 [2100/3750]\n",
      "train loss: 0.2154, train accuracy: 0.9375 [2200/3750]\n",
      "train loss: 0.3402, train accuracy: 0.8750 [2300/3750]\n",
      "train loss: 0.3194, train accuracy: 0.8750 [2400/3750]\n",
      "train loss: 0.6013, train accuracy: 0.8125 [2500/3750]\n",
      "train loss: 0.1139, train accuracy: 0.9375 [2600/3750]\n",
      "train loss: 0.1094, train accuracy: 0.9375 [2700/3750]\n",
      "train loss: 0.1775, train accuracy: 0.8750 [2800/3750]\n",
      "train loss: 0.2579, train accuracy: 0.8750 [2900/3750]\n",
      "train loss: 0.0223, train accuracy: 1.0000 [3000/3750]\n",
      "train loss: 0.0548, train accuracy: 1.0000 [3100/3750]\n",
      "train loss: 0.3312, train accuracy: 0.9375 [3200/3750]\n",
      "train loss: 0.2351, train accuracy: 0.8750 [3300/3750]\n",
      "train loss: 0.0968, train accuracy: 1.0000 [3400/3750]\n",
      "train loss: 0.3619, train accuracy: 0.8750 [3500/3750]\n",
      "train loss: 0.1909, train accuracy: 0.8750 [3600/3750]\n",
      "train loss: 0.3259, train accuracy: 0.8750 [3700/3750]\n",
      "eval loss: 0.2815, eval accuracy: 0.8996\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "train loss: 0.2559, train accuracy: 0.8125 [0/3750]\n",
      "train loss: 0.0362, train accuracy: 1.0000 [100/3750]\n",
      "train loss: 0.1785, train accuracy: 0.9375 [200/3750]\n",
      "train loss: 0.0524, train accuracy: 1.0000 [300/3750]\n",
      "train loss: 0.1018, train accuracy: 0.9375 [400/3750]\n",
      "train loss: 0.0163, train accuracy: 1.0000 [500/3750]\n",
      "train loss: 0.0499, train accuracy: 1.0000 [600/3750]\n",
      "train loss: 0.4869, train accuracy: 0.9375 [700/3750]\n",
      "train loss: 0.1211, train accuracy: 1.0000 [800/3750]\n",
      "train loss: 0.3638, train accuracy: 0.9375 [900/3750]\n",
      "train loss: 0.2499, train accuracy: 0.8750 [1000/3750]\n",
      "train loss: 0.1872, train accuracy: 0.9375 [1100/3750]\n",
      "train loss: 0.6748, train accuracy: 0.7500 [1200/3750]\n",
      "train loss: 0.1818, train accuracy: 0.8750 [1300/3750]\n",
      "train loss: 0.0065, train accuracy: 1.0000 [1400/3750]\n",
      "train loss: 0.2800, train accuracy: 0.8750 [1500/3750]\n",
      "train loss: 0.1808, train accuracy: 0.8750 [1600/3750]\n",
      "train loss: 0.0116, train accuracy: 1.0000 [1700/3750]\n",
      "train loss: 0.0586, train accuracy: 0.9375 [1800/3750]\n",
      "train loss: 0.4188, train accuracy: 0.7500 [1900/3750]\n",
      "train loss: 0.4493, train accuracy: 0.8750 [2000/3750]\n",
      "train loss: 0.1486, train accuracy: 0.9375 [2100/3750]\n",
      "train loss: 0.1153, train accuracy: 1.0000 [2200/3750]\n",
      "train loss: 0.2988, train accuracy: 0.9375 [2300/3750]\n",
      "train loss: 0.0465, train accuracy: 1.0000 [2400/3750]\n",
      "train loss: 0.0468, train accuracy: 1.0000 [2500/3750]\n",
      "train loss: 0.1936, train accuracy: 0.9375 [2600/3750]\n",
      "train loss: 0.1015, train accuracy: 0.9375 [2700/3750]\n",
      "train loss: 0.2541, train accuracy: 0.9375 [2800/3750]\n",
      "train loss: 0.0960, train accuracy: 1.0000 [2900/3750]\n",
      "train loss: 0.3591, train accuracy: 0.8750 [3000/3750]\n",
      "train loss: 0.4975, train accuracy: 0.8750 [3100/3750]\n",
      "train loss: 0.1078, train accuracy: 1.0000 [3200/3750]\n",
      "train loss: 0.0961, train accuracy: 0.9375 [3300/3750]\n",
      "train loss: 0.2846, train accuracy: 0.8750 [3400/3750]\n",
      "train loss: 0.0279, train accuracy: 1.0000 [3500/3750]\n",
      "train loss: 0.0124, train accuracy: 1.0000 [3600/3750]\n",
      "train loss: 0.0795, train accuracy: 0.9375 [3700/3750]\n",
      "eval loss: 0.2728, eval accuracy: 0.9048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 37.25it/s]   \n",
      "2024/11/09 09:44:37 INFO mlflow.tracking._tracking_service.client: üèÉ View run image_classification_2024-11-09_09:42:15 at: https://francecentral.api.azureml.ms/mlflow/v2.0/subscriptions/40018f20-6173-46c6-9434-ce9df3089dce/resourceGroups/rg-azure-ml/providers/Microsoft.MachineLearningServices/workspaces/azure-ml-workspace-gui-/#/experiments/ba0ceff2-ddbe-4308-9a4f-6a846a2dd0c7/runs/15cf21b0-576e-420b-b4f1-aaeef2352ddc.\n",
      "2024/11/09 09:44:37 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: https://francecentral.api.azureml.ms/mlflow/v2.0/subscriptions/40018f20-6173-46c6-9434-ce9df3089dce/resourceGroups/rg-azure-ml/providers/Microsoft.MachineLearningServices/workspaces/azure-ml-workspace-gui-/#/experiments/ba0ceff2-ddbe-4308-9a4f-6a846a2dd0c7.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "name = f\"image_classification_{datetime.now().strftime('%Y-%m-%d_%H:%M:%S')}\"\n",
    "with mlflow.start_run(run_name=name) as run:\n",
    "    params = {\n",
    "        \"epochs\": epochs,\n",
    "        \"learning_rate\": LR,\n",
    "        \"batch_size\": BS,\n",
    "        \"num_classes\": num_classes,\n",
    "        \"loss_fn\": loss_fn.__class__.__name__,\n",
    "        \"metrics_fn\": metrics_fn.__class__.__name__,\n",
    "        \"optimizer\": \"Adam\",\n",
    "    }\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    with open(\"model_summary.txt\", \"w\") as f:\n",
    "        f.write(str(summary(model, input_size=(BS, 1, 28, 28), device=device)))\n",
    "    mlflow.log_artifact(\"model_summary.txt\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
    "        train(train_dataloader, model, loss_fn, metrics_fn, optimizer, epoch)\n",
    "        evaluate(test_dataloader, model, loss_fn, metrics_fn, epoch)\n",
    "    \n",
    "    mlflow.pytorch.log_model(model, \"models\", input_example=image_batch.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si aqu√≠ nos vamos a la secci√≥n de `Jobs` de nuestro `Workspace` veremos que se ha creado un nuevo `Experiment` con el nombre que le hemos dado. Dentro en la pesta√±a `Metrics` podremos ver gr√°fcas las m√©tricas que hemos ido guardando y en la pesta√±a `Outputs + logs` podremos ver los logs de la ejecuci√≥n y una carpeta llamada `models` con el modelo guardado del experimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo bueno de mlflow es que tiene integraci√≥n con la mayor√≠a de librer√≠as de machine learning, por lo que este modelo despu√©s puede ser importado a trav√©s de mlflow y ser usado en cualquier otro sitio, de hecho vamos a hacerlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descarga del modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 30.69it/s]\n"
     ]
    }
   ],
   "source": [
    "logged_model = f\"runs:/{run.info.run_id}/models\"\n",
    "loaded_model = mlflow.pytorch.load_model(logged_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos el modelos entrenado con una muestra del conjunto de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    idx = randint(0, len(subset_test_data))\n",
    "except:\n",
    "    print(idx, len(subset_test_data))\n",
    "sample_test_img, label = subset_test_data[idx]\n",
    "output = loaded_model(sample_test_img.to(output.device).unsqueeze(0))\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: 5, True label: 5\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+nwwy3EqxQxvJI3RUUkn8BWhb+HtXu3jSDT53aX7gC/e+n07+neo9a0i50HWLnS7wxme3fazRPuRuMgg9wQQaoVc0vUZNK1GK8ijjkaPOEkztORjnBB/Wur8O+MdWn8S6XbQx2UKS3MURWO3ReGcbjuOSuRwcHGK6vxn4Rs9Z177dcXf2O4eJRIgw24qSobOf7oUfhXn+jaXYLcCS71XS9rR5USM52t2yNuPY5qxqWleHoNTubttZheyZt8dpYqzStnkqCw2qoJIySTgdCa6HwH4rtodbliCado1ilq3l/dDSNvGN8r5ZjgtxkDjpTPiJr1pfa/by2upwXCC1VWaFi4B3vxkDGcEfnXm9FFFf/9k=",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABdElEQVR4AWNgGNyAiQXqPqbtmqguZQJz1ZV5bDxFsv7PYmCAqQSJ/2NgChc9x+L58gzLZI75QBmIaogJTAyS7P9+fdnN+ZqLg0VYjYGBESIOJJn+Mf3jcZfnfy8jIMp/QfaXeNUJhCRIFVMP12EVhkYxw527vr9ljUWVZBD69gNi1Pp/73nbEQ5i+gcUfgdyBIhxhYGB3x/hIJAQAwvTv39ghhL3rx9sCJ0gOYY/IAJohqTR57ufv6BJgqWAWv9e+cXE/QgmyQLWA7QRaCpfgKs8wz8mppsQSRYj6W87QSYCHSNbq/CX4TMrx1umj0BJpn8izm8/l4El/zGUOjBUnSlX/CjKxP0D7PI3L/kvbQoEaXTYqJjofYbBhJufnZPpJ8TYp9LG74M2/lON01mwHuTYz59YPn4WZWVRj/jxnV+W+6Pg11YFs52B4JjgkHnEJMqiwscoYPCL4ReDONc3yc/3z0AC4g9Du9bzH18ZqkEWDSoAAPd4dWgqkGa9AAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_label = torch.argmax(output, dim=1).item()\n",
    "print(f\"Predicted label: {predicted_label}, True label: {label}\")\n",
    "sample_test_img_PIL = ToPILImage()(sample_test_img)\n",
    "sample_test_img_PIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos el entrenamiento ha sido exitoso"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azure_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
