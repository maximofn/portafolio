{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure ML - Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loguearse a Azure ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como las acciones que vamos a hacer por CLI o a través del SDK de Python necesitan una autentificación, primero vamos a loguearnos en Azure ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Login en Azure ML con el CLI de Azure ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para logearnos en Azure hacemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se nos abrirá el navegador para logearnos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear un cliente de Azure ML con el SDK de Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero creamos dos variables con la ID de la suscripción y el grupo de recursos, como estos son datos personales, no los voy a poner aquí. Lo que voy a hacer es incluirlos en un archivo `.env` que no voy a subir a GitHub\n",
    "\n",
    "```bash\n",
    "AZURE_SUSCRIPION_ID=\"xxxxx-xxxx-xxxx-xxxx-xxxxx\"\n",
    "AZURE_ML_RESOURCE_GRPU_ID=\"xxxxx-xxxx-xxxx-xxxx-xxxxx\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora para leerlos primero necesitasos tener instalado `dotenv` que lo hacemos mediante `pip install python-dotenv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "AZURE_SUSCRIPION_ID = os.getenv(\"AZURE_SUSCRIPION_ID\")\n",
    "AZURE_ML_RESOURCE_GRPU_ID = os.getenv(\"AZURE_ML_RESOURCE_GRPU_ID\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos estas variables creamos un cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "ml_client = MLClient(DefaultAzureCredential(), AZURE_SUSCRIPION_ID, AZURE_ML_RESOURCE_GRPU_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A la hora de entrenar un modelo, lo primero que necesitamos es tener un dataset. Así que vamos a ver cómo crearlo en Azure ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero antes de eso, vamos a ver qué datasets vamos a usar. Vamos a usar dos datasets, por un lado el dataset [Cats-vs-Dogs](https://www.kaggle.com/datasets/shaunthesheep/microsoft-catsvsdogs-dataset) para entrenar un modelo de clasificación de imágenes y el dataset [mteb/amazon_reviews_multi](https://huggingface.co/datasets/mteb/amazon_reviews_multi/viewer/en) para entrenar un modelo de clasificación de texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storage account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear una cuenta de almacenamiento fuera de Azure ML para que en caso de borrar los recursos de Azure ML, que los datos no se pierdan por si los está usando otro recurso, por si los vamos a queres usar en otro recurso o por si queremos hacer un backup de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para crear el `storage account` en Azure ML hay que seguir los siguientes pasos:\n",
    " * Ir al portal de Azure\n",
    " * Ahora crear un nuevo grupo de recursos con la siguiente configuración:\n",
    "   * En `Suscription` elegir la suscripción que hemos creado, si es que la has creado, y si no la que tengas\n",
    "   * En `Resource group` poner un nombre para el grupo de recursos, en mi caso he puesto `rg-storage-account`\n",
    "   * En `Region` elegir la región que más te convenga, en mi caso he elegido `France Central`\n",
    " * Una vez creado el grupo de recursos, vamos a crear un nuevo recurso. Buscamos `Storage account` en el buscador que se nos abre y le damos a `Create`\n",
    "   * En `Subscription` elegimos la suscripción que hemos creado, si es que la has creado, y si no la que tengas\n",
    "   * En `Resource group` elegimos el grupo de recursos que hemos creado\n",
    "   * En `Name` ponemos un nombre para el servicio almacenamiento, en mi caso he puesto `storageaccountmfn`\n",
    "   * En `Region` elegimos la región que más nos convenga, en mi caso he elegido `France Central`. Pero lo ideal es que sea la misma región que el grupo de recursos\n",
    "   * En `Rendimiento` elegimos `Standar`\n",
    "   * En `Redundancia` elegimos `LRS` ya que no vamos a tener aplicaciones reales, esto es solo un post\n",
    "   * Por último le damos al botón de `Review + create` y si todo está bien le damos al botón de `Create`\n",
    "\n",
    "Cuando termine aparecerá un botón de `Go to resource` que nos llevará a la página principal del servicio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear un contenedor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez estamos en el recurso darle a `Blob service` y se nos abrirá la sección de contenedores, creamos uno nuevo con las siguientes características:\n",
    " * En `Name` ponemos un nombre, en mi caso he puesto `storage-account-container`\n",
    " * Le damos al botón de `Create`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vincular el contenedor a Azure ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volvemos a `Studio`, vamos a la sección de `Connections`, le damos al botón de `Connect` y elegimos `Azure Blob Storage`. Ahora le damos a `Next` y elegimos el contenedor que hemos creado. Por último le damos a `Create` a continuación:\n",
    " * En `Suscription` elegimos nuestra suscripcción\n",
    " * En `Resource group` elegimos el grupo de recursos que hemos creado, en mi caso `rg-storage-account`\n",
    " * En `Blob container` elegimos el contenedor que hemos creado, en mi caso `storage-account-container`\n",
    " * En `Authentication method` elegimos `Credential based`\n",
    " * En `Authentication type` elegimos `Account key`\n",
    " * En `Azure` volvemos a nuestro `storage account` y en la sección de `Security + networking` le damos a `Access keys` y copiamos la `Key1` y la pegamos en la `Account key` de `Studio`\n",
    " * Por último en `Connection name` le ponemos un nombre a la conexión, en mi caso he puesto `stor_acc_connection`\n",
    "\n",
    "Por último le damos al botón de `Save` para guardar la conexión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subir los datasets al contenedor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos el contenedor y lo tenemos vinculado a Azure ML, vamos a subir los datasets que vamos a usar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solo vamos a ver cómo hacerlo mediante la CLI, ya que este post se centra en el uso de `Azure ML`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volvemos a `Azure`, al `Storage account`, seleccionamos `containers` y entramos en el contenedor que hemos creado. Ahora le damos al botón de `Upload` y seleccionamos los datasets que queremos subir.\n",
    "\n",
    "Subimos la carpeta `PetImages` del dataset `Cats-vs-Dogs` y la carpeta `en` del dataset `amazon_reviews_multi`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizar los datos del dataset `amazon rewiews multi`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos los datos podemos utilizar herramientas de `Azure ML` para visualizarlos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volvemos a `Studio` y seleccionamos `Data` de la zona `Assets`. Le damos a `Create` y hacemos lo siguiente\n",
    "\n",
    " * En `Name` ponemos in nombre para el dataset, en mi caso he puesto `amazon-reviews-mult-english-train`\n",
    " * En `Description` ponemos una descripción, en mi caso he puesto `Dataset with reviews of Amazon products with starts in english. Train subset`.\n",
    " * En `Type` elegimos `File (uri_file)`\n",
    "\n",
    "Le damos al botón de `Next`. Pasaremos a elegir la fuente de datos, elegimos `From Azure Storage` y volvemos a darle al botón de `Next`\n",
    "\n",
    "A continuación tenemos que elegir de qué `blob storage` queremos coger los datos. Elegimos el que hemos creado antes, en mi caso `stor_acc_connection`. Le damos al botón de `Next`\n",
    "\n",
    "Seleccionamos el archivo `train.json` de la carpeta `en` y le damos al botón de `Next`\n",
    "\n",
    "Cuando se haya revisado todo, por último le damos al botón de `Create`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se nos ha creado el `Dataset` de `Azure ML`. Como la interfaz nos ha dejado dentro del `Dataset` le damos a la pestaña `Explore` para poder explorarlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si seleccionamos la pestaña `Consume` nos aparece un código para poder cargarlo en un `DataFrame` de `Pandas`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizar los datos del dataset `Pets-vs-Dogs`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volvemos a meternos en la sección de `Data` de la zona de `Assets` y le damos a `Create`\n",
    "\n",
    " * En `Name` ponemos in nombre para el dataset, en mi caso he puesto `cats-vs-dogs`\n",
    " * En `Description` ponemos una descripción, en mi caso he puesto `Dataset with images of cats and dogs`\n",
    " * En `Type` elegimos `Folder (uri_folder)`\n",
    "\n",
    "Le damos a `Next`. Pasaremos a elegir la fuente de datos, elegimos `From Azure Storage` y volvemos a darle al botón de `Next`\n",
    "\n",
    "A continuación tenemos que elegir de qué `blob storage` queremos coger los datos. Elegimos el que hemos creado antes, en mi caso `stor_acc_connection`. Le damos al botón de `Next`\n",
    "\n",
    "Seleccionamos la carpeta `PetImages` y le damos al botón de `Next`\n",
    "\n",
    "Cuando se haya revisado todo, por último le damos al botón de `Create`\n",
    "\n",
    "Se nos ha creado el `Dataset` de `Azure ML`. Como la interfaz nos ha dejado dentro del `Dataset` le damos a la pestaña `Explore` para poder explorarlo\n",
    "\n",
    "Si seleccionamos la pestaña `Consume` nos aparece un código para poder cargarlo en un `DataFrame` de `Pandas`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azure_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
