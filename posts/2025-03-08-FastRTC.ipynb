{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FastRTC: La Biblioteca de Comunicaci√≥n en Tiempo Real para Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En los √∫ltimos meses, hemos visto un gran avance en modelos de voz en tiempo real, con empresas enteras fundadas alrededor de modelos tanto de c√≥digo abierto como cerrado. Algunos hitos importantes incluyen:\n",
        "\n",
        "* ``OpenAI`` y ``Google`` lanzaron sus APIs multimodales en vivo para ChatGPT y Gemini. ¬°OpenAI incluso lanz√≥ un n√∫mero de tel√©fono ``1-800-ChatGPT``!\n",
        "* ``Kyutai`` lanz√≥ [Moshi](https://huggingface.co/kyutai), un LLM de audio a audio completamente de c√≥digo abierto.\n",
        "* ``Alibaba`` lanz√≥ [Qwen2-Audio](https://huggingface.co/Qwen/Qwen2-Audio-7B-Instruct), un LLM de c√≥digo abierto que entiende audio de forma nativa.\n",
        "* ``Fixie.ai`` lanz√≥ [Ultravox](https://huggingface.co/fixie-ai/ultravox-v0_5-llama-3_3-70b), otro LLM de c√≥digo abierto que tambi√©n entiende audio de forma nativa.\n",
        "* ``ElevenLabs`` recaud√≥ 180 millones de d√≥lares en su Serie C."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A pesar de esta explosi√≥n en modelos y financiaci√≥n, sigue siendo dif√≠cil construir aplicaciones de IA en tiempo real que transmitan audio y video, especialmente en Python.\n",
        "\n",
        "* Los ingenieros de ML pueden no tener experiencia con las tecnolog√≠as necesarias para construir aplicaciones en tiempo real, como ``WebRTC``.\n",
        "* Incluso herramientas de asistencia de c√≥digo como ``Cursor`` y ``Copilot`` tienen dificultades para escribir c√≥digo Python que soporte aplicaciones de audio/video en tiempo real.\n",
        "\n",
        "Por eso es emocionante el anuncio de `FastRTC`, la biblioteca de comunicaci√≥n en tiempo real para Python. ¬°La biblioteca est√° dise√±ada para facilitar la construcci√≥n de aplicaciones de IA de audio y video en tiempo real completamente en Python!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Caracter√≠sticas principales de FastRTC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* üó£Ô∏è Detecci√≥n de voz autom√°tica y toma de turnos incorporada, para que solo tengas que preocuparte por la l√≥gica de respuesta al usuario.\n",
        "* üíª UI autom√°tica - UI de Gradio habilitada para WebRTC incorporada para pruebas (¬°o despliegue a producci√≥n!).\n",
        "* üìû Llamada por tel√©fono - Usa ``fastphone()`` para obtener un n√∫mero de tel√©fono **gratuito** para llamar a tu stream de audio (se requiere un token HF).\n",
        "* ‚ö°Ô∏è Soporte para ``WebRTC`` y ``Websocket``.\n",
        "* üí™ Personalizable - Puedes montar el stream en cualquier aplicaci√≥n ``FastAPI`` para servir una UI personalizada y desplegar m√°s all√° de ``Gradio``.\n",
        "* üß∞ Muchas utilidades para ``text-to-speech``, ``speech-to-text``, ``detecci√≥n de parada`` para ayudarte a comenzar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Instalaci√≥n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para poder usar `FastRTC`, primero necesitas instalar la biblioteca:\n",
        "\n",
        "``` bash\n",
        "pip install fastrtc\n",
        "```\n",
        "\n",
        "Pero si queremos instalar las funcionalidades de detecci√≥n de pausa, speech-to-text y text-to-speech, necesitamos instalar algunas dependencias adicionales:\n",
        "\n",
        "``` bash\n",
        "pip install \"fastrtc[vad, stt, tts]\"\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Primeros pasos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Empezaremos construyendo el `hola mundo` del audio en tiempo real: hacer eco de lo que dice el usuario. En `FastRTC`, esto es tan simple como:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7872\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        }
      ],
      "source": [
        "from fastrtc import Stream, ReplyOnPause\n",
        "import numpy as np\n",
        "\n",
        "def echo(audio: tuple[int, np.ndarray]) -> tuple[int, np.ndarray]:\n",
        "    yield audio\n",
        "\n",
        "stream = Stream(ReplyOnPause(echo), modality=\"audio\", mode=\"send-receive\")\n",
        "stream.ui.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cuando vamos al enlace que nos sugiere Gradio, primero tenemos que dar permisos al navegador para acceder al micr√≥fono. A continuaci√≥n nos aparecer√° esto\n",
        "\n",
        "![fastrct - hello world - init](https://images.maximofn.com/fastRTC%20-%20hello%20world%20-%20init.webp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Si pinchamos en la pesta√±a de la derecha de la palabra `Record` podemos seleccionar el micr√≥fono que queremos usar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A continuaci√≥n si pulsamos en el bot√≥n de `Record`, todo lo que digamos, la aplicaci√≥n lo repetir√°. Es decir captura el audio, detecta cuando hemos dejado de hablar y lo repite."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos a desglosarlo:\n",
        "\n",
        "* `ReplyOnPause` manejar√° la detecci√≥n de voz y la toma de turnos por ti. Solo tienes que preocuparte por la l√≥gica para responder al usuario. Hay que pasarle la funci√≥n que se encargar√° de gestionar el audio de entrada. En nuestro caso es la funci√≥n `echo`, que captura el audio de entrada y lo devuelve en stream mediante el uso de `yield`, que mucha gente no conoce, pero es un generador, es decir, es un m√©todo de python para crear iteradores. Si quieres saber m√°s sobre `yield` puedes leer mi post de [Python](https://www.maximofn.com/python#6.5.-Generadores). Cualquier generador que devuelva una tupla de audio (representada como `(sample_rate, audio_data)`) funcionar√°.\n",
        "* La clase `Stream` construir√° una UI de Gradio para que puedas probar r√°pidamente tu stream. Una vez que hayas terminado de prototipar, puedes desplegar tu Stream como una aplicaci√≥n FastAPI lista para producci√≥n en una sola l√≠nea de c√≥digo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Aqu√≠ podemos ver un ejemplo de los creadores de `FastRTC`\n",
        "\n",
        "<video src=\"https://github.com/user-attachments/assets/fcf2d30e-3e98-47c9-8dc3-23340784c441\" controls></video>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Subiendo de nivel: Chat de voz con LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El siguiente nivel es usar un LLM para responder al usuario. `FastRTC` viene con capacidades de ``speech-to-text`` y ``text-to-speech`` incorporadas, por lo que trabajar con LLMs es realmente f√°cil. Vamos a cambiar nuestra funci√≥n `echo` en consecuencia:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded as API: https://maximofn-smollm2-localmodel.hf.space ‚úî\n",
            "* Running on local URL:  http://127.0.0.1:7871\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        }
      ],
      "source": [
        "from fastrtc import ReplyOnPause, Stream, get_stt_model, get_tts_model\n",
        "from gradio_client import Client\n",
        "\n",
        "client = Client(\"Maximofn/SmolLM2_localModel\")\n",
        "stt_model = get_stt_model()\n",
        "tts_model = get_tts_model()\n",
        "\n",
        "def echo(audio):\n",
        "    prompt = stt_model.stt(audio)\n",
        "    response = client.predict(\n",
        "            message=prompt,\n",
        "            system_message=\"You are a friendly Chatbot. Always reply in the language in which the user is writing to you.\",\n",
        "            max_tokens=512,\n",
        "            temperature=0.7,\n",
        "            top_p=0.95,\n",
        "            api_name=\"/chat\"\n",
        "    )\n",
        "    prompt = response\n",
        "    for audio_chunk in tts_model.stream_tts_sync(prompt):\n",
        "        yield audio_chunk\n",
        "\n",
        "stream = Stream(ReplyOnPause(echo), modality=\"audio\", mode=\"send-receive\")\n",
        "stream.ui.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como modelo de ``speech-to-text`` usa ``Moonshine`` que supuestamente solo soporta ingl√©s, pero lo he probado en espa√±ol y me entiende bien."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como modelo de lenguaje vamos a usar el modelo que desplegu√© en un backend en Hugging Face y que escrib√≠ en el post [Desplegar backend con LLM en HuggingFace](https://www.maximofn.com/deploy-backend-with-llm-in-huggingface). Utiliza el LLM `HuggingFaceTB/SmolLM2-1.7B-Instruct` que es un modelo peque√±o, ya que est√° corriendo en un backend con CPU, pero que funciona bastante bien."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como modelo de ``text-to-speech`` usa ``Kokoro`` que s√≠ tiene opciones de hablar en otros idiomas, pero que de momento en la librer√≠a de `FastRTC` de momento no est√° implementado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Si nos interesa mucho usar modelos de `speech-to-speech` y `text-to-speech` en otros idiomas, podr√≠amos implementarlos nosotros mismos, porque el mayor potencial de `FastRTC` est√° en la capa de comunicaci√≥n en tiempo real, pero no me voy a meter en eso ahora."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora s√≠ probamos el c√≥digo que acabamos de escribir podemos tener un chatbot, por voz en tiempo real."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Llamada por tel√©fono\n",
        "\n",
        "Si en lugar de `stream.ui.launch()`, llamas a `stream.fastphone()`, obtendr√°s un n√∫mero de tel√©fono gratuito para llamar a tu stream. Ten en cuenta que se requiere un token de Hugging Face.\n",
        "\n",
        "Generamos un script, porque en un Jupyter Notebook no siempre funciona"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile fastrtc_phone_demo.py\n",
        "\n",
        "from fastrtc import ReplyOnPause, Stream, get_stt_model, get_tts_model\n",
        "import gradio\n",
        "from gradio_client import Client\n",
        "import os\n",
        "from gradio.networking import setup_tunnel as original_setup_tunnel\n",
        "import socket\n",
        "\n",
        "# Monkey patch setup_tunnel para que acepte el par√°metro adicional\n",
        "def patched_setup_tunnel(host, port, share_token, share_server_address, share_server_tls_certificate=None):\n",
        "    return original_setup_tunnel(host, port, share_token, share_server_address, share_server_tls_certificate)\n",
        "\n",
        "# Replace the original function with our patched version\n",
        "gradio.networking.setup_tunnel = patched_setup_tunnel\n",
        "\n",
        "# Get the token from the environment variable\n",
        "HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN = os.getenv(\"HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN\")\n",
        "\n",
        "# Initialize the LLM client\n",
        "llm_client = Client(\"Maximofn/SmolLM2_localModel\")\n",
        "\n",
        "# Initialize the STT and TTS models\n",
        "stt_model = get_stt_model()\n",
        "tts_model = get_tts_model()\n",
        "\n",
        "# Define the echo function\n",
        "def echo(audio):\n",
        "    # Convert the audio to text\n",
        "    prompt = stt_model.stt(audio)\n",
        "\n",
        "    # Generate the response\n",
        "    response = llm_client.predict(\n",
        "            message=prompt,\n",
        "            system_message=\"You are a friendly Chatbot. Always reply in the language in which the user is writing to you.\",\n",
        "            max_tokens=512,\n",
        "            temperature=0.7,\n",
        "            top_p=0.95,\n",
        "            api_name=\"/chat\"\n",
        "    )\n",
        "    \n",
        "    # Convert the response to audio\n",
        "    prompt = response\n",
        "\n",
        "    # Stream the audio\n",
        "    for audio_chunk in tts_model.stream_tts_sync(prompt):\n",
        "        yield audio_chunk\n",
        "\n",
        "def find_free_port(start_port=8000, max_port=9000):\n",
        "    \"\"\"Find the first free port starting from start_port.\"\"\"\n",
        "    print(f\"Searching for a free port starting from {start_port}...\")\n",
        "    for port in range(start_port, max_port):\n",
        "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:\n",
        "            result = sock.connect_ex(('127.0.0.1', port))\n",
        "            if result != 0:  # If result != 0, the port is free\n",
        "                print(f\"Free port found: {port}\")\n",
        "                return port\n",
        "    raise RuntimeError(f\"No free port found between {start_port} and {max_port}\")\n",
        "    \n",
        "free_port = find_free_port()    # Search for a free port\n",
        "\n",
        "stream = Stream(ReplyOnPause(echo), modality=\"audio\", mode=\"send-receive\")\n",
        "stream.fastphone(token=HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN, port=free_port)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Explicamos el c√≥digo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La parte\n",
        "\n",
        "``` pyhon\n",
        "# Monkey patch setup_tunnel para que acepte el par√°metro adicional\n",
        "def patched_setup_tunnel(host, port, share_token, share_server_address, share_server_tls_certificate=None):\n",
        "    return original_setup_tunnel(host, port, share_token, share_server_address, share_server_tls_certificate)\n",
        "\n",
        "# Replace the original function with our patched version\n",
        "gradio.networking.setup_tunnel = patched_setup_tunnel\n",
        "```\n",
        "\n",
        "Es necesario porque `FastRTC` est√° escrito para una versi√≥n antigua de `gradio` que no soporta el par√°metro `share_server_address` en el m√©todo `setup_tunnel`. As√≠ que lo parcheamos para que acepte el par√°metro adicional."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como es necesario un token de Hugging Face, lo obtenemos de la variable de entorno `HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN`.\n",
        "\n",
        "``` python\n",
        "# Get the token from the environment variable\n",
        "HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN = os.getenv(\"HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN\")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A continuaci√≥n se crean los modelos de lenguaje, de `speech-to-text` y de `text-to-speech`, y creamos la funci√≥n `echo` que se encargar√° de gestionar el audio de entrada y salida.\n",
        "\n",
        "``` python\n",
        "# Initialize the LLM client\n",
        "llm_client = Client(\"Maximofn/SmolLM2_localModel\")\n",
        "\n",
        "# Initialize the STT and TTS models\n",
        "stt_model = get_stt_model()\n",
        "tts_model = get_tts_model()\n",
        "\n",
        "# Define the echo function\n",
        "def echo(audio):\n",
        "    # Convert the audio to text\n",
        "    prompt = stt_model.stt(audio)\n",
        "\n",
        "    # Generate the response\n",
        "    response = llm_client.predict(\n",
        "            message=prompt,\n",
        "            system_message=\"You are a friendly Chatbot. Always reply in the language in which the user is writing to you.\",\n",
        "            max_tokens=512,\n",
        "            temperature=0.7,\n",
        "            top_p=0.95,\n",
        "            api_name=\"/chat\"\n",
        "    )\n",
        "    \n",
        "    # Convert the response to audio\n",
        "    prompt = response\n",
        "\n",
        "    # Stream the audio\n",
        "    for audio_chunk in tts_model.stream_tts_sync(prompt):\n",
        "        yield audio_chunk\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como antes hemos usado el puerto `8000`, por si os dice que est√° ocupado, creamos una funci√≥n para encontrar un puerto libre y encontramos uno\n",
        "\n",
        "``` python\n",
        "def find_free_port(start_port=8000, max_port=9000):\n",
        "    \"\"\"Find the first free port starting from start_port.\"\"\"\n",
        "    print(f\"Searching for a free port starting from {start_port}...\")\n",
        "    for port in range(start_port, max_port):\n",
        "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:\n",
        "            result = sock.connect_ex(('127.0.0.1', port))\n",
        "            if result != 0:  # If result != 0, the port is free\n",
        "                print(f\"Free port found: {port}\")\n",
        "                return port\n",
        "    raise RuntimeError(f\"No free port found between {start_port} and {max_port}\")\n",
        "    \n",
        "free_port = find_free_port()    # Search for a free port\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se crea el stream y ahora se usa `stream.fastphone()` para obtener un n√∫mero de tel√©fono gratuito para llamar a tu stream, en vez de `stream.ui.launch()` que usamos antes para crear la interfaz gr√°fica.\n",
        "\n",
        "``` python\n",
        "stream = Stream(ReplyOnPause(echo), modality=\"audio\", mode=\"send-receive\")\n",
        "stream.fastphone(token=HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN, port=free_port)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Si lo ejecutamos, veremos algo como esto:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded as API: https://maximofn-smollm2-localmodel.hf.space ‚úî\n",
            "\u001b[32mINFO\u001b[0m:\t  Warming up STT model.\n",
            "\u001b[32mINFO\u001b[0m:\t  STT model warmed up.\n",
            "\u001b[32mINFO\u001b[0m:\t  Warming up VAD model.\n",
            "\u001b[32mINFO\u001b[0m:\t  VAD model warmed up.\n",
            "Searching for a free port starting from 8000...\n",
            "Free port found: 8004\n",
            "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m24029\u001b[0m]\n",
            "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
            "\u001b[32mINFO\u001b[0m:\t  Visit \u001b[36mhttps://fastrtc.org/userguide/api/\u001b[0m for WebRTC or Websocket API docs.\n",
            "\u001b[32mINFO\u001b[0m:     Application startup complete.\n",
            "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://127.0.0.1:8004\u001b[0m (Press CTRL+C to quit)\n",
            "\u001b[32mINFO\u001b[0m:\t  Your FastPhone is now live! Call \u001b[36m+1 877-713-4471\u001b[0m and use code \u001b[36m994514\u001b[0m to connect to your stream.\n",
            "\u001b[32mINFO\u001b[0m:\t  You have \u001b[36m30:00\u001b[0m minutes remaining in your quota (Resetting on \u001b[36m2025-04-07\u001b[0m)\n",
            "\u001b[32mINFO\u001b[0m:\t  Visit \u001b[36mhttps://fastrtc.org/userguide/audio/#telephone-integration\u001b[0m for information on making your handler compatible with phone usage.\n"
          ]
        }
      ],
      "source": [
        "!python fastrtc_phone_demo.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vemos que aparece\n",
        "\n",
        "``` bash\n",
        "INFO:\t  Your FastPhone is now live! Call +1 877-713-4471 and use code 994514 to connect to your stream.\n",
        "INFO:\t  You have 30:00 minutes remaining in your quota (Resetting on 2025-04-07)\n",
        "```\n",
        "\n",
        "Es decir, si llamamos al n√∫mero `+1 877-713-4471` y usamos el c√≥digo `994514` nos conectar√° a nuestro stream."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Si nos vamos a [Telephone Integration](https://fastrtc.org/userguide/audio/#telephone-integration) de la documentaci√≥n de `FastRTC` veremos que usa [twilio](https://www.twilio.com/) para hacer la llamada. Tiene opci√≥n para configurar un n√∫mero local desde estados unidos, Dublin, Frankfurt, Tokio, Singapur, Sidney y Sao Paulo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "He probado a hacer la llamada desde Espa√±a (que me va a costar bastante) y funciona, pero es lento. He llamado, he metido el c√≥digo y he estado esperando a que conectara con el agente, pero como estaba tardando mucho, he colgado."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "fastrtc",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "maximofn": {
      "date": "2025-03-08",
      "description_en": "Learn how to use FastRTC to create real-time AI voice applications in Python. Follow our step-by-step guide to build a voice chatbot with LLMs, from basic installation to integrating it with a phone call.",
      "description_es": "Aprende a usar FastRTC para crear aplicaciones de IA con voz en tiempo real en Python. Sigue nuestra gu√≠a paso a paso para construir un chatbot de voz con LLMs, desde la instalaci√≥n b√°sica hasta integrarlo con una llamada telef√≥nica.",
      "description_pt": "Aprenda a usar o FastRTC para criar aplicativos de IA por voz em tempo real com Python. Siga nosso guia passo a passo para construir um chatbot de voz com LLMs, desde a instala√ß√£o b√°sica at√© a integra√ß√£o com uma chamada telef√¥nica.",
      "end_url": "fastrtc",
      "image": "https://images.maximofn.com/fastrtc-thumbnail.webp",
      "image_hover_path": "https://images.maximofn.com/fastrtc-thumbnail.webp",
      "keywords_en": "fastrtc, real-time, ai, application, phone, python, voice chat, llm",
      "keywords_es": "fastrtc, real-time, ai, aplicaci√≥n, tel√©fono, python, chat de voz, llm",
      "keywords_pt": "fastrtc, real-time, ai, aplica√ß√£o, telefone, python, chat de voz, llm",
      "title_en": "Complete Guide to FastRTC: Create a Real-Time AI Voice Chat with Python",
      "title_es": "Gu√≠a Completa de FastRTC: Crea un Chat de Voz con IA en Tiempo Real con Python",
      "title_pt": "Guia Completo de FastRTC: Crie um Chat de Voz com IA em Tempo Real com Python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
