{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LangGraph` es un marco de orquestación de bajo nivel para construir agentes controlables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mientras que `LangChain` proporciona integraciones y componentes para agilizar el desarrollo de aplicaciones LLM, la biblioteca `LangGraph` permite la orquestación de agentes, ofreciendo arquitecturas personalizables, memoria a largo plazo y `human in the loop` para manejar de manera confiable tareas complejas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cómo funciona `LangGraph`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LangGraph` se basa en tres componentes:\n",
    "\n",
    " * **Nodos**: Representan las unidades de procesamiento de la aplicación, como llamar a un LLM, o a una herramienta. Son funciones de Python que se ejecutan cuando se llama al nodo.\n",
    "   * Toman el estado como entrada\n",
    "   * Realizan alguna operación\n",
    "   * Devuelven el estado actualizado\n",
    " * **Edges**: Representan las transiciones entre los nodos. Definen la lógica de cómo se va a ejecutar el grafo, es decir, qué nodo se va a ejecutar después de otro. Pueden ser:\n",
    "   * Directos: Van de un nodo a otro\n",
    "   * Condicionales: Dependen de una condición\n",
    " * **State**: Representa el estado de la aplicación, es decir, que contiene toda la información necesaria para la aplicación. Se mantiene durante la ejecución de la aplicación. Es definido por el usuario, así que hay que pensar muy bien qué se va a guardar en él."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![LangGraph concept](https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/LangGraph_concept.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos los grafos de `LangGraph` comienzan desde un nodo `START` y terminan en un nodo `END`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalación de LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para instalar `LangGraph` se puede usar pip:\n",
    "\n",
    "```bash\n",
    "pip install -U langgraph\n",
    "```\n",
    "\n",
    "o instalar desde conda:\n",
    "\n",
    "```bash\n",
    "conda install langgraph\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalación de módulo de Hugging Face y Anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a usar un modelo de lenguaje de `Hugging Face`, por lo que necesitamos instalar su paquete de langgraph.\n",
    "\n",
    "```bash\n",
    "pip install langchain-huggingface\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para una parte vamos a usar `Sonnet 3.7`, luego explicaremos por qué. Así que tambien instalamos el paquere de `Anthropic`.\n",
    "\n",
    "```bash\n",
    "pip install langchain_anthropic\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API KEY de Hugging Face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a usar `Qwen/Qwen2.5-72B-Instruct` a través de `Hugging Face Inference Endpoints`, por lo que necesitamos una API KEY."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder usar el `Inference Endpoints` de HuggingFace, lo primero que necesitas es tener una cuenta en HuggingFace. Una vez la tengas, hay que ir a [Access tokens](https://huggingface.co/settings/keys) en la configuración de tu perfil y generar un nuevo token.\n",
    "\n",
    "Hay que ponerle un nombre. En mi caso, le voy a poner `langgraph` y habilitar el permiso `Make calls to inference providers`. Nos creará un token que tendremos que copiar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para gestionar el token, vamos a crear un archivo en la misma ruta en la que estemos trabajando llamado`.env` y vamos a poner el token que hemos copiado en el archivo de la siguiente manera:\n",
    "\n",
    "``` bash\n",
    "HUGGINGFACE_LANGGRAPH=\"hf_....\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, para poder obtener el token, necesitamos tener instalado `dotenv`, que lo instalamos mediante\n",
    "\n",
    "```bash\n",
    "pip install python-dotenv\n",
    "```\n",
    "\n",
    "Y ejecutamos lo siguiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "HUGGINGFACE_TOKEN = os.getenv(\"HUGGINGFACE_LANGGRAPH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos un token, creamos un cliente. Para ello, necesitamos tener instalada la librería `huggingface_hub`. La instalamos mediante conda o pip.\n",
    "\n",
    "``` bash\n",
    "pip install --upgrade huggingface_hub\n",
    "```\n",
    "\n",
    "o\n",
    "\n",
    "``` bash\n",
    "conda install -c conda-forge huggingface_hub\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tenemos que elegir qué modelo vamos a usar. Puedes ver los modelos disponibles en la página de [Supported models](https://huggingface.co/docs/api-inference/supported-models) de la documentación de `Inference Endpoints` de Hugging Face.\n",
    "\n",
    "Vamos a usar `Qwen2.5-72B-Instruct` que es un modelo muy bueno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"Qwen/Qwen2.5-72B-Instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos crear el cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<InferenceClient(model='Qwen/Qwen2.5-72B-Instruct', timeout=None)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "client = InferenceClient(api_key=HUGGINGFACE_TOKEN, model=MODEL)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos una prueba a ver si funciona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Hola! Estoy bien, gracias por preguntar. ¿Cómo estás tú? ¿En qué puedo ayudarte hoy?\n"
     ]
    }
   ],
   "source": [
    "message = [\n",
    "\t{ \"role\": \"user\", \"content\": \"Hola, qué tal?\" }\n",
    "]\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "\tmessages=message, \n",
    "\ttemperature=0.5,\n",
    "\tmax_tokens=1024,\n",
    "\ttop_p=0.7,\n",
    "\tstream=False\n",
    ")\n",
    "\n",
    "response = stream.choices[0].message.content\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API KEY de Anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear un chatbot básico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear un chatbot simple usando `LangGraph`. Este chatbot responderá directamente a los mensajes del usuario. Aunque es simple, nos servirá para ver los conceptos básicos de la construcción de grafos con `LangGraph`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como su nomre indica, `LangGraph` es una biblioteca para manejar grafos. así que comenzamos creando un grafo [StateGraph](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.state.StateGraph).\n",
    "\n",
    "Un `StateGraph` define la estructura de nuestro chatbot como una `máquina de estados`. Agregaremos `nodos` para representar el `llm` y `funciones` a nuestro chatbot que podrá llamar y `edges` para especificar cómo el bot debe hacer la transición entre estas funciones o `nodos`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así que comenzamos creando un `StateGraph` que necesita una clase `State` para manejar el estado del grafo. Como ahora vamos a crear una chatbot sencillo, solo necesitamos manejar una lista de mensajes en el estado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función [add_messages](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.message.add_messages) une dos listas de mensajes.\n",
    "\n",
    "Llegarán nuevas listas de mensajes, por lo que se unirán a la lista de mensajes ya existente. Cada lista de mensajes contiene un `ID`, por lo que se agregan con este `ID`. Esto asegura que los mensajes solo se añaden, no se reemplazan, a no ser que un nuevo mensaje tenga el mismo `ID` que uno ya existente.\n",
    "\n",
    "`add_messages` es una [reducer function](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers), es una función que se encarga de actualizar el estado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El grafo `graph_builder` que hemos creado, recibe un estado `State` y devuelve un nuevo estado `State`. Además, actualiza la lista de mensajes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > **Concepto**\n",
    " >\n",
    " > Al definir un grafo, el primer paso es definir su `State`. El `State` incluye el esquema del grafo y las `reducer functions` que manejan actualizaciones del estado. \n",
    " > \n",
    " > En nuestro ejemplo, `State` es de tipo `TypedDict` (diccionario tipado) con una llave: `messages`.\n",
    " > \n",
    " > `add_messages` es una `reducer function` que se utiliza para agregar nuevos mensajes a la lista en lugar de sobrescribirlos en la lista. Si una llave de un estado no tiene una `reducer function`, cada valor que llegue de esa clave sobrescribirán los valores anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a agregar al grafo el nodo `chatbot`. Los nodos representan unidades de trabajo. Por lo general, son funciones regulares de `Python`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadimos un nodo con el método `add_node` que recibe el nombre del nodo y la función que se ejecutará."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De modo que vamos a crear un LLM con HuggingFace, después crearemos un chat model con `LangChain` que hará referencia al LLM creado. Una vez tenemos definido un chat model, definimos la función que se ejecutará en el nodo de nuestro grafo. Esa función hará una llamada al chat model creado y devolverá el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x11dd48440>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from huggingface_hub import login\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"    # Disable LangSmith tracing\n",
    "\n",
    "# Create the LLM model\n",
    "login(token=HUGGINGFACE_TOKEN)  # Login to HuggingFace to use the model\n",
    "MODEL = \"Qwen/Qwen2.5-72B-Instruct\"\n",
    "model = HuggingFaceEndpoint(\n",
    "    repo_id=MODEL,\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=512,\n",
    "    do_sample=False,\n",
    "    repetition_penalty=1.03,\n",
    ")\n",
    "# Create the chat model\n",
    "llm = ChatHuggingFace(llm=model)\n",
    "\n",
    "# Define the chatbot function\n",
    "def chatbot_function(state: State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# The first argument is the unique node name\n",
    "# The second argument is the function or object that will be called whenever\n",
    "# the node is used.\n",
    "graph_builder.add_node(\"chatbot_node\", chatbot_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos usado [ChatHuggingFace](https://python.langchain.com/api_reference/huggingface/chat_models/langchain_huggingface.chat_models.huggingface.ChatHuggingFace.html#langchain_huggingface.chat_models.huggingface.ChatHuggingFace) que es un chat del tipo [BaseChatModel](https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.chat_models.BaseChatModel.html#langchain_core.language_models.chat_models.BaseChatModel) que es un tipo de chat base de `LangChain`. Una vez hemos creado el `BaseChatModel`, hemos creado la función `chatbot_function` que se ejecutará cuando se ejecute el nodo. Y por último, hemos creado el nodo `chatbot_node` y le hemos indicado que tiene que ejecutar la función `chatbot_function`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > **Aviso** \n",
    " >\n",
    " > La función de nodo `chatbot_function` toma el estado `State` como entrada y devuelve un diccionario que contiene una actualización de la lista `messages` para la key `mensajes`. Este es el patrón básico para todas las funciones del nodo `LangGraph`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La `reducer function` de nuestro grafo `add_messages` agregará los mensajes de respuesta del `llm` a cualquier mensaje que ya esté en el estado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, agregamos un nodo `entry`. Esto le dice a nuestro grafo dónde empezar su trabajo cada vez que lo ejecutamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x11dd48440>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import START\n",
    "\n",
    "graph_builder.add_edge(START, \"chatbot_node\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del mismo modo, añadimos un nodo `finish`. Esto indica al grafo `cada vez que se ejecuta este nodo, puede terminar el trabajo.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x11dd48440>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import END\n",
    "\n",
    "graph_builder.add_edge(\"chatbot_node\", END)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos importado `START` y `END` que podemos encontrarlos en [constants](https://langchain-ai.github.io/langgraph/reference/constants/) y el primer y último nodo de nuestro grafo.\n",
    "\n",
    "Normalmente son nodos virtuales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, queremos poder ejecutar nuestro grafo. Para hacerlo, usamos el método constructor de grafos `compile()`. Esto crea un `CompiledGraph` que podemos usar para ejecutar nuestra aplicación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos visualizar el grafo usando el método `get_graph` y uno de los métodos de \"dibujo\", como `draw_ascii` o `draw_mermaid_png`. El dibujo de cada uno de los métodos requiere dependencias adicionales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Error al visualizar el grafo: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Ahora podemos probar el chatbot!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > **Consejo**\n",
    " >\n",
    " > Puedes salir del bucle de chat en cualquier momento escribiendo `quit`, `exit` o `q`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mUser: \u001b[0mHello\n",
      "\u001b[33mAssistant: \u001b[0mHello! It's nice to meet you. How can I assist you today? Whether you have questions, need information, or just want to chat, I'm here to help!\n",
      "\u001b[32mUser: \u001b[0mHow are you doing?\n",
      "\u001b[33mAssistant: \u001b[0mI'm just a computer program, so I don't have feelings, but I'm here and ready to help you with any questions or tasks you have! How can I assist you today?\n",
      "\u001b[32mUser: \u001b[0mMe well, I'm making a post about LangGraph, what do you think?\n",
      "\u001b[33mAssistant: \u001b[0mLangGraph is an intriguing topic, especially if you're delving into the realm of graph-based models and their applications in natural language processing (NLP). LangGraph, as I understand, is a framework or tool that leverages graph theory to improve or provide a new perspective on NLP tasks such as text classification, information extraction, and semantic analysis. By representing textual information as graphs (nodes for entities and edges for relationships), it can offer a more nuanced understanding of the context and semantics in language data.\n",
      "\n",
      "If you're making a post about it, here are a few points you might consider:\n",
      "\n",
      "1. **Introduction to LangGraph**: Start with a brief explanation of what LangGraph is and its core principles. How does it model language or text differently compared to traditional NLP approaches? What unique advantages does it offer by using graph-based methods?\n",
      "\n",
      "2. **Applications of LangGraph**: Discuss some of the key applications where LangGraph has been or can be applied. This could include improving the accuracy of sentiment analysis, enhancing machine translation, or optimizing chatbot responses to be more contextually aware.\n",
      "\n",
      "3. **Technical Innovations**: Highlight any technical innovations or advancements that LangGraph brings to the table. This could be about new algorithms, more efficient data structures, or novel ways of training models on graph data.\n",
      "\n",
      "4. **Challenges and Limitations**: It's also important to address the challenges and limitations of using graph-based methods in NLP. Performance, scalability, and the current state of the technology can be discussed here.\n",
      "\n",
      "5. **Future Prospects**: Wrap up with a look into the future of LangGraph and graph-based NLP in general. What are the upcoming trends, potential areas of growth, and how might these tools start impacting broader technology landscapes?\n",
      "\n",
      "Each section can help frame your post in a way that's informative and engaging for your audience, whether they're technical experts or casual readers looking for an introduction to this intriguing area of NLP.\n",
      "\u001b[32mUser: \u001b[0mq\n",
      "\u001b[33mAssistant: \u001b[0mGoodbye!\n"
     ]
    }
   ],
   "source": [
    "# Colors for the terminal\n",
    "COLOR_GREEN = \"\\033[32m\"\n",
    "COLOR_YELLOW = \"\\033[33m\"\n",
    "COLOR_RESET = \"\\033[0m\"\n",
    "\n",
    "\n",
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        for value in event.values():\n",
    "            print(f\"{COLOR_GREEN}User: {COLOR_RESET}{user_input}\")\n",
    "            print(f\"{COLOR_YELLOW}Assistant: {COLOR_RESET}{value['messages'][-1].content}\")\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(f\"{COLOR_GREEN}User: {COLOR_RESET}{user_input}\")\n",
    "            print(f\"{COLOR_YELLOW}Assistant: {COLOR_RESET}Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        events =stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**!Felicidades!** Has construido tu primer chatbot usando `LangGraph`. Este bot puede participar en una conversación básica tomando la entrada del usuario y generando respuestas utilizando el `LLM` que hemos definido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, este bot se limita a lo que hay en sus datos de entrenamiento. Así que vamos a agregar una herramienta de búsqueda web para expandir el conocimiento del bot y hacerlo más capaz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mejorar el chatbot con herramientas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para manejar algunas consultas, nuestro chatbot no puede responder `desde su conocimiento`, así que vamos a integrar una herramienta de búsqueda web. Nuestro bot puede utilizar esta herramienta para encontrar información relevante y proporcionar mejores respuestas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requisitos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de comenzar, tenemos que instalar el buscador [Tavily](https://python.langchain.com/docs/integrations/tools/tavily_search/) que es un buscador web que nos permite buscar información en la web.\n",
    "\n",
    "```bash\n",
    "pip install -U tavily-python langchain_community\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después, tenemos que crear una [API KEY](https://app.tavily.com/home), la escribimos en nuestro archivo `.env` y la cargamos en una variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "HUGGINGFACE_TOKEN = os.getenv(\"HUGGINGFACE_LANGGRAPH\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_LANGGRAPH_API_KEY\")\n",
    "ANTRHOPIC_API_KEY = os.getenv(\"ANTHROPIC_LANGGRAPH_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, definimos la herramienta de búsqueda web mediante [TavilySearchResults](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.tavily_search.tool.TavilySearchResults.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "wrapper = TavilySearchAPIWrapper(tavily_api_key=TAVILY_API_KEY)\n",
    "tool = TavilySearchResults(api_wrapper=wrapper, max_results=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos la herramienta, vamos a hacer una búsqueda en internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://eu.api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://eu.api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'title': 'HIGHLIGHTS | Real Madrid 3-1 Manchester City | Champions League',\n",
       "  'url': 'https://www.youtube.com/watch?v=9zW_CKWb3oM',\n",
       "  'content': 'Real Madrid booked their place in the last 16 of the Champions League. The Whites followed up the impressive performance in the first leg by',\n",
       "  'score': 0.63939893},\n",
       " {'title': 'Real Madrid | History | UEFA Champions League',\n",
       "  'url': 'https://www.uefa.com/uefachampionsleague/history/clubs/50051--real-madrid/',\n",
       "  'content': '1955/56 P W D L Final 7 5 0 2\\nUEFA Champions League [...] 2010/11 P W D L Semi-finals 12 8 3 1\\n2009/10 P W D L Round of 16 8 4 2 2\\n2000s\\n2008/09 P W D L Round of 16 8 4 0 4\\n2007/08 P W D L Round of 16 8 3 2 3\\n2006/07 P W D L Round of 16 8 4 2 2\\n2005/06 P W D L Round of 16 8 3 2 3\\n2004/05 P W D L Round of 16 10 6 2 2\\n2003/04 P W D L Quarter-finals 10 6 3 1\\n2002/03 P W D L Semi-finals 16 7 5 4\\n2001/02 P W D L Final 17 12 3 2\\n2000/01 P W D L Semi-finals 16 9 2 5\\n1990s\\n1999/00 P W D L Final 17 10 3 4\\n1998/99 P W D L Quarter-finals 8 4 1 3 [...] 1969/70 P W D L Second round 4 2 0 2\\n1968/69 P W D L Second round 4 3 0 1\\n1967/68 P W D L Semi-finals 8 2 4 2\\n1966/67 P W D L Quarter-finals 4 1 0 3\\n1965/66 P W D L Final 9 5 2 2\\n1964/65 P W D L Quarter-finals 6 4 1 1\\n1963/64 P W D L Final 9 7 0 2\\n1962/63 P W D L Preliminary round 2 0 1 1\\n1961/62 P W D L Final 10 8 0 2\\n1960/61 P W D L First round 2 0 1 1\\n1950s\\n1959/60 P W D L Final 7 6 0 1\\n1958/59 P W D L Final 8 5 2 1\\n1957/58 P W D L Final 7 5 1 1\\n1956/57 P W D L Final 8 6 1 1',\n",
       "  'score': 0.6030211}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://eu.api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://eu.api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://eu.api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://eu.api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://eu.api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://eu.api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://eu.api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://eu.api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://eu.api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://eu.api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://eu.api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://eu.api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://eu.api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://eu.api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://eu.api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://eu.api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://eu.api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://eu.api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://eu.api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://eu.api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://eu.api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://eu.api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://eu.api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://eu.api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://eu.api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://eu.api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://eu.api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://eu.api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://eu.api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://eu.api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://eu.api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://eu.api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://eu.api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://eu.api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://eu.api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://eu.api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://eu.api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://eu.api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://eu.api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://eu.api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://eu.api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://eu.api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    }
   ],
   "source": [
    "tool.invoke(\"What was the result of Real Madrid's at last match in the Champions League?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados son resúmenes de páginas que nuestro chatbot puede usar para responder preguntas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una lista de herramientas, porque nuestro grafo necesita definir las herramientas mediante una lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_list = [tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzaremos a definir nuestro gráfico. Lo siguiente es todo lo mismo que antes, excepto que hemos añadido `bind_tools` en nuestro `LLM`. Esto le permite al `LLM` saber el formato `JSON` correcto para usar si desea usar el motor de búsqueda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos el grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación el `LLM` con las `bind_tools` y lo añadimos al grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10bfaaf90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from huggingface_hub import login\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"    # Disable LangSmith tracing\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "# Create the LLM\n",
    "# login(token=HUGGINGFACE_TOKEN)  # Login to HuggingFace to use the model\n",
    "# MODEL = \"Qwen/Qwen2.5-72B-Instruct\"\n",
    "# model = HuggingFaceEndpoint(\n",
    "#     repo_id=MODEL,\n",
    "#     task=\"text-generation\",\n",
    "#     max_new_tokens=512,\n",
    "#     do_sample=False,\n",
    "#     repetition_penalty=1.03,\n",
    "# )\n",
    "# # Create the chat model\n",
    "# llm = ChatHuggingFace(llm=model)\n",
    "llm = ChatAnthropic(model=\"claude-3-7-sonnet-20250219\", api_key=ANTRHOPIC_API_KEY)\n",
    "\n",
    "# Modification: tell the LLM which tools it can call\n",
    "llm_with_tools = llm.bind_tools(tools_list)\n",
    "\n",
    "# Define the chatbot function\n",
    "def chatbot_function(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "# Add the chatbot node\n",
    "graph_builder.add_node(\"chatbot_node\", chatbot_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necesitamos crear una función para ejecutar las `tools_list` si se llaman. Agregamos las `tools_list` a un nuevo nodo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a implementar la clase `BasicToolNode`, que comprueba el mensaje más reciente en el estado y llama a las `tools_list` si el mensaje contiene `tool_calls`.\n",
    "\n",
    "Se basa en el soporte de `tool_calling` de los `LLM`s , que está disponible en `Anthropic`, `HuggingFace`, `Google Gemini` y varios otros proveedores de `LLM`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Más tarde reemplazaremos esto con el método [ToolNode](https://langchain-ai.github.io/langgraph/reference/prebuilt/#toolnode) de `LangGraph` para acelerar las cosas, pero primero lo construiremos nosotros mismos para entender cómo funciona."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una de las cosas que usa `LangGraph` para entender "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10bfaaf90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "class BasicToolNode:\n",
    "    \"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\n",
    "\n",
    "    def __init__(self, tools: list) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the tools\n",
    "\n",
    "        Args:\n",
    "            tools (list): The tools to use\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        # Initialize the tools\n",
    "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "    def __call__(self, inputs: dict):\n",
    "        \"\"\"\n",
    "        Call the node\n",
    "\n",
    "        Args:\n",
    "            inputs (dict): The inputs to the node\n",
    "\n",
    "        Returns:\n",
    "            dict: The outputs of the node\n",
    "        \"\"\"\n",
    "        # Get the last message\n",
    "        if messages := inputs.get(\"messages\", []):\n",
    "            message = messages[-1]\n",
    "        else:\n",
    "            raise ValueError(\"No message found in input\")\n",
    "        \n",
    "        # Execute the tools\n",
    "        outputs = []\n",
    "        for tool_call in message.tool_calls:\n",
    "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
    "                tool_call[\"args\"]\n",
    "            )\n",
    "            outputs.append(\n",
    "                ToolMessage(\n",
    "                    content=json.dumps(tool_result),\n",
    "                    name=tool_call[\"name\"],\n",
    "                    tool_call_id=tool_call[\"id\"],\n",
    "                )\n",
    "            )\n",
    "        return {\"messages\": outputs}\n",
    "\n",
    "\n",
    "basic_tool_node = BasicToolNode(tools=tools_list)\n",
    "graph_builder.add_node(\"tools_node\", basic_tool_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos usado [ToolMessage](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.tool.ToolMessage.html) que pasa el resultado de ejecutar una `tool` de nuevo al `LLM`.\n",
    "\n",
    "`ToolMessage` contiene el resultado de una invocación de una `tool`.\n",
    "\n",
    "Es decir, en cuanto tenemos el resultado de usar una `Tool` se lo pasamos al LLM para que lo procese"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el nodo de `basic_tool_node` (que es un objeto de la clase `BasicToolNode` que hemos creado) agregado al grafo, podemos definir los `conditional_edges`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El `enrutador` enruta el flujo de control de un nodo al siguiente. Los `conditional_edges` por lo general, contienen declaraciones `if` para enrutar a diferentes nodos dependiendo del estado actual del grafo.\n",
    "\n",
    "Estas funciones reciben el grafo actual `state` y devuelven una cadena o lista de cadenas que indican qué nodo o nodos llamar a continuación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a definir una función de enrutadora llamada `route_tools_function`, que comprueba si hay `tool_calls` en la salida del chatbot.\n",
    "\n",
    "Añadimos esta función al gráfico llamando `add_conditional_edges`, que le dice al grafo que cada vez que el nodo del `basic_tool_node` se ejecuta, se llama a la función para verificar a dónde ir a continuación.\n",
    "\n",
    "La condición se dirigirá a `tools_node` si las llamadas de herramientas están presentes y `END` si no.\n",
    "\n",
    "Más tarde, reemplazaremos esto con el método preconstruido `tools_condition` para ser más rápidos, pero ahora lo implementamos nosotros mismos primero ver cómo funciona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10bfaaf90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def route_tools_function(\n",
    "    state: State,\n",
    "):\n",
    "    \"\"\"\n",
    "    Use in the conditional_edge to route to the ToolNode if the last message\n",
    "    has tool calls. Otherwise, route to the end.\n",
    "    \"\"\"\n",
    "    # Get las message\n",
    "    if isinstance(state, list):\n",
    "        ai_message = state[-1]\n",
    "    elif messages := state.get(\"messages\", []):\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "    \n",
    "    # Router in function of last message\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        return \"tools_node\"\n",
    "    return END\n",
    "\n",
    "\n",
    "# The `tools_condition` function returns \"tools\" if the chatbot asks to use a tool, and \"END\" if\n",
    "# it is fine directly responding. This conditional routing defines the main agent loop.\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot_node\",\n",
    "    route_tools_function,\n",
    "    # The following dictionary lets you tell the graph to interpret the condition's outputs as a specific node\n",
    "    # It defaults to the identity function, but if you\n",
    "    # want to use a node named something else apart from \"tools\",\n",
    "    # You can update the value of the dictionary to something else\n",
    "    # e.g., \"tools\": \"my_tools\"\n",
    "    {\"tools_node\": \"tools_node\", END: END},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como el método de `LangGraph` ya existente `tools_condition`, nuestra función devuelve `END` si no se realizan llamadas de `tool`s. Cuando el grafo pasa a `END` éste no tiene más tareas que completar y cesa la ejecución."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como la condición puede devolver `END`, no necesitamos establecer explícitamente un `finish_point` esta vez. Nuestro grafo ya tiene una manera de terminar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10bfaaf90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_edge(\"tools_node\", \"chatbot_node\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadimos un otro nodo `edge`, pero en este caso incluye el uso de la `tool` o en final `END`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10bfaaf90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_edge(START, \"chatbot_node\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > **Aviso** \n",
    " >\n",
    " > Los `conditional_edge`s comienzan desde un solo nodo. Esto le dice al grafo \"en cualquier momento el 'chatbot' se ejecuta el nodo, ve a las 'tools' si se llama a una herramienta o termina el bucle si responde directamente\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilamos el grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos el grafo que hemos construido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Error al visualizar el grafo: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos hacer preguntas al bot fuera de sus datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mUser: \u001b[0mHow did Real Madrid fare this weekend against Leganes in La Liga?\n",
      "\u001b[33mAssistant: \u001b[0m[{'text': \"I'll help you find information about the recent match between Real Madrid and Leganes in La Liga. Let me search for the latest results.\", 'type': 'text'}, {'id': 'toolu_01D1iq2Lvi3sQD8w2ZsjiraY', 'input': {'query': 'Real Madrid vs Leganes La Liga result this weekend'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "\u001b[32mUser: \u001b[0mHow did Real Madrid fare this weekend against Leganes in La Liga?\n",
      "\u001b[33mAssistant: \u001b[0m[{\"title\": \"Real Madrid 3-2 Leganes: Goals and highlights - LaLiga 24/25 | Marca\", \"url\": \"https://www.marca.com/en/soccer/laliga/r-madrid-leganes/2025/03/29/01_0101_20250329_186_957-live.html\", \"content\": \"The two teams have already played twice this season, with Real Madrid securing a 3-0 win in the reverse league fixture. They also met in the quarter-finals of the Copa del Rey, a game Real won 3-2.\\n\\nReal Madrid vs Leganes LIVE - Latest Updates\\n\\nMatch ends, Real Madrid 3, Leganes 2.\\n\\nSecond Half ends, Real Madrid 3, Leganes 2.\\n\\nFoul by Vin\\u00edcius J\\u00fanior (Real Madrid).\\n\\nSeydouba Ciss\\u00e9 (Leganes) wins a free kick in the defensive half. [...] While their form has varied throughout the campaign there is no denying Real Madrid are a force at home in LaLiga this season, as they head into Saturday's match having picked up 34 points from 13 matches.\\n\\nAs for Leganes they currently sit 18th in the table, though they are level with Alaves for 17th as both teams look to stay in the top flight. [...] Goal! Real Madrid 1, Leganes 1. Diego Garc\\u00eda (Leganes) left footed shot from very close range.\\n\\nAttempt missed. \\u00d3scar Rodr\\u00edguez (Leganes) left footed shot from the centre of the box.\\n\\nGoal! Real Madrid 1, Leganes 0. Kylian Mbapp\\u00e9 (Real Madrid) converts the penalty with a right footed shot.\\n\\nPenalty Real Madrid. Arda G\\u00fcler draws a foul in the penalty area.\\n\\nPenalty conceded by \\u00d3scar Rodr\\u00edguez (Leganes) after a foul in the penalty area.\\n\\nDelay over. They are ready to continue.\", \"score\": 0.8742601}, {\"title\": \"Real Madrid 3-2 Legan\\u00e9s (Mar 29, 2025) Game Analysis - ESPN\", \"url\": \"https://www.espn.com/soccer/report/_/gameId/704946\", \"content\": \"Real Madrid\\n\\nLegan\\u00e9s\\n\\nMbapp\\u00e9 nets twice to keep Real Madrid's title hopes alive\\n\\nReal Madrid vs. Legan\\u00e9s - Game Highlights\\n\\nWatch the Game Highlights from Real Madrid vs. Legan\\u00e9s, 03/30/2025\\n\\nReal Madrid's Kylian Mbapp\\u00e9 struck twice to help his side come from behind to claim a hard-fought 3-2 home win over relegation-threatened Leganes on Saturday to move the second-placed reigning champions level on points with leaders Barcelona. [...] Leganes pushed for an equaliser but fell to a third consecutive defeat to sit 18th on 27 points, level with Alaves who are one place higher in the safety zone on goal difference.\\n\\n\\\"We have done a tremendous job. We leave with our heads held high because we were fighting until the end to score here,\\\" Leganes striker Garcia said.\\n\\n\\\"Ultimately, it was down to the details that they took it. We played a very serious game and now we have to think about next week.\\\"\\n\\nGame Information\", \"score\": 0.8682137}]\n",
      "\u001b[32mUser: \u001b[0mHow did Real Madrid fare this weekend against Leganes in La Liga?\n",
      "\u001b[33mAssistant: \u001b[0mBased on my search, here's what happened in the match between Real Madrid and Leganes this weekend:\n",
      "\n",
      "Real Madrid defeated Leganes 3-2 in their La Liga match on Saturday (March 29, 2025). It was a hard-fought victory for Real Madrid at home.\n",
      "\n",
      "Key highlights of the match:\n",
      "- Kylian Mbappé was the star performer for Real Madrid, scoring twice (including a penalty)\n",
      "- Real Madrid had to come from behind to secure the win\n",
      "- Leganes put up a strong fight, with Diego García scoring one of their goals\n",
      "- This was Leganes' third consecutive defeat\n",
      "\n",
      "After this result, Real Madrid moved level on points with leaders Barcelona in the La Liga standings. Meanwhile, Leganes currently sit in 18th place (in the relegation zone) with 27 points, level with Alaves who are one place higher in the safety zone on goal difference.\n",
      "\n",
      "Leganes striker García was quoted saying they \"leave with their heads held high\" after fighting until the end despite the defeat.\n",
      "\u001b[32mUser: \u001b[0mq\n",
      "\u001b[33mAssistant: \u001b[0mGoodbye!\n"
     ]
    }
   ],
   "source": [
    "# Colors for the terminal\n",
    "COLOR_GREEN = \"\\033[32m\"\n",
    "COLOR_YELLOW = \"\\033[33m\"\n",
    "COLOR_RESET = \"\\033[0m\"\n",
    "\n",
    "\n",
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        for value in event.values():\n",
    "            print(f\"{COLOR_GREEN}User: {COLOR_RESET}{user_input}\")\n",
    "            print(f\"{COLOR_YELLOW}Assistant: {COLOR_RESET}{value['messages'][-1].content}\")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(f\"{COLOR_GREEN}User: {COLOR_RESET}{user_input}\")\n",
    "            print(f\"{COLOR_YELLOW}Assistant: {COLOR_RESET}Goodbye!\")\n",
    "            break\n",
    "\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ves, primero le he preguntado cómo quedó el Real Madrid en su último partido en la Liga contra el Villareal, como es algo de actualidad, ha decidido usar la herramienta de búsqueda, con lo que ha obtenido el resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, a continuación le he preguntado qué jugadores jugaron y no sabía de qué le hablaba, eso es porque no se mantiene el contexto de la conversación. Así que lo siguiente que vamos a hacer es agregar una memoria al agente para que pueda mantener el contexto de la conversación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agregar memoria al chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro chatbot ahora puede usar herramientas para responder preguntas de los usuarios, pero no recuerda el contexto de las interacciones anteriores. Esto limita su capacidad de tener conversaciones coherentes y de múltiples tandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LangGraph` resuelve este problema a través de puntos de control persistentes o `checkpoints`. Si le proporcionamos un `checkpointer` al compilar el grafo y un `thread_id` al llamar al grafo, `LangGraph` guarda automáticamente el estado después de cada iteración en la conversación.\n",
    "\n",
    "Cuando invoquemos el grafo nuevamente usando el mismo `thread_id`, el grafo cargará su estado guardado, permitiendo que el chatbot continúe donde lo dejó."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veremos más tarde que ese `checkpointing` es mucho más potente que la simple memoria de chat: le permite guardar y reanudar estados complejos en cualquier momento para la recuperación de errores, flujos de trabajo con `human in the loop`, interacciones en el tiempo y más. Pero antes de ver todo eso, vamos a agregar puntos de control para permitir conversaciones de varias iteraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "HUGGINGFACE_TOKEN = os.getenv(\"HUGGINGFACE_LANGGRAPH\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_LANGGRAPH_API_KEY\")\n",
    "ANTRHOPIC_API_KEY = os.getenv(\"ANTHROPIC_LANGGRAPH_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para empezar, creamos un `checkpointer` [MemorySaver](https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.memory.MemorySaver)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > **Aviso**\n",
    " >\n",
    " > Estamos usando un `checkpointer` en memoria. Esto es conveniente para nuestro caso, ya que lo guarda todo en memoria la memoria del ordenador. En una aplicación de producción, es probable que se necesite cambiar esto para usarlo con `SqliteSaver` o `PostgresSaver` y conéctarnos a nuestra propia base de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, definimos el grafo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la `tool`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "wrapper = TavilySearchAPIWrapper(tavily_api_key=TAVILY_API_KEY)\n",
    "tool = TavilySearchResults(api_wrapper=wrapper, max_results=2)\n",
    "tools_list = [tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación el `LLM` con las `bind_tools` y lo añadimos al grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x122995160>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from huggingface_hub import login\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"    # Disable LangSmith tracing\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "# Create the LLM\n",
    "# login(token=HUGGINGFACE_TOKEN)  # Login to HuggingFace to use the model\n",
    "# MODEL = \"Qwen/Qwen2.5-72B-Instruct\"\n",
    "# model = HuggingFaceEndpoint(\n",
    "#     repo_id=MODEL,\n",
    "#     task=\"text-generation\",\n",
    "#     max_new_tokens=512,\n",
    "#     do_sample=False,\n",
    "#     repetition_penalty=1.03,\n",
    "# )\n",
    "# # Create the chat model\n",
    "# llm = ChatHuggingFace(llm=model)\n",
    "llm = ChatAnthropic(model=\"claude-3-7-sonnet-20250219\", api_key=ANTRHOPIC_API_KEY)\n",
    "\n",
    "# Modification: tell the LLM which tools it can call\n",
    "llm_with_tools = llm.bind_tools(tools_list)\n",
    "\n",
    "# Define the chatbot function\n",
    "def chatbot_function(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "# Add the chatbot node\n",
    "graph_builder.add_node(\"chatbot_node\", chatbot_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes construimos nuestro propio `BasicToolNode` para aprender cómo funciona, ahora lo reemplazaremos con el método de LangGraph `ToolNode` y `tools_condition`, ya que estos hacen algunas cosas buenas como la ejecución paralela de API. Aparte de eso, el resto es igual que antes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x122995160>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadimos el nodo de `tools_condition` al grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x122995160>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot_node\",\n",
    "    tools_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadimos el nodo de `tools` al grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x122995160>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_edge(\"tools\", \"chatbot_node\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadimos el nodo de `START` al grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x122995160>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_edge(START, \"chatbot_node\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilamos el grafo añadiendo el `checkpointer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo representamos gráficamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Error al visualizar el grafo: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una configuración con un `thread_id` de un usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER1_THREAD_ID = \"1\"\n",
    "config_USER1 = {\"configurable\": {\"thread_id\": USER1_THREAD_ID}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi there! My name is Maximo.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Maximo! It's nice to meet you. My name is Claude, and I'm an AI assistant. How can I help you today? \n",
      "\n",
      "Feel free to ask me any questions you might have or let me know if there's something specific you'd like assistance with.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Hi there! My name is Maximo.\"\n",
    "\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config_USER1,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Do you remember my name?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Yes, I remember your name! You introduced yourself as Maximo in your first message. Is there something specific I can help you with today, Maximo?\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Do you remember my name?\"\n",
    "\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config_USER1,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver, no hemos pasado una lista con los mensakes, todo está siendo gestionado por el `checkpointer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si ahora probamos con otro usuario, es decir, con otro `thread_id`, veremos que el grafo no recuerda la conversación anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Do you remember my name?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I don't have any record or memory of your name from previous conversations. As an AI assistant, I don't store personal information between sessions, so I wouldn't be able to remember your name unless you've shared it with me in this current conversation, which you haven't yet.\n",
      "\n",
      "If you'd like, you can introduce yourself, and I'll be happy to address you by name during our current conversation.\n"
     ]
    }
   ],
   "source": [
    "USER2_THREAD_ID = \"2\"\n",
    "config_USER2 = {\"configurable\": {\"thread_id\": USER2_THREAD_ID}}\n",
    "\n",
    "user_input = \"Do you remember my name?\"\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config_USER2,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que nuestro chatbot tiene herramientas de búsqueda y memoria, vamos a repetir el ejemplo anterior, donde le pregunto por el resultado del último partido del Real Madrid en la Liga y luego por qué jugadores jugaron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "How did Real Madrid fare this weekend against Leganes in La Liga?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"I'll find the latest information about Real Madrid's match against Leganes in La Liga this weekend for you. Let me search for the result.\", 'type': 'text'}, {'id': 'toolu_01ELwkoSXrNXb1UHDc5Xoxuj', 'input': {'query': 'Real Madrid vs Leganes La Liga result this weekend'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_01ELwkoSXrNXb1UHDc5Xoxuj)\n",
      " Call ID: toolu_01ELwkoSXrNXb1UHDc5Xoxuj\n",
      "  Args:\n",
      "    query: Real Madrid vs Leganes La Liga result this weekend\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"Real Madrid 3-2 Leganes: Goals and highlights - LaLiga 24/25 | Marca\", \"url\": \"https://www.marca.com/en/soccer/laliga/r-madrid-leganes/2025/03/29/01_0101_20250329_186_957-live.html\", \"content\": \"The two teams have already played twice this season, with Real Madrid securing a 3-0 win in the reverse league fixture. They also met in the quarter-finals of the Copa del Rey, a game Real won 3-2.\\n\\nReal Madrid vs Leganes LIVE - Latest Updates\\n\\nMatch ends, Real Madrid 3, Leganes 2.\\n\\nSecond Half ends, Real Madrid 3, Leganes 2.\\n\\nFoul by Vinícius Júnior (Real Madrid).\\n\\nSeydouba Cissé (Leganes) wins a free kick in the defensive half. [...] While their form has varied throughout the campaign there is no denying Real Madrid are a force at home in LaLiga this season, as they head into Saturday's match having picked up 34 points from 13 matches.\\n\\nAs for Leganes they currently sit 18th in the table, though they are level with Alaves for 17th as both teams look to stay in the top flight. [...] Goal! Real Madrid 1, Leganes 1. Diego García (Leganes) left footed shot from very close range.\\n\\nAttempt missed. Óscar Rodríguez (Leganes) left footed shot from the centre of the box.\\n\\nGoal! Real Madrid 1, Leganes 0. Kylian Mbappé (Real Madrid) converts the penalty with a right footed shot.\\n\\nPenalty Real Madrid. Arda Güler draws a foul in the penalty area.\\n\\nPenalty conceded by Óscar Rodríguez (Leganes) after a foul in the penalty area.\\n\\nDelay over. They are ready to continue.\", \"score\": 0.8742601}, {\"title\": \"Real Madrid 3-2 Leganés (Mar 29, 2025) Game Analysis - ESPN\", \"url\": \"https://www.espn.com/soccer/report/_/gameId/704946\", \"content\": \"Real Madrid\\n\\nLeganés\\n\\nMbappé nets twice to keep Real Madrid's title hopes alive\\n\\nReal Madrid vs. Leganés - Game Highlights\\n\\nWatch the Game Highlights from Real Madrid vs. Leganés, 03/30/2025\\n\\nReal Madrid's Kylian Mbappé struck twice to help his side come from behind to claim a hard-fought 3-2 home win over relegation-threatened Leganes on Saturday to move the second-placed reigning champions level on points with leaders Barcelona. [...] Leganes pushed for an equaliser but fell to a third consecutive defeat to sit 18th on 27 points, level with Alaves who are one place higher in the safety zone on goal difference.\\n\\n\\\"We have done a tremendous job. We leave with our heads held high because we were fighting until the end to score here,\\\" Leganes striker Garcia said.\\n\\n\\\"Ultimately, it was down to the details that they took it. We played a very serious game and now we have to think about next week.\\\"\\n\\nGame Information\", \"score\": 0.8682137}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on my search, I can provide you with information about Real Madrid's match against Leganes in La Liga this weekend:\n",
      "\n",
      "Real Madrid defeated Leganes 3-2 in a hard-fought match at home on Saturday, March 29, 2025.\n",
      "\n",
      "Match highlights:\n",
      "- Kylian Mbappé scored twice for Real Madrid, including the first goal from a penalty\n",
      "- Real Madrid had to come from behind to secure the win\n",
      "- Leganes' Diego García scored to make it 1-1 at one point\n",
      "- This was Leganes' third consecutive defeat\n",
      "\n",
      "The victory was important for Real Madrid's title hopes, as it moved them level on points with league leaders Barcelona. Meanwhile, Leganes remains in the relegation zone, sitting 18th in the table with 27 points, level with Alaves who are in 17th place (the safety zone) but ahead on goal difference.\n",
      "\n",
      "This was actually the third meeting between these teams this season. Real Madrid won the reverse league fixture 3-0 earlier in the season and also beat Leganes 3-2 in the Copa del Rey quarter-finals.\n"
     ]
    }
   ],
   "source": [
    "USER3_THREAD_ID = \"3\"\n",
    "config_USER3 = {\"configurable\": {\"thread_id\": USER3_THREAD_ID}}\n",
    "\n",
    "user_input = \"How did Real Madrid fare this weekend against Leganes in La Liga?\"\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config_USER3,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora le preguntamos por los jugadores que jugaron en el partido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Which players played against Leganes?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"I'll search for the lineup information for the Real Madrid vs Leganes match to see which players participated.\", 'type': 'text'}, {'id': 'toolu_01UbyguYBNwtcMjivg6f6mnL', 'input': {'query': 'Real Madrid vs Leganes lineup starting 11 March 29 2025'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_01UbyguYBNwtcMjivg6f6mnL)\n",
      " Call ID: toolu_01UbyguYBNwtcMjivg6f6mnL\n",
      "  Args:\n",
      "    query: Real Madrid vs Leganes lineup starting 11 March 29 2025\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"CONFIRMED lineups: Real Madrid vs Leganés, 2025 La Liga\", \"url\": \"https://www.managingmadrid.com/2025/3/29/24396638/real-madrid-vs-leganes-2025-la-liga-live-online-stream\", \"content\": \"Real Madrid starting XI: Lunin, Vazquez, Rudiger, Asencio, Fran Garcia, Camavinga, Guler, Modric, Bellingham, Brahim, Mbappe.\\n\\nLeganes starting XI (TBC): Dmitrovic, Rosier, Nastasic, González, Hernández, Tapia, Cruz, Brasanac, Cisse, Rodríguez, Raba.\\n\\nIt won't be easy for Real Madrid to beat Leganés right after the FIFA break even if they have been quite mediocre this season and are currently fighting to avoid relegation. Composure and intensity will be needed.\\n\\nHOW TO WATCH, STREAM LA LIGA [...] Date: 03/29/2025\\n\\nTime: 21:00CET, 03:00pm EST.\\n\\nVenue: Santiago Bernabéu, Madrid, Spain.\\n\\nAvailable TV: Movistar La Liga, ABC\\n\\nAvailable Streaming: ESPN+\\n\\nManaging Madrid has affiliate partnerships. These do not influence editorial content, though Vox Media may earn commissions for products purchased via affiliate links.\\n\\n\\n\\n\\n\\nA post shared by Managing Madrid (@managingmadrid)\\n\\nMore From\\n    \\n        Managing Madrid\\n\\nMost Read\\n\\nLoading comments... [...] Follow Managing Madrid online:\\n\\nSite search\\n\\nManaging Madrid main menu\\n\\nFiled under:\\n\\nCONFIRMED lineups: Real Madrid vs Leganés, 2025 La Liga\\n\\nAll set for another LaLiga game!\\n\\nShare this story\\n\\nShare\\nAll sharing options for:\\nCONFIRMED lineups: Real Madrid vs Leganés, 2025 La Liga\\n\\nReal Madrid have published their starting lineup for the upcoming match against Leganés in La Liga.\", \"score\": 0.9328032}, {\"title\": \"Real Madrid v Leganes | March 29, 2025 | Goal.com US\", \"url\": \"https://www.goal.com/en-us/match/real-madrid-vs-leganes/lineups/sZTw_SnjyKCcntxKHHQI7\", \"content\": \"LEG. -Line up · 13. M. Dmitrovic · 6. S. Gonzalez (C) · 12. V. Rosier · 20. J. Hernandez. 62' · 22. M. Nastasic · 10. D. Raba. 41'. 86' · 11. J. Cruz.\", \"score\": 0.9284155}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Let me get more complete information about both teams' lineups and any substitutions that may have occurred during the match.\", 'type': 'text'}, {'id': 'toolu_01RwFB2thAzGtwipk59VjFfw', 'input': {'query': 'Real Madrid vs Leganes March 29 2025 full team lineups substitutions'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_01RwFB2thAzGtwipk59VjFfw)\n",
      " Call ID: toolu_01RwFB2thAzGtwipk59VjFfw\n",
      "  Args:\n",
      "    query: Real Madrid vs Leganes March 29 2025 full team lineups substitutions\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"Starting Lineups - Real Madrid vs Leganes | 29.03.2025 - Sky Sports\", \"url\": \"https://www.skysports.com/football/real-madrid-vs-leganes/teams/506580\", \"content\": \"Substitutes ; 26: F González ; 34: S Mestre ; 4: D Alaba ; 7: Vinicius Júnior. 62'62nd minute ; 8: F Valverde. 72'72nd minute.\", \"score\": 0.94263905}, {\"title\": \"Real Madrid v Leganes | March 29, 2025 | Goal.com US\", \"url\": \"https://www.goal.com/en-us/match/real-madrid-vs-leganes/lineups/sZTw_SnjyKCcntxKHHQI7\", \"content\": \"Substitutes · 7. Vinicius Junior. 62' · 14. A. Tchouameni. 81' · 18. J. Vallejo · 8. F. Valverde. 72' · 4. D. Alaba · 16. Endrick · 11. Rodrygo. 62'.\", \"score\": 0.94135845}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Let me search for one more source to get comprehensive information about both teams' lineups.\", 'type': 'text'}, {'id': 'toolu_01U9QYkfxkrcGvtukr1in5bo', 'input': {'query': 'Real Madrid vs Leganes March 29 2025 full match report all players who played'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_01U9QYkfxkrcGvtukr1in5bo)\n",
      " Call ID: toolu_01U9QYkfxkrcGvtukr1in5bo\n",
      "  Args:\n",
      "    query: Real Madrid vs Leganes March 29 2025 full match report all players who played\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"Real Madrid 3-2 Leganés (Mar 29, 2025) Game Analysis - ESPN\", \"url\": \"https://www.espn.com/soccer/report/_/gameId/704946\", \"content\": \"Real Madrid\\n\\nLeganés\\n\\nMbappé nets twice to keep Real Madrid's title hopes alive\\n\\nReal Madrid vs. Leganés - Game Highlights\\n\\nWatch the Game Highlights from Real Madrid vs. Leganés, 03/30/2025\\n\\nReal Madrid's Kylian Mbappé struck twice to help his side come from behind to claim a hard-fought 3-2 home win over relegation-threatened Leganes on Saturday to move the second-placed reigning champions level on points with leaders Barcelona. [...] However, Leganes responded almost immediately as Diego Garcia tapped in a loose ball at the far post to equalise in the following minute before Rodriguez set up Dani Raba to slot past goalkeeper Andriy Lunin in the 41st.\\n\\nReal midfielder Jude Bellingham brought the scores level two minutes after the break, sliding the ball into the net after a rebound off the crossbar. Mbappé then bagged the winner with a brilliant curled free kick in the 76th minute for his second. [...] Real have 63 points from 29 matches along with Barca, who host Girona on Sunday. Third-placed Atletico Madrid dropped points in a 1-1 draw at Espanyol earlier on Saturday and are now six points off the pace with 57.\\n\\n\\\"It was difficult match. After the international break it's always difficult,\\\" Mbappé told RMTV.\\n\\nThe hosts made a dominant start and opened the scoring after 32 minutes when Mbappé coolly chipped in a penalty, awarded after Óscar Rodríguez brought down Arda Güler.\", \"score\": 0.8773195}, {\"title\": \"Player Ratings: Real Madrid 3-2 Leganes; 2025 La Liga\", \"url\": \"https://www.managingmadrid.com/2025/3/30/24396688/player-ratings-real-madrid-3-2-leganes-2025-la-liga\", \"content\": \"Raúl Asencio—7: Applauded by the Bernabeu on multiple occasions with good sweeping up defensively.\\n\\nFran García—6: Better on the offensive end, getting into the final third and playing some dagger crosses.\\n\\nEduardo Camavinga—6: Modric and Camavinga struggled to deal with Leganes counter attacks and Diego, playing as a #10 for Leganes, got the better of both of them. [...] Follow Managing Madrid online:\\n\\nSite search\\n\\nManaging Madrid main menu\\n\\nFiled under:\\n\\nPlayer Ratings: Real Madrid 3-2 Leganes; 2025 La Liga\\n\\nKylian Mbappe scores a brace to help Madrid secure a nervy 3-2 victory.\\n\\nShare this story\\n\\nShare\\nAll sharing options for:\\nPlayer Ratings: Real Madrid 3-2 Leganes; 2025 La Liga\\n\\nFull match player ratings below:\\n\\nAndriy Lunin—7: Not at fault for the goals, was left with the opposition taking a shot from near the six yard box. [...] Lucas Vázquez—4: Exposed in transition and lacking the speed and athleticism to cover the gaps he leaves when venturing forward. Needs a more “pessimistic” attitude when the ball is on the opposite flank, occupying better spots in ““rest defense”.\\n\\nAntonio Rudiger—5: Several unnecessary long distance shots to hurt Madrid’s rhythm and reinforce Leganes game plan. Playing with too many matches in his legs and it’s beginning to show.\", \"score\": 0.86954874}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on the search results, I can provide you with information about the players who played in the Real Madrid vs Leganes match on March 29, 2025:\n",
      "\n",
      "**Real Madrid Starting XI:**\n",
      "- Andriy Lunin (Goalkeeper)\n",
      "- Lucas Vázquez (Defender)\n",
      "- Antonio Rüdiger (Defender)\n",
      "- Raúl Asencio (Defender)\n",
      "- Fran García (Defender)\n",
      "- Eduardo Camavinga (Midfielder)\n",
      "- Arda Güler (Midfielder)\n",
      "- Luka Modrić (Midfielder)\n",
      "- Jude Bellingham (Midfielder) - Scored in the 47th minute\n",
      "- Brahim Díaz (Forward)\n",
      "- Kylian Mbappé (Forward) - Scored twice (32nd minute penalty, 76th minute free kick)\n",
      "\n",
      "**Real Madrid Substitutes who played:**\n",
      "- Vinícius Júnior (came on in the 62nd minute)\n",
      "- Rodrygo (came on in the 62nd minute)\n",
      "- Federico Valverde (came on in the 72nd minute)\n",
      "- Aurélien Tchouaméni (came on in the 81st minute)\n",
      "\n",
      "**Leganes Starting XI:**\n",
      "- Marko Dmitrović (Goalkeeper)\n",
      "- Víctor Rosier (Defender)\n",
      "- Matija Nastasić (Defender)\n",
      "- Sergio González (Captain, Defender)\n",
      "- Juan Hernández (Defender, substituted in the 62nd minute)\n",
      "- Renato Tapia (Midfielder)\n",
      "- Juan Cruz (Midfielder)\n",
      "- Darko Brašanac (Midfielder)\n",
      "- Seydouba Cissé (Midfielder)\n",
      "- Óscar Rodríguez (Midfielder)\n",
      "- Dani Raba (Forward, scored in the 41st minute, substituted in the 86th minute)\n",
      "\n",
      "**Other Leganes players mentioned:**\n",
      "- Diego García (Forward, scored in the match)\n",
      "\n",
      "The match was a hard-fought 3-2 victory for Real Madrid, with goals from Mbappé (2) and Bellingham for Real Madrid, and Diego García and Dani Raba for Leganes.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Which players played against Leganes?\"\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config_USER3,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras mucho buscar, al final lo encuentra. Por lo que ya tenemos un chatbot con `tools` y memoria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ahora, hemos creado unos `checkpoints` en tres hilos diferentes. Pero, ¿qué entra en cada `checkpoint`? Para inspeccionar el estado de un grafo para una configuración dada podemos usar el método `get_state(config)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='How did Real Madrid fare this weekend against Leganes in La Liga?', additional_kwargs={}, response_metadata={}, id='533ee07d-517a-4286-98f6-13a7f3f61228'), AIMessage(content=[{'text': \"I'll find the latest information about Real Madrid's match against Leganes in La Liga this weekend for you. Let me search for the result.\", 'type': 'text'}, {'id': 'toolu_01ELwkoSXrNXb1UHDc5Xoxuj', 'input': {'query': 'Real Madrid vs Leganes La Liga result this weekend'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}], additional_kwargs={}, response_metadata={'id': 'msg_01Ya8M5awAkPmsz1vmKj95A1', 'model': 'claude-3-7-sonnet-20250219', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 431, 'output_tokens': 99}, 'model_name': 'claude-3-7-sonnet-20250219'}, id='run-bb25993a-b3a5-45d9-b1fd-61166e24f1d3-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'Real Madrid vs Leganes La Liga result this weekend'}, 'id': 'toolu_01ELwkoSXrNXb1UHDc5Xoxuj', 'type': 'tool_call'}], usage_metadata={'input_tokens': 431, 'output_tokens': 99, 'total_tokens': 530, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}), ToolMessage(content='[{\"title\": \"Real Madrid 3-2 Leganes: Goals and highlights - LaLiga 24/25 | Marca\", \"url\": \"https://www.marca.com/en/soccer/laliga/r-madrid-leganes/2025/03/29/01_0101_20250329_186_957-live.html\", \"content\": \"The two teams have already played twice this season, with Real Madrid securing a 3-0 win in the reverse league fixture. They also met in the quarter-finals of the Copa del Rey, a game Real won 3-2.\\\\n\\\\nReal Madrid vs Leganes LIVE - Latest Updates\\\\n\\\\nMatch ends, Real Madrid 3, Leganes 2.\\\\n\\\\nSecond Half ends, Real Madrid 3, Leganes 2.\\\\n\\\\nFoul by Vinícius Júnior (Real Madrid).\\\\n\\\\nSeydouba Cissé (Leganes) wins a free kick in the defensive half. [...] While their form has varied throughout the campaign there is no denying Real Madrid are a force at home in LaLiga this season, as they head into Saturday\\'s match having picked up 34 points from 13 matches.\\\\n\\\\nAs for Leganes they currently sit 18th in the table, though they are level with Alaves for 17th as both teams look to stay in the top flight. [...] Goal! Real Madrid 1, Leganes 1. Diego García (Leganes) left footed shot from very close range.\\\\n\\\\nAttempt missed. Óscar Rodríguez (Leganes) left footed shot from the centre of the box.\\\\n\\\\nGoal! Real Madrid 1, Leganes 0. Kylian Mbappé (Real Madrid) converts the penalty with a right footed shot.\\\\n\\\\nPenalty Real Madrid. Arda Güler draws a foul in the penalty area.\\\\n\\\\nPenalty conceded by Óscar Rodríguez (Leganes) after a foul in the penalty area.\\\\n\\\\nDelay over. They are ready to continue.\", \"score\": 0.8742601}, {\"title\": \"Real Madrid 3-2 Leganés (Mar 29, 2025) Game Analysis - ESPN\", \"url\": \"https://www.espn.com/soccer/report/_/gameId/704946\", \"content\": \"Real Madrid\\\\n\\\\nLeganés\\\\n\\\\nMbappé nets twice to keep Real Madrid\\'s title hopes alive\\\\n\\\\nReal Madrid vs. Leganés - Game Highlights\\\\n\\\\nWatch the Game Highlights from Real Madrid vs. Leganés, 03/30/2025\\\\n\\\\nReal Madrid\\'s Kylian Mbappé struck twice to help his side come from behind to claim a hard-fought 3-2 home win over relegation-threatened Leganes on Saturday to move the second-placed reigning champions level on points with leaders Barcelona. [...] Leganes pushed for an equaliser but fell to a third consecutive defeat to sit 18th on 27 points, level with Alaves who are one place higher in the safety zone on goal difference.\\\\n\\\\n\\\\\"We have done a tremendous job. We leave with our heads held high because we were fighting until the end to score here,\\\\\" Leganes striker Garcia said.\\\\n\\\\n\\\\\"Ultimately, it was down to the details that they took it. We played a very serious game and now we have to think about next week.\\\\\"\\\\n\\\\nGame Information\", \"score\": 0.8682137}]', name='tavily_search_results_json', id='4b4ac4f2-97d4-497f-be85-9e3611ccdd86', tool_call_id='toolu_01ELwkoSXrNXb1UHDc5Xoxuj', artifact={'query': 'Real Madrid vs Leganes La Liga result this weekend', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://www.marca.com/en/soccer/laliga/r-madrid-leganes/2025/03/29/01_0101_20250329_186_957-live.html', 'title': 'Real Madrid 3-2 Leganes: Goals and highlights - LaLiga 24/25 | Marca', 'content': \"The two teams have already played twice this season, with Real Madrid securing a 3-0 win in the reverse league fixture. They also met in the quarter-finals of the Copa del Rey, a game Real won 3-2.\\n\\nReal Madrid vs Leganes LIVE - Latest Updates\\n\\nMatch ends, Real Madrid 3, Leganes 2.\\n\\nSecond Half ends, Real Madrid 3, Leganes 2.\\n\\nFoul by Vinícius Júnior (Real Madrid).\\n\\nSeydouba Cissé (Leganes) wins a free kick in the defensive half. [...] While their form has varied throughout the campaign there is no denying Real Madrid are a force at home in LaLiga this season, as they head into Saturday's match having picked up 34 points from 13 matches.\\n\\nAs for Leganes they currently sit 18th in the table, though they are level with Alaves for 17th as both teams look to stay in the top flight. [...] Goal! Real Madrid 1, Leganes 1. Diego García (Leganes) left footed shot from very close range.\\n\\nAttempt missed. Óscar Rodríguez (Leganes) left footed shot from the centre of the box.\\n\\nGoal! Real Madrid 1, Leganes 0. Kylian Mbappé (Real Madrid) converts the penalty with a right footed shot.\\n\\nPenalty Real Madrid. Arda Güler draws a foul in the penalty area.\\n\\nPenalty conceded by Óscar Rodríguez (Leganes) after a foul in the penalty area.\\n\\nDelay over. They are ready to continue.\", 'score': 0.8742601, 'raw_content': None}, {'url': 'https://www.espn.com/soccer/report/_/gameId/704946', 'title': 'Real Madrid 3-2 Leganés (Mar 29, 2025) Game Analysis - ESPN', 'content': 'Real Madrid\\n\\nLeganés\\n\\nMbappé nets twice to keep Real Madrid\\'s title hopes alive\\n\\nReal Madrid vs. Leganés - Game Highlights\\n\\nWatch the Game Highlights from Real Madrid vs. Leganés, 03/30/2025\\n\\nReal Madrid\\'s Kylian Mbappé struck twice to help his side come from behind to claim a hard-fought 3-2 home win over relegation-threatened Leganes on Saturday to move the second-placed reigning champions level on points with leaders Barcelona. [...] Leganes pushed for an equaliser but fell to a third consecutive defeat to sit 18th on 27 points, level with Alaves who are one place higher in the safety zone on goal difference.\\n\\n\"We have done a tremendous job. We leave with our heads held high because we were fighting until the end to score here,\" Leganes striker Garcia said.\\n\\n\"Ultimately, it was down to the details that they took it. We played a very serious game and now we have to think about next week.\"\\n\\nGame Information', 'score': 0.8682137, 'raw_content': None}], 'response_time': 2.51}), AIMessage(content=\"Based on my search, I can provide you with information about Real Madrid's match against Leganes in La Liga this weekend:\\n\\nReal Madrid defeated Leganes 3-2 in a hard-fought match at home on Saturday, March 29, 2025.\\n\\nMatch highlights:\\n- Kylian Mbappé scored twice for Real Madrid, including the first goal from a penalty\\n- Real Madrid had to come from behind to secure the win\\n- Leganes' Diego García scored to make it 1-1 at one point\\n- This was Leganes' third consecutive defeat\\n\\nThe victory was important for Real Madrid's title hopes, as it moved them level on points with league leaders Barcelona. Meanwhile, Leganes remains in the relegation zone, sitting 18th in the table with 27 points, level with Alaves who are in 17th place (the safety zone) but ahead on goal difference.\\n\\nThis was actually the third meeting between these teams this season. Real Madrid won the reverse league fixture 3-0 earlier in the season and also beat Leganes 3-2 in the Copa del Rey quarter-finals.\", additional_kwargs={}, response_metadata={'id': 'msg_013Ad2X74Vo4icWkPXLWxsk6', 'model': 'claude-3-7-sonnet-20250219', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 1367, 'output_tokens': 253}, 'model_name': 'claude-3-7-sonnet-20250219'}, id='run-8f1dfab4-c70e-4ae4-b621-154acdec5b73-0', usage_metadata={'input_tokens': 1367, 'output_tokens': 253, 'total_tokens': 1620, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}), HumanMessage(content='Which players played against Leganes?', additional_kwargs={}, response_metadata={}, id='43c86d68-973e-40d6-b686-c41d8d365e7f'), AIMessage(content=[{'text': \"I'll search for the lineup information for the Real Madrid vs Leganes match to see which players participated.\", 'type': 'text'}, {'id': 'toolu_01UbyguYBNwtcMjivg6f6mnL', 'input': {'query': 'Real Madrid vs Leganes lineup starting 11 March 29 2025'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}], additional_kwargs={}, response_metadata={'id': 'msg_018o9Gqi1cj8a6GEemMLvZ1Q', 'model': 'claude-3-7-sonnet-20250219', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 1631, 'output_tokens': 97}, 'model_name': 'claude-3-7-sonnet-20250219'}, id='run-c985efce-9cd0-42f8-8623-b518f3bf8045-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'Real Madrid vs Leganes lineup starting 11 March 29 2025'}, 'id': 'toolu_01UbyguYBNwtcMjivg6f6mnL', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1631, 'output_tokens': 97, 'total_tokens': 1728, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}), ToolMessage(content='[{\"title\": \"CONFIRMED lineups: Real Madrid vs Leganés, 2025 La Liga\", \"url\": \"https://www.managingmadrid.com/2025/3/29/24396638/real-madrid-vs-leganes-2025-la-liga-live-online-stream\", \"content\": \"Real Madrid starting XI: Lunin, Vazquez, Rudiger, Asencio, Fran Garcia, Camavinga, Guler, Modric, Bellingham, Brahim, Mbappe.\\\\n\\\\nLeganes starting XI (TBC): Dmitrovic, Rosier, Nastasic, González, Hernández, Tapia, Cruz, Brasanac, Cisse, Rodríguez, Raba.\\\\n\\\\nIt won\\'t be easy for Real Madrid to beat Leganés right after the FIFA break even if they have been quite mediocre this season and are currently fighting to avoid relegation. Composure and intensity will be needed.\\\\n\\\\nHOW TO WATCH, STREAM LA LIGA [...] Date: 03/29/2025\\\\n\\\\nTime: 21:00CET, 03:00pm EST.\\\\n\\\\nVenue: Santiago Bernabéu, Madrid, Spain.\\\\n\\\\nAvailable TV: Movistar La Liga, ABC\\\\n\\\\nAvailable Streaming: ESPN+\\\\n\\\\nManaging Madrid has affiliate partnerships. These do not influence editorial content, though Vox Media may earn commissions for products purchased via affiliate links.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nA post shared by Managing Madrid (@managingmadrid)\\\\n\\\\nMore From\\\\n    \\\\n        Managing Madrid\\\\n\\\\nMost Read\\\\n\\\\nLoading comments... [...] Follow Managing Madrid online:\\\\n\\\\nSite search\\\\n\\\\nManaging Madrid main menu\\\\n\\\\nFiled under:\\\\n\\\\nCONFIRMED lineups: Real Madrid vs Leganés, 2025 La Liga\\\\n\\\\nAll set for another LaLiga game!\\\\n\\\\nShare this story\\\\n\\\\nShare\\\\nAll sharing options for:\\\\nCONFIRMED lineups: Real Madrid vs Leganés, 2025 La Liga\\\\n\\\\nReal Madrid have published their starting lineup for the upcoming match against Leganés in La Liga.\", \"score\": 0.9328032}, {\"title\": \"Real Madrid v Leganes | March 29, 2025 | Goal.com US\", \"url\": \"https://www.goal.com/en-us/match/real-madrid-vs-leganes/lineups/sZTw_SnjyKCcntxKHHQI7\", \"content\": \"LEG. -Line up · 13. M. Dmitrovic · 6. S. Gonzalez (C) · 12. V. Rosier · 20. J. Hernandez. 62\\' · 22. M. Nastasic · 10. D. Raba. 41\\'. 86\\' · 11. J. Cruz.\", \"score\": 0.9284155}]', name='tavily_search_results_json', id='3d5a5455-18c9-41d8-82c2-e9e4b13937e5', tool_call_id='toolu_01UbyguYBNwtcMjivg6f6mnL', artifact={'query': 'Real Madrid vs Leganes lineup starting 11 March 29 2025', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://www.managingmadrid.com/2025/3/29/24396638/real-madrid-vs-leganes-2025-la-liga-live-online-stream', 'title': 'CONFIRMED lineups: Real Madrid vs Leganés, 2025 La Liga', 'content': \"Real Madrid starting XI: Lunin, Vazquez, Rudiger, Asencio, Fran Garcia, Camavinga, Guler, Modric, Bellingham, Brahim, Mbappe.\\n\\nLeganes starting XI (TBC): Dmitrovic, Rosier, Nastasic, González, Hernández, Tapia, Cruz, Brasanac, Cisse, Rodríguez, Raba.\\n\\nIt won't be easy for Real Madrid to beat Leganés right after the FIFA break even if they have been quite mediocre this season and are currently fighting to avoid relegation. Composure and intensity will be needed.\\n\\nHOW TO WATCH, STREAM LA LIGA [...] Date: 03/29/2025\\n\\nTime: 21:00CET, 03:00pm EST.\\n\\nVenue: Santiago Bernabéu, Madrid, Spain.\\n\\nAvailable TV: Movistar La Liga, ABC\\n\\nAvailable Streaming: ESPN+\\n\\nManaging Madrid has affiliate partnerships. These do not influence editorial content, though Vox Media may earn commissions for products purchased via affiliate links.\\n\\n\\n\\n\\n\\nA post shared by Managing Madrid (@managingmadrid)\\n\\nMore From\\n    \\n        Managing Madrid\\n\\nMost Read\\n\\nLoading comments... [...] Follow Managing Madrid online:\\n\\nSite search\\n\\nManaging Madrid main menu\\n\\nFiled under:\\n\\nCONFIRMED lineups: Real Madrid vs Leganés, 2025 La Liga\\n\\nAll set for another LaLiga game!\\n\\nShare this story\\n\\nShare\\nAll sharing options for:\\nCONFIRMED lineups: Real Madrid vs Leganés, 2025 La Liga\\n\\nReal Madrid have published their starting lineup for the upcoming match against Leganés in La Liga.\", 'score': 0.9328032, 'raw_content': None}, {'url': 'https://www.goal.com/en-us/match/real-madrid-vs-leganes/lineups/sZTw_SnjyKCcntxKHHQI7', 'title': 'Real Madrid v Leganes | March 29, 2025 | Goal.com US', 'content': \"LEG. -Line up · 13. M. Dmitrovic · 6. S. Gonzalez (C) · 12. V. Rosier · 20. J. Hernandez. 62' · 22. M. Nastasic · 10. D. Raba. 41'. 86' · 11. J. Cruz.\", 'score': 0.9284155, 'raw_content': None}], 'response_time': 2.8}), AIMessage(content=[{'text': \"Let me get more complete information about both teams' lineups and any substitutions that may have occurred during the match.\", 'type': 'text'}, {'id': 'toolu_01RwFB2thAzGtwipk59VjFfw', 'input': {'query': 'Real Madrid vs Leganes March 29 2025 full team lineups substitutions'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}], additional_kwargs={}, response_metadata={'id': 'msg_01L8ngEDcKgPTyX5NnMz5zkT', 'model': 'claude-3-7-sonnet-20250219', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 2476, 'output_tokens': 102}, 'model_name': 'claude-3-7-sonnet-20250219'}, id='run-b31b0608-221f-4b83-8c84-f4c5e13d8f7f-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'Real Madrid vs Leganes March 29 2025 full team lineups substitutions'}, 'id': 'toolu_01RwFB2thAzGtwipk59VjFfw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2476, 'output_tokens': 102, 'total_tokens': 2578, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}), ToolMessage(content='[{\"title\": \"Starting Lineups - Real Madrid vs Leganes | 29.03.2025 - Sky Sports\", \"url\": \"https://www.skysports.com/football/real-madrid-vs-leganes/teams/506580\", \"content\": \"Substitutes ; 26: F González ; 34: S Mestre ; 4: D Alaba ; 7: Vinicius Júnior. 62\\'62nd minute ; 8: F Valverde. 72\\'72nd minute.\", \"score\": 0.94263905}, {\"title\": \"Real Madrid v Leganes | March 29, 2025 | Goal.com US\", \"url\": \"https://www.goal.com/en-us/match/real-madrid-vs-leganes/lineups/sZTw_SnjyKCcntxKHHQI7\", \"content\": \"Substitutes · 7. Vinicius Junior. 62\\' · 14. A. Tchouameni. 81\\' · 18. J. Vallejo · 8. F. Valverde. 72\\' · 4. D. Alaba · 16. Endrick · 11. Rodrygo. 62\\'.\", \"score\": 0.94135845}]', name='tavily_search_results_json', id='c425ce48-eeff-42a6-9f99-14933c5c8c38', tool_call_id='toolu_01RwFB2thAzGtwipk59VjFfw', artifact={'query': 'Real Madrid vs Leganes March 29 2025 full team lineups substitutions', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://www.skysports.com/football/real-madrid-vs-leganes/teams/506580', 'title': 'Starting Lineups - Real Madrid vs Leganes | 29.03.2025 - Sky Sports', 'content': \"Substitutes ; 26: F González ; 34: S Mestre ; 4: D Alaba ; 7: Vinicius Júnior. 62'62nd minute ; 8: F Valverde. 72'72nd minute.\", 'score': 0.94263905, 'raw_content': None}, {'url': 'https://www.goal.com/en-us/match/real-madrid-vs-leganes/lineups/sZTw_SnjyKCcntxKHHQI7', 'title': 'Real Madrid v Leganes | March 29, 2025 | Goal.com US', 'content': \"Substitutes · 7. Vinicius Junior. 62' · 14. A. Tchouameni. 81' · 18. J. Vallejo · 8. F. Valverde. 72' · 4. D. Alaba · 16. Endrick · 11. Rodrygo. 62'.\", 'score': 0.94135845, 'raw_content': None}], 'response_time': 1.97}), AIMessage(content=[{'text': \"Let me search for one more source to get comprehensive information about both teams' lineups.\", 'type': 'text'}, {'id': 'toolu_01U9QYkfxkrcGvtukr1in5bo', 'input': {'query': 'Real Madrid vs Leganes March 29 2025 full match report all players who played'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}], additional_kwargs={}, response_metadata={'id': 'msg_01CyiUszsBZmMJibZ3EHQjP8', 'model': 'claude-3-7-sonnet-20250219', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 2895, 'output_tokens': 97}, 'model_name': 'claude-3-7-sonnet-20250219'}, id='run-19fcfd27-6270-43ae-90cb-8564290bae86-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'Real Madrid vs Leganes March 29 2025 full match report all players who played'}, 'id': 'toolu_01U9QYkfxkrcGvtukr1in5bo', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2895, 'output_tokens': 97, 'total_tokens': 2992, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}), ToolMessage(content='[{\"title\": \"Real Madrid 3-2 Leganés (Mar 29, 2025) Game Analysis - ESPN\", \"url\": \"https://www.espn.com/soccer/report/_/gameId/704946\", \"content\": \"Real Madrid\\\\n\\\\nLeganés\\\\n\\\\nMbappé nets twice to keep Real Madrid\\'s title hopes alive\\\\n\\\\nReal Madrid vs. Leganés - Game Highlights\\\\n\\\\nWatch the Game Highlights from Real Madrid vs. Leganés, 03/30/2025\\\\n\\\\nReal Madrid\\'s Kylian Mbappé struck twice to help his side come from behind to claim a hard-fought 3-2 home win over relegation-threatened Leganes on Saturday to move the second-placed reigning champions level on points with leaders Barcelona. [...] However, Leganes responded almost immediately as Diego Garcia tapped in a loose ball at the far post to equalise in the following minute before Rodriguez set up Dani Raba to slot past goalkeeper Andriy Lunin in the 41st.\\\\n\\\\nReal midfielder Jude Bellingham brought the scores level two minutes after the break, sliding the ball into the net after a rebound off the crossbar. Mbappé then bagged the winner with a brilliant curled free kick in the 76th minute for his second. [...] Real have 63 points from 29 matches along with Barca, who host Girona on Sunday. Third-placed Atletico Madrid dropped points in a 1-1 draw at Espanyol earlier on Saturday and are now six points off the pace with 57.\\\\n\\\\n\\\\\"It was difficult match. After the international break it\\'s always difficult,\\\\\" Mbappé told RMTV.\\\\n\\\\nThe hosts made a dominant start and opened the scoring after 32 minutes when Mbappé coolly chipped in a penalty, awarded after Óscar Rodríguez brought down Arda Güler.\", \"score\": 0.8773195}, {\"title\": \"Player Ratings: Real Madrid 3-2 Leganes; 2025 La Liga\", \"url\": \"https://www.managingmadrid.com/2025/3/30/24396688/player-ratings-real-madrid-3-2-leganes-2025-la-liga\", \"content\": \"Raúl Asencio—7: Applauded by the Bernabeu on multiple occasions with good sweeping up defensively.\\\\n\\\\nFran García—6: Better on the offensive end, getting into the final third and playing some dagger crosses.\\\\n\\\\nEduardo Camavinga—6: Modric and Camavinga struggled to deal with Leganes counter attacks and Diego, playing as a #10 for Leganes, got the better of both of them. [...] Follow Managing Madrid online:\\\\n\\\\nSite search\\\\n\\\\nManaging Madrid main menu\\\\n\\\\nFiled under:\\\\n\\\\nPlayer Ratings: Real Madrid 3-2 Leganes; 2025 La Liga\\\\n\\\\nKylian Mbappe scores a brace to help Madrid secure a nervy 3-2 victory.\\\\n\\\\nShare this story\\\\n\\\\nShare\\\\nAll sharing options for:\\\\nPlayer Ratings: Real Madrid 3-2 Leganes; 2025 La Liga\\\\n\\\\nFull match player ratings below:\\\\n\\\\nAndriy Lunin—7: Not at fault for the goals, was left with the opposition taking a shot from near the six yard box. [...] Lucas Vázquez—4: Exposed in transition and lacking the speed and athleticism to cover the gaps he leaves when venturing forward. Needs a more “pessimistic” attitude when the ball is on the opposite flank, occupying better spots in ““rest defense”.\\\\n\\\\nAntonio Rudiger—5: Several unnecessary long distance shots to hurt Madrid’s rhythm and reinforce Leganes game plan. Playing with too many matches in his legs and it’s beginning to show.\", \"score\": 0.86954874}]', name='tavily_search_results_json', id='770fcf52-99b6-4170-b862-52271b10b237', tool_call_id='toolu_01U9QYkfxkrcGvtukr1in5bo', artifact={'query': 'Real Madrid vs Leganes March 29 2025 full match report all players who played', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://www.espn.com/soccer/report/_/gameId/704946', 'title': 'Real Madrid 3-2 Leganés (Mar 29, 2025) Game Analysis - ESPN', 'content': 'Real Madrid\\n\\nLeganés\\n\\nMbappé nets twice to keep Real Madrid\\'s title hopes alive\\n\\nReal Madrid vs. Leganés - Game Highlights\\n\\nWatch the Game Highlights from Real Madrid vs. Leganés, 03/30/2025\\n\\nReal Madrid\\'s Kylian Mbappé struck twice to help his side come from behind to claim a hard-fought 3-2 home win over relegation-threatened Leganes on Saturday to move the second-placed reigning champions level on points with leaders Barcelona. [...] However, Leganes responded almost immediately as Diego Garcia tapped in a loose ball at the far post to equalise in the following minute before Rodriguez set up Dani Raba to slot past goalkeeper Andriy Lunin in the 41st.\\n\\nReal midfielder Jude Bellingham brought the scores level two minutes after the break, sliding the ball into the net after a rebound off the crossbar. Mbappé then bagged the winner with a brilliant curled free kick in the 76th minute for his second. [...] Real have 63 points from 29 matches along with Barca, who host Girona on Sunday. Third-placed Atletico Madrid dropped points in a 1-1 draw at Espanyol earlier on Saturday and are now six points off the pace with 57.\\n\\n\"It was difficult match. After the international break it\\'s always difficult,\" Mbappé told RMTV.\\n\\nThe hosts made a dominant start and opened the scoring after 32 minutes when Mbappé coolly chipped in a penalty, awarded after Óscar Rodríguez brought down Arda Güler.', 'score': 0.8773195, 'raw_content': None}, {'url': 'https://www.managingmadrid.com/2025/3/30/24396688/player-ratings-real-madrid-3-2-leganes-2025-la-liga', 'title': 'Player Ratings: Real Madrid 3-2 Leganes; 2025 La Liga', 'content': 'Raúl Asencio—7: Applauded by the Bernabeu on multiple occasions with good sweeping up defensively.\\n\\nFran García—6: Better on the offensive end, getting into the final third and playing some dagger crosses.\\n\\nEduardo Camavinga—6: Modric and Camavinga struggled to deal with Leganes counter attacks and Diego, playing as a #10 for Leganes, got the better of both of them. [...] Follow Managing Madrid online:\\n\\nSite search\\n\\nManaging Madrid main menu\\n\\nFiled under:\\n\\nPlayer Ratings: Real Madrid 3-2 Leganes; 2025 La Liga\\n\\nKylian Mbappe scores a brace to help Madrid secure a nervy 3-2 victory.\\n\\nShare this story\\n\\nShare\\nAll sharing options for:\\nPlayer Ratings: Real Madrid 3-2 Leganes; 2025 La Liga\\n\\nFull match player ratings below:\\n\\nAndriy Lunin—7: Not at fault for the goals, was left with the opposition taking a shot from near the six yard box. [...] Lucas Vázquez—4: Exposed in transition and lacking the speed and athleticism to cover the gaps he leaves when venturing forward. Needs a more “pessimistic” attitude when the ball is on the opposite flank, occupying better spots in ““rest defense”.\\n\\nAntonio Rudiger—5: Several unnecessary long distance shots to hurt Madrid’s rhythm and reinforce Leganes game plan. Playing with too many matches in his legs and it’s beginning to show.', 'score': 0.86954874, 'raw_content': None}], 'response_time': 2.3}), AIMessage(content='Based on the search results, I can provide you with information about the players who played in the Real Madrid vs Leganes match on March 29, 2025:\\n\\n**Real Madrid Starting XI:**\\n- Andriy Lunin (Goalkeeper)\\n- Lucas Vázquez (Defender)\\n- Antonio Rüdiger (Defender)\\n- Raúl Asencio (Defender)\\n- Fran García (Defender)\\n- Eduardo Camavinga (Midfielder)\\n- Arda Güler (Midfielder)\\n- Luka Modrić (Midfielder)\\n- Jude Bellingham (Midfielder) - Scored in the 47th minute\\n- Brahim Díaz (Forward)\\n- Kylian Mbappé (Forward) - Scored twice (32nd minute penalty, 76th minute free kick)\\n\\n**Real Madrid Substitutes who played:**\\n- Vinícius Júnior (came on in the 62nd minute)\\n- Rodrygo (came on in the 62nd minute)\\n- Federico Valverde (came on in the 72nd minute)\\n- Aurélien Tchouaméni (came on in the 81st minute)\\n\\n**Leganes Starting XI:**\\n- Marko Dmitrović (Goalkeeper)\\n- Víctor Rosier (Defender)\\n- Matija Nastasić (Defender)\\n- Sergio González (Captain, Defender)\\n- Juan Hernández (Defender, substituted in the 62nd minute)\\n- Renato Tapia (Midfielder)\\n- Juan Cruz (Midfielder)\\n- Darko Brašanac (Midfielder)\\n- Seydouba Cissé (Midfielder)\\n- Óscar Rodríguez (Midfielder)\\n- Dani Raba (Forward, scored in the 41st minute, substituted in the 86th minute)\\n\\n**Other Leganes players mentioned:**\\n- Diego García (Forward, scored in the match)\\n\\nThe match was a hard-fought 3-2 victory for Real Madrid, with goals from Mbappé (2) and Bellingham for Real Madrid, and Diego García and Dani Raba for Leganes.', additional_kwargs={}, response_metadata={'id': 'msg_01AHwx9j2fL97XCX1kGb7QWp', 'model': 'claude-3-7-sonnet-20250219', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 3940, 'output_tokens': 528}, 'model_name': 'claude-3-7-sonnet-20250219'}, id='run-e4137010-3046-4935-977f-26f9db99dba9-0', usage_metadata={'input_tokens': 3940, 'output_tokens': 528, 'total_tokens': 4468, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})]}, next=(), config={'configurable': {'thread_id': '3', 'checkpoint_ns': '', 'checkpoint_id': '1f00e5a3-1486-6e9a-800c-52cf0c7ce6da'}}, metadata={'source': 'loop', 'writes': {'chatbot_node': {'messages': [AIMessage(content='Based on the search results, I can provide you with information about the players who played in the Real Madrid vs Leganes match on March 29, 2025:\\n\\n**Real Madrid Starting XI:**\\n- Andriy Lunin (Goalkeeper)\\n- Lucas Vázquez (Defender)\\n- Antonio Rüdiger (Defender)\\n- Raúl Asencio (Defender)\\n- Fran García (Defender)\\n- Eduardo Camavinga (Midfielder)\\n- Arda Güler (Midfielder)\\n- Luka Modrić (Midfielder)\\n- Jude Bellingham (Midfielder) - Scored in the 47th minute\\n- Brahim Díaz (Forward)\\n- Kylian Mbappé (Forward) - Scored twice (32nd minute penalty, 76th minute free kick)\\n\\n**Real Madrid Substitutes who played:**\\n- Vinícius Júnior (came on in the 62nd minute)\\n- Rodrygo (came on in the 62nd minute)\\n- Federico Valverde (came on in the 72nd minute)\\n- Aurélien Tchouaméni (came on in the 81st minute)\\n\\n**Leganes Starting XI:**\\n- Marko Dmitrović (Goalkeeper)\\n- Víctor Rosier (Defender)\\n- Matija Nastasić (Defender)\\n- Sergio González (Captain, Defender)\\n- Juan Hernández (Defender, substituted in the 62nd minute)\\n- Renato Tapia (Midfielder)\\n- Juan Cruz (Midfielder)\\n- Darko Brašanac (Midfielder)\\n- Seydouba Cissé (Midfielder)\\n- Óscar Rodríguez (Midfielder)\\n- Dani Raba (Forward, scored in the 41st minute, substituted in the 86th minute)\\n\\n**Other Leganes players mentioned:**\\n- Diego García (Forward, scored in the match)\\n\\nThe match was a hard-fought 3-2 victory for Real Madrid, with goals from Mbappé (2) and Bellingham for Real Madrid, and Diego García and Dani Raba for Leganes.', additional_kwargs={}, response_metadata={'id': 'msg_01AHwx9j2fL97XCX1kGb7QWp', 'model': 'claude-3-7-sonnet-20250219', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 3940, 'output_tokens': 528}, 'model_name': 'claude-3-7-sonnet-20250219'}, id='run-e4137010-3046-4935-977f-26f9db99dba9-0', usage_metadata={'input_tokens': 3940, 'output_tokens': 528, 'total_tokens': 4468, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})]}}, 'thread_id': '3', 'step': 12, 'parents': {}}, created_at='2025-03-31T18:01:38.516127+00:00', parent_config={'configurable': {'thread_id': '3', 'checkpoint_ns': '', 'checkpoint_id': '1f00e5a2-c557-6fe0-800b-291da54f4727'}}, tasks=())"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config_USER3)\n",
    "snapshot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos ver el siguiente nodo a procesar, podemos usar el atributo `next`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot.next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dado que el grafo ha finalizado, `next` está vacío. Si obtienes un estado desde dentro de una invocación del grafo, next indica qué nodo se ejecutará a continuación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La instantánea anterior (`snapshot`) contiene los valores de estado actuales, la configuración correspondiente y el siguiente nodo (`next`) a procesar. En nuestro caso, el gráfico ha alcanzado el estado `END`, por eso `next` está vacío."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¡Felicidades!** Nuestro chatbot ahora puede mantener el estado de conversación en todas las sesiones gracias al sistema de puntos de control (`checkpoints`) de `LangGraph`. Esto abre posibilidades para interacciones más naturales y contextuales. El control de `LangGraph` incluso maneja estados de grafos complejos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human in the loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque un agente puede realizar tareas, para según que tareas, es necesario que haya una supervisión humana. A esto se le llama `human in the loop`. Así que vamos a ver cómo se puede hacer esto con `LangGraph`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La capa de [persistencia](https://langchain-ai.github.io/langgraph/concepts/persistence/) de `LangGraph` admite flujos de trabajo con humanos en el bucle, lo que permite que la ejecución se detenga y reanude en función de los comentarios de los usuarios. La interfaz principal de esta funcionalidad es la función [interrupt](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/#interrupt). Llamando a `interrupt` dentro de un nodo se detendrá la ejecución. La ejecución se puede reanudar, junto con la nueva aportación del humano, pasada en una primitiva [Command](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/#the-command-primitive). `interrupt` es similar al comando de Python `input()`, pero con algunas consideraciones extra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a repetir el código anterior, pero haremos un cambio, que es agregar una simple herramienta `human_assistance`. Esta herramienta utiliza `interrupt` para recibir información de un humano."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero cargamos los valores de las API KEYs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "HUGGINGFACE_TOKEN = os.getenv(\"HUGGINGFACE_LANGGRAPH\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_LANGGRAPH_API_KEY\")\n",
    "ANTRHOPIC_API_KEY = os.getenv(\"ANTHROPIC_LANGGRAPH_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la `tool` de búsqueda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "wrapper = TavilySearchAPIWrapper(tavily_api_key=TAVILY_API_KEY)\n",
    "search_tool = TavilySearchResults(api_wrapper=wrapper, max_results=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora creamos la `tool` de ayuda humana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command, interrupt\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def human_assistance(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Request assistance from a human expert. Use this tool ONLY ONCE per conversation.\n",
    "    After receiving the expert's response, you should provide an elaborated response to the user based on the information received\n",
    "    based on the information received, without calling this tool again.\n",
    "\n",
    "    Args:\n",
    "        query: The query to ask the human expert.\n",
    "\n",
    "    Returns:\n",
    "        The response from the human expert.\n",
    "    \"\"\"\n",
    "    human_response = interrupt({\"query\": query})\n",
    "    return human_response[\"data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LangGraph` obtiene información de las herramientas mediante la documentación de la herramienta, es decir, el docstring de la función. Por lo que es muy importante generar un buen docstring para la herramienta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una lista de `tools`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_list = [search_tool, human_assistance]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación el `LLM` con las `bind_tools` y lo añadimos al grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10be4b380>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from huggingface_hub import login\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"    # Disable LangSmith tracing\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "# Create the LLM\n",
    "# login(token=HUGGINGFACE_TOKEN)\n",
    "# MODEL = \"Qwen/Qwen2.5-72B-Instruct\"\n",
    "# model = HuggingFaceEndpoint(\n",
    "#     repo_id=MODEL,\n",
    "#     task=\"text-generation\",\n",
    "#     max_new_tokens=512,\n",
    "#     do_sample=False,\n",
    "#     repetition_penalty=1.03,\n",
    "# )\n",
    "# # Create the chat model\n",
    "# llm = ChatHuggingFace(llm=model)\n",
    "llm = ChatAnthropic(model=\"claude-3-7-sonnet-20250219\", api_key=ANTRHOPIC_API_KEY)\n",
    "\n",
    "# Modification: tell the LLM which tools it can call\n",
    "llm_with_tools = llm.bind_tools(tools_list)\n",
    "\n",
    "# Define the chatbot function\n",
    "def chatbot_function(state: State):\n",
    "    message = llm_with_tools.invoke(state[\"messages\"])\n",
    "    assert len(message.tool_calls) <= 1\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "# Add the chatbot node\n",
    "graph_builder.add_node(\"chatbot_node\", chatbot_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si te fijas, hemos cambiado la forma de definir la función `chatbot_function`, ya que ahora tiene que manejar la interrupción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadimos la `tool_node` al grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10be4b380>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "tool_node = ToolNode(tools=tools_list)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "graph_builder.add_conditional_edges(\"chatbot_node\", tools_condition)\n",
    "graph_builder.add_edge(\"tools\", \"chatbot_node\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadimos el nodo de `START` al grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10be4b380>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_edge(START, \"chatbot_node\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un `checkpointer` [MemorySaver](https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.memory.MemorySaver)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilamos el grafo con el `checkpointer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo representamos gráficamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Error al visualizar el grafo: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora solicitemos el chatbot con una pregunta que involucrará a la nueva herramienta `human_assistance`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I need some expert guidance for building an AI agent. Could you request assistance for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"I'd be happy to help you request expert assistance for building an AI agent. To make the request most useful, it would help to know more about your specific needs or challenges with AI agent development.\\n\\nLet me request assistance from a human expert on your behalf:\", 'type': 'text'}, {'id': 'toolu_01PnuA9NDYpqbUgJjWMnhCNu', 'input': {'query': 'The user is looking for guidance on building an AI agent. Could you provide expert advice on best practices, frameworks, or approaches for AI agent development? Any insights on architecture, tools, or common pitfalls would be helpful.'}, 'name': 'human_assistance', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  human_assistance (toolu_01PnuA9NDYpqbUgJjWMnhCNu)\n",
      " Call ID: toolu_01PnuA9NDYpqbUgJjWMnhCNu\n",
      "  Args:\n",
      "    query: The user is looking for guidance on building an AI agent. Could you provide expert advice on best practices, frameworks, or approaches for AI agent development? Any insights on architecture, tools, or common pitfalls would be helpful.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"I need some expert guidance for building an AI agent. Could you request assistance for me?\"\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver, el chatbot generó una llamada de herramienta de asistencia humana.\n",
    "\n",
    "``` markdown\n",
    "Tool Calls:\n",
    "  human_assistance (0)\n",
    " Call ID: 0\n",
    "  Args:\n",
    "    query: I need some expert guidance for building an AI agent. Could you provide advice on key considerations, best practices, and potential pitfalls to avoid?\n",
    "```\n",
    "\n",
    "pero luego la ejecución se ha interrumpido. Vamos a ver el estado del grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tools',)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "snapshot.next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que se detuvo en el nodo de `tools`. Analizamos cómo se ha definido la herramienta `human_assistance`.\n",
    "\n",
    "``` python\n",
    "from langgraph.types import Command, interrupt\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def human_assistance(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Request assistance from a human expert. Use this tool ONLY ONCE per conversation.\n",
    "    After receiving the expert's response, you should provide an elaborated response to the user based on the information received\n",
    "    based on the information received, without calling this tool again.\n",
    "\n",
    "    Args:\n",
    "        query: The query to ask the human expert.\n",
    "\n",
    "    Returns:\n",
    "        The response from the human expert.\n",
    "    \"\"\"\n",
    "    human_response = interrupt({\"query\": query})\n",
    "    return human_response[\"data\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llamando a la herramienta `interrupt` se detendrá la ejecución, similar al la función de Python `input()`.\n",
    "\n",
    "El progreso se mantiene en función de nuestra elección de [checkpointer](https://langchain-ai.github.io/langgraph/concepts/persistence/#checkpointer-libraries). Es decir, la elección de dónde se guarda el estado del grafo. Así que si estamos persistiendo (guardando el estado del grafo) con una base de datos como `Postgres`, podemos reanudar la ejecución en cualquier momento siempre y cuando la base de datos esté viva.\n",
    "\n",
    "Aquí estamos persistiendo (guardando el estado del grafo) con el puntero de verificación en memoria, por lo que podemos reanudar en cualquier momento mientras nuestro kernel de Python se esté ejecutando. En mi caso, mientras no resetee el kernel de mi Jupyter Notebook.\n",
    "\n",
    "Para reanudar la ejecución, pasamos un objeto [Command](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/#the-command-primitive) que contiene los datos esperados por la herramienta. El formato de estos datos se puede personalizar en función de nuestras necesidades. Aquí, solo necesitamos un diccionario con una key `data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"I'd be happy to help you request expert assistance for building an AI agent. To make the request most useful, it would help to know more about your specific needs or challenges with AI agent development.\\n\\nLet me request assistance from a human expert on your behalf:\", 'type': 'text'}, {'id': 'toolu_01PnuA9NDYpqbUgJjWMnhCNu', 'input': {'query': 'The user is looking for guidance on building an AI agent. Could you provide expert advice on best practices, frameworks, or approaches for AI agent development? Any insights on architecture, tools, or common pitfalls would be helpful.'}, 'name': 'human_assistance', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  human_assistance (toolu_01PnuA9NDYpqbUgJjWMnhCNu)\n",
      " Call ID: toolu_01PnuA9NDYpqbUgJjWMnhCNu\n",
      "  Args:\n",
      "    query: The user is looking for guidance on building an AI agent. Could you provide expert advice on best practices, frameworks, or approaches for AI agent development? Any insights on architecture, tools, or common pitfalls would be helpful.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: human_assistance\n",
      "\n",
      "We, the experts are here to help! We'd recommend you check out LangGraph to build your agent.It's much more reliable and extensible than simple autonomous agents.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thank you for your patience. I've received feedback from a human expert on AI agent development. Based on their recommendation:\n",
      "\n",
      "**Expert Recommendation for AI Agent Development:**\n",
      "\n",
      "The expert suggests using **LangGraph** as a framework for building your AI agent. LangGraph is highlighted as being more reliable and extensible than simpler autonomous agent approaches.\n",
      "\n",
      "**Why LangGraph might be beneficial:**\n",
      "- Greater reliability in agent behavior\n",
      "- More extensible architecture for complex tasks\n",
      "- Better structured approach than basic autonomous agents\n",
      "\n",
      "LangGraph is designed to help you create agents with more sophisticated reasoning and workflow capabilities, allowing for state management and complex decision-making processes.\n",
      "\n",
      "Would you like me to provide more information about LangGraph specifically, or are there particular aspects of AI agent development you're interested in learning more about?\n"
     ]
    }
   ],
   "source": [
    "human_response = (\n",
    "    \"We, the experts are here to help! We'd recommend you check out LangGraph to build your agent.\"\n",
    "    \"It's much more reliable and extensible than simple autonomous agents.\"\n",
    ")\n",
    "\n",
    "human_command = Command(resume={\"data\": human_response})\n",
    "\n",
    "events = graph.stream(human_command, config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, el chatbot ha esperado a que un humano le proporcione la respuesta y luego ha generado una respuesta basada en la información recibida. Le hemos pedido por la ayuda sobre un experto sobre cómo crear agentes, el humano le ha dicho que lo mejor es usar LangGraph, y el chatbot ha generado una respuesta basada en esa información."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero sigue teniendo la posibilidad de realizar búsquedas en la web. Así que ahora le vamos a pedir las últimas noticias sobre LangGraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What's the latest news about LangGraph?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"I'll search for the latest news about LangGraph for you:\", 'type': 'text'}, {'id': 'toolu_019tvCikWprw4kWhUNtoawAY', 'input': {'query': 'latest news about LangGraph AI framework updates 2023 2024'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_019tvCikWprw4kWhUNtoawAY)\n",
      " Call ID: toolu_019tvCikWprw4kWhUNtoawAY\n",
      "  Args:\n",
      "    query: latest news about LangGraph AI framework updates 2023 2024\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"LangChain State of AI 2024 Report\", \"url\": \"https://blog.langchain.dev/langchain-state-of-ai-2024/\", \"content\": \"As companies are getting more serious about incorporating AI agents across various industries, adoption of our controllable agent framework, LangGraph, is also on the rise. Since its release in March 2024, LangGraph has steadily gained traction — with 43% of LangSmith organizations are now sending LangGraph traces. These traces represent complex, orchestrated tasks that go beyond basic LLM interactions. [...] Few-shot prompting to improve tool-calling performance ------------------------------------------------------\\nBy LangChain 8 min read\\n\\nImproving core tool interfaces and docs in LangChain ----------------------------------------------------\\nBy LangChain 4 min read\\n\\nAnnouncing LangGraph v0.1 & LangGraph Cloud: Running agents at scale, reliably ------------------------------------------------------------------------------\\nBy LangChain 6 min read\\n\\nSign up\\n\\n© LangChain Blog 2024\", \"score\": 0.8815438}, {\"title\": \"Top 5 LangGraph Agents in Production 2024 - LangChain Blog\", \"url\": \"https://blog.langchain.dev/top-5-langgraph-agents-in-production-2024/\", \"content\": \"We launched LangGraph in early 2024 as a new take on an agentic framework. Incorporating lessons learned from LangChain, we made LangGraph very low level, controllable agentic framework. No hidden prompts, no obfuscated \\\"cognitive architecture\\\". Soon after it's launch, we saw LangGraph become the go-to default framework for agents.\", \"score\": 0.82761955}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here's the latest news about LangGraph based on my search:\n",
      "\n",
      "### Latest LangGraph Updates and News:\n",
      "\n",
      "1. **Official Release**: LangGraph was officially released in March 2024 as a controllable agent framework by LangChain.\n",
      "\n",
      "2. **Growing Adoption**: According to LangChain's State of AI 2024 Report, LangGraph has seen steady growth since its launch, with 43% of LangSmith organizations now sending LangGraph traces. These traces represent complex, orchestrated tasks beyond basic LLM interactions.\n",
      "\n",
      "3. **Version 0.1 Release**: LangChain announced LangGraph v0.1 along with LangGraph Cloud, which focuses on \"running agents at scale, reliably.\"\n",
      "\n",
      "4. **Framework Philosophy**: LangGraph was designed as a low-level, controllable agentic framework with \"no hidden prompts, no obfuscated cognitive architecture.\" This approach makes it more transparent and customizable than other agent frameworks.\n",
      "\n",
      "5. **Industry Recognition**: According to LangChain, LangGraph has quickly become the \"go-to default framework for agents\" since its launch in early 2024.\n",
      "\n",
      "6. **Production Use**: There are now multiple documented cases of LangGraph agents being used in production environments across various industries.\n",
      "\n",
      "This indicates that LangGraph is a relatively new but rapidly growing framework in the AI agent development space, with increasing adoption in production environments and ongoing development by LangChain.\n",
      "\n",
      "Would you like more specific information about any aspect of LangGraph or how to get started with it for your AI agent development?\n"
     ]
    }
   ],
   "source": [
    "user_input = \"What's the latest news about LangGraph?\"\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ha buscado las últimas noticias sobre LangGraph y ha generado una respuesta basada en la información recibida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personalización del estado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > Nota: Este apartado lo vamos a hacer usando Sonnet 3.7, ya que a día de la escritura del post, es el mejor modelo para uso con agentes, y es el único que entiende cuando tiene que llamar a las tools y cuando no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta ahora, hemos confiado en un estado simple con una entrada, una lista de mensajes. Se puede llegar lejos con este estado simple, pero si se desea definir un comportamiento complejo sin depender de la lista de mensajes, se pueden agregar campos adicionales al estado.\n",
    "\n",
    "Aquí vamos a ver un nuevo escenario, en el que el chatbot está utilizando la herramienta de búsqueda para encontrar información específica, y reenviándola a un ser humano para su revisión. Vamos a hacer que el chatbot investigue el cumpleaños de una entidad. Agregaremos `name` y `birthday` claves del estado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero cargamos los valores de las API KEYs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "HUGGINGFACE_TOKEN = os.getenv(\"HUGGINGFACE_LANGGRAPH\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_LANGGRAPH_API_KEY\")\n",
    "ANTHROPIC_TOKEN = os.getenv(\"ANTHROPIC_LANGGRAPH_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el nuevo estado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    name: str\n",
    "    birthday: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregar esta información al estado hace que sea fácilmente accesible por otros nodos del grafo (por ejemplo, un nodo downstram que almacena o procesa la información), así como la capa de persistencia del grafo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora creamos el grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la `tool` de búsqueda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "wrapper = TavilySearchAPIWrapper(tavily_api_key=TAVILY_API_KEY)\n",
    "search_tool = TavilySearchResults(api_wrapper=wrapper, max_results=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora creamos la tool de asistencia humana. En esta tool rellenaremos las claves de estado dentro de nuestra herramienta `human_assistance`. Esto permite a un ser humano revisar la información antes de que se almacene en el estado. Volveremos a usar `Command`, esta vez para emitir una actualización de estado desde el interior de nuestra herramienta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import InjectedToolCallId, tool\n",
    "\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "\n",
    "@tool\n",
    "# Note that because we are generating a ToolMessage for a state update, we\n",
    "# generally require the ID of the corresponding tool call. We can use\n",
    "# LangChain's InjectedToolCallId to signal that this argument should not\n",
    "# be revealed to the model in the tool's schema.\n",
    "def human_assistance(\n",
    "    name: str, birthday: str, tool_call_id: Annotated[str, InjectedToolCallId]\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Request assistance from a human expert. Use this tool ONLY ONCE per conversation.\n",
    "    After receiving the expert's response, you should provide an elaborated response to the user based on the information received\n",
    "    based on the information received, without calling this tool again.\n",
    "\n",
    "    Args:\n",
    "        query: The query to ask the human expert.\n",
    "\n",
    "    Returns:\n",
    "        The response from the human expert.\n",
    "    \"\"\"\n",
    "    human_response = interrupt(\n",
    "        {\n",
    "            \"question\": \"Is this correct?\",\n",
    "            \"name\": name,\n",
    "            \"birthday\": birthday,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # If the information is correct, update the state as-is.\n",
    "    if human_response.get(\"correct\", \"\").lower().startswith(\"y\"):\n",
    "        verified_name = name\n",
    "        verified_birthday = birthday\n",
    "        response = \"Correct\"\n",
    "\n",
    "    # Otherwise, receive information from the human reviewer.\n",
    "    else:\n",
    "        verified_name = human_response.get(\"name\", name)\n",
    "        verified_birthday = human_response.get(\"birthday\", birthday)\n",
    "        response = f\"Made a correction: {human_response}\"\n",
    "\n",
    "    # This time we explicitly update the state with a ToolMessage inside\n",
    "    # the tool.\n",
    "    state_update = {\n",
    "        \"name\": verified_name,\n",
    "        \"birthday\": verified_birthday,\n",
    "        \"messages\": [ToolMessage(response, tool_call_id=tool_call_id)],\n",
    "    }\n",
    "    \n",
    "    # We return a Command object in the tool to update our state.\n",
    "    return Command(update=state_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos usado [ToolMessage](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.tool.ToolMessage.html) que se usa para pasar el resultado de ejecutar una `tool` de nuevo a un modelo y [InjectedToolCallId](https://python.langchain.com/api_reference/core/tools/langchain_core.tools.base.InjectedToolCallId.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una lista de `tools`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_list = [search_tool, human_assistance]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación el `LLM` con las `bind_tools` y lo añadimos al grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10d62ad50>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from huggingface_hub import login\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"    # Disable LangSmith tracing\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "\n",
    "# Create the LLM\n",
    "# login(token=HUGGINGFACE_TOKEN)\n",
    "# MODEL = \"mistralai/Mistral-Small-3.1-24B-Instruct-2503\"\n",
    "# model = HuggingFaceEndpoint(\n",
    "#     repo_id=MODEL,\n",
    "#     task=\"text-generation\",\n",
    "#     max_new_tokens=512,\n",
    "#     do_sample=False,\n",
    "#     repetition_penalty=1.03,\n",
    "# )\n",
    "# Create the chat model\n",
    "# llm = ChatHuggingFace(llm=model)\n",
    "llm = ChatAnthropic(model=\"claude-3-7-sonnet-20250219\", api_key=ANTHROPIC_TOKEN)\n",
    "\n",
    "# Modification: tell the LLM which tools it can call\n",
    "llm_with_tools = llm.bind_tools(tools_list)\n",
    "\n",
    "# Define the chatbot function\n",
    "def chatbot_function(state: State):\n",
    "    message = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # Because we will be interrupting during tool execution,\n",
    "    # we disable parallel tool calling to avoid repeating any\n",
    "    # tool invocations when we resume.\n",
    "    assert len(message.tool_calls) <= 1\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "# Add the chatbot node\n",
    "graph_builder.add_node(\"chatbot_node\", chatbot_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadimos la `tool` al grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10d62ad50>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "tool_node = ToolNode(tools=tools_list)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "graph_builder.add_conditional_edges(\"chatbot_node\", tools_condition)\n",
    "graph_builder.add_edge(\"tools\", \"chatbot_node\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadimos el nodo de `START` al grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10d62ad50>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_edge(START, \"chatbot_node\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un `checkpointer` [MemorySaver](https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.memory.MemorySaver)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilamos el grafo con el `checkpointer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo representamos gráficamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Error al visualizar el grafo: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a pedir a nuestro chatbot que busque el \"cumpleaños\" de la biblioteca de `LangGraph`.\n",
    "\n",
    "Dirigiremos al chatbot hata la herramienta `human_assistance` una vez que tenga la información requerida. Los argumentos `name` y `birthday` son obligatorios para la herramienta `human_assistance`, así que obligan al chatbot a generar propuestas para estos campos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can you look up when LangGraph was released? When you have the answer, use the human_assistance tool for review.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"I'll help you find out when LangGraph was released. Let me search for that information first.\", 'type': 'text'}, {'id': 'toolu_01WdjhcH39pTnMbU5xP1Tzs3', 'input': {'query': 'when was LangGraph released date of launch'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_01WdjhcH39pTnMbU5xP1Tzs3)\n",
      " Call ID: toolu_01WdjhcH39pTnMbU5xP1Tzs3\n",
      "  Args:\n",
      "    query: when was LangGraph released date of launch\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"Introducing LangGraph - LangChain - Changelog\", \"url\": \"https://changelog.langchain.com/announcements/week-of-1-22-24-langchain-release-notes\", \"content\": \"AUTHOR:\\nThe LangChain Team\\nLangGraph\\n🤖🚀 Introducing LangGraph\\nDATE: January 22, 2024\\nAUTHOR: The LangChain Team\\nIntroducing LangGraph\\nWe just launched LangGraph, which helps customize your Agent Runtime. You can read more about it on the blog.\\nLangGraph helps construct a powerful agent executor that allows for loops in logic while keeping track of application state. Agents constructed with LangGraph can handle more ambiguous inputs and accomplish tasks more consistently. These agents can: [...] Products\\nLangChain LangSmith LangGraph\\nMethods\\nRetrieval Agents Evaluation\\nResources\\nBlog Case Studies LangChain Academy Community Experts Changelog\\nDocs\\nPython\\nLangChain LangSmith LangGraph\\nJavaScript\\nLangChain LangSmith LangGraph\\nCompany\\nAbout Careers \\nPricing\\nGet a demo\\nSign up\\nLangChain Changelog\\nSign up for our newsletter to stay up to date\\nThank you! Your submission has been received!\\nOops! Something went wrong while submitting the form.\\nBack to Announcements\\nDATE:\\nJanuary 22, 2024\", \"score\": 0.80771893}, {\"title\": \"LangGraph Studio: The first agent IDE | by Bhavik Jikadara - Medium\", \"url\": \"https://bhavikjikadara.medium.com/langgraph-studio-the-first-agent-ide-468132628274\", \"content\": \"LangGraph, launched in January 2023, is a low-level orchestration framework designed for building controllable and complex agentic applications.\", \"score\": 0.79561085}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Based on my search, I've found conflicting information about when LangGraph was released. One source indicates that LangGraph was launched on January 22, 2024, while another mentions January 2023. Let me submit this to a human expert for verification.\", 'type': 'text'}, {'id': 'toolu_018ue7nu8oBgN4XUbUWGrX9a', 'input': {'name': 'LangGraph release date verification', 'birthday': 'January 22, 2024'}, 'name': 'human_assistance', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  human_assistance (toolu_018ue7nu8oBgN4XUbUWGrX9a)\n",
      " Call ID: toolu_018ue7nu8oBgN4XUbUWGrX9a\n",
      "  Args:\n",
      "    name: LangGraph release date verification\n",
      "    birthday: January 22, 2024\n"
     ]
    }
   ],
   "source": [
    "user_input = (\n",
    "    \"Can you look up when LangGraph was released? \"\n",
    "    \"When you have the answer, use the human_assistance tool for review.\"\n",
    ")\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ha parado por el `interrupt` en la herramienta `human_assistance`. En este caso, el chatbot no identificó la fecha correcta, por lo que podemos introducirla nosotros mismos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Based on my search, I've found conflicting information about when LangGraph was released. One source indicates that LangGraph was launched on January 22, 2024, while another mentions January 2023. Let me submit this to a human expert for verification.\", 'type': 'text'}, {'id': 'toolu_018ue7nu8oBgN4XUbUWGrX9a', 'input': {'name': 'LangGraph release date verification', 'birthday': 'January 22, 2024'}, 'name': 'human_assistance', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  human_assistance (toolu_018ue7nu8oBgN4XUbUWGrX9a)\n",
      " Call ID: toolu_018ue7nu8oBgN4XUbUWGrX9a\n",
      "  Args:\n",
      "    name: LangGraph release date verification\n",
      "    birthday: January 22, 2024\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: human_assistance\n",
      "\n",
      "Made a correction: {'name': 'LangGraph', 'birthday': 'Jan 17, 2024'}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thank you for the expert verification. I can now provide you with the accurate information about LangGraph's release.\n",
      "\n",
      "LangGraph was officially released on January 17, 2024, not January 22 as one source suggested or January 2023 as another incorrectly stated. This is a relatively new framework from the LangChain team, designed for building controllable and complex agentic applications that can handle loops in logic while maintaining application state.\n",
      "\n",
      "The framework helps developers customize their Agent Runtime and build more sophisticated AI agents that can handle ambiguous inputs and accomplish tasks more consistently.\n"
     ]
    }
   ],
   "source": [
    "human_command = Command(\n",
    "    resume={\n",
    "        \"name\": \"LangGraph\",\n",
    "        \"birthday\": \"Jan 17, 2024\",\n",
    "    },\n",
    ")\n",
    "\n",
    "events = graph.stream(human_command, config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'LangGraph', 'birthday': 'Jan 17, 2024'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "\n",
    "{k: v for k, v in snapshot.values.items() if k in (\"name\", \"birthday\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actualización manual del estado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangGraph proporciona un alto grado de control sobre el estado de aplicación. Por ejemplo, en cualquier punto (incluso cuando se interrumpe), podemos soreescribir manualmente una key del estado usando `graph.update_state`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a actualizar el `name` del estado a `LangGraph (library)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f0067be-cd1d-6fd4-8006-fa5a987d1d2c'}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.update_state(config, {\"name\": \"LangGraph (library)\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si ahora vemos el estado con `graph.get_state(config)` veremos que el `name` se ha actualizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'LangGraph (library)', 'birthday': 'Jan 17, 2024'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "\n",
    "{k: v for k, v in snapshot.values.items() if k in (\"name\", \"birthday\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las actualizaciones de estado manuales generarán una traza en `LangSmith`. Se pueden usar para controlar flujos de trabajo de `human in the loop`, como se puede ver en esta [guía](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/edit-graph-state/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En un flujo de trabajo típico de un chatbot, el usuario interactúa con el chatbot una o más veces para realizar una tarea. En las secciones anteriores, vimos cómo agregar memoria y un `human in the loop` para poder verificar nuestro estado de gráfico y controlar las respuestas futuras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero, a lo mejor un usuario quiere comenzar desde una respuesta anterior y o quiere `ramificar` para explorar un resultado separado. Esto es útil para aplicaciones de agentes, cuando un flujo falla pueden volver a un checkpoint anterior y probar otra estrategia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LangGraph` da esta posibilidad mediante los `checkpoints`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero cargamos los valores de las API KEYs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "HUGGINGFACE_TOKEN = os.getenv(\"HUGGINGFACE_LANGGRAPH\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_LANGGRAPH_API_KEY\")\n",
    "ANTHROPIC_TOKEN = os.getenv(\"ANTHROPIC_LANGGRAPH_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el nuevo estado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora creamos el grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la `tool` de búsqueda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "wrapper = TavilySearchAPIWrapper(tavily_api_key=TAVILY_API_KEY)\n",
    "search_tool = TavilySearchResults(api_wrapper=wrapper, max_results=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una lista de `tools`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_list = [search_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación el `LLM` con las `bind_tools` y lo añadimos al grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10c34b380>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from huggingface_hub import login\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"    # Disable LangSmith tracing\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "\n",
    "# Create the LLM\n",
    "# login(token=HUGGINGFACE_TOKEN)\n",
    "# MODEL = \"Qwen/Qwen2.5-72B-Instruct\"\n",
    "# model = HuggingFaceEndpoint(\n",
    "#     repo_id=MODEL,\n",
    "#     task=\"text-generation\",\n",
    "#     max_new_tokens=512,\n",
    "#     do_sample=False,\n",
    "#     repetition_penalty=1.03,\n",
    "# )\n",
    "# # Create the chat model\n",
    "# llm = ChatHuggingFace(llm=model)\n",
    "llm = ChatAnthropic(model=\"claude-3-7-sonnet-20250219\", api_key=ANTHROPIC_TOKEN)\n",
    "\n",
    "# Modification: tell the LLM which tools it can call\n",
    "llm_with_tools = llm.bind_tools(tools_list)\n",
    "\n",
    "# Define the chatbot function\n",
    "def chatbot_function(state: State):\n",
    "    message = llm_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "# Add the chatbot node\n",
    "graph_builder.add_node(\"chatbot_node\", chatbot_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadimos la `tool` al grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10c34b380>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "tool_node = ToolNode(tools=tools_list)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "graph_builder.add_conditional_edges(\"chatbot_node\", tools_condition)\n",
    "graph_builder.add_edge(\"tools\", \"chatbot_node\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadimos el nodo de `START` al grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10c34b380>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_edge(START, \"chatbot_node\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un `checkpointer` [MemorySaver](https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.memory.MemorySaver)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilamos el grafo con el `checkpointer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo representamos gráficamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Error al visualizar el grafo: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hagamos que nuestro gráfico dé un par de pasos. Cada paso será guardado en el historial del estado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos la primera llamada al modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm learning LangGraph. Could you do some research on it for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"I'd be happy to research LangGraph for you. Let me search for some up-to-date information about it.\", 'type': 'text'}, {'id': 'toolu_011EHHsHURw6YLkeLmGv34Li', 'input': {'query': 'LangGraph framework AI programming language models'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_011EHHsHURw6YLkeLmGv34Li)\n",
      " Call ID: toolu_011EHHsHURw6YLkeLmGv34Li\n",
      "  Args:\n",
      "    query: LangGraph framework AI programming language models\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"Which AI Agent framework should i use? (CrewAI, Langgraph ...\", \"url\": \"https://medium.com/@aydinKerem/which-ai-agent-framework-i-should-use-crewai-langgraph-majestic-one-and-pure-code-e16a6e4d9252\", \"content\": \"2. LangGraph\\nLangGraph is a framework built upon the Langchain library and uses its many functions and tools. LangGraph utilizes graphs to create a multi-agent or single agent structure. Graph represents the general flow of the architecture. LangGraph is a tool designed to visualize and manage complex relationships and workflows involving language models by creating a graph-like representation of component interactions.\", \"score\": 0.8889231}, {\"title\": \"LangGraph Quickstart - GitHub Pages\", \"url\": \"https://langchain-ai.github.io/langgraph/tutorials/introduction/\", \"content\": \"[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-9-1)Assistant: LangGraph is a library designed to help build stateful multi-agent applications using language models. It provides tools for creating workflows and state machines to coordinate multiple AI agents or language model interactions. LangGraph is built on top of LangChain, leveraging its components while adding graph-based coordination capabilities. It's particularly useful for developing more complex, [...] [](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-6)   LangGraph is a library designed for building stateful, multi-actor applications with Large Language Models (LLMs). It's particularly useful for creating agent and multi-agent workflows.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-8)2. Developer: [...] [](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-20)2. Integration with Large Language Models (LLMs):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-21)   There's a tutorial that specifically mentions using Gemini 2.0 (Google's LLM) with LangGraph to build autonomous agents. This suggests that LangGraph can be integrated with various LLMs, giving you flexibility in choosing the language model that best fits your needs.\", \"score\": 0.8865877}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Let me gather more specific information about LangGraph's technical details and how it's used:\", 'type': 'text'}, {'id': 'toolu_018BhBRSY5QuRR8TWCmk3Ba6', 'input': {'query': 'LangGraph technical details state management agents workflows examples'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_018BhBRSY5QuRR8TWCmk3Ba6)\n",
      " Call ID: toolu_018BhBRSY5QuRR8TWCmk3Ba6\n",
      "  Args:\n",
      "    query: LangGraph technical details state management agents workflows examples\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"Workflows and Agents - GitHub Pages\", \"url\": \"https://langchain-ai.github.io/langgraph/tutorials/workflows/\", \"content\": \"Resources¶\\nExamples\\nHere is an assistant that uses evaluator-optimizer to improve a report. See our video here.\\nHere is a RAG workflow that grades answers for hallucinations or errors. See our video here.\\nExample Implementation¶\\n[](https://langchain-ai.github.io/langgraph/tutorials/workflows/#__codelineno-16-1)# Graph state\\n[](https://langchain-ai.github.io/langgraph/tutorials/workflows/#__codelineno-16-2)class State(TypedDict): [...] Resources¶\\nDocumentation\\nSee our documentation on parallelization here.\\nLangChain Academy\\nSee our lesson on parallelization here.\\nExample Implementation¶\\n[](https://langchain-ai.github.io/langgraph/tutorials/workflows/#__codelineno-7-1)# Graph state\\n[](https://langchain-ai.github.io/langgraph/tutorials/workflows/#__codelineno-7-2)class State(TypedDict):\\n[](https://langchain-ai.github.io/langgraph/tutorials/workflows/#__codelineno-7-3)    topic: str [...] [](https://langchain-ai.github.io/langgraph/tutorials/workflows/#__codelineno-7-9)\\n[](https://langchain-ai.github.io/langgraph/tutorials/workflows/#__codelineno-7-10)# Nodes\\n[](https://langchain-ai.github.io/langgraph/tutorials/workflows/#__codelineno-7-11)def call_llm_1(state: State):\\n[](https://langchain-ai.github.io/langgraph/tutorials/workflows/#__codelineno-7-12)\\\"\\\"\\\"First LLM call to generate initial joke\\\"\\\"\\\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/workflows/#__codelineno-7-13)\", \"score\": 0.7409441}, {\"title\": \"Building Agentic Flows with LangGraph & Model Context Protocol\", \"url\": \"https://www.qodo.ai/blog/building-agentic-flows-with-langgraph-model-context-protocol/\", \"content\": \"Built-in state management\\nOne challenge in multi-step workflows is tracking intermediate outputs without us manually juggling state at every step. LangGraph provides built-in state management under the hood, all you need is a session-ID and the rest is taken care of. This allows us to keep each node’s data accessible to subsequent steps.\", \"score\": 0.7125728}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': 'Let me look up how LangGraph relates to LangChain and its practical applications:', 'type': 'text'}, {'id': 'toolu_01BHxoJ9RFdZUWuskW2Gpf86', 'input': {'query': 'LangGraph vs LangChain differences comparison how to get started'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_01BHxoJ9RFdZUWuskW2Gpf86)\n",
      " Call ID: toolu_01BHxoJ9RFdZUWuskW2Gpf86\n",
      "  Args:\n",
      "    query: LangGraph vs LangChain differences comparison how to get started\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"LangChain vs. LangGraph: Choosing the Right Framework | Medium\", \"url\": \"https://medium.com/@tahirbalarabe2/langchain-vs-langgraph-choosing-the-right-framework-0e393513da3d\", \"content\": \"LangChain is generally easier to understand and implement, especially for simpler workflows. Its straightforward structure and pre-built integrations contribute to a quicker learning curve. LangGraph, with its focus on complex workflows and explicit state management, is more complicated and requires more time to master. The complexity arises from the need to manage intricate data flows, task dependencies, and potentially multi-agent interactions. [...] LangChain is designed for Directed Acyclic Graph (DAG) or linear workflows, making it suitable for step-by-step processes without iterations or cycles. While it supports simple branching, it does not natively handle iterations or loops. LangGraph, on the other hand, excels at managing complex, non-linear graph-style workflows. This includes nested branching, merging, iterations, cycles, and loops, making it ideal for agentic and multi-actor use cases. [...] LangChain employs implicit state management, automatically handling and passing relevant data (inputs, outputs) between steps without requiring explicit user-defined structures. This simplifies task chaining but limits fine-grained control over state transitions in complex workflows. LangGraph uses explicit state management, requiring developers to define, manage, and control the workflow’s state throughout execution. This offers fine-grained control over data flow, task dependencies, and\", \"score\": 0.9020676}, {\"title\": \"LangChain vs LangGraph: A Tale of Two Frameworks - YouTube\", \"url\": \"https://www.youtube.com/watch?v=qAF1NjEVHhY\", \"content\": \"the primary focus. Now the Primary focus of LangGraph Is to create and manage what is known as multi agent systems and workflows. The focus of LangChain is to provide an abstraction layer for chaining LLM operations into large language model applications. That's the difference between the two. Now, as for. Structure, LangChain adopts no surprise here a chain structure. And that acts as a Dag, that is an acronym for directed acyclic graph, Which means that tasks are executed in a specific order\", \"score\": 0.8974172}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on the research, here's what I've found about LangGraph:\n",
      "\n",
      "# LangGraph: An Overview\n",
      "\n",
      "## What is LangGraph?\n",
      "\n",
      "LangGraph is a framework designed for building stateful, multi-agent applications using Large Language Models (LLMs). It's built on top of LangChain but extends its capabilities with graph-based coordination features, making it particularly well-suited for complex workflows and agent coordination.\n",
      "\n",
      "## Key Features and Capabilities\n",
      "\n",
      "1. **Graph-Based Architecture**: \n",
      "   - Uses graphs to represent and manage workflows between components and agents\n",
      "   - Supports complex, non-linear workflows including loops, branches, and cycles\n",
      "   - Visualizes the interactions between different components\n",
      "\n",
      "2. **State Management**:\n",
      "   - Built-in explicit state management capabilities\n",
      "   - Makes intermediate outputs accessible to subsequent steps\n",
      "   - Requires only a session ID to track state automatically\n",
      "\n",
      "3. **Multi-Agent Systems**:\n",
      "   - Designed specifically for coordinating multiple AI agents\n",
      "   - Allows agents to communicate and collaborate in complex workflows\n",
      "   - Supports both single-agent and multi-agent architectures\n",
      "\n",
      "## LangGraph vs. LangChain\n",
      "\n",
      "While both are from the same ecosystem, they have distinct purposes:\n",
      "\n",
      "| Feature | LangChain | LangGraph |\n",
      "|---------|-----------|-----------|\n",
      "| Primary Focus | Abstraction layer for chaining LLM operations | Creating and managing multi-agent systems and workflows |\n",
      "| Workflow Type | Directed Acyclic Graph (DAG) or linear workflows | Complex, non-linear graph-style workflows |\n",
      "| State Management | Implicit state handling | Explicit state management |\n",
      "| Complexity | Generally easier to understand and implement | More complex, requires more time to master |\n",
      "| Best For | Simpler workflows, step-by-step processes | Complex workflows with iterations, cycles, and multi-agent interactions |\n",
      "\n",
      "## Getting Started with LangGraph\n",
      "\n",
      "LangGraph provides documentation and tutorials to help you get started. Based on the research, the workflow typically involves:\n",
      "\n",
      "1. Defining your state structure (using TypedDict or similar)\n",
      "2. Creating nodes that represent different components or agents\n",
      "3. Defining the relationships and transitions between nodes\n",
      "4. Managing state throughout the workflow execution\n",
      "\n",
      "## Practical Applications\n",
      "\n",
      "LangGraph is particularly useful for:\n",
      "- Building autonomous agents that can perform complex tasks\n",
      "- Creating workflows that require multiple iterations or feedback loops\n",
      "- Coordinating multiple AI agents working together on a task\n",
      "- Applications that need fine-grained control over state transitions\n",
      "- Projects requiring explicit management of workflow states\n",
      "\n",
      "## Resources\n",
      "\n",
      "There are several resources available to learn more about LangGraph:\n",
      "- Official documentation: https://langchain-ai.github.io/langgraph/\n",
      "- Tutorial examples including RAG workflows and assistants\n",
      "- LangChain Academy lessons on parallelization and other concepts\n",
      "\n",
      "Would you like me to dive deeper into any specific aspect of LangGraph, such as its implementation details, code examples, or specific use cases?\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    \"I'm learning LangGraph. \"\n",
    "                    \"Could you do some research on it for me?\"\n",
    "                ),\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora la segunda llamada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Ya that's helpful. Maybe I'll build an autonomous agent with it!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Building an autonomous agent with LangGraph sounds like a great idea! It's definitely one of the framework's strengths.\n",
      "\n",
      "Here's what you should know about building autonomous agents with LangGraph:\n",
      "\n",
      "## Getting Started with Autonomous Agents in LangGraph\n",
      "\n",
      "### Key Components for Your Agent\n",
      "\n",
      "1. **Agent State Management**\n",
      "   - Define a state class to track your agent's knowledge, progress, and goals\n",
      "   - LangGraph's explicit state management is perfect for this, as it helps you track context across multiple steps\n",
      "\n",
      "2. **Agent Decision-Making Flow**\n",
      "   - Design your agent's thinking process as a graph\n",
      "   - Include nodes for reasoning, planning, tool-calling, and action execution\n",
      "   - Use conditional edges to create dynamic workflows (e.g., \"if task complete, move to next task; if not, retry\")\n",
      "\n",
      "3. **Tools and Capabilities**\n",
      "   - Integrate external tools your agent can use (web search, data access, etc.)\n",
      "   - LangGraph works well with LangChain's tools ecosystem\n",
      "\n",
      "### Common Architectural Patterns\n",
      "\n",
      "1. **ReAct Pattern** (Reasoning + Acting)\n",
      "   - Create a loop where your agent:\n",
      "     - Observes the environment\n",
      "     - Thinks/reasons about next steps\n",
      "     - Takes actions\n",
      "     - Evaluates results\n",
      "\n",
      "2. **Planning-Execution Cycle**\n",
      "   - Have your agent create a plan first\n",
      "   - Execute steps of the plan\n",
      "   - Revise the plan as needed based on results\n",
      "\n",
      "3. **Self-Improvement Loop**\n",
      "   - Include evaluation nodes that critique the agent's own work\n",
      "   - Allow the agent to improve its outputs based on self-evaluation\n",
      "\n",
      "### Implementation Tips\n",
      "\n",
      "- Start with a simple, focused agent that does one thing well\n",
      "- Test thoroughly as you add complexity\n",
      "- Use LangGraph's visualization capabilities to debug your agent's workflow\n",
      "- Consider implementing feedback mechanisms to handle failed steps\n",
      "\n",
      "### Example Use Cases\n",
      "\n",
      "- Research assistants that gather, synthesize, and present information\n",
      "- Task automation agents that handle multi-step workflows\n",
      "- Personal assistants that can understand context and maintain conversations\n",
      "- Creative agents for content generation with refinement cycles\n",
      "- Problem-solving agents that break down complex issues\n",
      "\n",
      "Building with LangGraph gives you the ability to create agents with memory, planning capabilities, and sophisticated decision-making patterns - going well beyond what you could do with simple prompt chaining.\n",
      "\n",
      "If you decide to build your autonomous agent, I'd recommend starting with the LangGraph documentation and perhaps following one of their tutorials to get a feel for the framework before diving into your own custom implementation. Would you like more specific guidance on any particular aspect of autonomous agent development?\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    \"Ya that's helpful. Maybe I'll \"\n",
    "                    \"build an autonomous agent with it!\"\n",
    "                ),\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que hemos hecho dos llamadas al modelo, vamos a ver el historial del estado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Messages:  10 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  9 Next:  ('chatbot_node',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  8 Next:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  8 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  7 Next:  ('chatbot_node',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  6 Next:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  5 Next:  ('chatbot_node',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  4 Next:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  3 Next:  ('chatbot_node',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  2 Next:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  1 Next:  ('chatbot_node',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  0 Next:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "to_replay = None\n",
    "for state in graph.get_state_history(config):\n",
    "    print(\"Num Messages: \", len(state.values[\"messages\"]), \"Next: \", state.next)\n",
    "    print(\"-\" * 80)\n",
    "    if len(state.values[\"messages\"]) == 2:\n",
    "        # We are somewhat arbitrarily selecting a specific state based on the number of chat messages in the state.\n",
    "        to_replay = state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos guardado en `to_replay` el estado del grafo en cada iteración. Podemos volver a un estado pasado y continuar el flujo desde allí."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para reanudar el flujo en ese estado hay que usar el método `next`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('tools',)\n"
     ]
    }
   ],
   "source": [
    "print(to_replay.next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La configuración del checkpoint contiene el `checkpoint_id`, que es un timestamp del flujo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f00e610-5567-6dfc-8001-aa1ef75568f5'}}\n"
     ]
    }
   ],
   "source": [
    "print(to_replay.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dando este `checkpoint_id` a `LangGrah` carga el estado en ese momento del flujo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"I'd be happy to research LangGraph for you. Let me search for some up-to-date information about it.\", 'type': 'text'}, {'id': 'toolu_011EHHsHURw6YLkeLmGv34Li', 'input': {'query': 'LangGraph framework AI programming language models'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_011EHHsHURw6YLkeLmGv34Li)\n",
      " Call ID: toolu_011EHHsHURw6YLkeLmGv34Li\n",
      "  Args:\n",
      "    query: LangGraph framework AI programming language models\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"Which AI Agent framework should i use? (CrewAI, Langgraph ...\", \"url\": \"https://medium.com/@aydinKerem/which-ai-agent-framework-i-should-use-crewai-langgraph-majestic-one-and-pure-code-e16a6e4d9252\", \"content\": \"2. LangGraph\\nLangGraph is a framework built upon the Langchain library and uses its many functions and tools. LangGraph utilizes graphs to create a multi-agent or single agent structure. Graph represents the general flow of the architecture. LangGraph is a tool designed to visualize and manage complex relationships and workflows involving language models by creating a graph-like representation of component interactions.\", \"score\": 0.8889231}, {\"title\": \"LangGraph Quickstart - GitHub Pages\", \"url\": \"https://langchain-ai.github.io/langgraph/tutorials/introduction/\", \"content\": \"[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-9-1)Assistant: LangGraph is a library designed to help build stateful multi-agent applications using language models. It provides tools for creating workflows and state machines to coordinate multiple AI agents or language model interactions. LangGraph is built on top of LangChain, leveraging its components while adding graph-based coordination capabilities. It's particularly useful for developing more complex, [...] [](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-6)   LangGraph is a library designed for building stateful, multi-actor applications with Large Language Models (LLMs). It's particularly useful for creating agent and multi-agent workflows.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-8)2. Developer: [...] [](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-20)2. Integration with Large Language Models (LLMs):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-21)   There's a tutorial that specifically mentions using Gemini 2.0 (Google's LLM) with LangGraph to build autonomous agents. This suggests that LangGraph can be integrated with various LLMs, giving you flexibility in choosing the language model that best fits your needs.\", \"score\": 0.8865877}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Let me search for more specific information about LangGraph's features and implementation details.\", 'type': 'text'}, {'id': 'toolu_01RvuxX83WcqCgwKB3nXwimj', 'input': {'query': 'LangGraph tutorial state management agents examples langchain'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_01RvuxX83WcqCgwKB3nXwimj)\n",
      " Call ID: toolu_01RvuxX83WcqCgwKB3nXwimj\n",
      "  Args:\n",
      "    query: LangGraph tutorial state management agents examples langchain\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"LangGraph Tutorial: Building LLM Agents with LangChain's ... - Zep AI\", \"url\": \"https://www.getzep.com/ai-agents/langgraph-tutorial\", \"content\": \"This is just one example of how LangGraph agents work at a high level. You can create different combinations of nodes and edges to achieve your desired functionality.\\nPersistence\\nOne key LangGraph feature that distinguishes it from traditional LangChain agents is its built-in persistence mechanism. LangGraph introduces the concept of an agent state shared among all the nodes and edges in a workflow. This allows automatic error recovery, enabling the workflow to resume where it left off. [...] | Building a LangGraph agent | Creating a LangGraph agent is the best way to understand the core concepts of nodes, edges, and state. The LangGraph Python libraries are modular and provide the functionality to build a stateful graph by incrementally adding nodes and edges.\\nIncorporating tools enables an agent to perform specific tasks and access external information. For example, the ArXiv tool wrapper can return content from research papers. [...] LangGraph introduces cycling graphs, allowing agents to communicate with tools in a cyclic manner. For example, an agent may call a tool, retrieve information from the tool, and then call the same or another tool to retrieve follow-up information. Similarly, tools may call each other multiple times to share and refine information before passing it back to an agent. This differentiates it from DAG-based solutions.\\nHuman-in-the-loop capability\", \"score\": 0.82117355}, {\"title\": \"Complete Guide to Building LangChain Agents with the LangGraph ...\", \"url\": \"https://www.getzep.com/ai-agents/langchain-agents-langgraph\", \"content\": \"LangGraph efficiently manages short-term memory within conversations using state checkpoints. This approach is ideal for scenarios like basic customer support, where maintaining the context of the current interaction is sufficient.\\nExample - basic customer support\\n```python\\nfrom langgraph.graph import StateGraph, MessagesState, START, END\\nfrom langchain_core.messages import HumanMessage\\nclass State(TypedDict):\\n    messages: Annotated[list, add_messages]\\ndef support_agent(state: State): [...] For example, consider a workflow where an agent must process user input, perform a series of checks, and decide whether to continue processing or end the task based on the input length. The code below demonstrates the same.\\n```python\\nfrom langgraph.graph import StateGraph, MessagesState, START, END\\nDefine the state structure\\nclass State(TypedDict):\\n    messages: Annotated[list, add_messages]\\nDefine node functions\\ndef node1(state: State):\\n    input_msg = state['messages'][-1]['content'] [...] LangChain: Focuses on chaining tasks in a sequence, suitable for straightforward workflows.\\nLangGraph: Also focuses on chaining tasks but with added capabilities for handling complex workflows.\\n\\nState Management: \\n\\nLangChain: Provides basic memory management through context windows, which may struggle with maintaining state over long or complex interactions.\\nLangGraph: Offers advanced state management with persistent states across nodes.\\n\\nUse Case Fit:\", \"score\": 0.78886026}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': 'Let me gather more information about how LangGraph compares to other frameworks and its practical applications.', 'type': 'text'}, {'id': 'toolu_01WxLGchMgjc575reDX7oqbc', 'input': {'query': 'LangGraph vs LangChain differences state management implementation examples'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_01WxLGchMgjc575reDX7oqbc)\n",
      " Call ID: toolu_01WxLGchMgjc575reDX7oqbc\n",
      "  Args:\n",
      "    query: LangGraph vs LangChain differences state management implementation examples\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"LangChain vs. LangGraph: Choosing the Right Framework | Medium\", \"url\": \"https://medium.com/@tahirbalarabe2/langchain-vs-langgraph-choosing-the-right-framework-0e393513da3d\", \"content\": \"LangChain employs implicit state management, automatically handling and passing relevant data (inputs, outputs) between steps without requiring explicit user-defined structures. This simplifies task chaining but limits fine-grained control over state transitions in complex workflows. LangGraph uses explicit state management, requiring developers to define, manage, and control the workflow’s state throughout execution. This offers fine-grained control over data flow, task dependencies, and [...] LangChain is generally easier to understand and implement, especially for simpler workflows. Its straightforward structure and pre-built integrations contribute to a quicker learning curve. LangGraph, with its focus on complex workflows and explicit state management, is more complicated and requires more time to master. The complexity arises from the need to manage intricate data flows, task dependencies, and potentially multi-agent interactions. [...] Which framework offers more flexibility, and why?\\nLangGraph provides greater flexibility, particularly when dealing with complex workflows involving branching, nested conditions, merging, loops, and dynamic transitions that depend on runtime state. Although LangChain can handle simpler linear workflows and has limited support for branching, its lack of native support for iterations and complex state management makes it less adaptable to intricate scenarios.\", \"score\": 0.8934678}, {\"title\": \"Complete Guide to Building LangChain Agents with the LangGraph ...\", \"url\": \"https://www.getzep.com/ai-agents/langchain-agents-langgraph\", \"content\": \"LangChain: Focuses on chaining tasks in a sequence, suitable for straightforward workflows.\\nLangGraph: Also focuses on chaining tasks but with added capabilities for handling complex workflows.\\n\\nState Management: \\n\\nLangChain: Provides basic memory management through context windows, which may struggle with maintaining state over long or complex interactions.\\nLangGraph: Offers advanced state management with persistent states across nodes.\\n\\nUse Case Fit: [...] | Overview of LangChain vs. LangGraph | LangChain is a flexible framework for simple, linear LLM workflows, excelling in task chaining and modularity. LangGraph handles complex workflows through graph-based orchestration, persistent state management, and multi-agent coordination, making it better suited for advanced applications. | [...] LangChain is ideal for simpler, linear task chains, offering flexibility and modularity. In contrast, LangGraph shines in managing more complex workflows that require advanced orchestration and state management. The ability to handle persistent states and incorporate human-in-the-loop workflows further enhances its capability to build sophisticated AI agents.\", \"score\": 0.8891543}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on my research, here's a comprehensive overview of LangGraph:\n",
      "\n",
      "# LangGraph: A Comprehensive Overview\n",
      "\n",
      "## What is LangGraph?\n",
      "\n",
      "LangGraph is a framework designed for building stateful, multi-agent applications with Large Language Models (LLMs). It's built on top of LangChain, extending its capabilities with graph-based coordination and advanced state management features. The framework is particularly useful for developing complex, multi-step AI workflows that require coordination between multiple agents or components.\n",
      "\n",
      "## Key Features and Capabilities\n",
      "\n",
      "### 1. Graph-Based Architecture\n",
      "- Uses a graph structure to represent and manage workflows\n",
      "- Nodes represent individual tasks or agents\n",
      "- Edges define the relationships and transitions between nodes\n",
      "- Supports both directed acyclic graphs (DAGs) and cyclic graphs for complex interactions\n",
      "\n",
      "### 2. Advanced State Management\n",
      "- **Explicit State Management**: Requires developers to define, manage, and control workflow state\n",
      "- **Persistence Mechanism**: Built-in state persistence allowing for automatic error recovery\n",
      "- **State Checkpoints**: Efficiently manages short-term memory within conversations\n",
      "- Enables workflows to resume where they left off after interruptions\n",
      "\n",
      "### 3. Multi-Agent Support\n",
      "- Designed specifically for coordinating multiple AI agents\n",
      "- Enables agents to communicate with each other and with tools in a structured way\n",
      "- Supports human-in-the-loop capabilities for collaborative workflows\n",
      "\n",
      "### 4. Cycling Graphs\n",
      "- Allows agents to communicate with tools in a cyclic manner\n",
      "- Enables iterative refinement of information between agents and tools\n",
      "- Differentiates it from purely DAG-based solutions\n",
      "\n",
      "## LangGraph vs. LangChain\n",
      "\n",
      "### Architecture and Workflow Design\n",
      "- **LangChain**: Focuses on chaining tasks in a sequence, suitable for straightforward workflows\n",
      "- **LangGraph**: Handles complex workflows with branching, loops, and dynamic transitions\n",
      "\n",
      "### State Management\n",
      "- **LangChain**: Implicit state management with limited control over state transitions\n",
      "- **LangGraph**: Explicit state management offering fine-grained control over data flow\n",
      "\n",
      "### Complexity and Learning Curve\n",
      "- **LangChain**: Generally easier to understand and implement, especially for simpler workflows\n",
      "- **LangGraph**: More complex and requires more time to master but offers greater flexibility\n",
      "\n",
      "### Use Cases\n",
      "- **LangChain**: Ideal for simpler, linear task chains\n",
      "- **LangGraph**: Better for complex workflows requiring advanced orchestration and state management\n",
      "\n",
      "## Implementation Example\n",
      "\n",
      "Here's a simplified example of building a LangGraph agent:\n",
      "\n",
      "```python\n",
      "from langgraph.graph import StateGraph, MessagesState, START, END\n",
      "from langchain_core.messages import HumanMessage\n",
      "\n",
      "# Define the state structure\n",
      "class State(TypedDict):\n",
      "    messages: Annotated[list, add_messages]\n",
      "\n",
      "# Define node function\n",
      "def support_agent(state: State):\n",
      "    # Agent logic here\n",
      "    pass\n",
      "\n",
      "# Create a graph\n",
      "graph = StateGraph(State)\n",
      "\n",
      "# Add nodes\n",
      "graph.add_node(\"agent\", support_agent)\n",
      "\n",
      "# Define edges\n",
      "graph.add_edge(START, \"agent\")\n",
      "graph.add_edge(\"agent\", END)\n",
      "\n",
      "# Compile the graph\n",
      "app = graph.compile()\n",
      "```\n",
      "\n",
      "## When to Use LangGraph\n",
      "\n",
      "LangGraph is particularly useful when:\n",
      "1. Building complex, stateful applications with LLMs\n",
      "2. Coordinating multiple agents that need to interact with each other\n",
      "3. Implementing workflows with branching logic, loops, or conditional execution\n",
      "4. Requiring persistent state management across interactions\n",
      "5. Creating systems that need to recover from errors or interruptions\n",
      "6. Implementing human-in-the-loop workflows\n",
      "\n",
      "## Resources for Learning\n",
      "\n",
      "To continue learning about LangGraph, you might want to explore:\n",
      "1. The official LangGraph documentation and tutorials\n",
      "2. Example implementations showcasing different use cases\n",
      "3. Comparisons with other agent frameworks like CrewAI\n",
      "4. Integration examples with various LLMs such as Gemini 2.0\n",
      "\n",
      "Would you like me to dive deeper into any specific aspect of LangGraph, such as implementation details, specific use cases, or more advanced features?\n"
     ]
    }
   ],
   "source": [
    "# The `checkpoint_id` in the `to_replay.config` corresponds to a state we've persisted to our checkpointer.\n",
    "for event in graph.stream(None, to_replay.config, stream_mode=\"values\"):\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El grafo reanudó la ejecución desde el nodo `tool calls`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
