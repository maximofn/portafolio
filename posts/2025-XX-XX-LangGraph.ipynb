{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LangGraph` es un marco de orquestación de bajo nivel para construir agentes controlables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mientras que `LangChain` proporciona integraciones y componentes para agilizar el desarrollo de aplicaciones LLM, la biblioteca `LangGraph` permite la orquestación de agentes, ofreciendo arquitecturas personalizables, memoria a largo plazo y `human in the loop` para manejar de manera confiable tareas complejas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cómo funciona `LangGraph`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LangGraph` se basa en tres componentes:\n",
    "\n",
    " * **Nodos**: Representan las unidades de procesamiento de la aplicación, como llamar a un LLM, o a una herramienta. Son funciones de Python que se ejecutan cuando se llama al nodo.\n",
    "   * Toman el estado como entrada\n",
    "   * Realizan alguna operación\n",
    "   * Devuelven el estado actualizado\n",
    " * **Edges**: Representan las transiciones entre los nodos. Definen la lógica de cómo se va a ejecutar el grafo, es decir, qué nodo se va a ejecutar después de otro. Pueden ser:\n",
    "   * Directos: Van de un nodo a otro\n",
    "   * Condicionales: Dependen de una condición\n",
    " * **State**: Representa el estado de la aplicación, es decir, que contiene toda la información necesaria para la aplicación. Se mantiene durante la ejecución de la aplicación. Es definido por el usuario, así que hay que pensar muy bien qué se va a guardar en él."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![LangGraph concept](https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/LangGraph_concept.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos los grafos de `LangGraph` comienzan desde un nodo `START` y terminan en un nodo `END`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalación de LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para instalar `LangGraph` se puede usar pip:\n",
    "\n",
    "```bash\n",
    "pip install -U langgraph\n",
    "```\n",
    "\n",
    "o instalar desde conda:\n",
    "\n",
    "```bash\n",
    "conda install langgraph\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalación de módulo de Hugging Face y Anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a usar un modelo de lenguaje de `Hugging Face`, por lo que necesitamos instalar su paquete de langgraph.\n",
    "\n",
    "```bash\n",
    "pip install langchain-huggingface\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para una parte vamos a usar `Sonnet 3.7`, luego explicaremos por qué. Así que tambien instalamos el paquere de `Anthropic`.\n",
    "\n",
    "```bash\n",
    "pip install langchain_anthropic\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API KEY de Hugging Face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a usar `Qwen/Qwen2.5-72B-Instruct` a través de `Hugging Face Inference Endpoints`, por lo que necesitamos una API KEY."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder usar el `Inference Endpoints` de HuggingFace, lo primero que necesitas es tener una cuenta en HuggingFace. Una vez la tengas, hay que ir a [Access tokens](https://huggingface.co/settings/keys) en la configuración de tu perfil y generar un nuevo token.\n",
    "\n",
    "Hay que ponerle un nombre. En mi caso, le voy a poner `langgraph` y habilitar el permiso `Make calls to inference providers`. Nos creará un token que tendremos que copiar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para gestionar el token, vamos a crear un archivo en la misma ruta en la que estemos trabajando llamado`.env` y vamos a poner el token que hemos copiado en el archivo de la siguiente manera:\n",
    "\n",
    "``` bash\n",
    "HUGGINGFACE_LANGGRAPH=\"hf_....\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, para poder obtener el token, necesitamos tener instalado `dotenv`, que lo instalamos mediante\n",
    "\n",
    "```bash\n",
    "pip install python-dotenv\n",
    "```\n",
    "\n",
    "Y ejecutamos lo siguiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "HUGGINGFACE_TOKEN = os.getenv(\"HUGGINGFACE_LANGGRAPH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos un token, creamos un cliente. Para ello, necesitamos tener instalada la librería `huggingface_hub`. La instalamos mediante conda o pip.\n",
    "\n",
    "``` bash\n",
    "pip install --upgrade huggingface_hub\n",
    "```\n",
    "\n",
    "o\n",
    "\n",
    "``` bash\n",
    "conda install -c conda-forge huggingface_hub\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tenemos que elegir qué modelo vamos a usar. Puedes ver los modelos disponibles en la página de [Supported models](https://huggingface.co/docs/api-inference/supported-models) de la documentación de `Inference Endpoints` de Hugging Face.\n",
    "\n",
    "Vamos a usar `Qwen2.5-72B-Instruct` que es un modelo muy bueno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"Qwen/Qwen2.5-72B-Instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos crear el cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<InferenceClient(model='Qwen/Qwen2.5-72B-Instruct', timeout=None)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "client = InferenceClient(api_key=HUGGINGFACE_TOKEN, model=MODEL)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos una prueba a ver si funciona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Hola! Estoy bien, gracias por preguntar. ¿Cómo estás tú? ¿En qué puedo ayudarte hoy?\n"
     ]
    }
   ],
   "source": [
    "message = [\n",
    "\t{ \"role\": \"user\", \"content\": \"Hola, qué tal?\" }\n",
    "]\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "\tmessages=message, \n",
    "\ttemperature=0.5,\n",
    "\tmax_tokens=1024,\n",
    "\ttop_p=0.7,\n",
    "\tstream=False\n",
    ")\n",
    "\n",
    "response = stream.choices[0].message.content\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API KEY de Anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear un chatbot básico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear un chatbot simple usando `LangGraph`. Este chatbot responderá directamente a los mensajes del usuario. Aunque es simple, nos servirá para ver los conceptos básicos de la construcción de grafos con `LangGraph`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como su nomre indica, `LangGraph` es una biblioteca para manejar grafos. así que comenzamos creando un grafo [StateGraph](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.state.StateGraph).\n",
    "\n",
    "Un `StateGraph` define la estructura de nuestro chatbot como una `máquina de estados`. Agregaremos `nodos` para representar el `llm` y `funciones` a nuestro chatbot que podrá llamar y `edges` para especificar cómo el bot debe hacer la transición entre estas funciones o `nodos`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así que comenzamos creando un `StateGraph` que necesita una clase `State` para manejar el estado del grafo. Como ahora vamos a crear una chatbot sencillo, solo necesitamos manejar una lista de mensajes en el estado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función [add_messages](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.message.add_messages) une dos listas de mensajes.\n",
    "\n",
    "Llegarán nuevas listas de mensajes, por lo que se unirán a la lista de mensajes ya existente. Cada lista de mensajes contiene un `ID`, por lo que se agregan con este `ID`. Esto asegura que los mensajes solo se añaden, no se reemplazan, a no ser que un nuevo mensaje tenga el mismo `ID` que uno ya existente.\n",
    "\n",
    "`add_messages` es una [reducer function](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers), es una función que se encarga de actualizar el estado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El grafo `graph_builder` que hemos creado, recibe un estado `State` y devuelve un nuevo estado `State`. Además, actualiza la lista de mensajes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > **Concepto**\n",
    " >\n",
    " > Al definir un grafo, el primer paso es definir su `State`. El `State` incluye el esquema del grafo y las `reducer functions` que manejan actualizaciones del estado. \n",
    " > \n",
    " > En nuestro ejemplo, `State` es de tipo `TypedDict` (diccionario tipado) con una llave: `messages`.\n",
    " > \n",
    " > `add_messages` es una `reducer function` que se utiliza para agregar nuevos mensajes a la lista en lugar de sobrescribirlos en la lista. Si una llave de un estado no tiene una `reducer function`, cada valor que llegue de esa clave sobrescribirán los valores anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a agregar al grafo el nodo `chatbot`. Los nodos representan unidades de trabajo. Por lo general, son funciones regulares de `Python`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadimos un nodo con el método `add_node` que recibe el nombre del nodo y la función que se ejecutará."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De modo que vamos a crear un LLM con HuggingFace, después crearemos un chat model con `LangChain` que hará referencia al LLM creado. Una vez tenemos definido un chat model, definimos la función que se ejecutará en el nodo de nuestro grafo. Esa función hará una llamada al chat model creado y devolverá el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x11dd48440>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from huggingface_hub import login\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"    # Disable LangSmith tracing\n",
    "\n",
    "# Create the LLM model\n",
    "login(token=HUGGINGFACE_TOKEN)  # Login to HuggingFace to use the model\n",
    "MODEL = \"Qwen/Qwen2.5-72B-Instruct\"\n",
    "model = HuggingFaceEndpoint(\n",
    "    repo_id=MODEL,\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=512,\n",
    "    do_sample=False,\n",
    "    repetition_penalty=1.03,\n",
    ")\n",
    "# Create the chat model\n",
    "llm = ChatHuggingFace(llm=model)\n",
    "\n",
    "# Define the chatbot function\n",
    "def chatbot_function(state: State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# The first argument is the unique node name\n",
    "# The second argument is the function or object that will be called whenever\n",
    "# the node is used.\n",
    "graph_builder.add_node(\"chatbot_node\", chatbot_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos usado [ChatHuggingFace](https://python.langchain.com/api_reference/huggingface/chat_models/langchain_huggingface.chat_models.huggingface.ChatHuggingFace.html#langchain_huggingface.chat_models.huggingface.ChatHuggingFace) que es un chat del tipo [BaseChatModel](https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.chat_models.BaseChatModel.html#langchain_core.language_models.chat_models.BaseChatModel) que es un tipo de chat base de `LangChain`. Una vez hemos creado el `BaseChatModel`, hemos creado la función `chatbot_function` que se ejecutará cuando se ejecute el nodo. Y por último, hemos creado el nodo `chatbot_node` y le hemos indicado que tiene que ejecutar la función `chatbot_function`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > **Aviso** \n",
    " >\n",
    " > La función de nodo `chatbot_function` toma el estado `State` como entrada y devuelve un diccionario que contiene una actualización de la lista `messages` para la key `mensajes`. Este es el patrón básico para todas las funciones del nodo `LangGraph`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La `reducer function` de nuestro grafo `add_messages` agregará los mensajes de respuesta del `llm` a cualquier mensaje que ya esté en el estado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, agregamos un nodo `entry`. Esto le dice a nuestro grafo dónde empezar su trabajo cada vez que lo ejecutamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x11dd48440>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import START\n",
    "\n",
    "graph_builder.add_edge(START, \"chatbot_node\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del mismo modo, añadimos un nodo `finish`. Esto indica al grafo `cada vez que se ejecuta este nodo, puede terminar el trabajo.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x11dd48440>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import END\n",
    "\n",
    "graph_builder.add_edge(\"chatbot_node\", END)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos importado `START` y `END` que podemos encontrarlos en [constants](https://langchain-ai.github.io/langgraph/reference/constants/) y el primer y último nodo de nuestro grafo.\n",
    "\n",
    "Normalmente son nodos virtuales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, queremos poder ejecutar nuestro grafo. Para hacerlo, usamos el método constructor de grafos `compile()`. Esto crea un `CompiledGraph` que podemos usar para ejecutar nuestra aplicación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos visualizar el grafo usando el método `get_graph` y uno de los métodos de \"dibujo\", como `draw_ascii` o `draw_mermaid_png`. El dibujo de cada uno de los métodos requiere dependencias adicionales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Error al visualizar el grafo: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Ahora podemos probar el chatbot!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > **Consejo**\n",
    " >\n",
    " > Puedes salir del bucle de chat en cualquier momento escribiendo `quit`, `exit` o `q`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mUser: \u001b[0mHello\n",
      "\u001b[33mAssistant: \u001b[0mHello! It's nice to meet you. How can I assist you today? Whether you have questions, need information, or just want to chat, I'm here to help!\n",
      "\u001b[32mUser: \u001b[0mHow are you doing?\n",
      "\u001b[33mAssistant: \u001b[0mI'm just a computer program, so I don't have feelings, but I'm here and ready to help you with any questions or tasks you have! How can I assist you today?\n",
      "\u001b[32mUser: \u001b[0mMe well, I'm making a post about LangGraph, what do you think?\n",
      "\u001b[33mAssistant: \u001b[0mLangGraph is an intriguing topic, especially if you're delving into the realm of graph-based models and their applications in natural language processing (NLP). LangGraph, as I understand, is a framework or tool that leverages graph theory to improve or provide a new perspective on NLP tasks such as text classification, information extraction, and semantic analysis. By representing textual information as graphs (nodes for entities and edges for relationships), it can offer a more nuanced understanding of the context and semantics in language data.\n",
      "\n",
      "If you're making a post about it, here are a few points you might consider:\n",
      "\n",
      "1. **Introduction to LangGraph**: Start with a brief explanation of what LangGraph is and its core principles. How does it model language or text differently compared to traditional NLP approaches? What unique advantages does it offer by using graph-based methods?\n",
      "\n",
      "2. **Applications of LangGraph**: Discuss some of the key applications where LangGraph has been or can be applied. This could include improving the accuracy of sentiment analysis, enhancing machine translation, or optimizing chatbot responses to be more contextually aware.\n",
      "\n",
      "3. **Technical Innovations**: Highlight any technical innovations or advancements that LangGraph brings to the table. This could be about new algorithms, more efficient data structures, or novel ways of training models on graph data.\n",
      "\n",
      "4. **Challenges and Limitations**: It's also important to address the challenges and limitations of using graph-based methods in NLP. Performance, scalability, and the current state of the technology can be discussed here.\n",
      "\n",
      "5. **Future Prospects**: Wrap up with a look into the future of LangGraph and graph-based NLP in general. What are the upcoming trends, potential areas of growth, and how might these tools start impacting broader technology landscapes?\n",
      "\n",
      "Each section can help frame your post in a way that's informative and engaging for your audience, whether they're technical experts or casual readers looking for an introduction to this intriguing area of NLP.\n",
      "\u001b[32mUser: \u001b[0mq\n",
      "\u001b[33mAssistant: \u001b[0mGoodbye!\n"
     ]
    }
   ],
   "source": [
    "# Colors for the terminal\n",
    "COLOR_GREEN = \"\\033[32m\"\n",
    "COLOR_YELLOW = \"\\033[33m\"\n",
    "COLOR_RESET = \"\\033[0m\"\n",
    "\n",
    "\n",
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        for value in event.values():\n",
    "            print(f\"{COLOR_GREEN}User: {COLOR_RESET}{user_input}\")\n",
    "            print(f\"{COLOR_YELLOW}Assistant: {COLOR_RESET}{value['messages'][-1].content}\")\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(f\"{COLOR_GREEN}User: {COLOR_RESET}{user_input}\")\n",
    "            print(f\"{COLOR_YELLOW}Assistant: {COLOR_RESET}Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        events =stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**!Felicidades!** Has construido tu primer chatbot usando `LangGraph`. Este bot puede participar en una conversación básica tomando la entrada del usuario y generando respuestas utilizando el `LLM` que hemos definido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, este bot se limita a lo que hay en sus datos de entrenamiento. Así que vamos a agregar una herramienta de búsqueda web para expandir el conocimiento del bot y hacerlo más capaz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mejorar el chatbot con herramientas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para manejar algunas consultas, nuestro chatbot no puede responder `desde su conocimiento`, así que vamos a integrar una herramienta de búsqueda web. Nuestro bot puede utilizar esta herramienta para encontrar información relevante y proporcionar mejores respuestas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requisitos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de comenzar, tenemos que instalar el buscador [Tavily](https://python.langchain.com/docs/integrations/tools/tavily_search/) que es un buscador web que nos permite buscar información en la web.\n",
    "\n",
    "```bash\n",
    "pip install -U tavily-python langchain_community\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después, tenemos que crear una [API KEY](https://app.tavily.com/home), la escribimos en nuestro archivo `.env` y la cargamos en una variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "HUGGINGFACE_TOKEN = os.getenv(\"HUGGINGFACE_LANGGRAPH\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_LANGGRAPH_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, definimos la herramienta de búsqueda web mediante [TavilySearchResults](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.tavily_search.tool.TavilySearchResults.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "wrapper = TavilySearchAPIWrapper(tavily_api_key=TAVILY_API_KEY)\n",
    "tool = TavilySearchResults(api_wrapper=wrapper, max_results=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos la herramienta, vamos a hacer una búsqueda en internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://eu.api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://eu.api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'title': 'HIGHLIGHTS | Real Madrid 3-1 Manchester City | Champions League',\n",
       "  'url': 'https://www.youtube.com/watch?v=9zW_CKWb3oM',\n",
       "  'content': 'Real Madrid booked their place in the last 16 of the Champions League. The Whites followed up the impressive performance in the first leg by',\n",
       "  'score': 0.63939893},\n",
       " {'title': 'Real Madrid | History | UEFA Champions League',\n",
       "  'url': 'https://www.uefa.com/uefachampionsleague/history/clubs/50051--real-madrid/',\n",
       "  'content': '1955/56 P W D L Final 7 5 0 2\\nUEFA Champions League [...] 2010/11 P W D L Semi-finals 12 8 3 1\\n2009/10 P W D L Round of 16 8 4 2 2\\n2000s\\n2008/09 P W D L Round of 16 8 4 0 4\\n2007/08 P W D L Round of 16 8 3 2 3\\n2006/07 P W D L Round of 16 8 4 2 2\\n2005/06 P W D L Round of 16 8 3 2 3\\n2004/05 P W D L Round of 16 10 6 2 2\\n2003/04 P W D L Quarter-finals 10 6 3 1\\n2002/03 P W D L Semi-finals 16 7 5 4\\n2001/02 P W D L Final 17 12 3 2\\n2000/01 P W D L Semi-finals 16 9 2 5\\n1990s\\n1999/00 P W D L Final 17 10 3 4\\n1998/99 P W D L Quarter-finals 8 4 1 3 [...] 1969/70 P W D L Second round 4 2 0 2\\n1968/69 P W D L Second round 4 3 0 1\\n1967/68 P W D L Semi-finals 8 2 4 2\\n1966/67 P W D L Quarter-finals 4 1 0 3\\n1965/66 P W D L Final 9 5 2 2\\n1964/65 P W D L Quarter-finals 6 4 1 1\\n1963/64 P W D L Final 9 7 0 2\\n1962/63 P W D L Preliminary round 2 0 1 1\\n1961/62 P W D L Final 10 8 0 2\\n1960/61 P W D L First round 2 0 1 1\\n1950s\\n1959/60 P W D L Final 7 6 0 1\\n1958/59 P W D L Final 8 5 2 1\\n1957/58 P W D L Final 7 5 1 1\\n1956/57 P W D L Final 8 6 1 1',\n",
       "  'score': 0.6030211}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.invoke(\"What was the result of Real Madrid's at last match in the Champions League?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados son resúmenes de páginas que nuestro chatbot puede usar para responder preguntas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una lista de herramientas, porque nuestro grafo necesita definir las herramientas mediante una lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, comenzaremos a definir nuestro gráfico. Lo siguiente es todo lo mismo que antes, excepto que hemos añadido `bind_tools` en nuestro `LLM`. Esto le permite al `LLM` saber el formato `JSON` correcto para usar si desea usar el motor de búsqueda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos el grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación el `LLM` con las `bind_tools` y lo añadimos al grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x106a9ef90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from huggingface_hub import login\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"    # Disable LangSmith tracing\n",
    "\n",
    "# Create the LLM\n",
    "login(token=HUGGINGFACE_TOKEN)  # Login to HuggingFace to use the model\n",
    "MODEL = \"Qwen/Qwen2.5-72B-Instruct\"\n",
    "model = HuggingFaceEndpoint(\n",
    "    repo_id=MODEL,\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=512,\n",
    "    do_sample=False,\n",
    "    repetition_penalty=1.03,\n",
    ")\n",
    "# Create the chat model\n",
    "llm = ChatHuggingFace(llm=model)\n",
    "\n",
    "# Modification: tell the LLM which tools it can call\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# Define the chatbot function\n",
    "def chatbot_function(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "# Add the chatbot node\n",
    "graph_builder.add_node(\"chatbot_node\", chatbot_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, necesitamos crear una función para ejecutar las `tools` si se llaman. Agregamos las `tools` a un nuevo nodo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a implementar la clase `BasicToolNode`, que comprueba el mensaje más reciente en el estado y llama a las `tools` si el mensaje contiene `tool_calls`.\n",
    "\n",
    "Se basa en el soporte de `tool_calling` de los `LLM`s , que está disponible en `Anthropic`, `HuggingFace`, `Google Gemini` y varios otros proveedores de `LLM`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Más tarde reemplazaremos esto con el método [ToolNode](https://langchain-ai.github.io/langgraph/reference/prebuilt/#toolnode) de `LangGraph` para acelerar las cosas, pero primero lo construiremos nosotros mismos para entender cómo funciona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x106a9ef90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "class BasicToolNode:\n",
    "    \"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\n",
    "\n",
    "    def __init__(self, tools: list) -> None:\n",
    "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "    def __call__(self, inputs: dict):\n",
    "        if messages := inputs.get(\"messages\", []):\n",
    "            message = messages[-1]\n",
    "        else:\n",
    "            raise ValueError(\"No message found in input\")\n",
    "        outputs = []\n",
    "        for tool_call in message.tool_calls:\n",
    "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
    "                tool_call[\"args\"]\n",
    "            )\n",
    "            outputs.append(\n",
    "                ToolMessage(\n",
    "                    content=json.dumps(tool_result),\n",
    "                    name=tool_call[\"name\"],\n",
    "                    tool_call_id=tool_call[\"id\"],\n",
    "                )\n",
    "            )\n",
    "        return {\"messages\": outputs}\n",
    "\n",
    "\n",
    "basic_tool_node = BasicToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools_node\", basic_tool_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos usado [ToolMessage](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.tool.ToolMessage.html) que pasa el resultado de ejecutar una `tool` de nuevo al `LLM`.\n",
    "\n",
    "`ToolMessage` contiene el resultado de una invocación de una `tool`.\n",
    "\n",
    "Es decir, en cuanto tenemos el resultado de usar una `Tool` se lo pasamos al LLM para que lo procese"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el nodo de `basic_tool_node` (que es un objeto de la clase `BasicToolNode` que hemos creado) agregado al grafo, podemos definir los `conditional_edges`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El `enrutador` enruta el flujo de control de un nodo al siguiente. Los `conditional_edges` por lo general, contienen declaraciones `if` para enrutar a diferentes nodos dependiendo del estado actual del grafo.\n",
    "\n",
    "Estas funciones reciben el grafo actual `state` y devuelven una cadena o lista de cadenas que indican qué nodo o nodos llamar a continuación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a definir una función de enrutadora llamada `route_tools_function`, que comprueba si hay `tool_calls` en la salida del chatbot.\n",
    "\n",
    "Añadimos esta función al gráfico llamando `add_conditional_edges`, que le dice al grafo que cada vez que el nodo del `basic_tool_node` se ejecuta, se llama a la función para verificar a dónde ir a continuación.\n",
    "\n",
    "La condición se dirigirá a `tools_node` si las llamadas de herramientas están presentes y `END` si no.\n",
    "\n",
    "Más tarde, reemplazaremos esto con el método preconstruido `tools_condition` para ser más rápidos, pero ahora lo implementamos nosotros mismos primero ver cómo funciona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x106a9ef90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def route_tools_function(\n",
    "    state: State,\n",
    "):\n",
    "    \"\"\"\n",
    "    Use in the conditional_edge to route to the ToolNode if the last message\n",
    "    has tool calls. Otherwise, route to the end.\n",
    "    \"\"\"\n",
    "    # Get las message\n",
    "    if isinstance(state, list):\n",
    "        ai_message = state[-1]\n",
    "    elif messages := state.get(\"messages\", []):\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "    \n",
    "    # Router in function of last message\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        return \"tools_node\"\n",
    "    return END\n",
    "\n",
    "\n",
    "# The `tools_condition` function returns \"tools\" if the chatbot asks to use a tool, and \"END\" if\n",
    "# it is fine directly responding. This conditional routing defines the main agent loop.\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot_node\",\n",
    "    route_tools_function,\n",
    "    # The following dictionary lets you tell the graph to interpret the condition's outputs as a specific node\n",
    "    # It defaults to the identity function, but if you\n",
    "    # want to use a node named something else apart from \"tools\",\n",
    "    # You can update the value of the dictionary to something else\n",
    "    # e.g., \"tools\": \"my_tools\"\n",
    "    {\"tools_node\": \"tools_node\", END: END},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como el método de `LangGraph` ya existente `tools_condition`, nuestra función devuelve `END` si no se realizan llamadas de `tool`s. Cuando el grafo pasa a `END` éste no tiene más tareas que completar y cesa la ejecución."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como la condición puede devolver `END`, no necesitamos establecer explícitamente un `finish_point` esta vez. Nuestro grafo ya tiene una manera de terminar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x106a9ef90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_edge(\"tools_node\", \"chatbot_node\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadimos un otro nodo `edge`, pero en este caso incluye el uso de la `tool` o en final `END`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x106a9ef90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_edge(START, \"chatbot_node\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > **Aviso** \n",
    " >\n",
    " > Los `conditional_edge`s comienzan desde un solo nodo. Esto le dice al grafo \"en cualquier momento el 'chatbot' se ejecuta el nodo, ve a las 'tools' si se llama a una herramienta o termina el bucle si responde directamente\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilamos el grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos el grafo que hemos construido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Error al visualizar el grafo: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos hacer preguntas al bot fuera de sus datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mUser: \u001b[0mHow did Real Madrid fare this weekend against Leganes in La Liga?\n",
      "\u001b[33mAssistant: \u001b[0m[{'text': \"I'll check the recent match result between Real Madrid and Leganes in La Liga for you.\", 'type': 'text'}, {'id': 'toolu_01Kt4DSDCFDfXp6uRf417Rz8', 'input': {'query': 'Real Madrid vs Leganes La Liga result this weekend'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "\u001b[32mUser: \u001b[0mHow did Real Madrid fare this weekend against Leganes in La Liga?\n",
      "\u001b[33mAssistant: \u001b[0m[{\"title\": \"Real Madrid 3-2 Leganes: Goals and highlights - LaLiga 24/25 | Marca\", \"url\": \"https://www.marca.com/en/soccer/laliga/r-madrid-leganes/2025/03/29/01_0101_20250329_186_957-live.html\", \"content\": \"The two teams have already played twice this season, with Real Madrid securing a 3-0 win in the reverse league fixture. They also met in the quarter-finals of the Copa del Rey, a game Real won 3-2.\\n\\nReal Madrid vs Leganes LIVE - Latest Updates\\n\\nMatch ends, Real Madrid 3, Leganes 2.\\n\\nSecond Half ends, Real Madrid 3, Leganes 2.\\n\\nFoul by Vin\\u00edcius J\\u00fanior (Real Madrid).\\n\\nSeydouba Ciss\\u00e9 (Leganes) wins a free kick in the defensive half. [...] While their form has varied throughout the campaign there is no denying Real Madrid are a force at home in LaLiga this season, as they head into Saturday's match having picked up 34 points from 13 matches.\\n\\nAs for Leganes they currently sit 18th in the table, though they are level with Alaves for 17th as both teams look to stay in the top flight. [...] Goal! Real Madrid 1, Leganes 1. Diego Garc\\u00eda (Leganes) left footed shot from very close range.\\n\\nAttempt missed. \\u00d3scar Rodr\\u00edguez (Leganes) left footed shot from the centre of the box.\\n\\nGoal! Real Madrid 1, Leganes 0. Kylian Mbapp\\u00e9 (Real Madrid) converts the penalty with a right footed shot.\\n\\nPenalty Real Madrid. Arda G\\u00fcler draws a foul in the penalty area.\\n\\nPenalty conceded by \\u00d3scar Rodr\\u00edguez (Leganes) after a foul in the penalty area.\\n\\nDelay over. They are ready to continue.\", \"score\": 0.8742601}, {\"title\": \"Real Madrid 3-2 Legan\\u00e9s (Mar 29, 2025) Game Analysis - ESPN\", \"url\": \"https://www.espn.com/soccer/report/_/gameId/704946\", \"content\": \"Real Madrid\\n\\nLegan\\u00e9s\\n\\nMbapp\\u00e9 nets twice to keep Real Madrid's title hopes alive\\n\\nReal Madrid vs. Legan\\u00e9s - Game Highlights\\n\\nWatch the Game Highlights from Real Madrid vs. Legan\\u00e9s, 03/30/2025\\n\\nReal Madrid's Kylian Mbapp\\u00e9 struck twice to help his side come from behind to claim a hard-fought 3-2 home win over relegation-threatened Leganes on Saturday to move the second-placed reigning champions level on points with leaders Barcelona. [...] Leganes pushed for an equaliser but fell to a third consecutive defeat to sit 18th on 27 points, level with Alaves who are one place higher in the safety zone on goal difference.\\n\\n\\\"We have done a tremendous job. We leave with our heads held high because we were fighting until the end to score here,\\\" Leganes striker Garcia said.\\n\\n\\\"Ultimately, it was down to the details that they took it. We played a very serious game and now we have to think about next week.\\\"\\n\\nGame Information\", \"score\": 0.8682137}]\n",
      "\u001b[32mUser: \u001b[0mHow did Real Madrid fare this weekend against Leganes in La Liga?\n",
      "\u001b[33mAssistant: \u001b[0mBased on the search results, I can provide you with information about the Real Madrid vs Leganes match from this weekend:\n",
      "\n",
      "Real Madrid defeated Leganes 3-2 in their La Liga match on Saturday (March 29, 2025).\n",
      "\n",
      "Key details from the match:\n",
      "- Kylian Mbappé was a standout performer for Real Madrid, scoring twice\n",
      "- Real Madrid had to come from behind to secure the win\n",
      "- The match was hard-fought against relegation-threatened Leganes\n",
      "- Mbappé opened the scoring with a penalty\n",
      "- Diego García scored for Leganes to make it 1-1 at one point\n",
      "\n",
      "This victory helped Real Madrid move level on points with league leaders Barcelona. Meanwhile, Leganes remain in the relegation zone, sitting 18th in the table with 27 points, level with Alaves who are one place higher in the safety zone on goal difference.\n",
      "\n",
      "This was the third meeting between these teams this season, with Real Madrid having won the reverse league fixture 3-0 and a Copa del Rey quarter-final 3-2 earlier in the season.\n",
      "\u001b[32mUser: \u001b[0mWhich players played?\n",
      "\u001b[33mAssistant: \u001b[0mI need more context to answer your question. \"Which players played?\" is quite general and could refer to:\n",
      "\n",
      "- A specific game or match\n",
      "- A particular sport\n",
      "- A specific tournament or competition\n",
      "- A certain time period\n",
      "\n",
      "Could you please provide more details about which game, sport, or event you're asking about? This would help me search for the right information about the players who participated.\n",
      "\u001b[32mUser: \u001b[0mq\n",
      "\u001b[33mAssistant: \u001b[0mGoodbye!\n"
     ]
    }
   ],
   "source": [
    "# Colors for the terminal\n",
    "COLOR_GREEN = \"\\033[32m\"\n",
    "COLOR_YELLOW = \"\\033[33m\"\n",
    "COLOR_RESET = \"\\033[0m\"\n",
    "\n",
    "\n",
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        for value in event.values():\n",
    "            print(f\"{COLOR_GREEN}User: {COLOR_RESET}{user_input}\")\n",
    "            print(f\"{COLOR_YELLOW}Assistant: {COLOR_RESET}{value['messages'][-1].content}\")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(f\"{COLOR_GREEN}User: {COLOR_RESET}{user_input}\")\n",
    "            print(f\"{COLOR_YELLOW}Assistant: {COLOR_RESET}Goodbye!\")\n",
    "            break\n",
    "\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ves, primero le he preguntado cómo quedó el Real Madrid en su último partido en la Liga contra el Villareal, como es algo de actualidad, ha decidido usar la herramienta de búsqueda, con lo que ha obtenido el resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, a continuación le he preguntado qué jugadores jugaron y no sabía de qué le hablaba, eso es porque no se mantiene el contexto de la conversación. Así que lo siguiente que vamos a hacer es agregar una memoria al agente para que pueda mantener el contexto de la conversación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agregar memoria al chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro chatbot ahora puede usar herramientas para responder preguntas de los usuarios, pero no recuerda el contexto de las interacciones anteriores. Esto limita su capacidad de tener conversaciones coherentes y de múltiples tandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LangGraph` resuelve este problema a través de puntos de control persistentes o `checkpoints`. Si le proporcionamos un `checkpointer` al compilar el grafo y un `thread_id` al llamar al grafo, `LangGraph` guarda automáticamente el estado después de cada iteración en la conversación.\n",
    "\n",
    "Cuando invoquemos el grafo nuevamente usando el mismo `thread_id`, el grafo cargará su estado guardado, permitiendo que el chatbot continúe donde lo dejó."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veremos más tarde que ese `checkpointing` es mucho más potente que la simple memoria de chat: le permite guardar y reanudar estados complejos en cualquier momento para la recuperación de errores, flujos de trabajo con `human in the loop`, interacciones en el tiempo y más. Pero de ver todo eso, vamos a agregar puntos de control para permitir conversaciones de varias iteraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "HUGGINGFACE_TOKEN = os.getenv(\"HUGGINGFACE_LANGGRAPH\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_LANGGRAPH_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para empezar, creamos un `checkpointer` [MemorySaver](https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.memory.MemorySaver)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > **Aviso**\n",
    " >\n",
    " > Estamos usando un `checkpointer` en memoria. Esto es conveniente para nuestro caso, ya que lo guarda todo en memoria la memoria del ordenador. En una aplicación de producción, es probable que se necesite cambiar esto para usarlo con `SqliteSaver` o `PostgresSaver` y conéctarnos a nuestra propia base de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, definimos el grafo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos el grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la `tool`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "wrapper = TavilySearchAPIWrapper(tavily_api_key=TAVILY_API_KEY)\n",
    "tool = TavilySearchResults(api_wrapper=wrapper, max_results=2)\n",
    "tools = [tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación el `LLM` con las `bind_tools` y lo añadimos al grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x107e0a270>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from huggingface_hub import login\n",
    "\n",
    "login(token=HUGGINGFACE_TOKEN)\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"    # Disable LangSmith tracing\n",
    "\n",
    "# Create the LLM\n",
    "MODEL = \"Qwen/Qwen2.5-72B-Instruct\"\n",
    "model = HuggingFaceEndpoint(\n",
    "    repo_id=MODEL,\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=512,\n",
    "    do_sample=False,\n",
    "    repetition_penalty=1.03,\n",
    ")\n",
    "# Create the chat model\n",
    "llm = ChatHuggingFace(llm=model)\n",
    "\n",
    "# Modification: tell the LLM which tools it can call\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# Define the chatbot function\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "# Add the chatbot node\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que ya hemos construido el nuestro `BasicToolNode`, lo reemplazaremos con el método de LangGraph `ToolNode` y `tools_condition`, ya que estos hacen algunas cosas buenas como la ejecución paralela de API. Aparte de eso, el resto es igual que antes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x107e0a270>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadimos el nodo de `tools_condition` al grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x107e0a270>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadimos el nodo de `tools` al grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x107e0a270>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_edge(\"tools\", \"chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadimos el nodo de `START` al grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x107e0a270>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_edge(START, \"chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilamos el grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo representamos gráficamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Error al visualizar el grafo: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una configuración con un `thread_id` de un usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER1_THREAD_ID = \"1\"\n",
    "config_USER1 = {\"configurable\": {\"thread_id\": USER1_THREAD_ID}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi there! My name is Maximo.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Maximo! It's nice to meet you. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Hi there! My name is Maximo.\"\n",
    "\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config_USER1,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Remember my name?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (0)\n",
      " Call ID: 0\n",
      "  Args:\n",
      "    query: query for information about recent events or current news topics. Useful for answering questions about current events or news. Does not include ads. Input should be a search query. For example, you can use a query term like\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"SQL Query wildcard search - Stack Overflow\", \"url\": \"https://stackoverflow.com/questions/5290554/sql-query-wildcard-search\", \"content\": \"Use the LIKE operator. SELECT * FROM Table WHERE PhoneNumber LIKE '%value%' OR Name LIKE '%value%' OR City LIKE '%value%'\", \"score\": 0.17604777}, {\"title\": \"What the hell is wrong with google search? : r/degoogle - Reddit\", \"url\": \"https://www.reddit.com/r/degoogle/comments/106fru1/what_the_hell_is_wrong_with_google_search/\", \"content\": \"I've been a strong user of Android since the Samsung Galaxy S3. Used google search since dial-up internet was the norm.\", \"score\": 0.13990518000000002}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Of course, Maximo! I remember your name. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Remember my name?\"\n",
    "\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config_USER1,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver, no hemos pasado una lista con los mensakes, todo está siendo gestionado por el `checkpointer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si ahora probamos con otro usuario, es decir, con otro `thread_id`, veremos que el grafo no recuerda la conversación anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Remember my name?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'm sorry, I don't have a specific name to recall as our conversations are not tracked for personal information. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "USER2_THREAD_ID = \"2\"\n",
    "config_USER2 = {\"configurable\": {\"thread_id\": USER2_THREAD_ID}}\n",
    "\n",
    "user_input = \"Remember my name?\"\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config_USER2,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que nuestro chatbot tiene herramientas de búsqueda y memoria, vamos a repetir el ejemplo anterior, donde le pregunto por el resultado del último partido del Real Madrid en la Liga y luego por qué jugadores jugaron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "How did Real Madrid fare this weekend against Villareal in La Liga?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (0)\n",
      " Call ID: 0\n",
      "  Args:\n",
      "    query: Real Madrid vs Villareal La Liga weekend result\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"Real Madrid 2-1 Villarreal (Mar 15, 2025) Game Analysis - ESPN\", \"url\": \"https://www.espn.com/soccer/report/_/gameId/704939\", \"content\": \"Kylian Mbappé scored twice to help Real Madrid fight back to beat Villarreal 2-1 on Saturday and move provisionally top of the LaLiga standings.\", \"score\": 0.8724455}, {\"title\": \"Real Madrid 2-1 Villarreal (15 Mar, 2025) Final Score - ESPN Global\", \"url\": \"https://global.espn.com/football/match/_/gameId/704939/real-madrid-villarreal\", \"content\": \"Kylian Mbappé scored twice to help Real Madrid fight back to beat Villarreal 2-1 on Saturday and move provisionally top of the LaLiga standings.\", \"score\": 0.7700667911111111}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Real Madrid defeated Villarreal 2-1, with Kylian Mbappé scoring both goals, which moved Real Madrid provisionally to the top of LaLiga standings.\n"
     ]
    }
   ],
   "source": [
    "USER3_THREAD_ID = \"3\"\n",
    "config_USER3 = {\"configurable\": {\"thread_id\": USER3_THREAD_ID}}\n",
    "\n",
    "user_input = \"How did Real Madrid fare this weekend against Villareal in La Liga?\"\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config_USER3,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora le preguntamos por los jugadores que jugaron en el partido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Which players played against Villareal?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (0)\n",
      " Call ID: 0\n",
      "  Args:\n",
      "    query: Real Madrid Villareal squad list match 15 Mar 2025\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"Villarreal v Real Madrid | March 15, 2025 | Goal.com US\", \"url\": \"https://www.goal.com/en-us/match/villarreal-vs-real-madrid/lineups/B_4aE8NTdMuaWGZQjye8h\", \"content\": \"Substitutes · 43. D. Aguado · 4. D. Alaba · 16. Endrick · 26. F. Gonzalez · 22. A. Ruediger. 61' · 13. A. Lunin · 45. V. Valdepenas · 7. Vinicius Junior.\", \"score\": 0.8891543}, {\"title\": \"Real Madrid squad for Villarreal match\", \"url\": \"https://www.realmadrid.com/en-US/news/football/first-team/squad-call/convocatoria-del-real-madrid-contra-el-villarreal-14-03-2025\", \"content\": \"Midfielders: Bellingham, Camavinga, Valverde, Modrić, Tchouameni and Arda Güler. Forwards: Vini Jr., Mbappé, Rodrygo, Endrick and Brahim.\", \"score\": 0.7188278125}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (0)\n",
      " Call ID: 0\n",
      "  Args:\n",
      "    query: which real Madrid players played against Villareal?\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"Real Madrid announce squad for LaLiga match against Villarreal\", \"url\": \"https://www.managingmadrid.com/2025/3/14/24385700/villarreal-real-madrid-2025-liga-squad-list\", \"content\": \"Goalkeepers: Courtois, Lunin y Fran González. Defenders: Alaba, Lucas V., Fran García, Rüdiger, Asencio, Diego Aguado y Valdepeñas. Midfielders:\", \"score\": 0.7763013}, {\"title\": \"Real Madrid player ratings from 2-1 win vs Villarreal in LaLiga\", \"url\": \"https://therealchamps.com/real-madrid-player-ratings-from-2-1-win-vs-villarreal-in-laliga-01jpdehskd0y\", \"content\": \"Real Madrid player ratings from 2-1 win vs Villarreal in LaLiga · GK Thibaut Courtois · RB Lucas Vazquez · CB Raul Asencio · CB Aurelien Tchouameni.\", \"score\": 0.7348644}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (0)\n",
      " Call ID: 0\n",
      "  Args:\n",
      "    query: Real Madrid vs Villarreal match lineup March 15, 2025\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"Villarreal v Real Madrid | March 15, 2025 | Goal.com US\", \"url\": \"https://www.goal.com/en-us/match/villarreal-vs-real-madrid/lineups/B_4aE8NTdMuaWGZQjye8h\", \"content\": \"Substitutes · 43. D. Aguado · 4. D. Alaba · 16. Endrick · 26. F. Gonzalez · 22. A. Ruediger. 61' · 13. A. Lunin · 45. V. Valdepenas · 7. Vinicius Junior.\", \"score\": 0.9368016}, {\"title\": \"Villarreal vs. Real Madrid final score: La Liga result, updates, stats ...\", \"url\": \"https://www.sportingnews.com/us/soccer/news/villarreal-vs-real-madrid-score-result-updates-stats-la-liga/67cd5249ed55e513dcbfd906\", \"content\": \"— Villarreal CF (@VillarrealCF) March 15, 2025. 1 hr 30 mins before kickoff: Here's the Madrid lineup. Plenty of changes from Carlo Ancelotti\", \"score\": 0.7115741333333333}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The starting lineup for Real Madrid against Villarreal included the following players:\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">Goalkeepers: Thibaut Courtois, Andriy Lunin, and Fran González.\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">Defenders: David Alaba, Lucas Vázquez, Fran García, Antonio Rüdiger, Raúl Asensio, Diego Aguado, and Víctor Valdepeñas.\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">Midfielders: Jude Bellingham, Eduardo Camavinga, Federico Valverde, Luka Modrić, Aurélien Tchouaméni, and Arda Güler.\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">Forwards: Vinicius Júnior, Kylian Mbappé, Rodrygo, Endrick, and Brahim.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Which players played against Villareal?\"\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config_USER3,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras mucho buscar, al final lo encuentra. Por lo que ya tenemos un chatbot con `tools` y memoria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ahora, hemos creado unos `checkpoints` en tres hilos diferentes. Pero, ¿qué entra en cada `checkpoint`? Para inspeccionar el estado de un grafo para una configuración dada podemos usar el método `get_state(config)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='How did Real Madrid fare this weekend against Villareal in La Liga?', additional_kwargs={}, response_metadata={}, id='4badb145-8e5b-4b68-aba0-861c5bfc991e'), AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': {'query': 'Real Madrid vs Villareal La Liga weekend result'}, 'name': 'tavily_search_results_json', 'description': None}, 'id': '0', 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 297, 'total_tokens': 327}, 'model': '', 'finish_reason': 'stop'}, id='run-dbb9a5f5-7eb6-4eaf-b18c-7f5caf67c2ba-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'Real Madrid vs Villareal La Liga weekend result'}, 'id': '0', 'type': 'tool_call'}]), ToolMessage(content='[{\"title\": \"Real Madrid 2-1 Villarreal (Mar 15, 2025) Game Analysis - ESPN\", \"url\": \"https://www.espn.com/soccer/report/_/gameId/704939\", \"content\": \"Kylian Mbappé scored twice to help Real Madrid fight back to beat Villarreal 2-1 on Saturday and move provisionally top of the LaLiga standings.\", \"score\": 0.8724455}, {\"title\": \"Real Madrid 2-1 Villarreal (15 Mar, 2025) Final Score - ESPN Global\", \"url\": \"https://global.espn.com/football/match/_/gameId/704939/real-madrid-villarreal\", \"content\": \"Kylian Mbappé scored twice to help Real Madrid fight back to beat Villarreal 2-1 on Saturday and move provisionally top of the LaLiga standings.\", \"score\": 0.7700667911111111}]', name='tavily_search_results_json', id='6fed7a08-d7a3-4824-90ec-fe0ec4d37537', tool_call_id='0', artifact={'query': 'Real Madrid vs Villareal La Liga weekend result', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://www.espn.com/soccer/report/_/gameId/704939', 'title': 'Real Madrid 2-1 Villarreal (Mar 15, 2025) Game Analysis - ESPN', 'content': 'Kylian Mbappé scored twice to help Real Madrid fight back to beat Villarreal 2-1 on Saturday and move provisionally top of the LaLiga standings.', 'score': 0.8724455, 'raw_content': None}, {'url': 'https://global.espn.com/football/match/_/gameId/704939/real-madrid-villarreal', 'title': 'Real Madrid 2-1 Villarreal (15 Mar, 2025) Final Score - ESPN Global', 'content': 'Kylian Mbappé scored twice to help Real Madrid fight back to beat Villarreal 2-1 on Saturday and move provisionally top of the LaLiga standings.', 'score': 0.7700667911111111, 'raw_content': None}], 'response_time': 2.15}), AIMessage(content='Real Madrid defeated Villarreal 2-1, with Kylian Mbappé scoring both goals, which moved Real Madrid provisionally to the top of LaLiga standings.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 553, 'total_tokens': 605}, 'model': '', 'finish_reason': 'stop'}, id='run-5bbba0c8-a7f8-4b21-9604-9554bd4a89f8-0'), HumanMessage(content='Which players played against Villareal?', additional_kwargs={}, response_metadata={}, id='54e05178-0d37-4d07-9d9b-645aaa69568b'), AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': {'query': 'Real Madrid Villareal squad list match 15 Mar 2025'}, 'name': 'tavily_search_results_json', 'description': None}, 'id': '0', 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 607, 'total_tokens': 644}, 'model': '', 'finish_reason': 'stop'}, id='run-70d198fc-444d-4111-bfc1-368de43b84ac-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'Real Madrid Villareal squad list match 15 Mar 2025'}, 'id': '0', 'type': 'tool_call'}]), ToolMessage(content='[{\"title\": \"Villarreal v Real Madrid | March 15, 2025 | Goal.com US\", \"url\": \"https://www.goal.com/en-us/match/villarreal-vs-real-madrid/lineups/B_4aE8NTdMuaWGZQjye8h\", \"content\": \"Substitutes · 43. D. Aguado · 4. D. Alaba · 16. Endrick · 26. F. Gonzalez · 22. A. Ruediger. 61\\' · 13. A. Lunin · 45. V. Valdepenas · 7. Vinicius Junior.\", \"score\": 0.8891543}, {\"title\": \"Real Madrid squad for Villarreal match\", \"url\": \"https://www.realmadrid.com/en-US/news/football/first-team/squad-call/convocatoria-del-real-madrid-contra-el-villarreal-14-03-2025\", \"content\": \"Midfielders: Bellingham, Camavinga, Valverde, Modrić, Tchouameni and Arda Güler. Forwards: Vini Jr., Mbappé, Rodrygo, Endrick and Brahim.\", \"score\": 0.7188278125}]', name='tavily_search_results_json', id='bf59fb6c-6578-470c-b887-a61788f966db', tool_call_id='0', artifact={'query': 'Real Madrid Villareal squad list match 15 Mar 2025', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://www.goal.com/en-us/match/villarreal-vs-real-madrid/lineups/B_4aE8NTdMuaWGZQjye8h', 'title': 'Villarreal v Real Madrid | March 15, 2025 | Goal.com US', 'content': \"Substitutes · 43. D. Aguado · 4. D. Alaba · 16. Endrick · 26. F. Gonzalez · 22. A. Ruediger. 61' · 13. A. Lunin · 45. V. Valdepenas · 7. Vinicius Junior.\", 'score': 0.8891543, 'raw_content': None}, {'url': 'https://www.realmadrid.com/en-US/news/football/first-team/squad-call/convocatoria-del-real-madrid-contra-el-villarreal-14-03-2025', 'title': 'Real Madrid squad for Villarreal match', 'content': 'Midfielders: Bellingham, Camavinga, Valverde, Modrić, Tchouameni and Arda Güler. Forwards: Vini Jr., Mbappé, Rodrygo, Endrick and Brahim.', 'score': 0.7188278125, 'raw_content': None}], 'response_time': 1.46}), AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': {'query': 'which real Madrid players played against Villareal?'}, 'name': 'tavily_search_results_json', 'description': None}, 'id': '0', 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 929, 'total_tokens': 959}, 'model': '', 'finish_reason': 'stop'}, id='run-62f6edae-4dc9-4168-8907-4c503eb2e828-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'which real Madrid players played against Villareal?'}, 'id': '0', 'type': 'tool_call'}]), ToolMessage(content='[{\"title\": \"Real Madrid announce squad for LaLiga match against Villarreal\", \"url\": \"https://www.managingmadrid.com/2025/3/14/24385700/villarreal-real-madrid-2025-liga-squad-list\", \"content\": \"Goalkeepers: Courtois, Lunin y Fran González. Defenders: Alaba, Lucas V., Fran García, Rüdiger, Asencio, Diego Aguado y Valdepeñas. Midfielders:\", \"score\": 0.7763013}, {\"title\": \"Real Madrid player ratings from 2-1 win vs Villarreal in LaLiga\", \"url\": \"https://therealchamps.com/real-madrid-player-ratings-from-2-1-win-vs-villarreal-in-laliga-01jpdehskd0y\", \"content\": \"Real Madrid player ratings from 2-1 win vs Villarreal in LaLiga · GK Thibaut Courtois · RB Lucas Vazquez · CB Raul Asencio · CB Aurelien Tchouameni.\", \"score\": 0.7348644}]', name='tavily_search_results_json', id='74587d4d-2374-445a-9544-cb63c4fa006d', tool_call_id='0', artifact={'query': 'which real Madrid players played against Villareal?', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://www.managingmadrid.com/2025/3/14/24385700/villarreal-real-madrid-2025-liga-squad-list', 'title': 'Real Madrid announce squad for LaLiga match against Villarreal', 'content': 'Goalkeepers: Courtois, Lunin y Fran González. Defenders: Alaba, Lucas V., Fran García, Rüdiger, Asencio, Diego Aguado y Valdepeñas. Midfielders:', 'score': 0.7763013, 'raw_content': None}, {'url': 'https://therealchamps.com/real-madrid-player-ratings-from-2-1-win-vs-villarreal-in-laliga-01jpdehskd0y', 'title': 'Real Madrid player ratings from 2-1 win vs Villarreal in LaLiga', 'content': 'Real Madrid player ratings from 2-1 win vs Villarreal in LaLiga · GK Thibaut Courtois · RB Lucas Vazquez · CB Raul Asencio · CB Aurelien Tchouameni.', 'score': 0.7348644, 'raw_content': None}], 'response_time': 1.45}), AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': {'query': 'Real Madrid vs Villarreal match lineup March 15, 2025'}, 'name': 'tavily_search_results_json', 'description': None}, 'id': '0', 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 1217, 'total_tokens': 1251}, 'model': '', 'finish_reason': 'stop'}, id='run-61b371e7-a3ae-48d5-bf53-aaadeb0e13e6-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'Real Madrid vs Villarreal match lineup March 15, 2025'}, 'id': '0', 'type': 'tool_call'}]), ToolMessage(content='[{\"title\": \"Villarreal v Real Madrid | March 15, 2025 | Goal.com US\", \"url\": \"https://www.goal.com/en-us/match/villarreal-vs-real-madrid/lineups/B_4aE8NTdMuaWGZQjye8h\", \"content\": \"Substitutes · 43. D. Aguado · 4. D. Alaba · 16. Endrick · 26. F. Gonzalez · 22. A. Ruediger. 61\\' · 13. A. Lunin · 45. V. Valdepenas · 7. Vinicius Junior.\", \"score\": 0.9368016}, {\"title\": \"Villarreal vs. Real Madrid final score: La Liga result, updates, stats ...\", \"url\": \"https://www.sportingnews.com/us/soccer/news/villarreal-vs-real-madrid-score-result-updates-stats-la-liga/67cd5249ed55e513dcbfd906\", \"content\": \"— Villarreal CF (@VillarrealCF) March 15, 2025. 1 hr 30 mins before kickoff: Here\\'s the Madrid lineup. Plenty of changes from Carlo Ancelotti\", \"score\": 0.7115741333333333}]', name='tavily_search_results_json', id='bb3ee5d9-5b18-469e-a5a3-7dc9222eec73', tool_call_id='0', artifact={'query': 'Real Madrid vs Villarreal match lineup March 15, 2025', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://www.goal.com/en-us/match/villarreal-vs-real-madrid/lineups/B_4aE8NTdMuaWGZQjye8h', 'title': 'Villarreal v Real Madrid | March 15, 2025 | Goal.com US', 'content': \"Substitutes · 43. D. Aguado · 4. D. Alaba · 16. Endrick · 26. F. Gonzalez · 22. A. Ruediger. 61' · 13. A. Lunin · 45. V. Valdepenas · 7. Vinicius Junior.\", 'score': 0.9368016, 'raw_content': None}, {'url': 'https://www.sportingnews.com/us/soccer/news/villarreal-vs-real-madrid-score-result-updates-stats-la-liga/67cd5249ed55e513dcbfd906', 'title': 'Villarreal vs. Real Madrid final score: La Liga result, updates, stats ...', 'content': \"— Villarreal CF (@VillarrealCF) March 15, 2025. 1 hr 30 mins before kickoff: Here's the Madrid lineup. Plenty of changes from Carlo Ancelotti\", 'score': 0.7115741333333333, 'raw_content': None}], 'response_time': 1.58}), AIMessage(content='The starting lineup for Real Madrid against Villarreal included the following players:\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">Goalkeepers: Thibaut Courtois, Andriy Lunin, and Fran González.\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">Defenders: David Alaba, Lucas Vázquez, Fran García, Antonio Rüdiger, Raúl Asensio, Diego Aguado, and Víctor Valdepeñas.\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">Midfielders: Jude Bellingham, Eduardo Camavinga, Federico Valverde, Luka Modrić, Aurélien Tchouaméni, and Arda Güler.\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">Forwards: Vinicius Júnior, Kylian Mbappé, Rodrygo, Endrick, and Brahim. ', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 235, 'prompt_tokens': 1557, 'total_tokens': 1792}, 'model': '', 'finish_reason': 'stop'}, id='run-cbe4043a-bbf1-4671-9ad6-e491c2bd490c-0')]}, next=(), config={'configurable': {'thread_id': '3', 'checkpoint_ns': '', 'checkpoint_id': '1f003681-88f6-6a0e-800c-b30587220347'}}, metadata={'source': 'loop', 'writes': {'chatbot': {'messages': [AIMessage(content='The starting lineup for Real Madrid against Villarreal included the following players:\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">Goalkeepers: Thibaut Courtois, Andriy Lunin, and Fran González.\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">Defenders: David Alaba, Lucas Vázquez, Fran García, Antonio Rüdiger, Raúl Asensio, Diego Aguado, and Víctor Valdepeñas.\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">Midfielders: Jude Bellingham, Eduardo Camavinga, Federico Valverde, Luka Modrić, Aurélien Tchouaméni, and Arda Güler.\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">\">Forwards: Vinicius Júnior, Kylian Mbappé, Rodrygo, Endrick, and Brahim. ', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 235, 'prompt_tokens': 1557, 'total_tokens': 1792}, 'model': '', 'finish_reason': 'stop'}, id='run-cbe4043a-bbf1-4671-9ad6-e491c2bd490c-0')]}}, 'thread_id': '3', 'step': 12, 'parents': {}}, created_at='2025-03-17T19:43:27.201925+00:00', parent_config={'configurable': {'thread_id': '3', 'checkpoint_ns': '', 'checkpoint_id': '1f003681-2cd9-6050-800b-55c0e26ea9a9'}}, tasks=())"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config_USER3)\n",
    "snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot.next  # (since the graph ended this turn, `next` is empty. If you fetch a state from within a graph invocation, next tells which node will execute next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La instantánea anterior (`snapshot`) contiene los valores de estado actuales, la configuración correspondiente y el siguiente nodo (`next`) a procesar. En nuestro caso, el gráfico ha alcanzado el estado `END`, por eso `next` está vacío."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¡Felicidades!** Nuestro chatbot ahora puede mantener el estado de conversación en todas las sesiones gracias al sistema de puntos de control (`checkpoints`) de `LangGraph`. Esto abre posibilidades para interacciones más naturales y contextuales. El control de `LangGraph` incluso maneja estados de grafos complejos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human in the loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque un agente puede realizar tareas, para según que tareas, es necesario que haya una supervisión humana. A esto se le llama `human in the loop`. Así que vamos a ver cómo se puede hacer esto con `LangGraph`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La capa de [persistencia](https://langchain-ai.github.io/langgraph/concepts/persistence/) de `LangGraph` admite flujos de trabajo humanos en el bucle, lo que permite que la ejecución se detenga y reanude en función de los comentarios de los usuarios. La interfaz principal de esta funcionalidad es la función [interrupt](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/#interrupt). Llamando a `interrupt` dentro de un nodo se detendrá la ejecución. La ejecución se puede reanudar, junto con la nueva aportación del humano, pasanda en una primitiva [Command](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/#the-command-primitive). `interrupt` es similar al comando de Python `input()`, pero con algunas consideraciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a repetir el código anterior, pero haremos un cambio, que es agregar una simple herramienta `human_assistance`. Esta herramienta utiliza `interrupt` para recibir información de un humano."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero cargamos los valores de las API KEYs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "HUGGINGFACE_TOKEN = os.getenv(\"HUGGINGFACE_LANGGRAPH\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_LANGGRAPH_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la `tool` de búsqueda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "wrapper = TavilySearchAPIWrapper(tavily_api_key=TAVILY_API_KEY)\n",
    "search_tool = TavilySearchResults(api_wrapper=wrapper, max_results=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora creamos la `tool` de ayuda humana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command, interrupt\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def human_assistance(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Request assistance from a human expert. Use this tool ONLY ONCE per conversation.\n",
    "    After receiving the expert's response, you should provide an elaborated response to the user based on the information received\n",
    "    based on the information received, without calling this tool again.\n",
    "    \"\"\"\n",
    "    human_response = interrupt({\"query\": query})\n",
    "    return human_response[\"data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una lista de `tools`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search_tool, human_assistance]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación el `LLM` con las `bind_tools` y lo añadimos al grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x106605160>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from huggingface_hub import login\n",
    "\n",
    "login(token=HUGGINGFACE_TOKEN)\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"    # Disable LangSmith tracing\n",
    "\n",
    "# Create the LLM\n",
    "MODEL = \"Qwen/Qwen2.5-72B-Instruct\"\n",
    "model = HuggingFaceEndpoint(\n",
    "    repo_id=MODEL,\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=512,\n",
    "    do_sample=False,\n",
    "    repetition_penalty=1.03,\n",
    ")\n",
    "# Create the chat model\n",
    "llm = ChatHuggingFace(llm=model)\n",
    "\n",
    "# Modification: tell the LLM which tools it can call\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# Define the chatbot function\n",
    "def chatbot(state: State):\n",
    "    message = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # Because we will be interrupting during tool execution,\n",
    "    # we disable parallel tool calling to avoid repeating any\n",
    "    # tool invocations when we resume.\n",
    "    assert len(message.tool_calls) <= 1\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "# Add the chatbot node\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si te fijas, hemos cambiado la forma de definir la función `chatbot`, ya que ahora tiene que manejar la interrupción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadimos la `tool` al grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x106605160>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "graph_builder.add_conditional_edges(\"chatbot\", tools_condition)\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadimos el nodo de `START` al grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x106605160>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_edge(START, \"chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un `checkpointer` [MemorySaver](https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.memory.MemorySaver)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilamos el grafo con el `checkpointer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo representamos gráficamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Error al visualizar el grafo: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora solicitemos el chatbot con una pregunta que involucrará a la nueva herramienta `human_assistance`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I need some expert guidance for building an AI agent. Could you request assistance for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  human_assistance (0)\n",
      " Call ID: 0\n",
      "  Args:\n",
      "    query: I need some expert guidance for building an AI agent. Could you provide advice on key considerations, best practices, and potential pitfalls to avoid?\n"
     ]
    }
   ],
   "source": [
    "user_input = \"I need some expert guidance for building an AI agent. Could you request assistance for me?\"\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver, el chatbot generó una llamada de herramienta de asistencia humana.\n",
    "\n",
    "``` markdown\n",
    "Tool Calls:\n",
    "  human_assistance (0)\n",
    " Call ID: 0\n",
    "  Args:\n",
    "    query: I need some expert guidance for building an AI agent. Could you provide advice on key considerations, best practices, and potential pitfalls to avoid?\n",
    "```\n",
    "\n",
    "pero luego la ejecución se ha interrumpido. Vamos a ver el estado del grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tools',)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "snapshot.next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que se detuvo en el nodo de `tools`. Analizamos cómo se ha definido la herramienta `human_assistance`.\n",
    "\n",
    "``` python\n",
    "from langgraph.types import Command, interrupt\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def human_assistance(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Request assistance from a human expert. Use this tool ONLY ONCE per conversation.\n",
    "    After receiving the expert's response, you should provide an elaborated response to the user based on the information received\n",
    "    based on the information received, without calling this tool again.\n",
    "    \"\"\"\n",
    "    human_response = interrupt({\"query\": query})\n",
    "    return human_response[\"data\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llamando a la herramienta `interrupt` se detendrá la ejecución, similar al la función de Python `input()`.\n",
    "\n",
    "El progreso se mantiene en función de nuestra elección de [checkpointer](https://langchain-ai.github.io/langgraph/concepts/persistence/#checkpointer-libraries). Es decir, la elección de dónde se guarda el estado del grafo. Así que si estamos persistiendo (guardando el estado del grafo) con una base de datos como `Postgres`, podemos reanudar la ejecución en cualquier momento siempre y cuando la base de datos esté viva.\n",
    "\n",
    "Aquí estamos persistiendo (guardando el estado del grafo) con el puntero de verificación en memoria, por lo que podemos reanudar en cualquier momento mientras nuestro kernel de Python se esté ejecutando. En mi caso, mientras no resetee el kernel de mi Jupyter Notebook.\n",
    "\n",
    "Para reanudar la ejecución, pasamos un objeto [Command](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/#the-command-primitive) que contiene los datos esperados por la herramienta. El formato de estos datos se puede personalizar en función de nuestras necesidades. Aquí, solo necesitamos un diccionario con una key `data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  human_assistance (0)\n",
      " Call ID: 0\n",
      "  Args:\n",
      "    query: I need some expert guidance for building an AI agent. Could you provide advice on key considerations, best practices, and potential pitfalls to avoid?\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: human_assistance\n",
      "\n",
      "We, the experts are here to help! We'd recommend you check out LangGraph to build your agent.It's much more reliable and extensible than simple autonomous agents.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The experts recommend checking out LangGraph for building your AI agent. It's much more reliable and extensible compared to simple autonomous agents.\n"
     ]
    }
   ],
   "source": [
    "human_response = (\n",
    "    \"We, the experts are here to help! We'd recommend you check out LangGraph to build your agent.\"\n",
    "    \"It's much more reliable and extensible than simple autonomous agents.\"\n",
    ")\n",
    "\n",
    "human_command = Command(resume={\"data\": human_response})\n",
    "\n",
    "events = graph.stream(human_command, config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, el chatbot ha esperado a que un humano le proporcione la respuesta y luego ha generado una respuesta basada en la información recibida. Le hemos pedido por la ayuda sobre un experto sobre cómo crear agentes, el humano le ha dicho que lo mejor es usar LangGraph, y el chatbot ha generado una respuesta basada en esa información."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero sigue teniendo la posibilidad de realizar búsquedas en la web. Así que ahora le vamos a pedir las últimas noticias sobre LangGraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What's the latest news about LangGraph?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (0)\n",
      " Call ID: 0\n",
      "  Args:\n",
      "    query: latest news about LangGraph\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"Top 5 LangGraph Agents in Production 2024 - LangChain Blog\", \"url\": \"https://blog.langchain.dev/top-5-langgraph-agents-in-production-2024/\", \"content\": \"We launched LangGraph in early 2024 as a new take on an agentic framework. Incorporating lessons learned from LangChain, we made LangGraph very low level, controllable agentic framework. No hidden prompts, no obfuscated \\\"cognitive architecture\\\". Soon after it's launch, we saw LangGraph become the go-to default framework for agents.\", \"score\": 0.7293491339285714}, {\"title\": \"LangGraph 0.3 Release: Prebuilt Agents - LangChain Blog\", \"url\": \"https://blog.langchain.dev/langgraph-0-3-release-prebuilt-agents/\", \"content\": \"LangGraph 0.3 Release: Prebuilt Agents\\n2 min read Feb 27, 2025\\nBy Nuno Campos and Vadym Barda\\nOver the past year, we’ve invested heavily in making LangGraph the go-to framework for building AI agents. With companies like Replit, Klarna, LinkedIn and Uber choosing to build on top of LangGraph, we have more conviction than ever that we are on the right path. [...] Up to this point, we’ve had one higher level abstraction and it’s lived in the main langgraph package. It was create_react_agent, a wrapper for creating a simple tool calling agent. Today, we are splitting that out of langgraph as part of a 0.3 release, and moving it into langgraph-prebuilt.\\nWe are also introducing a new set of prebuilt agents built on top of LangGraph, in both Python and JavaScript.\\nOver the past three weeks, we’ve already released a few of these: [...] Published Time: 2025-02-27T15:09:15.000Z\\nLangGraph 0.3 Release: Prebuilt Agents\\nSkip to content\\n\\n\\nCase Studies\\nIn the Loop\\nLangChain\\nDocs\\nChangelog\\n\\nSign in Subscribe\", \"score\": 0.7048658747619049}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (0)\n",
      " Call ID: 0\n",
      "  Args:\n",
      "    query: latest news about LangGraph\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"Top 5 LangGraph Agents in Production 2024 - LangChain Blog\", \"url\": \"https://blog.langchain.dev/top-5-langgraph-agents-in-production-2024/\", \"content\": \"We launched LangGraph in early 2024 as a new take on an agentic framework. Incorporating lessons learned from LangChain, we made LangGraph very low level, controllable agentic framework. No hidden prompts, no obfuscated \\\"cognitive architecture\\\". Soon after it's launch, we saw LangGraph become the go-to default framework for agents.\", \"score\": 0.7293491339285714}, {\"title\": \"LangGraph 0.3 Release: Prebuilt Agents - LangChain Blog\", \"url\": \"https://blog.langchain.dev/langgraph-0-3-release-prebuilt-agents/\", \"content\": \"LangGraph 0.3 Release: Prebuilt Agents\\n2 min read Feb 27, 2025\\nBy Nuno Campos and Vadym Barda\\nOver the past year, we’ve invested heavily in making LangGraph the go-to framework for building AI agents. With companies like Replit, Klarna, LinkedIn and Uber choosing to build on top of LangGraph, we have more conviction than ever that we are on the right path. [...] Up to this point, we’ve had one higher level abstraction and it’s lived in the main langgraph package. It was create_react_agent, a wrapper for creating a simple tool calling agent. Today, we are splitting that out of langgraph as part of a 0.3 release, and moving it into langgraph-prebuilt.\\nWe are also introducing a new set of prebuilt agents built on top of LangGraph, in both Python and JavaScript.\\nOver the past three weeks, we’ve already released a few of these: [...] Published Time: 2025-02-27T15:09:15.000Z\\nLangGraph 0.3 Release: Prebuilt Agents\\nSkip to content\\n\\n\\nCase Studies\\nIn the Loop\\nLangChain\\nDocs\\nChangelog\\n\\nSign in Subscribe\", \"score\": 0.7048658747619049}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (0)\n",
      " Call ID: 0\n",
      "  Args:\n",
      "    query: latestnews about Lang:// lang46 released927418\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"Lang Lang - News - Deutsche Grammophon\", \"url\": \"https://www.deutschegrammophon.com/en/artists/langlang/news\", \"content\": \"Deutsche Grammophon Releases Lang Lang's World Premiere Recording of Long-Lost Chopin Waltz · Lang Lang Celebrates the Year of the Dragon · Lang Lang's New Album\", \"score\": 0.25990826}, {\"title\": \"Lang Lang - Wikipedia\", \"url\": \"https://en.wikipedia.org/wiki/Lang_Lang\", \"content\": \"On 30 September 2021, Lang performed at the opening ceremony of Expo 2020 in Dubai, UAE.\\nOn 7 May 2023, Lang performed at the Coronation Concert, held in celebration of the coronation of King Charles III and Queen Camilla the day before.[63] Lang played the piano for the song \\\"Reflection\\\", from Disney's 1998 animated film Mulan, accompanied by singer Nicole Scherzinger.[64]\\nBooks\\n[edit] [...] On 30 April 2015, Lang performed at the Expo 2015 opening concert with Andrea Bocelli at Piazza del Duomo in Milan.\\nOn 4 July 2015, Lang performed \\\"Rhapsody in Blue\\\" during \\\"A Capitol Fourth\\\", a U.S. Independence Day celebration televised from Washington, D.C.\\nOn 24 September 2015, Lang performed the Edvard Grieg Piano Concerto in A minor, Op. 16 at the New York Philharmonic Opening Gala Concert at the David Geffen Hall with Alan Gilbert conducting. [...] Lang's autobiography, Journey of a Thousand Miles, published by Random House in 8 languages, was released in the summer of 2008.[citation needed] Delacorte Press also released a version of the autobiography specifically for younger readers, entitled Playing with Flying Keys.\\nAwards and outreach\\n[edit]\", \"score\": 0.22016132313218395}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (0)\n",
      " Call ID: 0\n",
      "  Args:\n",
      "    query: latest news about LangGraph\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"Top 5 LangGraph Agents in Production 2024 - LangChain Blog\", \"url\": \"https://blog.langchain.dev/top-5-langgraph-agents-in-production-2024/\", \"content\": \"We launched LangGraph in early 2024 as a new take on an agentic framework. Incorporating lessons learned from LangChain, we made LangGraph very low level, controllable agentic framework. No hidden prompts, no obfuscated \\\"cognitive architecture\\\". Soon after it's launch, we saw LangGraph become the go-to default framework for agents.\", \"score\": 0.7293491339285714}, {\"title\": \"LangGraph 0.3 Release: Prebuilt Agents - LangChain Blog\", \"url\": \"https://blog.langchain.dev/langgraph-0-3-release-prebuilt-agents/\", \"content\": \"LangGraph 0.3 Release: Prebuilt Agents\\n2 min read Feb 27, 2025\\nBy Nuno Campos and Vadym Barda\\nOver the past year, we’ve invested heavily in making LangGraph the go-to framework for building AI agents. With companies like Replit, Klarna, LinkedIn and Uber choosing to build on top of LangGraph, we have more conviction than ever that we are on the right path. [...] Up to this point, we’ve had one higher level abstraction and it’s lived in the main langgraph package. It was create_react_agent, a wrapper for creating a simple tool calling agent. Today, we are splitting that out of langgraph as part of a 0.3 release, and moving it into langgraph-prebuilt.\\nWe are also introducing a new set of prebuilt agents built on top of LangGraph, in both Python and JavaScript.\\nOver the past three weeks, we’ve already released a few of these: [...] Published Time: 2025-02-27T15:09:15.000Z\\nLangGraph 0.3 Release: Prebuilt Agents\\nSkip to content\\n\\n\\nCase Studies\\nIn the Loop\\nLangChain\\nDocs\\nChangelog\\n\\nSign in Subscribe\", \"score\": 0.7048658747619049}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (0)\n",
      " Call ID: 0\n",
      "  Args:\n",
      "    query: LangGraph latest news\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"LangChain - Changelog\", \"url\": \"https://changelog.langchain.com/\", \"content\": \"LangGraph 🔁 Modify graph state from tools in LangGraph --------------------------------------------- LangGraph's latest update gives you greater control over your agents by enabling tools to directly update the graph state. This is a game-changer for use... December 18, 2024 [...] LangGraph `interrupt`: Simplifying human-in-the-loop agents --------------------------------------------------- Our latest feature in LangGraph, interrupt , makes building human-in-the-loop workflows easier. Agents aren’t perfect, so keeping humans “in the loop”... December 16, 2024\", \"score\": 0.7828389173362446}, {\"title\": \"Top 5 LangGraph Agents in Production 2024 - LangChain Blog\", \"url\": \"https://blog.langchain.dev/top-5-langgraph-agents-in-production-2024/\", \"content\": \"We launched LangGraph in early 2024 as a new take on an agentic framework. Incorporating lessons learned from LangChain, we made LangGraph very low level, controllable agentic framework. No hidden prompts, no obfuscated \\\"cognitive architecture\\\". Soon after it's launch, we saw LangGraph become the go-to default framework for agents.\", \"score\": 0.7102904655021833}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (0)\n",
      " Call ID: 0\n",
      "  Args:\n",
      "    query: LangGraph latest news\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"LangChain - Changelog\", \"url\": \"https://changelog.langchain.com/\", \"content\": \"LangGraph 🔁 Modify graph state from tools in LangGraph --------------------------------------------- LangGraph's latest update gives you greater control over your agents by enabling tools to directly update the graph state. This is a game-changer for use... December 18, 2024 [...] LangGraph `interrupt`: Simplifying human-in-the-loop agents --------------------------------------------------- Our latest feature in LangGraph, interrupt , makes building human-in-the-loop workflows easier. Agents aren’t perfect, so keeping humans “in the loop”... December 16, 2024\", \"score\": 0.7828389173362446}, {\"title\": \"Top 5 LangGraph Agents in Production 2024 - LangChain Blog\", \"url\": \"https://blog.langchain.dev/top-5-langgraph-agents-in-production-2024/\", \"content\": \"We launched LangGraph in early 2024 as a new take on an agentic framework. Incorporating lessons learned from LangChain, we made LangGraph very low level, controllable agentic framework. No hidden prompts, no obfuscated \\\"cognitive architecture\\\". Soon after it's launch, we saw LangGraph become the go-to default framework for agents.\", \"score\": 0.7102904655021833}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The latest news about LangGraph includes two significant updates:\\\\- **Modify Graph State from Tools**: This update gives developers greater control over their agents by enabling tools to directly update the graph state. (Announced on December 18, 2024) \\\\- **LangGraph `interrupt`**: A new feature that simplifies human-in-the-loop workflows, making it easier to keep humans involved in the decision-making process of AI agents. (Announced on December 16, 2024) For more details, you can check out the [LangChain Changelog](https://changelog.langchain.com/) or the [LangChain Blog](https://blog.langchain.dev/top-5-langgraph-agents-in-production-2024/) for the top 5 LangGraph agents in production.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"What's the latest news about LangGraph?\"\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ha buscado las últimas noticias sobre LangGraph y ha generado una respuesta basada en la información recibida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personalización del estado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > Nota: Este apartado lo vamos a hacer usando Sonnet 3.7, ya que a día de la escritura del post, es el mejor modelo para uso con agentes, y es el único que entiende cuando tiene que llamar a las tools y cuando no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta ahora, hemos confiado en un estado simple con una entrada, una lista de mensajes. Se puede llegar lejos con este estado simple, pero si se desea definir un comportamiento complejo sin depender de la lista de mensajes, se pueden agregar campos adicionales al estado.\n",
    "\n",
    "Aquí vamos a ver un nuevo escenario, en el que el chatbot está utilizando la herramienta de búsqueda para encontrar información específica, y reenviándola a un ser humano para su revisión. Vamos a hacer que el chatbot investigue el cumpleaños de una entidad. Agregaremos `name` y `birthday` claves del estado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero cargamos los valores de las API KEYs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "HUGGINGFACE_TOKEN = os.getenv(\"HUGGINGFACE_LANGGRAPH\")\n",
    "ANTHROPIC_TOKEN = os.getenv(\"ANTHROPIC_LANGGRAPH_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_LANGGRAPH_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el nuevo estado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    name: str\n",
    "    birthday: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregar esta información al estado hace que sea fácilmente accesible por otros nodos del grafo (por ejemplo, un nodo downstram que almacena o procesa la información), así como la capa de persistencia del grafo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora creamos el grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la `tool` de búsqueda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "wrapper = TavilySearchAPIWrapper(tavily_api_key=TAVILY_API_KEY)\n",
    "search_tool = TavilySearchResults(api_wrapper=wrapper, max_results=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora creamos la tool de asistencia humana. En esta tool rellenaremos las claves de estado dentro de nuestra herramienta `human_assistance`. Esto permite a un ser humano revisar la información antes de que se almacene en el estado. Volveremos a usar `Command`, esta vez para emitir una actualización de estado desde el interior de nuestra herramienta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import InjectedToolCallId, tool\n",
    "\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "\n",
    "@tool\n",
    "# Note that because we are generating a ToolMessage for a state update, we\n",
    "# generally require the ID of the corresponding tool call. We can use\n",
    "# LangChain's InjectedToolCallId to signal that this argument should not\n",
    "# be revealed to the model in the tool's schema.\n",
    "def human_assistance(\n",
    "    name: str, birthday: str, tool_call_id: Annotated[str, InjectedToolCallId]\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Request assistance from a human expert. Use this tool ONLY ONCE per conversation.\n",
    "    After receiving the expert's response, you should provide an elaborated response to the user based on the information received\n",
    "    based on the information received, without calling this tool again.\n",
    "    \"\"\"\n",
    "    human_response = interrupt(\n",
    "        {\n",
    "            \"question\": \"Is this correct?\",\n",
    "            \"name\": name,\n",
    "            \"birthday\": birthday,\n",
    "        },\n",
    "    )\n",
    "    # If the information is correct, update the state as-is.\n",
    "    if human_response.get(\"correct\", \"\").lower().startswith(\"y\"):\n",
    "        verified_name = name\n",
    "        verified_birthday = birthday\n",
    "        response = \"Correct\"\n",
    "    # Otherwise, receive information from the human reviewer.\n",
    "    else:\n",
    "        verified_name = human_response.get(\"name\", name)\n",
    "        verified_birthday = human_response.get(\"birthday\", birthday)\n",
    "        response = f\"Made a correction: {human_response}\"\n",
    "\n",
    "    # This time we explicitly update the state with a ToolMessage inside\n",
    "    # the tool.\n",
    "    state_update = {\n",
    "        \"name\": verified_name,\n",
    "        \"birthday\": verified_birthday,\n",
    "        \"messages\": [ToolMessage(response, tool_call_id=tool_call_id)],\n",
    "    }\n",
    "    # We return a Command object in the tool to update our state.\n",
    "    return Command(update=state_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos usado [ToolMessage](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.tool.ToolMessage.html) que se usa para pasar el resultado de ejecutar una `tool` de nuevo a un modelo y [InjectedToolCallId](https://python.langchain.com/api_reference/core/tools/langchain_core.tools.base.InjectedToolCallId.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una lista de `tools`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search_tool, human_assistance]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación el `LLM` con las `bind_tools` y lo añadimos al grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x106405160>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from huggingface_hub import login\n",
    "\n",
    "login(token=HUGGINGFACE_TOKEN)\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"    # Disable LangSmith tracing\n",
    "\n",
    "# Create the LLM\n",
    "# MODEL = \"mistralai/Mistral-Small-3.1-24B-Instruct-2503\"\n",
    "# model = HuggingFaceEndpoint(\n",
    "#     repo_id=MODEL,\n",
    "#     task=\"text-generation\",\n",
    "#     max_new_tokens=512,\n",
    "#     do_sample=False,\n",
    "#     repetition_penalty=1.03,\n",
    "# )\n",
    "# Create the chat model\n",
    "# llm = ChatHuggingFace(llm=model)\n",
    "llm = ChatAnthropic(model=\"claude-3-7-sonnet-20250219\", api_key=ANTHROPIC_TOKEN)\n",
    "\n",
    "# Modification: tell the LLM which tools it can call\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# Define the chatbot function\n",
    "def chatbot(state: State):\n",
    "    message = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # Because we will be interrupting during tool execution,\n",
    "    # we disable parallel tool calling to avoid repeating any\n",
    "    # tool invocations when we resume.\n",
    "    assert len(message.tool_calls) <= 1\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "# Add the chatbot node\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadimos la `tool` al grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x106405160>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "graph_builder.add_conditional_edges(\"chatbot\", tools_condition)\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadimos el nodo de `START` al grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x106405160>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_edge(START, \"chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un `checkpointer` [MemorySaver](https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.memory.MemorySaver)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilamos el grafo con el `checkpointer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo representamos gráficamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Error al visualizar el grafo: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a pedir a nuestro chatbot que busque el \"cumpleaños\" de la biblioteca de `LangGraph`.\n",
    "\n",
    "Dirigiremos al chatbot hata la herramienta `human_assistance` una vez que tenga la información requerida. Los argumentos `name` y `birthday` son obligatorios para la herramienta `human_assistance`, así que obligan al chatbot a generar propuestas para estos campos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can you look up when LangGraph was released? When you have the answer, use the human_assistance tool for review.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"I'll help you find out when LangGraph was released and then have it reviewed by a human expert. Let me search for this information first.\", 'type': 'text'}, {'id': 'toolu_015TjcZmu3j4PSicctmEQrdE', 'input': {'query': 'when was LangGraph released official launch date'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_015TjcZmu3j4PSicctmEQrdE)\n",
      " Call ID: toolu_015TjcZmu3j4PSicctmEQrdE\n",
      "  Args:\n",
      "    query: when was LangGraph released official launch date\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"LangGraph Quickstart - GitHub Pages\", \"url\": \"https://langchain-ai.github.io/langgraph/tutorials/introduction/\", \"content\": \"[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-24)It's worth noting that LangGraph had been in development and use for some time before the LangGraph Cloud announcement, but the official initial release of LangGraph itself was on January 17, 2024.\\nNote that these fields are now reflected in the state:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-57-1)snapshot = graph.get_state(config) [...] [](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-20)To summarize:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-21)1. LangGraph's original release date: January 17, 2024\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-22)2. LangGraph Cloud announcement: June 27, 2024\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-23) [...] [](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-17)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-18)LangGraph was initially released on January 17, 2024. This information comes from the human assistance correction, which is more accurate than the search results I initially found.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-19)\", \"score\": 0.849569660980057}, {\"title\": \"LangChain Unveils LangGraph Studio: The First IDE for Agent ...\", \"url\": \"https://blockchain.news/news/langchain-unveils-langgraph-studio-the-first-ide-for-agent-development\", \"content\": \"LangGraph, introduced in January 2023, is a low-level orchestration framework for building agentic applications. Since its launch, LangGraph has undergone significant enhancements, culminating in a stable 0.1 release in June 2024. The framework supports complex applications requiring highly domain-specific cognitive architectures and features a persistence layer that enables human-in-the-loop interactions.\", \"score\": 0.8159328605128205}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"I found some information about LangGraph's release date, but there seems to be conflicting information. Let me request human assistance to verify this information.\", 'type': 'text'}, {'id': 'toolu_01EcmepXKp3XviABG2aTxi8X', 'input': {'name': 'LangGraph Release Date', 'birthday': 'January 2024'}, 'name': 'human_assistance', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  human_assistance (toolu_01EcmepXKp3XviABG2aTxi8X)\n",
      " Call ID: toolu_01EcmepXKp3XviABG2aTxi8X\n",
      "  Args:\n",
      "    name: LangGraph Release Date\n",
      "    birthday: January 2024\n"
     ]
    }
   ],
   "source": [
    "user_input = (\n",
    "    \"Can you look up when LangGraph was released? \"\n",
    "    \"When you have the answer, use the human_assistance tool for review.\"\n",
    ")\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ha parado por el `interrupt` en la herramienta `human_assistance`. En este caso, el chatbot no identificó la fecha correcta, por lo que podemos introducirla nosotros mismos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"I found some information about LangGraph's release date, but there seems to be conflicting information. Let me request human assistance to verify this information.\", 'type': 'text'}, {'id': 'toolu_01EcmepXKp3XviABG2aTxi8X', 'input': {'name': 'LangGraph Release Date', 'birthday': 'January 2024'}, 'name': 'human_assistance', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  human_assistance (toolu_01EcmepXKp3XviABG2aTxi8X)\n",
      " Call ID: toolu_01EcmepXKp3XviABG2aTxi8X\n",
      "  Args:\n",
      "    name: LangGraph Release Date\n",
      "    birthday: January 2024\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: human_assistance\n",
      "\n",
      "Made a correction: {'name': 'LangGraph', 'birthday': 'Jan 17, 2024'}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thank you for your patience. Based on my research and the human expert verification, I can now provide you with the accurate information:\n",
      "\n",
      "LangGraph was officially released on January 17, 2024. \n",
      "\n",
      "There was some conflicting information in my initial search results, with one source mentioning January 2023, but the human expert has confirmed that the correct release date is January 17, 2024. This aligns with the more reliable source I found that specifically noted this was the initial release date of the framework.\n",
      "\n",
      "LangGraph is a framework for orchestrating agentic applications, and since its initial release in January 2024, it has continued to evolve, with a stable 0.1 release in June 2024, followed by the announcement of LangGraph Cloud on June 27, 2024.\n"
     ]
    }
   ],
   "source": [
    "human_command = Command(\n",
    "    resume={\n",
    "        \"name\": \"LangGraph\",\n",
    "        \"birthday\": \"Jan 17, 2024\",\n",
    "    },\n",
    ")\n",
    "\n",
    "events = graph.stream(human_command, config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'LangGraph', 'birthday': 'Jan 17, 2024'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "\n",
    "{k: v for k, v in snapshot.values.items() if k in (\"name\", \"birthday\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actualización manual del estado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangGraph proporciona un alto grado de control sobre el estado de aplicación. Por ejemplo, en cualquier punto (incluso cuando se interrumpe), podemos soreescribir manualmente una key del estado usando `graph.update_state`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a actualizar el `name` del estado a `LangGraph (library)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f0067be-cd1d-6fd4-8006-fa5a987d1d2c'}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.update_state(config, {\"name\": \"LangGraph (library)\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si ahora vemos el estado con `graph.get_state(config)` veremos que el `name` se ha actualizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'LangGraph (library)', 'birthday': 'Jan 17, 2024'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "\n",
    "{k: v for k, v in snapshot.values.items() if k in (\"name\", \"birthday\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las actualizaciones de estado manuales generarán una traza en `LangSmith`. Se pueden usar para controlar flujos de trabajo de `human in the loop`, como se puede ver en esta [guía](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/edit-graph-state/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En un flujo de trabajo típico de un chatbot, el usuario interactúa con el chatbot una o más veces para realizar una tarea. En las secciones anteriores, vimos cómo agregar memoria y un `human in the loop` para poder verificar nuestro estado de gráfico y controlar las respuestas futuras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero, a lo mejor un usuario quiere comenzar desde una respuesta anterior y o quiere `ramificar` para explorar un resultado separado. Esto es útil para aplicaciones de agentes, cuando un flujo falla pueden volver a un checkpoint anterior y probar otra estrategia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LangGraph` da esta posibilidad mediante los `checkpoints`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero cargamos los valores de las API KEYs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "HUGGINGFACE_TOKEN = os.getenv(\"HUGGINGFACE_LANGGRAPH\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_LANGGRAPH_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el nuevo estado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregar esta información al estado hace que sea fácilmente accesible por otros nodos del grafo (por ejemplo, un nodo downstram que almacena o procesa la información), así como la capa de persistencia del grafo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora creamos el grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la `tool` de búsqueda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "wrapper = TavilySearchAPIWrapper(tavily_api_key=TAVILY_API_KEY)\n",
    "search_tool = TavilySearchResults(api_wrapper=wrapper, max_results=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora creamos la tool de asistencia humana. En esta tool rellenaremos las claves de estado dentro de nuestra herramienta `human_assistance`. Esto permite a un ser humano revisar la información antes de que se almacene en el estado. Volveremos a usar `Command`, esta vez para emitir una actualización de estado desde el interior de nuestra herramienta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una lista de `tools`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación el `LLM` con las `bind_tools` y lo añadimos al grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x114d05160>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from huggingface_hub import login\n",
    "\n",
    "login(token=HUGGINGFACE_TOKEN)\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"    # Disable LangSmith tracing\n",
    "\n",
    "# Create the LLM\n",
    "MODEL = \"Qwen/Qwen2.5-72B-Instruct\"\n",
    "model = HuggingFaceEndpoint(\n",
    "    repo_id=MODEL,\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=512,\n",
    "    do_sample=False,\n",
    "    repetition_penalty=1.03,\n",
    ")\n",
    "# Create the chat model\n",
    "llm = ChatHuggingFace(llm=model)\n",
    "\n",
    "# Modification: tell the LLM which tools it can call\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# Define the chatbot function\n",
    "def chatbot(state: State):\n",
    "    message = llm_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "# Add the chatbot node\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadimos la `tool` al grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x114d05160>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "graph_builder.add_conditional_edges(\"chatbot\", tools_condition)\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadimos el nodo de `START` al grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x114d05160>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_edge(START, \"chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un `checkpointer` [MemorySaver](https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.memory.MemorySaver)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilamos el grafo con el `checkpointer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo representamos gráficamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Error al visualizar el grafo: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hagamos que nuestro gráfico dé un par de pasos. Cada paso será guardado en el historial del estado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos la primera llamada al modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm learning LangGraph. Could you do some research on it for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (0)\n",
      " Call ID: 0\n",
      "  Args:\n",
      "    query: LangGraph\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"LangGraph Quickstart - GitHub Pages\", \"url\": \"https://langchain-ai.github.io/langgraph/tutorials/introduction/\", \"content\": \"[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-9-1)Assistant: LangGraph is a library designed to help build stateful multi-agent applications using language models. It provides tools for creating workflows and state machines to coordinate multiple AI agents or language model interactions. LangGraph is built on top of LangChain, leveraging its components while adding graph-based coordination capabilities. It's particularly useful for developing more complex, [...] [](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-6)   LangGraph is a library designed for building stateful, multi-actor applications with Large Language Models (LLMs). It's particularly useful for creating agent and multi-agent workflows.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-8)2. Developer: [...] [](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-19)LangGraph is likely a framework or library designed specifically for creating AI agents with advanced capabilities. Here are a few points to consider based on this recommendation:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-20)\", \"score\": 0.9032571072124412}, {\"title\": \"langchain-ai/langgraph: Build resilient language agents as graphs.\", \"url\": \"https://github.com/langchain-ai/langgraph\", \"content\": \"Note\\nLooking for the JS version? See the JS repo and the JS docs.\\nLangGraph — used by Replit, Uber, LinkedIn, GitLab and more — is a low-level orchestration framework for building controllable agents. While langchain provides integrations and composable components to streamline LLM application development, the LangGraph library enables agent orchestration — offering customizable architectures, long-term memory, and human-in-the-loop to reliably handle complex tasks.\\nshell [...] LangGraph is built for developers who want to build powerful, adaptable AI agents. Developers choose LangGraph for: [...] While LangGraph is our open-source agent orchestration framework, enterprises that need scalable agent deployment can benefit from LangGraph Platform.\\nLangGraph Platform can help engineering teams:\", \"score\": 0.8625389469131455}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph is a library built on top of LangChain, designed to facilitate the creation of stateful, multi-agent applications using large language models (LLMs). It offers tools for crafting workflows and state machines to coordinate interactions among multiple AI agents or language models. Key features include customizable architectures, support for long-term memory, and the ability to incorporate human-in-the-loop for managing complex tasks. This makes it particularly useful for developers looking to build powerful and adaptable AI agents. For more detailed information and tutorials, you can visit the official [LangGraph Quickstart guide](https://langchain-ai.github.io/langgraph/tutorials/introduction/) or the [LangGraph GitHub repository](https://github.com/langchain-ai/langgraph).\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    \"I'm learning LangGraph. \"\n",
    "                    \"Could you do some research on it for me?\"\n",
    "                ),\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora la segunda llamada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Ya that's helpful. Maybe I'll build an autonomous agent with it!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That sounds like an exciting project! Building an autonomous agent with LangGraph can be a rewarding experience. If you have any specific questions or need guidance along the way, feel free to ask. Good luck with your development!\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    \"Ya that's helpful. Maybe I'll \"\n",
    "                    \"build an autonomous agent with it!\"\n",
    "                ),\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que hemos hecho dos llamadas al modelo, vamos a ver el historial del estado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Messages:  6 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  5 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  4 Next:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  4 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  3 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  2 Next:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  1 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  0 Next:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "to_replay = None\n",
    "for state in graph.get_state_history(config):\n",
    "    print(\"Num Messages: \", len(state.values[\"messages\"]), \"Next: \", state.next)\n",
    "    print(\"-\" * 80)\n",
    "    if len(state.values[\"messages\"]) == 2:\n",
    "        # We are somewhat arbitrarily selecting a specific state based on the number of chat messages in the state.\n",
    "        to_replay = state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos guardado en `to_replay` el estado después del nodo del chatbot. Podemos volver a ese estado y continuar el flujo desde allí."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para reanudar el flujo en ese estado hay que usar el método `next`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('tools',)\n"
     ]
    }
   ],
   "source": [
    "print(to_replay.next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La configuración del checkpoint contiene el `checkpoint_id`, que es un timestamp del flujo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f00684f-a9cd-6570-8001-e85959dd7e1b'}}\n"
     ]
    }
   ],
   "source": [
    "print(to_replay.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dando este `checkpoint_id` a `LangGrah` carga el estado en ese momento del flujo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (0)\n",
      " Call ID: 0\n",
      "  Args:\n",
      "    query: LangGraph\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"LangGraph Quickstart - GitHub Pages\", \"url\": \"https://langchain-ai.github.io/langgraph/tutorials/introduction/\", \"content\": \"[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-9-1)Assistant: LangGraph is a library designed to help build stateful multi-agent applications using language models. It provides tools for creating workflows and state machines to coordinate multiple AI agents or language model interactions. LangGraph is built on top of LangChain, leveraging its components while adding graph-based coordination capabilities. It's particularly useful for developing more complex, [...] [](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-6)   LangGraph is a library designed for building stateful, multi-actor applications with Large Language Models (LLMs). It's particularly useful for creating agent and multi-agent workflows.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-8)2. Developer: [...] [](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-19)LangGraph is likely a framework or library designed specifically for creating AI agents with advanced capabilities. Here are a few points to consider based on this recommendation:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-20)\", \"score\": 0.9032571072124412}, {\"title\": \"langchain-ai/langgraph: Build resilient language agents as graphs.\", \"url\": \"https://github.com/langchain-ai/langgraph\", \"content\": \"Note\\nLooking for the JS version? See the JS repo and the JS docs.\\nLangGraph — used by Replit, Uber, LinkedIn, GitLab and more — is a low-level orchestration framework for building controllable agents. While langchain provides integrations and composable components to streamline LLM application development, the LangGraph library enables agent orchestration — offering customizable architectures, long-term memory, and human-in-the-loop to reliably handle complex tasks.\\nshell [...] LangGraph is built for developers who want to build powerful, adaptable AI agents. Developers choose LangGraph for: [...] While LangGraph is our open-source agent orchestration framework, enterprises that need scalable agent deployment can benefit from LangGraph Platform.\\nLangGraph Platform can help engineering teams:\", \"score\": 0.8625389469131455}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (0)\n",
      " Call ID: 0\n",
      "  Args:\n",
      "    query: LangGraph library for building multi-agent applications with language models\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"LangGraph Uncovered: Building Stateful Multi-Agent Applications ...\", \"url\": \"https://dev.to/sreeni5018/langgraph-uncovered-building-stateful-multi-agent-applications-with-llms-part-i-p86\", \"content\": \"Seenivasa RamaduraiPosted on Feb 10\\n       \\nLangGraph Uncovered: Building Stateful Multi-Agent Applications with LLMs-Part I\\n#langgraph #multiagent\\nIntroduction\\nThe field of AI-driven applications is advancing rapidly, with LangGraph emerging as a cutting-edge framework for developing intelligent multi-agent systems. Created by the team behind LangChain, LangGraph is an open-source library designed to enable developers to build stateful, structured workflows for Large Language Models (LLMs). [...] LangGraph distinguishes itself from traditional actor-based models by introducing a shared state mechanism. This approach enhances collaboration and control over agent interactions, moving beyond isolated message queues.\\nThis blog will delve into LangGraph's core features, its differences from traditional actor models, and practical applications. By the end, you will understand how to leverage LangGraph to build robust AI-powered applications.\", \"score\": 0.8229665345454544}, {\"title\": \"langchain-ai/langgraph: Build resilient language agents as graphs.\", \"url\": \"https://github.com/langchain-ai/langgraph\", \"content\": \"Note\\nLooking for the JS version? See the JS repo and the JS docs.\\nLangGraph — used by Replit, Uber, LinkedIn, GitLab and more — is a low-level orchestration framework for building controllable agents. While langchain provides integrations and composable components to streamline LLM application development, the LangGraph library enables agent orchestration — offering customizable architectures, long-term memory, and human-in-the-loop to reliably handle complex tasks.\\nshell [...] While LangGraph can be used standalone, it also integrates seamlessly with any LangChain product, giving developers a full suite of tools for building agents. To improve your LLM application development, pair LangGraph with:\", \"score\": 0.7898933337727273}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (0)\n",
      " Call ID: 0\n",
      "  Args:\n",
      "    query: LangGraph\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"LangGraph Quickstart - GitHub Pages\", \"url\": \"https://langchain-ai.github.io/langgraph/tutorials/introduction/\", \"content\": \"[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-9-1)Assistant: LangGraph is a library designed to help build stateful multi-agent applications using language models. It provides tools for creating workflows and state machines to coordinate multiple AI agents or language model interactions. LangGraph is built on top of LangChain, leveraging its components while adding graph-based coordination capabilities. It's particularly useful for developing more complex, [...] [](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-6)   LangGraph is a library designed for building stateful, multi-actor applications with Large Language Models (LLMs). It's particularly useful for creating agent and multi-agent workflows.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-8)2. Developer: [...] [](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-19)LangGraph is likely a framework or library designed specifically for creating AI agents with advanced capabilities. Here are a few points to consider based on this recommendation:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-20)\", \"score\": 0.9032571072124412}, {\"title\": \"langchain-ai/langgraph: Build resilient language agents as graphs.\", \"url\": \"https://github.com/langchain-ai/langgraph\", \"content\": \"Note\\nLooking for the JS version? See the JS repo and the JS docs.\\nLangGraph — used by Replit, Uber, LinkedIn, GitLab and more — is a low-level orchestration framework for building controllable agents. While langchain provides integrations and composable components to streamline LLM application development, the LangGraph library enables agent orchestration — offering customizable architectures, long-term memory, and human-in-the-loop to reliably handle complex tasks.\\nshell [...] LangGraph is built for developers who want to build powerful, adaptable AI agents. Developers choose LangGraph for: [...] While LangGraph is our open-source agent orchestration framework, enterprises that need scalable agent deployment can benefit from LangGraph Platform.\\nLangGraph Platform can help engineering teams:\", \"score\": 0.8625389469131455}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (0)\n",
      " Call ID: 0\n",
      "  Args:\n",
      "    query: LangGraph library for building stateful multi-agent applications using language models\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"LangGraph - CopilotKit\", \"url\": \"https://docs.copilotkit.ai/coagents/concepts/langgraph\", \"content\": \"LangGraph is an agentic framework for building LLM applications that can be used with Copilotkit. It is built on top of LangChain's LangGraph library and extends it with additional functionality for building agentic applications.\\nCoAgents and LangGraph\\nHow do CoAgents extend LangGraph? Let's read the first sentence of their project page to understand.\\n\\nLangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows.\", \"score\": 0.8715619834710744}, {\"title\": \"Introduction to LangGraph: A Beginner's Guide - Medium\", \"url\": \"https://medium.com/@cplog/introduction-to-langgraph-a-beginners-guide-14f9be027141\", \"content\": \"LangGraph is a powerful tool for building stateful, multi-actor applications with Large Language Models (LLMs). It extends the LangChain library, allowing you to coordinate multiple chains (or actors) across multiple steps of computation in a cyclic manner. In this article, we’ll introduce LangGraph, walk you through its basic concepts, and share some insights and common points of confusion for beginners.\\nWhat is LangGraph?\", \"score\": 0.8630661859504132}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph is an advanced library and framework designed for building stateful, multi-agent applications using Large Language Models (LLMs). It is built on top of LangChain and is used to create complex workflows and state machines to coordinate multiple AI agents or language model interactions. LangGraph introduces a shared state mechanism, distinguishing itself from traditional actor-based models by enhancing collaboration and control over agent interactions. It is particularly useful for developers who are looking to build powerful, adaptable AI agents, and it supports long-term memory and human-in-the-loop interactions. For more detailed information and to get started, you can visit the official LangGraph Quickstart guide at [LangGraph Quickstart - GitHub Pages](https://langchain-ai.github.io/langgraph/tutorials/introduction/) or explore the [LangGraph GitHub repository](https://github.com/langchain-ai/langgraph).\n"
     ]
    }
   ],
   "source": [
    "# The `checkpoint_id` in the `to_replay.config` corresponds to a state we've persisted to our checkpointer.\n",
    "for event in graph.stream(None, to_replay.config, stream_mode=\"values\"):\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El grafo reanudó la ejecución desde el nodo `action`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
