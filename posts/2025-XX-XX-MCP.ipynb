{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Context Protocol (MCP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¬øQu√© es MCP?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MCP (Model Context Protocol) es un estandar open source desarrollado por Anthropic para permitir a los modelos de IA interactuar con herramientas externas mediante un estandar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta el desarrollo del protocolo MCP, cuando quer√≠amos que un LLM interactuara con herramientas, ten√≠amos que crear c√≥digo para poder interactuar con la herramienta, y mediante `function calling` enviarle la informaci√≥n al LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MCP vs API](https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/MCP_vs_APIs.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As√≠ que mediante MCP, un LLM puede interactuar con herramientas gracias a un estandar. De esta manera si una persona crea un servidor MCP, dicho servidor puede ser reutilizado por otros con un √∫nico cliente. Si en tu aplicaci√≥n desarrollas un cliente, puedes descargarte un servidor MCP desarrollado por otro, y usarlo sin problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comunmente MCP se asemeja al estandar USB. Antes del USB, cada perif√©rico ten√≠a un tipo de conexi√≥n diferente, unos ten√≠an puertos serie, otros paralelo. Diferentes formatos de conectores, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![USB MCP](https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/mcp-usb.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la llegada del USB, todos los perif√©ricos se adaptaron a este estandar, por lo que con un solo conector USB en tu ordenador, puedes conectar casi cualquier perif√©rico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MCP tiene 7 componentes principales:\n",
    " * **Host**: Aplicaci√≥n LLM que tiene acceso a herramientas MCP.\n",
    " * **Servidor MCP**: Servidor que realiza la comunicaci√≥n con la API o herramienta a la que queremos exponer al LLM\n",
    " * **Cliente MCP**: Cliente que se conecta al servidor MCP y realiza las peticiones\n",
    " * **Tool**: Funci√≥n que se ejecuta en el servidor MCP y que puede ser invocada por el LLM\n",
    " * **Resource**: Recurso que se puede usar en el servidor MCP. Suelen dar al LLM acceso a recursos est√°ticos como archivos, bases de datos, etc.\n",
    " * **Resource template**: Template para crear recursos din√°micos. Mediante estas plantillas, el LLM puede crear din√°micamente el recurso al que quiere acceder\n",
    " * **Prompt**: Prompt que se usa para generar un prompt que ser√° usado por el LLM para interactuar con el servidor MCP.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un √∫nico host (aplicaci√≥n) puede tener varios clientes. Cada cliente se conectar√° a un servidor MCP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![mcp architecture](https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/mcp-system-architecture.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastMCP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque en la documentaci√≥n de MCP recomiendan instalar `mcp[\"cli\"]`, hay una librer√≠a creada por encima llamada `fastmcp`, que ayuda mucho a la hora de crear servidores MCP, as√≠ que vamos a usarla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear entorno virtual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para crear un servidor y un cliente MCP, vamos a crear entornos virtuales con `uv` con las dependencias que vamos a necesitar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Servidor MCP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero creamos una carpeta para el servidor de MCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir gitHub_MCP_server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniciamos el entorno `uv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized project `github-mcp-server` at `/Users/macm1/Documents/web/portafolio/posts/gitHub_MCP_server`\n"
     ]
    }
   ],
   "source": [
    "!cd gitHub_MCP_server && uv init ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo activamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPython 3.11.11\n",
      "Creating virtual environment at: .venv\n",
      "Activate with: source .venv/bin/activate\n"
     ]
    }
   ],
   "source": [
    "!cd gitHub_MCP_server && uv venv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E instalamos las linrer√≠as necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolved 42 packages in 34ms\n",
      "Installed 40 packages in 71ms\n",
      " \u001b[32m+\u001b[39m \u001b[1mannotated-types\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1manyio\u001b[0m\u001b[2m==4.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mauthlib\u001b[0m\u001b[2m==1.6.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcertifi\u001b[0m\u001b[2m==2025.6.15\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcffi\u001b[0m\u001b[2m==1.17.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcharset-normalizer\u001b[0m\u001b[2m==3.4.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mclick\u001b[0m\u001b[2m==8.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcryptography\u001b[0m\u001b[2m==45.0.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdistro\u001b[0m\u001b[2m==1.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mexceptiongroup\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfastmcp\u001b[0m\u001b[2m==2.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mh11\u001b[0m\u001b[2m==0.16.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttpcore\u001b[0m\u001b[2m==1.0.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttpx\u001b[0m\u001b[2m==0.28.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttpx-sse\u001b[0m\u001b[2m==0.4.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1midna\u001b[0m\u001b[2m==3.10\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjiter\u001b[0m\u001b[2m==0.10.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarkdown-it-py\u001b[0m\u001b[2m==3.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmcp\u001b[0m\u001b[2m==1.9.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmdurl\u001b[0m\u001b[2m==0.1.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopenapi-pydantic\u001b[0m\u001b[2m==0.5.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpycparser\u001b[0m\u001b[2m==2.22\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic\u001b[0m\u001b[2m==2.11.7\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic-core\u001b[0m\u001b[2m==2.33.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic-settings\u001b[0m\u001b[2m==2.10.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpygments\u001b[0m\u001b[2m==2.19.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-dotenv\u001b[0m\u001b[2m==1.1.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-multipart\u001b[0m\u001b[2m==0.0.20\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrequests\u001b[0m\u001b[2m==2.32.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrich\u001b[0m\u001b[2m==14.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mshellingham\u001b[0m\u001b[2m==1.5.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msniffio\u001b[0m\u001b[2m==1.3.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msse-starlette\u001b[0m\u001b[2m==2.3.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mstarlette\u001b[0m\u001b[2m==0.47.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyper\u001b[0m\u001b[2m==0.16.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyping-extensions\u001b[0m\u001b[2m==4.14.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyping-inspection\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyping-inspection\u001b[0m\u001b[2m==0.4.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd gitHub_MCP_server && uv add anthropic fastmcp python-dotenv requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cliente MCP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora creamos una carpeta donde programaremos el cliente MCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir client_MCP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniciamos el entorno uv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized project `client-mcp` at `/Users/macm1/Documents/web/portafolio/posts/client_MCP`\n"
     ]
    }
   ],
   "source": [
    "!cd client_MCP && uv init ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo activamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPython 3.11.11\n",
      "Creating virtual environment at: .venv\n",
      "Activate with: source .venv/bin/activate\n"
     ]
    }
   ],
   "source": [
    "!cd client_MCP && uv venv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y por √∫ltimo, instalamos las librer√≠as necesarias para el cliente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolved 42 packages in 307ms\n",
      "Prepared 5 packages in 115ms\n",
      "Installed 40 packages in 117ms\n",
      " \u001b[32m+\u001b[39m \u001b[1mannotated-types\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1manthropic\u001b[0m\u001b[2m==0.55.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1manyio\u001b[0m\u001b[2m==4.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mauthlib\u001b[0m\u001b[2m==1.6.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcertifi\u001b[0m\u001b[2m==2025.6.15\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcffi\u001b[0m\u001b[2m==1.17.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcharset-normalizer\u001b[0m\u001b[2m==3.4.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mclick\u001b[0m\u001b[2m==8.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcryptography\u001b[0m\u001b[2m==45.0.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdistro\u001b[0m\u001b[2m==1.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mexceptiongroup\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfastmcp\u001b[0m\u001b[2m==2.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mh11\u001b[0m\u001b[2m==0.16.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttpcore\u001b[0m\u001b[2m==1.0.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttpx\u001b[0m\u001b[2m==0.28.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttpx-sse\u001b[0m\u001b[2m==0.4.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1midna\u001b[0m\u001b[2m==3.10\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjiter\u001b[0m\u001b[2m==0.10.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarkdown-it-py\u001b[0m\u001b[2m==3.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmcp\u001b[0m\u001b[2m==1.9.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmdurl\u001b[0m\u001b[2m==0.1.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopenapi-pydantic\u001b[0m\u001b[2m==0.5.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpycparser\u001b[0m\u001b[2m==2.22\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic\u001b[0m\u001b[2m==2.11.7\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic-core\u001b[0m\u001b[2m==2.33.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic-settings\u001b[0m\u001b[2m==2.10.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpygments\u001b[0m\u001b[2m==2.19.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-dotenv\u001b[0m\u001b[2m==1.1.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-multipart\u001b[0m\u001b[2m==0.0.20\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrequests\u001b[0m\u001b[2m==2.32.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrich\u001b[0m\u001b[2m==14.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mshellingham\u001b[0m\u001b[2m==1.5.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msniffio\u001b[0m\u001b[2m==1.3.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msse-starlette\u001b[0m\u001b[2m==2.3.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mstarlette\u001b[0m\u001b[2m==0.47.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyper\u001b[0m\u001b[2m==0.16.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyping-extensions\u001b[0m\u001b[2m==4.14.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyping-inspection\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyping-inspection\u001b[0m\u001b[2m==0.4.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd client_MCP && uv add anthropic fastmcp python-dotenv requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a usar Sonnet 3.5 como modelo LLM, as√≠ que creamos un archivo `.env` en la carpeta del cliente con la API KEY de Claude que se puede obtener en la p√°gina [keys](https://console.anthropic.com/settings/keys) de la API de Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing client_MCP/.env\n"
     ]
    }
   ],
   "source": [
    "%%writefile client_MCP/.env\n",
    "\n",
    "ANTHROPIC_API_KEY=\"ANTHROPIC_API_KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCP b√°sico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escrib√≠mos el m√≠nimo c√≥digo que necesitamos para tener un servidor MCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting gitHub_MCP_server/github_server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile gitHub_MCP_server/github_server.py\n",
    "\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "\n",
    "# Create an MCP server\n",
    "mcp = FastMCP(\"GitHubMCP\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize and run the server\n",
    "    mcp.run(transport='stdio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver, tenemos que crear un objeto `FastMCP` y luego ejecutar el servidor con `mcp.run`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librer√≠a con funciones para leer de GitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vamos a crear un servidor MCP para poder usar utilidades de GitHub, vamos a crear un archivo con las funciones necesarias para construir los headers necesarios para poder usar la API de GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting gitHub_MCP_server/github.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile gitHub_MCP_server/github.py\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the GitHub token from the .env file\n",
    "load_dotenv()\n",
    "GITHUB_TOKEN = os.environ.get(\"GITHUB_TOKEN\")\n",
    "\n",
    "# Check if the GitHub token is configured\n",
    "if not GITHUB_TOKEN:\n",
    "    print(\"WARNING: The GITHUB_TOKEN environment variable is not configured.\")\n",
    "    print(\"Requests to the GitHub API may fail due to rate limits.\")\n",
    "    print(\"Create a .env file in this directory with GITHUB_TOKEN='your_token_here'\")\n",
    "    raise ValueError(\"GITHUB_TOKEN is not configured\")\n",
    "\n",
    "# Helper function to create headers for GitHub API requests\n",
    "def create_github_headers():\n",
    "    headers = {}\n",
    "    if GITHUB_TOKEN:\n",
    "        headers[\"Authorization\"] = f\"Bearer {GITHUB_TOKEN}\"\n",
    "    # GitHub recommends including a User-Agent\n",
    "    headers[\"User-Agent\"] = \"MCP_GitHub_Server_Example\"\n",
    "    headers[\"Accept\"] = \"application/vnd.github.v3+json\" # Good practice\n",
    "    return headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder construir los headers, necesitamos una token de GitHub. Para ello, vamos a [personal-access-tokens](https://github.com/settings/personal-access-tokens) y creamos una nueva token. Lo copiamos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, creamos un `.env`, d√≥nde vamos a almacenar el token de GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting gitHub_MCP_server/.env\n"
     ]
    }
   ],
   "source": [
    "%%writefile gitHub_MCP_server/.env\n",
    "\n",
    "GITHUB_TOKEN = \"GITHUB_TOKEN\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear `tool` de MCP para obtener una lista de issues de un repositorio de GitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Servidor MCP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A√±adimos una funci√≥n para poder listar los issues de un repositorio de GitHub. Para convertir dicha funci√≥n en una `tool` de MCP, usamos el decorador `@mcp.tool()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting gitHub_MCP_server/github_server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile gitHub_MCP_server/github_server.py\n",
    "\n",
    "import httpx\n",
    "from fastmcp import FastMCP\n",
    "from github import GITHUB_TOKEN, create_github_headers\n",
    "\n",
    "# Create a FastMCP server\n",
    "mcp = FastMCP(\"GitHubMCP\")\n",
    "\n",
    "@mcp.tool()\n",
    "async def list_repository_issues(owner: str, repo_name: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Lists open issues for a given GitHub repository.\n",
    "\n",
    "    Args:\n",
    "        owner: The owner of the repository (e.g., 'modelcontextprotocol')\n",
    "        repo_name: The name of the repository (e.g., 'python-sdk')\n",
    "\n",
    "    Returns:\n",
    "        list[dict]: A list of dictionaries, each containing information about an issue\n",
    "    \"\"\"\n",
    "    # Limit to the first 10 issues to avoid long responses\n",
    "    api_url = f\"https://api.github.com/repos/{owner}/{repo_name}/issues?state=open&per_page=10\"\n",
    "    print(f\"Fetching issues from {api_url}...\")\n",
    "    \n",
    "    async with httpx.AsyncClient() as client:\n",
    "        try:\n",
    "            response = await client.get(api_url, headers=create_github_headers())\n",
    "            response.raise_for_status()\n",
    "            issues_data = response.json()\n",
    "            \n",
    "            if not issues_data:\n",
    "                print(\"No open issues found for this repository.\")\n",
    "                return [{\"message\": \"No open issues found for this repository.\"}]\n",
    "\n",
    "            issues_summary = []\n",
    "            for issue in issues_data:\n",
    "                # Create a more concise summary\n",
    "                summary = f\"#{issue.get('number', 'N/A')}: {issue.get('title', 'Sin t√≠tulo')}\"\n",
    "                if issue.get('comments', 0) > 0:\n",
    "                    summary += f\" ({issue.get('comments')} comentarios)\"\n",
    "                \n",
    "                issues_summary.append({\n",
    "                    \"number\": issue.get(\"number\"),\n",
    "                    \"title\": issue.get(\"title\"),\n",
    "                    \"user\": issue.get(\"user\", {}).get(\"login\"),\n",
    "                    \"url\": issue.get(\"html_url\"),\n",
    "                    \"comments\": issue.get(\"comments\"),\n",
    "                    \"summary\": summary\n",
    "                })\n",
    "            \n",
    "            print(f\"Found {len(issues_summary)} open issues.\")\n",
    "            \n",
    "            # Add context information\n",
    "            result = {\n",
    "                \"total_found\": len(issues_summary),\n",
    "                \"repository\": f\"{owner}/{repo_name}\",\n",
    "                \"note\": \"Mostrando los primeros 10 issues abiertos\" if len(issues_summary) == 10 else f\"Mostrando todos los {len(issues_summary)} issues abiertos\",\n",
    "                \"issues\": issues_summary\n",
    "            }\n",
    "            \n",
    "            return [result]\n",
    "            \n",
    "        except httpx.HTTPStatusError as e:\n",
    "            error_message = e.response.json().get(\"message\", \"No additional message from API.\")\n",
    "            if e.response.status_code == 403 and GITHUB_TOKEN:\n",
    "                error_message += \" (Rate limit with token or token lacks permissions?)\"\n",
    "            elif e.response.status_code == 403 and not GITHUB_TOKEN:\n",
    "                error_message += \" (Rate limit without token. Consider creating a .env file with GITHUB_TOKEN.)\"\n",
    "            \n",
    "            print(f\"GitHub API error: {e.response.status_code}. {error_message}\")\n",
    "            return [{\n",
    "                \"error\": f\"GitHub API error: {e.response.status_code}\",\n",
    "                \"message\": error_message\n",
    "            }]\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {str(e)}\")\n",
    "            return [{\"error\": f\"An unexpected error occurred: {str(e)}\"}]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"DEBUG: Starting GitHub FastMCP server...\")\n",
    "    print(f\"DEBUG: Server name: {mcp.name}\")\n",
    "    print(\"DEBUG: Available tools: list_repository_issues\")\n",
    "    \n",
    "    # Initialize and run the server\n",
    "    mcp.run() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cliente MCP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora creamos un cliente MCP para poder usar la `tool` que hemos creado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting client_MCP/client.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile client_MCP/client.py\n",
    "\n",
    "import sys\n",
    "import asyncio\n",
    "from contextlib import AsyncExitStack\n",
    "from anthropic import Anthropic\n",
    "from dotenv import load_dotenv\n",
    "from fastmcp import Client\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "class FastMCPClient:\n",
    "    \"\"\"\n",
    "    FastMCP client that integrates with Claude to process user queries\n",
    "    and use tools exposed by a FastMCP server.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the FastMCP client with Anthropic and resource management.\"\"\"\n",
    "        self.exit_stack = AsyncExitStack()\n",
    "        self.anthropic = Anthropic()\n",
    "        self.client = None\n",
    "        \n",
    "    async def connect_to_server(self, server_script_path: str):\n",
    "        \"\"\"\n",
    "        Connect to the specified FastMCP server.\n",
    "        \n",
    "        Args:\n",
    "            server_script_path: Path to the server script (Python)\n",
    "        \"\"\"\n",
    "        print(f\"üîó Connecting to FastMCP server: {server_script_path}\")\n",
    "        \n",
    "        # Determine the server type based on the extension\n",
    "        if not server_script_path.endswith('.py'):\n",
    "            raise ValueError(f\"Unsupported server type. Use .py files. Received: {server_script_path}\")\n",
    "        \n",
    "        # Create FastMCP client \n",
    "        self.client = Client(server_script_path)\n",
    "        # Note: FastMCP Client automatically infers transport from .py files\n",
    "        \n",
    "        print(\"‚úÖ Client created successfully\")\n",
    "        \n",
    "    async def list_available_tools(self):\n",
    "        \"\"\"List available tools in the FastMCP server.\"\"\"\n",
    "        try:\n",
    "            # Get list of tools from the server using FastMCP context\n",
    "            async with self.client as client:\n",
    "                tools = await client.list_tools()\n",
    "                \n",
    "                if tools:\n",
    "                    print(f\"\\nüõ†Ô∏è  Available tools ({len(tools)}):\")\n",
    "                    print(\"=\" * 50)\n",
    "                    \n",
    "                    for tool in tools:\n",
    "                        print(f\"üìã {tool.name}\")\n",
    "                        if tool.description:\n",
    "                            print(f\"   Description: {tool.description}\")\n",
    "                        \n",
    "                        # Show parameters if available\n",
    "                        if hasattr(tool, 'inputSchema') and tool.inputSchema:\n",
    "                            if 'properties' in tool.inputSchema:\n",
    "                                params = list(tool.inputSchema['properties'].keys())\n",
    "                                print(f\"   Parameters: {', '.join(params)}\")\n",
    "                        print()\n",
    "                else:\n",
    "                    print(\"‚ö†Ô∏è  No tools found in the server\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error listing tools: {str(e)}\")\n",
    "\n",
    "    async def process_query(self, query: str) -> str:\n",
    "        \"\"\"\n",
    "        Process a user query, interacting with Claude and FastMCP tools.\n",
    "        \n",
    "        Args:\n",
    "            query: User query\n",
    "            \n",
    "        Returns:\n",
    "            str: Final processed response\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Use FastMCP context for all operations\n",
    "            async with self.client as client:\n",
    "                # Get available tools\n",
    "                tools_list = await client.list_tools()\n",
    "                \n",
    "                # Prepare tools for Claude in correct format\n",
    "                claude_tools = []\n",
    "                for tool in tools_list:\n",
    "                    claude_tool = {\n",
    "                        \"name\": tool.name,\n",
    "                        \"description\": tool.description or f\"Tool {tool.name}\",\n",
    "                        \"input_schema\": tool.inputSchema or {\"type\": \"object\", \"properties\": {}}\n",
    "                    }\n",
    "                    claude_tools.append(claude_tool)\n",
    "                \n",
    "                # Create initial message for Claude\n",
    "                messages = [\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": query\n",
    "                    }\n",
    "                ]\n",
    "                \n",
    "                # First call to Claude\n",
    "                response = self.anthropic.messages.create(\n",
    "                    model=\"claude-3-5-sonnet-20241022\",\n",
    "                    max_tokens=6000,\n",
    "                    messages=messages,\n",
    "                    tools=claude_tools if claude_tools else None\n",
    "                )\n",
    "                \n",
    "                # Process Claude's response\n",
    "                response_text = \"\"\n",
    "                \n",
    "                for content_block in response.content:\n",
    "                    if content_block.type == \"text\":\n",
    "                        response_text += content_block.text\n",
    "                        \n",
    "                    elif content_block.type == \"tool_use\":\n",
    "                        # Claude wants to use a tool\n",
    "                        tool_name = content_block.name\n",
    "                        tool_args = content_block.input\n",
    "                        tool_call_id = content_block.id\n",
    "                        \n",
    "                        print(f\"üîß Claude wants to use: {tool_name}\")\n",
    "                        print(f\"üìù Arguments: {tool_args}\")\n",
    "                        \n",
    "                        try:\n",
    "                            # Execute tool on the FastMCP server\n",
    "                            tool_result = await client.call_tool(tool_name, tool_args)\n",
    "                            \n",
    "                            print(f\"‚úÖ Tool executed successfully\")\n",
    "                            \n",
    "                            # Add tool result to the conversation\n",
    "                            messages.append({\n",
    "                                \"role\": \"assistant\", \n",
    "                                \"content\": response.content\n",
    "                            })\n",
    "                            \n",
    "                            # Format result for Claude\n",
    "                            if tool_result:\n",
    "                                # Convert result to string format for Claude\n",
    "                                result_content = str(tool_result)\n",
    "                                \n",
    "                                messages.append({\n",
    "                                    \"role\": \"user\",\n",
    "                                    \"content\": [{\n",
    "                                        \"type\": \"tool_result\",\n",
    "                                        \"tool_use_id\": tool_call_id,\n",
    "                                        \"content\": f\"Tool result: {result_content}\"\n",
    "                                    }]\n",
    "                                })\n",
    "                            else:\n",
    "                                messages.append({\n",
    "                                    \"role\": \"user\", \n",
    "                                    \"content\": [{\n",
    "                                        \"type\": \"tool_result\",\n",
    "                                        \"tool_use_id\": tool_call_id, \n",
    "                                        \"content\": \"Tool executed without response content\"\n",
    "                                    }]\n",
    "                                })\n",
    "                            \n",
    "                            # Second call to Claude with the tool result\n",
    "                            final_response = self.anthropic.messages.create(\n",
    "                                model=\"claude-3-5-sonnet-20241022\",\n",
    "                                max_tokens=6000,\n",
    "                                messages=messages,\n",
    "                                tools=claude_tools if claude_tools else None\n",
    "                            )\n",
    "                            \n",
    "                            # Extract text from the final response\n",
    "                            for final_content in final_response.content:\n",
    "                                if final_content.type == \"text\":\n",
    "                                    response_text += final_content.text\n",
    "                                    \n",
    "                        except Exception as e:\n",
    "                            error_msg = f\"‚ùå Error executing {tool_name}: {str(e)}\"\n",
    "                            print(error_msg)\n",
    "                            response_text += f\"\\n\\n{error_msg}\"\n",
    "                \n",
    "                return response_text\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"‚ùå Error processing query: {str(e)}\"\n",
    "            print(error_msg)\n",
    "            return error_msg\n",
    "    \n",
    "    async def chat_loop(self):\n",
    "        \"\"\"\n",
    "        Main chat loop with user interaction.\n",
    "        \"\"\"\n",
    "        print(\"\\nü§ñ FastMCP client started. Write 'quit', 'q', 'exit', 'salir' to exit.\")\n",
    "        print(\"üí¨ You can ask questions about GitHub repositories!\")\n",
    "        print(\"üìö The client can use tools from the FastMCP server\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                # Request user input\n",
    "                user_input = input(\"\\nüë§ You: \").strip()\n",
    "                \n",
    "                if user_input.lower() in ['quit', 'q', 'exit', 'salir']:\n",
    "                    print(\"üëã Bye!\")\n",
    "                    break\n",
    "                    \n",
    "                if not user_input:\n",
    "                    continue\n",
    "                \n",
    "                print(\"\\nü§î Claude is thinking...\")\n",
    "                \n",
    "                # Process query\n",
    "                response = await self.process_query(user_input)\n",
    "                \n",
    "                # Show response\n",
    "                print(f\"\\nü§ñ Claude: {response}\")\n",
    "                \n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\n\\nüëã Disconnecting...\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"\\n‚ùå Error in chat: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    async def cleanup(self):\n",
    "        \"\"\"Clean up resources and close connections.\"\"\"\n",
    "        print(\"üßπ Cleaning up resources...\")\n",
    "        # FastMCP Client cleanup is handled automatically by context manager\n",
    "        await self.exit_stack.aclose()\n",
    "        print(\"‚úÖ Resources released\")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    \"\"\"\n",
    "    Main function that initializes and runs the FastMCP client.\n",
    "    \"\"\"\n",
    "    # Verify command line arguments\n",
    "    if len(sys.argv) != 2:\n",
    "        print(\"‚ùå Usage: python client.py <path_to_fastmcp_server>\")\n",
    "        print(\"üìù Example: python client.py ../MCP_github/github_server.py\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    server_script_path = sys.argv[1]\n",
    "    \n",
    "    # Create and run client\n",
    "    client = FastMCPClient()\n",
    "    \n",
    "    try:\n",
    "        # Connect to the server\n",
    "        await client.connect_to_server(server_script_path)\n",
    "        \n",
    "        # List available tools after connection\n",
    "        await client.list_available_tools()\n",
    "        \n",
    "        # Start chat loop\n",
    "        await client.chat_loop()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Fatal error: {str(e)}\")\n",
    "    finally:\n",
    "        # Ensure resources are cleaned up\n",
    "        await client.cleanup()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Entry point of the script\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicaci√≥n del cliente MCP\n",
    "\n",
    " * En `main` se comprueba que se ha pasado un argumento con el path del servidor MCP.\n",
    " * Se crea un objeto de la clase `FastMCPClient` con el path del servidor MCP. Al crear el objeto se ejecuta el m√©todo `__init__` que crea la conexi√≥n con el LLM de Anthropic, que va a ser el LLM que va a poner el \"cerebro\"\n",
    " * Se intenta conectar con el servidor MCP llamando al m√©todo `connect_to_server` abrir una sesi√≥n con el servidor MCP.\n",
    " * Se listan las `tool`s disponibles con el m√©todo `list_available_tools`\n",
    " * Si se ha podido conectar, se llama al m√©todo `chat_loop` que es un bucle infinito para chatear con el LLM que se acaba de crear en el cliente. Solo se para la ejecuci√≥n cuando se introduce `quit`, `q`, `exit` o `salir` en el chat.\n",
    " * Se procesa la entrada del usuario con el m√©todo `process_query` que obtiene la lista de `tool`s disponibles y hace una petici√≥n al LLM con el mensaje del usuario y la lista de `tool`s\n",
    "   * Si el LLM responde con texto, se devuelve el texto, que ser√° impreso\n",
    "   * Si el LLM responde con `tool_use`, se obtiene el nombre de la `tool`, los argumentos y se crea una ID de ejecuci√≥n. Se ejecuta la tool. Con el resultado de la tool, se crea un nuevo mensaje que se le manda al LLM para que lo procese y genere una respuesta, que ser√° devuelta e impresa.\n",
    " * Cuando se termine la conversaci√≥n, se llamar√° al m√©todo `cleanup`, que cerrar√° lo que sea necesario cerrar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba de la `tool`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos vamos a la ruta del cliente y lo ejecutamos, d√°ndole la ruta del servidor MCP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Connecting to FastMCP server: ../gitHub_MCP_server/github_server.py\n",
      "‚úÖ Client created successfully\n",
      "[06/28/25 09:22:09] INFO     Starting MCP server 'GitHubMCP' with transport 'stdio'                          server.py:1246\n",
      "\n",
      "üõ†Ô∏è  Available tools (1):\n",
      "==================================================\n",
      "üìã list_repository_issues\n",
      "   Description: Lists open issues for a given GitHub repository.\n",
      "\n",
      "Args:\n",
      "    owner: The owner of the repository (e.g., 'modelcontextprotocol')\n",
      "    repo_name: The name of the repository (e.g., 'python-sdk')\n",
      "\n",
      "Returns:\n",
      "    list[dict]: A list of dictionaries, each containing information about an issue\n",
      "   Parameters: owner, repo_name\n",
      "\n",
      "ü§ñ FastMCP client started. Write 'quit', 'q', 'exit', 'salir' to exit.\n",
      "üí¨ You can ask questions about GitHub repositories!\n",
      "üìö The client can use tools from the FastMCP server\n",
      "------------------------------------------------------------\n",
      "\n",
      "üë§ You: Tell me de issues of repository transformers of huggingface\n",
      "\n",
      "ü§î Claude is thinking...\n",
      "üîß Claude wants to use: list_repository_issues\n",
      "üìù Arguments: {'owner': 'huggingface', 'repo_name': 'transformers'}\n",
      "‚úÖ Tool executed successfully\n",
      "\n",
      "ü§ñ Claude: I'll help you list the issues from the Hugging Face transformers repository. Let me use the `list_repository_issues` function with the appropriate parameters.I'll summarize the current open issues from the Hugging Face transformers repository. Here are the 10 most recent open issues:\n",
      "\n",
      "1. [#39097] Core issue about saving models with multiple shared tensor groups when dispatched\n",
      "2. [#39096] Pull request to fix position index in v4.52.4\n",
      "3. [#39095] Issue with Qwen2_5_VLVisionAttention flash attention missing 'is_causal' attribute\n",
      "4. [#39094] Documentation improvement for PyTorch examples\n",
      "5. [#39093] Style change PR for lru_cache decorator\n",
      "6. [#39091] Compatibility issue with sentencepiece on Windows in Python 3.13\n",
      "7. [#39090] Pull request for fixing bugs in finetune and batch inference\n",
      "8. [#39089] Bug report for LlavaOnevisonConfig initialization in version 4.52.4\n",
      "9. [#39087] Documentation PR for Gemma 3n audio encoder\n",
      "10. [#39084] Pull request for refactoring gemma3n\n",
      "\n",
      "Note that this is showing the 10 most recent open issues, and there might be more issues in the repository. Each issue has a link where you can find more details about the specific problem or proposed changes.\n",
      "\n",
      "Would you like more specific information about any of these issues?\n",
      "\n",
      "üë§ You: q\n",
      "üëã Bye!\n",
      "üßπ Cleaning up resources...\n",
      "‚úÖ Resources released\n"
     ]
    }
   ],
   "source": [
    "!cd client_MCP && source .venv/bin/activate && python client.py ../gitHub_MCP_server/github_server.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ejecutarlo vemos\n",
    "\n",
    "```\n",
    "üõ†Ô∏è  Available tools (1):\n",
    "==================================================\n",
    "üìã list_repository_issues\n",
    "   Description: Lists open issues for a given GitHub repository.\n",
    "\n",
    "Args:\n",
    "    owner: The owner of the repository (e.g., 'modelcontextprotocol')\n",
    "    repo_name: The name of the repository (e.g., 'python-sdk')\n",
    "\n",
    "Returns:\n",
    "    list[dict]: A list of dictionaries, each containing information about an issue\n",
    "   Parameters: owner, repo_name\n",
    "```\n",
    "\n",
    "Lo que indica que el cliente MCP puede ver la `tool` que hemos creado en el servidor MCP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depu√©s podemos ver\n",
    "\n",
    "```\n",
    "üë§ You: Tell me de issues of repository transformers of huggingface\n",
    "\n",
    "ü§î Claude is thinking...\n",
    "üîß Calling tool: list_repository_issues\n",
    "üìù Arguments: {'owner': 'huggingface', 'repo_name': 'transformers'}\n",
    "‚úÖ Tool executed successfully\n",
    "```\n",
    "\n",
    "Le pedimos los issues del repositorio `transformers` de `huggingface`. Tras pensar un rato nos dice que va a usar la `tool` `list_repository_issues` con los argumentos `{'owner': 'huggingface', 'repo_name': 'transformers'}`.\n",
    "\n",
    "Por √∫ltimo, nos dice que la `tool` se ha ejecutado correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por √∫ltimo, con el resultado de ejecutar la `tool`, Claude lo procesa y nos crea una respuesta con la lista de issues.\n",
    "\n",
    "```\n",
    "ü§ñ Claude: I'll help you list the issues from the Hugging Face transformers repository. Let me use the `list_repository_issues` function with the appropriate parameters.I'll summarize the current open issues from the Hugging Face transformers repository. Here are the 10 most recent open issues:\n",
    "\n",
    "1. [#39097] Core issue about saving models with multiple shared tensor groups when dispatched\n",
    "2. [#39096] Pull request to fix position index in v4.52.4\n",
    "3. [#39095] Issue with Qwen2_5_VLVisionAttention flash attention missing 'is_causal' attribute\n",
    "4. [#39094] Documentation improvement for PyTorch examples\n",
    "5. [#39093] Style change PR for lru_cache decorator\n",
    "6. [#39091] Compatibility issue with sentencepiece on Windows in Python 3.13\n",
    "7. [#39090] Pull request for fixing bugs in finetune and batch inference\n",
    "8. [#39089] Bug report for LlavaOnevisonConfig initialization in version 4.52.4\n",
    "9. [#39087] Documentation PR for Gemma 3n audio encoder\n",
    "10. [#39084] Pull request for refactoring gemma3n\n",
    "\n",
    "Note that this is showing the 10 most recent open issues, and there might be more issues in the repository. Each issue has a link where you can find more details about the specific problem or proposed changes.\n",
    "\n",
    "Would you like more specific information about any of these issues?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A√±adir contexto a la `tool`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Servidor MCP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A√±adimos una nueva funci√≥n al servidor MCP que nos permite obtener la informaci√≥n de un repositorio de GitHub. Gracias al decorador `@mcp.resource(\"github://repo/{owner}/{repo_name}\")` convertimos la funci√≥n a un `resource` MCP. Este `resource` es un endpoint al que se le puede pasar el repositorio y el due√±o del repositorio, haciendo que nos devuelva la informaci√≥n del repositorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting gitHub_MCP_server/github_server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile gitHub_MCP_server/github_server.py\n",
    "\n",
    "import httpx\n",
    "from fastmcp import FastMCP\n",
    "from github import GITHUB_TOKEN, create_github_headers\n",
    "\n",
    "# Create a FastMCP server\n",
    "mcp = FastMCP(\"GitHubMCP\")\n",
    "\n",
    "@mcp.resource(\"github://repo/{owner}/{repo_name}\")\n",
    "async def get_repository_info(owner: str, repo_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Gets detailed information for a given GitHub repository.\n",
    "\n",
    "    Args:\n",
    "        owner: The owner of the repository (e.g., 'modelcontextprotocol')\n",
    "        repo_name: The name of the repository (e.g., 'python-sdk')\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing repository details.\n",
    "    \"\"\"\n",
    "    api_url = f\"https://api.github.com/repos/{owner}/{repo_name}\"\n",
    "    print(f\"Fetching repository info from {api_url}...\")\n",
    "    \n",
    "    async with httpx.AsyncClient() as client:\n",
    "        try:\n",
    "            response = await client.get(api_url, headers=create_github_headers())\n",
    "            response.raise_for_status()\n",
    "            repo_data = response.json()\n",
    "            \n",
    "            # Return the data as a dictionary with repository information\n",
    "            return {\n",
    "                \"full_name\": repo_data.get(\"full_name\"),\n",
    "                \"description\": repo_data.get(\"description\"),\n",
    "                \"stars\": repo_data.get(\"stargazers_count\"),\n",
    "                \"forks\": repo_data.get(\"forks_count\"),\n",
    "                \"open_issues\": repo_data.get(\"open_issues_count\"),\n",
    "                \"language\": repo_data.get(\"language\"),\n",
    "                \"url\": repo_data.get(\"html_url\"),\n",
    "                \"created_at\": repo_data.get(\"created_at\"),\n",
    "                \"updated_at\": repo_data.get(\"updated_at\"),\n",
    "                \"size\": repo_data.get(\"size\"),\n",
    "                \"watchers\": repo_data.get(\"watchers_count\"),\n",
    "                \"default_branch\": repo_data.get(\"default_branch\"),\n",
    "                \"license\": repo_data.get(\"license\", {}).get(\"name\") if repo_data.get(\"license\") else None,\n",
    "                \"owner\": repo_data.get(\"owner\", {}).get(\"login\"),\n",
    "                \"owner_type\": repo_data.get(\"owner\", {}).get(\"type\"),\n",
    "                \"homepage\": repo_data.get(\"homepage\"),\n",
    "                \"topics\": repo_data.get(\"topics\", [])\n",
    "            }\n",
    "\n",
    "        except httpx.HTTPStatusError as e:\n",
    "            error_message = e.response.json().get(\"message\", \"No additional message from API.\")\n",
    "            if e.response.status_code == 403 and GITHUB_TOKEN:\n",
    "                error_message += \" (Rate limit with token or token lacks permissions?)\"\n",
    "            elif e.response.status_code == 403 and not GITHUB_TOKEN:\n",
    "                error_message += \" (Rate limit without token. Consider creating a .env file with GITHUB_TOKEN.)\"\n",
    "            \n",
    "            print(f\"GitHub API error: {e.response.status_code}. {error_message}\")\n",
    "            return {\n",
    "                \"error\": f\"GitHub API error: {e.response.status_code}\",\n",
    "                \"message\": error_message\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {str(e)}\")\n",
    "            return {\"error\": f\"An unexpected error occurred: {str(e)}\"}\n",
    "\n",
    "@mcp.tool()\n",
    "async def list_repository_issues(owner: str, repo_name: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Lists open issues for a given GitHub repository.\n",
    "\n",
    "    Args:\n",
    "        owner: The owner of the repository (e.g., 'modelcontextprotocol')\n",
    "        repo_name: The name of the repository (e.g., 'python-sdk')\n",
    "\n",
    "    Returns:\n",
    "        list[dict]: A list of dictionaries, each containing information about an issue\n",
    "    \"\"\"\n",
    "    # Limitar a los primeros 10 issues para evitar respuestas muy largas\n",
    "    api_url = f\"https://api.github.com/repos/{owner}/{repo_name}/issues?state=open&per_page=10\"\n",
    "    print(f\"Fetching issues from {api_url}...\")\n",
    "    \n",
    "    async with httpx.AsyncClient() as client:\n",
    "        try:\n",
    "            response = await client.get(api_url, headers=create_github_headers())\n",
    "            response.raise_for_status()\n",
    "            issues_data = response.json()\n",
    "            \n",
    "            if not issues_data:\n",
    "                print(\"No open issues found for this repository.\")\n",
    "                return [{\"message\": \"No open issues found for this repository.\"}]\n",
    "\n",
    "            issues_summary = []\n",
    "            for issue in issues_data:\n",
    "                # Create a more concise summary\n",
    "                summary = f\"#{issue.get('number', 'N/A')}: {issue.get('title', 'Sin t√≠tulo')}\"\n",
    "                if issue.get('comments', 0) > 0:\n",
    "                    summary += f\" ({issue.get('comments')} comentarios)\"\n",
    "                \n",
    "                issues_summary.append({\n",
    "                    \"number\": issue.get(\"number\"),\n",
    "                    \"title\": issue.get(\"title\"),\n",
    "                    \"user\": issue.get(\"user\", {}).get(\"login\"),\n",
    "                    \"url\": issue.get(\"html_url\"),\n",
    "                    \"comments\": issue.get(\"comments\"),\n",
    "                    \"summary\": summary\n",
    "                })\n",
    "            \n",
    "            print(f\"Found {len(issues_summary)} open issues.\")\n",
    "            \n",
    "            # Add context information\n",
    "            result = {\n",
    "                \"total_found\": len(issues_summary),\n",
    "                \"repository\": f\"{owner}/{repo_name}\",\n",
    "                \"note\": \"Mostrando los primeros 10 issues abiertos\" if len(issues_summary) == 10 else f\"Mostrando todos los {len(issues_summary)} issues abiertos\",\n",
    "                \"issues\": issues_summary\n",
    "            }\n",
    "            \n",
    "            return [result]\n",
    "            \n",
    "        except httpx.HTTPStatusError as e:\n",
    "            error_message = e.response.json().get(\"message\", \"No additional message from API.\")\n",
    "            if e.response.status_code == 403 and GITHUB_TOKEN:\n",
    "                error_message += \" (Rate limit with token or token lacks permissions?)\"\n",
    "            elif e.response.status_code == 403 and not GITHUB_TOKEN:\n",
    "                error_message += \" (Rate limit without token. Consider creating a .env file with GITHUB_TOKEN.)\"\n",
    "            \n",
    "            print(f\"GitHub API error: {e.response.status_code}. {error_message}\")\n",
    "            return [{\n",
    "                \"error\": f\"GitHub API error: {e.response.status_code}\",\n",
    "                \"message\": error_message\n",
    "            }]\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {str(e)}\")\n",
    "            return [{\"error\": f\"An unexpected error occurred: {str(e)}\"}]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"DEBUG: Starting GitHub FastMCP server...\")\n",
    "    print(f\"DEBUG: Server name: {mcp.name}\")\n",
    "    print(\"DEBUG: Available tools: list_repository_issues\")\n",
    "    print(\"DEBUG: Available resources: github://repo/{owner}/{repo_name}\")\n",
    "    \n",
    "    # Initialize and run the server\n",
    "    mcp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cliente MCP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completamos el cliente para poder usar el nuevo `resource` creado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting client_MCP/client.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile client_MCP/client.py\n",
    "\n",
    "import sys\n",
    "import asyncio\n",
    "from contextlib import AsyncExitStack\n",
    "from anthropic import Anthropic\n",
    "from dotenv import load_dotenv\n",
    "import mcp.types as types\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "class FastMCPClient:\n",
    "    \"\"\"\n",
    "    FastMCP client that integrates with Claude to process user queries\n",
    "    and use tools exposed by a FastMCP server via STDIO.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, server_script_path: str):\n",
    "        \"\"\"Initialize the FastMCP client with Anthropic and resource management.\"\"\"\n",
    "        self.exit_stack = AsyncExitStack()\n",
    "        self.anthropic = Anthropic()\n",
    "        self.session = None\n",
    "        self.server_params = None\n",
    "        self.server_script_path = server_script_path\n",
    "        \n",
    "    async def connect_to_server(self):\n",
    "        \"\"\"\n",
    "        Connect to the FastMCP server via STDIO.\n",
    "        \"\"\"\n",
    "        print(f\"üîó Connecting to FastMCP server: {self.server_script_path}\")\n",
    "        \n",
    "        # Determine the server type based on the extension\n",
    "        if self.server_script_path.endswith('.py'):\n",
    "            # Python server\n",
    "            self.server_params = StdioServerParameters(\n",
    "                command=\"python\",\n",
    "                args=[self.server_script_path],\n",
    "                env=None\n",
    "            )\n",
    "        elif self.server_script_path.endswith('.js'):\n",
    "            # JavaScript/Node.js server\n",
    "            self.server_params = StdioServerParameters(\n",
    "                command=\"node\", \n",
    "                args=[self.server_script_path],\n",
    "                env=None\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported server type. Use .py or .js files. Got: {self.server_script_path}\")\n",
    "        \n",
    "        # Set up connection to the server\n",
    "        stdio_transport = await self.exit_stack.enter_async_context(\n",
    "            stdio_client(self.server_params)\n",
    "        )\n",
    "        \n",
    "        # Create MCP session\n",
    "        self.session = await self.exit_stack.enter_async_context(\n",
    "            ClientSession(stdio_transport[0], stdio_transport[1])\n",
    "        )\n",
    "        \n",
    "        # Initialize the session\n",
    "        await self.session.initialize()\n",
    "        \n",
    "        print(\"‚úÖ Connection established successfully\")\n",
    "        \n",
    "        # List available tools and resources\n",
    "        await self.list_available_tools()\n",
    "        await self.list_available_resources()\n",
    "        \n",
    "    async def list_available_tools(self):\n",
    "        \"\"\"List available tools in the FastMCP server.\"\"\"\n",
    "        try:\n",
    "            # Get list of tools from the server\n",
    "            tools_result = await self.session.list_tools()\n",
    "            \n",
    "            if tools_result.tools:\n",
    "                print(f\"\\nüõ†Ô∏è  Available tools ({len(tools_result.tools)}):\")\n",
    "                print(\"=\" * 50)\n",
    "                \n",
    "                for tool in tools_result.tools:\n",
    "                    print(f\"üìã {tool.name}\")\n",
    "                    if tool.description:\n",
    "                        print(f\"   Description: {tool.description}\")\n",
    "                    \n",
    "                    # Show parameters if available\n",
    "                    if hasattr(tool, 'inputSchema') and tool.inputSchema:\n",
    "                        if 'properties' in tool.inputSchema:\n",
    "                            params = list(tool.inputSchema['properties'].keys())\n",
    "                            print(f\"   Parameters: {', '.join(params)}\")\n",
    "                    print()\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è  No tools found in the server\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error listing tools: {str(e)}\")\n",
    "\n",
    "    async def list_available_resources(self):\n",
    "        \"\"\"List available resources and resource templates in the FastMCP server.\"\"\"\n",
    "        try:\n",
    "            # Get list of static resources from the server\n",
    "            resources_result = await self.session.list_resources()\n",
    "            \n",
    "            # Get list of resource templates from the server  \n",
    "            templates_result = await self.session.list_resource_templates()\n",
    "            \n",
    "            total_count = len(resources_result.resources) + len(templates_result.resourceTemplates)\n",
    "            \n",
    "            if total_count > 0:\n",
    "                print(f\"\\nüìÇ Available resources & templates ({total_count}):\")\n",
    "                print(\"=\" * 50)\n",
    "                \n",
    "                # Show static resources\n",
    "                for resource in resources_result.resources:\n",
    "                    print(f\"üìÑ {resource.uri}\")\n",
    "                    if resource.name:\n",
    "                        print(f\"   Name: {resource.name}\")\n",
    "                    if resource.description:\n",
    "                        print(f\"   Description: {resource.description}\")\n",
    "                    if resource.mimeType:\n",
    "                        print(f\"   Type: {resource.mimeType}\")\n",
    "                    print()\n",
    "                \n",
    "                # Show resource templates\n",
    "                for template in templates_result.resourceTemplates:\n",
    "                    print(f\"üìã {template.uriTemplate} (template)\")\n",
    "                    if template.name:\n",
    "                        print(f\"   Name: {template.name}\")\n",
    "                    if template.description:\n",
    "                        print(f\"   Description: {template.description}\")\n",
    "                    if template.mimeType:\n",
    "                        print(f\"   Type: {template.mimeType}\")\n",
    "                    print()\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è  No resources or templates found in the server\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error listing resources: {str(e)}\")\n",
    "\n",
    "    async def read_resource(self, uri: str) -> str:\n",
    "        \"\"\"\n",
    "        Read a resource from the FastMCP server.\n",
    "        \n",
    "        Args:\n",
    "            uri: URI of the resource to read\n",
    "            \n",
    "        Returns:\n",
    "            str: Content of the resource\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(f\"üìñ Reading resource: {uri}\")\n",
    "            \n",
    "            # Try to read resource from the server\n",
    "            resource_result = await self.session.read_resource(uri)\n",
    "            \n",
    "            if resource_result.contents:\n",
    "                # Combine all content into a single string\n",
    "                combined_content = \"\"\n",
    "                for content in resource_result.contents:\n",
    "                    # Check if it's TextResourceContents (has text attribute)\n",
    "                    if hasattr(content, 'text'):\n",
    "                        combined_content += content.text + \"\\n\"\n",
    "                    # Check if it's BlobResourceContents (has data attribute)\n",
    "                    elif hasattr(content, 'data'):\n",
    "                        combined_content += f\"[Binary content from resource {uri}]\\n\"\n",
    "                    else:\n",
    "                        combined_content += f\"[Unknown content type from resource {uri}]\\n\"\n",
    "                \n",
    "                print(f\"‚úÖ Resource read successfully\")\n",
    "                return combined_content.strip()\n",
    "            else:\n",
    "                return f\"‚ùå Resource {uri} has no content\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            error_msg = f\"‚ùå Error reading resource {uri}: {str(e)}\"\n",
    "            print(error_msg)\n",
    "            return error_msg\n",
    "\n",
    "    async def call_tool(self, tool_name: str, arguments: dict) -> str:\n",
    "        \"\"\"\n",
    "        Call a tool on the FastMCP server via STDIO.\n",
    "        \n",
    "        Args:\n",
    "            tool_name: Name of the tool to call\n",
    "            arguments: Arguments for the tool\n",
    "            \n",
    "        Returns:\n",
    "            str: Result from the tool\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(f\"üîß Calling tool: {tool_name}\")\n",
    "            print(f\"üìù Arguments: {arguments}\")\n",
    "            \n",
    "            # Execute tool on the MCP server\n",
    "            tool_result = await self.session.call_tool(tool_name, arguments)\n",
    "            \n",
    "            print(f\"‚úÖ Tool executed successfully\")\n",
    "            \n",
    "            # Format result for Claude\n",
    "            if tool_result.content:\n",
    "                # Combine all content into a single result\n",
    "                combined_content = \"\"\n",
    "                for content in tool_result.content:\n",
    "                    # Check if it's TextContent (has text attribute)\n",
    "                    if hasattr(content, 'text'):\n",
    "                        combined_content += content.text + \"\\n\"\n",
    "                    # Check if it's ImageContent (has data attribute)  \n",
    "                    elif hasattr(content, 'data'):\n",
    "                        combined_content += f\"[Binary content returned by tool {tool_name}]\\n\"\n",
    "                    else:\n",
    "                        combined_content += f\"[Unknown content type returned by tool {tool_name}]\\n\"\n",
    "                \n",
    "                return combined_content.strip()\n",
    "            else:\n",
    "                return \"Tool executed without response content\"\n",
    "                    \n",
    "        except Exception as e:\n",
    "            error_msg = f\"‚ùå Error calling tool {tool_name}: {str(e)}\"\n",
    "            print(error_msg)\n",
    "            return error_msg\n",
    "    \n",
    "    async def process_query(self, query: str) -> str:\n",
    "        \"\"\"\n",
    "        Process a user query, interacting with Claude and FastMCP tools.\n",
    "        \n",
    "        Args:\n",
    "            query: User query\n",
    "            \n",
    "        Returns:\n",
    "            str: Final processed response\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Get available tools, resources and templates from the server\n",
    "            tools_result = await self.session.list_tools()\n",
    "            resources_result = await self.session.list_resources()\n",
    "            templates_result = await self.session.list_resource_templates()\n",
    "            \n",
    "            # Prepare tools for Claude in correct format\n",
    "            claude_tools = []\n",
    "            for tool in tools_result.tools:\n",
    "                claude_tool = {\n",
    "                    \"name\": tool.name,\n",
    "                    \"description\": tool.description or f\"Tool {tool.name}\",\n",
    "                    \"input_schema\": tool.inputSchema or {\"type\": \"object\", \"properties\": {}}\n",
    "                }\n",
    "                claude_tools.append(claude_tool)\n",
    "            \n",
    "            # Add a special tool for reading resources and templates\n",
    "            available_uris = []\n",
    "            available_uris.extend([str(r.uri) for r in resources_result.resources])\n",
    "            available_uris.extend([str(t.uriTemplate) for t in templates_result.resourceTemplates])\n",
    "            \n",
    "            if available_uris:\n",
    "                resource_tool = {\n",
    "                    \"name\": \"read_mcp_resource\",\n",
    "                    \"description\": \"Read a resource from the FastMCP server. Available resources and templates: \" + \n",
    "                                 \", \".join(available_uris),\n",
    "                    \"input_schema\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"uri\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"URI of the resource to read (can be static resource or template with parameters filled)\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"uri\"]\n",
    "                    }\n",
    "                }\n",
    "                claude_tools.append(resource_tool)\n",
    "            \n",
    "            # Create initial message for Claude\n",
    "            messages = [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": query\n",
    "                }\n",
    "            ]\n",
    "            \n",
    "            # First call to Claude\n",
    "            response = self.anthropic.messages.create(\n",
    "                model=\"claude-3-5-sonnet-20241022\",\n",
    "                max_tokens=6000,\n",
    "                messages=messages,\n",
    "                tools=claude_tools if claude_tools else None\n",
    "            )\n",
    "            \n",
    "            # Process Claude's response\n",
    "            response_text = \"\"\n",
    "            \n",
    "            for content_block in response.content:\n",
    "                if content_block.type == \"text\":\n",
    "                    response_text += content_block.text\n",
    "                    \n",
    "                elif content_block.type == \"tool_use\":\n",
    "                    # Claude wants to use a tool\n",
    "                    tool_name = content_block.name\n",
    "                    tool_args = content_block.input\n",
    "                    tool_call_id = content_block.id\n",
    "                    \n",
    "                    # Check if it's the special resource reading tool\n",
    "                    if tool_name == \"read_mcp_resource\":\n",
    "                        # Read resource directly\n",
    "                        tool_result = await self.read_resource(tool_args[\"uri\"])\n",
    "                    else:\n",
    "                        # Execute regular tool on the FastMCP server\n",
    "                        tool_result = await self.call_tool(tool_name, tool_args)\n",
    "                    \n",
    "                    # Add tool result to the conversation\n",
    "                    messages.append({\n",
    "                        \"role\": \"assistant\", \n",
    "                        \"content\": response.content\n",
    "                    })\n",
    "                    \n",
    "                    messages.append({\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [{\n",
    "                            \"type\": \"tool_result\",\n",
    "                            \"tool_use_id\": tool_call_id,\n",
    "                            \"content\": f\"Tool result: {tool_result}\"\n",
    "                        }]\n",
    "                    })\n",
    "                    \n",
    "                    # Second call to Claude with the tool result\n",
    "                    final_response = self.anthropic.messages.create(\n",
    "                        model=\"claude-3-5-sonnet-20241022\",\n",
    "                        max_tokens=6000,\n",
    "                        messages=messages,\n",
    "                        tools=claude_tools if claude_tools else None\n",
    "                    )\n",
    "                    \n",
    "                    # Extract text from the final response\n",
    "                    for final_content in final_response.content:\n",
    "                        if final_content.type == \"text\":\n",
    "                            response_text += final_content.text\n",
    "            \n",
    "            return response_text\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"‚ùå Error processing query: {str(e)}\"\n",
    "            print(error_msg)\n",
    "            return error_msg\n",
    "    \n",
    "    async def chat_loop(self):\n",
    "        \"\"\"\n",
    "        Main chat loop with user interaction.\n",
    "        \"\"\"\n",
    "        print(\"\\nü§ñ FastMCP client started. Write 'quit', 'q', 'exit', 'salir' to exit.\")\n",
    "        print(\"üí¨ You can ask questions about GitHub repositories!\")\n",
    "        print(\"üìö The client can use both tools and resources from the FastMCP server\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                # Get user input\n",
    "                user_input = input(\"\\nüë§ You: \").strip()\n",
    "                \n",
    "                if user_input.lower() in ['quit', 'q', 'exit', 'salir']:\n",
    "                    print(\"üëã Bye!\")\n",
    "                    break\n",
    "                    \n",
    "                if not user_input:\n",
    "                    continue\n",
    "                \n",
    "                print(\"\\nü§î Claude is thinking...\")\n",
    "                \n",
    "                # Process query\n",
    "                response = await self.process_query(user_input)\n",
    "                \n",
    "                # Show response\n",
    "                print(f\"\\nü§ñ Claude: {response}\")\n",
    "                \n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\n\\nüëã Disconnecting...\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"\\n‚ùå Error in chat: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "\n",
    "    async def cleanup(self):\n",
    "        \"\"\"Clean up resources and close connections.\"\"\"\n",
    "        print(\"üßπ Cleaning up resources...\")\n",
    "        await self.exit_stack.aclose()\n",
    "        print(\"‚úÖ Resources released\")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    \"\"\"\n",
    "    Main function that initializes and runs the FastMCP client.\n",
    "    \"\"\"\n",
    "    # Verify command line arguments\n",
    "    if len(sys.argv) != 2:\n",
    "        print(\"‚ùå Usage: python client.py <path_to_fastmcp_server>\")\n",
    "        print(\"üìù Example: python client.py ../MCP_github/github_server.py\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    server_script_path = sys.argv[1]\n",
    "    \n",
    "    print(f\"üöÄ Starting FastMCP client...\")\n",
    "    print(f\"üìÑ Server script: {server_script_path}\")\n",
    "    \n",
    "    # Create and run client\n",
    "    client = FastMCPClient(server_script_path)\n",
    "    \n",
    "    try:\n",
    "        # Connect to the server\n",
    "        await client.connect_to_server()\n",
    "        \n",
    "        # Start chat loop\n",
    "        await client.chat_loop()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Fatal error: {str(e)}\")\n",
    "        print(\"üí° Make sure:\")\n",
    "        print(\"   1. The server script path is correct\")\n",
    "        print(\"   2. You have ANTHROPIC_API_KEY in your .env file\")\n",
    "        print(\"   3. The server script is executable\")\n",
    "    finally:\n",
    "        # Ensure resources are cleaned up\n",
    "        await client.cleanup()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Entry point of the script\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos creado los m√©todos `list_available_resources` y `read_resource`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba del `resource`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos el `resource` creado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting FastMCP client...\n",
      "üìÑ Server script: ../gitHub_MCP_server/github_server.py\n",
      "üîó Connecting to FastMCP server: ../gitHub_MCP_server/github_server.py\n",
      "\u001b[2;36m[06/28/25 09:11:30]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Starting MCP server \u001b[32m'GitHubMCP'\u001b[0m with \u001b]8;id=206543;file:///Users/macm1/Documents/web/portafolio/posts/client_MCP/.venv/lib/python3.11/site-packages/fastmcp/server/server.py\u001b\\\u001b[2mserver.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=700093;file:///Users/macm1/Documents/web/portafolio/posts/client_MCP/.venv/lib/python3.11/site-packages/fastmcp/server/server.py#1246\u001b\\\u001b[2m1246\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         transport \u001b[32m'stdio'\u001b[0m                    \u001b[2m              \u001b[0m\n",
      "‚úÖ Connection established successfully\n",
      "\n",
      "üõ†Ô∏è  Available tools (1):\n",
      "==================================================\n",
      "üìã list_repository_issues\n",
      "   Description: Lists open issues for a given GitHub repository.\n",
      "\n",
      "Args:\n",
      "    owner: The owner of the repository (e.g., 'modelcontextprotocol')\n",
      "    repo_name: The name of the repository (e.g., 'python-sdk')\n",
      "\n",
      "Returns:\n",
      "    list[dict]: A list of dictionaries, each containing information about an issue\n",
      "   Parameters: owner, repo_name\n",
      "\n",
      "\n",
      "üìÇ Available resources & templates (1):\n",
      "==================================================\n",
      "üìã github://repo/{owner}/{repo_name} (template)\n",
      "   Name: get_repository_info\n",
      "   Description: Gets detailed information for a given GitHub repository.\n",
      "\n",
      "Args:\n",
      "    owner: The owner of the repository (e.g., 'modelcontextprotocol')\n",
      "    repo_name: The name of the repository (e.g., 'python-sdk')\n",
      "\n",
      "Returns:\n",
      "    dict: A dictionary containing repository details.\n",
      "   Type: text/plain\n",
      "\n",
      "\n",
      "ü§ñ FastMCP client started. Write 'quit', 'q', 'exit', 'salir' to exit.\n",
      "üí¨ You can ask questions about GitHub repositories!\n",
      "üìö The client can use both tools and resources from the FastMCP server\n",
      "------------------------------------------------------------\n",
      "\n",
      "üë§ You: ^C\n",
      "\n",
      "üë§ You: "
     ]
    }
   ],
   "source": [
    "!cd client_MCP && source .venv/bin/activate && python client.py ../gitHub_MCP_server/github_server.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
