{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IYb5_GZqkIk"
      },
      "source": [
        "# Introducción a agentes con LangGraph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2jGxGCOqkIm"
      },
      "source": [
        "`LangGraph` es un marco de orquestación de bajo nivel para construir agentes controlables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7Sq1NsEqkIm"
      },
      "source": [
        "Mientras que `LangChain` proporciona integraciones y componentes para agilizar el desarrollo de aplicaciones LLM, la biblioteca `LangGraph` permite la orquestación de agentes, ofreciendo arquitecturas personalizables, memoria a largo plazo y `human in the loop` para manejar de manera confiable tareas complejas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJEcyJBSqkIm"
      },
      "source": [
        "> En este post vamos a deshabilitar `LangSmith`, que es una herramienta de depuración de grafos. Lo vamos a deshabilitar para no añadir más complejidad al post y centrarnos únicamente en `LangGraph`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KV9FxTU4qkIm"
      },
      "source": [
        "## ¿Cómo funciona `LangGraph`?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-ZlqHTVqkIn"
      },
      "source": [
        "`LangGraph` se basa en tres componentes:\n",
        "\n",
        " * **Nodos**: Representan las unidades de procesamiento de la aplicación, como llamar a un LLM, o a una herramienta. Son funciones de Python que se ejecutan cuando se llama al nodo.\n",
        "   * Tomar el estado como entrada\n",
        "   * Realizan alguna operación\n",
        "   * Devuelven el estado actualizado\n",
        " * **Edges**: Representan las transiciones entre los nodos. Definen la lógica de cómo se va a ejecutar el grafo, es decir, qué nodo se va a ejecutar después de otro. Pueden ser:\n",
        "   * Directos: Van de un nodo a otro\n",
        "   * Condicionales: Dependen de una condición\n",
        " * **State**: Representa el estado de la aplicación, es decir, contiene toda la información necesaria para la aplicación. Se mantiene durante la ejecución de la aplicación. Es definido por el usuario, así que hay que pensar muy bien qué se va a guardar en él."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8UULBhZqkIn"
      },
      "source": [
        "![LangGraph concept](https://images.maximofn.com/langgraph_concept.webp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFcse2DeqkIn"
      },
      "source": [
        "Todos los grafos de `LangGraph` comienzan desde un nodo `START` y terminan en un nodo `END`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgHWnD-SqkIn"
      },
      "source": [
        "## Instalación de LangGraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfEzcn9vqkIn"
      },
      "outputs": [],
      "source": [
        "%pip install -U langgraph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvL2L-58qkIo"
      },
      "source": [
        "## Instalación de módulo Anthropic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1HdPV92qkIo"
      },
      "outputs": [],
      "source": [
        "pip install langchain_anthropic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cs1al7kUqkIo"
      },
      "source": [
        "## API KEY de Anthropic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpETrodCqkIo"
      },
      "source": [
        "Para poder la API de Anthropic, lo primero que necesitas es tener una cuenta en Antrhopic. Una vez la tengas, hay que ir a [keys](https://console.anthropic.com/settings/keys) y generar una nueva key.\n",
        "\n",
        "Hay que ponerle un nombre. En mi caso, le voy a poner `langgraph`. Nos creará una key que tendremos que copiar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pIbAsZXqkIo"
      },
      "source": [
        "Para gestionar la key, vamos a crear un archivo en la misma ruta en la que estemos trabajando llamado `.env` y vamos a poner la key que hemos copiado en el archivo de la siguiente manera:\n",
        "\n",
        "``` bash\n",
        "ANTHROPIC_LANGGRAPH_API_KEY==\"sk_....\"\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0He2GgEzqkIo"
      },
      "source": [
        "Ahora, para poder obtener el token, necesitamos tener instalado `dotenv`, que lo instalamos mediante"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EX7rKo3cqkIo",
        "outputId": "469a5806-4d65-48ab-cab1-a6584caff9dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "F3HMLqoDqkIo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import dotenv\n",
        "\n",
        "dotenv.load_dotenv()\n",
        "\n",
        "ANTHROPIC_TOKEN = os.getenv(\"ANTHROPIC_LANGGRAPH_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84AU9iIhqkIp"
      },
      "source": [
        "## Crear un chatbot básico"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzNg0GkfqkIp"
      },
      "source": [
        "Vamos a crear un chatbot simple usando `LangGraph`. Este chatbot responderá directamente a los mensajes del usuario. Aunque es simple, nos servirá para ver los conceptos básicos de la construcción de grafos con `LangGraph`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWJ2NqwFqkIp"
      },
      "source": [
        "Como su nombre indica, `LangGraph` es una biblioteca para manejar grafos. Así que comenzamos creando un grafo [StateGraph](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.state.StateGraph).\n",
        "\n",
        "Un `StateGraph` define la estructura de nuestro chatbot como una `máquina de estados`. Agregaremos `nodos` a nuestro grafo para representar los `llm`s, `tool`s y `funciones`, los `llm`s podrán hacer uso de esas `tool`s y `funciones`; y añadimos `edges` para especificar cómo el bot debe hacer la transición entre esos `nodos`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouAYhmNcqkIp"
      },
      "source": [
        "Así que comenzamos creando un `StateGraph` que necesita una clase `State` para manejar el estado del grafo. Como ahora vamos a crear un chatbot sencillo, solo necesitamos manejar una lista de mensajes en el estado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WP9bTyK4qkIp"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    # Messages have the type \"list\". The `add_messages` function\n",
        "    # in the annotation defines how this state key should be updated\n",
        "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "\n",
        "graph_builder = StateGraph(State)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_kbq-fsqkIp"
      },
      "source": [
        "La función [add_messages](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.message.add_messages) une dos listas de mensajes.\n",
        "\n",
        "Llegarán nuevas listas de mensajes, por lo que se unirán a la lista de mensajes ya existente. Cada lista de mensajes contiene un `ID`, por lo que se agregan con este `ID`. Esto asegura que los mensajes solo se añaden, no se reemplazan, a no ser que un nuevo mensaje tenga el mismo `ID` que uno ya existente, que entonces se remplaza.\n",
        "\n",
        "`add_messages` es una [reducer function](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers), es una función que se encarga de actualizar el estado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXSah1CkqkIp"
      },
      "source": [
        "El grafo `graph_builder` que hemos creado, recibe un estado `State` y devuelve un nuevo estado `State`. Además, actualiza la lista de mensajes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnIkSPO7qkIs"
      },
      "source": [
        " > **Concepto**\n",
        " >\n",
        " > Al definir un grafo, el primer paso es definir su `State`. El `State` incluye el esquema del grafo y las `reducer functions` que manejan actualizaciones del estado.\n",
        " >\n",
        " > En nuestro ejemplo, `State` es de tipo `TypedDict` (diccionario tipado) con una llave: `messages`.\n",
        " >\n",
        " > `add_messages` es una `reducer function` que se utiliza para agregar nuevos mensajes a la lista en lugar de sobrescribirlos en la lista. Si una llave de un estado no tiene una `reducer function`, cada valor que llegue de esa clave sobrescribirán los valores anteriores.\n",
        " >\n",
        " > `add_messages` es una `reducer function` de langgraph, pero nosotros vamos a poder crear las nuestras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNBQ_EAIqkIs"
      },
      "source": [
        "Ahora vamos a agregar al grafo el nodo `chatbot`. Los nodos representan unidades de trabajo. Por lo general, son funciones regulares de `Python`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTUK4LVhqkIs"
      },
      "source": [
        "Añadimos un nodo con el método `add_node` que recibe el nombre del nodo y la función que se ejecutará."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EykmNqS_qkIs"
      },
      "source": [
        "De modo que vamos a crear un LLM con HuggingFace, después crearemos un chat model con `LangChain` que hará referencia al LLM creado. Una vez tenemos definido un chat model, definimos la función que se ejecutará en el nodo de nuestro grafo. Esa función hará una llamada al chat model creado y devolverá el resultado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hS1jaJiBqkIs"
      },
      "source": [
        "Por último vamos a añadir un nodo con la función del chatbot al grafo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XAMtnGOTqkIs",
        "outputId": "83c34ac3-4dcf-4fc8-db0a-c22fd5194c92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7aa6f7d7ef50>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from langchain_anthropic import ChatAnthropic\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"    # Disable LangSmith tracing\n",
        "\n",
        "# Create the LLM model\n",
        "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20241022\", api_key=ANTHROPIC_TOKEN)\n",
        "\n",
        "# Define the chatbot function\n",
        "def chatbot_function(state: State):\n",
        "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
        "\n",
        "\n",
        "# The first argument is the unique node name\n",
        "# The second argument is the function or object that will be called whenever\n",
        "# the node is used.\n",
        "graph_builder.add_node(\"chatbot_node\", chatbot_function)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1O89XQtqkIt"
      },
      "source": [
        "Hemos usado [ChatHuggingFace](https://python.langchain.com/api_reference/huggingface/chat_models/langchain_huggingface.chat_models.huggingface.ChatHuggingFace.html#langchain_huggingface.chat_models.huggingface.ChatHuggingFace) que es un chat del tipo [BaseChatModel](https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.chat_models.BaseChatModel.html#langchain_core.language_models.chat_models.BaseChatModel) que es un tipo de chat base de `LangChain`. Una vez hemos creado el `BaseChatModel`, hemos creado la función `chatbot_function` que se ejecutará cuando se ejecute el nodo. Y por último, hemos creado el nodo `chatbot_node` y le hemos indicado que tiene que ejecutar la función `chatbot_function`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXYCpp06qkIt"
      },
      "source": [
        " > **Aviso**\n",
        " >\n",
        " > La función de nodo `chatbot_function` toma el estado `State` como entrada y devuelve un diccionario que contiene una actualización de la lista `messages` para la key `mensajes`. Este es el patrón básico para todas las funciones del nodo `LangGraph`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhSbAoaSqkIt"
      },
      "source": [
        "La `reducer function` de nuestro grafo `add_messages` agregará los mensajes de respuesta del `llm` a cualquier mensaje que ya esté en el estado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1k5wU9NzqkIt"
      },
      "source": [
        "A continuación, agregamos un nodo `entry`. Esto le dice a nuestro grafo dónde empezar su trabajo cada vez que lo ejecutamos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NkTre7PcqkIt",
        "outputId": "d01c1bb8-7c0b-46b1-e8e1-527c43a52b6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7aa6f7d7ef50>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from langgraph.graph import START\n",
        "\n",
        "graph_builder.add_edge(START, \"chatbot_node\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asUKFwbJqkIt"
      },
      "source": [
        "Del mismo modo, añadimos un nodo `finish`. Esto indica al grafo cada vez que se ejecuta este nodo, puede terminar el trabajo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SXzx5p5ZqkIt",
        "outputId": "f9468d6c-1a89-406f-8c46-da59e4709384",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7aa6f7d7ef50>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from langgraph.graph import END\n",
        "\n",
        "graph_builder.add_edge(\"chatbot_node\", END)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Xc1tm6XqkIt"
      },
      "source": [
        "Hemos importado `START` y `END` que podemos encontrarlos en [constants](https://langchain-ai.github.io/langgraph/reference/constants/) y son el primer y el último nodo de nuestro grafo.\n",
        "\n",
        "Normalmente son nodos virtuales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuupiXbMqkIt"
      },
      "source": [
        "Finalmente, tenemos que compilar nuestro grafo. Para hacerlo, usamos el método constructor de grafos `compile()`. Esto crea un `CompiledGraph` que podemos usar para ejecutar nuestra aplicación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-WAMalXfqkIt"
      },
      "outputs": [],
      "source": [
        "graph = graph_builder.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alUhs-uuqkIt"
      },
      "source": [
        "Podemos visualizar el grafo usando el método `get_graph` y uno de los métodos de \"dibujo\", como `draw_ascii` o `draw_mermaid_png`. El dibujo de cada uno de los métodos requiere dependencias adicionales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jyVOlOgOqkIt",
        "outputId": "fc9d6694-f0af-4bdc-d8fd-fb0bee492eed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception as e:\n",
        "    print(f\"Error al visualizar el grafo: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Hr5cSuDqkIt"
      },
      "source": [
        "¡Ahora podemos probar el chatbot!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ahcze00qkIt"
      },
      "source": [
        " > **Consejo**\n",
        " >\n",
        " > En el siguiente bloque de código, puedes salir del bucle de chat en cualquier momento escribiendo `quit`, `exit` o `q`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "shQ39kJeqkIt",
        "outputId": "a1250348-3c6a-431f-fd5a-45dcd9e7cd9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: What was the result of Real Madrid's at last match in the Champions League?\n",
            "\u001b[32mUser: \u001b[0mWhat was the result of Real Madrid's at last match in the Champions League?\n",
            "\u001b[33mAssistant: \u001b[0mI am not able to provide real-time sports results or know specific match outcomes without being updated. To find out Real Madrid's most recent Champions League match result, I recommend checking official sports websites, UEFA's website, or Real Madrid's official channels.\n",
            "User: q\n",
            "\u001b[32mUser: \u001b[0mq\n",
            "\u001b[33mAssistant: \u001b[0mGoodbye!\n"
          ]
        }
      ],
      "source": [
        "# Colors for the terminal\n",
        "COLOR_GREEN = \"\\033[32m\"\n",
        "COLOR_YELLOW = \"\\033[33m\"\n",
        "COLOR_RESET = \"\\033[0m\"\n",
        "\n",
        "\n",
        "def stream_graph_updates(user_input: str):\n",
        "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
        "        for value in event.values():\n",
        "            print(f\"{COLOR_GREEN}User: {COLOR_RESET}{user_input}\")\n",
        "            print(f\"{COLOR_YELLOW}Assistant: {COLOR_RESET}{value['messages'][-1].content}\")\n",
        "\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        user_input = input(\"User: \")\n",
        "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "            print(f\"{COLOR_GREEN}User: {COLOR_RESET}{user_input}\")\n",
        "            print(f\"{COLOR_YELLOW}Assistant: {COLOR_RESET}Goodbye!\")\n",
        "            break\n",
        "\n",
        "        events =stream_graph_updates(user_input)\n",
        "    except:\n",
        "        # fallback if input() is not available\n",
        "        user_input = \"What do you know about LangGraph?\"\n",
        "        print(\"User: \" + user_input)\n",
        "        stream_graph_updates(user_input)\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VXJjB5xqkIt"
      },
      "source": [
        "**!Felicidades!** Has construido tu primer chatbot usando `LangGraph`. Este bot puede participar en una conversación básica tomando la entrada del usuario y generando respuestas utilizando el `LLM` que hemos definido."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJxa0bHCqkIt"
      },
      "source": [
        "Antes hemos ido escribiendo el código poco a poco y puede que no haya quedado muy claro. Se ha hecho así para explicar cada parte del código, pero ahora vamos a volver a escribirlo, pero ordenado de otra manera, que queda más claro a la vista. Es decir, ahora que no hay que explicar cada parte del código, lo agrupamos de otra manera para que sea más claro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "s22orctbqkIt",
        "outputId": "988cc8e7-4bed-4d84-f452-38061e3e0f17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "\n",
        "from IPython.display import Image, display\n",
        "\n",
        "import os\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"    # Disable LangSmith tracing\n",
        "\n",
        "import dotenv\n",
        "dotenv.load_dotenv()\n",
        "ANTHROPIC_TOKEN = os.getenv(\"ANTHROPIC_LANGGRAPH_API_KEY\")\n",
        "\n",
        "# State\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "# Create the LLM model\n",
        "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20241022\", api_key=ANTHROPIC_TOKEN)\n",
        "\n",
        "# Function\n",
        "def chatbot_function(state: State):\n",
        "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
        "\n",
        "# Start to build the graph\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "# Add nodes to the graph\n",
        "graph_builder.add_node(\"chatbot_node\", chatbot_function)\n",
        "\n",
        "# Add edges\n",
        "graph_builder.add_edge(START, \"chatbot_node\")\n",
        "graph_builder.add_edge(\"chatbot_node\", END)\n",
        "\n",
        "# Compile the graph\n",
        "graph = graph_builder.compile()\n",
        "\n",
        "# Display the graph\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception as e:\n",
        "    print(f\"Error al visualizar el grafo: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjsvT2hhqkI3"
      },
      "source": [
        "## Mejorar el chatbot con herramientas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9n96dFwkqkI3"
      },
      "source": [
        "Para manejar algunas consultas, nuestro chatbot no puede responder `desde su conocimiento`, así que vamos a integrar una herramienta de búsqueda web. Nuestro bot puede utilizar esta herramienta para encontrar información relevante y proporcionar mejores respuestas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKIKBjlHqkI3"
      },
      "source": [
        "### Requisitos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moo4-rI_qkI3"
      },
      "source": [
        "Antes de comenzar, tenemos que instalar el buscador [Tavily](https://python.langchain.com/docs/integrations/tools/tavily_search/) que es un buscador web que nos permite buscar información en la web."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -U tavily-python langchain_community"
      ],
      "metadata": {
        "id": "1VattDCmtu5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fOtlu3UqkI3"
      },
      "source": [
        "Después, tenemos que crear una [API KEY](https://app.tavily.com/home), la escribimos en nuestro archivo `.env` y la cargamos en una variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EFDc8uqVqkI3"
      },
      "outputs": [],
      "source": [
        "import dotenv\n",
        "import os\n",
        "\n",
        "dotenv.load_dotenv()\n",
        "\n",
        "ANTHROPIC_TOKEN = os.getenv(\"ANTHROPIC_LANGGRAPH_API_KEY\")\n",
        "TAVILY_API_KEY = os.getenv(\"TAVILY_LANGGRAPH_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuksxOmuqkI3"
      },
      "source": [
        "### Chatbot con tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yon1R8IqkI3"
      },
      "source": [
        "Primero creamos el estado y el LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MJWtcSAGqkI3"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "\n",
        "import json\n",
        "import os\n",
        "from IPython.display import Image, display\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"    # Disable LangSmith tracing\n",
        "\n",
        "import dotenv\n",
        "ANTHROPIC_TOKEN = os.getenv(\"ANTHROPIC_LANGGRAPH_API_KEY\")\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "# Create the LLM\n",
        "llm = ChatAnthropic(model=\"claude-3-7-sonnet-20250219\", api_key=ANTHROPIC_TOKEN)\n",
        "\n",
        "# Start to build the graph\n",
        "graph_builder = StateGraph(State)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pg6KmcGhqkI3"
      },
      "source": [
        "Ahora, definimos la herramienta de búsqueda web mediante [TavilySearchResults](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.tavily_search.tool.TavilySearchResults.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "an7oDEd9qkI3",
        "outputId": "6b1b1745-7c64-4bee-a064-9f1834f0a5a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-3136919182>:7: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
            "  tool = TavilySearchResults(api_wrapper=wrapper, max_results=2)\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "TAVILY_API_KEY = os.getenv(\"TAVILY_LANGGRAPH_API_KEY\")\n",
        "\n",
        "wrapper = TavilySearchAPIWrapper(tavily_api_key=TAVILY_API_KEY)\n",
        "tool = TavilySearchResults(api_wrapper=wrapper, max_results=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0yuZ4NyqkI3"
      },
      "source": [
        "Probamos la herramienta, vamos a hacer una búsqueda en Internet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YkmLvb16qkI3",
        "outputId": "88bc5639-0a6c-4bc7-951c-771f6cce386a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'title': \"Real Madrid's greatest UEFA Champions League comebacks - ESPN\",\n",
              "  'url': 'https://www.espn.com/soccer/story/_/id/44681247/real-madrids-greatest-uefa-champions-league-comebacks',\n",
              "  'content': 'Madrid would go on to defeat Borussia Dortmund 2-0 in the final, with goals from Dani Carvajal and Vinícius sealing another unforgettable',\n",
              "  'score': 0.7253574},\n",
              " {'title': \"Real Madrid's Champions League ouster by Arsenal reinforces an ...\",\n",
              "  'url': 'https://sports.yahoo.com/soccer/live/real-madrids-champions-league-ouster-by-arsenal-reinforces-an-age-old-soccer-truth-190017620.html',\n",
              "  'content': 'But a year later, the sport clapped back.\\n\\nOn Wednesday, Real Madrid slumped out of the Champions League, beaten comprehensively by Arsenal over two legs, 5-1.\\n\\nKylian Mbappé and Vinicius Jr. crept off the field after a sour second leg, or simply stood there, dumbfounded, because on paper, their team was more super than ever before; but in practice, soccer is the ultimate team game. [...] The 2024-25 Champions League has reminded us of that age-old truth. Real Madrid won last year’s edition, then [signed Mbappé](https://sports.yahoo.com/kylian-mbappe-and-real-madrid-a-match-made-in-footballing-heaven-153630645.html). The assumption was that, together, they’d go on to win it, or at least compete for it, yet again.',\n",
              "  'score': 0.62303346}]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "tool.invoke(\"What was the result of Real Madrid's at last match in the Champions League?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JztE8KlqqkI3"
      },
      "source": [
        "Los resultados son resúmenes de páginas que nuestro chatbot puede usar para responder preguntas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDZZo3RJqkI3"
      },
      "source": [
        "Creamos una lista de herramientas, porque nuestro grafo necesita definir las herramientas mediante una lista."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "U56eqHiMqkI3"
      },
      "outputs": [],
      "source": [
        "tools_list = [tool]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwWt0VTsqkI3"
      },
      "source": [
        "Ahora que tenemos la lista de `tool`s creamos un `llm_with_tools`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IKkwi3U0qkI3"
      },
      "outputs": [],
      "source": [
        "# Modification: tell the LLM which tools it can call\n",
        "llm_with_tools = llm.bind_tools(tools_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrub2GHYqkI3"
      },
      "source": [
        "Definimos la función que irá en el nodo chat bot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jXl0AMJhqkI3"
      },
      "outputs": [],
      "source": [
        "# Define the chatbot function\n",
        "def chatbot_function(state: State):\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KAwRGxMqkI3"
      },
      "source": [
        "Necesitamos crear una función para ejecutar las `tools_list` si se llaman. Agregamos las `tools_list` a un nuevo nodo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTa7E_SGqkI3"
      },
      "source": [
        "Más tarde haremos esto con el método [ToolNode](https://langchain-ai.github.io/langgraph/reference/prebuilt/#toolnode) de `LangGraph`, pero primero lo construiremos nosotros mismos para entender cómo funciona."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uKshFIBqkI3"
      },
      "source": [
        "Vamos a usar los métodos de LangGraph `ToolNode` y `tools_condition`, que sirven para añadir un nodo de tipo Tool al grafo y determinan si se tiene que usar la tool o no\n",
        "\n",
        "Se basa en el soporte de `tool_calling` de los `LLM`s , que está disponible en `Anthropic`, `HuggingFace`, `Google Gemini`, `OpenAI` y varios otros proveedores de `LLM`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "QFIrUBFuqkI4",
        "outputId": "21ec496e-26b4-4d77-ca7f-a41e5d01e203",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7b2a1b542610>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "\n",
        "tool_node = ToolNode(tools=[tool])\n",
        "graph_builder.add_node(\"tools\", tool_node)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P169waTYqkI4"
      },
      "source": [
        "Ahora, igual que hicimos cuando construimos un chatbot básico, vamos a crear el grafo y añadirle nodos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "47d1-283qkI4",
        "outputId": "a1155c24-1e8b-40b9-a96f-cf1bf88a652b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7b29f984f0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Create graph\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "# Add the chatbot node\n",
        "graph_builder.add_node(\"chatbot_node\", chatbot_function)\n",
        "graph_builder.add_node(\"tools\", tool_node)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePAOnj0UqkI4"
      },
      "source": [
        "ACuando el LLM reciba un mensaje, como conoce las `tool`s que tiene a disposición, decidirá si contestar o usar una `tool`. Así que vamos a añadir esto al grafo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2KQ3oDtjqkI4",
        "outputId": "f6fd3a9e-59c7-40fc-80d2-03f1c6e5096b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7b29f984f0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "graph_builder.add_conditional_edges(\n",
        "    \"chatbot_node\",\n",
        "    tools_condition,\n",
        ")\n",
        "graph_builder.add_edge(\"tools\", \"chatbot_node\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOMMxAU7qkI4"
      },
      "source": [
        "Añadimos los `edge`s."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Lgjq1fJqkI4"
      },
      "source": [
        "Tenemos que añadir un `edge` especial mediante `add_conditional_edges`, que creará un nodo condicional. Une el nodo `chatbot_node` con la función de rutado que hemos creado antes `route_tools_function`. Con este nodo, si obtenemos a la salida de `route_tools_function` el string `tools_node` rutará el grafo al nodo `tools_node`, pero si recibimos `END` rutará el grafo al nodo `END` y terminará la ejecución del grafo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUMfPnHjqkI4"
      },
      "source": [
        "Más tarde, reemplazaremos esto con el método preconstruido `tools_condition`, pero ahora lo implementamos nosotros mismos para ver cómo funciona."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "DRvAxKT1qkI4",
        "outputId": "2c2e6354-ce0d-48f0-dcc0-dff589889541",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7b29f984f0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Add edges\n",
        "graph_builder.add_edge(START, \"chatbot_node\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ab3EWlDeqkI4"
      },
      "source": [
        "Compilamos el nodo y lo representamos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "dEyYg3lsqkI4",
        "outputId": "578df83a-14fe-4338-9bb6-a35839edba27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "graph = graph_builder.compile()\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception as e:\n",
        "    print(f\"Error al visualizar el grafo: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFktRBEoqkI4"
      },
      "source": [
        "Ahora podemos hacer preguntas al bot fuera de sus datos de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "gTRpJ7gYqkI4",
        "outputId": "c0f9b43d-9dde-43f2-fac5-f4d2d6c2ab5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: What was the result of Real Madrid's at last match in the Champions League?\n",
            "\u001b[32mUser: \u001b[0mWhat was the result of Real Madrid's at last match in the Champions League?\n",
            "\u001b[33mAssistant: \u001b[0m[{'text': \"I'll help you find information about Real Madrid's latest Champions League match result. Let me search for that information for you.\", 'type': 'text'}, {'id': 'toolu_01Bo7resCV5YzYbUw56WZ7AM', 'input': {'query': 'Real Madrid latest Champions League match result 2024'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
            "\u001b[32mUser: \u001b[0mWhat was the result of Real Madrid's at last match in the Champions League?\n",
            "\u001b[33mAssistant: \u001b[0m[{\"title\": \"Real Madrid full schedule 2024-25, results, top scorers - NBC Sports\", \"url\": \"https://www.nbcsports.com/soccer/news/real-madrid-full-schedule-2024-25-when-is-kylian-mbappe-and-jude-bellinghams-next-game\", \"content\": \"August 18, 2024: Mallorca 1-1 Real Madrid  \\nAugust 25, 2024: Real Madrid 3-0 Valladolid  \\nAugust 29, 2024: Las Palmas 1-1 Real Madrid  \\nSeptember 1, 2024: Real Madrid 2-0 Real Betis  \\nSeptember 14, 2024: Real Sociedad 0-2 Real Madrid  \\nSeptember 21, 2024: Real Madrid 4-1 Espanyol  \\nSeptember 24, 2024: Real Madrid 3-2 Alaves  \\nSeptember 29, 2024: Atletico Madrid 1-1 Real Madrid  \\nOctober 5, 2024: Real Madrid 2-0 Villarreal  \\nOctober 19, 2024: Celta Vigo 1-2 Real Madrid [...] December 22, 2024: Real Madrid 4-2 Sevilla  \\nJanuary 3, 2025: Valencia 1-2 Real Madrid  \\nJanuary 19, 2025: Real Madrid 4-1 Las Palmas  \\nJanuary 25, 2025: Valladolid 0-3 Real Madrid  \\nFebruary 2, 2025: Espanyol 1-0 Real Madrid  \\nFebruary 9, 2025: Real Madrid 1-1 Atletico Madrid  \\nFebruary 16, 2025: Osasuna 1-1 Real Madrid  \\nFebruary 23, 2025: Real Madrid 2-0 Girona  \\nMarch 2, 2025: Real Betis 2-1 Real Madrid  \\nMarch 9, 2025: Real Madrid 2-1 Rayo Vallecano [...] September 17, 2024: Real Madrid 3-1 Stuttgart  \\nOctober 2, 2024: Lille 1-0 Real Madrid  \\nOctober 22, 2024: Real Madrid 5-2 Borussia Dortmund  \\nNovember 5, 2024: Real Madrid 1-3 AC Milan  \\nNovember 27, 2024: Liverpool 2-0 Real Madrid  \\nDecember 10, 2024: Atalanta 2-3 Real Madrid  \\nJanuary 22, 2025: Real Madrid 5-1 Red Bull Salzburg  \\nJanuary 29, 2025: Brest 0-3 Real Madrid\", \"score\": 0.9100432}, {\"title\": \"Real Madrid 2024 Results - ESPN\", \"url\": \"https://www.espn.com/soccer/team/results/_/id/86/real-madrid\", \"content\": \"| Wed, Mar 12 | [ATM](/soccer/team/_/id/1068/atletico-madrid) | [1 - 0](/soccer/match/_/gameId/733606/real-madrid-atletico-madrid)2nd Leg · Tied 2-2 on aggregate · Real Madrid wins 4-2 on Penalty Kicks | [RMA](/soccer/team/_/id/86/real-madrid) | [FT-Pens](/soccer/match/_/gameId/733606/real-madrid-atletico-madrid) | UEFA Champions League | [...] | Wed, Feb 19 | [RMA](/soccer/team/_/id/86/real-madrid) | [3 - 1](/soccer/match/_/gameId/732200/manchester-city-real-madrid)2nd Leg · Real Madrid wins 6-3 on aggregate | [MNC](/soccer/team/_/id/382/manchester-city) | [FT](/soccer/match/_/gameId/732200/manchester-city-real-madrid) | UEFA Champions League | [...] | DATE | MATCH | | | RESULT | COMPETITION |\\n| --- | --- | --- | --- | --- | --- |\\n| Wed, Nov 27 | [LIV](/soccer/team/_/id/364/liverpool) | [2 - 0](/soccer/match/_/gameId/720369/real-madrid-liverpool) | [RMA](/soccer/team/_/id/86/real-madrid) | [FT](/soccer/match/_/gameId/720369/real-madrid-liverpool) | UEFA Champions League |\", \"score\": 0.86713725}]\n",
            "\u001b[32mUser: \u001b[0mWhat was the result of Real Madrid's at last match in the Champions League?\n",
            "\u001b[33mAssistant: \u001b[0mBased on my search, I can provide you with information about Real Madrid's most recent Champions League match:\n",
            "\n",
            "Real Madrid's last Champions League match was against Liverpool on November 27, 2024, which resulted in a 2-0 loss for Real Madrid. The match was played at Liverpool's home ground.\n",
            "\n",
            "Before that, Real Madrid played against AC Milan on November 5, 2024, losing 3-1, and prior to that, they defeated Borussia Dortmund 5-2 on October 22, 2024.\n",
            "\n",
            "Real Madrid's Champions League campaign this season has had mixed results, with their most recent match ending in a defeat against Liverpool.\n",
            "User: Which players played the match?\n",
            "\u001b[32mUser: \u001b[0mWhich players played the match?\n",
            "\u001b[33mAssistant: \u001b[0mI need more information to answer your question correctly. You're asking about players in a match, but I don't know which match you're referring to. Could you please specify:\n",
            "\n",
            "1. Which sport (football/soccer, tennis, basketball, etc.)\n",
            "2. Which specific match (teams, tournament, date, etc.)\n",
            "\n",
            "Once you provide these details, I can search for the players who participated in that match.\n",
            "User: q\n",
            "\u001b[32mUser: \u001b[0mq\n",
            "\u001b[33mAssistant: \u001b[0mGoodbye!\n"
          ]
        }
      ],
      "source": [
        "# Colors for the terminal\n",
        "COLOR_GREEN = \"\\033[32m\"\n",
        "COLOR_YELLOW = \"\\033[33m\"\n",
        "COLOR_RESET = \"\\033[0m\"\n",
        "\n",
        "\n",
        "def stream_graph_updates(user_input: str):\n",
        "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
        "        for value in event.values():\n",
        "            print(f\"{COLOR_GREEN}User: {COLOR_RESET}{user_input}\")\n",
        "            print(f\"{COLOR_YELLOW}Assistant: {COLOR_RESET}{value['messages'][-1].content}\")\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        user_input = input(\"User: \")\n",
        "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "            print(f\"{COLOR_GREEN}User: {COLOR_RESET}{user_input}\")\n",
        "            print(f\"{COLOR_YELLOW}Assistant: {COLOR_RESET}Goodbye!\")\n",
        "            break\n",
        "\n",
        "        stream_graph_updates(user_input)\n",
        "    except:\n",
        "        # fallback if input() is not available\n",
        "        user_input = \"What do you know about LangGraph?\"\n",
        "        print(\"User: \" + user_input)\n",
        "        stream_graph_updates(user_input)\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEZSOSYSqkI4"
      },
      "source": [
        "Como ves, primero le he preguntado por el último partido del Real Madrid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNfscOARqkI4"
      },
      "source": [
        "Sin embargo, a continuación le he preguntado qué jugadores jugaron y no sabía de qué le hablaba, eso es porque no se mantiene el contexto de la conversación. Así que lo siguiente que vamos a hacer es agregar una memoria al agente para que pueda mantener el contexto de la conversación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhlP_5hwqkI4"
      },
      "source": [
        "Vamos a escribir todo junto para que sea más legible"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-e57hm6PqkI4",
        "outputId": "888addc3-bccd-4934-da84-42fe745feba4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "\n",
        "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "from langchain_core.messages import ToolMessage\n",
        "\n",
        "from IPython.display import Image, display\n",
        "import json\n",
        "\n",
        "import os\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"    # Disable LangSmith tracing\n",
        "\n",
        "import dotenv\n",
        "ANTHROPIC_TOKEN = os.getenv(\"ANTHROPIC_LANGGRAPH_API_KEY\")\n",
        "TAVILY_API_KEY = os.getenv(\"TAVILY_LANGGRAPH_API_KEY\")\n",
        "\n",
        "# State\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "# Tools\n",
        "wrapper = TavilySearchAPIWrapper(tavily_api_key=TAVILY_API_KEY)\n",
        "tool = TavilySearchResults(api_wrapper=wrapper, max_results=2)\n",
        "tools_list = [tool]\n",
        "# Create the LLM model\n",
        "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20241022\", api_key=ANTHROPIC_TOKEN)\n",
        "# Create the LLM with tools\n",
        "llm_with_tools = llm.bind_tools(tools_list)\n",
        "\n",
        "# BasicToolNode class\n",
        "class BasicToolNode:\n",
        "    \"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\n",
        "\n",
        "    def __init__(self, tools: list) -> None:\n",
        "        \"\"\"\n",
        "        Initialize the tools\n",
        "\n",
        "        Args:\n",
        "            tools (list): The tools to use\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        # Initialize the tools\n",
        "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
        "\n",
        "    def __call__(self, inputs: dict):\n",
        "        \"\"\"\n",
        "        Call the node\n",
        "\n",
        "        Args:\n",
        "            inputs (dict): The inputs to the node\n",
        "\n",
        "        Returns:\n",
        "            dict: The outputs of the node\n",
        "        \"\"\"\n",
        "        # Get the last message\n",
        "        if messages := inputs.get(\"messages\", []):\n",
        "            message = messages[-1]\n",
        "        else:\n",
        "            raise ValueError(\"No message found in input\")\n",
        "\n",
        "        # Execute the tools\n",
        "        outputs = []\n",
        "        for tool_call in message.tool_calls:\n",
        "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
        "                tool_call[\"args\"]\n",
        "            )\n",
        "            outputs.append(\n",
        "                ToolMessage(\n",
        "                    content=json.dumps(tool_result),\n",
        "                    name=tool_call[\"name\"],\n",
        "                    tool_call_id=tool_call[\"id\"],\n",
        "                )\n",
        "            )\n",
        "        return {\"messages\": outputs}\n",
        "\n",
        "basic_tool_node = BasicToolNode(tools=tools_list)\n",
        "\n",
        "# Functions\n",
        "def chatbot_function(state: State):\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "# Route function\n",
        "def route_tools_function(state: State):\n",
        "    \"\"\"\n",
        "    Use in the conditional_edge to route to the ToolNode if the last message\n",
        "    has tool calls. Otherwise, route to the end.\n",
        "    \"\"\"\n",
        "    # Get last message\n",
        "    if isinstance(state, list):\n",
        "        ai_message = state[-1]\n",
        "    elif messages := state.get(\"messages\", []):\n",
        "        ai_message = messages[-1]\n",
        "    else:\n",
        "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
        "\n",
        "    # Router in function of last message\n",
        "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
        "        return \"tools_node\"\n",
        "    return END\n",
        "\n",
        "# Start to build the graph\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "# Add nodes to the graph\n",
        "graph_builder.add_node(\"chatbot_node\", chatbot_function)\n",
        "graph_builder.add_node(\"tools_node\", basic_tool_node)\n",
        "\n",
        "# Add edges\n",
        "graph_builder.add_edge(START, \"chatbot_node\")\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"chatbot_node\",\n",
        "    route_tools_function,\n",
        "    {\n",
        "        \"tools_node\": \"tools_node\",\n",
        "        END: END\n",
        "    },\n",
        ")\n",
        "graph_builder.add_edge(\"tools_node\", \"chatbot_node\")\n",
        "\n",
        "# Compile the graph\n",
        "graph = graph_builder.compile()\n",
        "\n",
        "# Display the graph\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception as e:\n",
        "    print(f\"Error al visualizar el grafo: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKFiuRNnqkI4"
      },
      "source": [
        "Ejecutamos el grafo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDhOMiNkqkI5"
      },
      "outputs": [],
      "source": [
        "# Colors for the terminal\n",
        "COLOR_GREEN = \"\\033[32m\"\n",
        "COLOR_YELLOW = \"\\033[33m\"\n",
        "COLOR_RESET = \"\\033[0m\"\n",
        "\n",
        "\n",
        "def stream_graph_updates(user_input: str):\n",
        "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
        "        for value in event.values():\n",
        "            print(f\"{COLOR_GREEN}User: {COLOR_RESET}{user_input}\")\n",
        "            print(f\"{COLOR_YELLOW}Assistant: {COLOR_RESET}{value['messages'][-1].content}\")\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        user_input = input(\"User: \")\n",
        "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "            print(f\"{COLOR_GREEN}User: {COLOR_RESET}{user_input}\")\n",
        "            print(f\"{COLOR_YELLOW}Assistant: {COLOR_RESET}Goodbye!\")\n",
        "            break\n",
        "\n",
        "        stream_graph_updates(user_input)\n",
        "    except:\n",
        "        # fallback if input() is not available\n",
        "        user_input = \"What do you know about LangGraph?\"\n",
        "        print(\"User: \" + user_input)\n",
        "        stream_graph_updates(user_input)\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28dhQ4joqkI5"
      },
      "source": [
        "Volvemos a ver que el problema es que no recuerda el contexto de la conversación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaDOPDgFqkI5"
      },
      "source": [
        "## Agregar memoria al chatbot - memoria a corto plazo, memoria dentro del hilo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmzZpn_pqkI5"
      },
      "source": [
        "Nuestro chatbot ahora puede usar herramientas para responder preguntas de los usuarios, pero no recuerda el contexto de las interacciones anteriores. Esto limita su capacidad de tener conversaciones coherentes y de múltiples turnos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GdC25A0qkI5"
      },
      "source": [
        "`LangGraph` resuelve este problema a través de puntos de control persistentes o `checkpoints`. Si le proporcionamos un `checkpointer` al compilar el grafo y un `thread_id` al llamar al grafo, `LangGraph` guarda automáticamente el estado después de cada iteración en la conversación.\n",
        "\n",
        "Cuando invoquemos el grafo nuevamente usando el mismo `thread_id`, el grafo cargará su estado guardado, permitiendo que el chatbot continúe donde lo dejó."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3N5J7CRcqkI5"
      },
      "source": [
        "Veremos más tarde que ese `checkpointing` es mucho más potente que la simple memoria de chat: le permite guardar y reanudar estados complejos en cualquier momento para la recuperación de errores, flujos de trabajo con `human in the loop`, interacciones en el tiempo y más. Pero antes de ver todo eso, vamos a agregar puntos de control para permitir conversaciones de varias iteraciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_fOgp7DPqkI5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import dotenv\n",
        "\n",
        "dotenv.load_dotenv()\n",
        "\n",
        "ANTHROPIC_TOKEN = os.getenv(\"ANTHROPIC_LANGGRAPH_API_KEY\")\n",
        "TAVILY_API_KEY = os.getenv(\"TAVILY_LANGGRAPH_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPo6X6ciqkI5"
      },
      "source": [
        "Para empezar, creamos un `checkpointer` [MemorySaver](https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.memory.MemorySaver)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "g3NBvBorqkI5"
      },
      "outputs": [],
      "source": [
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "memory = MemorySaver()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2jky8uzqkI5"
      },
      "source": [
        " > **Aviso**\n",
        " >\n",
        " > Estamos usando un `checkpointer` en memoria, es decir, se guarda en la RAM y cuando se termine de ejecutar el grafo se elimina. Esto nos vale para nuestro caso, ya que es un ejemplo para aprender a usar `LangGraph`. En una aplicación de producción, es probable que se necesite cambiar esto para usarlo con `SqliteSaver` o `PostgresSaver` y conéctarnos a nuestra propia base de datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFQyecJpqkI5"
      },
      "source": [
        "A continuación, definimos el grafo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_5M6muwPqkI5"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "\n",
        "graph_builder = StateGraph(State)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jdkGnN5qkI5"
      },
      "source": [
        "Definimos la `tool`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "B96_irjrqkI5",
        "outputId": "82c634b1-fdca-4dcc-dbaf-b0e8d26d510d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-3315549533>:5: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
            "  tool = TavilySearchResults(api_wrapper=wrapper, max_results=2)\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "wrapper = TavilySearchAPIWrapper(tavily_api_key=TAVILY_API_KEY)\n",
        "tool = TavilySearchResults(api_wrapper=wrapper, max_results=2)\n",
        "tools_list = [tool]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzunzd_KqkI5"
      },
      "source": [
        "A continuación, el `LLM` con las `bind_tools` y lo añadimos al grafo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "w4gouTYYqkI5",
        "outputId": "e4d1391b-3dc5-44ab-c161-bc07c1846083",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7d186775c9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from langchain_anthropic import ChatAnthropic\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"    # Disable LangSmith tracing\n",
        "\n",
        "# Create the LLM\n",
        "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20241022\", api_key=ANTHROPIC_TOKEN)\n",
        "\n",
        "# Modification: tell the LLM which tools it can call\n",
        "llm_with_tools = llm.bind_tools(tools_list)\n",
        "\n",
        "# Define the chatbot function\n",
        "def chatbot_function(state: State):\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "# Add the chatbot node\n",
        "graph_builder.add_node(\"chatbot_node\", chatbot_function)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E_-9gwiqkI5"
      },
      "source": [
        "Antes construimos nuestro propio `BasicToolNode` para aprender cómo funciona, ahora lo reemplazaremos con el método de LangGraph `ToolNode` y `tools_condition`, ya que estos hacen algunas cosas buenas como la ejecución paralela de API. Aparte de eso, el resto es igual que antes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dJybIlz3qkI5",
        "outputId": "5fdbf7c4-e11a-48dc-8e0b-6cc58597f59e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7d186775c9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "\n",
        "tool_node = ToolNode(tools=[tool])\n",
        "graph_builder.add_node(\"tools\", tool_node)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCPEpbGjqkI5"
      },
      "source": [
        "Añadimos el nodo de `tools_condition` al grafo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0eUHXOjvqkI5",
        "outputId": "579741a7-47a4-455d-bb57-7227494055c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7d186775c9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "graph_builder.add_conditional_edges(\n",
        "    \"chatbot_node\",\n",
        "    tools_condition,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqgNZDSmqkI5"
      },
      "source": [
        "Añadimos el nodo de `tools` al grafo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RNxhlYT7qkI5",
        "outputId": "690faad9-6ae0-448c-9654-64b39efa16c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7d186775c9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "graph_builder.add_edge(\"tools\", \"chatbot_node\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmLzNKpRqkI5"
      },
      "source": [
        "Añadimos el nodo de `START` al grafo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "FYgXpizyqkI5",
        "outputId": "d31b8c32-6631-44b0-8b4d-1e90ce269aa0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7d186775c9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "graph_builder.add_edge(START, \"chatbot_node\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wwhz2emvqkI6"
      },
      "source": [
        "Compilamos el grafo añadiendo el `checkpointer`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Fsp3y0qiqkI6"
      },
      "outputs": [],
      "source": [
        "graph = graph_builder.compile(checkpointer=memory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcE1uyiQqkI6"
      },
      "source": [
        "Lo representamos gráficamente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jaI7iMRIqkI6",
        "outputId": "d6663b9e-a556-425d-c67d-5ca00b13c7cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception as e:\n",
        "    print(f\"Error al visualizar el grafo: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ukboWT5qkI6"
      },
      "source": [
        "Creamos una configuración con un `thread_id` de un usuario"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "dfZC5JWYqkI6"
      },
      "outputs": [],
      "source": [
        "USER1_THREAD_ID = \"1\"\n",
        "config_USER1 = {\"configurable\": {\"thread_id\": USER1_THREAD_ID}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "iawnpH1mqkI6",
        "outputId": "928d2ce7-4000-4702-e86a-f778fc7572bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Hi there! My name is Maximo.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Hello Maximo! Nice to meet you. I'm an AI assistant with access to search capabilities that can help you find information and answer questions. Is there anything specific you'd like to know about or discuss?\n"
          ]
        }
      ],
      "source": [
        "user_input = \"Hi there! My name is Maximo.\"\n",
        "\n",
        "# The config is the **second positional argument** to stream() or invoke()!\n",
        "events = graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
        "    config_USER1,\n",
        "    stream_mode=\"values\",\n",
        ")\n",
        "for event in events:\n",
        "    event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "RGf33hgoqkI6",
        "outputId": "f56d39aa-610f-488b-b5db-c2983141a4c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Do you remember my name?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Yes, you told me your name is Maximo!\n"
          ]
        }
      ],
      "source": [
        "user_input = \"Do you remember my name?\"\n",
        "\n",
        "# The config is the **second positional argument** to stream() or invoke()!\n",
        "events = graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
        "    config_USER1,\n",
        "    stream_mode=\"values\",\n",
        ")\n",
        "for event in events:\n",
        "    event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_es2dl0jqkI6"
      },
      "source": [
        "Como se puede ver, no hemos pasado una lista con los mensajes, todo está siendo gestionado por el `checkpointer`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdwphFYAqkI6"
      },
      "source": [
        "Si ahora probamos con otro usuario, es decir, con otro `thread_id`, veremos que el grafo no recuerda la conversación anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Ij35b_pLqkI6",
        "outputId": "e1207594-57da-45fc-84f6-e2db0a2b8bfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Do you remember my name?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "I don't have access to any previous conversation history or personal information about users. I start fresh with each conversation and don't maintain any memory of past interactions. If you'd like me to know your name, you'll need to tell me what it is.\n"
          ]
        }
      ],
      "source": [
        "USER2_THREAD_ID = \"2\"\n",
        "config_USER2 = {\"configurable\": {\"thread_id\": USER2_THREAD_ID}}\n",
        "\n",
        "user_input = \"Do you remember my name?\"\n",
        "\n",
        "events = graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
        "    config_USER2,\n",
        "    stream_mode=\"values\",\n",
        ")\n",
        "for event in events:\n",
        "    event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nug9kyV3qkI6"
      },
      "source": [
        "Ahora que nuestro chatbot tiene herramientas de búsqueda y memoria, vamos a repetir el ejemplo anterior, donde le pregunto por el resultado del último partido del Real Madrid en la Liga y luego por qué jugadores jugaron."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "JdDB3UlPqkI6",
        "outputId": "79fdfe58-1201-43a2-8659-d40f12f1a342",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "How did Real Madrid fare against Leganes in La Liga?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "[{'text': 'Let me search for information about the recent Real Madrid vs Leganes match in La Liga.', 'type': 'text'}, {'id': 'toolu_01T4iNC1PuDrAeKk9ZVmGQLp', 'input': {'query': 'Real Madrid vs Leganes La Liga 2024 result'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (toolu_01T4iNC1PuDrAeKk9ZVmGQLp)\n",
            " Call ID: toolu_01T4iNC1PuDrAeKk9ZVmGQLp\n",
            "  Args:\n",
            "    query: Real Madrid vs Leganes La Liga 2024 result\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search_results_json\n",
            "\n",
            "[{\"title\": \"Real Madrid 3-0 Leganés (Nov 24, 2024) Final Score - ESPN\", \"url\": \"https://www.espn.com/soccer/match/_/gameId/704796/real-madrid-leganes\", \"content\": \"| [Leganés](/soccer/team/_/id/17534/leganes) | 38 | 9 | 13 | 16 | -17 | 40 |\\n| [Las Palmas](/soccer/team/_/id/98/las-palmas) | 38 | 8 | 8 | 22 | -21 | 32 |\\n| [Real Valladolid](/soccer/team/_/id/95/real-valladolid) | 38 | 4 | 4 | 30 | -64 | 16 | [...] ![](data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz48c3ZnIHdpZHRoPSI5OTk5OXB4IiBoZWlnaHQ9Ijk5OTk5cHgiIHZpZXdCb3g9IjAgMCA5OTk5OSA5OTk5OSIgdmVyc2lvbj0iMS4xIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIj48ZyBzdHJva2U9Im5vbmUiIGZpbGw9Im5vbmUiIGZpbGwtb3BhY2l0eT0iMCI+PHJlY3QgeD0iMCIgeT0iMCIgd2lkdGg9Ijk5OTk5IiBoZWlnaHQ9Ijk5OTk5Ij48L3JlY3Q+IDwvZz4gPC9zdmc+) [...] | -    Match ends, Leganes 0, Real Madrid 3. |\\n| 90'+4'    Second Half ends, Leganes 0, Real Madrid 3. |\\n| 90'+3'    Sébastien Haller (Leganes) wins a free kick in the defensive half. |\", \"score\": 0.9379027}, {\"title\": \"Leganes 0-3 Real Madrid - LaLiga 2024/2025 Head to Head Statistics\", \"url\": \"https://www.whoscored.com/matches/1821557/show/spain-laliga-2024-2025-leganes-real-madrid\", \"content\": \"Leganes take on Real Madrid in the 2024/2025 LaLiga on Sunday, November 24, 2024.\", \"score\": 0.9305657}]\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "[{'text': 'Based on the search results, Real Madrid defeated Leganes 3-0 in their La Liga match played on November 24, 2024. The match was a convincing victory for Real Madrid, with a clean sheet to go along with their three goals. Let me search for more details about the match.', 'type': 'text'}, {'id': 'toolu_01NP919jqsUr7XjZFQuV5z6A', 'input': {'query': 'Real Madrid vs Leganes La Liga November 24 2024 goals scorers match details'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (toolu_01NP919jqsUr7XjZFQuV5z6A)\n",
            " Call ID: toolu_01NP919jqsUr7XjZFQuV5z6A\n",
            "  Args:\n",
            "    query: Real Madrid vs Leganes La Liga November 24 2024 goals scorers match details\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search_results_json\n",
            "\n",
            "[{\"title\": \"Real Madrid 3-0 Leganés (Nov 24, 2024) Final Score - ESPN\", \"url\": \"https://www.espn.com/soccer/match/_/gameId/704796/real-madrid-leganes\", \"content\": \"| No.Name |\\n| --- |\\n| 13[Marko Dmitrovic](https://www.espn.com/soccer/player/_/id/179211/marko-dmitrovic) |\\n| 22[Matija Nastasic](https://www.espn.com/soccer/player/_/id/151765/matija-nastasic) |\\n| 20[Javi Hernández](https://www.espn.com/soccer/player/_/id/278174/javi-hernandez) |\\n| 6[Sergio González](https://www.espn.com/soccer/player/_/id/198849/sergio-gonzalez) | [...] | [Leganés](/soccer/team/_/id/17534/leganes) | 38 | 9 | 13 | 16 | -17 | 40 |\\n| [Las Palmas](/soccer/team/_/id/98/las-palmas) | 38 | 8 | 8 | 22 | -21 | 32 |\\n| [Real Valladolid](/soccer/team/_/id/95/real-valladolid) | 38 | 4 | 4 | 30 | -64 | 16 | [...] | -    Match ends, Leganes 0, Real Madrid 3. |\\n| 90'+4'    Second Half ends, Leganes 0, Real Madrid 3. |\\n| 90'+3'    Sébastien Haller (Leganes) wins a free kick in the defensive half. |\", \"score\": 0.92857105}, {\"title\": \"Leganés vs. Real Madrid - Final Score - November 24, 2024\", \"url\": \"https://www.foxsports.com/soccer/la-liga-leganes-vs-real-madrid-nov-24-2024-game-boxscore-145559\", \"content\": \"KEY PLAYERS ; Kylian Mbappe RMD · #9. 1 Goal, 3 SOG, 32 Passes ; Arda Guler RMD · #15. 1 Assist, 2 SOG, 38 Passes ; Daniel Raba LGN · #10. 4 Passes.\", \"score\": 0.9049283}]\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "From the additional search results, I can add that Kylian Mbappé was among the scorers for Real Madrid, scoring one goal in the match. Arda Güler also contributed with an assist. The 3-0 victory demonstrated Real Madrid's dominance in the match, with both their attack and defense performing well to secure the three points.\n"
          ]
        }
      ],
      "source": [
        "USER3_THREAD_ID = \"3\"\n",
        "config_USER3 = {\"configurable\": {\"thread_id\": USER3_THREAD_ID}}\n",
        "\n",
        "user_input = \"How did Real Madrid fare against Leganes in La Liga?\"\n",
        "\n",
        "events = graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
        "    config_USER3,\n",
        "    stream_mode=\"values\",\n",
        ")\n",
        "for event in events:\n",
        "    event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-beQjhMqkI6"
      },
      "source": [
        "Ahora le preguntamos por los jugadores que jugaron en el partido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "yMvZ-YUCqkI6",
        "outputId": "0a3bc917-38af-4078-f0fd-94775f92f660",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Which players played the match?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "[{'text': 'Let me search for the lineup and player information from this match.', 'type': 'text'}, {'id': 'toolu_019NcLcZAFmaFsESu22YsP5t', 'input': {'query': 'Real Madrid vs Leganes November 24 2024 La Liga lineups starting XI players'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (toolu_019NcLcZAFmaFsESu22YsP5t)\n",
            " Call ID: toolu_019NcLcZAFmaFsESu22YsP5t\n",
            "  Args:\n",
            "    query: Real Madrid vs Leganes November 24 2024 La Liga lineups starting XI players\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search_results_json\n",
            "\n",
            "[{\"title\": \"CONFIRMED lineups: Leganes vs Real Madrid, 2024 LaLiga\", \"url\": \"https://www.managingmadrid.com/2024/11/24/24304577/leganes-vs-real-madrid-2024-la-liga-live-online-stream\", \"content\": \"Real Madrid starting XI: Courtois, Valverde, Asencio, Rudiger, Garcia, Camavinga, Guler, Ceballos, Vinicius, Bellingham, Mbappe.\\n\\nLeganes starting XI (TBC): Dmitrovic, Altimira, Gonzalez, Nastasic, Hernandez, Neyou, Cisse, Brasanac, Cruz, Munir, De la Fuente. [...] ![Deportivo Alaves V Rcd Mallorca - Laliga Ea Sports](https://cdn.vox-cdn.com/thumbor/OhJ23mV11Yw9l-5uECFib85SpZk=/0x0:5000x3333/1200x800/filters:focal(1648x1310:2448x2110)/cdn.vox-cdn.com/uploads/chorus_image/image/73744313/2182373713.0.jpg)\\n\\n[Real Madrid](https://www.managingmadrid.com) have published their starting lineup for the upcoming match against Leganes in La Liga. [...] It will be extremely important for Real Madrid to play this game with the intensity it requires, as they will cut Barcelona’s lead in the table with a win. Staying healthy and fresh for Wednesday’s crucial match against [Liverpool](https://liverpooloffside.sbnation.com/) in the [Champions League](https://www.sbnation.com/champions-league) should also be a priority.\\n\\n**HOW TO WATCH, STREAM LA LIGA**\\n\\n**Date**: 11/24/2024\\n\\n**Time**: 18:30CET, 12:30pm EST.\\n\\n**Venue**: Butarque, Leganes, Spain.\", \"score\": 0.9609261}, {\"title\": \"Leganes vs Real Madrid Lineup (24 Nov 2024) - La Liga - myKhel\", \"url\": \"https://www.mykhel.com/football/la-liga-leganes-vs-real-madrid-lineup-2445143/\", \"content\": \"Leganes vs Real Madrid Line Up · Thibaut Courtois Goalkeeper. 1 · Raul Defender. 35 · Antonio Ruediger Defender. 22 · Federico Valverde Defender. 8.\", \"score\": 0.94401723}]\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "[{'text': 'Based on the search results, here are the starting lineups for both teams:\\n\\nReal Madrid starting XI:\\n- Thibaut Courtois (GK)\\n- Federico Valverde\\n- Marco Asensio\\n- Antonio Rüdiger\\n- Eric Garcia\\n- Eduardo Camavinga\\n- Arda Güler\\n- Dani Ceballos\\n- Vinícius Jr.\\n- Jude Bellingham\\n- Kylian Mbappé\\n\\nLeganés starting XI:\\n- Marko Dmitrovic (GK)\\n- Altimira\\n- Sergio González\\n- Matija Nastasic\\n- Javi Hernández\\n- Neyou\\n- Cisse\\n- Darko Brasanac\\n- Cruz\\n- Munir\\n- De la Fuente\\n\\nLet me search for information about any substitutions made during the match.', 'type': 'text'}, {'id': 'toolu_0188moKHFV4dqkYtZmbWdSyb', 'input': {'query': 'Real Madrid vs Leganes November 24 2024 substitutions changes players'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (toolu_0188moKHFV4dqkYtZmbWdSyb)\n",
            " Call ID: toolu_0188moKHFV4dqkYtZmbWdSyb\n",
            "  Args:\n",
            "    query: Real Madrid vs Leganes November 24 2024 substitutions changes players\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search_results_json\n",
            "\n",
            "[{\"title\": \"Leganés vs. Real Madrid - Final Score - November 24, 2024\", \"url\": \"https://www.foxsports.com/soccer/la-liga-leganes-vs-real-madrid-nov-24-2024-game-boxscore-145559\", \"content\": \"KEY PLAYERS · LEGANES. formation: 4-2-3-1. field. 13. Dmitrovic · 20. Hernandez · 22. Nastasic · 6. Gonzalez · 74'. 2. Altimira · 57'. 17. Neyou.\", \"score\": 0.8679453}, {\"title\": \"Real Madrid vs Leganés: Spanish La Liga stats & head-to-head - BBC\", \"url\": \"https://www.bbc.com/sport/football/live/cm2ndndvdgmt\", \"content\": \"#### Substitutes\\n\\n### home team, Real Madrid\\n\\n*   Number 43,\\n    \\n    Diego Aguado\\n    \\n*   Number 26,\\n    \\n    Fran González\\n    \\n*   Number 34,\\n    \\n    Sergio Mestre\\n    \\n*   Number 16,\\n    \\n    Endrick\\n    \\n*   Number 4,\\n    \\n    D. Alaba\\n    \\n*   Number 7,\\n    \\n    Vinícius Júnior\\n    \\n*   Number 11,\\n    \\n    Rodrygo\\n    \\n*   Number 14,\\n    \\n    A. Tchouaméni\\n    \\n*   Number 18,\\n    \\n    Jesús Vallejo\\n    \\n*   Number 8,\\n    \\n    F. Valverde [...] #### Substitutes\\n\\n*   Number 36,\\n    \\n    Alvin\\n    \\n*   Number 2,\\n    \\n    Adrià Alti\\n    \\n*   Number 14,\\n    \\n    D. Brašanac\\n    \\n*   Number 24,\\n    \\n    J. Chicco\\n    \\n*   Number 8,\\n    \\n    S. Cissé\\n    \\n*   Number 30,\\n    \\n    Y. Diomande\\n    \\n*   Number 23,\\n    \\n    M. El Haddadi\\n    \\n*   Number 18,\\n    \\n    Duk\\n    \\n*   Number 21,\\n    \\n    Roberto López\\n    \\n*   Number 1,\\n    \\n    Juan Soriano\\n    \\n*   Number 3,\\n    \\n    Jorge Sáenz\\n    \\n*   Number 9,\\n    \\n    Miguel de la Fuente [...] #### Substitutes\\n\\n*   Number 43,\\n    \\n    Diego Aguado\\n    \\n*   Number 26,\\n    \\n    Fran González\\n    \\n*   Number 34,\\n    \\n    Sergio Mestre\\n    \\n*   Number 16,\\n    \\n    Endrick\\n    \\n*   Number 4,\\n    \\n    D. Alaba\\n    \\n*   Number 7,\\n    \\n    Vinícius Júnior\\n    \\n*   Number 11,\\n    \\n    Rodrygo\\n    \\n*   Number 14,\\n    \\n    A. Tchouaméni\\n    \\n*   Number 18,\\n    \\n    Jesús Vallejo\\n    \\n*   Number 8,\\n    \\n    F. Valverde\", \"score\": 0.8302782}]\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "From the available information, both teams had substitutes available. For Real Madrid, the bench included:\n",
            "- Diego Aguado\n",
            "- Fran González\n",
            "- Sergio Mestre\n",
            "- Endrick\n",
            "- David Alaba\n",
            "- Rodrygo\n",
            "- Aurélien Tchouaméni\n",
            "- Jesús Vallejo\n",
            "\n",
            "For Leganés, the substitutes included:\n",
            "- Juan Soriano\n",
            "- Adrià Alti\n",
            "- Jorge Sáenz\n",
            "- Roberto López\n",
            "- Duk\n",
            "- Munir El Haddadi\n",
            "- Youssouf Diomande\n",
            "- Alvin\n",
            "\n",
            "The search results show that there were some substitutions during the match, with Altimira being replaced around the 74th minute and Neyou coming off around the 57th minute for Leganés, though the complete substitution information isn't fully available in the search results.\n"
          ]
        }
      ],
      "source": [
        "user_input = \"Which players played the match?\"\n",
        "\n",
        "events = graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
        "    config_USER3,\n",
        "    stream_mode=\"values\",\n",
        ")\n",
        "for event in events:\n",
        "    event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHzjFbhyqkI6"
      },
      "source": [
        "Tras mucho buscar, al final lo encuentra. Por lo que ya tenemos un chatbot con `tools` y memoria."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPYdXrSHqkI6"
      },
      "source": [
        "Por ahora, hemos creado unos `checkpoints` en tres hilos diferentes. Pero, ¿qué entra en cada `checkpoint`? Para inspeccionar el estado de un grafo para una configuración dada podemos usar el método `get_state(config)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "cRXsmJcMqkI6",
        "outputId": "2f8498d5-d58c-44f8-cf91-e4c1d8d61aa8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StateSnapshot(values={'messages': [HumanMessage(content='How did Real Madrid fare against Leganes in La Liga?', additional_kwargs={}, response_metadata={}, id='c0f69c6c-0c67-4fea-9030-6d0e2e00a55a'), AIMessage(content=[{'text': 'Let me search for information about the recent Real Madrid vs Leganes match in La Liga.', 'type': 'text'}, {'id': 'toolu_01T4iNC1PuDrAeKk9ZVmGQLp', 'input': {'query': 'Real Madrid vs Leganes La Liga 2024 result'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}], additional_kwargs={}, response_metadata={'id': 'msg_01UUpvtCcdmaSeLDhZ7Hkxcp', 'model': 'claude-3-5-sonnet-20241022', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 429, 'output_tokens': 90, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-3-5-sonnet-20241022'}, id='run--076c0b90-fdee-4a51-8b29-6140676af3b2-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'Real Madrid vs Leganes La Liga 2024 result'}, 'id': 'toolu_01T4iNC1PuDrAeKk9ZVmGQLp', 'type': 'tool_call'}], usage_metadata={'input_tokens': 429, 'output_tokens': 90, 'total_tokens': 519, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}), ToolMessage(content='[{\"title\": \"Real Madrid 3-0 Leganés (Nov 24, 2024) Final Score - ESPN\", \"url\": \"https://www.espn.com/soccer/match/_/gameId/704796/real-madrid-leganes\", \"content\": \"| [Leganés](/soccer/team/_/id/17534/leganes) | 38 | 9 | 13 | 16 | -17 | 40 |\\\\n| [Las Palmas](/soccer/team/_/id/98/las-palmas) | 38 | 8 | 8 | 22 | -21 | 32 |\\\\n| [Real Valladolid](/soccer/team/_/id/95/real-valladolid) | 38 | 4 | 4 | 30 | -64 | 16 | [...] ![](data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz48c3ZnIHdpZHRoPSI5OTk5OXB4IiBoZWlnaHQ9Ijk5OTk5cHgiIHZpZXdCb3g9IjAgMCA5OTk5OSA5OTk5OSIgdmVyc2lvbj0iMS4xIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIj48ZyBzdHJva2U9Im5vbmUiIGZpbGw9Im5vbmUiIGZpbGwtb3BhY2l0eT0iMCI+PHJlY3QgeD0iMCIgeT0iMCIgd2lkdGg9Ijk5OTk5IiBoZWlnaHQ9Ijk5OTk5Ij48L3JlY3Q+IDwvZz4gPC9zdmc+) [...] | -    Match ends, Leganes 0, Real Madrid 3. |\\\\n| 90\\'+4\\'    Second Half ends, Leganes 0, Real Madrid 3. |\\\\n| 90\\'+3\\'    Sébastien Haller (Leganes) wins a free kick in the defensive half. |\", \"score\": 0.9379027}, {\"title\": \"Leganes 0-3 Real Madrid - LaLiga 2024/2025 Head to Head Statistics\", \"url\": \"https://www.whoscored.com/matches/1821557/show/spain-laliga-2024-2025-leganes-real-madrid\", \"content\": \"Leganes take on Real Madrid in the 2024/2025 LaLiga on Sunday, November 24, 2024.\", \"score\": 0.9305657}]', name='tavily_search_results_json', id='6a3a4f7f-9e61-497f-beb1-833f84787218', tool_call_id='toolu_01T4iNC1PuDrAeKk9ZVmGQLp', artifact={'query': 'Real Madrid vs Leganes La Liga 2024 result', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://www.espn.com/soccer/match/_/gameId/704796/real-madrid-leganes', 'title': 'Real Madrid 3-0 Leganés (Nov 24, 2024) Final Score - ESPN', 'content': \"| [Leganés](/soccer/team/_/id/17534/leganes) | 38 | 9 | 13 | 16 | -17 | 40 |\\n| [Las Palmas](/soccer/team/_/id/98/las-palmas) | 38 | 8 | 8 | 22 | -21 | 32 |\\n| [Real Valladolid](/soccer/team/_/id/95/real-valladolid) | 38 | 4 | 4 | 30 | -64 | 16 | [...] ![](data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz48c3ZnIHdpZHRoPSI5OTk5OXB4IiBoZWlnaHQ9Ijk5OTk5cHgiIHZpZXdCb3g9IjAgMCA5OTk5OSA5OTk5OSIgdmVyc2lvbj0iMS4xIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIj48ZyBzdHJva2U9Im5vbmUiIGZpbGw9Im5vbmUiIGZpbGwtb3BhY2l0eT0iMCI+PHJlY3QgeD0iMCIgeT0iMCIgd2lkdGg9Ijk5OTk5IiBoZWlnaHQ9Ijk5OTk5Ij48L3JlY3Q+IDwvZz4gPC9zdmc+) [...] | -    Match ends, Leganes 0, Real Madrid 3. |\\n| 90'+4'    Second Half ends, Leganes 0, Real Madrid 3. |\\n| 90'+3'    Sébastien Haller (Leganes) wins a free kick in the defensive half. |\", 'score': 0.9379027, 'raw_content': None}, {'url': 'https://www.whoscored.com/matches/1821557/show/spain-laliga-2024-2025-leganes-real-madrid', 'title': 'Leganes 0-3 Real Madrid - LaLiga 2024/2025 Head to Head Statistics', 'content': 'Leganes take on Real Madrid in the 2024/2025 LaLiga on Sunday, November 24, 2024.', 'score': 0.9305657, 'raw_content': None}], 'response_time': 2.34}), AIMessage(content=[{'text': 'Based on the search results, Real Madrid defeated Leganes 3-0 in their La Liga match played on November 24, 2024. The match was a convincing victory for Real Madrid, with a clean sheet to go along with their three goals. Let me search for more details about the match.', 'type': 'text'}, {'id': 'toolu_01NP919jqsUr7XjZFQuV5z6A', 'input': {'query': 'Real Madrid vs Leganes La Liga November 24 2024 goals scorers match details'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}], additional_kwargs={}, response_metadata={'id': 'msg_01YNnUdqqt7ozyXAVf5xYFWm', 'model': 'claude-3-5-sonnet-20241022', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 1318, 'output_tokens': 144, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-3-5-sonnet-20241022'}, id='run--fa5dff65-5e04-4383-9448-42b82dc2fd9c-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'Real Madrid vs Leganes La Liga November 24 2024 goals scorers match details'}, 'id': 'toolu_01NP919jqsUr7XjZFQuV5z6A', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1318, 'output_tokens': 144, 'total_tokens': 1462, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}), ToolMessage(content='[{\"title\": \"Real Madrid 3-0 Leganés (Nov 24, 2024) Final Score - ESPN\", \"url\": \"https://www.espn.com/soccer/match/_/gameId/704796/real-madrid-leganes\", \"content\": \"| No.Name |\\\\n| --- |\\\\n| 13[Marko Dmitrovic](https://www.espn.com/soccer/player/_/id/179211/marko-dmitrovic) |\\\\n| 22[Matija Nastasic](https://www.espn.com/soccer/player/_/id/151765/matija-nastasic) |\\\\n| 20[Javi Hernández](https://www.espn.com/soccer/player/_/id/278174/javi-hernandez) |\\\\n| 6[Sergio González](https://www.espn.com/soccer/player/_/id/198849/sergio-gonzalez) | [...] | [Leganés](/soccer/team/_/id/17534/leganes) | 38 | 9 | 13 | 16 | -17 | 40 |\\\\n| [Las Palmas](/soccer/team/_/id/98/las-palmas) | 38 | 8 | 8 | 22 | -21 | 32 |\\\\n| [Real Valladolid](/soccer/team/_/id/95/real-valladolid) | 38 | 4 | 4 | 30 | -64 | 16 | [...] | -    Match ends, Leganes 0, Real Madrid 3. |\\\\n| 90\\'+4\\'    Second Half ends, Leganes 0, Real Madrid 3. |\\\\n| 90\\'+3\\'    Sébastien Haller (Leganes) wins a free kick in the defensive half. |\", \"score\": 0.92857105}, {\"title\": \"Leganés vs. Real Madrid - Final Score - November 24, 2024\", \"url\": \"https://www.foxsports.com/soccer/la-liga-leganes-vs-real-madrid-nov-24-2024-game-boxscore-145559\", \"content\": \"KEY PLAYERS ; Kylian Mbappe RMD · #9. 1 Goal, 3 SOG, 32 Passes ; Arda Guler RMD · #15. 1 Assist, 2 SOG, 38 Passes ; Daniel Raba LGN · #10. 4 Passes.\", \"score\": 0.9049283}]', name='tavily_search_results_json', id='6b619d60-7624-4201-8716-02380a73aa76', tool_call_id='toolu_01NP919jqsUr7XjZFQuV5z6A', artifact={'query': 'Real Madrid vs Leganes La Liga November 24 2024 goals scorers match details', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://www.espn.com/soccer/match/_/gameId/704796/real-madrid-leganes', 'title': 'Real Madrid 3-0 Leganés (Nov 24, 2024) Final Score - ESPN', 'content': \"| No.Name |\\n| --- |\\n| 13[Marko Dmitrovic](https://www.espn.com/soccer/player/_/id/179211/marko-dmitrovic) |\\n| 22[Matija Nastasic](https://www.espn.com/soccer/player/_/id/151765/matija-nastasic) |\\n| 20[Javi Hernández](https://www.espn.com/soccer/player/_/id/278174/javi-hernandez) |\\n| 6[Sergio González](https://www.espn.com/soccer/player/_/id/198849/sergio-gonzalez) | [...] | [Leganés](/soccer/team/_/id/17534/leganes) | 38 | 9 | 13 | 16 | -17 | 40 |\\n| [Las Palmas](/soccer/team/_/id/98/las-palmas) | 38 | 8 | 8 | 22 | -21 | 32 |\\n| [Real Valladolid](/soccer/team/_/id/95/real-valladolid) | 38 | 4 | 4 | 30 | -64 | 16 | [...] | -    Match ends, Leganes 0, Real Madrid 3. |\\n| 90'+4'    Second Half ends, Leganes 0, Real Madrid 3. |\\n| 90'+3'    Sébastien Haller (Leganes) wins a free kick in the defensive half. |\", 'score': 0.92857105, 'raw_content': None}, {'url': 'https://www.foxsports.com/soccer/la-liga-leganes-vs-real-madrid-nov-24-2024-game-boxscore-145559', 'title': 'Leganés vs. Real Madrid - Final Score - November 24, 2024', 'content': 'KEY PLAYERS ; Kylian Mbappe RMD · #9. 1 Goal, 3 SOG, 32 Passes ; Arda Guler RMD · #15. 1 Assist, 2 SOG, 38 Passes ; Daniel Raba LGN · #10. 4 Passes.', 'score': 0.9049283, 'raw_content': None}], 'response_time': 3.86}), AIMessage(content=\"From the additional search results, I can add that Kylian Mbappé was among the scorers for Real Madrid, scoring one goal in the match. Arda Güler also contributed with an assist. The 3-0 victory demonstrated Real Madrid's dominance in the match, with both their attack and defense performing well to secure the three points.\", additional_kwargs={}, response_metadata={'id': 'msg_01SitLngsVJvYdqZDK6aoGnc', 'model': 'claude-3-5-sonnet-20241022', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 2107, 'output_tokens': 81, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-3-5-sonnet-20241022'}, id='run--2f497ac1-52fd-4868-9a1b-a70cb87142d2-0', usage_metadata={'input_tokens': 2107, 'output_tokens': 81, 'total_tokens': 2188, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}), HumanMessage(content='Which players played the match?', additional_kwargs={}, response_metadata={}, id='427160cb-8932-49a6-a12c-1a2ba433052d'), AIMessage(content=[{'text': 'Let me search for the lineup and player information from this match.', 'type': 'text'}, {'id': 'toolu_019NcLcZAFmaFsESu22YsP5t', 'input': {'query': 'Real Madrid vs Leganes November 24 2024 La Liga lineups starting XI players'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}], additional_kwargs={}, response_metadata={'id': 'msg_01S3ZDcis58ifuNwFBCmYxJK', 'model': 'claude-3-5-sonnet-20241022', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 2197, 'output_tokens': 91, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-3-5-sonnet-20241022'}, id='run--fc63025f-0590-4efc-beec-dd38e2344f9b-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'Real Madrid vs Leganes November 24 2024 La Liga lineups starting XI players'}, 'id': 'toolu_019NcLcZAFmaFsESu22YsP5t', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2197, 'output_tokens': 91, 'total_tokens': 2288, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}), ToolMessage(content='[{\"title\": \"CONFIRMED lineups: Leganes vs Real Madrid, 2024 LaLiga\", \"url\": \"https://www.managingmadrid.com/2024/11/24/24304577/leganes-vs-real-madrid-2024-la-liga-live-online-stream\", \"content\": \"Real Madrid starting XI: Courtois, Valverde, Asencio, Rudiger, Garcia, Camavinga, Guler, Ceballos, Vinicius, Bellingham, Mbappe.\\\\n\\\\nLeganes starting XI (TBC): Dmitrovic, Altimira, Gonzalez, Nastasic, Hernandez, Neyou, Cisse, Brasanac, Cruz, Munir, De la Fuente. [...] ![Deportivo Alaves V Rcd Mallorca - Laliga Ea Sports](https://cdn.vox-cdn.com/thumbor/OhJ23mV11Yw9l-5uECFib85SpZk=/0x0:5000x3333/1200x800/filters:focal(1648x1310:2448x2110)/cdn.vox-cdn.com/uploads/chorus_image/image/73744313/2182373713.0.jpg)\\\\n\\\\n[Real Madrid](https://www.managingmadrid.com) have published their starting lineup for the upcoming match against Leganes in La Liga. [...] It will be extremely important for Real Madrid to play this game with the intensity it requires, as they will cut Barcelona’s lead in the table with a win. Staying healthy and fresh for Wednesday’s crucial match against [Liverpool](https://liverpooloffside.sbnation.com/) in the [Champions League](https://www.sbnation.com/champions-league) should also be a priority.\\\\n\\\\n**HOW TO WATCH, STREAM LA LIGA**\\\\n\\\\n**Date**: 11/24/2024\\\\n\\\\n**Time**: 18:30CET, 12:30pm EST.\\\\n\\\\n**Venue**: Butarque, Leganes, Spain.\", \"score\": 0.9609261}, {\"title\": \"Leganes vs Real Madrid Lineup (24 Nov 2024) - La Liga - myKhel\", \"url\": \"https://www.mykhel.com/football/la-liga-leganes-vs-real-madrid-lineup-2445143/\", \"content\": \"Leganes vs Real Madrid Line Up · Thibaut Courtois Goalkeeper. 1 · Raul Defender. 35 · Antonio Ruediger Defender. 22 · Federico Valverde Defender. 8.\", \"score\": 0.94401723}]', name='tavily_search_results_json', id='f04f385f-958f-4002-8c3b-2d7da5c9fb11', tool_call_id='toolu_019NcLcZAFmaFsESu22YsP5t', artifact={'query': 'Real Madrid vs Leganes November 24 2024 La Liga lineups starting XI players', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://www.managingmadrid.com/2024/11/24/24304577/leganes-vs-real-madrid-2024-la-liga-live-online-stream', 'title': 'CONFIRMED lineups: Leganes vs Real Madrid, 2024 LaLiga', 'content': 'Real Madrid starting XI: Courtois, Valverde, Asencio, Rudiger, Garcia, Camavinga, Guler, Ceballos, Vinicius, Bellingham, Mbappe.\\n\\nLeganes starting XI (TBC): Dmitrovic, Altimira, Gonzalez, Nastasic, Hernandez, Neyou, Cisse, Brasanac, Cruz, Munir, De la Fuente. [...] ![Deportivo Alaves V Rcd Mallorca - Laliga Ea Sports](https://cdn.vox-cdn.com/thumbor/OhJ23mV11Yw9l-5uECFib85SpZk=/0x0:5000x3333/1200x800/filters:focal(1648x1310:2448x2110)/cdn.vox-cdn.com/uploads/chorus_image/image/73744313/2182373713.0.jpg)\\n\\n[Real Madrid](https://www.managingmadrid.com) have published their starting lineup for the upcoming match against Leganes in La Liga. [...] It will be extremely important for Real Madrid to play this game with the intensity it requires, as they will cut Barcelona’s lead in the table with a win. Staying healthy and fresh for Wednesday’s crucial match against [Liverpool](https://liverpooloffside.sbnation.com/) in the [Champions League](https://www.sbnation.com/champions-league) should also be a priority.\\n\\n**HOW TO WATCH, STREAM LA LIGA**\\n\\n**Date**: 11/24/2024\\n\\n**Time**: 18:30CET, 12:30pm EST.\\n\\n**Venue**: Butarque, Leganes, Spain.', 'score': 0.9609261, 'raw_content': None}, {'url': 'https://www.mykhel.com/football/la-liga-leganes-vs-real-madrid-lineup-2445143/', 'title': 'Leganes vs Real Madrid Lineup (24 Nov 2024) - La Liga - myKhel', 'content': 'Leganes vs Real Madrid Line Up · Thibaut Courtois Goalkeeper. 1 · Raul Defender. 35 · Antonio Ruediger Defender. 22 · Federico Valverde Defender. 8.', 'score': 0.94401723, 'raw_content': None}], 'response_time': 2.29}), AIMessage(content=[{'text': 'Based on the search results, here are the starting lineups for both teams:\\n\\nReal Madrid starting XI:\\n- Thibaut Courtois (GK)\\n- Federico Valverde\\n- Marco Asensio\\n- Antonio Rüdiger\\n- Eric Garcia\\n- Eduardo Camavinga\\n- Arda Güler\\n- Dani Ceballos\\n- Vinícius Jr.\\n- Jude Bellingham\\n- Kylian Mbappé\\n\\nLeganés starting XI:\\n- Marko Dmitrovic (GK)\\n- Altimira\\n- Sergio González\\n- Matija Nastasic\\n- Javi Hernández\\n- Neyou\\n- Cisse\\n- Darko Brasanac\\n- Cruz\\n- Munir\\n- De la Fuente\\n\\nLet me search for information about any substitutions made during the match.', 'type': 'text'}, {'id': 'toolu_0188moKHFV4dqkYtZmbWdSyb', 'input': {'query': 'Real Madrid vs Leganes November 24 2024 substitutions changes players'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}], additional_kwargs={}, response_metadata={'id': 'msg_01RCTatSVzjZ2hAfLfwgNZ4J', 'model': 'claude-3-5-sonnet-20241022', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 2953, 'output_tokens': 286, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-3-5-sonnet-20241022'}, id='run--ad614313-e2db-48b7-93ff-297369e27126-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'Real Madrid vs Leganes November 24 2024 substitutions changes players'}, 'id': 'toolu_0188moKHFV4dqkYtZmbWdSyb', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2953, 'output_tokens': 286, 'total_tokens': 3239, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}), ToolMessage(content='[{\"title\": \"Leganés vs. Real Madrid - Final Score - November 24, 2024\", \"url\": \"https://www.foxsports.com/soccer/la-liga-leganes-vs-real-madrid-nov-24-2024-game-boxscore-145559\", \"content\": \"KEY PLAYERS · LEGANES. formation: 4-2-3-1. field. 13. Dmitrovic · 20. Hernandez · 22. Nastasic · 6. Gonzalez · 74\\'. 2. Altimira · 57\\'. 17. Neyou.\", \"score\": 0.8679453}, {\"title\": \"Real Madrid vs Leganés: Spanish La Liga stats & head-to-head - BBC\", \"url\": \"https://www.bbc.com/sport/football/live/cm2ndndvdgmt\", \"content\": \"#### Substitutes\\\\n\\\\n### home team, Real Madrid\\\\n\\\\n*   Number 43,\\\\n    \\\\n    Diego Aguado\\\\n    \\\\n*   Number 26,\\\\n    \\\\n    Fran González\\\\n    \\\\n*   Number 34,\\\\n    \\\\n    Sergio Mestre\\\\n    \\\\n*   Number 16,\\\\n    \\\\n    Endrick\\\\n    \\\\n*   Number 4,\\\\n    \\\\n    D. Alaba\\\\n    \\\\n*   Number 7,\\\\n    \\\\n    Vinícius Júnior\\\\n    \\\\n*   Number 11,\\\\n    \\\\n    Rodrygo\\\\n    \\\\n*   Number 14,\\\\n    \\\\n    A. Tchouaméni\\\\n    \\\\n*   Number 18,\\\\n    \\\\n    Jesús Vallejo\\\\n    \\\\n*   Number 8,\\\\n    \\\\n    F. Valverde [...] #### Substitutes\\\\n\\\\n*   Number 36,\\\\n    \\\\n    Alvin\\\\n    \\\\n*   Number 2,\\\\n    \\\\n    Adrià Alti\\\\n    \\\\n*   Number 14,\\\\n    \\\\n    D. Brašanac\\\\n    \\\\n*   Number 24,\\\\n    \\\\n    J. Chicco\\\\n    \\\\n*   Number 8,\\\\n    \\\\n    S. Cissé\\\\n    \\\\n*   Number 30,\\\\n    \\\\n    Y. Diomande\\\\n    \\\\n*   Number 23,\\\\n    \\\\n    M. El Haddadi\\\\n    \\\\n*   Number 18,\\\\n    \\\\n    Duk\\\\n    \\\\n*   Number 21,\\\\n    \\\\n    Roberto López\\\\n    \\\\n*   Number 1,\\\\n    \\\\n    Juan Soriano\\\\n    \\\\n*   Number 3,\\\\n    \\\\n    Jorge Sáenz\\\\n    \\\\n*   Number 9,\\\\n    \\\\n    Miguel de la Fuente [...] #### Substitutes\\\\n\\\\n*   Number 43,\\\\n    \\\\n    Diego Aguado\\\\n    \\\\n*   Number 26,\\\\n    \\\\n    Fran González\\\\n    \\\\n*   Number 34,\\\\n    \\\\n    Sergio Mestre\\\\n    \\\\n*   Number 16,\\\\n    \\\\n    Endrick\\\\n    \\\\n*   Number 4,\\\\n    \\\\n    D. Alaba\\\\n    \\\\n*   Number 7,\\\\n    \\\\n    Vinícius Júnior\\\\n    \\\\n*   Number 11,\\\\n    \\\\n    Rodrygo\\\\n    \\\\n*   Number 14,\\\\n    \\\\n    A. Tchouaméni\\\\n    \\\\n*   Number 18,\\\\n    \\\\n    Jesús Vallejo\\\\n    \\\\n*   Number 8,\\\\n    \\\\n    F. Valverde\", \"score\": 0.8302782}]', name='tavily_search_results_json', id='1b2abe16-37ac-483c-aecd-e6e2c5892603', tool_call_id='toolu_0188moKHFV4dqkYtZmbWdSyb', artifact={'query': 'Real Madrid vs Leganes November 24 2024 substitutions changes players', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://www.foxsports.com/soccer/la-liga-leganes-vs-real-madrid-nov-24-2024-game-boxscore-145559', 'title': 'Leganés vs. Real Madrid - Final Score - November 24, 2024', 'content': \"KEY PLAYERS · LEGANES. formation: 4-2-3-1. field. 13. Dmitrovic · 20. Hernandez · 22. Nastasic · 6. Gonzalez · 74'. 2. Altimira · 57'. 17. Neyou.\", 'score': 0.8679453, 'raw_content': None}, {'url': 'https://www.bbc.com/sport/football/live/cm2ndndvdgmt', 'title': 'Real Madrid vs Leganés: Spanish La Liga stats & head-to-head - BBC', 'content': '#### Substitutes\\n\\n### home team, Real Madrid\\n\\n*   Number 43,\\n    \\n    Diego Aguado\\n    \\n*   Number 26,\\n    \\n    Fran González\\n    \\n*   Number 34,\\n    \\n    Sergio Mestre\\n    \\n*   Number 16,\\n    \\n    Endrick\\n    \\n*   Number 4,\\n    \\n    D. Alaba\\n    \\n*   Number 7,\\n    \\n    Vinícius Júnior\\n    \\n*   Number 11,\\n    \\n    Rodrygo\\n    \\n*   Number 14,\\n    \\n    A. Tchouaméni\\n    \\n*   Number 18,\\n    \\n    Jesús Vallejo\\n    \\n*   Number 8,\\n    \\n    F. Valverde [...] #### Substitutes\\n\\n*   Number 36,\\n    \\n    Alvin\\n    \\n*   Number 2,\\n    \\n    Adrià Alti\\n    \\n*   Number 14,\\n    \\n    D. Brašanac\\n    \\n*   Number 24,\\n    \\n    J. Chicco\\n    \\n*   Number 8,\\n    \\n    S. Cissé\\n    \\n*   Number 30,\\n    \\n    Y. Diomande\\n    \\n*   Number 23,\\n    \\n    M. El Haddadi\\n    \\n*   Number 18,\\n    \\n    Duk\\n    \\n*   Number 21,\\n    \\n    Roberto López\\n    \\n*   Number 1,\\n    \\n    Juan Soriano\\n    \\n*   Number 3,\\n    \\n    Jorge Sáenz\\n    \\n*   Number 9,\\n    \\n    Miguel de la Fuente [...] #### Substitutes\\n\\n*   Number 43,\\n    \\n    Diego Aguado\\n    \\n*   Number 26,\\n    \\n    Fran González\\n    \\n*   Number 34,\\n    \\n    Sergio Mestre\\n    \\n*   Number 16,\\n    \\n    Endrick\\n    \\n*   Number 4,\\n    \\n    D. Alaba\\n    \\n*   Number 7,\\n    \\n    Vinícius Júnior\\n    \\n*   Number 11,\\n    \\n    Rodrygo\\n    \\n*   Number 14,\\n    \\n    A. Tchouaméni\\n    \\n*   Number 18,\\n    \\n    Jesús Vallejo\\n    \\n*   Number 8,\\n    \\n    F. Valverde', 'score': 0.8302782, 'raw_content': None}], 'response_time': 2.68}), AIMessage(content=\"From the available information, both teams had substitutes available. For Real Madrid, the bench included:\\n- Diego Aguado\\n- Fran González\\n- Sergio Mestre\\n- Endrick\\n- David Alaba\\n- Rodrygo\\n- Aurélien Tchouaméni\\n- Jesús Vallejo\\n\\nFor Leganés, the substitutes included:\\n- Juan Soriano\\n- Adrià Alti\\n- Jorge Sáenz\\n- Roberto López\\n- Duk\\n- Munir El Haddadi\\n- Youssouf Diomande\\n- Alvin\\n\\nThe search results show that there were some substitutions during the match, with Altimira being replaced around the 74th minute and Neyou coming off around the 57th minute for Leganés, though the complete substitution information isn't fully available in the search results.\", additional_kwargs={}, response_metadata={'id': 'msg_01C7ytX6YJJAkuazC3a6dvfQ', 'model': 'claude-3-5-sonnet-20241022', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 4211, 'output_tokens': 210, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-3-5-sonnet-20241022'}, id='run--e0f5aaf1-69a2-4279-94e2-075bd0068e11-0', usage_metadata={'input_tokens': 4211, 'output_tokens': 210, 'total_tokens': 4421, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})]}, next=(), config={'configurable': {'thread_id': '4', 'checkpoint_ns': '', 'checkpoint_id': '1f0486ce-4698-6ba6-800c-6cb516ce9d45'}}, metadata={'source': 'loop', 'writes': {'chatbot_node': {'messages': [AIMessage(content=\"From the available information, both teams had substitutes available. For Real Madrid, the bench included:\\n- Diego Aguado\\n- Fran González\\n- Sergio Mestre\\n- Endrick\\n- David Alaba\\n- Rodrygo\\n- Aurélien Tchouaméni\\n- Jesús Vallejo\\n\\nFor Leganés, the substitutes included:\\n- Juan Soriano\\n- Adrià Alti\\n- Jorge Sáenz\\n- Roberto López\\n- Duk\\n- Munir El Haddadi\\n- Youssouf Diomande\\n- Alvin\\n\\nThe search results show that there were some substitutions during the match, with Altimira being replaced around the 74th minute and Neyou coming off around the 57th minute for Leganés, though the complete substitution information isn't fully available in the search results.\", additional_kwargs={}, response_metadata={'id': 'msg_01C7ytX6YJJAkuazC3a6dvfQ', 'model': 'claude-3-5-sonnet-20241022', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 4211, 'output_tokens': 210, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-3-5-sonnet-20241022'}, id='run--e0f5aaf1-69a2-4279-94e2-075bd0068e11-0', usage_metadata={'input_tokens': 4211, 'output_tokens': 210, 'total_tokens': 4421, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})]}}, 'step': 12, 'parents': {}, 'thread_id': '4'}, created_at='2025-06-13T15:41:37.427523+00:00', parent_config={'configurable': {'thread_id': '4', 'checkpoint_ns': '', 'checkpoint_id': '1f0486ce-1d60-68b9-800b-1ea696da516e'}}, tasks=(), interrupts=())"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "snapshot = graph.get_state(config_USER3)\n",
        "snapshot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aJLttdPqkI6"
      },
      "source": [
        "Si queremos ver el siguiente nodo a procesar, podemos usar el atributo `next`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "K2CYbfyWqkI6",
        "outputId": "645db77a-f731-4fb5-cbd0-c8d16d94cd3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "()"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "snapshot.next"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tldh2boJqkI6"
      },
      "source": [
        "Dado que el grafo ha finalizado, `next` está vacío. Si obtienes un estado desde dentro de una invocación del grafo, `next` indica qué nodo se ejecutará a continuación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdsgyewGqkI6"
      },
      "source": [
        "La instantánea anterior (`snapshot`) contiene los valores de estado actuales, la configuración correspondiente y el siguiente nodo (`next`) a procesar. En nuestro caso, el gráfico ha alcanzado el estado `END`, por eso `next` está vacío."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0xEdzWFqkI6"
      },
      "source": [
        "Vamos a volver a escribir todo el código para que sea más legible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "VoiAZmpEqkI6",
        "outputId": "565019cc-a3df-4338-bb6d-7287e273f4b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
        "from huggingface_hub import login\n",
        "\n",
        "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "from langchain_core.messages import ToolMessage\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "from IPython.display import Image, display\n",
        "import json\n",
        "\n",
        "import os\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"    # Disable LangSmith tracing\n",
        "\n",
        "import dotenv\n",
        "dotenv.load_dotenv()\n",
        "HUGGINGFACE_TOKEN = os.getenv(\"HUGGINGFACE_LANGGRAPH\")\n",
        "TAVILY_API_KEY = os.getenv(\"TAVILY_LANGGRAPH_API_KEY\")\n",
        "\n",
        "# State\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "# Tools\n",
        "wrapper = TavilySearchAPIWrapper(tavily_api_key=TAVILY_API_KEY)\n",
        "tool = TavilySearchResults(api_wrapper=wrapper, max_results=2)\n",
        "tools_list = [tool]\n",
        "\n",
        "# Create the LLM model\n",
        "login(token=HUGGINGFACE_TOKEN)  # Login to HuggingFace to use the model\n",
        "MODEL = \"Qwen/Qwen2.5-72B-Instruct\"\n",
        "model = HuggingFaceEndpoint(\n",
        "    repo_id=MODEL,\n",
        "    task=\"text-generation\",\n",
        "    max_new_tokens=512,\n",
        "    do_sample=False,\n",
        "    repetition_penalty=1.03,\n",
        ")\n",
        "# Create the chat model\n",
        "llm = ChatHuggingFace(llm=model)\n",
        "# Create the LLM with tools\n",
        "llm_with_tools = llm.bind_tools(tools_list)\n",
        "\n",
        "# Tool node\n",
        "tool_node = ToolNode(tools=tools_list)\n",
        "\n",
        "# Functions\n",
        "def chatbot_function(state: State):\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "# Start to build the graph\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "# Add nodes to the graph\n",
        "graph_builder.add_node(\"chatbot_node\", chatbot_function)\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "\n",
        "# Add edges\n",
        "graph_builder.add_edge(START, \"chatbot_node\")\n",
        "graph_builder.add_conditional_edges( \"chatbot_node\", tools_condition)\n",
        "graph_builder.add_edge(\"tools\", \"chatbot_node\")\n",
        "\n",
        "# Compile the graph\n",
        "memory = MemorySaver()\n",
        "graph = graph_builder.compile(checkpointer=memory)\n",
        "\n",
        "# Display the graph\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception as e:\n",
        "    print(f\"Error al visualizar el grafo: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9Wl3o2aqkI7",
        "outputId": "a49e16e3-65af-465d-c951-a06e6c458289"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Hi there! My name is Maximo.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Hello Maximo! It's nice to meet you. How can I assist you today? Feel free to ask me any questions or let me know if you need help with anything specific.\n"
          ]
        }
      ],
      "source": [
        "USER1_THREAD_ID = \"1\"\n",
        "config_USER1 = {\"configurable\": {\"thread_id\": USER1_THREAD_ID}}\n",
        "\n",
        "user_input = \"Hi there! My name is Maximo.\"\n",
        "\n",
        "# The config is the **second positional argument** to stream() or invoke()!\n",
        "events = graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
        "    config_USER1,\n",
        "    stream_mode=\"values\",\n",
        ")\n",
        "for event in events:\n",
        "    event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcOEElGAqkI7",
        "outputId": "aacdd4b8-44c4-4c61-95d8-059c6006003e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Do you remember my name?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Yes, I remember your name! You mentioned it's Maximo. It's nice to chat with you, Maximo. How can I assist you today?\n"
          ]
        }
      ],
      "source": [
        "user_input = \"Do you remember my name?\"\n",
        "\n",
        "# The config is the **second positional argument** to stream() or invoke()!\n",
        "events = graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
        "    config_USER1,\n",
        "    stream_mode=\"values\",\n",
        ")\n",
        "for event in events:\n",
        "    event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpuJcc5SqkI7"
      },
      "source": [
        "**¡Felicidades!** Nuestro chatbot ahora puede mantener el estado de conversación en todas las sesiones gracias al sistema de puntos de control (`checkpoints`) de `LangGraph`. Esto abre posibilidades para interacciones más naturales y contextuales. El control de `LangGraph` incluso maneja estados de grafos complejos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqj2maXjqkI8"
      },
      "source": [
        "## Memoria a largo plazo, memoria entre hilos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h065Q79-qkI8"
      },
      "source": [
        "La memoria es una función cognitiva que permite a las personas almacenar, recuperar y utilizar información para comprender, a partir de su pasado, su presente y su futuro.\n",
        "\n",
        "Existen varios tipos de [memoria](https://langchain-ai.github.io/langgraph/concepts/memory) a largo plazo que pueden utilizarse en aplicaciones de IA."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpwP8ke0qkI8"
      },
      "source": [
        "### Introducción a LangGraph Memory Store"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWuuqa9KqkI8"
      },
      "source": [
        "LangGraph proporciona el [LangGraph Memory Store](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore), que es una forma de guardar y recuperar memoria a largo plazo entre diferentes hilos. De esta manera, en una conversación, un usuario puede indicar que le gusta algo, y en otra conversación, el chatbot puede recuperar esa información para generar una respuesta más personalizada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycVF3E-MqkI8"
      },
      "source": [
        "Se trata de una clase para almacenes persistentes de clave-valor (`key`-`value`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faGuUxbQqkI8"
      },
      "source": [
        "Cuando se almacenan objetos en la memoria se necesitan tres cosas:\n",
        " * Un `namespace` para el objeto, se hace mediante una `tupla`\n",
        " * Una `key` única\n",
        " * El `valor` del objeto\n",
        "\n",
        "Vamos a ver un ejemplo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BbBcusb3qkI8"
      },
      "outputs": [],
      "source": [
        "import uuid\n",
        "from langgraph.store.memory import InMemoryStore\n",
        "\n",
        "in_memory_store = InMemoryStore()\n",
        "\n",
        "# Namespace for the memory to save\n",
        "user_id = \"1\"\n",
        "namespace_for_memory = (user_id, \"memories\")\n",
        "\n",
        "# Save a memory to namespace as key and value\n",
        "key = str(uuid.uuid4())\n",
        "\n",
        "# The value needs to be a dictionary\n",
        "value = {\"food_preference\" : \"I like pizza\"}\n",
        "\n",
        "# Save the memory\n",
        "in_memory_store.put(namespace_for_memory, key, value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGcKXUlzqkI9"
      },
      "source": [
        "El objeto `in_memory_store` que hemos creado tiene varios [métodos](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore) y uno de ellos es `search`, que nos permite buscar por `namespace`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "h7QHBITaqkI9",
        "outputId": "5fad66c8-c5cc-4bd5-ba35-988d679254d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(list, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Search\n",
        "memories = in_memory_store.search(namespace_for_memory)\n",
        "type(memories), len(memories)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoxPHV32qkI9"
      },
      "source": [
        "Es una lista de un único valor, lo cual es lógico, porque solo hemos almacenado un valor, así que vamos a verlo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Y2qfrRrjqkI9",
        "outputId": "5fdf6bff-9e60-49e8-deee-536fcc958fd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'namespace': ['1', 'memories'],\n",
              " 'key': '73784c74-2a89-4f40-b975-ec3620ca2df5',\n",
              " 'value': {'food_preference': 'I like pizza'},\n",
              " 'created_at': '2025-06-13T15:43:11.549078+00:00',\n",
              " 'updated_at': '2025-06-13T15:43:11.549087+00:00',\n",
              " 'score': None}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "value = memories[0]\n",
        "value.dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTTnbNlSqkI9"
      },
      "source": [
        "Podemos ver su `key` y su `value`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ANvVySnIqkI9",
        "outputId": "bb53f80a-5761-472c-c5a9-6bc16c708a9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('73784c74-2a89-4f40-b975-ec3620ca2df5', {'food_preference': 'I like pizza'})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# The key, value\n",
        "memories[0].key, memories[0].value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SA72o_CwqkI9"
      },
      "source": [
        "También podemos usar el método `get` para obtener un objeto de la memoria a partir de su `namespace` y su `key`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "EdZ41FC3qkI9",
        "outputId": "5f1463dd-528b-4227-98f5-839f4b12106a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'namespace': ['1', 'memories'],\n",
              " 'key': '73784c74-2a89-4f40-b975-ec3620ca2df5',\n",
              " 'value': {'food_preference': 'I like pizza'},\n",
              " 'created_at': '2025-06-13T15:43:11.549078+00:00',\n",
              " 'updated_at': '2025-06-13T15:43:11.549087+00:00'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Get the memory by namespace and key\n",
        "memory = in_memory_store.get(namespace_for_memory, key)\n",
        "memory.dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmNNku6QqkI9"
      },
      "source": [
        "Al igual que para la memoria a corto plazo hemos usado los checkpoints, para la memoria a largo plazo vamos a usar `LangGraph Store`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRZQlB-kqkI9"
      },
      "source": [
        "### Chatbot con memoria a largo plazo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oDEaFZRqkI9"
      },
      "source": [
        "Creamos un chatbot básico, con memoria a largo plazo y memoria a corto plazo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rNHK2GphqkI9",
        "outputId": "26a4593e-ecec-40e2-8dca-3136d1d31ea0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph, MessagesState, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
        "from langgraph.checkpoint.memory import MemorySaver # Short-term memory\n",
        "from langgraph.store.base import BaseStore          # Long-term memory\n",
        "from langchain_core.runnables.config import RunnableConfig\n",
        "from langgraph.store.memory import InMemoryStore\n",
        "from IPython.display import Image, display\n",
        "import os\n",
        "import dotenv\n",
        "\n",
        "dotenv.load_dotenv()\n",
        "ANTHROPIC_TOKEN = os.getenv(\"ANTHROPIC_LANGGRAPH_API_KEY\")\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"    # Disable LangSmith tracing\n",
        "\n",
        "# Create the LLM model\n",
        "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20241022\", api_key=ANTHROPIC_TOKEN)\n",
        "\n",
        "# Chatbot instruction\n",
        "MODEL_SYSTEM_MESSAGE = \"\"\"You are a helpful assistant that can answer questions and help with tasks.\n",
        "You have access to a long-term memory that you can use to answer questions and help with tasks.\n",
        "Here is the memory (it may be empty): {memory}\"\"\"\n",
        "\n",
        "# Create new memory from the chat history and any existing memory\n",
        "CREATE_MEMORY_INSTRUCTION = \"\"\"You are a helpful assistant that gets information from the user to personalize your responses.\n",
        "\n",
        "# INFORMATION FROM THE USER:\n",
        "{memory}\n",
        "\n",
        "# INSTRUCTIONS:\n",
        "1. Carefully review the chat history\n",
        "2. Identify new information from the user, such as:\n",
        "   - Personal details (name, location)\n",
        "   - Preferences (likes, dislikes)\n",
        "   - Interests and hobbies\n",
        "   - Past experiences\n",
        "   - Goals or future plans\n",
        "3. Combine any new information with the existing memory\n",
        "4. Format the memory as a clear, bulleted list\n",
        "5. If new information conflicts with existing memory, keep the most recent version\n",
        "\n",
        "Remember: Only include factual information directly stated by the user. Do not make assumptions or inferences.\n",
        "\n",
        "Based on the chat history below, please update the user information:\"\"\"\n",
        "\n",
        "# Nodes\n",
        "def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
        "\n",
        "    \"\"\"Load memory from the store and use it to personalize the chatbot's response.\"\"\"\n",
        "\n",
        "    # Get the user ID from the config\n",
        "    user_id = config[\"configurable\"][\"user_id\"]\n",
        "\n",
        "    # Retrieve memory from the store\n",
        "    namespace = (\"memory\", user_id)\n",
        "    key = \"user_memory\"\n",
        "    existing_memory = store.get(namespace, key)\n",
        "\n",
        "    # Extract the actual memory content if it exists and add a prefix\n",
        "    if existing_memory:\n",
        "        # Value is a dictionary with a memory key\n",
        "        existing_memory_content = existing_memory.value.get('memory')\n",
        "    else:\n",
        "        existing_memory_content = \"No existing memory found.\"\n",
        "    if isinstance(existing_memory_content, str):\n",
        "        print(f\"\\t[Call model debug] Existing memory: {existing_memory_content}\")\n",
        "    else:\n",
        "        print(f\"\\t[Call model debug] Existing memory: {existing_memory_content.content}\")\n",
        "\n",
        "    # Format the memory in the system prompt\n",
        "    system_msg = MODEL_SYSTEM_MESSAGE.format(memory=existing_memory_content)\n",
        "\n",
        "    # Respond using memory as well as the chat history\n",
        "    response = llm.invoke([SystemMessage(content=system_msg)]+state[\"messages\"])\n",
        "\n",
        "    return {\"messages\": response}\n",
        "\n",
        "def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
        "\n",
        "    \"\"\"Reflect on the chat history and save a memory to the store.\"\"\"\n",
        "\n",
        "    # Get the user ID from the config\n",
        "    user_id = config[\"configurable\"][\"user_id\"]\n",
        "\n",
        "    # Retrieve existing memory from the store\n",
        "    namespace = (\"memory\", user_id)\n",
        "    existing_memory = store.get(namespace, \"user_memory\")\n",
        "\n",
        "    # Extract the memory\n",
        "    if existing_memory:\n",
        "        existing_memory_content = existing_memory.value.get('memory')\n",
        "    else:\n",
        "        existing_memory_content = \"No existing memory found.\"\n",
        "    if isinstance(existing_memory_content, str):\n",
        "        print(f\"\\t[Write memory debug] Existing memory: {existing_memory_content}\")\n",
        "    else:\n",
        "        print(f\"\\t[Write memory debug] Existing memory: {existing_memory_content.content}\")\n",
        "\n",
        "    # Format the memory in the system prompt\n",
        "    system_msg = CREATE_MEMORY_INSTRUCTION.format(memory=existing_memory_content)\n",
        "    new_memory = llm.invoke([SystemMessage(content=system_msg)]+state['messages'])\n",
        "    if isinstance(new_memory, str):\n",
        "        print(f\"\\n\\t[Write memory debug] New memory: {new_memory}\")\n",
        "    else:\n",
        "        print(f\"\\n\\t[Write memory debug] New memory: {new_memory.content}\")\n",
        "\n",
        "    # Overwrite the existing memory in the store\n",
        "    key = \"user_memory\"\n",
        "\n",
        "    # Write value as a dictionary with a memory key\n",
        "    store.put(namespace, key, {\"memory\": new_memory.content})\n",
        "\n",
        "# Create graph builder\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "# Add nodes\n",
        "graph_builder.add_node(\"call_model\", call_model)\n",
        "graph_builder.add_node(\"write_memory\", write_memory)\n",
        "\n",
        "# Connect nodes\n",
        "graph_builder.add_edge(START, \"call_model\")\n",
        "graph_builder.add_edge(\"call_model\", \"write_memory\")\n",
        "graph_builder.add_edge(\"write_memory\", END)\n",
        "\n",
        "# Store for long-term (across-thread) memory\n",
        "long_term_memory = InMemoryStore()\n",
        "\n",
        "# Checkpointer for short-term (within-thread) memory\n",
        "short_term_memory = MemorySaver()\n",
        "\n",
        "# Compile the graph\n",
        "graph = graph_builder.compile(checkpointer=short_term_memory, store=long_term_memory)\n",
        "\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPFQdQp7qkI9"
      },
      "source": [
        "Vamos a probarlo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JkngfeGZqkI9",
        "outputId": "be700980-9a24-4314-ad81-5e28b774b325",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Hi, my name is Maximo\n",
            "\t[Call model debug] Existing memory: No existing memory found.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Hello Maximo! Nice to meet you. I'll remember your name. How can I help you today?\n",
            "\t[Write memory debug] Existing memory: No existing memory found.\n",
            "\n",
            "\t[Write memory debug] New memory: \n",
            "\n",
            "Here's what I know about you so far:\n",
            "\n",
            "• Name: Maximo\n"
          ]
        }
      ],
      "source": [
        "# We supply a thread ID for short-term (within-thread) memory\n",
        "# We supply a user ID for long-term (across-thread) memory\n",
        "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n",
        "\n",
        "# User input\n",
        "input_messages = [HumanMessage(content=\"Hi, my name is Maximo\")]\n",
        "\n",
        "# Run the graph\n",
        "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
        "    chunk[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "T0CPPelFqkI9",
        "outputId": "e93408bb-a898-491e-c7b6-b4cf06f0820c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "I like to bike around San Francisco\n",
            "\t[Call model debug] Existing memory: \n",
            "\n",
            "Here's what I know about you so far:\n",
            "\n",
            "• Name: Maximo\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "That's great that you enjoy cycling in San Francisco! I'll remember that about you. San Francisco is a beautiful but challenging city for biking, with its steep hills and iconic streets. Do you have any favorite routes or areas you particularly enjoy riding in? Some popular spots include the Embarcadero waterfront, Golden Gate Park, and crossing the Golden Gate Bridge into Marin County. I'd be curious to hear about your biking experiences in the city!\n",
            "\t[Write memory debug] Existing memory: \n",
            "\n",
            "Here's what I know about you so far:\n",
            "\n",
            "• Name: Maximo\n",
            "\n",
            "\t[Write memory debug] New memory: \n",
            "\n",
            "Here's what I now know about you:\n",
            "\n",
            "• Name: Maximo\n",
            "• Location: San Francisco\n",
            "• Interests/Hobbies: Cycling/biking\n"
          ]
        }
      ],
      "source": [
        "# User input\n",
        "input_messages = [HumanMessage(content=\"I like to bike around San Francisco\")]\n",
        "\n",
        "# Run the graph\n",
        "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
        "    chunk[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uR8FIpCzqkI9"
      },
      "source": [
        "Si recuperamos la memoria a largo plazo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Ly85P6HZqkI9",
        "outputId": "9b6b2c3b-6270-41f6-e24b-0df96aba4152",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'namespace': ['memory', '1'],\n",
              " 'key': 'user_memory',\n",
              " 'value': {'memory': \"\\n\\nHere's what I now know about you:\\n\\n• Name: Maximo\\n• Location: San Francisco\\n• Interests/Hobbies: Cycling/biking\"},\n",
              " 'created_at': '2025-06-13T15:44:43.915561+00:00',\n",
              " 'updated_at': '2025-06-13T15:44:43.915568+00:00'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Namespace for the memory to save\n",
        "user_id = \"1\"\n",
        "namespace = (\"memory\", user_id)\n",
        "existing_memory = long_term_memory.get(namespace, \"user_memory\")\n",
        "existing_memory.dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OAZ1L7WqkI9"
      },
      "source": [
        "Obtenemos su valor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "pU_YTsUwqkI9",
        "outputId": "1a4ac1b1-38d5-47f2-9f54-ccc22b858ded",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Here's what I now know about you:\n",
            "\n",
            "• Name: Maximo\n",
            "• Location: San Francisco\n",
            "• Interests/Hobbies: Cycling/biking\n"
          ]
        }
      ],
      "source": [
        "print(existing_memory.value.get('memory'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dr7adtptqkI9"
      },
      "source": [
        "Ahora podemos empezar un nuevo hilo de conversación, pero con la misma memoria a largo plazo. Veremos que el chatbot recuerda la información del usuario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "IS8ASNh9qkI9",
        "outputId": "77c6469c-f3d8-498e-be31-9ea25715ff51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Hi! Where would you recommend that I go biking?\n",
            "\t[Call model debug] Existing memory: \n",
            "\n",
            "Here's what I now know about you:\n",
            "\n",
            "• Name: Maximo\n",
            "• Location: San Francisco\n",
            "• Interests/Hobbies: Cycling/biking\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Hi Maximo! Since you're in San Francisco, you have access to some fantastic biking opportunities! Here are some top recommendations:\n",
            "\n",
            "1. Golden Gate Bridge to Sausalito - A classic SF bike ride with stunning views. You can take the ferry back!\n",
            "\n",
            "2. Golden Gate Park - Miles of bike-friendly paths through the park, including car-free JFK Drive on weekends.\n",
            "\n",
            "3. The Presidio - Beautiful trails with forest and coastal views, plus connections to the Golden Gate Bridge.\n",
            "\n",
            "4. Angel Island - Take a ferry with your bike and ride around the island for amazing bay views.\n",
            "\n",
            "5. Mount Tamalpais - If you're into mountain biking or more challenging rides, Mt. Tam offers excellent trails just north of the city.\n",
            "\n",
            "6. The Embarcadero - A flat, scenic waterfront ride perfect for casual cycling.\n",
            "\n",
            "7. Twin Peaks - For a challenging climb with rewarding city views (though be prepared for the hills!)\n",
            "\n",
            "Would you like more specific details about any of these routes? Also, what type of riding do you prefer - casual cruising, road cycling, or mountain biking?\n",
            "\t[Write memory debug] Existing memory: \n",
            "\n",
            "Here's what I now know about you:\n",
            "\n",
            "• Name: Maximo\n",
            "• Location: San Francisco\n",
            "• Interests/Hobbies: Cycling/biking\n",
            "\n",
            "\t[Write memory debug] New memory: []\n"
          ]
        }
      ],
      "source": [
        "# We supply a user ID for across-thread memory as well as a new thread ID\n",
        "config = {\"configurable\": {\"thread_id\": \"2\", \"user_id\": \"1\"}}\n",
        "\n",
        "# User input\n",
        "input_messages = [HumanMessage(content=\"Hi! Where would you recommend that I go biking?\")]\n",
        "\n",
        "# Run the graph\n",
        "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
        "    chunk[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Y8wBoS0qkI-"
      },
      "source": [
        "He abierto un nuevo hilo de conversación, le he preguntado dónde podría ir a montar en bici, ha recordado que le había dicho que me gusta ir a montar en bici por San Francisco y me ha respondido con lugares de San Francisco a los que podría ir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gC6od5VGqkI-"
      },
      "source": [
        "### Chatbot con perfil de usuario"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQkKnCvEqkI-"
      },
      "source": [
        "Podemos crear tipados para que el LLM genere una salida con una estructura definida por nosotros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GzMMHXJqkI-"
      },
      "source": [
        "Vamos a crear un tipado para el perfil de usuario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "TUlqiVTvqkI-"
      },
      "outputs": [],
      "source": [
        "from typing import TypedDict, List\n",
        "\n",
        "class UserProfile(TypedDict):\n",
        "    \"\"\"User profile schema with typed fields\"\"\"\n",
        "    user_name: str  # The user's preferred name\n",
        "    interests: List[str]  # A list of the user's interests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWf3VK3XqkI-"
      },
      "source": [
        "Ahora volvemos a crear el grafo, pero ahora con el tipado `UserProfile`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h77y-9rIqkI-"
      },
      "source": [
        "Vamos a usar `with_structured_output` para que el LLM genere una salida con una estructura definida por nosotros, esa estructura la vamos a definir con la clase `Subjects` que es una clase de tipo `BaseModel` de `Pydantic`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "gd1QFv0kqkI-",
        "outputId": "a39eec55-e829-4ad8-e4f4-f0fa5aec57b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph, MessagesState, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
        "from langgraph.checkpoint.memory import MemorySaver # Short-term memory\n",
        "from langgraph.store.base import BaseStore          # Long-term memory\n",
        "from langchain_core.runnables.config import RunnableConfig\n",
        "from langgraph.store.memory import InMemoryStore\n",
        "from IPython.display import Image, display\n",
        "from pydantic import BaseModel, Field\n",
        "import os\n",
        "import dotenv\n",
        "\n",
        "dotenv.load_dotenv()\n",
        "ANTHROPIC_TOKEN = os.getenv(\"ANTHROPIC_LANGGRAPH_API_KEY\")\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"    # Disable LangSmith tracing\n",
        "\n",
        "# Create the LLM model\n",
        "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20241022\", api_key=ANTHROPIC_TOKEN)\n",
        "llm_with_structured_output = llm.with_structured_output(UserProfile)\n",
        "\n",
        "# Chatbot instruction\n",
        "MODEL_SYSTEM_MESSAGE = \"\"\"You are a helpful assistant with memory that provides information about the user.\n",
        "If you have memory for this user, use it to personalize your responses.\n",
        "Here is the memory (it may be empty): {memory}\"\"\"\n",
        "\n",
        "# Create new memory from the chat history and any existing memory\n",
        "CREATE_MEMORY_INSTRUCTION = \"\"\"Create or update a user profile memory based on the user's chat history.\n",
        "This will be saved for long-term memory. If there is an existing memory, simply update it.\n",
        "Here is the existing memory (it may be empty): {memory}\"\"\"\n",
        "\n",
        "# Nodes\n",
        "def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
        "\n",
        "    \"\"\"Load memory from the store and use it to personalize the chatbot's response.\"\"\"\n",
        "\n",
        "    # Get the user ID from the config\n",
        "    user_id = config[\"configurable\"][\"user_id\"]\n",
        "\n",
        "    # Retrieve memory from the store\n",
        "    namespace = (\"memory\", user_id)\n",
        "    existing_memory = store.get(namespace, \"user_memory\")\n",
        "\n",
        "    # Format the memories for the system prompt\n",
        "    if existing_memory and existing_memory.value:\n",
        "        memory_dict = existing_memory.value\n",
        "        formatted_memory = (\n",
        "            f\"Name: {memory_dict.get('user_name', 'Unknown')}\\n\"\n",
        "            f\"Interests: {', '.join(memory_dict.get('interests', []))}\"\n",
        "        )\n",
        "    else:\n",
        "        formatted_memory = None\n",
        "    # if isinstance(existing_memory_content, str):\n",
        "    print(f\"\\t[Call model debug] Existing memory: {formatted_memory}\")\n",
        "    # else:\n",
        "    #     print(f\"\\t[Call model debug] Existing memory: {existing_memory_content.content}\")\n",
        "\n",
        "    # Format the memory in the system prompt\n",
        "    system_msg = MODEL_SYSTEM_MESSAGE.format(memory=formatted_memory)\n",
        "\n",
        "    # Respond using memory as well as the chat history\n",
        "    response = llm.invoke([SystemMessage(content=system_msg)]+state[\"messages\"])\n",
        "\n",
        "    return {\"messages\": response}\n",
        "\n",
        "def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
        "\n",
        "    \"\"\"Reflect on the chat history and save a memory to the store.\"\"\"\n",
        "\n",
        "    # Get the user ID from the config\n",
        "    user_id = config[\"configurable\"][\"user_id\"]\n",
        "\n",
        "    # Retrieve existing memory from the store\n",
        "    namespace = (\"memory\", user_id)\n",
        "    existing_memory = store.get(namespace, \"user_memory\")\n",
        "\n",
        "    # Format the memories for the system prompt\n",
        "    if existing_memory and existing_memory.value:\n",
        "        memory_dict = existing_memory.value\n",
        "        formatted_memory = (\n",
        "            f\"Name: {memory_dict.get('user_name', 'Unknown')}\\n\"\n",
        "            f\"Interests: {', '.join(memory_dict.get('interests', []))}\"\n",
        "        )\n",
        "    else:\n",
        "        formatted_memory = None\n",
        "    print(f\"\\t[Write memory debug] Existing memory: {formatted_memory}\")\n",
        "\n",
        "    # Format the existing memory in the instruction\n",
        "    system_msg = CREATE_MEMORY_INSTRUCTION.format(memory=formatted_memory)\n",
        "\n",
        "    # Invoke the model to produce structured output that matches the schema\n",
        "    new_memory = llm_with_structured_output.invoke([SystemMessage(content=system_msg)]+state['messages'])\n",
        "    print(f\"\\t[Write memory debug] New memory: {new_memory}\")\n",
        "\n",
        "    # Overwrite the existing use profile memory\n",
        "    key = \"user_memory\"\n",
        "    store.put(namespace, key, new_memory)\n",
        "\n",
        "# Create graph builder\n",
        "graph_builder = StateGraph(MessagesState)\n",
        "\n",
        "# Add nodes\n",
        "graph_builder.add_node(\"call_model\", call_model)\n",
        "graph_builder.add_node(\"write_memory\", write_memory)\n",
        "\n",
        "# Connect nodes\n",
        "graph_builder.add_edge(START, \"call_model\")\n",
        "graph_builder.add_edge(\"call_model\", \"write_memory\")\n",
        "graph_builder.add_edge(\"write_memory\", END)\n",
        "\n",
        "# Store for long-term (across-thread) memory\n",
        "long_term_memory = InMemoryStore()\n",
        "\n",
        "# Checkpointer for short-term (within-thread) memory\n",
        "short_term_memory = MemorySaver()\n",
        "\n",
        "# Compile the graph\n",
        "graph = graph_builder.compile(checkpointer=short_term_memory, store=long_term_memory)\n",
        "\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlNO8WWZqkI-"
      },
      "source": [
        "Ejecutamos el grafo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "bJETEIHrqkI-",
        "outputId": "750fcfcf-236c-4655-9be0-3efcae3aa94b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Hi, my name is Maximo and I like to bike around Madrid and eat salads.\n",
            "\t[Call model debug] Existing memory: None\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Hello Maximo! It's nice to meet you. I don't have any previous memory of our interactions, but I'll remember that you enjoy biking around Madrid and eating salads. Those are great healthy habits! Madrid is a wonderful city for cycling, with its bike lanes and parks like Retiro and Casa de Campo. Do you have any favorite cycling routes or special salad spots in Madrid that you particularly enjoy?\n",
            "\t[Write memory debug] Existing memory: None\n",
            "\t[Write memory debug] New memory: {'user_name': 'Maximo', 'interests': ['cycling', 'biking', 'healthy eating', 'salads', 'Madrid']}\n"
          ]
        }
      ],
      "source": [
        "# We supply a thread ID for short-term (within-thread) memory\n",
        "# We supply a user ID for long-term (across-thread) memory\n",
        "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n",
        "\n",
        "# User input\n",
        "input_messages = [HumanMessage(content=\"Hi, my name is Maximo and I like to bike around Madrid and eat salads.\")]\n",
        "\n",
        "# Run the graph\n",
        "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
        "    chunk[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngQO-ZNbqkI-"
      },
      "source": [
        "Como vemos, el LLM ha generado una salida con la estructura definida por nosotros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oslp4aGCqkI-"
      },
      "source": [
        "Vamos a ver cómo se ha guardado la memoria a largo plazo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "0SpOGx-fqkI-",
        "outputId": "3b4e6eee-1898-4065-f4d0-5f0412fb74d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'user_name': 'Maximo',\n",
              " 'interests': ['cycling', 'biking', 'healthy eating', 'salads', 'Madrid']}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Namespace for the memory to save\n",
        "user_id = \"1\"\n",
        "namespace = (\"memory\", user_id)\n",
        "existing_memory = long_term_memory.get(namespace, \"user_memory\")\n",
        "existing_memory.value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Xom7x-PqkJB"
      },
      "source": [
        "## Human in the loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMCnoEv3qkJB"
      },
      "source": [
        "Aunque un agente puede realizar tareas, para según qué tareas, es necesario que haya una supervisión humana. A esto se le llama `human in the loop`. Así que vamos a ver cómo se puede hacer esto con `LangGraph`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzbzoekSqkJB"
      },
      "source": [
        "La capa de [persistencia](https://langchain-ai.github.io/langgraph/concepts/persistence/) de `LangGraph` admite flujos de trabajo con humanos en el bucle, lo que permite que la ejecución se detenga y reanude en función de los comentarios de los usuarios. La interfaz principal de esta funcionalidad es la función [interrupt](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/#interrupt). Llamando a `interrupt` dentro de un nodo se detendrá la ejecución. La ejecución se puede reanudar, junto con la nueva aportación del humano, pasada en una primitiva [Command](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/#the-command-primitive). `interrupt` es similar al comando de Python `input()`, pero con algunas consideraciones extra."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3f6SWc2qkJB"
      },
      "source": [
        "Vamos a añadir al chatbot que tiene memoria a corto plazo y acceso a tools, pero haremos un cambio, que es agregar una simple herramienta `human_assistance`. Esta herramienta utiliza `interrupt` para recibir información de un humano."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMM_kj3gqkJC"
      },
      "source": [
        "Primero cargamos los valores de las API KEYs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wLv5TJBEqkJC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import dotenv\n",
        "\n",
        "dotenv.load_dotenv()\n",
        "\n",
        "ANTHROPIC_TOKEN = os.getenv(\"ANTHROPIC_LANGGRAPH_API_KEY\")\n",
        "TAVILY_API_KEY = os.getenv(\"TAVILY_LANGGRAPH_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dq7hLUQgqkJC"
      },
      "source": [
        "Creamos el grafo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "th69JG8tqkJC"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "graph_builder = StateGraph(State)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFHWY-u9qkJC"
      },
      "source": [
        "Definimos la `tool` de búsqueda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EbfYpv9vqkJC",
        "outputId": "72a188ca-04eb-44ec-a112-8de768a2bba0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-2955814646>:5: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
            "  search_tool = TavilySearchResults(api_wrapper=wrapper, max_results=2)\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "wrapper = TavilySearchAPIWrapper(tavily_api_key=TAVILY_API_KEY)\n",
        "search_tool = TavilySearchResults(api_wrapper=wrapper, max_results=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8DSplJDqkJC"
      },
      "source": [
        "Ahora creamos la `tool` de ayuda humana"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DkwgJjk_qkJC"
      },
      "outputs": [],
      "source": [
        "from langgraph.types import Command, interrupt\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def human_assistance(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Request assistance from a human expert. Use this tool ONLY ONCE per conversation.\n",
        "    After receiving the expert's response, you should provide an elaborated response to the user based on the information received\n",
        "    based on the information received, without calling this tool again.\n",
        "\n",
        "    Args:\n",
        "        query: The query to ask the human expert.\n",
        "\n",
        "    Returns:\n",
        "        The response from the human expert.\n",
        "    \"\"\"\n",
        "    human_response = interrupt({\"query\": query})\n",
        "    return human_response[\"data\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUT9md3AqkJC"
      },
      "source": [
        "`LangGraph` obtiene información de las herramientas mediante la documentación de la herramienta, es decir, el `docstring` de la función. Por lo que es muy importante generar un buen `docstring` para la herramienta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bo8PuxdcqkJC"
      },
      "source": [
        "Creamos una lista de `tools`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4c3QoGqOqkJC"
      },
      "outputs": [],
      "source": [
        "tools_list = [search_tool, human_assistance]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbhWshYMqkJD"
      },
      "source": [
        "A continuación, el `LLM` con las `bind_tools` y lo añadimos al grafo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "htcaHoTVqkJD",
        "outputId": "427f4870-c5cf-4e56-e9d5-7d014be16d10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7c34b74df1d0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from langchain_anthropic import ChatAnthropic\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"    # Disable LangSmith tracing\n",
        "\n",
        "# Create the LLM\n",
        "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20241022\", api_key=ANTHROPIC_TOKEN)\n",
        "\n",
        "# Modification: tell the LLM which tools it can call\n",
        "llm_with_tools = llm.bind_tools(tools_list)\n",
        "\n",
        "# Define the chatbot function\n",
        "def chatbot_function(state: State):\n",
        "    message = llm_with_tools.invoke(state[\"messages\"])\n",
        "    assert len(message.tool_calls) <= 1\n",
        "    return {\"messages\": [message]}\n",
        "\n",
        "# Add the chatbot node\n",
        "graph_builder.add_node(\"chatbot_node\", chatbot_function)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBgdgcxWqkJD"
      },
      "source": [
        "Si te fijas, hemos cambiado la forma de definir la función `chatbot_function`, ya que ahora tiene que manejar la interrupción."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig1E2cc3qkJD"
      },
      "source": [
        "Añadimos la `tool_node` al grafo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ehd51IJRqkJD",
        "outputId": "4b509150-0165-4058-ecae-c31db802482c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7c34b74df1d0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "\n",
        "tool_node = ToolNode(tools=tools_list)\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "graph_builder.add_conditional_edges(\"chatbot_node\", tools_condition)\n",
        "graph_builder.add_edge(\"tools\", \"chatbot_node\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac2xmgBrqkJD"
      },
      "source": [
        "Añadimos el nodo de `START` al grafo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RQCzPaAFqkJD",
        "outputId": "45ccfbc9-f4c0-4435-a7d6-f278f77996b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7c34b74df1d0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "graph_builder.add_edge(START, \"chatbot_node\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnR1KbJdqkJD"
      },
      "source": [
        "Creamos un `checkpointer` [MemorySaver](https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.memory.MemorySaver)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nhFGC3TCqkJD"
      },
      "outputs": [],
      "source": [
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "memory = MemorySaver()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32W9SY8HqkJD"
      },
      "source": [
        "Compilamos el grafo con el `checkpointer`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "F9_t5MWjqkJD"
      },
      "outputs": [],
      "source": [
        "graph = graph_builder.compile(checkpointer=memory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8636rf_qkJD"
      },
      "source": [
        "Lo representamos gráficamente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YB8B7dhtqkJD",
        "outputId": "ebe9cce9-5641-49c9-f403-1e6857c77e15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception as e:\n",
        "    print(f\"Error al visualizar el grafo: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8w4ACL1qkJD"
      },
      "source": [
        "Ahora solicitemos al chatbot con una pregunta que involucrará a la nueva herramienta `human_assistance`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "BAvTkeu7qkJD",
        "outputId": "132002d1-75ac-469e-a29e-7f901ead1b18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "I need some expert guidance for building an AI agent. Could you request assistance for me?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "[{'text': \"I'll help you get expert guidance on building an AI agent. I'll use the human assistance tool to get specialized advice on this topic.\", 'type': 'text'}, {'id': 'toolu_01HVn3hPNeZ4BYPavxbtNoK1', 'input': {'query': 'Could you provide guidance and best practices for building an AI agent? Please include key considerations for design, implementation, and potential challenges to be aware of.'}, 'name': 'human_assistance', 'type': 'tool_use'}]\n",
            "Tool Calls:\n",
            "  human_assistance (toolu_01HVn3hPNeZ4BYPavxbtNoK1)\n",
            " Call ID: toolu_01HVn3hPNeZ4BYPavxbtNoK1\n",
            "  Args:\n",
            "    query: Could you provide guidance and best practices for building an AI agent? Please include key considerations for design, implementation, and potential challenges to be aware of.\n"
          ]
        }
      ],
      "source": [
        "user_input = \"I need some expert guidance for building an AI agent. Could you request assistance for me?\"\n",
        "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "\n",
        "events = graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
        "    config,\n",
        "    stream_mode=\"values\",\n",
        ")\n",
        "for event in events:\n",
        "    if \"messages\" in event:\n",
        "        event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGLlESHAqkJD"
      },
      "source": [
        "Como se puede ver, el chatbot generó una llamada a la herramienta de asistencia humana.\n",
        "\n",
        "``` markdown\n",
        "Tool Calls:\n",
        "  human_assistance (0)\n",
        " Call ID: 0\n",
        "  Args:\n",
        "    query: I need some expert guidance for building an AI agent. Could you provide advice on key considerations, best practices, and potential pitfalls to avoid?\n",
        "```\n",
        "\n",
        "Pero luego la ejecución se ha interrumpido. Vamos a ver el estado del grafo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "rB6WftmcqkJD",
        "outputId": "b0a59f6a-9ef7-43af-9384-29651ee48e42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('tools',)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "snapshot = graph.get_state(config)\n",
        "snapshot.next"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVd4x7fiqkJD"
      },
      "source": [
        "Vemos que se detuvo en el nodo de `tools`. Analizamos cómo se ha definido la herramienta `human_assistance`.\n",
        "\n",
        "``` python\n",
        "from langgraph.types import Command, interrupt\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def human_assistance(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Request assistance from a human expert. Use this tool ONLY ONCE per conversation.\n",
        "    After receiving the expert's response, you should provide an elaborated response to the user based on the information received\n",
        "    based on the information received, without calling this tool again.\n",
        "\n",
        "    Args:\n",
        "        query: The query to ask the human expert.\n",
        "\n",
        "    Returns:\n",
        "        The response from the human expert.\n",
        "    \"\"\"\n",
        "    human_response = interrupt({\"query\": query})\n",
        "    return human_response[\"data\"]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ku_XZuSqkJD"
      },
      "source": [
        "Llamando a la herramienta `interrupt` se detendrá la ejecución, similar a la función de Python `input()`.\n",
        "\n",
        "El progreso se mantiene en función de nuestra elección de [checkpointer](https://langchain-ai.github.io/langgraph/concepts/persistence/#checkpointer-libraries). Es decir, la elección de dónde se guarda el estado del grafo. Así que si estamos persistiendo (guardando el estado del grafo) con una base de datos como `SQLite`, `Postgres`, etc, podemos reanudar la ejecución en cualquier momento siempre y cuando la base de datos esté viva.\n",
        "\n",
        "Aquí estamos persistiendo (guardando el estado del grafo) con el puntero de verificación en memoria RAM, por lo que podemos reanudar en cualquier momento mientras nuestro kernel de Python se esté ejecutando. En mi caso, mientras no resetee el kernel de mi Jupyter Notebook.\n",
        "\n",
        "Para reanudar la ejecución, pasamos un objeto [Command](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/#the-command-primitive) que contiene los datos esperados por la herramienta. El formato de estos datos se puede personalizar en función de nuestras necesidades. Aquí, solo necesitamos un diccionario con una key `data`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "IRqwFBM9qkJD",
        "outputId": "563f1461-5e59-4e57-9537-9098d8215861",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "[{'text': \"I'll help you get expert guidance on building an AI agent. I'll use the human assistance tool to get specialized advice on this topic.\", 'type': 'text'}, {'id': 'toolu_01HVn3hPNeZ4BYPavxbtNoK1', 'input': {'query': 'Could you provide guidance and best practices for building an AI agent? Please include key considerations for design, implementation, and potential challenges to be aware of.'}, 'name': 'human_assistance', 'type': 'tool_use'}]\n",
            "Tool Calls:\n",
            "  human_assistance (toolu_01HVn3hPNeZ4BYPavxbtNoK1)\n",
            " Call ID: toolu_01HVn3hPNeZ4BYPavxbtNoK1\n",
            "  Args:\n",
            "    query: Could you provide guidance and best practices for building an AI agent? Please include key considerations for design, implementation, and potential challenges to be aware of.\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: human_assistance\n",
            "\n",
            "We, the experts are here to help! We'd recommend you check out LangGraph to build your agent.It's much more reliable and extensible than simple autonomous agents.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Based on the expert's response, I can elaborate on this guidance for building an AI agent:\n",
            "\n",
            "The expert recommends using LangGraph as a framework for building your AI agent. This is a notable recommendation because:\n",
            "\n",
            "1. Reliability: LangGraph is highlighted as being more reliable than simple autonomous agents, which is crucial for building robust AI systems.\n",
            "\n",
            "2. Extensibility: The framework offers better extensibility, meaning you can more easily:\n",
            "   - Add new features and capabilities\n",
            "   - Scale your agent as needed\n",
            "   - Modify functionality without major restructuring\n",
            "\n",
            "This recommendation aligns with current best practices in AI agent development, where using established frameworks can help avoid common pitfalls and provide a more structured development approach.\n",
            "\n",
            "Would you like to know more specific details about LangGraph or would you prefer guidance on particular aspects of AI agent development?\n"
          ]
        }
      ],
      "source": [
        "human_response = (\n",
        "    \"We, the experts are here to help! We'd recommend you check out LangGraph to build your agent.\"\n",
        "    \"It's much more reliable and extensible than simple autonomous agents.\"\n",
        ")\n",
        "\n",
        "human_command = Command(resume={\"data\": human_response})\n",
        "\n",
        "events = graph.stream(human_command, config, stream_mode=\"values\")\n",
        "for event in events:\n",
        "    if \"messages\" in event:\n",
        "        event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_s4Lz3dLqkJD"
      },
      "source": [
        "Como vemos, el chatbot ha esperado a que un humano le proporcione la respuesta y luego ha generado una respuesta basada en la información recibida. Le hemos pedido por la ayuda sobre un experto sobre cómo crear agentes, el humano le ha dicho que lo mejor es usar LangGraph, y el chatbot ha generado una respuesta basada en esa información."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2OmtAGdqkJE"
      },
      "source": [
        "Pero sigue teniendo la posibilidad de realizar búsquedas en la web. Así que ahora le vamos a pedir las últimas noticias sobre LangGraph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "58AwPemZqkJE",
        "outputId": "dfae37e6-08bd-4bc9-dde3-51cd58598471",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "What's the latest news about LangGraph?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "[{'text': \"I'll search for the most recent information about LangGraph.\", 'type': 'text'}, {'id': 'toolu_01L3ehSc2pmig3C9Uqrt2KNq', 'input': {'query': 'LangGraph latest news developments updates 2024'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (toolu_01L3ehSc2pmig3C9Uqrt2KNq)\n",
            " Call ID: toolu_01L3ehSc2pmig3C9Uqrt2KNq\n",
            "  Args:\n",
            "    query: LangGraph latest news developments updates 2024\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search_results_json\n",
            "\n",
            "[{\"title\": \"December 2024 - LangChain - Changelog\", \"url\": \"https://changelog.langchain.com/?categories=cat_5UBL6DD8PcXXL&date=2024-12-01\", \"content\": \"December 2024. LangGraph. Modify graph state from tools in LangGraph. LangGraph's latest update gives you greater control over your agents by enabling tools\", \"score\": 0.8571119}, {\"title\": \"October 2024 - LangChain - Changelog\", \"url\": \"https://changelog.langchain.com/?date=2024-11-01&page=2\", \"content\": \"LangChain Changelog ; LangGraph is now compatible with Python 3.13 · October 11, 2024 ; LangGraph long-term memory support · October 8, 2024.\", \"score\": 0.83225065}]\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "[{'text': 'Let me search for more detailed information about these recent developments.', 'type': 'text'}, {'id': 'toolu_01DBK8M131EHyP6ifiywpA1N', 'input': {'query': 'LangGraph features memory support tools updates technical details'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (toolu_01DBK8M131EHyP6ifiywpA1N)\n",
            " Call ID: toolu_01DBK8M131EHyP6ifiywpA1N\n",
            "  Args:\n",
            "    query: LangGraph features memory support tools updates technical details\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search_results_json\n",
            "\n",
            "[{\"title\": \"Building Agentic Systems with LangGraph: A Technical Deep Dive\", \"url\": \"https://www.linkedin.com/pulse/building-agentic-systems-langgraph-technical-deep-dive-mm2oe\", \"content\": \"Maintaining context over long interactions is crucial for creating responsive and intelligent agents. LangGraph supports both short-term and long-term memory to achieve this.\\n\\nShort-term memory retains transient conversation context, keeping track of the current interaction within the graph’s state. For deeper persistence, long-term memory integrations—such as with Zep—store key facts and user details, allowing the agent to recall information across multiple sessions. [...] LangGraph empowers developers to build agentic AI systems that are dynamic, stateful, and robust. By leveraging a graph-based architecture, integrating external tools, and managing memory effectively, you can design applications where LLMs drive the workflow—making decisions, retrieving information, and even involving human oversight when needed. [...] Next, map out your workflow as a graph, identifying nodes that handle different tasks. Input retrieval nodes process user queries, ensuring they are correctly captured. LLM processing nodes generate responses or determine the next steps based on the context. Tool execution nodes handle external API calls, such as web searches or vector retrieval, to enhance responses with real-time or stored data. Finally, memory update nodes persist key details, maintaining continuity across interactions.\", \"score\": 0.6599319}, {\"title\": \"Launching Long-Term Memory Support in LangGraph\", \"url\": \"https://blog.langchain.dev/launching-long-term-memory-support-in-langgraph/\", \"content\": \"This feature is part of the OSS library, and it is enabled by default for all LangGraph Cloud & Studio users. [...] Today, we are excited to announce the first steps towards long-term memory support in LangGraph, available both in [Python](https://langchain-ai.github.io/langgraph/how-tos/cross-thread-persistence/?ref=blog.langchain.dev) and [JavaScript](https://langchain-ai.github.io/langgraphjs/how-tos/cross-thread-persistence/?ref=blog.langchain.dev). Long-term memory lets you store and recall information between conversations so your agent can **learn from feedback** and adapt to **user preferences**. [...] ![LangChain Blog](https://blog.langchain.dev/content/images/2024/03/LangChain-logo.png)\\n![Launching Long-Term Memory Support in LangGraph](/content/images/size/w760/format/webp/2024/10/Long-term-memory-blog-post--3-.png)\\n\\n# Launching Long-Term Memory Support in LangGraph\", \"score\": 0.6194488}]\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Based on the recent searches, here are the latest significant developments with LangGraph:\n",
            "\n",
            "1. Latest Updates (December 2024):\n",
            "- New feature allowing modification of graph state from tools in LangGraph\n",
            "- Enhanced control over agents through improved tool integration\n",
            "\n",
            "2. Recent Technical Improvements:\n",
            "- Python 3.13 compatibility (announced October 11, 2024)\n",
            "- Introduction of long-term memory support (October 8, 2024)\n",
            "\n",
            "3. Key Features of the Long-Term Memory Support:\n",
            "- Enables storage and recall of information between conversations\n",
            "- Allows agents to learn from feedback and adapt to user preferences\n",
            "- Available in both Python and JavaScript implementations\n",
            "- Included by default for all LangGraph Cloud & Studio users\n",
            "\n",
            "4. Architecture and Functionality:\n",
            "- Supports both short-term and long-term memory systems\n",
            "   - Short-term memory: handles transient conversation context\n",
            "   - Long-term memory: stores key facts and user details across sessions\n",
            "- Features a graph-based architecture with specialized nodes for:\n",
            "   - Input retrieval\n",
            "   - LLM processing\n",
            "   - Tool execution\n",
            "   - Memory updates\n",
            "\n",
            "These updates demonstrate LangGraph's continued evolution as a robust framework for building AI agents, with particular emphasis on improving memory capabilities and tool integration. The platform is actively maintained and regularly updated with new features to enhance agent development capabilities.\n"
          ]
        }
      ],
      "source": [
        "user_input = \"What's the latest news about LangGraph?\"\n",
        "\n",
        "events = graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
        "    config,\n",
        "    stream_mode=\"values\",\n",
        ")\n",
        "for event in events:\n",
        "    if \"messages\" in event:\n",
        "        event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmcw97OgqkJE"
      },
      "source": [
        "Ha buscado las últimas noticias sobre LangGraph y ha generado una respuesta basada en la información recibida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCfplSNnqkJE"
      },
      "source": [
        "Vamos a escribir todo junto para que sea más comprensible"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_CD60Z1PqkJE",
        "outputId": "f9b9b4b8-89cb-4877-eaee-a02653f844b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
        "from huggingface_hub import login\n",
        "\n",
        "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "from langchain_core.messages import ToolMessage\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "\n",
        "from langgraph.types import Command, interrupt\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "from IPython.display import Image, display\n",
        "import json\n",
        "\n",
        "import os\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"    # Disable LangSmith tracing\n",
        "\n",
        "import dotenv\n",
        "dotenv.load_dotenv()\n",
        "HUGGINGFACE_TOKEN = os.getenv(\"HUGGINGFACE_LANGGRAPH\")\n",
        "TAVILY_API_KEY = os.getenv(\"TAVILY_LANGGRAPH_API_KEY\")\n",
        "\n",
        "# State\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "# Tools\n",
        "wrapper = TavilySearchAPIWrapper(tavily_api_key=TAVILY_API_KEY)\n",
        "tool_search = TavilySearchResults(api_wrapper=wrapper, max_results=2)\n",
        "\n",
        "@tool\n",
        "def human_assistance(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Request assistance from a human expert. Use this tool ONLY ONCE per conversation.\n",
        "    After receiving the expert's response, you should provide an elaborated response to the user based on the information received\n",
        "    based on the information received, without calling this tool again.\n",
        "\n",
        "    Args:\n",
        "        query: The query to ask the human expert.\n",
        "\n",
        "    Returns:\n",
        "        The response from the human expert.\n",
        "    \"\"\"\n",
        "    human_response = interrupt({\"query\": query})\n",
        "    return human_response[\"data\"]\n",
        "\n",
        "tools_list = [tool_search, human_assistance]\n",
        "\n",
        "# Create the LLM model\n",
        "login(token=HUGGINGFACE_TOKEN)  # Login to HuggingFace to use the model\n",
        "MODEL = \"Qwen/Qwen2.5-72B-Instruct\"\n",
        "model = HuggingFaceEndpoint(\n",
        "    repo_id=MODEL,\n",
        "    task=\"text-generation\",\n",
        "    max_new_tokens=512,\n",
        "    do_sample=False,\n",
        "    repetition_penalty=1.03,\n",
        ")\n",
        "# Create the chat model\n",
        "llm = ChatHuggingFace(llm=model)\n",
        "# Create the LLM with tools\n",
        "llm_with_tools = llm.bind_tools(tools_list)\n",
        "\n",
        "# Tool node\n",
        "tool_node = ToolNode(tools=tools_list)\n",
        "\n",
        "# Functions\n",
        "def chatbot_function(state: State):\n",
        "    message = llm_with_tools.invoke(state[\"messages\"])\n",
        "    assert len(message.tool_calls) <= 1\n",
        "    return {\"messages\": [message]}\n",
        "\n",
        "# Start to build the graph\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "# Add nodes to the graph\n",
        "graph_builder.add_node(\"chatbot_node\", chatbot_function)\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "\n",
        "# Add edges\n",
        "graph_builder.add_edge(START, \"chatbot_node\")\n",
        "graph_builder.add_conditional_edges( \"chatbot_node\", tools_condition)\n",
        "graph_builder.add_edge(\"tools\", \"chatbot_node\")\n",
        "\n",
        "# Compile the graph\n",
        "memory = MemorySaver()\n",
        "graph = graph_builder.compile(checkpointer=memory)\n",
        "\n",
        "# Display the graph\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception as e:\n",
        "    print(f\"Error al visualizar el grafo: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53fWlUYcqkJE"
      },
      "source": [
        "Volvemos a pedirle ayuda al chatbot para crear agentes. Le pedimos que busque ayuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ummM8AMBqkJE",
        "outputId": "4ced9a2a-81bd-40b6-d1a0-8496ea001f2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "I need some expert guidance for building an AI agent. Could you request assistance for me?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  human_assistance (0)\n",
            " Call ID: 0\n",
            "  Args:\n",
            "    query: I need expert guidance for building an AI agent.\n"
          ]
        }
      ],
      "source": [
        "user_input = \"I need some expert guidance for building an AI agent. Could you request assistance for me?\"\n",
        "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "\n",
        "events = graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
        "    config,\n",
        "    stream_mode=\"values\",\n",
        ")\n",
        "for event in events:\n",
        "    if \"messages\" in event:\n",
        "        event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MO6NDa0-qkJE"
      },
      "source": [
        "Vemos en qué estado se ha quedado el grafo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxswzuQOqkJE",
        "outputId": "6c79f1b5-4124-4b1d-f321-0139c6a7ab81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('tools',)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "snapshot = graph.get_state(config)\n",
        "snapshot.next"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLXRpRaBqkJE"
      },
      "source": [
        "Le damos la asistencia que está pidiendo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0SUxJrOqkJE",
        "outputId": "8062da96-573a-4073-970c-f461d943e3dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  human_assistance (0)\n",
            " Call ID: 0\n",
            "  Args:\n",
            "    query: I need expert guidance for building an AI agent.\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: human_assistance\n",
            "\n",
            "We, the experts are here to help! We'd recommend you check out LangGraph to build your agent.It's much more reliable and extensible than simple autonomous agents.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  human_assistance (0)\n",
            " Call ID: 0\n",
            "  Args:\n",
            "    query: I need some expert guidance for building an AI agent. Could you recommend a platform and any tips for getting started?\n"
          ]
        }
      ],
      "source": [
        "human_response = (\n",
        "    \"We, the experts are here to help! We'd recommend you check out LangGraph to build your agent.\"\n",
        "    \"It's much more reliable and extensible than simple autonomous agents.\"\n",
        ")\n",
        "\n",
        "human_command = Command(resume={\"data\": human_response})\n",
        "\n",
        "events = graph.stream(human_command, config, stream_mode=\"values\")\n",
        "for event in events:\n",
        "    if \"messages\" in event:\n",
        "        event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oemqUPsWqkJE"
      },
      "source": [
        "Y por último le pedimos que busque en internet las últimas noticias de LangGraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGP1ssEQqkJE",
        "outputId": "2e30a2e0-8d76-4126-9523-0fe8a2946174"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "What's the latest news about LangGraph?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (0)\n",
            " Call ID: 0\n",
            "  Args:\n",
            "    query: latest news about LangGraph\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search_results_json\n",
            "\n",
            "[{\"title\": \"LangChain Blog\", \"url\": \"https://blog.langchain.dev/\", \"content\": \"LangSmith Incident on May 1, 2025\\n\\nRequests to the US LangSmith API from both the web application and SDKs experienced an elevated error rate for 28 minutes on May 1, 2025\\n\\nFeatured\\n\\nHow Klarna's AI assistant redefined customer support at scale for 85 million active users\\n\\nIs LangGraph Used In Production?\\n\\nIntroducing Interrupt: The AI Agent Conference by LangChain\\n\\nTop 5 LangGraph Agents in Production 2024 [...] See how Harmonic uses LangSmith and LangGraph products to streamline venture investing workflows.\\n\\nWhy Definely chose LangGraph for building their multi-agent AI system\\n\\nSee how Definely used LangGraph to design a multi-agent system to help lawyers speed up their workflows.\\n\\nIntroducing End-to-End OpenTelemetry Support in LangSmith\\n\\nLangSmith now provides end-to-end OpenTelemetry (OTel) support for applications built on LangChain and/or LangGraph.\", \"score\": 0.6811549}, {\"title\": \"LangGraph + UiPath: advancing agentic automation together\", \"url\": \"https://www.uipath.com/blog/product-and-updates/langgraph-uipath-advancing-agentic-automation-together\", \"content\": \"Raghu Malpani, Chief Technology Officer at UiPath, emphasizes the significance of these announcements for the UiPath developer community:\\n\\nOur collaboration with LangChain on LangSmith and Agent Protocol advances interoperability across agent frameworks. Further, by enabling the deployment of LangGraph agents into UiPath's enterprise-grade infrastructure, we are expanding the capabilities of our platform and opening up more possibilities for our developer community. [...] Today, we’re excited to announce:\\n\\nNative support for LangSmith observability in the UiPath LLM Gateway via OpenTelemetry (OTLP), enabling developers to monitor, debug, and evaluate LLM-powered features in UiPath using LangSmith either in LangChain’s cloud or self-hosted on-premises. This feature is currently in private preview.\", \"score\": 0.6557114}]\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (0)\n",
            " Call ID: 0\n",
            "  Args:\n",
            "    query: latest news about LangGraph\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search_results_json\n",
            "\n",
            "[{\"title\": \"LangChain Blog\", \"url\": \"https://blog.langchain.dev/\", \"content\": \"LangSmith Incident on May 1, 2025\\n\\nRequests to the US LangSmith API from both the web application and SDKs experienced an elevated error rate for 28 minutes on May 1, 2025\\n\\nFeatured\\n\\nHow Klarna's AI assistant redefined customer support at scale for 85 million active users\\n\\nIs LangGraph Used In Production?\\n\\nIntroducing Interrupt: The AI Agent Conference by LangChain\\n\\nTop 5 LangGraph Agents in Production 2024 [...] See how Harmonic uses LangSmith and LangGraph products to streamline venture investing workflows.\\n\\nWhy Definely chose LangGraph for building their multi-agent AI system\\n\\nSee how Definely used LangGraph to design a multi-agent system to help lawyers speed up their workflows.\\n\\nIntroducing End-to-End OpenTelemetry Support in LangSmith\\n\\nLangSmith now provides end-to-end OpenTelemetry (OTel) support for applications built on LangChain and/or LangGraph.\", \"score\": 0.6811549}, {\"title\": \"LangGraph + UiPath: advancing agentic automation together\", \"url\": \"https://www.uipath.com/blog/product-and-updates/langgraph-uipath-advancing-agentic-automation-together\", \"content\": \"Raghu Malpani, Chief Technology Officer at UiPath, emphasizes the significance of these announcements for the UiPath developer community:\\n\\nOur collaboration with LangChain on LangSmith and Agent Protocol advances interoperability across agent frameworks. Further, by enabling the deployment of LangGraph agents into UiPath's enterprise-grade infrastructure, we are expanding the capabilities of our platform and opening up more possibilities for our developer community. [...] Today, we’re excited to announce:\\n\\nNative support for LangSmith observability in the UiPath LLM Gateway via OpenTelemetry (OTLP), enabling developers to monitor, debug, and evaluate LLM-powered features in UiPath using LangSmith either in LangChain’s cloud or self-hosted on-premises. This feature is currently in private preview.\", \"score\": 0.6557114}]\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (0)\n",
            " Call ID: 0\n",
            "  Args:\n",
            "    query: latest news about LangGraph\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search_results_json\n",
            "\n",
            "[{\"title\": \"LangChain Blog\", \"url\": \"https://blog.langchain.dev/\", \"content\": \"LangSmith Incident on May 1, 2025\\n\\nRequests to the US LangSmith API from both the web application and SDKs experienced an elevated error rate for 28 minutes on May 1, 2025\\n\\nFeatured\\n\\nHow Klarna's AI assistant redefined customer support at scale for 85 million active users\\n\\nIs LangGraph Used In Production?\\n\\nIntroducing Interrupt: The AI Agent Conference by LangChain\\n\\nTop 5 LangGraph Agents in Production 2024 [...] See how Harmonic uses LangSmith and LangGraph products to streamline venture investing workflows.\\n\\nWhy Definely chose LangGraph for building their multi-agent AI system\\n\\nSee how Definely used LangGraph to design a multi-agent system to help lawyers speed up their workflows.\\n\\nIntroducing End-to-End OpenTelemetry Support in LangSmith\\n\\nLangSmith now provides end-to-end OpenTelemetry (OTel) support for applications built on LangChain and/or LangGraph.\", \"score\": 0.6811549}, {\"title\": \"LangGraph + UiPath: advancing agentic automation together\", \"url\": \"https://www.uipath.com/blog/product-and-updates/langgraph-uipath-advancing-agentic-automation-together\", \"content\": \"Raghu Malpani, Chief Technology Officer at UiPath, emphasizes the significance of these announcements for the UiPath developer community:\\n\\nOur collaboration with LangChain on LangSmith and Agent Protocol advances interoperability across agent frameworks. Further, by enabling the deployment of LangGraph agents into UiPath's enterprise-grade infrastructure, we are expanding the capabilities of our platform and opening up more possibilities for our developer community. [...] Today, we’re excited to announce:\\n\\nNative support for LangSmith observability in the UiPath LLM Gateway via OpenTelemetry (OTLP), enabling developers to monitor, debug, and evaluate LLM-powered features in UiPath using LangSmith either in LangChain’s cloud or self-hosted on-premises. This feature is currently in private preview.\", \"score\": 0.6557114}]\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (0)\n",
            " Call ID: 0\n",
            "  Args:\n",
            "    query: latest news about LangGraph\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search_results_json\n",
            "\n",
            "[{\"title\": \"LangChain Blog\", \"url\": \"https://blog.langchain.dev/\", \"content\": \"LangSmith Incident on May 1, 2025\\n\\nRequests to the US LangSmith API from both the web application and SDKs experienced an elevated error rate for 28 minutes on May 1, 2025\\n\\nFeatured\\n\\nHow Klarna's AI assistant redefined customer support at scale for 85 million active users\\n\\nIs LangGraph Used In Production?\\n\\nIntroducing Interrupt: The AI Agent Conference by LangChain\\n\\nTop 5 LangGraph Agents in Production 2024 [...] See how Harmonic uses LangSmith and LangGraph products to streamline venture investing workflows.\\n\\nWhy Definely chose LangGraph for building their multi-agent AI system\\n\\nSee how Definely used LangGraph to design a multi-agent system to help lawyers speed up their workflows.\\n\\nIntroducing End-to-End OpenTelemetry Support in LangSmith\\n\\nLangSmith now provides end-to-end OpenTelemetry (OTel) support for applications built on LangChain and/or LangGraph.\", \"score\": 0.6811549}, {\"title\": \"LangGraph + UiPath: advancing agentic automation together\", \"url\": \"https://www.uipath.com/blog/product-and-updates/langgraph-uipath-advancing-agentic-automation-together\", \"content\": \"Raghu Malpani, Chief Technology Officer at UiPath, emphasizes the significance of these announcements for the UiPath developer community:\\n\\nOur collaboration with LangChain on LangSmith and Agent Protocol advances interoperability across agent frameworks. Further, by enabling the deployment of LangGraph agents into UiPath's enterprise-grade infrastructure, we are expanding the capabilities of our platform and opening up more possibilities for our developer community. [...] Today, we’re excited to announce:\\n\\nNative support for LangSmith observability in the UiPath LLM Gateway via OpenTelemetry (OTLP), enabling developers to monitor, debug, and evaluate LLM-powered features in UiPath using LangSmith either in LangChain’s cloud or self-hosted on-premises. This feature is currently in private preview.\", \"score\": 0.6557114}]\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (0)\n",
            " Call ID: 0\n",
            "  Args:\n",
            "    query: latest news about LangGraph\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search_results_json\n",
            "\n",
            "[{\"title\": \"LangChain Blog\", \"url\": \"https://blog.langchain.dev/\", \"content\": \"LangSmith Incident on May 1, 2025\\n\\nRequests to the US LangSmith API from both the web application and SDKs experienced an elevated error rate for 28 minutes on May 1, 2025\\n\\nFeatured\\n\\nHow Klarna's AI assistant redefined customer support at scale for 85 million active users\\n\\nIs LangGraph Used In Production?\\n\\nIntroducing Interrupt: The AI Agent Conference by LangChain\\n\\nTop 5 LangGraph Agents in Production 2024 [...] See how Harmonic uses LangSmith and LangGraph products to streamline venture investing workflows.\\n\\nWhy Definely chose LangGraph for building their multi-agent AI system\\n\\nSee how Definely used LangGraph to design a multi-agent system to help lawyers speed up their workflows.\\n\\nIntroducing End-to-End OpenTelemetry Support in LangSmith\\n\\nLangSmith now provides end-to-end OpenTelemetry (OTel) support for applications built on LangChain and/or LangGraph.\", \"score\": 0.6811549}, {\"title\": \"LangGraph + UiPath: advancing agentic automation together\", \"url\": \"https://www.uipath.com/blog/product-and-updates/langgraph-uipath-advancing-agentic-automation-together\", \"content\": \"Raghu Malpani, Chief Technology Officer at UiPath, emphasizes the significance of these announcements for the UiPath developer community:\\n\\nOur collaboration with LangChain on LangSmith and Agent Protocol advances interoperability across agent frameworks. Further, by enabling the deployment of LangGraph agents into UiPath's enterprise-grade infrastructure, we are expanding the capabilities of our platform and opening up more possibilities for our developer community. [...] Today, we’re excited to announce:\\n\\nNative support for LangSmith observability in the UiPath LLM Gateway via OpenTelemetry (OTLP), enabling developers to monitor, debug, and evaluate LLM-powered features in UiPath using LangSmith either in LangChain’s cloud or self-hosted on-premises. This feature is currently in private preview.\", \"score\": 0.6557114}]\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (0)\n",
            " Call ID: 0\n",
            "  Args:\n",
            "    query: latest news about LangGraph\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search_results_json\n",
            "\n",
            "[{\"title\": \"LangChain Blog\", \"url\": \"https://blog.langchain.dev/\", \"content\": \"LangSmith Incident on May 1, 2025\\n\\nRequests to the US LangSmith API from both the web application and SDKs experienced an elevated error rate for 28 minutes on May 1, 2025\\n\\nFeatured\\n\\nHow Klarna's AI assistant redefined customer support at scale for 85 million active users\\n\\nIs LangGraph Used In Production?\\n\\nIntroducing Interrupt: The AI Agent Conference by LangChain\\n\\nTop 5 LangGraph Agents in Production 2024 [...] See how Harmonic uses LangSmith and LangGraph products to streamline venture investing workflows.\\n\\nWhy Definely chose LangGraph for building their multi-agent AI system\\n\\nSee how Definely used LangGraph to design a multi-agent system to help lawyers speed up their workflows.\\n\\nIntroducing End-to-End OpenTelemetry Support in LangSmith\\n\\nLangSmith now provides end-to-end OpenTelemetry (OTel) support for applications built on LangChain and/or LangGraph.\", \"score\": 0.6811549}, {\"title\": \"LangGraph + UiPath: advancing agentic automation together\", \"url\": \"https://www.uipath.com/blog/product-and-updates/langgraph-uipath-advancing-agentic-automation-together\", \"content\": \"Raghu Malpani, Chief Technology Officer at UiPath, emphasizes the significance of these announcements for the UiPath developer community:\\n\\nOur collaboration with LangChain on LangSmith and Agent Protocol advances interoperability across agent frameworks. Further, by enabling the deployment of LangGraph agents into UiPath's enterprise-grade infrastructure, we are expanding the capabilities of our platform and opening up more possibilities for our developer community. [...] Today, we’re excited to announce:\\n\\nNative support for LangSmith observability in the UiPath LLM Gateway via OpenTelemetry (OTLP), enabling developers to monitor, debug, and evaluate LLM-powered features in UiPath using LangSmith either in LangChain’s cloud or self-hosted on-premises. This feature is currently in private preview.\", \"score\": 0.6557114}]\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (0)\n",
            " Call ID: 0\n",
            "  Args:\n",
            "    query: latest news about LangGraph\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search_results_json\n",
            "\n",
            "[{\"title\": \"LangChain Blog\", \"url\": \"https://blog.langchain.dev/\", \"content\": \"LangSmith Incident on May 1, 2025\\n\\nRequests to the US LangSmith API from both the web application and SDKs experienced an elevated error rate for 28 minutes on May 1, 2025\\n\\nFeatured\\n\\nHow Klarna's AI assistant redefined customer support at scale for 85 million active users\\n\\nIs LangGraph Used In Production?\\n\\nIntroducing Interrupt: The AI Agent Conference by LangChain\\n\\nTop 5 LangGraph Agents in Production 2024 [...] See how Harmonic uses LangSmith and LangGraph products to streamline venture investing workflows.\\n\\nWhy Definely chose LangGraph for building their multi-agent AI system\\n\\nSee how Definely used LangGraph to design a multi-agent system to help lawyers speed up their workflows.\\n\\nIntroducing End-to-End OpenTelemetry Support in LangSmith\\n\\nLangSmith now provides end-to-end OpenTelemetry (OTel) support for applications built on LangChain and/or LangGraph.\", \"score\": 0.6811549}, {\"title\": \"LangGraph + UiPath: advancing agentic automation together\", \"url\": \"https://www.uipath.com/blog/product-and-updates/langgraph-uipath-advancing-agentic-automation-together\", \"content\": \"Raghu Malpani, Chief Technology Officer at UiPath, emphasizes the significance of these announcements for the UiPath developer community:\\n\\nOur collaboration with LangChain on LangSmith and Agent Protocol advances interoperability across agent frameworks. Further, by enabling the deployment of LangGraph agents into UiPath's enterprise-grade infrastructure, we are expanding the capabilities of our platform and opening up more possibilities for our developer community. [...] Today, we’re excited to announce:\\n\\nNative support for LangSmith observability in the UiPath LLM Gateway via OpenTelemetry (OTLP), enabling developers to monitor, debug, and evaluate LLM-powered features in UiPath using LangSmith either in LangChain’s cloud or self-hosted on-premises. This feature is currently in private preview.\", \"score\": 0.6557114}]\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (0)\n",
            " Call ID: 0\n",
            "  Args:\n",
            "    query: latest news about LangGraph\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search_results_json\n",
            "\n",
            "[{\"title\": \"LangChain Blog\", \"url\": \"https://blog.langchain.dev/\", \"content\": \"LangSmith Incident on May 1, 2025\\n\\nRequests to the US LangSmith API from both the web application and SDKs experienced an elevated error rate for 28 minutes on May 1, 2025\\n\\nFeatured\\n\\nHow Klarna's AI assistant redefined customer support at scale for 85 million active users\\n\\nIs LangGraph Used In Production?\\n\\nIntroducing Interrupt: The AI Agent Conference by LangChain\\n\\nTop 5 LangGraph Agents in Production 2024 [...] See how Harmonic uses LangSmith and LangGraph products to streamline venture investing workflows.\\n\\nWhy Definely chose LangGraph for building their multi-agent AI system\\n\\nSee how Definely used LangGraph to design a multi-agent system to help lawyers speed up their workflows.\\n\\nIntroducing End-to-End OpenTelemetry Support in LangSmith\\n\\nLangSmith now provides end-to-end OpenTelemetry (OTel) support for applications built on LangChain and/or LangGraph.\", \"score\": 0.6811549}, {\"title\": \"LangGraph + UiPath: advancing agentic automation together\", \"url\": \"https://www.uipath.com/blog/product-and-updates/langgraph-uipath-advancing-agentic-automation-together\", \"content\": \"Raghu Malpani, Chief Technology Officer at UiPath, emphasizes the significance of these announcements for the UiPath developer community:\\n\\nOur collaboration with LangChain on LangSmith and Agent Protocol advances interoperability across agent frameworks. Further, by enabling the deployment of LangGraph agents into UiPath's enterprise-grade infrastructure, we are expanding the capabilities of our platform and opening up more possibilities for our developer community. [...] Today, we’re excited to announce:\\n\\nNative support for LangSmith observability in the UiPath LLM Gateway via OpenTelemetry (OTLP), enabling developers to monitor, debug, and evaluate LLM-powered features in UiPath using LangSmith either in LangChain’s cloud or self-hosted on-premises. This feature is currently in private preview.\", \"score\": 0.6557114}]\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (0)\n",
            " Call ID: 0\n",
            "  Args:\n",
            "    query: Latest news about LangGraph\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search_results_json\n",
            "\n",
            "[{\"title\": \"LangChain Blog\", \"url\": \"https://blog.langchain.dev/\", \"content\": \"LangSmith Incident on May 1, 2025\\n\\nRequests to the US LangSmith API from both the web application and SDKs experienced an elevated error rate for 28 minutes on May 1, 2025\\n\\nFeatured\\n\\nHow Klarna's AI assistant redefined customer support at scale for 85 million active users\\n\\nIs LangGraph Used In Production?\\n\\nIntroducing Interrupt: The AI Agent Conference by LangChain\\n\\nTop 5 LangGraph Agents in Production 2024 [...] See how Harmonic uses LangSmith and LangGraph products to streamline venture investing workflows.\\n\\nWhy Definely chose LangGraph for building their multi-agent AI system\\n\\nSee how Definely used LangGraph to design a multi-agent system to help lawyers speed up their workflows.\\n\\nIntroducing End-to-End OpenTelemetry Support in LangSmith\\n\\nLangSmith now provides end-to-end OpenTelemetry (OTel) support for applications built on LangChain and/or LangGraph.\", \"score\": 0.67758125}, {\"title\": \"LangGraph + UiPath: advancing agentic automation together\", \"url\": \"https://www.uipath.com/blog/product-and-updates/langgraph-uipath-advancing-agentic-automation-together\", \"content\": \"Raghu Malpani, Chief Technology Officer at UiPath, emphasizes the significance of these announcements for the UiPath developer community:\\n\\nOur collaboration with LangChain on LangSmith and Agent Protocol advances interoperability across agent frameworks. Further, by enabling the deployment of LangGraph agents into UiPath's enterprise-grade infrastructure, we are expanding the capabilities of our platform and opening up more possibilities for our developer community. [...] Today, we’re excited to announce:\\n\\nNative support for LangSmith observability in the UiPath LLM Gateway via OpenTelemetry (OTLP), enabling developers to monitor, debug, and evaluate LLM-powered features in UiPath using LangSmith either in LangChain’s cloud or self-hosted on-premises. This feature is currently in private preview.\", \"score\": 0.6522641}]\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (0)\n",
            " Call ID: 0\n",
            "  Args:\n",
            "    query: latest news about LangGraph\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search_results_json\n",
            "\n",
            "[{\"title\": \"LangGraph - LangChain\", \"url\": \"https://www.langchain.com/langgraph\", \"content\": \"“As Ally advances its exploration of Generative AI, our tech labs is excited by LangGraph, the new library from LangChain, which is central to our experiments\", \"score\": 0.98559}, {\"title\": \"Evaluating LangGraph Framework : Series 1 | by Jalaj Agrawal\", \"url\": \"https://medium.com/@jalajagr/evaluating-langgraph-as-a-multiagent-framework-a-10-dimensional-framework-series-1-c7203b7f4659\", \"content\": \": LangGraph excels with its intuitive graph-based abstraction that allows new developers to build working multi-agent systems within hours.\", \"score\": 0.98196}]\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "It looks like LangGraph has been generating some significant buzz in the AI community, especially for its capabilities in building multi-agent systems. Here are a few highlights from the latest news:\n",
            "\n",
            "1. **LangGraph in Production**: Companies like Klarna and Definely are already using LangGraph to build and optimize their AI systems. Klarna has leveraged LangGraph to enhance their customer support, and Definely has used it to design a multi-agent system to speed up legal workflows.\n",
            "\n",
            "2. **Integration with UiPath**: LangChain and UiPath have collaborated to advance agentic automation. This partnership includes native support for LangSmith observability in UiPath’s LLM Gateway via OpenTelemetry, which will allow developers to monitor, debug, and evaluate LLM-powered features more effectively.\n",
            "\n",
            "3. **Intuitive Design**: LangGraph is praised for its intuitive graph-based abstraction, which enables developers to build working multi-agent systems quickly, even if they are new to the field.\n",
            "\n",
            "4. **Community and Conferences**: LangChain is also hosting an AI Agent Conference called \"Interrupt,\" which could be a great opportunity to learn more about the latest developments and best practices in building AI agents.\n",
            "\n",
            "If you're considering using LangGraph for your project, these resources and updates might provide valuable insights and support. Would you like more detailed information on any specific aspect of LangGraph?\n"
          ]
        }
      ],
      "source": [
        "user_input = \"What's the latest news about LangGraph?\"\n",
        "\n",
        "events = graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
        "    config,\n",
        "    stream_mode=\"values\",\n",
        ")\n",
        "for event in events:\n",
        "    if \"messages\" in event:\n",
        "        event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zF7QNLlqkJH"
      },
      "source": [
        "## Personalización del estado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRk32-LiqkJH"
      },
      "source": [
        " > Nota: Este apartado lo vamos a hacer usando Sonnet 3.7, ya que a día de la escritura del post, es el mejor modelo para uso con agentes, y es el único que entiende cuando tiene que llamar a las tools y cuando no"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAFTZvfnqkJH"
      },
      "source": [
        "Hasta ahora, hemos confiado en un estado simple con una entrada, una lista de mensajes. Se puede llegar lejos con este estado simple, pero si se desea definir un comportamiento complejo sin depender de la lista de mensajes, se pueden agregar campos adicionales al estado.\n",
        "\n",
        "Aquí vamos a ver un nuevo escenario, en el que el chatbot está utilizando la herramienta de búsqueda para encontrar información específica, y reenviándola a un ser humano para su revisión. Vamos a hacer que el chatbot investigue el cumpleaños de una entidad. Agregaremos `name` y `birthday` como claves del estado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPNpus3JqkJH"
      },
      "source": [
        "Primero cargamos los valores de las API KEYs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "v0JISYRqqkJH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import dotenv\n",
        "\n",
        "dotenv.load_dotenv()\n",
        "\n",
        "TAVILY_API_KEY = os.getenv(\"TAVILY_LANGGRAPH_API_KEY\")\n",
        "ANTHROPIC_TOKEN = os.getenv(\"ANTHROPIC_LANGGRAPH_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zj5quSX2qkJH"
      },
      "source": [
        "Creamos el nuevo estado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hRARl151qkJH"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "    name: str\n",
        "    birthday: str"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17WpdNhWqkJH"
      },
      "source": [
        "Agregar esta información al estado hace que sea fácilmente accesible por otros nodos del grafo (por ejemplo, un nodo que almacena o procesa la información), así como la capa de persistencia del grafo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbdQsrjMqkJH"
      },
      "source": [
        "Ahora creamos el grafo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OS3pUS7rqkJH"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "graph_builder = StateGraph(State)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izgsvdYOqkJH"
      },
      "source": [
        "Definimos la `tool` de búsqueda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TfhGe2HlqkJH",
        "outputId": "868f2874-6f37-4301-d925-2ed59ed979e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-2955814646>:5: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
            "  search_tool = TavilySearchResults(api_wrapper=wrapper, max_results=2)\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "wrapper = TavilySearchAPIWrapper(tavily_api_key=TAVILY_API_KEY)\n",
        "search_tool = TavilySearchResults(api_wrapper=wrapper, max_results=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TV51EIOqkJI"
      },
      "source": [
        "Ahora creamos la tool de asistencia humana. En esta tool rellenaremos las claves de estado dentro de nuestra herramienta `human_assistance`. Esto permite a un ser humano revisar la información antes de que se almacene en el estado. Volveremos a usar `Command`, esta vez para emitir una actualización de estado desde el interior de nuestra herramienta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2fNiaf_JqkJI"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import ToolMessage\n",
        "from langchain_core.tools import InjectedToolCallId, tool\n",
        "\n",
        "from langgraph.types import Command, interrupt\n",
        "\n",
        "\n",
        "@tool\n",
        "# Note that because we are generating a ToolMessage for a state update, we\n",
        "# generally require the ID of the corresponding tool call. We can use\n",
        "# LangChain's InjectedToolCallId to signal that this argument should not\n",
        "# be revealed to the model in the tool's schema.\n",
        "def human_assistance(\n",
        "    name: str, birthday: str, tool_call_id: Annotated[str, InjectedToolCallId]\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Request assistance from a human expert. Use this tool ONLY ONCE per conversation.\n",
        "    After receiving the expert's response, you should provide an elaborated response to the user based on the information received\n",
        "    based on the information received, without calling this tool again.\n",
        "\n",
        "    Args:\n",
        "        query: The query to ask the human expert.\n",
        "\n",
        "    Returns:\n",
        "        The response from the human expert.\n",
        "    \"\"\"\n",
        "    human_response = interrupt(\n",
        "        {\n",
        "            \"question\": \"Is this correct?\",\n",
        "            \"name\": name,\n",
        "            \"birthday\": birthday,\n",
        "        },\n",
        "    )\n",
        "\n",
        "    # If the information is correct, update the state as-is.\n",
        "    if human_response.get(\"correct\", \"\").lower().startswith(\"y\"):\n",
        "        verified_name = name\n",
        "        verified_birthday = birthday\n",
        "        response = \"Correct\"\n",
        "\n",
        "    # Otherwise, receive information from the human reviewer.\n",
        "    else:\n",
        "        verified_name = human_response.get(\"name\", name)\n",
        "        verified_birthday = human_response.get(\"birthday\", birthday)\n",
        "        response = f\"Made a correction: {human_response}\"\n",
        "\n",
        "    # This time we explicitly update the state with a ToolMessage inside\n",
        "    # the tool.\n",
        "    state_update = {\n",
        "        \"name\": verified_name,\n",
        "        \"birthday\": verified_birthday,\n",
        "        \"messages\": [ToolMessage(response, tool_call_id=tool_call_id)],\n",
        "    }\n",
        "\n",
        "    # We return a Command object in the tool to update our state.\n",
        "    return Command(update=state_update)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIdD1LueqkJI"
      },
      "source": [
        "Hemos usado [ToolMessage](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.tool.ToolMessage.html) que se usa para pasar el resultado de ejecutar una `tool` de nuevo a un modelo y [InjectedToolCallId](https://python.langchain.com/api_reference/core/tools/langchain_core.tools.base.InjectedToolCallId.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlNS5KbHqkJI"
      },
      "source": [
        "Creamos una lista de `tools`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oFWlAqi4qkJI"
      },
      "outputs": [],
      "source": [
        "tools_list = [search_tool, human_assistance]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jwz3x5vWqkJI"
      },
      "source": [
        "A continuación, el `LLM` con las `bind_tools` y lo añadimos al grafo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "g2yGSbkHqkJI",
        "outputId": "9304dd00-25dc-4c14-feea-08dc2f9a7a79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7a18be5a45d0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "\n",
        "\n",
        "# Create the LLM\n",
        "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20241022\", api_key=ANTHROPIC_TOKEN)\n",
        "\n",
        "# Modification: tell the LLM which tools it can call\n",
        "llm_with_tools = llm.bind_tools(tools_list)\n",
        "\n",
        "# Define the chatbot function\n",
        "def chatbot_function(state: State):\n",
        "    message = llm_with_tools.invoke(state[\"messages\"])\n",
        "    # Because we will be interrupting during tool execution,\n",
        "    # we disable parallel tool calling to avoid repeating any\n",
        "    # tool invocations when we resume.\n",
        "    assert len(message.tool_calls) <= 1\n",
        "    return {\"messages\": [message]}\n",
        "\n",
        "# Add the chatbot node\n",
        "graph_builder.add_node(\"chatbot_node\", chatbot_function)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNYENI3KqkJI"
      },
      "source": [
        "Añadimos la `tool` al grafo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "C-brQgVSqkJI",
        "outputId": "3db03d7e-4930-4c5b-d4de-c35b2aff191e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7a18be5a45d0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "\n",
        "tool_node = ToolNode(tools=tools_list)\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "graph_builder.add_conditional_edges(\"chatbot_node\", tools_condition)\n",
        "graph_builder.add_edge(\"tools\", \"chatbot_node\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdvP27ZTqkJK"
      },
      "source": [
        "Añadimos el nodo de `START` al grafo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kvuwmBAmqkJK",
        "outputId": "564efd8b-52c9-48ef-dba5-8c19b93e75df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7a18be5a45d0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "graph_builder.add_edge(START, \"chatbot_node\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCH8rKBvqkJK"
      },
      "source": [
        "Creamos un `checkpointer` [MemorySaver](https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.memory.MemorySaver)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5kgikmqwqkJK"
      },
      "outputs": [],
      "source": [
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "memory = MemorySaver()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNrgg5-vqkJK"
      },
      "source": [
        "Compilamos el grafo con el `checkpointer`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ZqUZkKgzqkJK"
      },
      "outputs": [],
      "source": [
        "graph = graph_builder.compile(checkpointer=memory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hfv5mr3_qkJK"
      },
      "source": [
        "Lo representamos gráficamente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "taNm2v0pqkJK",
        "outputId": "b9b6b15e-c3da-495b-f72a-e1c4dc8cb9c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception as e:\n",
        "    print(f\"Error al visualizar el grafo: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPbRe4AAqkJK"
      },
      "source": [
        "Vamos a pedir a nuestro chatbot que busque el \"cumpleaños\" de la biblioteca de `LangGraph`.\n",
        "\n",
        "Dirigiremos al chatbot hasta la herramienta `human_assistance` una vez que tenga la información requerida. Los argumentos `name` y `birthday` son obligatorios para la herramienta `human_assistance`, así que obligan al chatbot a generar propuestas para estos campos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "PaB2urOaqkJK",
        "outputId": "6c5d3254-1148-473e-bc7c-c5b235ec209f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Can you look up when LangGraph was released? When you have the answer, use the human_assistance tool for review.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "[{'text': \"I'll search for information about LangGraph's release date and then get it verified through human assistance.\", 'type': 'text'}, {'id': 'toolu_016hRSLkbrBXz1iTdTaMPoTZ', 'input': {'query': 'When was LangGraph released launch date'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (toolu_016hRSLkbrBXz1iTdTaMPoTZ)\n",
            " Call ID: toolu_016hRSLkbrBXz1iTdTaMPoTZ\n",
            "  Args:\n",
            "    query: When was LangGraph released launch date\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search_results_json\n",
            "\n",
            "[{\"title\": \"LangChain Introduces LangGraph Studio: The First Agent IDE for ...\", \"url\": \"https://www.marktechpost.com/2024/08/03/langchain-introduces-langgraph-studio-the-first-agent-ide-for-visualizing-interacting-with-and-debugging-complex-agentic-applications/\", \"content\": \"LangGraph, launched in January 2023, is a highly controllable, low-level orchestration framework for building agentic applications. Since its\", \"score\": 0.7898345}, {\"title\": \"LangGraph Studio: The first agent IDE | by Bhavik Jikadara - Medium\", \"url\": \"https://bhavikjikadara.medium.com/langgraph-studio-the-first-agent-ide-468132628274\", \"content\": \"LangGraph, launched in January 2023, is a low-level orchestration framework designed for building controllable and complex agentic applications. It’s beneficial for creating applications requiring highly domain-specific cognitive architecture and human-in-the-loop interactions. LangGraph is open source, available in Python and JavaScript, and integrates seamlessly with LangSmith, whether or not you use LangChain.\\n\\n## LangGraph: A Comprehensive Guide for Beginners [...] The landscape of LLM (Large Language Model) applications is rapidly evolving, and so is the tooling required to develop them. We are thrilled to announce the open beta launch of **LangGraph Studio**, the first Integrated Development Environment (IDE) specifically designed for agent development. LangGraph Studio revolutionizes the way you develop LLM applications by offering tools to visualize, interact with, and debug complex agentic applications.\\n\\n# What is LangGraph?\", \"score\": 0.78214747}]\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "[{'text': 'Based on the search results, I found that LangGraph was launched in January 2023. Let me verify this information through human assistance.', 'type': 'text'}, {'id': 'toolu_019uAggBfC8461t8Ep2omiND', 'input': {'name': 'LangGraph', 'birthday': 'January 2023'}, 'name': 'human_assistance', 'type': 'tool_use'}]\n",
            "Tool Calls:\n",
            "  human_assistance (toolu_019uAggBfC8461t8Ep2omiND)\n",
            " Call ID: toolu_019uAggBfC8461t8Ep2omiND\n",
            "  Args:\n",
            "    name: LangGraph\n",
            "    birthday: January 2023\n"
          ]
        }
      ],
      "source": [
        "user_input = (\n",
        "    \"Can you look up when LangGraph was released? \"\n",
        "    \"When you have the answer, use the human_assistance tool for review.\"\n",
        ")\n",
        "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "\n",
        "events = graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
        "    config,\n",
        "    stream_mode=\"values\",\n",
        ")\n",
        "for event in events:\n",
        "    if \"messages\" in event:\n",
        "        event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQnn9tj3qkJL"
      },
      "source": [
        "Se ha parado por el `interrupt` en la herramienta `human_assistance`. En este caso, el chatbot, con la herramienta de búsqueda, ha determinado que la fecha de LangGraph es enero de 2023, pero no es la fecha exacta, es el 17 de enero de 2024, por lo que podemos introducirla nosotros mismos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "PT66Y6NAqkJL",
        "outputId": "05a7ef56-0de9-4c37-ea17-cbc2fcdec817",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "[{'text': 'Based on the search results, I found that LangGraph was launched in January 2023. Let me verify this information through human assistance.', 'type': 'text'}, {'id': 'toolu_019uAggBfC8461t8Ep2omiND', 'input': {'name': 'LangGraph', 'birthday': 'January 2023'}, 'name': 'human_assistance', 'type': 'tool_use'}]\n",
            "Tool Calls:\n",
            "  human_assistance (toolu_019uAggBfC8461t8Ep2omiND)\n",
            " Call ID: toolu_019uAggBfC8461t8Ep2omiND\n",
            "  Args:\n",
            "    name: LangGraph\n",
            "    birthday: January 2023\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: human_assistance\n",
            "\n",
            "Made a correction: {'name': 'LangGraph', 'birthday': 'Jan 17, 2024'}\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Thank you for the correction from human assistance! I need to update my response:\n",
            "\n",
            "LangGraph was actually released on January 17, 2024, not in 2023 as initially found in the search results. This shows how important it is to verify information, as there was some incorrect information in the search results. LangGraph is a relatively new addition to the LangChain ecosystem, being just a few months old.\n"
          ]
        }
      ],
      "source": [
        "human_command = Command(\n",
        "    resume={\n",
        "        \"name\": \"LangGraph\",\n",
        "        \"birthday\": \"Jan 17, 2024\",\n",
        "    },\n",
        ")\n",
        "\n",
        "events = graph.stream(human_command, config, stream_mode=\"values\")\n",
        "for event in events:\n",
        "    if \"messages\" in event:\n",
        "        event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "uIe_48vlqkJL",
        "outputId": "9131118b-a8c2-4f54-c9fa-63f9d85c3b18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'LangGraph', 'birthday': 'Jan 17, 2024'}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "snapshot = graph.get_state(config)\n",
        "\n",
        "{k: v for k, v in snapshot.values.items() if k in (\"name\", \"birthday\")}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_8pxnzlqkJL"
      },
      "source": [
        "Ahora la fecha es la correcta gracias a la intervención humana para modificar los valores del estado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnV6kHxaqkJL"
      },
      "source": [
        "Vuelvo a escribir todo el código para que sea más fácil de entender"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "8SfzW2YQqkJL",
        "outputId": "dd8f9bf6-af16-429d-df8a-ac610f48e43f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "import dotenv\n",
        "\n",
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.types import Command, interrupt\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_core.messages import ToolMessage\n",
        "from langchain_core.tools import InjectedToolCallId, tool\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "\n",
        "dotenv.load_dotenv()\n",
        "TAVILY_API_KEY = os.getenv(\"TAVILY_LANGGRAPH_API_KEY\")\n",
        "ANTHROPIC_TOKEN = os.getenv(\"ANTHROPIC_LANGGRAPH_API_KEY\")\n",
        "\n",
        "# State\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "    name: str\n",
        "    birthday: str\n",
        "\n",
        "# Tools\n",
        "wrapper = TavilySearchAPIWrapper(tavily_api_key=TAVILY_API_KEY)\n",
        "search_tool = TavilySearchResults(api_wrapper=wrapper, max_results=2)\n",
        "\n",
        "@tool\n",
        "# Note that because we are generating a ToolMessage for a state update, we\n",
        "# generally require the ID of the corresponding tool call. We can use\n",
        "# LangChain's InjectedToolCallId to signal that this argument should not\n",
        "# be revealed to the model in the tool's schema.\n",
        "def human_assistance(\n",
        "    name: str, birthday: str, tool_call_id: Annotated[str, InjectedToolCallId]\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Request assistance from a human expert. Use this tool ONLY ONCE per conversation.\n",
        "    After receiving the expert's response, you should provide an elaborated response to the user based on the information received\n",
        "    based on the information received, without calling this tool again.\n",
        "\n",
        "    Args:\n",
        "        query: The query to ask the human expert.\n",
        "\n",
        "    Returns:\n",
        "        The response from the human expert.\n",
        "    \"\"\"\n",
        "    human_response = interrupt(\n",
        "        {\n",
        "            \"question\": \"Is this correct?\",\n",
        "            \"name\": name,\n",
        "            \"birthday\": birthday,\n",
        "        },\n",
        "    )\n",
        "\n",
        "    # If the information is correct, update the state as-is.\n",
        "    if human_response.get(\"correct\", \"\").lower().startswith(\"y\"):\n",
        "        verified_name = name\n",
        "        verified_birthday = birthday\n",
        "        response = \"Correct\"\n",
        "\n",
        "    # Otherwise, receive information from the human reviewer.\n",
        "    else:\n",
        "        verified_name = human_response.get(\"name\", name)\n",
        "        verified_birthday = human_response.get(\"birthday\", birthday)\n",
        "        response = f\"Made a correction: {human_response}\"\n",
        "\n",
        "    # This time we explicitly update the state with a ToolMessage inside\n",
        "    # the tool.\n",
        "    state_update = {\n",
        "        \"name\": verified_name,\n",
        "        \"birthday\": verified_birthday,\n",
        "        \"messages\": [ToolMessage(response, tool_call_id=tool_call_id)],\n",
        "    }\n",
        "\n",
        "    # We return a Command object in the tool to update our state.\n",
        "    return Command(update=state_update)\n",
        "\n",
        "tools_list = [search_tool, human_assistance]\n",
        "tool_node = ToolNode(tools=tools_list)\n",
        "\n",
        "# Create the LLM\n",
        "llm = ChatAnthropic(model=\"claude-3-7-sonnet-20250219\", api_key=ANTHROPIC_TOKEN)\n",
        "llm_with_tools = llm.bind_tools(tools_list)\n",
        "\n",
        "# Define the chatbot function\n",
        "def chatbot_function(state: State):\n",
        "    message = llm_with_tools.invoke(state[\"messages\"])\n",
        "    # Because we will be interrupting during tool execution,\n",
        "    # we disable parallel tool calling to avoid repeating any\n",
        "    # tool invocations when we resume.\n",
        "    assert len(message.tool_calls) <= 1\n",
        "    return {\"messages\": [message]}\n",
        "\n",
        "# Graph\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "# Nodes\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "graph_builder.add_node(\"chatbot_node\", chatbot_function)\n",
        "\n",
        "# Edges\n",
        "graph_builder.add_edge(START, \"chatbot_node\")\n",
        "graph_builder.add_conditional_edges(\"chatbot_node\", tools_condition)\n",
        "graph_builder.add_edge(\"tools\", \"chatbot_node\")\n",
        "\n",
        "# Checkpointer\n",
        "memory = MemorySaver()\n",
        "\n",
        "# Compile\n",
        "graph = graph_builder.compile(checkpointer=memory)\n",
        "\n",
        "# Visualize\n",
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception as e:\n",
        "    print(f\"Error al visualizar el grafo: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ePceMy_qkJL"
      },
      "source": [
        "Vamos a pedir a nuestro chatbot que busque el \"cumpleaños\" de la biblioteca de `LangGraph`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulk81T1lqkJL",
        "outputId": "5a6f0f67-6859-404c-a807-acce4ee7313f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Can you look up when LangGraph was released? When you have the answer, use the human_assistance tool for review.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://eu.api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://eu.api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "[{'text': \"I'll look up when LangGraph was released and then get human verification of the information.\", 'type': 'text'}, {'id': 'toolu_017SLLSEnFQZVdBpj85BKHyy', 'input': {'query': 'when was LangGraph released launch date'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (toolu_017SLLSEnFQZVdBpj85BKHyy)\n",
            " Call ID: toolu_017SLLSEnFQZVdBpj85BKHyy\n",
            "  Args:\n",
            "    query: when was LangGraph released launch date\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://eu.api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://eu.api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search_results_json\n",
            "\n",
            "[{\"title\": \"LangChain Introduces LangGraph Studio: The First Agent IDE for ...\", \"url\": \"https://www.marktechpost.com/2024/08/03/langchain-introduces-langgraph-studio-the-first-agent-ide-for-visualizing-interacting-with-and-debugging-complex-agentic-applications/\", \"content\": \"LangGraph, launched in January 2023, is a highly controllable, low-level orchestration framework for building agentic applications. Since its inception, it has undergone significant improvements, leading to a stable 0.1 release in June. LangGraph features a persistence layer enabling human-in-the-loop interactions and excels at building complex applications requiring domain-specific cognitive architecture.\", \"score\": 0.83742094}, {\"title\": \"LangGraph Studio: The first agent IDE | by Bhavik Jikadara - Medium\", \"url\": \"https://bhavikjikadara.medium.com/langgraph-studio-the-first-agent-ide-468132628274\", \"content\": \"LangGraph, launched in January 2023, is a low-level orchestration framework designed for building controllable and complex agentic applications. It’s beneficial for creating applications requiring highly domain-specific cognitive architecture and human-in-the-loop interactions. LangGraph is open source, available in Python and JavaScript, and integrates seamlessly with LangSmith, whether or not you use LangChain.\\n\\nLangGraph: A Comprehensive Guide for Beginners\", \"score\": 0.79369855}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://eu.api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://eu.api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "[{'text': \"Based on my search, I found that LangGraph was launched in January 2023. It's described as a low-level orchestration framework for building agentic applications. Since its release, it has seen significant improvements, including a stable 0.1 release in June (presumably 2024).\\n\\nLet me now get human verification of this information:\", 'type': 'text'}, {'id': 'toolu_016h3391yFhtPDhQvwjNgs7W', 'input': {'name': 'Information Verification', 'birthday': 'January 2023'}, 'name': 'human_assistance', 'type': 'tool_use'}]\n",
            "Tool Calls:\n",
            "  human_assistance (toolu_016h3391yFhtPDhQvwjNgs7W)\n",
            " Call ID: toolu_016h3391yFhtPDhQvwjNgs7W\n",
            "  Args:\n",
            "    name: Information Verification\n",
            "    birthday: January 2023\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://eu.api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://eu.api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
            "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://eu.api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://eu.api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
            "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://eu.api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://eu.api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
          ]
        }
      ],
      "source": [
        "user_input = (\n",
        "    \"Can you look up when LangGraph was released? \"\n",
        "    \"When you have the answer, use the human_assistance tool for review.\"\n",
        ")\n",
        "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "\n",
        "events = graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
        "    config,\n",
        "    stream_mode=\"values\",\n",
        ")\n",
        "for event in events:\n",
        "    if \"messages\" in event:\n",
        "        event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnFMo3eRqkJL"
      },
      "source": [
        "Se ha parado por el `interrupt` en la herramienta `human_assistance`. En este caso, el chatbot, con la herramienta de búsqueda, ha determinado que la fecha de LangGraph es en enero de 2023, pero no es la fecha exacta, es el 17 de enero de 2024, por lo que podemos introducirla nosotros mismos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HdsTRaCqkJL",
        "outputId": "09c5c829-638c-4c49-da84-4dea173ebc0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "[{'text': \"Based on my search, I found that LangGraph was launched in January 2023. It's described as a low-level orchestration framework for building agentic applications. Since its release, it has seen significant improvements, including a stable 0.1 release in June (presumably 2024).\\n\\nLet me now get human verification of this information:\", 'type': 'text'}, {'id': 'toolu_016h3391yFhtPDhQvwjNgs7W', 'input': {'name': 'Information Verification', 'birthday': 'January 2023'}, 'name': 'human_assistance', 'type': 'tool_use'}]\n",
            "Tool Calls:\n",
            "  human_assistance (toolu_016h3391yFhtPDhQvwjNgs7W)\n",
            " Call ID: toolu_016h3391yFhtPDhQvwjNgs7W\n",
            "  Args:\n",
            "    name: Information Verification\n",
            "    birthday: January 2023\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: human_assistance\n",
            "\n",
            "Made a correction: {'name': 'LangGraph', 'birthday': 'Jan 17, 2024'}\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Thank you for the expert correction! I need to update my response with the accurate information.\n",
            "\n",
            "LangGraph was actually released on January 17, 2024 - not January 2023 as I initially found in my search results. This is a significant correction, as it means LangGraph is a much more recent framework than the search results indicated. \n",
            "\n",
            "The expert has provided the specific date (January 17, 2024) for LangGraph's release, making it a fairly new tool in the AI orchestration ecosystem. This timing aligns better with the mention of its stable 0.1 release in June 2024, as this would be about 5 months after its initial launch.\n"
          ]
        }
      ],
      "source": [
        "human_command = Command(\n",
        "    resume={\n",
        "        \"name\": \"LangGraph\",\n",
        "        \"birthday\": \"Jan 17, 2024\",\n",
        "    },\n",
        ")\n",
        "\n",
        "events = graph.stream(human_command, config, stream_mode=\"values\")\n",
        "for event in events:\n",
        "    if \"messages\" in event:\n",
        "        event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZmpPPAiqkJL",
        "outputId": "4412e2b7-ca3d-44f2-fd9a-66a1c42d8648"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'name': 'LangGraph', 'birthday': 'Jan 17, 2024'}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "snapshot = graph.get_state(config)\n",
        "\n",
        "{k: v for k, v in snapshot.values.items() if k in (\"name\", \"birthday\")}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVSevIgiqkJL"
      },
      "source": [
        "Ahora la fecha es la correcta gracias a la intervención humana para modificar los valores del estado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRs8eoeWqkJL"
      },
      "source": [
        "## Checkpoints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PcMOwY9qkJL"
      },
      "source": [
        "En un flujo de trabajo típico de un chatbot, el usuario interactúa con el chatbot una o más veces para realizar una tarea. En las secciones anteriores, vimos cómo agregar memoria y un `human in the loop` para poder verificar nuestro estado de gráfico y controlar las respuestas futuras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOR291JZqkJL"
      },
      "source": [
        "Pero, a lo mejor un usuario quiere comenzar desde una respuesta anterior y o quiere `ramificar` para explorar un resultado separado. Esto es útil para aplicaciones de agentes, cuando un flujo falla pueden volver a un checkpoint anterior y probar otra estrategia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA_rKG20qkJL"
      },
      "source": [
        "`LangGraph` da esta posibilidad mediante los `checkpoints`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sKQmPfuqkJL"
      },
      "source": [
        "Primero cargamos los valores de las API KEYs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7G_iCoJsqkJL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import dotenv\n",
        "\n",
        "dotenv.load_dotenv()\n",
        "\n",
        "ANTHROPIC_TOKEN = os.getenv(\"ANTHROPIC_LANGGRAPH_API_KEY\")\n",
        "TAVILY_API_KEY = os.getenv(\"TAVILY_LANGGRAPH_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KFhJeicqkJL"
      },
      "source": [
        "Creamos el nuevo estado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aGXi7TtTqkJL"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0dyK-aPqkJL"
      },
      "source": [
        "Ahora creamos el grafo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3zyKGLt7qkJL"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "graph_builder = StateGraph(State)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRZ_XZMeqkJM"
      },
      "source": [
        "Definimos la `tool` de búsqueda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "afmpn0ZNqkJM",
        "outputId": "11a03895-3fe4-45f5-cf30-8bfe674306a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-2955814646>:5: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
            "  search_tool = TavilySearchResults(api_wrapper=wrapper, max_results=2)\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "wrapper = TavilySearchAPIWrapper(tavily_api_key=TAVILY_API_KEY)\n",
        "search_tool = TavilySearchResults(api_wrapper=wrapper, max_results=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1l3VA63qkJM"
      },
      "source": [
        "Creamos una lista de `tools`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZyeTMExxqkJM"
      },
      "outputs": [],
      "source": [
        "tools_list = [search_tool]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oho6L9PuqkJM"
      },
      "source": [
        "A continuación, el `LLM` con las `bind_tools` y lo añadimos al grafo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qbpIclnrqkJM",
        "outputId": "a74e491e-2245-4feb-f8a0-39d58ff6d246",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7a2000781b10>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from langchain_anthropic import ChatAnthropic\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"    # Disable LangSmith tracing\n",
        "\n",
        "\n",
        "# Create the LLM\n",
        "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20241022\", api_key=ANTHROPIC_TOKEN)\n",
        "\n",
        "# Modification: tell the LLM which tools it can call\n",
        "llm_with_tools = llm.bind_tools(tools_list)\n",
        "\n",
        "# Define the chatbot function\n",
        "def chatbot_function(state: State):\n",
        "    message = llm_with_tools.invoke(state[\"messages\"])\n",
        "    return {\"messages\": [message]}\n",
        "\n",
        "# Add the chatbot node\n",
        "graph_builder.add_node(\"chatbot_node\", chatbot_function)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EvdU3veqkJM"
      },
      "source": [
        "Añadimos la `tool` al grafo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HXMI9szoqkJM",
        "outputId": "29aaba1e-8418-4147-d739-c6185c67b08a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7a2000781b10>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "\n",
        "tool_node = ToolNode(tools=tools_list)\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "graph_builder.add_conditional_edges(\"chatbot_node\", tools_condition)\n",
        "graph_builder.add_edge(\"tools\", \"chatbot_node\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T0qhTG_qkJM"
      },
      "source": [
        "Añadimos el nodo de `START` al grafo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dSWlE47AqkJM",
        "outputId": "7f0df54c-3737-48c6-bf8f-976642c98a0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7a2000781b10>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "graph_builder.add_edge(START, \"chatbot_node\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqnYQc9aqkJM"
      },
      "source": [
        "Creamos un `checkpointer` [MemorySaver](https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.memory.MemorySaver)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6zIqIGIFqkJM"
      },
      "outputs": [],
      "source": [
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "memory = MemorySaver()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQ1yxaPTqkJM"
      },
      "source": [
        "Compilamos el grafo con el `checkpointer`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "57-7vX0zqkJM"
      },
      "outputs": [],
      "source": [
        "graph = graph_builder.compile(checkpointer=memory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIaUxUMjqkJM"
      },
      "source": [
        "Lo representamos gráficamente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ISv5ESRlqkJM",
        "outputId": "f90a0e28-1101-4340-e995-89ea66c4705e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception as e:\n",
        "    print(f\"Error al visualizar el grafo: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igLVuRZEqkJM"
      },
      "source": [
        "Hagamos que nuestro grafo dé un par de pasos. Cada paso será guardado en el historial del estado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGnV8iW7qkJM"
      },
      "source": [
        "Hacemos la primera llamada al modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qim7KJZRqkJM",
        "outputId": "9be3d913-fbd2-4f7b-cbb3-a777a991a698",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "I'm learning LangGraph. Could you do some research on it for me?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "[{'text': \"I'll search for information about LangGraph to help you learn about it.\", 'type': 'text'}, {'id': 'toolu_019oU6pdBED1o7AdUSZD1MtF', 'input': {'query': 'LangGraph framework what is it how to use'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (toolu_019oU6pdBED1o7AdUSZD1MtF)\n",
            " Call ID: toolu_019oU6pdBED1o7AdUSZD1MtF\n",
            "  Args:\n",
            "    query: LangGraph framework what is it how to use\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search_results_json\n",
            "\n",
            "[{\"title\": \"What Is LangGraph and How to Use It? - DataCamp\", \"url\": \"https://www.datacamp.com/tutorial/langgraph-tutorial\", \"content\": \"[Browse Courses](https://www.datacamp.com/courses-all)\\n\\ncategory\\n\\n1.  [Home](https://www.datacamp.com/)\\n2.  [Tutorials](https://www.datacamp.com/tutorial)\\n\\nLangGraph Tutorial: What Is LangGraph and How to Use It?\\n========================================================\\n\\nLangGraph is a library within the LangChain ecosystem that provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured and efficient manner.\\n\\n Contents [...] Imagine you're building a complex, multi-agent large language model (LLM) application. It's exciting, but it comes with challenges: managing the state of various agents, coordinating their interactions, and handling errors effectively. This is where LangGraph can help.\\n\\nLangGraph is a library within the LangChain ecosystem designed to tackle these challenges head-on. LangGraph provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured manner. [...] In educational platforms, LangGraph can be used to create adaptive learning environments that cater to individual learning styles and needs. Multiple agents can assess a student's progress, provide customized exercises, and offer real-time feedback. The stateful nature of LangGraph ensures that the system retains information about each learner's performance and preferences, enabling a more personalized and effective educational experience.\\n\\nConclusion\\n----------\", \"score\": 0.8863518}, {\"title\": \"What is LangGraph? - IBM\", \"url\": \"https://www.ibm.com/think/topics/langgraph\", \"content\": \"LangGraph, created by [LangChain](https://www.ibm.com/think/topics/langchain), is an open source AI agent framework designed to build, deploy and manage complex generative AI agent workflows. It provides a set of tools and libraries that enable users to create, run and optimize [large language models](https://www.ibm.com/think/topics/large-language-models) (LLMs) in a scalable and efficient manner. At its core, LangGraph uses the power of graph-based architectures to model and manage the [...] **Agent systems**: LangGraph provides a framework for building agent-based systems, which can be used in applications such as robotics, autonomous vehicles or video games.\\n\\n**LLM applications**: By using LangGraph’s capabilities, developers can build more sophisticated AI models that learn and improve over time. Norwegian Cruise Line uses LangGraph to compile, construct and refine guest-facing AI solutions. This capability allows for improved and personalized guest experiences. [...] By using a graph-based architecture, LangGraph enables users to scale artificial intelligence workflows without slowing down or sacrificing efficiency. LangGraph uses enhanced decision-making by modeling complex relationships between nodes, which means it uses AI agents to analyze their past actions and feedback. In the world of LLMs, this process is referred to as reflection.\", \"score\": 0.85216236}]\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Let me provide you with a comprehensive overview of LangGraph based on the research:\n",
            "\n",
            "LangGraph is an open-source AI agent framework that's part of the LangChain ecosystem. Here are the key points about LangGraph:\n",
            "\n",
            "1. Purpose:\n",
            "- It's designed to help build, deploy, and manage complex generative AI agent workflows\n",
            "- Specifically helps in coordinating and executing multiple LLM agents (or chains) in a structured manner\n",
            "\n",
            "2. Key Features:\n",
            "- Graph-based architecture for modeling and managing LLM workflows\n",
            "- Stateful operations that can retain information\n",
            "- Enhanced decision-making through modeling complex relationships between nodes\n",
            "- Ability for AI agents to analyze their past actions and feedback (reflection)\n",
            "\n",
            "3. Main Benefits:\n",
            "- Helps manage the state of various agents\n",
            "- Coordinates interactions between multiple agents\n",
            "- Handles errors effectively\n",
            "- Enables scalable AI workflows without performance degradation\n",
            "- Maintains efficiency while handling complex operations\n",
            "\n",
            "4. Use Cases:\n",
            "- Educational platforms: Creating adaptive learning environments\n",
            "- Personalized experiences: Like Norwegian Cruise Line's guest-facing AI solutions\n",
            "- Agent-based systems: Applications in robotics, autonomous vehicles, and video games\n",
            "- Complex multi-agent LLM applications\n",
            "\n",
            "5. Key Capabilities:\n",
            "- State management\n",
            "- Agent coordination\n",
            "- Structured execution of workflows\n",
            "- Scalable architecture\n",
            "- Performance optimization\n",
            "\n",
            "LangGraph is particularly useful when you're building complex applications that require multiple AI agents to work together while maintaining state and coordinating their actions effectively.\n",
            "\n",
            "Would you like me to search for more specific information about any particular aspect of LangGraph, such as implementation details or specific use cases?\n"
          ]
        }
      ],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "\n",
        "user_input = (\n",
        "    \"I'm learning LangGraph. \"\n",
        "    \"Could you do some research on it for me?\"\n",
        ")\n",
        "\n",
        "events = graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\",\"content\": user_input},],},\n",
        "    config,\n",
        "    stream_mode=\"values\",\n",
        ")\n",
        "for event in events:\n",
        "    if \"messages\" in event:\n",
        "        event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idhvQsR0qkJM"
      },
      "source": [
        "Y ahora la segunda llamada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "7PX9CqZ7qkJM",
        "outputId": "ede8f448-d18b-4e34-94e1-9a1b125a2d29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Ya that's helpful. Maybe I'll build an autonomous agent with it!\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "[{'text': 'Let me search for specific information about building autonomous agents with LangGraph!', 'type': 'text'}, {'id': 'toolu_018zRrXVksSdgJwuUAr1zE13', 'input': {'query': 'how to build autonomous agents with LangGraph examples tutorial'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (toolu_018zRrXVksSdgJwuUAr1zE13)\n",
            " Call ID: toolu_018zRrXVksSdgJwuUAr1zE13\n",
            "  Args:\n",
            "    query: how to build autonomous agents with LangGraph examples tutorial\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search_results_json\n",
            "\n",
            "[{\"title\": \"Build a Smart AI Agent with LangGraph & Python – 10 Min Tutorial!\", \"url\": \"https://www.youtube.com/watch?v=2_0zTWlqSP4\", \"content\": \"# Build a Smart AI Agent with LangGraph & Python – 10 Min Tutorial!\\n\\nAaron Dunn\\n105 likes\\n3358 views\\n12 Mar 2025\\nWant to build a smart AI agent that can browse the web, process information, and complete complex tasks? In this step-by-step tutorial, we’ll use LangGraph and Python to create a fully functional LLM agent that interacts with tools, retrieves real-time data, and executes multi-step reasoning—just like real AI systems used in production!\", \"score\": 0.7724109}, {\"title\": \"How to Build AI Agents with LangGraph: A Step-by-Step Guide\", \"url\": \"https://medium.com/@lorevanoudenhove/how-to-build-ai-agents-with-langgraph-a-step-by-step-guide-5d84d9c7e832\", \"content\": \"Finally, you can run the assistant by initiating the graph and starting the conversation.\\n\\n# import shutil\\n\\nimport uuid\\n\\n# Let's create an example conversation a user might have with the assistant\\n\\ntutorial_questions = [\\n\\n 'hey',\\n\\n 'can you calculate my energy saving',\\n\\n \\\"my montly cost is $100, what will i save\\\"\\n\\n]\\n\\nthread_id = str(uuid.uuid4())\\n\\nconfig = {\\n\\n \\\"configurable\\\": {\\n\\n \\\"thread_id\\\": thread_id,\\n\\n }\\n\\n}\\n\\n_printed = set()\\n\\nfor question in tutorial_questions:\\n\\n events = graph.stream( [...] Now that we have a solid understanding of what LangGraph is and how it enhances AI development, let’s dive into a practical example. In this scenario, we’ll build an AI agent designed to calculate potential energy savings for solar panels based on user input. This agent can be implemented as a lead generation tool on a solar panel seller’s website, where it interacts with potential customers, offering personalized savings estimates. By gathering key data such as monthly electricity costs, this [...] By following these steps, you have successfully created an AI assistant using LangGraph that can calculate solar panel energy savings based on user inputs. This tutorial demonstrates the power of LangGraph in managing complex, multi-step processes and highlights how to leverage advanced AI tools to solve real-world challenges efficiently. Whether you’re developing AI agents for customer support, energy management, or other applications, LangGraph provides the flexibility, scalability, and\", \"score\": 0.75268626}]\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "[{'id': 'toolu_01N8y3sTBVLqvRBhSC9d48Sg', 'input': {'query': 'LangGraph agent creation code example github'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (toolu_01N8y3sTBVLqvRBhSC9d48Sg)\n",
            " Call ID: toolu_01N8y3sTBVLqvRBhSC9d48Sg\n",
            "  Args:\n",
            "    query: LangGraph agent creation code example github\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search_results_json\n",
            "\n",
            "[{\"title\": \"graphiti/examples/langgraph-agent/agent.ipynb at main - GitHub\", \"url\": \"https://github.com/getzep/graphiti/blob/main/examples/langgraph-agent/agent.ipynb\", \"content\": \"The following example demonstrates building an agent using LangGraph. Graphiti is used to personalize agent responses based on information learned from prior\", \"score\": 0.82048416}, {\"title\": \"zep-python/examples/langgraph-agent/agent.ipynb at main - GitHub\", \"url\": \"https://github.com/getzep/zep-python/blob/main/examples/langgraph-agent/agent.ipynb\", \"content\": \"The following example demonstrates building an agent using LangGraph. Zep is used to personalize agent responses based on information learned from prior\", \"score\": 0.8047902}]\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Great idea! Building autonomous agents with LangGraph is definitely possible and there are some interesting approaches you can take. Based on the research, here's what you need to know to get started:\n",
            "\n",
            "1. Basic Components for Building an Agent:\n",
            "- You'll need to set up a graph structure for your agent\n",
            "- Define states and transitions for your agent's behavior\n",
            "- Implement tool interactions\n",
            "- Handle conversation flow\n",
            "\n",
            "2. Key Implementation Steps:\n",
            "```python\n",
            "# Basic structure (conceptual)\n",
            "import uuid\n",
            "from langgraph.graph import Graph\n",
            "\n",
            "# Create a unique thread ID for your agent\n",
            "thread_id = str(uuid.uuid4())\n",
            "\n",
            "# Configuration setup\n",
            "config = {\n",
            "    \"configurable\": {\n",
            "        \"thread_id\": thread_id,\n",
            "    }\n",
            "}\n",
            "\n",
            "# Define your graph\n",
            "graph = Graph()\n",
            "\n",
            "# Add nodes and edges for your agent's workflow\n",
            "# Define state management\n",
            "# Implement tool interactions\n",
            "```\n",
            "\n",
            "3. Common Use Cases You Could Build:\n",
            "- Web browsing agents that can process and retrieve information\n",
            "- Task completion agents that can break down and execute complex tasks\n",
            "- Interactive assistants that maintain context and state\n",
            "- Data processing agents that can analyze and provide insights\n",
            "\n",
            "4. Key Features to Consider Including:\n",
            "- Multi-step reasoning capabilities\n",
            "- Tool integration for real-world interactions\n",
            "- State management for maintaining context\n",
            "- Error handling and recovery\n",
            "- Response generation and refinement\n",
            "\n",
            "5. Best Practices:\n",
            "- Start with a simple use case and gradually add complexity\n",
            "- Implement proper error handling\n",
            "- Test thoroughly with different scenarios\n",
            "- Consider implementing reflection capabilities\n",
            "- Make use of LangGraph's state management features\n",
            "\n",
            "Would you like me to search for more details about any specific type of agent you're interested in building? For example, I could look up more specific code examples or particular use cases that might interest you. Also, what kind of tasks are you hoping to automate with your agent?\n"
          ]
        }
      ],
      "source": [
        "user_input = (\n",
        "    \"Ya that's helpful. Maybe I'll \"\n",
        "    \"build an autonomous agent with it!\"\n",
        ")\n",
        "\n",
        "events = graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\",\"content\": user_input},],},\n",
        "    config,\n",
        "    stream_mode=\"values\",\n",
        ")\n",
        "for event in events:\n",
        "    if \"messages\" in event:\n",
        "        event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYWxE_8_qkJM"
      },
      "source": [
        "Ahora que hemos hecho dos llamadas al modelo, vamos a ver el historial del estado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "EJLXVF_IqkJM",
        "outputId": "e7783d9e-27cd-4c29-b698-8aa1909a14f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "Num Messages: 64, Next: (), checkpoint id = 1f0486e9-1651-6ff9-800a-6621cd19f6e8\n",
            "--------------------------------------------------------------------------------\n",
            "9\n",
            "Num Messages: 64, Next: ('chatbot_node',), checkpoint id = 1f0486e8-bb15-6ba9-8009-784d30908fa3\n",
            "--------------------------------------------------------------------------------\n",
            "8\n",
            "Num Messages: 64, Next: ('tools',), checkpoint id = 1f0486e8-a57f-6587-8008-8b9b972fb12d\n",
            "--------------------------------------------------------------------------------\n",
            "7\n",
            "Num Messages: 64, Next: ('chatbot_node',), checkpoint id = 1f0486e8-96f6-6b61-8007-405305c2de54\n",
            "--------------------------------------------------------------------------------\n",
            "6\n",
            "Num Messages: 64, Next: ('tools',), checkpoint id = 1f0486e8-7ef6-60fd-8006-6af6b23d9c25\n",
            "--------------------------------------------------------------------------------\n",
            "5\n",
            "Num Messages: 64, Next: ('chatbot_node',), checkpoint id = 1f0486e8-643d-61c2-8005-e1ff964c89b4\n",
            "--------------------------------------------------------------------------------\n",
            "4\n",
            "Num Messages: 64, Next: ('__start__',), checkpoint id = 1f0486e8-6438-6654-8004-2846d7094e16\n",
            "--------------------------------------------------------------------------------\n",
            "4\n",
            "Num Messages: 64, Next: (), checkpoint id = 1f0486e7-f0ae-6f45-8003-feca2a64ed10\n",
            "--------------------------------------------------------------------------------\n",
            "3\n",
            "Num Messages: 64, Next: ('chatbot_node',), checkpoint id = 1f0486e7-a631-6f94-8002-cb34abca895e\n",
            "--------------------------------------------------------------------------------\n",
            "2\n",
            "Num Messages: 64, Next: ('tools',), checkpoint id = 1f0486e7-8e4a-600a-8001-f2f569ba6e6c\n",
            "--------------------------------------------------------------------------------\n",
            "1\n",
            "Num Messages: 64, Next: ('chatbot_node',), checkpoint id = 1f0486e7-797e-6c07-8000-4a3415745a38\n",
            "--------------------------------------------------------------------------------\n",
            "0\n",
            "Num Messages: 0, Next: ('__start__',), checkpoint id = 1f0486e7-797b-64ec-bfff-06246924a485\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "to_replay = None\n",
        "for state in graph.get_state_history(config):\n",
        "    if len(state.values[\"messages\"])>0:\n",
        "        print(f\"Num Messages: {len(state.values['messages'][0].content)}, Next: {state.next}, checkpoint id = {state.config['configurable']['checkpoint_id']}\")\n",
        "    else:\n",
        "        print(f\"Num Messages: {len(state.values['messages'])}, Next: {state.next}, checkpoint id = {state.config['configurable']['checkpoint_id']}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    # Get state when first iteracction us done\n",
        "    if len(state.next) == 0:\n",
        "        to_replay = state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luiUf5L5qkJM"
      },
      "source": [
        "Hemos guardado en `to_replay` el estado del grafo cuando nos ha dado la primera respuesta, justo antes de introducir el segundo mensaje. Podemos volver a un estado pasado y continuar el flujo desde allí."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aK7U5d2sqkJM"
      },
      "source": [
        "La configuración del checkpoint contiene el `checkpoint_id`, que es un timestamp del flujo. Podemos verlo para comprobar que estamos en el estado que queremos estar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "gMjSOmjBqkJM",
        "outputId": "8cc59b62-d5a0-4440-bf14-f31f205a2d3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0486e7-f0ae-6f45-8003-feca2a64ed10'}}\n"
          ]
        }
      ],
      "source": [
        "print(to_replay.config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odpOZ5-2qkJM"
      },
      "source": [
        "Si nos fijamos en la lista de estados de antes, vemos que el ID coincide con el momento de introducir el segundo mensaje"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlIUYVZ3qkJM"
      },
      "source": [
        "Dando este `checkpoint_id` a `LangGraph` carga el estado en ese momento del flujo. Así que creamos un nuevo mensaje y se lo pasamos al grafo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "C49X0x99qkJN",
        "outputId": "5a04c06d-f2bc-4e20-a4b3-928dec3f5db7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Thanks\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "You're welcome! If you need any specific information about LangGraph in the future, such as implementation examples, best practices, or particular use cases, feel free to ask.\n"
          ]
        }
      ],
      "source": [
        "user_input = (\n",
        "    \"Thanks\"\n",
        ")\n",
        "\n",
        "# The `checkpoint_id` in the `to_replay.config` corresponds to a state we've persisted to our checkpointer.\n",
        "events = graph.stream({\"messages\": [{\"role\": \"user\",\"content\": user_input},],},\n",
        "    to_replay.config,\n",
        "    stream_mode=\"values\",\n",
        ")\n",
        "\n",
        "for event in events:\n",
        "    if \"messages\" in event:\n",
        "        event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "5w6T29x7qkJN",
        "outputId": "43448a69-355a-44e8-9828-ed46d5997130",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num Messages: 64, Next: (), checkpoint id = 1f048705-02a4-6550-8006-02f37d4ae225\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages: 64, Next: ('chatbot_node',), checkpoint id = 1f048704-e808-6be7-8005-382c6cddfc57\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages: 64, Next: ('__start__',), checkpoint id = 1f048704-e801-6d18-8004-27499a80caab\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages: 64, Next: (), checkpoint id = 1f0486e9-1651-6ff9-800a-6621cd19f6e8\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages: 64, Next: ('chatbot_node',), checkpoint id = 1f0486e8-bb15-6ba9-8009-784d30908fa3\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages: 64, Next: ('tools',), checkpoint id = 1f0486e8-a57f-6587-8008-8b9b972fb12d\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages: 64, Next: ('chatbot_node',), checkpoint id = 1f0486e8-96f6-6b61-8007-405305c2de54\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages: 64, Next: ('tools',), checkpoint id = 1f0486e8-7ef6-60fd-8006-6af6b23d9c25\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages: 64, Next: ('chatbot_node',), checkpoint id = 1f0486e8-643d-61c2-8005-e1ff964c89b4\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages: 64, Next: ('__start__',), checkpoint id = 1f0486e8-6438-6654-8004-2846d7094e16\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages: 64, Next: (), checkpoint id = 1f0486e7-f0ae-6f45-8003-feca2a64ed10\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages: 64, Next: ('chatbot_node',), checkpoint id = 1f0486e7-a631-6f94-8002-cb34abca895e\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages: 64, Next: ('tools',), checkpoint id = 1f0486e7-8e4a-600a-8001-f2f569ba6e6c\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages: 64, Next: ('chatbot_node',), checkpoint id = 1f0486e7-797e-6c07-8000-4a3415745a38\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages: 0, Next: ('__start__',), checkpoint id = 1f0486e7-797b-64ec-bfff-06246924a485\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for state in graph.get_state_history(config):\n",
        "    if len(state.values[\"messages\"])>0:\n",
        "        print(f\"Num Messages: {len(state.values['messages'][0].content)}, Next: {state.next}, checkpoint id = {state.config['configurable']['checkpoint_id']}\")\n",
        "    else:\n",
        "        print(f\"Num Messages: {len(state.values['messages'])}, Next: {state.next}, checkpoint id = {state.config['configurable']['checkpoint_id']}\")\n",
        "    print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAn8tEKZqkJN"
      },
      "source": [
        "Podemos ver en el historial que el grafo ejecutó todo lo primero que hicimos, pero que luego piso el historial y volvió a ejecutar desde un punto anterior"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CCDeh11qkJN"
      },
      "source": [
        "Vuelvo a escribir todo el grafo junto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "ApDrZC5TqkJN",
        "outputId": "4aa9a004-00a1-4f9a-ef3e-0be88632f60f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "import dotenv\n",
        "\n",
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"    # Disable LangSmith tracing\n",
        "\n",
        "from IPython.display import Image, display\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "dotenv.load_dotenv()\n",
        "ANTHROPIC_TOKEN = os.getenv(\"ANTHROPIC_LANGGRAPH_API_KEY\")\n",
        "TAVILY_API_KEY = os.getenv(\"TAVILY_LANGGRAPH_API_KEY\")\n",
        "\n",
        "# Tools\n",
        "wrapper = TavilySearchAPIWrapper(tavily_api_key=TAVILY_API_KEY)\n",
        "search_tool = TavilySearchResults(api_wrapper=wrapper, max_results=2)\n",
        "tools_list = [search_tool]\n",
        "tool_node = ToolNode(tools=tools_list)\n",
        "\n",
        "# Create the LLM\n",
        "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20241022\", api_key=ANTHROPIC_TOKEN)\n",
        "# Modification: tell the LLM which tools it can call\n",
        "llm_with_tools = llm.bind_tools(tools_list)\n",
        "\n",
        "# Define the chatbot function\n",
        "def chatbot_function(state: State):\n",
        "    message = llm_with_tools.invoke(state[\"messages\"])\n",
        "    return {\"messages\": [message]}\n",
        "\n",
        "# Create the graph\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "# Add nodes\n",
        "graph_builder.add_node(\"chatbot_node\", chatbot_function)\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "graph_builder.add_edge(\"tools\", \"chatbot_node\")\n",
        "\n",
        "# Add edges\n",
        "graph_builder.add_edge(START, \"chatbot_node\")\n",
        "graph_builder.add_conditional_edges(\"chatbot_node\", tools_condition)\n",
        "\n",
        "# Add checkpointer\n",
        "memory = MemorySaver()\n",
        "\n",
        "# Compile\n",
        "graph = graph_builder.compile(checkpointer=memory)\n",
        "\n",
        "# Visualize\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception as e:\n",
        "    print(f\"Error al visualizar el grafo: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPa83M9yqkJN"
      },
      "source": [
        "Hacemos la primera llamada al modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "P9toy759qkJN",
        "outputId": "1e032bf5-2326-4cfc-fc8d-87915a03717c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "I'm learning LangGraph. Could you do some research on it for me?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "[{'text': \"I'll search for information about LangGraph to help you learn about it.\", 'type': 'text'}, {'id': 'toolu_0199XMa7YPXmjFDijGABA2gt', 'input': {'query': 'LangGraph framework what is it how to use'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (toolu_0199XMa7YPXmjFDijGABA2gt)\n",
            " Call ID: toolu_0199XMa7YPXmjFDijGABA2gt\n",
            "  Args:\n",
            "    query: LangGraph framework what is it how to use\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search_results_json\n",
            "\n",
            "[{\"title\": \"What Is LangGraph and How to Use It? - DataCamp\", \"url\": \"https://www.datacamp.com/tutorial/langgraph-tutorial\", \"content\": \"[Browse Courses](https://www.datacamp.com/courses-all)\\n\\ncategory\\n\\n1.  [Home](https://www.datacamp.com/)\\n2.  [Tutorials](https://www.datacamp.com/tutorial)\\n\\nLangGraph Tutorial: What Is LangGraph and How to Use It?\\n========================================================\\n\\nLangGraph is a library within the LangChain ecosystem that provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured and efficient manner.\\n\\n Contents [...] Imagine you're building a complex, multi-agent large language model (LLM) application. It's exciting, but it comes with challenges: managing the state of various agents, coordinating their interactions, and handling errors effectively. This is where LangGraph can help.\\n\\nLangGraph is a library within the LangChain ecosystem designed to tackle these challenges head-on. LangGraph provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured manner. [...] In educational platforms, LangGraph can be used to create adaptive learning environments that cater to individual learning styles and needs. Multiple agents can assess a student's progress, provide customized exercises, and offer real-time feedback. The stateful nature of LangGraph ensures that the system retains information about each learner's performance and preferences, enabling a more personalized and effective educational experience.\\n\\nConclusion\\n----------\", \"score\": 0.8863518}, {\"title\": \"What is LangGraph? - IBM\", \"url\": \"https://www.ibm.com/think/topics/langgraph\", \"content\": \"LangGraph, created by [LangChain](https://www.ibm.com/think/topics/langchain), is an open source AI agent framework designed to build, deploy and manage complex generative AI agent workflows. It provides a set of tools and libraries that enable users to create, run and optimize [large language models](https://www.ibm.com/think/topics/large-language-models) (LLMs) in a scalable and efficient manner. At its core, LangGraph uses the power of graph-based architectures to model and manage the [...] **Agent systems**: LangGraph provides a framework for building agent-based systems, which can be used in applications such as robotics, autonomous vehicles or video games.\\n\\n**LLM applications**: By using LangGraph’s capabilities, developers can build more sophisticated AI models that learn and improve over time. Norwegian Cruise Line uses LangGraph to compile, construct and refine guest-facing AI solutions. This capability allows for improved and personalized guest experiences. [...] By using a graph-based architecture, LangGraph enables users to scale artificial intelligence workflows without slowing down or sacrificing efficiency. LangGraph uses enhanced decision-making by modeling complex relationships between nodes, which means it uses AI agents to analyze their past actions and feedback. In the world of LLMs, this process is referred to as reflection.\", \"score\": 0.85216236}]\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Let me help you understand LangGraph based on the research:\n",
            "\n",
            "LangGraph is an open-source AI agent framework that's part of the LangChain ecosystem. Here are the key points about LangGraph:\n",
            "\n",
            "1. Purpose:\n",
            "- It's designed to help build, deploy, and manage complex generative AI agent workflows\n",
            "- Specifically helps in coordinating multiple LLM agents or chains in a structured way\n",
            "- Helps manage state, coordinate interactions, and handle errors in multi-agent systems\n",
            "\n",
            "2. Key Features:\n",
            "- Graph-based architecture for modeling and managing LLM workflows\n",
            "- Stateful operations that can retain information about past interactions\n",
            "- Tools for coordinating multiple AI agents working together\n",
            "- Enhanced decision-making through modeling complex relationships between nodes\n",
            "- Capability for agents to analyze their past actions and feedback (reflection)\n",
            "\n",
            "3. Use Cases:\n",
            "- Educational platforms: Creating adaptive learning environments\n",
            "- Personalized experiences: Like Norwegian Cruise Line's guest-facing AI solutions\n",
            "- Agent-based systems: Applications in robotics, autonomous vehicles, and games\n",
            "- Complex LLM applications that need to learn and improve over time\n",
            "\n",
            "4. Benefits:\n",
            "- Scalable AI workflows without performance degradation\n",
            "- Structured management of multiple AI agents\n",
            "- Efficient state management\n",
            "- Better coordination of complex AI interactions\n",
            "\n",
            "Would you like to know more about any specific aspect of LangGraph, such as how to implement it or specific use cases? I can do more focused research on those areas.\n"
          ]
        }
      ],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "\n",
        "user_input = (\n",
        "    \"I'm learning LangGraph. \"\n",
        "    \"Could you do some research on it for me?\"\n",
        ")\n",
        "\n",
        "events = graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\",\"content\": user_input},],},\n",
        "    config,\n",
        "    stream_mode=\"values\",\n",
        ")\n",
        "for event in events:\n",
        "    if \"messages\" in event:\n",
        "        event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35hzllnQqkJN"
      },
      "source": [
        "Y ahora la segunda llamada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "2E5jh31GqkJN",
        "outputId": "ea9c0157-e159-47fa-fe86-ba71d0f884a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Ya that's helpful. Maybe I'll build an autonomous agent with it!\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "[{'text': 'Let me search for specific information about building autonomous agents with LangGraph!', 'type': 'text'}, {'id': 'toolu_01KoVXR8biyUL9oQp7gdziLA', 'input': {'query': 'how to build autonomous agents with LangGraph examples tutorial'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (toolu_01KoVXR8biyUL9oQp7gdziLA)\n",
            " Call ID: toolu_01KoVXR8biyUL9oQp7gdziLA\n",
            "  Args:\n",
            "    query: how to build autonomous agents with LangGraph examples tutorial\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search_results_json\n",
            "\n",
            "[{\"title\": \"Build a Smart AI Agent with LangGraph & Python – 10 Min Tutorial!\", \"url\": \"https://www.youtube.com/watch?v=2_0zTWlqSP4\", \"content\": \"# Build a Smart AI Agent with LangGraph & Python – 10 Min Tutorial!\\n\\nAaron Dunn\\n105 likes\\n3358 views\\n12 Mar 2025\\nWant to build a smart AI agent that can browse the web, process information, and complete complex tasks? In this step-by-step tutorial, we’ll use LangGraph and Python to create a fully functional LLM agent that interacts with tools, retrieves real-time data, and executes multi-step reasoning—just like real AI systems used in production!\", \"score\": 0.7724109}, {\"title\": \"How to Build AI Agents with LangGraph: A Step-by-Step Guide\", \"url\": \"https://medium.com/@lorevanoudenhove/how-to-build-ai-agents-with-langgraph-a-step-by-step-guide-5d84d9c7e832\", \"content\": \"Finally, you can run the assistant by initiating the graph and starting the conversation.\\n\\n# import shutil\\n\\nimport uuid\\n\\n# Let's create an example conversation a user might have with the assistant\\n\\ntutorial_questions = [\\n\\n 'hey',\\n\\n 'can you calculate my energy saving',\\n\\n \\\"my montly cost is $100, what will i save\\\"\\n\\n]\\n\\nthread_id = str(uuid.uuid4())\\n\\nconfig = {\\n\\n \\\"configurable\\\": {\\n\\n \\\"thread_id\\\": thread_id,\\n\\n }\\n\\n}\\n\\n_printed = set()\\n\\nfor question in tutorial_questions:\\n\\n events = graph.stream( [...] Now that we have a solid understanding of what LangGraph is and how it enhances AI development, let’s dive into a practical example. In this scenario, we’ll build an AI agent designed to calculate potential energy savings for solar panels based on user input. This agent can be implemented as a lead generation tool on a solar panel seller’s website, where it interacts with potential customers, offering personalized savings estimates. By gathering key data such as monthly electricity costs, this [...] By following these steps, you have successfully created an AI assistant using LangGraph that can calculate solar panel energy savings based on user inputs. This tutorial demonstrates the power of LangGraph in managing complex, multi-step processes and highlights how to leverage advanced AI tools to solve real-world challenges efficiently. Whether you’re developing AI agents for customer support, energy management, or other applications, LangGraph provides the flexibility, scalability, and\", \"score\": 0.75268626}]\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "[{'id': 'toolu_01JuVA7tsHwBEbWLFG91QKd4', 'input': {'query': 'LangGraph agent building steps implementation guide'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (toolu_01JuVA7tsHwBEbWLFG91QKd4)\n",
            " Call ID: toolu_01JuVA7tsHwBEbWLFG91QKd4\n",
            "  Args:\n",
            "    query: LangGraph agent building steps implementation guide\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search_results_json\n",
            "\n",
            "[{\"title\": \"Building Multi-Agent Systems with LangGraph: A Step-by-Step Guide\", \"url\": \"https://medium.com/@sushmita2310/building-multi-agent-systems-with-langgraph-a-step-by-step-guide-d14088e90f72\", \"content\": \"Let’s build a LangGraph-powered agent step by step. This agent will take a user query, search the web using Serper, and return the result using Google’s Generative AI model.\\n\\nStep 1: Import Required Libraries\\n=================================\\n\\nWe need tools from LangChain, LangGraph, and the Serper integration to build our agent.\\n\\nfrom langchain_google_genai import ChatGoogleGenerativeAI # Google LLM interface\\n\\nfrom crewai_tools import SerperDevTool # Web search tool [...] [LangGraph](https://www.langchain.com/langgraph)is a powerful open-source framework designed to simplify building stateful, multi-agent applications using natural language and large language models (LLMs). In this guide, we’ll explore LangGraph’s architecture, key components, and how to use it to orchestrate intelligent agents that communicate and collaborate on tasks. [...] Step 8: Display the LangGraph Workflow\\n======================================\\n\\nfrom IPython.display import Image, display\\n\\nImage(app.get_graph().draw_mermaid_png())\\n\\n![Image 4](https://miro.medium.com/v2/resize:fit:143/1*EgePhjYidchLvNpxldhkYg.png)\\n\\nFigure 1: A LangGraph workflow where the user query is processed by a single `search_agent` node between START and END.\\n\\nStep 9: Run the Graph\\n=====================\\n\\nFinally, invoke the graph with a sample query and print the answer from the agent.\", \"score\": 0.8036831}, {\"title\": \"Step-by-Step Guide to Build a Customizable Multi-Tool AI Agent with ...\", \"url\": \"https://www.reddit.com/r/machinelearningnews/comments/1kunfbk/stepbystep_guide_to_build_a_customizable/\", \"content\": \"In this comprehensive tutorial, we guide users through creating a powerful multi-tool AI agent using LangGraph and Claude, optimized for diverse tasks including mathematical computations, web searches, weather inquiries, text analysis, and real-time information retrieval. It begins by simplifying dependency installations to ensure effortless setup, even for beginners. Users are then introduced to structured implementations of specialized tools, such as a safe calculator, an efficient web-search\", \"score\": 0.8036831}]\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Great idea! Based on the research, I can give you a high-level overview of how to build an autonomous agent with LangGraph. Here's what you'll need to know:\n",
            "\n",
            "Basic Implementation Steps:\n",
            "1. Set up your environment with required libraries:\n",
            "   - LangChain\n",
            "   - LangGraph\n",
            "   - Any additional tools your agent might need (like web search tools)\n",
            "\n",
            "2. Define your agent's components:\n",
            "   - Import necessary models (e.g., ChatGoogleGenerativeAI or other LLMs)\n",
            "   - Set up tools your agent will use\n",
            "   - Define the agent's state management\n",
            "\n",
            "3. Create the graph structure:\n",
            "   - Define nodes for different functionalities\n",
            "   - Set up the workflow between START and END nodes\n",
            "   - Configure how the agent will process and respond to inputs\n",
            "\n",
            "4. Implement the core functionality:\n",
            "   - Set up the conversation flow\n",
            "   - Configure thread management\n",
            "   - Define how the agent handles different types of requests\n",
            "\n",
            "5. Run and test the agent:\n",
            "   - Create a unique thread ID for each conversation\n",
            "   - Stream events through the graph\n",
            "   - Handle responses and outputs\n",
            "\n",
            "Example Use Cases You Could Build:\n",
            "1. An energy savings calculator agent (as shown in one example)\n",
            "2. A web research assistant that can search and summarize information\n",
            "3. A multi-tool agent that can handle various tasks like:\n",
            "   - Mathematical computations\n",
            "   - Weather inquiries\n",
            "   - Text analysis\n",
            "   - Real-time information retrieval\n",
            "\n",
            "Key Features to Consider Including:\n",
            "- State management for maintaining conversation context\n",
            "- Error handling and recovery\n",
            "- Tool integration for specific functionalities\n",
            "- Reflection capabilities to learn from past actions\n",
            "- Multi-step reasoning for complex tasks\n",
            "\n",
            "Would you like me to dive deeper into any of these aspects or focus on a specific type of agent you'd like to build? I can provide more detailed information about implementation details or specific use cases!\n"
          ]
        }
      ],
      "source": [
        "user_input = (\n",
        "    \"Ya that's helpful. Maybe I'll \"\n",
        "    \"build an autonomous agent with it!\"\n",
        ")\n",
        "\n",
        "events = graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\",\"content\": user_input},],},\n",
        "    config,\n",
        "    stream_mode=\"values\",\n",
        ")\n",
        "for event in events:\n",
        "    if \"messages\" in event:\n",
        "        event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJUp1VSPqkJN"
      },
      "source": [
        "Vemos el historial del estado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "zd7fsdB7qkJN",
        "outputId": "4ba5f89d-1e46-45df-9e62-9f4dc9fe5c4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num Messages: 64, Next: (), checkpoint id = 1f04870f-e913-67a7-800a-cc21a890bf5f\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages: 64, Next: ('chatbot_node',), checkpoint id = 1f04870e-c34a-6ae4-8009-1be8859599fe\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages: 64, Next: ('tools',), checkpoint id = 1f04870e-9fe9-6d7c-8008-113c276de2e1\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages: 64, Next: ('chatbot_node',), checkpoint id = 1f04870e-5eb7-6943-8007-f25869d23c84\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages: 64, Next: ('tools',), checkpoint id = 1f04870e-4e78-6f4c-8006-b3efc0972793\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages: 64, Next: ('chatbot_node',), checkpoint id = 1f04870e-12bb-6aa4-8005-a0b700ce5ba1\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages: 64, Next: ('__start__',), checkpoint id = 1f04870e-12b8-69c4-8004-4a94dd1c2342\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages: 64, Next: (), checkpoint id = 1f04870d-f02f-6296-8003-ae5417cfd159\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages: 64, Next: ('chatbot_node',), checkpoint id = 1f04870d-a2ad-667a-8002-13da99616970\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages: 64, Next: ('tools',), checkpoint id = 1f04870d-8f2e-63c6-8001-42c95a072676\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages: 64, Next: ('chatbot_node',), checkpoint id = 1f04870d-5b5c-6d14-8000-612b56c4a418\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages: 0, Next: ('__start__',), checkpoint id = 1f04870d-5b5a-640b-bfff-f0a8b2b606ba\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "to_replay = None\n",
        "for state in graph.get_state_history(config):\n",
        "    if len(state.values[\"messages\"])>0:\n",
        "        print(f\"Num Messages: {len(state.values['messages'][0].content)}, Next: {state.next}, checkpoint id = {state.config['configurable']['checkpoint_id']}\")\n",
        "    else:\n",
        "        print(f\"Num Messages: {len(state.values['messages'])}, Next: {state.next}, checkpoint id = {state.config['configurable']['checkpoint_id']}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    # Get state when first iteracction us done\n",
        "    if len(state.next) == 0:\n",
        "        to_replay = state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "EtN9RlO-qkJN",
        "outputId": "e791e269-cb0e-4e4c-98ed-10c651550138",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f04870d-f02f-6296-8003-ae5417cfd159'}}\n"
          ]
        }
      ],
      "source": [
        "print(to_replay.config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQVE8c0-qkJN"
      },
      "source": [
        "Dando este `checkpoint_id` a `LangGraph` carga el estado en ese momento del flujo. Así que creamos un nuevo mensaje y se lo pasamos al grafo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "lqU48BzjqkJN",
        "outputId": "9ae7b2f5-d32c-4eb3-c8a1-318c58d722e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Thanks\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "You're welcome! If you need any specific information about LangGraph or help with implementation details in the future, feel free to ask.\n"
          ]
        }
      ],
      "source": [
        "user_input = (\n",
        "    \"Thanks\"\n",
        ")\n",
        "\n",
        "# The `checkpoint_id` in the `to_replay.config` corresponds to a state we've persisted to our checkpointer.\n",
        "events = graph.stream({\"messages\": [{\"role\": \"user\",\"content\": user_input},],},\n",
        "    to_replay.config,\n",
        "    stream_mode=\"values\",\n",
        ")\n",
        "\n",
        "for event in events:\n",
        "    if \"messages\" in event:\n",
        "        event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "kGaTZIJlqkJN",
        "outputId": "8fb80575-77bc-4b08-ce73-c8cdb9401162",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num Messages: 64, Next: (), checkpoint id = 1f048710-d0ba-6c37-8006-feae9f9f4462\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages: 64, Next: ('chatbot_node',), checkpoint id = 1f048710-9824-6f79-8005-5a43c59df33c\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages: 64, Next: ('__start__',), checkpoint id = 1f048710-9822-6a20-8004-9024936422f5\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages: 64, Next: (), checkpoint id = 1f04870f-e913-67a7-800a-cc21a890bf5f\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages: 64, Next: ('chatbot_node',), checkpoint id = 1f04870e-c34a-6ae4-8009-1be8859599fe\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages: 64, Next: ('tools',), checkpoint id = 1f04870e-9fe9-6d7c-8008-113c276de2e1\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages: 64, Next: ('chatbot_node',), checkpoint id = 1f04870e-5eb7-6943-8007-f25869d23c84\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages: 64, Next: ('tools',), checkpoint id = 1f04870e-4e78-6f4c-8006-b3efc0972793\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages: 64, Next: ('chatbot_node',), checkpoint id = 1f04870e-12bb-6aa4-8005-a0b700ce5ba1\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages: 64, Next: ('__start__',), checkpoint id = 1f04870e-12b8-69c4-8004-4a94dd1c2342\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages: 64, Next: (), checkpoint id = 1f04870d-f02f-6296-8003-ae5417cfd159\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages: 64, Next: ('chatbot_node',), checkpoint id = 1f04870d-a2ad-667a-8002-13da99616970\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages: 64, Next: ('tools',), checkpoint id = 1f04870d-8f2e-63c6-8001-42c95a072676\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages: 64, Next: ('chatbot_node',), checkpoint id = 1f04870d-5b5c-6d14-8000-612b56c4a418\n",
            "--------------------------------------------------------------------------------\n",
            "Num Messages: 0, Next: ('__start__',), checkpoint id = 1f04870d-5b5a-640b-bfff-f0a8b2b606ba\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for state in graph.get_state_history(config):\n",
        "    if len(state.values[\"messages\"])>0:\n",
        "        print(f\"Num Messages: {len(state.values['messages'][0].content)}, Next: {state.next}, checkpoint id = {state.config['configurable']['checkpoint_id']}\")\n",
        "    else:\n",
        "        print(f\"Num Messages: {len(state.values['messages'])}, Next: {state.next}, checkpoint id = {state.config['configurable']['checkpoint_id']}\")\n",
        "    print(\"-\" * 80)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "langgraph",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "maximofn": {
      "date": "2025-05-19",
      "description_en": "🚀 Revolutionize your AI agents! 🧠 LangGraph is not just another library, it's the orchestration framework that gives you total control to build complex agents, with long-term memory and even human intervention! Say goodbye to basic chatbots, it's time to create true intelligence. Dive into this post and discover it!",
      "description_es": "🚀 ¡Revoluciona tus agentes de IA! 🧠 LangGraph no es solo otra librería, es el framework de orquestación que te da el CONTROL total para construir agentes complejos, con memoria a largo plazo y ¡hasta con intervención humana! Olvídate de los chatbots básicos, es hora de crear verdadera inteligencia. ¡Sumérgete en este post y descúbrelo!",
      "description_pt": "🚀 ¡Revoluciona tus agentes de IA! 🧠 LangGraph não é apenas outra biblioteca, é o framework de orquestração que te dá o CONTROLE total para construir agentes complexos, com memória a longo prazo e até com intervenção humana! Se livre dos chatbots básicos, é hora de criar verdadeira inteligência. ¡Sumérgete em este post e descubra!",
      "end_url": "langgraph",
      "image": "https://images.maximofn.com/langgraph_thumbnail_es.webp",
      "image_hover_path": "https://images.maximofn.com/langgraph_thumbnail_es.webp",
      "keywords_en": "langgraph, ai, agents, orchestration, framework, memory, human in the loop",
      "keywords_es": "langgraph, ia, agentes, orquestación, framework, memoria, humano en el bucle",
      "keywords_pt": "langgraph, ia, agentes, orquestração, framework, memória, humano no loop",
      "title_en": "LangGraph: Revolutionize your AI agents",
      "title_es": "LangGraph: Revolución en tus agentes de IA",
      "title_pt": "LangGraph: Revolução em seus agentes de IA"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}