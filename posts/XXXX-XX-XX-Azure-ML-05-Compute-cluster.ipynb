{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure ML - Compute Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loguearse a Azure ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como las acciones que vamos a hacer por CLI o a través del SDK de Python necesitan una autentificación, primero vamos a loguearnos en Azure ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Login en Azure ML con el CLI de Azure ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para logearnos en Azure hacemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se nos abrirá el navegador para logearnos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear un cliente de Azure ML con el SDK de Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero creamos dos variables con la ID de la suscripción y el grupo de recursos, como estos son datos personales, no los voy a poner aquí. Lo que voy a hacer es incluirlos en un archivo `.env` que no voy a subir a GitHub\n",
    "\n",
    "```bash\n",
    "AZURE_SUSCRIPION_ID=\"xxxxx-xxxx-xxxx-xxxx-xxxxx\"\n",
    "AZURE_ML_RESOURCE_GRPU_ID=\"xxxxx-xxxx-xxxx-xxxx-xxxxx\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora para leerlos primero necesitasos tener instalado `dotenv` que lo hacemos mediante `pip install python-dotenv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "AZURE_SUSCRIPION_ID = os.getenv(\"AZURE_SUSCRIPION_ID\")\n",
    "AZURE_ML_RESOURCE_GRPU_ID = os.getenv(\"AZURE_ML_RESOURCE_GRPU_ID\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos estas variables creamos un cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "workspace_name = \"azure-ml-workspace-Python-SDK\"\n",
    "\n",
    "ml_client = MLClient(DefaultAzureCredential(), AZURE_SUSCRIPION_ID, AZURE_ML_RESOURCE_GRPU_ID, workspace_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a volver a ver la arquitectura de `Azure ML`\n",
    "\n",
    "![Azure ML architecture concepts](https://images.maximofn.com/azureml-architecture-concepts.webp)\n",
    "\n",
    "Al igual que antes henmos creado un `Compute Instance`, ahora vamos a ver cómo crear un `Compute Cluster`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crear un `Compute Cluster` desde la interfaz gráfica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En `Azure ML studio` deberíamos tener el `Workspace` `Azure ML Workspace GUI`, así que entramos en él y pinchamos en el botón `New` y seleccionamos `Compute cluster`\n",
    " * En localización seleccionamos la misma que antes que el `Workspace`, en mi caso `France Central`\n",
    " * En `Virtual Machine tier` podemos seleccionar `Dedicated` para que garantice que siempre esté disponible, aunque es más caro, o `Low priority` que es más barato pero puede ser que no esté disponible\n",
    " * Seleccionamos el tipo de máquina, si `CPU` o `GPU`, en mi caso selecciono `GPU` para poder entrenar modelos\n",
    " * Seleccionamos el tipo de `GPU` que queremos, espero que cuando leas esto los filtros sean mejores y puedas filtrar por `VRAM`, pero cuando lo estoy escribiendo no está ese filtro básico. En mi caso, como no voy a hacer entrenamientos muy grandes elijo la `Standard_NC4as_T4_v3` que tiene una `Tesla T4` con `16GB` de `VRAM`\n",
    " * Pulsamos `Next`\n",
    " * Le ponemos un nombre, en mi caso le pondré `compute-cluster-GUI`\n",
    " * Ponemos el número mínimo de nodos. En mi caso pongo 0, así cuando no esté en uso no me cobrarán\n",
    " * Ponemos el número máximo de nodos. En mi caso pongo 4, aunque para el uso que le voy a dar en este post con 1 me sobra\n",
    " * Seleccionamos los segundos para que se reduzca el número de nodos, en mi caso pongo 60 segundos\n",
    " * Pulsamos `Create` para crear el cluster, tardará unos minutos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desafortunadamente por defecto no vamos a tener quota de máquinas con GPU. Por lo que aunque hayamos creado un cluster con GPU, no vamos a poder usarlo. Más adelante hablaremos de esto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando se crea hay una zona llamada `Applications` donde podemos elegir si ejecutar el cluster en `JupyterLab`, `Jupyter`, `vscode` en la web o `vscode` en local."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por otro lado, cuando se crea el cluster, se crea con el mínimo número de nodos que hayas configurado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crear un `Compute cluster` con el CLI de Azure ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos la `Compute instance` con el siguiente comando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K{| Finished ..\n",
      "  \"enable_node_public_ip\": true,\n",
      "  \"id\": \"/subscriptions/40018f20-6173-46c6-9434-ce9df3089dce/resourceGroups/rg-azure-ml/providers/Microsoft.MachineLearningServices/workspaces/azure-ml-workspace-CLI/computes/compute-instance-CLI\",\n",
      "  \"idle_time_before_scale_down\": 60,\n",
      "  \"location\": \"francecentral\",\n",
      "  \"max_instances\": 4,\n",
      "  \"min_instances\": 0,\n",
      "  \"name\": \"compute-instance-CLI\",\n",
      "  \"network_settings\": {},\n",
      "  \"provisioning_state\": \"Succeeded\",\n",
      "  \"resourceGroup\": \"rg-azure-ml\",\n",
      "  \"size\": \"Standard_E4ds_v4\",\n",
      "  \"ssh_public_access_enabled\": true,\n",
      "  \"tier\": \"dedicated\",\n",
      "  \"type\": \"amlcompute\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!GROUP='rg-azure-ml' && \\\n",
    "WORKSPACE='azure-ml-workspace-CLI' && \\\n",
    "NAME=\"compute-instance-CLI\" && \\\n",
    "SIZE=\"Standard_E4ds_v4\" && \\\n",
    "TYPE=\"AmlCompute\" && \\\n",
    "IDLE_BEFORE_SCALE_DOWN=\"60\" && \\\n",
    "MIN_NODES=\"0\" && \\\n",
    "MAX_NODES=\"4\" && \\\n",
    "az ml compute create --name $NAME --size $SIZE --type $TYPE --workspace-name $WORKSPACE --resource-group $GROUP --idle-time-before-scale-down $IDLE_BEFORE_SCALE_DOWN --min-instances $MIN_NODES --max-instances $MAX_NODES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desafortunadamente por defecto no vamos a tener quota de máquinas con GPU. Por lo que aunque hayamos creado un cluster con GPU, no vamos a poder usarlo. Más adelante hablaremos de esto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crear un `Compute cluster` con el SDK de Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el `Compute cluster` con el siguiente código. Lo llamo `compute-cluster-Python` y no `compute-cluster-Python-SDK` porque el nombre tienen que tener 24 caracteres como máximo. Además, este `Compute cluster` lo voy a crear con una GPU `Standard_NC8as_T4_v3` porque no me deja crear más `Compute instance`s con la GPU que he elegido antes en la misma suscripción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "compute_cluster_name = \"compute-cluster-Python\"\n",
    "size = \"Standard_E4ds_v4\"\n",
    "idle_time_before_scale_down = \"30\"\n",
    "type_compute = \"amlcompute\"\n",
    "location = \"francecentral\"\n",
    "min_nodes = 0\n",
    "max_nodes = 4\n",
    "tier=\"Dedicated\"\n",
    "\n",
    "compute_cluster = AmlCompute(\n",
    "    name=compute_cluster_name, \n",
    "    type=type_compute,\n",
    "    location=location,\n",
    "    size=size, \n",
    "    min_instances=min_nodes,\n",
    "    max_instances=max_nodes,\n",
    "    idle_time_before_scale_down=idle_time_before_scale_down,\n",
    "    tier=tier,\n",
    ")\n",
    "\n",
    "result = ml_client.begin_create_or_update(compute_cluster).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AmlCompute({'type': 'amlcompute', 'created_on': None, 'provisioning_state': 'Succeeded', 'provisioning_errors': None, 'name': 'compute-cluster-Python', 'description': None, 'tags': None, 'properties': {}, 'print_as_yaml': False, 'id': '/subscriptions/40018f20-6173-46c6-9434-ce9df3089dce/resourceGroups/rg-azure-ml/providers/Microsoft.MachineLearningServices/workspaces/azure-ml-workspace-Python-SDK/computes/compute-cluster-Python', 'Resource__source_path': '', 'base_path': '/home/maximofernandez/Documents/web/portafolio/posts', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x740169725750>, 'resource_id': None, 'location': 'francecentral', 'size': 'Standard_E4ds_v4', 'min_instances': 0, 'max_instances': 4, 'idle_time_before_scale_down': 30.0, 'identity': None, 'ssh_public_access_enabled': True, 'ssh_settings': None, 'network_settings': <azure.ai.ml.entities._compute.compute.NetworkSettings object at 0x74016a2c82d0>, 'tier': 'dedicated', 'enable_node_public_ip': True, 'subnet': None})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desafortunadamente por defecto no vamos a tener quota de máquinas con GPU. Por lo que aunque hayamos creado un cluster con GPU, no vamos a poder usarlo. Más adelante hablaremos de esto"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azure_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
