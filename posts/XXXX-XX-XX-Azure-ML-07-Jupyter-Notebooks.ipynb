{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure ML - Jupyter Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loguearse a Azure ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como las acciones que vamos a hacer por CLI o a través del SDK de Python necesitan una autentificación, primero vamos a loguearnos en Azure ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Login en Azure ML con el CLI de Azure ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para logearnos en Azure hacemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se nos abrirá el navegador para logearnos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear un cliente de Azure ML con el SDK de Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero creamos dos variables con la ID de la suscripción y el grupo de recursos, como estos son datos personales, no los voy a poner aquí. Lo que voy a hacer es incluirlos en un archivo `.env` que no voy a subir a GitHub\n",
    "\n",
    "```bash\n",
    "AZURE_SUSCRIPION_ID=\"xxxxx-xxxx-xxxx-xxxx-xxxxx\"\n",
    "AZURE_ML_RESOURCE_GRPU_ID=\"xxxxx-xxxx-xxxx-xxxx-xxxxx\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora para leerlos primero necesitasos tener instalado `dotenv` que lo hacemos mediante `pip install python-dotenv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "AZURE_SUSCRIPION_ID = os.getenv(\"AZURE_SUSCRIPION_ID\")\n",
    "AZURE_ML_RESOURCE_GRPU_ID = os.getenv(\"AZURE_ML_RESOURCE_GRPU_ID\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos estas variables creamos un cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "workspace_name = \"azure-ml-workspace-Python-SDK\"\n",
    "\n",
    "ml_client = MLClient(DefaultAzureCredential(), AZURE_SUSCRIPION_ID, AZURE_ML_RESOURCE_GRPU_ID, workspace_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta parte es la haremos con la interfaz gráfica, por lo que hazlo con el `Workspace` que quieras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En Studio seleccionamos `Notebooks` en la parte izquierda de la interfaz. Vemos que tenemos una zona con las carpetas y otra en la que podemos darle al botón de `+ Files` para crear nuevos archivos, de modo que le damos al botón, seleccionamos `Create new file`, ponemos un nombre, en mo caso pondré `image-classification.ipynb`, en `File type` seleccionamos `Notebook` y le damos a `Create`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que se nos ha creado un Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleccionar un `Compute Instance`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que tenemos que hacer es seleccionar un `Compute Instance` para ello pinchar en la zona de `Compute` de la parte superior del notebook. Nos aparecerán los `Compute Instance`s que hayamos creado, seleccionamos uno y le damos al botón de `Start`, tardará un poco en arrancar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez hemos levantado una `Compute Instance` tenemos que elegir un kernel, igual que cuando ejecutamos un Jupyter Notebook en local. Para ellos pinchamos en la zona de `Kernel` en la parte superior del notebook y seleccionamos el kernel que queramos. En mo caso voy a seleccionar `Python 3.10 - SDK v2`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este kernel es un entorno de conda, por lo que podemos crearnos nuevos si queremos. En la zona donde se ven las carpetas hay un botón con formade una terminal, si dejamos el botón encima aparece el texto `Open terminal`. Si le damos se nos abrirá la terminal de esa `Compute Instance`, por lo que podríamos crear nuevos entornos de conda si queremos. Luego podremos seleccionar esos entornos como kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En mi caso voy a usar el kernel `Python 3.10 - SDK v2`, abro la terminal e instalo las siguientes librerías\n",
    "\n",
    "```bash\n",
    "conda activate azureml_py310_sdkv2\n",
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "pip install torchinfo torchmetrics\n",
    "pip install mlflow azureml-mlflow\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si te fijas, en realidad hemos instalado las mismas librerías que en los `Environment`s que habíamos creadao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desafortunadamente, aunque estemos en `Azure ML`, hayamos creado un `Compute Instance` con GPU, como ya dijimos por defecto no tenemos quota para GPU. Yo la he pedido, pero a saber si me la dan, y si me la dan, a saber cuando. Además si tu estás mirando esto, seguramente estés en la misma situación, que aunque la pidas a saber si te la dan y cuándo. Así que voy a hacer un entreno de un modelo pequeño sobre un dataset pequeño para poder ejecutarlo todo en la CPU y no esperar mucho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dónde editar el Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También, cuando levantamos el `Compute Instance` se habilita una zona en la parte superior del notebook que pone `Edit in VS Code`. Si le damos se abrirá un menú en el que podemos seleccionar si editarlo en vscode en la web o en local. Haz lo que prefieras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación pondré el notebook que he usado para entrenar el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "from torchmetrics import Accuracy\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "import mlflow\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descargamos el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos una muestra del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 5\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+tnSX8OLbMNYttVknLna1ncxxqFwOoZCSc57iu30LT/COleErvxtHFfzTWkps7S3v0jkie7KblbCkZVRyQfyOMHzu4sb8Mks1lPH56+ah8goHUk/MowBjIPTjin2ei6lqGn3t9aWU01rZKrXEqLkRhjgZ/wA+p6CqcUMk8yQwxtJK7BERASzEnAAHc19BeBb7TNE1bw98OJrO21DUUuZry/nZAyWs4iZwiZzukXAUt25Ayelb4zeLrvw74vs7S1C7X09JWyoJ3GSQdwT0Arsvhn4M0zwx4eju7Bprl9VhguWnlIBKGMMqhegALMfXnk8VB430Tw94ciuvHn2JYdUsoCsByNrzt8qNsHV8nr0AycZAI8Y+DcrSfF3R5ZXLu/2ks7HJYmCTknuc1a+OtyZ/ibcRk58i1gjHt8m7/wBmrn9B+I/i3w3bLa6brMy2q8LBMqzIo9FDg7R9MU3xV8QfEXjK3gt9Xu0e3gfekMUSxruxjccDk4OOff1rK8P69e+Gdbt9X04xi7t93lmRNy/MpU8fQmjxBr1/4m1qbVtSdHu5wocogUfKoUYA9gK//9k=",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACJUlEQVR4AW1SPWgUURD+3u7b5P68Q40GjRrxJ/7gT6MIFlZWCgFBbARtoiI2FgYtFbQQbdTCwsLKyspYeBCIhkhAC8scsYrJGhPuf8+93bvbfeO83ZM7wSl2vvm+mfdmZx7QM2GahhAiIiYSMPuUHmR0nyaR7DFxAccaPKEXgBHBKMMM09P728rOnwhrPybfXoWgnsj4gis3jPi5k3t3WtVdHP/XntKbFCCNflFYA2zMzNCZfr4PS0inlQZyjxaP9dExlDiuyhj9RgvLz/45WMuEs6H/eWl00dqSkZowFH8ERQ0KHEBqbGHTjjAxFVVqjUt082aArKTLh4ebHSxrWgwk/s6H/V0qcaZbqVBWi5FZXf0czQyyWK843SmMv9c63yBgrn7VmBqlZou9hYOud2drQnPAlHdKO3LKwXf2fFx+pbDy8fYwB1fooWYE1YvBnM4CavaSvWY/PwSUvnDIuyKnqF7rizCXc2Snnr52aXvdzetkNkXCBva9e6lq6+uluh0STc+exgAkV1bX6AbkrfPzhUw4aPjJiufuyc6jHZcCZchP13cHfsczFQwzMzIRj5LbFVSBSLmrCTOEJGXAzAhYHchAqHI4dKRgNLGx6Xoq9ALRSD8GOtGpvwRUm7u9mcxuToU+hY3cz3u6GVZFJ/ACL0q7OBv8VtyrOx73YiHjeH5zG0T8yoaOjrXUhyL/A+u83gdVT73SqUa0U43M7mY01kP/Ay0+2f7mQAg1AAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "idx = randint(0, len(training_data))\n",
    "sample_img, label = training_data[idx]\n",
    "sample_img_PIL = ToPILImage()(sample_img)\n",
    "print(f\"Label: {label}\")\n",
    "sample_img_PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos la dimensión del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len_training_data = len(training_data)\n",
    "len_test_data = len(test_data)\n",
    "len_training_data, len_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos el número de clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 10, classes: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n"
     ]
    }
   ],
   "source": [
    "set_clases = set({})\n",
    "for i in range(len_training_data):\n",
    "    _, label = training_data[i]\n",
    "    set_clases.add(label)\n",
    "num_classes = len(set_clases)\n",
    "print(f\"Number of classes: {num_classes}, classes: {set_clases}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dejamos el código para crear un subset por si te quieres hacer un subset más pequeño"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "factor = 1\n",
    "subset_training_data = torch.utils.data.Subset(training_data, range(0, len_training_data//factor))\n",
    "subset_test_data = torch.utils.data.Subset(test_data, range(0, len_test_data//factor))\n",
    "\n",
    "len(subset_training_data), len(subset_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3750, 625)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BS = 16\n",
    "train_dataloader = DataLoader(subset_training_data, batch_size=BS, shuffle=True)\n",
    "test_dataloader = DataLoader(subset_test_data, batch_size=BS, shuffle=True)\n",
    "\n",
    "len(train_dataloader), len(test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        super(ImageClassifier, self).__init__()\n",
    "        self.imageClassifier = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(self.num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.imageClassifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos el modelo con una muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 1, 28, 28]), torch.Size([16, 10]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_batch = next(iter(train_dataloader))\n",
    "image_batch, label_batch = sample_batch\n",
    "model = ImageClassifier(num_classes)\n",
    "output = model(image_batch)\n",
    "image_batch.shape, output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos el modelo está en la CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funciones de entrenamiento y evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, metrics_fn, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        metric = metrics_fn(pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss = loss.item()\n",
    "            current = batch\n",
    "            step = batch // 100 * (epoch + 1)\n",
    "            print(f\"train loss: {loss:.4f}, train accuracy: {metric:.4f} [{current}/{len(dataloader)}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader, model, loss_fn, metrics_fn, epoch):\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    eval_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            eval_loss += loss_fn(pred, y).item()\n",
    "            eval_accuracy += metrics_fn(pred, y).item()\n",
    "\n",
    "    eval_loss /= num_batches\n",
    "    eval_accuracy /= num_batches\n",
    "\n",
    "    print(f\"eval loss: {eval_loss:.4f}, eval accuracy: {eval_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "LR = 1e-3\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "metrics_fn = Accuracy(task=\"multiclass\", num_classes=num_classes).to(device)\n",
    "model = ImageClassifier(num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "train loss: 2.2683, train accuracy: 0.3750 [0/3750]\n",
      "train loss: 0.5679, train accuracy: 0.8750 [100/3750]\n",
      "train loss: 0.5187, train accuracy: 0.8750 [200/3750]\n",
      "train loss: 0.5773, train accuracy: 0.7500 [300/3750]\n",
      "train loss: 0.2902, train accuracy: 0.8750 [400/3750]\n",
      "train loss: 0.7192, train accuracy: 0.7500 [500/3750]\n",
      "train loss: 0.5701, train accuracy: 0.7500 [600/3750]\n",
      "train loss: 0.3450, train accuracy: 0.9375 [700/3750]\n",
      "train loss: 0.4336, train accuracy: 0.7500 [800/3750]\n",
      "train loss: 0.4114, train accuracy: 0.8125 [900/3750]\n",
      "train loss: 0.5610, train accuracy: 0.8125 [1000/3750]\n",
      "train loss: 0.7050, train accuracy: 0.7500 [1100/3750]\n",
      "train loss: 0.1474, train accuracy: 1.0000 [1200/3750]\n",
      "train loss: 0.4820, train accuracy: 0.8750 [1300/3750]\n",
      "train loss: 0.5237, train accuracy: 0.9375 [1400/3750]\n",
      "train loss: 0.2627, train accuracy: 0.8125 [1500/3750]\n",
      "train loss: 0.9840, train accuracy: 0.8125 [1600/3750]\n",
      "train loss: 0.6027, train accuracy: 0.7500 [1700/3750]\n",
      "train loss: 0.5454, train accuracy: 0.7500 [1800/3750]\n",
      "train loss: 0.2977, train accuracy: 0.9375 [1900/3750]\n",
      "train loss: 0.3452, train accuracy: 0.8750 [2000/3750]\n",
      "train loss: 0.1860, train accuracy: 0.9375 [2100/3750]\n",
      "train loss: 0.2017, train accuracy: 0.9375 [2200/3750]\n",
      "train loss: 0.2491, train accuracy: 0.8125 [2300/3750]\n",
      "train loss: 0.7236, train accuracy: 0.8750 [2400/3750]\n",
      "train loss: 0.0904, train accuracy: 1.0000 [2500/3750]\n",
      "train loss: 0.1461, train accuracy: 1.0000 [2600/3750]\n",
      "train loss: 0.2187, train accuracy: 0.9375 [2700/3750]\n",
      "train loss: 0.3069, train accuracy: 0.8750 [2800/3750]\n",
      "train loss: 0.1170, train accuracy: 0.9375 [2900/3750]\n",
      "train loss: 0.3323, train accuracy: 0.8750 [3000/3750]\n",
      "train loss: 0.2540, train accuracy: 0.8750 [3100/3750]\n",
      "train loss: 0.2071, train accuracy: 0.8750 [3200/3750]\n",
      "train loss: 0.3470, train accuracy: 0.8125 [3300/3750]\n",
      "train loss: 0.2497, train accuracy: 0.9375 [3400/3750]\n",
      "train loss: 0.3669, train accuracy: 0.8125 [3500/3750]\n",
      "train loss: 0.5956, train accuracy: 0.6875 [3600/3750]\n",
      "train loss: 0.2337, train accuracy: 0.9375 [3700/3750]\n",
      "eval loss: 0.3066, eval accuracy: 0.8905\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "train loss: 0.2056, train accuracy: 0.9375 [0/3750]\n",
      "train loss: 0.1042, train accuracy: 0.9375 [100/3750]\n",
      "train loss: 0.3872, train accuracy: 0.8750 [200/3750]\n",
      "train loss: 0.1077, train accuracy: 0.9375 [300/3750]\n",
      "train loss: 0.2190, train accuracy: 0.9375 [400/3750]\n",
      "train loss: 0.3859, train accuracy: 0.7500 [500/3750]\n",
      "train loss: 0.3434, train accuracy: 0.8750 [600/3750]\n",
      "train loss: 0.1250, train accuracy: 0.9375 [700/3750]\n",
      "train loss: 0.0551, train accuracy: 1.0000 [800/3750]\n",
      "train loss: 0.1084, train accuracy: 0.9375 [900/3750]\n",
      "train loss: 0.2589, train accuracy: 0.8750 [1000/3750]\n",
      "train loss: 0.2512, train accuracy: 0.9375 [1100/3750]\n",
      "train loss: 0.1243, train accuracy: 1.0000 [1200/3750]\n",
      "train loss: 0.2385, train accuracy: 0.8750 [1300/3750]\n",
      "train loss: 0.0873, train accuracy: 1.0000 [1400/3750]\n",
      "train loss: 0.4327, train accuracy: 0.8750 [1500/3750]\n",
      "train loss: 0.0799, train accuracy: 1.0000 [1600/3750]\n",
      "train loss: 0.1680, train accuracy: 0.9375 [1700/3750]\n",
      "train loss: 0.3024, train accuracy: 0.9375 [1800/3750]\n",
      "train loss: 0.0716, train accuracy: 1.0000 [1900/3750]\n",
      "train loss: 0.1941, train accuracy: 0.9375 [2000/3750]\n",
      "train loss: 0.2016, train accuracy: 0.9375 [2100/3750]\n",
      "train loss: 0.1394, train accuracy: 0.9375 [2200/3750]\n",
      "train loss: 0.0667, train accuracy: 1.0000 [2300/3750]\n",
      "train loss: 0.3497, train accuracy: 0.8750 [2400/3750]\n",
      "train loss: 0.3286, train accuracy: 0.8750 [2500/3750]\n",
      "train loss: 0.2024, train accuracy: 0.8750 [2600/3750]\n",
      "train loss: 0.1918, train accuracy: 0.8750 [2700/3750]\n",
      "train loss: 0.1249, train accuracy: 0.9375 [2800/3750]\n",
      "train loss: 0.0539, train accuracy: 1.0000 [2900/3750]\n",
      "train loss: 0.0225, train accuracy: 1.0000 [3000/3750]\n",
      "train loss: 0.1376, train accuracy: 0.9375 [3100/3750]\n",
      "train loss: 0.1466, train accuracy: 0.8750 [3200/3750]\n",
      "train loss: 0.0849, train accuracy: 0.9375 [3300/3750]\n",
      "train loss: 0.0577, train accuracy: 1.0000 [3400/3750]\n",
      "train loss: 0.2098, train accuracy: 0.9375 [3500/3750]\n",
      "train loss: 0.0631, train accuracy: 1.0000 [3600/3750]\n",
      "train loss: 0.1845, train accuracy: 0.9375 [3700/3750]\n",
      "eval loss: 0.2798, eval accuracy: 0.9018\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "train loss: 0.0467, train accuracy: 1.0000 [0/3750]\n",
      "train loss: 0.1550, train accuracy: 0.8750 [100/3750]\n",
      "train loss: 0.0414, train accuracy: 1.0000 [200/3750]\n",
      "train loss: 0.2475, train accuracy: 0.9375 [300/3750]\n",
      "train loss: 0.5265, train accuracy: 0.8750 [400/3750]\n",
      "train loss: 0.4018, train accuracy: 0.9375 [500/3750]\n",
      "train loss: 0.0211, train accuracy: 1.0000 [600/3750]\n",
      "train loss: 0.1100, train accuracy: 0.9375 [700/3750]\n",
      "train loss: 0.2601, train accuracy: 0.9375 [800/3750]\n",
      "train loss: 0.0870, train accuracy: 0.9375 [900/3750]\n",
      "train loss: 0.4083, train accuracy: 0.8125 [1000/3750]\n",
      "train loss: 0.2577, train accuracy: 0.8750 [1100/3750]\n",
      "train loss: 0.1155, train accuracy: 1.0000 [1200/3750]\n",
      "train loss: 0.0776, train accuracy: 1.0000 [1300/3750]\n",
      "train loss: 0.3697, train accuracy: 0.8125 [1400/3750]\n",
      "train loss: 0.4671, train accuracy: 0.9375 [1500/3750]\n",
      "train loss: 0.0816, train accuracy: 0.9375 [1600/3750]\n",
      "train loss: 0.3219, train accuracy: 0.9375 [1700/3750]\n",
      "train loss: 0.2419, train accuracy: 0.8750 [1800/3750]\n",
      "train loss: 0.2335, train accuracy: 0.9375 [1900/3750]\n",
      "train loss: 0.3507, train accuracy: 0.8125 [2000/3750]\n",
      "train loss: 0.2562, train accuracy: 0.9375 [2100/3750]\n",
      "train loss: 0.2138, train accuracy: 0.8750 [2200/3750]\n",
      "train loss: 0.0559, train accuracy: 1.0000 [2300/3750]\n",
      "train loss: 0.1945, train accuracy: 0.9375 [2400/3750]\n",
      "train loss: 0.0693, train accuracy: 1.0000 [2500/3750]\n",
      "train loss: 0.0492, train accuracy: 1.0000 [2600/3750]\n",
      "train loss: 0.2190, train accuracy: 0.9375 [2700/3750]\n",
      "train loss: 0.1627, train accuracy: 0.8750 [2800/3750]\n",
      "train loss: 0.2145, train accuracy: 0.9375 [2900/3750]\n",
      "train loss: 0.0883, train accuracy: 0.9375 [3000/3750]\n",
      "train loss: 0.1097, train accuracy: 1.0000 [3100/3750]\n",
      "train loss: 0.1670, train accuracy: 0.9375 [3200/3750]\n",
      "train loss: 0.0116, train accuracy: 1.0000 [3300/3750]\n",
      "train loss: 0.5043, train accuracy: 0.7500 [3400/3750]\n",
      "train loss: 0.4234, train accuracy: 0.8750 [3500/3750]\n",
      "train loss: 0.1369, train accuracy: 0.9375 [3600/3750]\n",
      "train loss: 0.1831, train accuracy: 0.8750 [3700/3750]\n",
      "eval loss: 0.2801, eval accuracy: 0.9024\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, metrics_fn, optimizer, epoch)\n",
    "    evaluate(test_dataloader, model, loss_fn, metrics_fn, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prueba del modelo entrenado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos el modelos entrenado con una muestra del conjunto de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    idx = randint(0, len(subset_test_data))\n",
    "except:\n",
    "    print(idx, len(subset_test_data))\n",
    "sample_test_img, label = subset_test_data[idx]\n",
    "output = model(sample_test_img.to(output.device).unsqueeze(0))\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: 2, True label: 2\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APB7CxuNSv4bK1TfPMwVFzjn3PYe9e8+DzD4Y8PwaZ9j0ya5Vd09y0Jy7MzHBPUgDaAf0rzbx/oksupXXiG1trWCynKF7e3UIIGIC42gDIJHUdSeeTXD11vw5jVvFiuQCY4JGUnsSNufyJr1OdRnKYZezYxkdj+VZniKNLrwvqwkIZ/s5fGOyjIP5qK8Srr/AIb/APIyze1nKf5V6koBtoSCOYYznP8AsrWVrZA0bWBuBI05+B/vHmvE67T4YBW8UXCsoYHTrng+0ZIP5itKD4uazDbwwjSdGZUjVAWhlyQqgc/vPatO18UXHivw74pmvLGxga10rEf2ZGX70nJOWOTXk1f/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAB8UlEQVR4AV2SOW8TQRTH35tjd+2YxE5QgpyA4lAGEEg0EVSu+AYUfAaQaPko9DQ0CCHRgDiEqDgkhKDjEBCCIixfsMfszHuMdwxeMcXuaH7v/3/HDMJi9ftbev/53cUBLrb3z5IxcdJoA3I4FdWvCllTaZLErYcAcwZqrvTBb18dmQ7lzgj+U86Cr527N8mn6W13+Z/yb869S93y9flsFR/0Ng8ePw1+c9vejTfDH61ssr+xMiB5FZ9UNBQEVz6PckgnRk+0ovHHi0E5hyfsskRkFunW7rCTrsua8mSjILN7Kpeofx+NrYMzNbhnDKtv3wWzyl8kasns1OAgV8s2iZhnsyGI09UaXHOyW5BEY0vW3Gxzp4KhldhorVBGhBKsBiWjGlRQvOyUIKUAg+133EprtgJp3PQz1JIEKf6lQofhi4oKXTpi0loAT5WrKUEb02AEBCsILegAQ0FOEEkROSiJQVDh25mtYOvjlXAWvMiiRSHqSu+DTnIZaRZO+MsOsw220vsRalaz8ZiNlSJcc7AFxVlDRolEH7z04bBZVjmDErQo8rwk4RhcljkZCgpQF1ncHTUFcunSTo+y8P7mObcfyXU/HGYG2vzy9fj7mi1duJOePtj2poD5MdXtP6vBwSd78xY7h/6tUOvn9cNxBf8Ak7jY+Exh2LAAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_label = torch.argmax(output, dim=1).item()\n",
    "print(f\"Predicted label: {predicted_label}, True label: {label}\")\n",
    "sample_test_img_PIL = ToPILImage()(sample_test_img)\n",
    "sample_test_img_PIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos el entrenamiento ha sido exitoso"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azure_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
