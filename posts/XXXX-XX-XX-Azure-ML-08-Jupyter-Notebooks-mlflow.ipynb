{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure ML - Jupyter Notebooks - mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loguearse a Azure ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como las acciones que vamos a hacer por CLI o a través del SDK de Python necesitan una autentificación, primero vamos a loguearnos en Azure ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Login en Azure ML con el CLI de Azure ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para logearnos en Azure hacemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se nos abrirá el navegador para logearnos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear un cliente de Azure ML con el SDK de Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero creamos dos variables con la ID de la suscripción y el grupo de recursos, como estos son datos personales, no los voy a poner aquí. Lo que voy a hacer es incluirlos en un archivo `.env` que no voy a subir a GitHub\n",
    "\n",
    "```bash\n",
    "AZURE_SUSCRIPION_ID=\"xxxxx-xxxx-xxxx-xxxx-xxxxx\"\n",
    "AZURE_ML_RESOURCE_GRPU_ID=\"xxxxx-xxxx-xxxx-xxxx-xxxxx\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora para leerlos primero necesitasos tener instalado `dotenv` que lo hacemos mediante `pip install python-dotenv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "AZURE_SUSCRIPION_ID = os.getenv(\"AZURE_SUSCRIPION_ID\")\n",
    "AZURE_ML_RESOURCE_GRPU_ID = os.getenv(\"AZURE_ML_RESOURCE_GRPU_ID\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos estas variables creamos un cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "workspace_name = \"azure-ml-workspace-Python-SDK\"\n",
    "\n",
    "ml_client = MLClient(DefaultAzureCredential(), AZURE_SUSCRIPION_ID, AZURE_ML_RESOURCE_GRPU_ID, workspace_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Notebooks mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta parte es la haremos con la interfaz gráfica, por lo que hazlo con el `Workspace` que quieras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos visto cómo hacer un entrenamiento básico con un Jupyter Notebook, ahora vamos a ver cómo hacerlo con `mlflow` para poder hacer seguimiento del entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En Studio seleccionamos `Notebooks` en la parte izquierda de la interfaz. Vemos que tenemos una zona con las carpetas y otra en la que podemos darle al botón de `+ Files` para crear nuevos archivos, de modo que le damos al botón, seleccionamos `Create new file`, ponemos un nombre, en mo caso pondré `image-classification-mlflow.ipynb`, en `File type` seleccionamos `Notebook` y le damos a `Create`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que se nos ha creado un Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleccionar un `Compute Instance`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que tenemos que hacer es seleccionar un `Compute Instance` para ello pinchar en la zona de `Compute` de la parte superior del notebook. Nos aparecerán los `Compute Instance`s que hayamos creado, seleccionamos uno y le damos al botón de `Start`, tardará un poco en arrancar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez hemos levantado una `Compute Instance` tenemos que elegir un kernel, igual que cuando ejecutamos un Jupyter Notebook en local. Para ellos pinchamos en la zona de `Kernel` en la parte superior del notebook y seleccionamos el kernel que queramos. En mo caso voy a seleccionar `Python 3.10 - SDK v2`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este kernel es un entorno de conda, por lo que podemos crearnos nuevos si queremos. En la zona donde se ven las carpetas hay un botón con formade una terminal, si dejamos el botón encima aparece el texto `Open terminal`. Si le damos se nos abrirá la terminal de esa `Compute Instance`, por lo que podríamos crear nuevos entornos de conda si queremos. Luego podremos seleccionar esos entornos como kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En mi caso voy a usar el kernel `Python 3.10 - SDK v2`, abro la terminal e instalo las siguientes librerías\n",
    "\n",
    "```bash\n",
    "conda activate azureml_py310_sdkv2\n",
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "pip install mlflow azureml-mlflow\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dónde editar el Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También, cuando levantamos el `Compute Instance` se habilita una zona en la parte superior del notebook que pone `Edit in VS Code`. Si le damos se abrirá un menú en el que podemos seleccionar si editarlo en vscode en la web o en local. Haz lo que prefieras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación pondré el notebook que he usado para entrenar el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "from torchmetrics import Accuracy\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "import mlflow\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descargamos el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos una muestra del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APH/AA9oaanDJP5to8sb7Ra3MxhDDGS2/gcemR3r0DQ/EupaDZfYAnhKSBNxiSS7fEeSSR8pwRnJ9eevSud1aKXxFf3N/qlz4d8yY75rm2mIeNcAfLGCN2AAAMEk9e5rhJkSOeRI33orEK+Mbh2OK2tF16SzENk9hZXMJkxue3XzlDcNtcDdnHTOcdRzXTz2UHmOIvAV/LhiNxa7Oeayb+5Ok25li8LLYTFhGXvIXlQggnGyUFd3AweuAa5i8u5r66e5nKGR8Z2Rqg4GBhVAA4HYVEjbXVskYOcivQLmawaaVZPGd2mHPypbE4/OQVz2uyWzWSrBr1zqH70Hy5Y9oAwfm++ef8etc9RXbSeLb8vk29gzEZLNaITk/UVja3rt3qFuttNHbLGGD/uoFQ5Ge4HvWFX/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACOElEQVR4AVVSTWtTQRS989689/KdWDDFgjaoBNPWBhuEov9AxKX0D4jdCC7EX1Bc+QvaleBGETcK4sKN0JUQkYI1YiPGkJIPkrxIkvfm05l5iZJZzNyZM/ecO+cOArC5JUCN506y5Y432nf1xgwMYDBn/eyVo2HRIaULpVT3NwckAZC5Ui6uw3H3hXDc5OHji5dZUH+tUQPGrsn+hPuTzTJ8/AUpiXM9yowUwI1H9kzk3+Lt76pYacJWZe9NOptZCrxwWY6STTT8ebtfU4Cmvend2pqM+tCMk/TodJWlU+erB7gzNWApIQuNHlEqSFCgDrPXWoOAGdr8+BgQjocICSY4ZxzbtSFcqrxUpHCv8Wz3fTGhQ7C9VC4NsP/51bu9SHNte/tTdkMkbAkWqkOhU6u1TnvqamQCwFPcdYNwTDmlMa/8wNBoECEp4XqmAWNLcskQEfk6WOpMv1Mv4Oc4A0FCbWmMIznzRzMgWLnq6sDSEzhmjhxSZ7yy016RDrY44d/Ccw9NU4x9ihlOfgxGhEyEpJaDvIVMAc3qdyTZVAITmOpCNK6NV5oy8MdEpalq1c9YzNSVtB1pC+ECYjLrm5SZCZbIPyGigCzA1lcJ3v3FgjrNDvpCPeZTzGmwoKlYjk7+2K7NOWExSSPW//NmDuz54+e/Zl4t7BwyFmDVbpGkS28D85UjUBPccQU7I0hAk63VD0pVjQhUT67GfSxwSKY42cwNIhOifqpeLGcmoeq1lDYfImIS4S+m6gFxJeYrpQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "idx = randint(0, len(training_data))\n",
    "sample_img, label = training_data[idx]\n",
    "sample_img_PIL = ToPILImage()(sample_img)\n",
    "print(f\"Label: {label}\")\n",
    "sample_img_PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos la dimensión del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len_training_data = len(training_data)\n",
    "len_test_data = len(test_data)\n",
    "len_training_data, len_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos el número de clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 10, classes: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n"
     ]
    }
   ],
   "source": [
    "set_clases = set({})\n",
    "for i in range(len_training_data):\n",
    "    _, label = training_data[i]\n",
    "    set_clases.add(label)\n",
    "num_classes = len(set_clases)\n",
    "print(f\"Number of classes: {num_classes}, classes: {set_clases}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dejamos el código para crear un subset por si te quieres hacer un subset más pequeño"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "factor = 1\n",
    "subset_training_data = torch.utils.data.Subset(training_data, range(0, len_training_data//factor))\n",
    "subset_test_data = torch.utils.data.Subset(test_data, range(0, len_test_data//factor))\n",
    "\n",
    "len(subset_training_data), len(subset_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3750, 625)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BS = 16\n",
    "train_dataloader = DataLoader(subset_training_data, batch_size=BS, shuffle=True)\n",
    "test_dataloader = DataLoader(subset_test_data, batch_size=BS, shuffle=True)\n",
    "\n",
    "len(train_dataloader), len(test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        super(ImageClassifier, self).__init__()\n",
    "        self.imageClassifier = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(self.num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.imageClassifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos el modelo con una muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 1, 28, 28]), torch.Size([16, 10]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_batch = next(iter(train_dataloader))\n",
    "image_batch, label_batch = sample_batch\n",
    "model = ImageClassifier(num_classes)\n",
    "output = model(image_batch)\n",
    "image_batch.shape, output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/09 09:42:14 WARNING mlflow.utils.autologging_utils: MLflow pytorch autologging is known to be compatible with 1.9.0 <= torch <= 2.4.0, but the installed version is 2.5.1. If you encounter errors during autologging, try upgrading / downgrading torch to a compatible version, or try upgrading MLflow.\n"
     ]
    }
   ],
   "source": [
    "mlflow.pytorch.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí pon tus valores para `SUSCRIPTION_ID`, `RESOURCE_GROUP` y `WORKSPACE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUSCRIPTION_ID = \"\"\n",
    "RESOURCE_GROUP = \"\"\n",
    "WORKSPACE = \"\"\n",
    "mlflow.set_tracking_uri = f\"azureml://francecentral.api.azureml.ms/mlflow/v1.0/subscriptions/{SUSCRIPTION_ID}/resourceGroups/{RESOURCE_GROUP}/providers/Microsoft.MachineLearningServices/workspaces/{WORKSPACE}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azureml/mlflow/_protos/aml_service_pb2.py:10: UserWarning: google.protobuf.service module is deprecated. RPC implementations should provide code generator plugins which generate code specific to the RPC implementation. service.py will be removed in Jan 2025\n",
      "  from google.protobuf import service as _service\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='', creation_time=1731141371877, experiment_id='ba0ceff2-ddbe-4308-9a4f-6a846a2dd0c7', last_update_time=None, lifecycle_stage='active', name='image-classification', tags={}>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlflow.set_experiment(experiment_name=\"image-classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos el modelo está en la CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funciones de entrenamiento y evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, metrics_fn, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        metric = metrics_fn(pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss = loss.item()\n",
    "            current = batch\n",
    "            step = batch // 1000 * (epoch + 1)\n",
    "            mlflow.log_metric(\"train_loss\", f\"{loss:.4f}\", step=step)\n",
    "            mlflow.log_metric(\"train_accuracy\", f\"{metric:.4f}\", step=step)\n",
    "            print(f\"train loss: {loss:.4f}, train accuracy: {metric:.4f} [{current}/{len(dataloader)}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader, model, loss_fn, metrics_fn, epoch):\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    eval_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            eval_loss += loss_fn(pred, y).item()\n",
    "            eval_accuracy += metrics_fn(pred, y).item()\n",
    "\n",
    "    eval_loss /= num_batches\n",
    "    eval_accuracy /= num_batches\n",
    "    mlflow.log_metric(\"eval_loss\", f\"{eval_loss:.4f}\", step=epoch)\n",
    "    mlflow.log_metric(\"eval_accuracy\", f\"{eval_accuracy:.4f}\", step=epoch)\n",
    "\n",
    "    print(f\"eval loss: {eval_loss:.4f}, eval accuracy: {eval_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "LR = 1e-3\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "metrics_fn = Accuracy(task=\"multiclass\", num_classes=num_classes).to(device)\n",
    "model = ImageClassifier(num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "train loss: 2.3623, train accuracy: 0.0625 [0/3750]\n",
      "train loss: 0.4929, train accuracy: 0.8750 [100/3750]\n",
      "train loss: 0.4513, train accuracy: 0.8750 [200/3750]\n",
      "train loss: 0.6159, train accuracy: 0.7500 [300/3750]\n",
      "train loss: 0.2675, train accuracy: 0.8750 [400/3750]\n",
      "train loss: 0.2816, train accuracy: 0.8750 [500/3750]\n",
      "train loss: 0.2231, train accuracy: 0.9375 [600/3750]\n",
      "train loss: 0.5147, train accuracy: 0.6875 [700/3750]\n",
      "train loss: 0.4221, train accuracy: 0.8750 [800/3750]\n",
      "train loss: 0.1267, train accuracy: 1.0000 [900/3750]\n",
      "train loss: 0.3912, train accuracy: 0.8750 [1000/3750]\n",
      "train loss: 1.0029, train accuracy: 0.6250 [1100/3750]\n",
      "train loss: 0.1412, train accuracy: 1.0000 [1200/3750]\n",
      "train loss: 0.2537, train accuracy: 0.8125 [1300/3750]\n",
      "train loss: 0.3991, train accuracy: 0.6875 [1400/3750]\n",
      "train loss: 0.2171, train accuracy: 0.9375 [1500/3750]\n",
      "train loss: 0.3148, train accuracy: 0.8750 [1600/3750]\n",
      "train loss: 0.2962, train accuracy: 0.9375 [1700/3750]\n",
      "train loss: 0.6517, train accuracy: 0.7500 [1800/3750]\n",
      "train loss: 0.4082, train accuracy: 0.8750 [1900/3750]\n",
      "train loss: 0.1639, train accuracy: 0.8750 [2000/3750]\n",
      "train loss: 0.2061, train accuracy: 0.9375 [2100/3750]\n",
      "train loss: 0.1150, train accuracy: 1.0000 [2200/3750]\n",
      "train loss: 0.2200, train accuracy: 0.8750 [2300/3750]\n",
      "train loss: 0.3156, train accuracy: 0.9375 [2400/3750]\n",
      "train loss: 0.1665, train accuracy: 0.9375 [2500/3750]\n",
      "train loss: 0.5031, train accuracy: 0.7500 [2600/3750]\n",
      "train loss: 0.4877, train accuracy: 0.8750 [2700/3750]\n",
      "train loss: 0.3961, train accuracy: 0.8750 [2800/3750]\n",
      "train loss: 0.4473, train accuracy: 0.8125 [2900/3750]\n",
      "train loss: 0.1523, train accuracy: 0.9375 [3000/3750]\n",
      "train loss: 0.2188, train accuracy: 0.8750 [3100/3750]\n",
      "train loss: 0.2436, train accuracy: 0.8750 [3200/3750]\n",
      "train loss: 0.3093, train accuracy: 0.9375 [3300/3750]\n",
      "train loss: 0.3131, train accuracy: 0.8750 [3400/3750]\n",
      "train loss: 0.3726, train accuracy: 0.8125 [3500/3750]\n",
      "train loss: 0.2582, train accuracy: 0.9375 [3600/3750]\n",
      "train loss: 0.2596, train accuracy: 0.8125 [3700/3750]\n",
      "eval loss: 0.3139, eval accuracy: 0.8884\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "train loss: 0.2148, train accuracy: 0.9375 [0/3750]\n",
      "train loss: 0.5943, train accuracy: 0.8125 [100/3750]\n",
      "train loss: 0.1100, train accuracy: 1.0000 [200/3750]\n",
      "train loss: 0.2512, train accuracy: 0.8750 [300/3750]\n",
      "train loss: 0.3152, train accuracy: 0.8750 [400/3750]\n",
      "train loss: 0.6021, train accuracy: 0.8125 [500/3750]\n",
      "train loss: 0.0645, train accuracy: 0.9375 [600/3750]\n",
      "train loss: 0.1431, train accuracy: 0.9375 [700/3750]\n",
      "train loss: 0.2588, train accuracy: 0.8750 [800/3750]\n",
      "train loss: 0.3870, train accuracy: 0.8750 [900/3750]\n",
      "train loss: 0.4990, train accuracy: 0.8750 [1000/3750]\n",
      "train loss: 0.2030, train accuracy: 0.8750 [1100/3750]\n",
      "train loss: 0.4924, train accuracy: 0.8750 [1200/3750]\n",
      "train loss: 0.2795, train accuracy: 0.9375 [1300/3750]\n",
      "train loss: 0.1306, train accuracy: 0.9375 [1400/3750]\n",
      "train loss: 0.1574, train accuracy: 0.9375 [1500/3750]\n",
      "train loss: 0.0618, train accuracy: 1.0000 [1600/3750]\n",
      "train loss: 0.2075, train accuracy: 0.9375 [1700/3750]\n",
      "train loss: 0.2181, train accuracy: 0.9375 [1800/3750]\n",
      "train loss: 0.7746, train accuracy: 0.7500 [1900/3750]\n",
      "train loss: 0.2126, train accuracy: 0.9375 [2000/3750]\n",
      "train loss: 0.3604, train accuracy: 0.8125 [2100/3750]\n",
      "train loss: 0.2154, train accuracy: 0.9375 [2200/3750]\n",
      "train loss: 0.3402, train accuracy: 0.8750 [2300/3750]\n",
      "train loss: 0.3194, train accuracy: 0.8750 [2400/3750]\n",
      "train loss: 0.6013, train accuracy: 0.8125 [2500/3750]\n",
      "train loss: 0.1139, train accuracy: 0.9375 [2600/3750]\n",
      "train loss: 0.1094, train accuracy: 0.9375 [2700/3750]\n",
      "train loss: 0.1775, train accuracy: 0.8750 [2800/3750]\n",
      "train loss: 0.2579, train accuracy: 0.8750 [2900/3750]\n",
      "train loss: 0.0223, train accuracy: 1.0000 [3000/3750]\n",
      "train loss: 0.0548, train accuracy: 1.0000 [3100/3750]\n",
      "train loss: 0.3312, train accuracy: 0.9375 [3200/3750]\n",
      "train loss: 0.2351, train accuracy: 0.8750 [3300/3750]\n",
      "train loss: 0.0968, train accuracy: 1.0000 [3400/3750]\n",
      "train loss: 0.3619, train accuracy: 0.8750 [3500/3750]\n",
      "train loss: 0.1909, train accuracy: 0.8750 [3600/3750]\n",
      "train loss: 0.3259, train accuracy: 0.8750 [3700/3750]\n",
      "eval loss: 0.2815, eval accuracy: 0.8996\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "train loss: 0.2559, train accuracy: 0.8125 [0/3750]\n",
      "train loss: 0.0362, train accuracy: 1.0000 [100/3750]\n",
      "train loss: 0.1785, train accuracy: 0.9375 [200/3750]\n",
      "train loss: 0.0524, train accuracy: 1.0000 [300/3750]\n",
      "train loss: 0.1018, train accuracy: 0.9375 [400/3750]\n",
      "train loss: 0.0163, train accuracy: 1.0000 [500/3750]\n",
      "train loss: 0.0499, train accuracy: 1.0000 [600/3750]\n",
      "train loss: 0.4869, train accuracy: 0.9375 [700/3750]\n",
      "train loss: 0.1211, train accuracy: 1.0000 [800/3750]\n",
      "train loss: 0.3638, train accuracy: 0.9375 [900/3750]\n",
      "train loss: 0.2499, train accuracy: 0.8750 [1000/3750]\n",
      "train loss: 0.1872, train accuracy: 0.9375 [1100/3750]\n",
      "train loss: 0.6748, train accuracy: 0.7500 [1200/3750]\n",
      "train loss: 0.1818, train accuracy: 0.8750 [1300/3750]\n",
      "train loss: 0.0065, train accuracy: 1.0000 [1400/3750]\n",
      "train loss: 0.2800, train accuracy: 0.8750 [1500/3750]\n",
      "train loss: 0.1808, train accuracy: 0.8750 [1600/3750]\n",
      "train loss: 0.0116, train accuracy: 1.0000 [1700/3750]\n",
      "train loss: 0.0586, train accuracy: 0.9375 [1800/3750]\n",
      "train loss: 0.4188, train accuracy: 0.7500 [1900/3750]\n",
      "train loss: 0.4493, train accuracy: 0.8750 [2000/3750]\n",
      "train loss: 0.1486, train accuracy: 0.9375 [2100/3750]\n",
      "train loss: 0.1153, train accuracy: 1.0000 [2200/3750]\n",
      "train loss: 0.2988, train accuracy: 0.9375 [2300/3750]\n",
      "train loss: 0.0465, train accuracy: 1.0000 [2400/3750]\n",
      "train loss: 0.0468, train accuracy: 1.0000 [2500/3750]\n",
      "train loss: 0.1936, train accuracy: 0.9375 [2600/3750]\n",
      "train loss: 0.1015, train accuracy: 0.9375 [2700/3750]\n",
      "train loss: 0.2541, train accuracy: 0.9375 [2800/3750]\n",
      "train loss: 0.0960, train accuracy: 1.0000 [2900/3750]\n",
      "train loss: 0.3591, train accuracy: 0.8750 [3000/3750]\n",
      "train loss: 0.4975, train accuracy: 0.8750 [3100/3750]\n",
      "train loss: 0.1078, train accuracy: 1.0000 [3200/3750]\n",
      "train loss: 0.0961, train accuracy: 0.9375 [3300/3750]\n",
      "train loss: 0.2846, train accuracy: 0.8750 [3400/3750]\n",
      "train loss: 0.0279, train accuracy: 1.0000 [3500/3750]\n",
      "train loss: 0.0124, train accuracy: 1.0000 [3600/3750]\n",
      "train loss: 0.0795, train accuracy: 0.9375 [3700/3750]\n",
      "eval loss: 0.2728, eval accuracy: 0.9048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 8/8 [00:00<00:00, 37.25it/s]   \n",
      "2024/11/09 09:44:37 INFO mlflow.tracking._tracking_service.client: 🏃 View run image_classification_2024-11-09_09:42:15 at: https://francecentral.api.azureml.ms/mlflow/v2.0/subscriptions/40018f20-6173-46c6-9434-ce9df3089dce/resourceGroups/rg-azure-ml/providers/Microsoft.MachineLearningServices/workspaces/azure-ml-workspace-gui-/#/experiments/ba0ceff2-ddbe-4308-9a4f-6a846a2dd0c7/runs/15cf21b0-576e-420b-b4f1-aaeef2352ddc.\n",
      "2024/11/09 09:44:37 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://francecentral.api.azureml.ms/mlflow/v2.0/subscriptions/40018f20-6173-46c6-9434-ce9df3089dce/resourceGroups/rg-azure-ml/providers/Microsoft.MachineLearningServices/workspaces/azure-ml-workspace-gui-/#/experiments/ba0ceff2-ddbe-4308-9a4f-6a846a2dd0c7.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "name = f\"image_classification_{datetime.now().strftime('%Y-%m-%d_%H:%M:%S')}\"\n",
    "with mlflow.start_run(run_name=name) as run:\n",
    "    params = {\n",
    "        \"epochs\": epochs,\n",
    "        \"learning_rate\": LR,\n",
    "        \"batch_size\": BS,\n",
    "        \"num_classes\": num_classes,\n",
    "        \"loss_fn\": loss_fn.__class__.__name__,\n",
    "        \"metrics_fn\": metrics_fn.__class__.__name__,\n",
    "        \"optimizer\": \"Adam\",\n",
    "    }\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    with open(\"model_summary.txt\", \"w\") as f:\n",
    "        f.write(str(summary(model, input_size=(BS, 1, 28, 28), device=device)))\n",
    "    mlflow.log_artifact(\"model_summary.txt\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
    "        train(train_dataloader, model, loss_fn, metrics_fn, optimizer, epoch)\n",
    "        evaluate(test_dataloader, model, loss_fn, metrics_fn, epoch)\n",
    "    \n",
    "    mlflow.pytorch.log_model(model, \"models\", input_example=image_batch.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si aquí nos vamos a la sección de `Jobs` de nuestro `Workspace` veremos que se ha creado un nuevo `Experiment` con el nombre que le hemos dado. Dentro en la pestaña `Metrics` podremos ver gráfcas las métricas que hemos ido guardando y en la pestaña `Outputs + logs` podremos ver los logs de la ejecución y una carpeta llamada `models` con el modelo guardado del experimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo bueno de mlflow es que tiene integración con la mayoría de librerías de machine learning, por lo que este modelo después puede ser importado a través de mlflow y ser usado en cualquier otro sitio, de hecho vamos a hacerlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descarga del modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 8/8 [00:00<00:00, 30.69it/s]\n"
     ]
    }
   ],
   "source": [
    "logged_model = f\"runs:/{run.info.run_id}/models\"\n",
    "loaded_model = mlflow.pytorch.load_model(logged_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos el modelos entrenado con una muestra del conjunto de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    idx = randint(0, len(subset_test_data))\n",
    "except:\n",
    "    print(idx, len(subset_test_data))\n",
    "sample_test_img, label = subset_test_data[idx]\n",
    "output = loaded_model(sample_test_img.to(output.device).unsqueeze(0))\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: 5, True label: 5\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+nwwy3EqxQxvJI3RUUkn8BWhb+HtXu3jSDT53aX7gC/e+n07+neo9a0i50HWLnS7wxme3fazRPuRuMgg9wQQaoVc0vUZNK1GK8ijjkaPOEkztORjnBB/Wur8O+MdWn8S6XbQx2UKS3MURWO3ReGcbjuOSuRwcHGK6vxn4Rs9Z177dcXf2O4eJRIgw24qSobOf7oUfhXn+jaXYLcCS71XS9rR5USM52t2yNuPY5qxqWleHoNTubttZheyZt8dpYqzStnkqCw2qoJIySTgdCa6HwH4rtodbliCado1ilq3l/dDSNvGN8r5ZjgtxkDjpTPiJr1pfa/by2upwXCC1VWaFi4B3vxkDGcEfnXm9FFFf/9k=",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABdElEQVR4AWNgGNyAiQXqPqbtmqguZQJz1ZV5bDxFsv7PYmCAqQSJ/2NgChc9x+L58gzLZI75QBmIaogJTAyS7P9+fdnN+ZqLg0VYjYGBESIOJJn+Mf3jcZfnfy8jIMp/QfaXeNUJhCRIFVMP12EVhkYxw527vr9ljUWVZBD69gNi1Pp/73nbEQ5i+gcUfgdyBIhxhYGB3x/hIJAQAwvTv39ghhL3rx9sCJ0gOYY/IAJohqTR57ufv6BJgqWAWv9e+cXE/QgmyQLWA7QRaCpfgKs8wz8mppsQSRYj6W87QSYCHSNbq/CX4TMrx1umj0BJpn8izm8/l4El/zGUOjBUnSlX/CjKxP0D7PI3L/kvbQoEaXTYqJjofYbBhJufnZPpJ8TYp9LG74M2/lON01mwHuTYz59YPn4WZWVRj/jxnV+W+6Pg11YFs52B4JjgkHnEJMqiwscoYPCL4ReDONc3yc/3z0AC4g9Du9bzH18ZqkEWDSoAAPd4dWgqkGa9AAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_label = torch.argmax(output, dim=1).item()\n",
    "print(f\"Predicted label: {predicted_label}, True label: {label}\")\n",
    "sample_test_img_PIL = ToPILImage()(sample_test_img)\n",
    "sample_test_img_PIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos el entrenamiento ha sido exitoso"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azure_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
