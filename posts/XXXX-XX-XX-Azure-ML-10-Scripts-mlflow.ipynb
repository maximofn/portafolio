{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure ML - Scripts mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loguearse a Azure ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como las acciones que vamos a hacer por CLI o a través del SDK de Python necesitan una autentificación, primero vamos a loguearnos en Azure ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Login en Azure ML con el CLI de Azure ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para logearnos en Azure hacemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se nos abrirá el navegador para logearnos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear un cliente de Azure ML con el SDK de Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero creamos dos variables con la ID de la suscripción y el grupo de recursos, como estos son datos personales, no los voy a poner aquí. Lo que voy a hacer es incluirlos en un archivo `.env` que no voy a subir a GitHub\n",
    "\n",
    "```bash\n",
    "AZURE_SUSCRIPION_ID=\"xxxxx-xxxx-xxxx-xxxx-xxxxx\"\n",
    "AZURE_ML_RESOURCE_GRPU_ID=\"xxxxx-xxxx-xxxx-xxxx-xxxxx\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora para leerlos primero necesitasos tener instalado `dotenv` que lo hacemos mediante `pip install python-dotenv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "AZURE_SUSCRIPION_ID = os.getenv(\"AZURE_SUSCRIPION_ID\")\n",
    "AZURE_ML_RESOURCE_GRPU_ID = os.getenv(\"AZURE_ML_RESOURCE_GRPU_ID\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos estas variables creamos un cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "workspace_name = \"azure-ml-workspace-Python-SDK\"\n",
    "\n",
    "ml_client = MLClient(DefaultAzureCredential(), AZURE_SUSCRIPION_ID, AZURE_ML_RESOURCE_GRPU_ID, workspace_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scripts - mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que con los Jupyter Notebook, podemos hacer un seguimiento de los scripts con mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecutar un script desde la interfaz gráfica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crear el script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volvemos a dar al botón con el símbolo `+`, le damos a `Create new file`, en `File type` seleccionamos `Python (*.py)` y le ponemos el nombre `text-classification-mlflow.py`. Ahora copiamos el siguiente código\n",
    "\n",
    "```python\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "from torchmetrics import Accuracy\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "import mlflow\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "\n",
    "def load_dataset():\n",
    "    training_data = datasets.FashionMNIST(\n",
    "        root=\"data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=ToTensor()\n",
    "    )\n",
    "\n",
    "    test_data = datasets.FashionMNIST(\n",
    "        root=\"data\",\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=ToTensor()\n",
    "    )\n",
    "    return training_data, test_data\n",
    "\n",
    "def get_num_classes(train_dataset):\n",
    "    set_clases = set({})\n",
    "    len_training_data = len(train_dataset)\n",
    "    for i in range(len_training_data):\n",
    "        _, label = train_dataset[i]\n",
    "        set_clases.add(label)\n",
    "    num_classes = len(set_clases)\n",
    "    return num_classes\n",
    "\n",
    "def create_subset(tran_dataset, test_dataset, factor):\n",
    "    len_training_data = len(tran_dataset)\n",
    "    len_test_data = len(test_dataset)\n",
    "    subset_training_data = torch.utils.data.Subset(tran_dataset, range(0, len_training_data//factor))\n",
    "    subset_test_data = torch.utils.data.Subset(test_dataset, range(0, len_test_data//factor))\n",
    "    return subset_training_data, subset_test_data\n",
    "\n",
    "def get_dataloaders(train_dataset, test_dataset, batch_size):\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "    return train_dataloader, test_dataloader\n",
    "\n",
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        super(ImageClassifier, self).__init__()\n",
    "        self.imageClassifier = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(self.num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.imageClassifier(x)\n",
    "\n",
    "def train(dataloader, model, loss_fn, metrics_fn, optimizer, epoch, device):\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        metric = metrics_fn(pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss = loss.item()\n",
    "            current = batch\n",
    "            step = batch // 1000 * (epoch + 1)\n",
    "            mlflow.log_metric(\"train_loss\", f\"{loss:.4f}\", step=step)\n",
    "            mlflow.log_metric(\"train_accuracy\", f\"{metric:.4f}\", step=step)\n",
    "            print(f\"train loss: {loss:.4f}, train accuracy: {metric:.4f} [{current}/{len(dataloader)}]\")\n",
    "\n",
    "    return model\n",
    "\n",
    "def evaluate(dataloader, model, loss_fn, metrics_fn, epoch, device):\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    eval_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            eval_loss += loss_fn(pred, y).item()\n",
    "            eval_accuracy += metrics_fn(pred, y).item()\n",
    "\n",
    "    eval_loss /= num_batches\n",
    "    eval_accuracy /= num_batches\n",
    "    mlflow.log_metric(\"eval_loss\", f\"{eval_loss:.4f}\", step=epoch)\n",
    "    mlflow.log_metric(\"eval_accuracy\", f\"{eval_accuracy:.4f}\", step=epoch)\n",
    "\n",
    "    print(f\"eval loss: {eval_loss:.4f}, eval accuracy: {eval_accuracy:.4f}\")\n",
    "\n",
    "def main(subset_factor, batch_size, suscription_id, resource_group, workspace_name, experiment_name, epochs=3, learning_rate=1e-3):\n",
    "    train_dataset, test_dataset = load_dataset()\n",
    "    num_classes = get_num_classes(train_dataset)\n",
    "    train_subset, test_subset = create_subset(train_dataset, test_dataset, factor=subset_factor)\n",
    "\n",
    "    train_dataloader, test_dataloader = get_dataloaders(train_subset, test_subset, batch_size=batch_size)\n",
    "    sample_batch = next(iter(train_dataloader))\n",
    "    image_batch, _ = sample_batch\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = ImageClassifier(num_classes).to(device)\n",
    "\n",
    "    mlflow.pytorch.autolog()\n",
    "    mlflow.set_tracking_uri = f\"azureml://francecentral.api.azureml.ms/mlflow/v1.0/subscriptions/{suscription_id}/resourceGroups/{resource_group}/providers/Microsoft.MachineLearningServices/workspaces/{workspace_name}\"\n",
    "    mlflow.set_experiment(experiment_name=experiment_name)\n",
    "\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    metrics_fn = Accuracy(task=\"multiclass\", num_classes=num_classes).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    name = f\"{experiment_name}_{datetime.now().strftime('%Y-%m-%d_%H:%M:%S')}\"\n",
    "    with mlflow.start_run(run_name=name) as run:\n",
    "        params = {\n",
    "            \"epochs\": epochs,\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"num_classes\": num_classes,\n",
    "            \"loss_fn\": loss_fn.__class__.__name__,\n",
    "            \"metrics_fn\": metrics_fn.__class__.__name__,\n",
    "            \"optimizer\": \"Adam\",\n",
    "        }\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        with open(\"model_summary.txt\", \"w\") as f:\n",
    "            f.write(str(summary(model, input_size=(batch_size, 1, 28, 28), device=device)))\n",
    "        mlflow.log_artifact(\"model_summary.txt\")\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
    "            train(train_dataloader, model, loss_fn, metrics_fn, optimizer, epoch, device)\n",
    "            evaluate(test_dataloader, model, loss_fn, metrics_fn, epoch, device)\n",
    "        \n",
    "        mlflow.pytorch.log_model(model, \"models\", input_example=image_batch.numpy())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--subset_factor\", type=int, default=1)\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=16)\n",
    "    parser.add_argument(\"--suscription_id\", type=str, required=True)\n",
    "    parser.add_argument(\"--resource_group\", type=str, required=True)\n",
    "    parser.add_argument(\"--workspace_name\", type=str, required=True)\n",
    "    parser.add_argument(\"--experiment_name\", type=str, required=True)\n",
    "    parser.add_argument(\"--epochs\", type=int, default=3)\n",
    "    parser.add_argument(\"--learning_rate\", type=float, default=1e-3)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    subset_factor = args.subset_factor\n",
    "    batch_size = args.batch_size\n",
    "    suscription_id = args.suscription_id\n",
    "    resource_group = args.resource_group\n",
    "    workspace_name = args.workspace_name\n",
    "    experiment_name = args.experiment_name\n",
    "    epochs = args.epochs\n",
    "    learning_rate = args.learning_rate\n",
    "\n",
    "    main(subset_factor, batch_size, suscription_id, resource_group, workspace_name, experiment_name, epochs, learning_rate)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejecutar el script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volvemos a dar al botón con el símbolo `+`, le damos a `Create new file`, en `File type` seleccionamos `Notebook (*.ipynb)` y le ponemos el nombre `run_text-clasification-mlflow.ipynb`. Ahora copiamos las siguientes celdas de código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except:\n",
    "    credential = InteractiveBrowserCredential()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "ml_client = MLClient.from_config(credential=credential)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from azure.ai.ml import command\n",
    "\n",
    "SUSCRIPTION_ID = \"\"\n",
    "RESOURCE_GROUP = \"\"\n",
    "WORKSPACE = \"\"\n",
    "EXPERIMENT_NAME = \"image_classification-mlflow\"\n",
    "\n",
    "execute_command = f\"python image-classification-mlflow.py --suscription_id {SUSCRIPTION_ID} --resource_group {RESOURCE_GROUP} --workspace_name {WORKSPACE} --experiment_name {EXPERIMENT_NAME} --batch_size 16 --epochs 3 --learning_rate 1e-3\"\n",
    "environment = \"cuda_11_8_0_cudnn8_devel_ubuntu22_04_transformers_GUI@latest\"\n",
    "compute_instance = \"compute-instance-GUI\"\n",
    "display_name = \"image-classificator\"\n",
    "\n",
    "# configure job\n",
    "job = command(\n",
    "    code=\"./\",\n",
    "    command=execute_command,\n",
    "    environment=environment,\n",
    "    compute=compute_instance,\n",
    "    display_name=display_name,\n",
    "    experiment_name=EXPERIMENT_NAME\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "returned_job = ml_client.create_or_update(job)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rellena `SUSCRIPTION_ID`, `RESOURCE_GROUP` y `WORKSPACE` con tus valores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizar el entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si nos vamos a la sección `Jobs` en la parte izquierda de la pantalla, veremos el experimento que hemos creado, si le damos veremos la salida del script.\n",
    "\n",
    "A diferencia de antes, es que ahora al usar mlflow, podemos ver las gráficas de las métricas y tendremos el modelo como salida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecutar un script con el CLI de Azure ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No he encotrado la manera de ejecutar el script mediante la CLI de Azure ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecutar un script con el SDK de Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ejecutar un script primero tenemos que subir los datos y el script igual que lo hemos hecho en la interfaz gráfica. No he encotrado la manera de subirlos mediante el SDK de Python. Por lo que nos aseguramos de estar en el workspace en el que hemos hecho todo con el SDK de Python y subimos los datos y el script igual que lo hemos hecho antes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora para ejecutar el script ejecutamos el mismo código que ejecutamos en el notebook mediante la interfaz gráfica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "\n",
    "SUSCRIPTION_ID = \"\"\n",
    "RESOURCE_GROUP = \"\"\n",
    "WORKSPACE = \"\"\n",
    "EXPERIMENT_NAME = \"image_classification-mlflow\"\n",
    "\n",
    "execute_command = f\"python image-classification-mlflow.py --suscription_id {SUSCRIPTION_ID} --resource_group {RESOURCE_GROUP} --workspace_name {WORKSPACE} --experiment_name {EXPERIMENT_NAME} --batch_size 16 --epochs 3 --learning_rate 1e-3\"\n",
    "environment = \"cuda_11_8_0_cudnn8_devel_ubuntu22_04_transformers_GUI@latest\"\n",
    "compute_instance = \"compute-instance-Python\"\n",
    "display_name = \"image-classificator\"\n",
    "\n",
    "# configure job\n",
    "job = command(\n",
    "    code=\"./\",\n",
    "    command=execute_command,\n",
    "    environment=environment,\n",
    "    compute=compute_instance,\n",
    "    display_name=display_name,\n",
    "    experiment_name=EXPERIMENT_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rellena `SUSCRIPTION_ID`, `RESOURCE_GROUP` y `WORKSPACE` con tus valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "returned_job = ml_client.create_or_update(job)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azure_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
