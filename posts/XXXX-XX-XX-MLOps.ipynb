{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLOps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLOps viene de DevOps y son las pr谩cticas y herramientas que se utilizan para mejorar la colaboraci贸n y la comunicaci贸n entre los equipos de desarrollo de software y los equipos de operaciones.\n",
    "\n",
    "En el caso de MLOps, se refiere a las pr谩cticas y herramientas que se utilizan para mejorar la colaboraci贸n y la comunicaci贸n entre los equipos de desarrollo de modelos de machine learning y los equipos de operaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estapas de MLOps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estas son las etapas de MLOps:\n",
    "\n",
    "![Etapas MLOps](https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/mlops_operations.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a explicarlas:\n",
    "\n",
    " * Dise帽o: En esta etapa se define el problema que se va a resolver y se recopilan los datos necesarios para resolverlo.\n",
    " * Desarrollo del modelo: En esta etapa se entrena el modelo y se eval煤a su rendimiento.\n",
    " * Operaciones: En esta etapa se despliega el modelo en producci贸n, se crean los pipelines de CI/CD y se monitoriza el rendimiento del modelo.\n",
    "\n",
    "Como se puede ver no son etapas cerradas, sino que nos podemos mover de una a otra en cualquier momento como se puede ver en la siguiente imagen:\n",
    "\n",
    "![mlops operations](https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/mlops_operations2.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Componentes de MLOps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos son los componentes de MLOps:\n",
    "\n",
    " * Control de versiones: Git\n",
    " * CI/CD: GitHub Actions, Jenkins, GitLab CI\n",
    " * Orquestaci贸n de pipelines: DVC, Prefect, Hydra\n",
    " * Model y container registry: MLflow\n",
    " * Compute serving: Batch serving, Real-time serving\n",
    " * Monitoreo: Grafana, Prometheus, Kibana\n",
    "\n",
    "Con estos componentes vamos a poder implementar MLOps en un proyecto de machine learning, en el que entrenaremos un modelo de machine learning y lo desplegaremos en producci贸n, a trav茅s de una API lo vamos a poder consumir, mientras que por otro lado vamos a almacenar las salidas del modelo en una base de datos para monitorizar su rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 驴Para qu茅 sirve el tracking en MLOps?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver en la siguiente imagen, en MLOps tenemos varias etapas, por un lado la preparaci贸n de los datos, la creaci贸n del modelo, el despliegue del modelo en producci贸n y el monitoreo del modelo\n",
    "\n",
    "![mlops tracking](https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/mlops_tracking_models.webp)\n",
    "\n",
    "Por lo que es importante trackear todo, tanto con qu茅 datos estamos haciendo el entrenamiento, como el modelo que estamos entrenando, como el rendimiento del modelo en producci贸n. El tracking es importante para tener trazabilidad, porque a lo largo de un desarrollo hay tantas posibles operaciones que se pueden hacer que es importante tener un registro de todo lo que se ha hecho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esto podemos usar `mlflow`, que es una herramienta que nos permite trackear todo lo que hacemos en un proyecto de machine learning, desde la preparaci贸n de los datos, el entrenamiento del modelo, el despliegue del modelo en producci贸n y el monitoreo del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adem谩s, como en un desarrollo puede haber varias personas, es importante tener un registro de todo lo que se ha hecho, para que si alguien tiene una duda, pueda ver todo lo que se ha hecho y por qu茅 se ha hecho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El 茅xito de un flujo de MLOps radica en la mayor automatizaci贸n de procesos posible, para que los equipos de desarrollo y operaciones puedan centrarse en lo que realmente importa, que es la creaci贸n de modelos de machine learning y su despliegue en producci贸n. Adem谩s evitando errores humanos en las tareas repetitivas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es importante almacenar todos los metadatos posibles, porque eso va a ayudar a tener una trazabilidad de todo lo que se ha hecho en un proyecto de machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalar MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para instalar `mlflow` podemos hacerlo con `conda`:\n",
    "\n",
    "```bash\n",
    "conda install conda-forge::mlflow\n",
    "```\n",
    "\n",
    "O con `pip`:\n",
    "\n",
    "```bash\n",
    "pip install mlflow\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instalar el resto de las dependencias. Como vamos a hacer el fine tuning de un modelo habr铆a que instalar `pytorch`, `transformers`, `evaluate`, `bitsandbytes`, `accelerate` y `datasets`:\n",
    "\n",
    "```bash\n",
    "conda install -y pytorch torchvision pytorch-cuda=12.4 -c pytorch -c nvidia\n",
    "pip install evaluate bitsandbytes accelerate datasets transformers -q\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking de experimentos con MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos las librer铆as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    ")\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descargamos el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d21e8903975b400cbf3dc9eca088de8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/4.98k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d2ccae72344f46b94fa8e0f34c7a40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/359k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a807bb7f869f4debac47486fdcc7a7ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/5574 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sms_dataset = load_dataset('sms_spam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo dividimos en train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_train_test = sms_dataset['train'].train_test_split(test_size=0.2)\n",
    "train_dataset = sms_train_test['train']\n",
    "test_dataset = sms_train_test['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos una muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What does the dance river do?\\n', 0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "idx = randint(0, len(train_dataset))\n",
    "train_dataset[idx]['sms'], train_dataset[idx]['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver las clases que hay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5877039a3ed146e7916541836ffa1f23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/4459 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.unique('label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que el dataset clasifica con `0` y `1` si un sms es spam o no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el tokenizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d90f169d77aa4e16b4348ae7d15bf60d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb44f060c144aea865ed6b3a04f0b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb6802b078f04edb92bf64f3b5106143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9367d6ecc434099998114a9469e504b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una funci贸n de tokenizaci贸n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['sms'], padding='max_length', truncation=True, max_length=128, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a probarla con un ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 128]), torch.Size([1, 128]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenize_function(train_dataset[idx])\n",
    "tokens.input_ids.shape, tokens.attention_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizaos el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1be8fa0c18e459488202f9154efa410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4459 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8545ddeb05aa480a8530a4d86274d7f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1115 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed = 22\n",
    "train_tokenized = train_dataset.map(tokenize_function, batched=True, remove_columns=['sms']).shuffle(seed=seed)\n",
    "test_tokenized = test_dataset.map(tokenize_function, batched=True, remove_columns=['sms']).shuffle(seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos diccionarios para pasar de id a la etiqueta y de la etiqueta al id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: 'ham', 1: 'spam'}\n",
    "label2id = {'ham': 0, 'spam': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c2d9522dfb423a83abd20358c61c0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'distilbert-base-uncased', \n",
    "    num_labels=2,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos la funci贸n de m茅tricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load('accuracy')\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    logits, labels = pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    return metric.compute(predictions=preds, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuramos el trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wallabot/miniconda3/envs/mlops/lib/python3.11/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_ouput_path = 'sms_trainer'\n",
    "trainig_args = TrainingArguments(\n",
    "    output_dir=training_ouput_path,\n",
    "    evaluation_strategy='epoch',\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    logging_steps=8,\n",
    "    num_train_epochs=3,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=trainig_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=test_tokenized,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un tracker de mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero tenemos que ejecutar esto en una terminal para iniciar el servidor de mlflow:\n",
    "\n",
    "```bash\n",
    "mlflow server --port 5000 --host 0.0.0.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri('http://localhost:5000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si ahora abrimos un navegador y vamos a [http://localhost:5000](http://localhost:5000) veremos el dashboard de mlflow\n",
    "\n",
    "![mlflow dashboard](https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/mlflow_server.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asignamos un nombre al experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/06 19:39:48 INFO mlflow.tracking.fluent: Experiment with name 'SMS Spam Classification' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/869247621359487510', creation_time=1730918388725, experiment_id='869247621359487510', last_update_time=1730918388725, lifecycle_stage='active', name='SMS Spam Classification', tags={}>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment('SMS Spam Classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora aparecer谩 en el dashboard de mlflow un nuevo experimento llamado `SMS Spam Classification`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mlflow est谩 muy bien integrada con la mayor铆a de las librer铆as de machine learning\n",
    "\n",
    "![mlflow integrations](https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/mlflow_integrations.webp)\n",
    "\n",
    "Por lo que para empezar el entrenamiento solo tenemos que hacer lo siguiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab3db45ef36496aa21c8ef50e09aa77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/837 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wallabot/miniconda3/envs/mlops/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4455, 'grad_norm': 1.8081084489822388, 'learning_rate': 4.95221027479092e-05, 'epoch': 0.03}\n",
      "{'loss': 0.1221, 'grad_norm': 0.669918417930603, 'learning_rate': 4.90442054958184e-05, 'epoch': 0.06}\n",
      "{'loss': 0.0322, 'grad_norm': 11.449009895324707, 'learning_rate': 4.8566308243727596e-05, 'epoch': 0.09}\n",
      "{'loss': 0.0322, 'grad_norm': 0.7715699672698975, 'learning_rate': 4.80884109916368e-05, 'epoch': 0.11}\n",
      "{'loss': 0.005, 'grad_norm': 0.8292357921600342, 'learning_rate': 4.7610513739546e-05, 'epoch': 0.14}\n",
      "{'loss': 0.0037, 'grad_norm': 0.02695838175714016, 'learning_rate': 4.71326164874552e-05, 'epoch': 0.17}\n",
      "{'loss': 0.1845, 'grad_norm': 0.05402424931526184, 'learning_rate': 4.66547192353644e-05, 'epoch': 0.2}\n",
      "{'loss': 0.0175, 'grad_norm': 0.0833834782242775, 'learning_rate': 4.61768219832736e-05, 'epoch': 0.23}\n",
      "{'loss': 0.0877, 'grad_norm': 13.283378601074219, 'learning_rate': 4.56989247311828e-05, 'epoch': 0.26}\n",
      "{'loss': 0.0078, 'grad_norm': 0.08746110647916794, 'learning_rate': 4.5221027479092e-05, 'epoch': 0.29}\n",
      "{'loss': 0.0262, 'grad_norm': 0.46065542101860046, 'learning_rate': 4.4743130227001195e-05, 'epoch': 0.32}\n",
      "{'loss': 0.1009, 'grad_norm': 1.6743664741516113, 'learning_rate': 4.42652329749104e-05, 'epoch': 0.34}\n",
      "{'loss': 0.1952, 'grad_norm': 8.667765617370605, 'learning_rate': 4.378733572281959e-05, 'epoch': 0.37}\n",
      "{'loss': 0.0484, 'grad_norm': 0.26116499304771423, 'learning_rate': 4.3309438470728796e-05, 'epoch': 0.4}\n",
      "{'loss': 0.0449, 'grad_norm': 0.14275887608528137, 'learning_rate': 4.283154121863799e-05, 'epoch': 0.43}\n",
      "{'loss': 0.0179, 'grad_norm': 0.046592723578214645, 'learning_rate': 4.2353643966547194e-05, 'epoch': 0.46}\n",
      "{'loss': 0.0519, 'grad_norm': 0.06788275390863419, 'learning_rate': 4.1875746714456396e-05, 'epoch': 0.49}\n",
      "{'loss': 0.0747, 'grad_norm': 0.05998223274946213, 'learning_rate': 4.13978494623656e-05, 'epoch': 0.52}\n",
      "{'loss': 0.0394, 'grad_norm': 0.05431315675377846, 'learning_rate': 4.0919952210274794e-05, 'epoch': 0.54}\n",
      "{'loss': 0.1099, 'grad_norm': 0.21424992382526398, 'learning_rate': 4.0442054958183996e-05, 'epoch': 0.57}\n",
      "{'loss': 0.0793, 'grad_norm': 2.7466776371002197, 'learning_rate': 3.996415770609319e-05, 'epoch': 0.6}\n",
      "{'loss': 0.0461, 'grad_norm': 0.0973486602306366, 'learning_rate': 3.9486260454002395e-05, 'epoch': 0.63}\n",
      "{'loss': 0.0048, 'grad_norm': 0.4035756587982178, 'learning_rate': 3.900836320191159e-05, 'epoch': 0.66}\n",
      "{'loss': 0.103, 'grad_norm': 1.8360981941223145, 'learning_rate': 3.8530465949820786e-05, 'epoch': 0.69}\n",
      "{'loss': 0.0079, 'grad_norm': 1.4558252096176147, 'learning_rate': 3.805256869772999e-05, 'epoch': 0.72}\n",
      "{'loss': 0.124, 'grad_norm': 0.08928893506526947, 'learning_rate': 3.7574671445639184e-05, 'epoch': 0.75}\n",
      "{'loss': 0.0964, 'grad_norm': 0.2028975933790207, 'learning_rate': 3.7096774193548386e-05, 'epoch': 0.77}\n",
      "{'loss': 0.0089, 'grad_norm': 0.179122194647789, 'learning_rate': 3.661887694145759e-05, 'epoch': 0.8}\n",
      "{'loss': 0.0165, 'grad_norm': 0.03858159855008125, 'learning_rate': 3.614097968936679e-05, 'epoch': 0.83}\n",
      "{'loss': 0.1324, 'grad_norm': 0.09463584423065186, 'learning_rate': 3.566308243727599e-05, 'epoch': 0.86}\n",
      "{'loss': 0.0026, 'grad_norm': 0.04126795008778572, 'learning_rate': 3.518518518518519e-05, 'epoch': 0.89}\n",
      "{'loss': 0.0448, 'grad_norm': 0.12471386045217514, 'learning_rate': 3.4707287933094385e-05, 'epoch': 0.92}\n",
      "{'loss': 0.0377, 'grad_norm': 0.5049582719802856, 'learning_rate': 3.422939068100359e-05, 'epoch': 0.95}\n",
      "{'loss': 0.0416, 'grad_norm': 0.04534032940864563, 'learning_rate': 3.375149342891278e-05, 'epoch': 0.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "277cc512d97743de8d668db07118c6b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.051197364926338196, 'eval_accuracy': 0.9883408071748879, 'eval_runtime': 3.7395, 'eval_samples_per_second': 298.165, 'eval_steps_per_second': 18.719, 'epoch': 1.0}\n",
      "{'loss': 0.0019, 'grad_norm': 0.039650414139032364, 'learning_rate': 3.3273596176821985e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wallabot/miniconda3/envs/mlops/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0016, 'grad_norm': 0.029194805771112442, 'learning_rate': 3.279569892473118e-05, 'epoch': 1.03}\n",
      "{'loss': 0.0381, 'grad_norm': 0.024087436497211456, 'learning_rate': 3.231780167264038e-05, 'epoch': 1.06}\n",
      "{'loss': 0.0014, 'grad_norm': 0.027520226314663887, 'learning_rate': 3.183990442054958e-05, 'epoch': 1.09}\n",
      "{'loss': 0.0476, 'grad_norm': 0.1449233889579773, 'learning_rate': 3.136200716845878e-05, 'epoch': 1.12}\n",
      "{'loss': 0.004, 'grad_norm': 0.0265234112739563, 'learning_rate': 3.0884109916367984e-05, 'epoch': 1.15}\n",
      "{'loss': 0.0012, 'grad_norm': 0.017263587564229965, 'learning_rate': 3.0406212664277183e-05, 'epoch': 1.18}\n",
      "{'loss': 0.0393, 'grad_norm': 0.021364768967032433, 'learning_rate': 2.9928315412186382e-05, 'epoch': 1.2}\n",
      "{'loss': 0.0009, 'grad_norm': 0.023421071469783783, 'learning_rate': 2.9450418160095584e-05, 'epoch': 1.23}\n",
      "{'loss': 0.0027, 'grad_norm': 0.030992012470960617, 'learning_rate': 2.897252090800478e-05, 'epoch': 1.26}\n",
      "{'loss': 0.038, 'grad_norm': 0.0179757010191679, 'learning_rate': 2.8494623655913982e-05, 'epoch': 1.29}\n",
      "{'loss': 0.0522, 'grad_norm': 0.017976071685552597, 'learning_rate': 2.8016726403823178e-05, 'epoch': 1.32}\n",
      "{'loss': 0.059, 'grad_norm': 1.284709095954895, 'learning_rate': 2.753882915173238e-05, 'epoch': 1.35}\n",
      "{'loss': 0.0117, 'grad_norm': 4.161077976226807, 'learning_rate': 2.706093189964158e-05, 'epoch': 1.38}\n",
      "{'loss': 0.0379, 'grad_norm': 0.02316894754767418, 'learning_rate': 2.6583034647550775e-05, 'epoch': 1.41}\n",
      "{'loss': 0.0052, 'grad_norm': 0.01285792887210846, 'learning_rate': 2.6105137395459977e-05, 'epoch': 1.43}\n",
      "{'loss': 0.0008, 'grad_norm': 0.00965092983096838, 'learning_rate': 2.5627240143369173e-05, 'epoch': 1.46}\n",
      "{'loss': 0.0014, 'grad_norm': 0.010399609804153442, 'learning_rate': 2.5149342891278375e-05, 'epoch': 1.49}\n",
      "{'loss': 0.0593, 'grad_norm': 0.01008743979036808, 'learning_rate': 2.4671445639187578e-05, 'epoch': 1.52}\n",
      "{'loss': 0.0012, 'grad_norm': 0.023504016920924187, 'learning_rate': 2.4193548387096777e-05, 'epoch': 1.55}\n",
      "{'loss': 0.0557, 'grad_norm': 0.03718645125627518, 'learning_rate': 2.3715651135005976e-05, 'epoch': 1.58}\n",
      "{'loss': 0.0098, 'grad_norm': 0.03115892969071865, 'learning_rate': 2.3237753882915175e-05, 'epoch': 1.61}\n",
      "{'loss': 0.0016, 'grad_norm': 0.01849350519478321, 'learning_rate': 2.2759856630824374e-05, 'epoch': 1.63}\n",
      "{'loss': 0.0507, 'grad_norm': 3.396381139755249, 'learning_rate': 2.2281959378733573e-05, 'epoch': 1.66}\n",
      "{'loss': 0.0008, 'grad_norm': 0.021560445427894592, 'learning_rate': 2.1804062126642775e-05, 'epoch': 1.69}\n",
      "{'loss': 0.0018, 'grad_norm': 0.021567201241850853, 'learning_rate': 2.132616487455197e-05, 'epoch': 1.72}\n",
      "{'loss': 0.0551, 'grad_norm': 0.03570172190666199, 'learning_rate': 2.084826762246117e-05, 'epoch': 1.75}\n",
      "{'loss': 0.0011, 'grad_norm': 0.0330757275223732, 'learning_rate': 2.037037037037037e-05, 'epoch': 1.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wallabot/miniconda3/envs/mlops/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0467, 'grad_norm': 0.02618269994854927, 'learning_rate': 1.989247311827957e-05, 'epoch': 1.81}\n",
      "{'loss': 0.0464, 'grad_norm': 0.15360097587108612, 'learning_rate': 1.941457586618877e-05, 'epoch': 1.84}\n",
      "{'loss': 0.0181, 'grad_norm': 0.02892197109758854, 'learning_rate': 1.893667861409797e-05, 'epoch': 1.86}\n",
      "{'loss': 0.001, 'grad_norm': 0.014254506677389145, 'learning_rate': 1.845878136200717e-05, 'epoch': 1.89}\n",
      "{'loss': 0.0529, 'grad_norm': 0.026519518345594406, 'learning_rate': 1.7980884109916368e-05, 'epoch': 1.92}\n",
      "{'loss': 0.026, 'grad_norm': 0.07904544472694397, 'learning_rate': 1.7502986857825567e-05, 'epoch': 1.95}\n",
      "{'loss': 0.0158, 'grad_norm': 0.08638814091682434, 'learning_rate': 1.702508960573477e-05, 'epoch': 1.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05658b62cf7d4759b1d0e26871af7aa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04106992855668068, 'eval_accuracy': 0.9883408071748879, 'eval_runtime': 3.7469, 'eval_samples_per_second': 297.581, 'eval_steps_per_second': 18.682, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wallabot/miniconda3/envs/mlops/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0107, 'grad_norm': 0.05254911631345749, 'learning_rate': 1.6547192353643968e-05, 'epoch': 2.01}\n",
      "{'loss': 0.0225, 'grad_norm': 0.05086367204785347, 'learning_rate': 1.6069295101553167e-05, 'epoch': 2.04}\n",
      "{'loss': 0.0026, 'grad_norm': 0.01178144384175539, 'learning_rate': 1.5591397849462366e-05, 'epoch': 2.06}\n",
      "{'loss': 0.0008, 'grad_norm': 0.010033085942268372, 'learning_rate': 1.5113500597371565e-05, 'epoch': 2.09}\n",
      "{'loss': 0.0007, 'grad_norm': 0.009925906546413898, 'learning_rate': 1.4635603345280766e-05, 'epoch': 2.12}\n",
      "{'loss': 0.0254, 'grad_norm': 0.012725817039608955, 'learning_rate': 1.4157706093189965e-05, 'epoch': 2.15}\n",
      "{'loss': 0.0242, 'grad_norm': 0.009354802779853344, 'learning_rate': 1.3679808841099166e-05, 'epoch': 2.18}\n",
      "{'loss': 0.0046, 'grad_norm': 2.219235420227051, 'learning_rate': 1.3201911589008365e-05, 'epoch': 2.21}\n",
      "{'loss': 0.001, 'grad_norm': 0.02153380960226059, 'learning_rate': 1.2724014336917564e-05, 'epoch': 2.24}\n",
      "{'loss': 0.0014, 'grad_norm': 0.01680711843073368, 'learning_rate': 1.2246117084826763e-05, 'epoch': 2.27}\n",
      "{'loss': 0.0022, 'grad_norm': 0.2790946662425995, 'learning_rate': 1.1768219832735962e-05, 'epoch': 2.29}\n",
      "{'loss': 0.0005, 'grad_norm': 0.02129960060119629, 'learning_rate': 1.129032258064516e-05, 'epoch': 2.32}\n",
      "{'loss': 0.0008, 'grad_norm': 0.008115025237202644, 'learning_rate': 1.0812425328554361e-05, 'epoch': 2.35}\n",
      "{'loss': 0.0005, 'grad_norm': 0.05357383191585541, 'learning_rate': 1.033452807646356e-05, 'epoch': 2.38}\n",
      "{'loss': 0.0005, 'grad_norm': 0.020236244425177574, 'learning_rate': 9.856630824372761e-06, 'epoch': 2.41}\n",
      "{'loss': 0.0218, 'grad_norm': 0.009720196016132832, 'learning_rate': 9.37873357228196e-06, 'epoch': 2.44}\n",
      "{'loss': 0.0005, 'grad_norm': 0.016726179048419, 'learning_rate': 8.90083632019116e-06, 'epoch': 2.47}\n",
      "{'loss': 0.0009, 'grad_norm': 0.02544545754790306, 'learning_rate': 8.42293906810036e-06, 'epoch': 2.49}\n",
      "{'loss': 0.0008, 'grad_norm': 0.009576977230608463, 'learning_rate': 7.945041816009559e-06, 'epoch': 2.52}\n",
      "{'loss': 0.002, 'grad_norm': 0.01419459655880928, 'learning_rate': 7.467144563918758e-06, 'epoch': 2.55}\n",
      "{'loss': 0.0199, 'grad_norm': 0.040664881467819214, 'learning_rate': 6.989247311827957e-06, 'epoch': 2.58}\n",
      "{'loss': 0.0028, 'grad_norm': 0.006964878179132938, 'learning_rate': 6.511350059737156e-06, 'epoch': 2.61}\n",
      "{'loss': 0.0202, 'grad_norm': 0.0065557388588786125, 'learning_rate': 6.033452807646357e-06, 'epoch': 2.64}\n",
      "{'loss': 0.0004, 'grad_norm': 0.008270186372101307, 'learning_rate': 5.555555555555556e-06, 'epoch': 2.67}\n",
      "{'loss': 0.0012, 'grad_norm': 0.008812004700303078, 'learning_rate': 5.077658303464755e-06, 'epoch': 2.7}\n",
      "{'loss': 0.0009, 'grad_norm': 0.006754722446203232, 'learning_rate': 4.599761051373955e-06, 'epoch': 2.72}\n",
      "{'loss': 0.0005, 'grad_norm': 0.010569144040346146, 'learning_rate': 4.121863799283155e-06, 'epoch': 2.75}\n",
      "{'loss': 0.0013, 'grad_norm': 0.023501921445131302, 'learning_rate': 3.643966547192354e-06, 'epoch': 2.78}\n",
      "{'loss': 0.0005, 'grad_norm': 0.00815554242581129, 'learning_rate': 3.1660692951015535e-06, 'epoch': 2.81}\n",
      "{'loss': 0.0062, 'grad_norm': 0.008610575459897518, 'learning_rate': 2.688172043010753e-06, 'epoch': 2.84}\n",
      "{'loss': 0.0005, 'grad_norm': 0.006536387838423252, 'learning_rate': 2.2102747909199524e-06, 'epoch': 2.87}\n",
      "{'loss': 0.0004, 'grad_norm': 0.018808409571647644, 'learning_rate': 1.7323775388291518e-06, 'epoch': 2.9}\n",
      "{'loss': 0.0004, 'grad_norm': 0.006726319435983896, 'learning_rate': 1.2544802867383513e-06, 'epoch': 2.92}\n",
      "{'loss': 0.0004, 'grad_norm': 0.008157391101121902, 'learning_rate': 7.765830346475508e-07, 'epoch': 2.95}\n",
      "{'loss': 0.0004, 'grad_norm': 0.006602972745895386, 'learning_rate': 2.9868578255675034e-07, 'epoch': 2.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wallabot/miniconda3/envs/mlops/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8936380c972b461392e660dd9f7cc889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04692317917943001, 'eval_accuracy': 0.9910313901345291, 'eval_runtime': 3.7624, 'eval_samples_per_second': 296.357, 'eval_steps_per_second': 18.605, 'epoch': 3.0}\n",
      "{'train_runtime': 112.3026, 'train_samples_per_second': 119.116, 'train_steps_per_second': 7.453, 'train_loss': 0.03214372153195865, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/06 19:47:38 INFO mlflow.tracking._tracking_service.client:  View run nosy-crane-928 at: http://localhost:5000/#/experiments/869247621359487510/runs/0b2646cefe97455c807f4a21cefd19c6.\n",
      "2024/11/06 19:47:38 INFO mlflow.tracking._tracking_service.client: И View experiment at: http://localhost:5000/#/experiments/869247621359487510.\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hemos definido el entrenamiento como `run` con esta l铆nea `with mlflow.start_run() as run:`, ahora podemos obtener informaci贸n de la ejecuci贸n con `run.info`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RunInfo: artifact_uri='mlflow-artifacts:/869247621359487510/0b2646cefe97455c807f4a21cefd19c6/artifacts', end_time=None, experiment_id='869247621359487510', lifecycle_stage='active', run_id='0b2646cefe97455c807f4a21cefd19c6', run_name='nosy-crane-928', run_uuid='0b2646cefe97455c807f4a21cefd19c6', start_time=1730918744527, status='RUNNING', user_id='wallabot'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un `pipeline` de la librer铆a `transformers` con el modelo reci茅n entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "tuned_pipeline = pipeline(\n",
    "    task='text-classification',\n",
    "    model=trainer.model,\n",
    "    batch_size=8,\n",
    "    tokenizer=tokenizer,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos el modelo con un ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'ham', 'score': 0.9975218176841736}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = \"\"\"\n",
    "I have a question regardding the project development timeline and allocated resources;\n",
    "specifically, how certain are you that John and Ringo can work together on writing this next song?\n",
    "Do we need to get Paul involved here, or do you truly believe, as you said, 'nah, they got this'?\n",
    "\"\"\"\n",
    "\n",
    "tuned_pipeline(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo clasifica como no spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una firma del modelo que mlflow entiende"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_for_mlflow = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model_config = {\n",
    "    \"batch_size\": 8,\n",
    "    \"device\": device_for_mlflow,\n",
    "}\n",
    "\n",
    "signature = mlflow.models.infer_signature(\n",
    "    [\"This is a test!\", \"And this is also a test!\"],\n",
    "    mlflow.transformers.generate_signature_output(\n",
    "        tuned_pipeline, [\"This is a test response!\", \"So is this.\"]\n",
    "    ),\n",
    "    params=model_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora logueamos esa firma en mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa6d221031cb4a948ed2a2df3c6164ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/8.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eca3d182d384f979a45be353c0b3c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LICENSE:   0%|          | 0.00/11.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/06 20:04:30 INFO mlflow.tracking._tracking_service.client:  View run nosy-crane-928 at: http://localhost:5000/#/experiments/869247621359487510/runs/0b2646cefe97455c807f4a21cefd19c6.\n",
      "2024/11/06 20:04:30 INFO mlflow.tracking._tracking_service.client: И View experiment at: http://localhost:5000/#/experiments/869247621359487510.\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_id=run.info.run_id):\n",
    "    model_info = mlflow.transformers.log_model(\n",
    "        transformers_model=tuned_pipeline,\n",
    "        artifact_path=\"fine_tuned\",\n",
    "        signature=signature,\n",
    "        model_config=model_config,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto logeamos el modelo en mlflow. Si nos vamos al dashboard de mlflow veremos que aparece el modelo en la pesta帽a `Artifacts` del `run`. Esto adem谩s hace que este modelo se pueda exportar a otros sitios. Como mlflow tiene integraciones con casi todas las librer铆as de machine learning, podemos exportar este modelo a cualquier otra librer铆a de machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra ventaja de esto es que podemos tener un control de versiones del modelo, por lo que si en un futuro queremos volver a un modelo anterior, podemos hacerlo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el modelo desde el artifact de mlflow y hacemos inferencia con 茅l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero eliminamos el modelo y el pipeline para asegurarnos que hacemos inferencia con el modelo que hemos guardado en mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model, tuned_pipeline, trainer, signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcd1b547c65f4a9d8fed6175d049f59b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/06 20:14:27 INFO mlflow.transformers: 'runs:/0b2646cefe97455c807f4a21cefd19c6/fine_tuned' resolved as 'mlflow-artifacts:/869247621359487510/0b2646cefe97455c807f4a21cefd19c6/artifacts/fine_tuned'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2c296278915453ca1fd7060559c241c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/06 20:14:27 WARNING mlflow.transformers.model_io: Could not specify device parameter for this pipeline type.Falling back to loading the model with the default device.\n"
     ]
    }
   ],
   "source": [
    "model_loaded = mlflow.transformers.load_model(model_uri=model_info.model_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y probamos a hacer inferencia con 茅l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'spam', 'score': 0.9834991097450256}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_text = \"\"\"\n",
    "Want to learn how to make millions with no effort? Click here now! See for yourself! Guaranteed to make you instantly rich!\n",
    "Don't miss out you could be a winner!\n",
    "\"\"\"\n",
    "\n",
    "model_loaded(validation_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que funciona bien y lo marca como spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loaded.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y adem谩s vemos que lo ha cargado en la GPU, que es lo que le pasamos en `model_config`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por 煤ltimo paramos el servidor que hab谩ismo levantado en la terminal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
