<section class="section-block-markdown-cell">
<h1 id="Tokens">Tokens<a class="anchor-link" href="#Tokens">¶</a></h1>
</section>
<section class="section-block-markdown-cell">
<p>Ahora que están en auge los <code>LLM</code>s, no paramos de escuchar el número de <code>token</code>s que admite cada modelo, pero ¿qué son los <code>token</code>s? Son las unidades mínimas de representación de las palabras</p>
</section>
<section class="section-block-markdown-cell">
<p>Para explicar qué son los <code>token</code>s, primero veámoslo con un ejemplo práctico, vamos a usar el tokenizador de <code>OpenAI</code>, llamado <a href="https://github.com/openai/tiktoken">tiktoken</a>.</p>
<p>Así que, primero instalamos el paquete:</p>
<div class='highlight'><pre><code class="language-bash">pip install tiktoken
</code></pre></div>
</section>
<section class="section-block-markdown-cell">
<p>Una vez instalado creamos un tokenizador usando el modelo <code>cl100k_base</code>, que en el notebook de ejemplo <a href="https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb">How to count tokens with tiktoken</a> explica que es el usado por los modelos <code>gpt-4</code>, <code>gpt-3.5-turbo</code> y <code>text-embedding-ada-002</code></p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">tiktoken</span>
<span class="w"> </span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">tiktoken</span><span class="o">.</span><span class="n">get_encoding</span><span class="p">(</span><span class="s2">&quot;cl100k_base&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Ahora creamos una palabra de ejemplo para tokenizarla</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">example_word</span> <span class="o">=</span> <span class="s2">&quot;breakdown&quot;</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Y la tokenizamos</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">tokens</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">example_word</span><span class="p">)</span>
<span class="n">tokens</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>[9137, 2996]
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Se ha dividido la palabra en 2 <code>token</code>s, el <code>9137</code> y el <code>2996</code>. Vamos a ver a qué palabras corresponden</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">word1</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">decode</span><span class="p">([</span><span class="n">tokens</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
<span class="n">word2</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">decode</span><span class="p">([</span><span class="n">tokens</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
<span class="n">word1</span><span class="p">,</span> <span class="n">word2</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>(&#x27;break&#x27;, &#x27;down&#x27;)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>El tokenizador de <code>OpenAI</code> ha dividido la palabra <code>breakdown</code> en las palabras <code>break</code> y <code>down</code>. Es decir, ha dividido la palabra en 2 más sencillas.</p>
<p>Esto es importante, ya que cuando se dice que un <code>LLM</code> admite x <code>token</code>s no se refiere a que admite x palabras, sino a que admite x unidades mínimas de representación de las palabras.</p>
</section>
<section class="section-block-markdown-cell">
<p>Si tienes un texto y quieres ver el número de <code>token</code>s que tiene para el tokenizador de <code>OpenAI</code>, puedes verlo en la página <a href="https://platform.openai.com/tokenizer">Tokenizer</a>, que muestra cada <code>token</code> en un color diferente</p>
<img src="https://images.maximofn.com/tokenizer.webp" alt="tokenizer">
</section>
<section class="section-block-markdown-cell">
<p>Hemos visto el tokenizador de <code>OpenAI</code>, pero cada <code>LLM</code> podrá usar otro</p>
</section>
<section class="section-block-markdown-cell">
<p>Como hemos dicho, los <code>token</code>s son las unidades mínimas de representación de las palabras, así que vamos a ver cuántos tokens distintos tiene <code>tiktoken</code></p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">n_vocab</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">n_vocab</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Vocab size: </span><span class="si">{</span><span class="n">n_vocab</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Vocab size: 100277
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vamos a ver cómo tokeniza otro tipo de palabras</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">):</span>
<span class="w">    </span><span class="n">tokens</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
<span class="w">    </span><span class="n">decode_tokens</span> <span class="o">=</span> <span class="p">[]</span>
<span class="w">    </span><span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">:</span>
<span class="w">        </span><span class="n">decode_tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">decode</span><span class="p">([</span><span class="n">token</span><span class="p">]))</span>
<span class="w">    </span><span class="k">return</span> <span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">word</span> <span class="o">=</span> <span class="s2">&quot;dog&quot;</span>
<span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span> <span class="o">=</span> <span class="n">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Word: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2"> ==&amp;gt; tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">, decode_tokens: </span><span class="si">{</span><span class="n">decode_tokens</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">word</span> <span class="o">=</span> <span class="s2">&quot;tomorrow...&quot;</span>
<span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span> <span class="o">=</span> <span class="n">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Word: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2"> ==&amp;gt; tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">, decode_tokens: </span><span class="si">{</span><span class="n">decode_tokens</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">word</span> <span class="o">=</span> <span class="s2">&quot;artificial intelligence&quot;</span>
<span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span> <span class="o">=</span> <span class="n">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Word: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2"> ==&amp;gt; tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">, decode_tokens: </span><span class="si">{</span><span class="n">decode_tokens</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">word</span> <span class="o">=</span> <span class="s2">&quot;Python&quot;</span>
<span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span> <span class="o">=</span> <span class="n">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Word: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2"> ==&amp;gt; tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">, decode_tokens: </span><span class="si">{</span><span class="n">decode_tokens</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">word</span> <span class="o">=</span> <span class="s2">&quot;12/25/2023&quot;</span>
<span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span> <span class="o">=</span> <span class="n">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Word: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2"> ==&amp;gt; tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">, decode_tokens: </span><span class="si">{</span><span class="n">decode_tokens</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">word</span> <span class="o">=</span> <span class="s2">&quot;😊&quot;</span>
<span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span> <span class="o">=</span> <span class="n">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Word: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2"> ==&amp;gt; tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">, decode_tokens: </span><span class="si">{</span><span class="n">decode_tokens</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Word: dog ==&amp;gt; tokens: [18964], decode_tokens: [&#x27;dog&#x27;]
Word: tomorrow... ==&amp;gt; tokens: [38501, 7924, 1131], decode_tokens: [&#x27;tom&#x27;, &#x27;orrow&#x27;, &#x27;...&#x27;]
Word: artificial intelligence ==&amp;gt; tokens: [472, 16895, 11478], decode_tokens: [&#x27;art&#x27;, &#x27;ificial&#x27;, &#x27; intelligence&#x27;]
Word: Python ==&amp;gt; tokens: [31380], decode_tokens: [&#x27;Python&#x27;]
Word: 12/25/2023 ==&amp;gt; tokens: [717, 14, 914, 14, 2366, 18], decode_tokens: [&#x27;12&#x27;, &#x27;/&#x27;, &#x27;25&#x27;, &#x27;/&#x27;, &#x27;202&#x27;, &#x27;3&#x27;]
Word: 😊 ==&amp;gt; tokens: [76460, 232], decode_tokens: [&#x27;�&#x27;, &#x27;�&#x27;]
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Por último vamos a verlo con palabras en otro idioma</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">word</span> <span class="o">=</span> <span class="s2">&quot;perro&quot;</span>
<span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span> <span class="o">=</span> <span class="n">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Word: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2"> ==&amp;gt; tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">, decode_tokens: </span><span class="si">{</span><span class="n">decode_tokens</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">word</span> <span class="o">=</span> <span class="s2">&quot;perra&quot;</span>
<span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span> <span class="o">=</span> <span class="n">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Word: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2"> ==&amp;gt; tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">, decode_tokens: </span><span class="si">{</span><span class="n">decode_tokens</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">word</span> <span class="o">=</span> <span class="s2">&quot;mañana...&quot;</span>
<span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span> <span class="o">=</span> <span class="n">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Word: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2"> ==&amp;gt; tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">, decode_tokens: </span><span class="si">{</span><span class="n">decode_tokens</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">word</span> <span class="o">=</span> <span class="s2">&quot;inteligencia artificial&quot;</span>
<span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span> <span class="o">=</span> <span class="n">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Word: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2"> ==&amp;gt; tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">, decode_tokens: </span><span class="si">{</span><span class="n">decode_tokens</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">word</span> <span class="o">=</span> <span class="s2">&quot;Python&quot;</span>
<span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span> <span class="o">=</span> <span class="n">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Word: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2"> ==&amp;gt; tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">, decode_tokens: </span><span class="si">{</span><span class="n">decode_tokens</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">word</span> <span class="o">=</span> <span class="s2">&quot;12/25/2023&quot;</span>
<span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span> <span class="o">=</span> <span class="n">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Word: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2"> ==&amp;gt; tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">, decode_tokens: </span><span class="si">{</span><span class="n">decode_tokens</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">word</span> <span class="o">=</span> <span class="s2">&quot;😊&quot;</span>
<span class="n">tokens</span><span class="p">,</span> <span class="n">decode_tokens</span> <span class="o">=</span> <span class="n">encode_decode</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Word: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2"> ==&amp;gt; tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">, decode_tokens: </span><span class="si">{</span><span class="n">decode_tokens</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Word: perro ==&amp;gt; tokens: [716, 299], decode_tokens: [&#x27;per&#x27;, &#x27;ro&#x27;]
Word: perra ==&amp;gt; tokens: [79, 14210], decode_tokens: [&#x27;p&#x27;, &#x27;erra&#x27;]
Word: mañana... ==&amp;gt; tokens: [1764, 88184, 1131], decode_tokens: [&#x27;ma&#x27;, &#x27;ñana&#x27;, &#x27;...&#x27;]
Word: inteligencia artificial ==&amp;gt; tokens: [396, 39567, 8968, 21075], decode_tokens: [&#x27;int&#x27;, &#x27;elig&#x27;, &#x27;encia&#x27;, &#x27; artificial&#x27;]
Word: Python ==&amp;gt; tokens: [31380], decode_tokens: [&#x27;Python&#x27;]
Word: 12/25/2023 ==&amp;gt; tokens: [717, 14, 914, 14, 2366, 18], decode_tokens: [&#x27;12&#x27;, &#x27;/&#x27;, &#x27;25&#x27;, &#x27;/&#x27;, &#x27;202&#x27;, &#x27;3&#x27;]
Word: 😊 ==&amp;gt; tokens: [76460, 232], decode_tokens: [&#x27;�&#x27;, &#x27;�&#x27;]
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Podemos ver para palabras similares, en español se generan más <code>token</code>s que en inglés, por lo que para un mismo texto, con un número similar de palabras, el número de <code>token</code>s será mayor en español que en inglés</p>
</section>