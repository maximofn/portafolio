<p>
	<!-- Custom stylesheet, it must be in the same directory as the html file -->
	<!-- Loading mathjax macro --><!-- Load mathjax --><!-- MathJax configuration -->
<p>
<style>
	/* Media query para pantallas grandes */
	@media screen and (min-width: 1000px) {
		.container {
			flex-wrap: nowrap;
			display: flex;
			justify-content: space-between;
			height: 100vh; /* altura del viewport */
		}
		
		.indice {
			width: 25%; /* Ancho del índice en pantallas grandes */
			border-right: 1px solid #ccc;
			max-height: calc(100vh - 40px); /* Ajustar según tus necesidades. Aquí estamos restando el doble del padding para mantener todo visible */
			padding: 20px;
			box-sizing: border-box;
			overflow-y: auto; /* desplazamiento vertical cuando sea necesario */
		}
		
		.contenido {
			width: 70%; /* Ancho del contenido en pantallas grandes */
			max-height: calc(100vh - 40px); /* Ajustar según tus necesidades. Aquí estamos restando el doble del padding para mantener todo visible */
			padding: 20px;
			box-sizing: border-box;
			overflow-y: auto; /* desplazamiento vertical cuando sea necesario */
		}
	}
</style>
<!-- Open div notebook -->
<div id="notebook" class="border-box-sizing" tabindex="-1">
	<!-- Open div notebook container -->
	<div id="notebook-container" class="container">
		<!-- Open div indice -->
		<div class="indice">
			<!-- Open div index header -->
			<div class="cell border-box-sizing text_cell rendered">
				<h2 class="prompt input_prompt">
					<span style="
					color: var(--darkreader-text--heading-color, var(--darkreader-text--heading-2-color,
					var(--darkreader-text--headings-color)));
					font-family: var(--fontFamily); font-size: var(--fontSize);
					font-style: var(--fontStyle, inherit);
					font-weight: var(--fontWeight);
					letter-spacing: var(--letterSpacing);
					text-transform: var(--textTransform);
					background-color: transparent;
					--darkreader-inline-color: var(--darkreader-text--darkreader-text--heading-color,
					var(--darkreader-text--darkreader-text--heading-2-color, var(--darkreader-text--darkreader-text--headings-color)));
					--darkreader-inline-bgcolor: transparent;"
					data-darkreader-inline-color="" data-darkreader-inline-bgcolor="">
						Índice
					</span>
					<a class="anchor-link" style="
					font-family: var(--fontFamily);
					font-size: var(--fontSize);
					font-style: var(--fontStyle, inherit);
					font-weight: var(--fontWeight);
					letter-spacing: var(--letterSpacing);
					text-transform: var(--textTransform);
					background-color: transparent;
					--darkreader-inline-bgcolor: transparent;"
					href="#Índice" data-darkreader-inline-bgcolor="">
					</a>
				</h2>
			<!-- Close div index header -->
			</div>
			<!-- Index body -->
			<div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Tokenização-index">
									<a class="anchor-link" href="#Tokenização">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Tokenização</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Embeddings-de-entrada-index">
									<a class="anchor-link" href="#Embeddings-de-entrada">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Embeddings de entrada</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Codificador---decodificador-index">
									<a class="anchor-link" href="#Codificador---decodificador">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Codificador - decodificador</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Projeção-index">
									<a class="anchor-link" href="#Projeção">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Projeção</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Codificador-e-decodificador-x6-index">
									<a class="anchor-link" href="#Codificador-e-decodificador-x6">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Codificador e decodificador x6</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Atenção---Alimentação-index">
									<a class="anchor-link" href="#Atenção---Alimentação">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Atenção - Alimentação</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Atenção-index">
									<a class="anchor-link" href="#Atenção">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Atenção</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Alimentação-index">
									<a class="anchor-link" href="#Alimentação">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Alimentação</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Codificação-posicional-index">
									<a class="anchor-link" href="#Codificação-posicional">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Codificação posicional</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Add-&-Norm-index">
									<a class="anchor-link" href="#Add-&-Norm">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Add & Norm</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Mecanismos-de-atendimento-index">
									<a class="anchor-link" href="#Mecanismos-de-atendimento">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Mecanismos de atendimento</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Atenção-a-várias-cabeças-index">
									<a class="anchor-link" href="#Atenção-a-várias-cabeças">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Atenção a várias cabeças</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Atenção-ao-produto-de-ponto-de-escala-index">
									<a class="anchor-link" href="#Atenção-ao-produto-de-ponto-de-escala">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Atenção ao produto de ponto de escala</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h4 id="Atenção-ao-produto-de-pontos-da-escala-Endocer-index">
									<a class="anchor-link" href="#Atenção-ao-produto-de-pontos-da-escala-Endocer">
										<p style="margin-left: 80px; font-size: 12px; line-height: 1.5;">Atenção ao produto de pontos da escala Endocer</p>
									</a>
								</h4>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h5 id="Matmul-index">
									<a class="anchor-link" href="#Matmul">
										<p style="margin-left: 120px; font-size: 12px; line-height: 1.5;">Matmul</p>
									</a>
								</h5>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h5 id="Scale-index">
									<a class="anchor-link" href="#Scale">
										<p style="margin-left: 120px; font-size: 12px; line-height: 1.5;">Scale</p>
									</a>
								</h5>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h5 id="Mask-(opcional)-index">
									<a class="anchor-link" href="#Mask-(opcional)">
										<p style="margin-left: 120px; font-size: 12px; line-height: 1.5;">Mask (opcional)</p>
									</a>
								</h5>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h5 id="Softmax-index">
									<a class="anchor-link" href="#Softmax">
										<p style="margin-left: 120px; font-size: 12px; line-height: 1.5;">Softmax</p>
									</a>
								</h5>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h5 id="Matmul-index">
									<a class="anchor-link" href="#Matmul">
										<p style="margin-left: 120px; font-size: 12px; line-height: 1.5;">Matmul</p>
									</a>
								</h5>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h5 id="Resumo-index">
									<a class="anchor-link" href="#Resumo">
										<p style="margin-left: 120px; font-size: 12px; line-height: 1.5;">Resumo</p>
									</a>
								</h5>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h4 id="Decodificador-de-escala-mascarada-atenção-ao-produto-de-pontos-index">
									<a class="anchor-link" href="#Decodificador-de-escala-mascarada-atenção-ao-produto-de-pontos">
										<p style="margin-left: 80px; font-size: 12px; line-height: 1.5;">Decodificador de escala mascarada atenção ao produto de pontos</p>
									</a>
								</h4>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h5 id="Por-que-a-máscara-index">
									<a class="anchor-link" href="#Por-que-a-máscara">
										<p style="margin-left: 120px; font-size: 12px; line-height: 1.5;">Por que a máscara</p>
									</a>
								</h5>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h5 id="Mask-index">
									<a class="anchor-link" href="#Mask">
										<p style="margin-left: 120px; font-size: 12px; line-height: 1.5;">Mask</p>
									</a>
								</h5>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h4 id="Atenção-ao-produto-de-ponto-da-escala-do-codificador-decodificador-index">
									<a class="anchor-link" href="#Atenção-ao-produto-de-ponto-da-escala-do-codificador-decodificador">
										<p style="margin-left: 80px; font-size: 12px; line-height: 1.5;">Atenção ao produto de ponto da escala do codificador-decodificador</p>
									</a>
								</h4>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Resumo-index">
									<a class="anchor-link" href="#Resumo">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Resumo</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
			</div>
		<!-- Close div indice -->
		</div>
 
		<!-- Content -->
		<div class="contenido">
		<div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><a href="https://colab.research.google.com/github/maximofn/portafolio/blob/main/posts/notebooks_translated/2024-02-23-Transformers-from-top-to-the-bottom_PT.ipynb" target="_blank"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h1 id="Transformers---de-cima-para-baixo">
								<a class="anchor-link" href="#Transformers---de-cima-para-baixo">
									<p style="margin-left: 0px">Transformers - de cima para baixo</p>
								</a>
							</h1>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Nesta postagem, veremos como os Transformers funcionam de cima para baixo.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Este caderno foi traduzido automaticamente para torná-lo acessível a mais pessoas, por favor me avise se você vir algum erro de digitação..</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">## Transformador como uma caixa preta</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">A arquitetura do transformador foi criada para o problema de tradução, portanto, vamos explicá-la para esse problema.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Imagine o transformador como uma caixa preta, que recebe uma frase em um idioma e produz a mesma frase traduzida em outro idioma.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Transformador - caixa preta] (http://maximofn.com/wp-content/uploads/2024/02/Transformer-black-box.png)</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Tokenização">
								<a class="anchor-link" href="#Tokenização">
									<p style="margin-left: 10px">Tokenização</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Mas, como vimos na postagem <a href="https://maximofn.com/tokens/" target="_blank">tokens</a>, os modelos de linguagem não entendem as palavras como nós, eles precisam de números para poder realizar operações. Portanto, a sentença original do idioma precisa ser convertida em tokens por um tokenizador e, na saída, precisamos de um detokenizador para converter os tokens de saída em palavras.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="http://maximofn.com/wp-content/uploads/2024/02/Transformer-black-box-tokenizers.png" alt="Transformer - black box - tokenizers"></p></p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Assim, o tokenizador cria uma sequência de tokens $n_{input-tokens}$ e o destokenizador recebe uma sequência de tokens $n_{output-tokens}$.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Embeddings-de-entrada">
								<a class="anchor-link" href="#Embeddings-de-entrada">
									<p style="margin-left: 10px">Embeddings de entrada</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Na postagem <a href="https://maximofn.com/embeddings/" target="_blank">embeddings</a>, vimos que os embeddings são uma forma de representar palavras em um espaço vetorial. Portanto, os tokens de entrada são passados por uma camada de embeddings para convertê-los em vetores.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Em um resumo rápido, o processo de incorporação consiste em converter uma sequência de números (tokens) em uma sequência de vetores. Assim, é criado um novo espaço vetorial no qual as palavras que têm semelhança semântica estarão muito próximas.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="http://maximofn.com/wp-content/uploads/2023/12/word_embedding_3_dimmension.webp" alt="word_embedding_3_dimmension"></p></p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Se tivéssemos $n_{input-tokens}$ tokens, agora teríamos $n_{input-tokens}$ vetores. Cada um desses vetores tem um comprimento de $d_{model}$. Ou seja, cada token é convertido em um vetor que representa esse token em um espaço vetorial de dimensões $d_{model}$$.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Portanto, depois de passar pela camada de incorporação, a sequência de tokens $n_{input-tokens}$ se torna uma matriz de ($n_{input-tokens}$$ x $d_{model}$).</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Transformador - caixa preta - embeddings de entrada](http://maximofn.com/wp-content/uploads/2024/02/Transformer-black-box-input-embeddings.png)</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Codificador---decodificador">
								<a class="anchor-link" href="#Codificador---decodificador">
									<p style="margin-left: 10px">Codificador - decodificador</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vimos o transformador atuando como uma caixa preta, mas, na realidade, o transformador é uma arquitetura composta de duas partes, um codificador e um decodificador.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Transformador - codificador-decodificador] (http://maximofn.com/wp-content/uploads/2024/02/Transformer-encoder-decoder.png)</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">O codificador é responsável por comprimir as informações da frase de entrada, criando um espaço latente no qual as informações da frase de entrada são comprimidas. Em seguida, essas informações comprimidas entram no decodificador, que sabe como converter essas informações comprimidas em uma frase do idioma de saída.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">E como o decodificador converte essas informações compactadas em uma frase no idioma de saída? Bem, token por token. Para entender melhor, vamos esquecer os tokens de saída por um momento e imaginar que temos a seguinte arquitetura</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Transformador - codificador-decodificador (sem destokenizador)](http://maximofn.com/wp-content/uploads/2024/02/Transformer-encoder-decoder-no-detokenizer.png)</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Ou seja, a frase do idioma original é convertida em tokens, esses tokens são convertidos em embeddings, que entram no codificador, o codificador comprime as informações, o decodificador as pega e as converte em palavras do idioma de saída.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Assim, o decodificador gera uma nova palavra na saída a cada etapa.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="https://raw.githubusercontent.com/maximofn/portafolio/main/images/Transformer%20-%20encoder-decoder%20(no%20detokenizer" alt="Transformer - codificador-decodificador (sem detokenizador)"></p>.gif)</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Mas como o decodificador sabe qual palavra deve ser gerada a cada vez? Porque lhe é passada a frase que já foi traduzida e, a cada etapa, ele gera a próxima palavra. Em outras palavras, a cada etapa, o decodificador recebe a frase que traduziu até o momento e gera a próxima palavra.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Mas, mesmo assim, como ele sabe que precisa gerar a primeira palavra? Porque lhe é passada uma palavra especial que significa "começar a traduzir" e, a partir daí, ele gera as palavras seguintes.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">E, finalmente, como o transformador sabe que precisa parar de gerar palavras? Porque, quando termina de traduzir, ele gera uma palavra especial que significa "fim da tradução", que, quando volta para o transformador, significa que ele não gera mais palavras.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="https://raw.githubusercontent.com/maximofn/portafolio/main/images/Transformer%20-%20encoder-decoder%20(no%20detokenizer" alt="Transformer - encoder-decoder (no detokenizer) (input)"></p>%20(input).gif)</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Agora que já entendemos isso em palavras, o que é mais simples, vamos colocar o detokenizador de volta na saída.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Transformador - codificador-decodificador] (http://maximofn.com/wp-content/uploads/2024/02/Transformer-encoder-decoder.png)</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Portanto, o decodificador gerará tokens. Para saber que precisa iniciar uma frase, é inserido um token especial comumente chamado de <code><b>SOS</b></code> (Start Of Sentence) e, para saber que precisa terminar, ele gera outro token especial comumente chamado de <code><b>EOS</b></code> (End Of Sentence).</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">E, assim como o codificador, o token de entrada precisa passar por uma camada de incorporação para converter os tokens em representações vetoriais.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Supondo que cada token seja equivalente a uma palavra, o processo de tradução seria o seguinte</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="https://raw.githubusercontent.com/maximofn/portafolio/main/images/Transformer%20-%20encoder-decoder%20(detokenizer" alt="Transformer - encoder-decoder (detokenizer)"></p>.gif)</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">No momento, temos esta arquitetura</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Transformador - codificador-decodificador (detokenizador)](http://maximofn.com/wp-content/uploads/2024/02/Transformer-encoder-decoder-detokenizer-2.png)</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Projeção">
								<a class="anchor-link" href="#Projeção">
									<p style="margin-left: 10px">Projeção</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Dissemos que o decodificador recebe um token que passa pela camada de incorporação <code><b>Output embedding</b></code>.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">O decodificador <code><b>Output</b></code> cria um vetor para cada token, de modo que na saída do decodificador <code><b>Output</b></code> temos uma matriz de ($n_{output-tokens}$ x $d_{model}$).</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">O decodificador executa operações, mas gera uma matriz com a mesma dimensão. Portanto, ele precisa converter essa matriz em um token, e faz isso por meio de uma camada linear que gera uma matriz com a mesma dimensão dos possíveis tokens no idioma a ser traduzido (vocabulário de saída).</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Essa matriz corresponde aos logits de cada token possível e, portanto, é passada por uma camada softmax que converte esses logits em probabilidades. Ou seja, teremos a probabilidade de que cada token seja o próximo token.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Transformer - projeção](http://maximofn.com/wp-content/uploads/2024/02/Transformer-projection.png)</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Codificador-e-decodificador-x6">
								<a class="anchor-link" href="#Codificador-e-decodificador-x6">
									<p style="margin-left: 10px">Codificador e decodificador x6</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">No documento original, eles usam 6 camadas para o codificador e outras 6 camadas para o decodificador. Não há motivo para que sejam 6. Acho que eles tentaram vários valores e esse foi o que funcionou melhor para eles.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">A saída do último codificador é enviada para cada decodificador.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Transformador - codificador-decodificador (x6)](http://maximofn.com/wp-content/uploads/2024/02/Transformer-encoder-decoder-x6.png)</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Para simplificar o diagrama, vamos representá-lo da seguinte forma</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Transformador - codificador-decodificador (Nx)](http://maximofn.com/wp-content/uploads/2024/02/Transformer-encoder-decoder-Nx.png)</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Atenção---Alimentação">
								<a class="anchor-link" href="#Atenção---Alimentação">
									<p style="margin-left: 10px">Atenção - Alimentação</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vamos começar a examinar o que há dentro do codificador e do decodificador. Basicamente, o que você tem é um mecanismo de atenção e uma camada de avanço.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="http://maximofn.com/wp-content/uploads/2024/02/Transformer-encoder-decoder-attention-ff.png" alt="Transformador - codificador-decodificador - atenção-ff"></p></p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h3 id="Atenção">
								<a class="anchor-link" href="#Atenção">
									<p style="margin-left: 20px">Atenção</p>
								</a>
							</h3>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Podemos ver que três setas entram nos mecanismos de atenção. Veremos isso mais tarde, quando analisarmos em profundidade como funcionam os mecanismos de atenção.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Mas, por enquanto, podemos dizer que são operações realizadas para obter a relação que existe entre os tokens (e, portanto, a relação que existe entre as palavras).</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Antes dos transformadores, as redes neurais recorrentes eram usadas para o problema de tradução, que consistia em redes que recebiam um token de entrada, processavam-no e geravam outro token de saída. Em seguida, um segundo token era inserido, processado e outro token era gerado, e assim por diante com todos os tokens na sequência de entrada. O problema com essas redes é que, quando as frases eram muito longas, quando os últimos tokens eram inseridos, a rede "esquecia" os primeiros tokens. Por exemplo, em frases muito longas, poderia acontecer de o gênero do sujeito mudar ao longo da frase traduzida. E isso acontecia porque, depois de muitos tokens, a rede esquecia se o sujeito era masculino ou feminino.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Para resolver isso, a sequência inteira é inserida no mecanismo de atenção dos transformadores e as relações (atenção) entre todos os tokens são calculadas de uma só vez.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Isso é muito eficiente, pois em um único cálculo ele fornece a relação entre todos os tokens, independentemente do tamanho da sequência.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Embora essa seja uma grande vantagem e seja o que levou os transformadores a serem usados na maioria das melhores redes modernas, também é sua maior desvantagem, pois o cálculo da atenção é muito caro do ponto de vista computacional. Ele requer multiplicações de matrizes muito grandes.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Essas multiplicações são realizadas entre matrizes que correspondem às incorporações de cada um dos tokens por si só. Ou seja, a matriz que representa as incorporações dos tokens é multiplicada por ela mesma. Para realizar essa multiplicação, uma das matrizes deve ser girada (requisitos de álgebra para poder multiplicar matrizes). Assim, uma matriz é multiplicada por ela mesma; se a sequência de entrada tiver mais tokens, as matrizes que estão sendo multiplicadas serão maiores, uma em altura e outra em largura, de modo que a memória necessária para armazenar essas matrizes aumentará quadraticamente.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Portanto, à medida que o comprimento das sequências aumenta, a quantidade de memória necessária para armazenar essas matrizes cresce quadraticamente. E essa é uma grande limitação atual, a quantidade de memória que as GPUs têm, que é onde essas multiplicações geralmente são realizadas.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Uma única camada de atenção é usada no codificador para extrair as relações entre os tokens de entrada.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Duas camadas de atenção são usadas no decodificador, uma para extrair as relações entre os tokens de saída e outra para extrair as relações entre os tokens do codificador e os tokens do decodificador.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h3 id="Alimentação">
								<a class="anchor-link" href="#Alimentação">
									<p style="margin-left: 20px">Alimentação</p>
								</a>
							</h3>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Após a camada de atenção, a sequência entra em uma camada de <code><b>Feed forward</b></code> que tem duas finalidades</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">
								<ul>
									<li>Uma delas é adicionar não linearidades. Como explicamos, a atenção é obtida por meio de multiplicações de matrizes dos tokens das sequências de entrada. Mas se nenhuma camada não linear for aplicada a uma rede, no final, toda a arquitetura poderá ser resumida em alguns cálculos lineares. Portanto, as redes neurais não seriam capazes de resolver problemas não lineares. Portanto, essa camada é adicionada para acrescentar a não linearidade.</li>
									<ul><li>Outra é a extração de recursos. Embora a atenção já extraia recursos, esses são recursos das relações entre tokens. Mas essa camada <code><b>Feed forward</b></code> é responsável por extrair recursos dos próprios tokens. Ou seja, os recursos são extraídos de cada token que são considerados importantes para o problema que está sendo resolvido.</li></ul>
								</ul>
							</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Codificação-posicional">
								<a class="anchor-link" href="#Codificação-posicional">
									<p style="margin-left: 10px">Codificação posicional</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Explicamos que na camada de atenção são obtidas as relações entre os tokens, que essa relação é calculada por multiplicações de matrizes e que essas multiplicações são realizadas entre a matriz de incorporação por si só. Portanto, nas sentenças <code><b>O gato come peixe</b></code> e <code><b>O peixe come gato</b></code>, a relação entre <code><b>o</b></code> e <code><b>gato</b></code> é a mesma em ambas as sentenças, uma vez que a relação é calculada por meio de multiplicações de matrizes dos embeddings de <code><b>o</b></code> e <code><b>gato</b></code>.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Entretanto, na primeira, <code><b>the</b></code> se refere ao <code><b>cat</b></code>, enquanto na segunda <code><b>the</b></code> se refere ao <code><b>fish</b></code>. Portanto, além das relações entre as palavras, precisamos ter algum mecanismo para indicar sua posição na frase.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">No documento, eles propõem a introdução de um mecanismo de atenção que é responsável por adicionar valores aos vetores de incorporação.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Transformador - codificação posicional](http://maximofn.com/wp-content/uploads/2024/02/Transformer-positional-encoding.png)</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">A fórmula para calcular esses valores é</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Transformador - codificação posicional (fórmula)](http://maximofn.com/wp-content/uploads/2024/02/Transformer-positional-encoding-formula.png)</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Como isso é um pouco difícil de entender, vamos ver como seria uma distribuição de valores da "codificação posicional".</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Transformador - codificação posicional (diagrama)](http://maximofn.com/wp-content/uploads/2024/02/Transformer-positional-encoding-diagram.png)</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">O primeiro token terá os valores da primeira linha (a inferior) adicionados a ele, o segundo token terá os valores da segunda linha, e assim por diante, o que causa uma alteração nos embeddings, conforme mostrado na figura. Visto em duas dimensões, você pode ver as ondas que estão sendo adicionadas.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Essas ondas significam que, quando são feitos cálculos de atenção, as palavras mais próximas estão mais relacionadas do que as palavras mais distantes.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Mas podemos pensar em algo: se o processo de incorporação consiste em criar um espaço vetorial no qual palavras com o mesmo significado semântico estão próximas umas das outras, essa relação não seria quebrada se valores fossem adicionados às incorporações?</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Se olharmos novamente para o exemplo do espaço vetorial anterior</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="http://maximofn.com/wp-content/uploads/2023/12/word_embedding_3_dimmension.webp" alt="word_embedding_3_dimmension"></p></p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Podemos ver que os valores variam mais ou menos de -1000 a 1000 em cada eixo, enquanto o gráfico de distribuições</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Transformador - codificação posicional (diagrama)](http://maximofn.com/wp-content/uploads/2024/02/Transformer-positional-encoding-diagram.png)</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">variam de -1 a 1, pois esse é o intervalo das funções seno e cosseno.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Portanto, estamos variando em um intervalo entre -1 e 1 os valores dos embeddings, que são duas ou três ordens de magnitude a mais, de modo que a variação será muito pequena em comparação com o valor dos embeddings.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Portanto, já temos uma maneira de conhecer a relação da posição dos tokens na frase.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Add-&-Norm">
								<a class="anchor-link" href="#Add-&-Norm">
									<p style="margin-left: 10px">Add & Norm</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Resta apenas um bloco de alto nível, que são as camadas <code><b>Add & Norm</b></code>.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Transformer - Add & norm](http://maximofn.com/wp-content/uploads/2024/02/Transformer-Add-norm.png)</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Essas camadas são adicionadas após cada camada de atenção e camada de avanço. Essa camada agrega a saída e a entrada de uma camada. Isso é chamado de conexões residuais e tem as seguintes vantagens</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">
								<ul>
									<li>Durante o treinamento:</li>
									<ul><li>Reduzem o problema do desvanecimento do gradiente: Quando uma rede neural é muito grande, no processo de treinamento, os gradientes se tornam cada vez menores à medida que você se aprofunda nas camadas. Isso faz com que as camadas mais profundas não consigam atualizar bem seus pesos. As conexões residuais permitem que os gradientes passem diretamente pelas camadas, o que ajuda a mantê-los grandes o suficiente para que o modelo continue aprendendo, mesmo nas camadas mais profundas.</li></ul>
									<ul><li>Permitir o treinamento de redes mais profundas: ao ajudar a atenuar o problema do desvanecimento do gradiente, as conexões residuais também facilitam o treinamento de redes mais profundas, o que pode levar a um melhor desempenho.</li></ul>
									<li>Durante a inferência:</li>
									<ul><li>Permitem a transmissão de informações entre diferentes camadas: como as conexões residuais permitem que a saída de cada camada se torne a soma da entrada e da saída da camada, as informações das camadas mais profundas são transmitidas para as camadas de nível mais alto. Isso pode ser benéfico em muitas tarefas, especialmente quando as informações de baixo nível e de alto nível podem ser úteis.</li></ul>
									<ul><li>Melhorar a robustez do modelo: como as conexões residuais permitem que as camadas aprendam melhor em camadas mais profundas, os modelos com conexões residuais podem ser mais robustos a perturbações nos dados de entrada.</li></ul>
									<ul><li>Permitem a recuperação de informações perdidas: se algumas informações forem perdidas durante a transformação em qualquer camada, as conexões residuais podem permitir que essas informações sejam recuperadas nas camadas subsequentes.</li></ul>
								</ul>
							</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Essa camada é chamada de <code><b>Add & Norm</b></code>, já vimos a <code><b>Add</b></code>, vamos dar uma olhada na <code><b>Norm</b></code>. A normalização é adicionada para que a adição da entrada e da saída não acione os valores.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Já vimos todas as camadas de alto nível do transformador.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="http://maximofn.com/wp-content/uploads/2023/12/transformer-scaled.webp" alt="transformer"></p></p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">para que possamos examinar a parte mais importante que dá nome ao documento, os mecanismos de atenção.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Mecanismos-de-atendimento">
								<a class="anchor-link" href="#Mecanismos-de-atendimento">
									<p style="margin-left: 10px">Mecanismos de atendimento</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h3 id="Atenção-a-várias-cabeças">
								<a class="anchor-link" href="#Atenção-a-várias-cabeças">
									<p style="margin-left: 20px">Atenção a várias cabeças</p>
								</a>
							</h3>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Antes de analisarmos o mecanismo real da atenção, temos que analisar a atenção de várias cabeças.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Transformador - atenção a vários cabeçotes] (http://maximofn.com/wp-content/uploads/2024/02/Transformer-multi-head-attention.png)</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Quando explicamos as camadas de alto nível, vimos que nas camadas de atenção havia 3 setas, que são <code><b>Q</b></code>, <code><b>K</b></code> e <code><b>V</b></code>. Essas são matrizes que correspondem às informações de tokens; no caso do mecanismo de atenção do codificador, elas correspondem aos tokens da sentença do idioma original e, no caso da camada de atenção do decodificador, elas correspondem aos tokens da sentença que foi traduzida até o momento e à saída do codificador.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Não nos importamos com a origem dos tokens agora, apenas lembre-se de que eles correspondem a tokens. Conforme explicado acima, os tokens são convertidos em embeddings, de modo que <code><b>Q</b></code>, <code><b>K</b></code> e <code><b>V</b></code> são matrizes de tamanho ($n_{tokens}$ x $d_{model}$). Normalmente, a dimensão de incorporação ($d_{model}$) é um número grande, como 512, 1024, 2048 etc. (não precisa ser uma potência de 2, esses são apenas exemplos).</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Já explicamos que os embeddings são representações vetoriais de tokens. Ou seja, os tokens são convertidos em espaços vetoriais nos quais as palavras com significado semântico semelhante estão muito próximas.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Portanto, de todas essas dimensões, algumas podem estar relacionadas a características morfológicas, outras a características sintáticas, outras a características semânticas etc. Portanto, faz sentido calcular os mecanismos de atenção entre as dimensões de embeddings com características semelhantes.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Lembre-se de que os mecanismos de atenção buscam a similaridade entre as palavras, portanto, faz sentido buscar a similaridade entre recursos semelhantes.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Portanto, antes de calcular os mecanismos de atenção, as dimensões de incorporação são separadas em grupos de características semelhantes, e os mecanismos de atenção entre esses grupos são calculados.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">E como essa separação é feita? Você teria que procurar dimensões semelhantes, mas fazer isso em um espaço de 512, 1024, 2048 etc. dimensões é muito complicado. Além disso, não é possível saber quais características são semelhantes e, em cada caso, as características consideradas semelhantes mudarão.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">As projeções lineares são, portanto, usadas para separar as dimensões em grupos. Em outras palavras, os embeddings passam por camadas lineares que os separam em grupos de características semelhantes. Dessa forma, durante o treinamento do transformador, os pesos das camadas lineares serão alterados até chegar a um ponto em que o agrupamento seja feito de maneira ideal.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Agora podemos ter a questão de em quantos grupos devemos nos dividir. No documento original, ele é dividido em 8 grupos, mas não há motivo para que sejam 8. Acho que eles tentaram vários valores e esse foi o que funcionou melhor para eles.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Uma vez que as incorporações tenham sido divididas em grupos semelhantes e a atenção nos diferentes grupos tenha sido calculada, os resultados são concatenados. Isso é lógico, suponhamos que tenhamos um ebedding de 512 dimensões e o dividamos em 8 grupos de 64 dimensões. Se calcularmos a atenção em cada um dos grupos, teremos 8 matrizes de atenção de 64 dimensões; se as concatenarmos, teremos uma matriz de atenção de 512 dimensões, que é a mesma dimensão que tínhamos no início.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Mas a concatenação faz com que todos os recursos fiquem juntos. As primeiras 64 dimensões correspondem a um recurso, as 64 seguintes a outro, e assim por diante. Portanto, para misturá-los novamente, você passa por uma camada linear que mistura todos os recursos. E essa combinação é aprendida durante o treinamento.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h3 id="Atenção-ao-produto-de-ponto-de-escala">
								<a class="anchor-link" href="#Atenção-ao-produto-de-ponto-de-escala">
									<p style="margin-left: 20px">Atenção ao produto de ponto de escala</p>
								</a>
							</h3>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Chegamos à parte mais importante do transformador, o mecanismo de atenção, a "atenção do produto escalonado de pontos".</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Transformador - atenção ao produto de pontos em escala](http://maximofn.com/wp-content/uploads/2024/02/Transformer-scaled-dot-product-attention.png)</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Transformador - fórmula de atenção do produto escalonado](http://maximofn.com/wp-content/uploads/2024/02/Transformer-scaled-dot-product-attention-formula.png)</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Como vimos, na arquitetura do Transformer há três mecanismos de atendimento</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="http://maximofn.com/wp-content/uploads/2023/12/transformer-scaled.webp" alt="transformer"></p></p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">O codificador, o decodificador e o codificador-decodificador. Portanto, vamos explicá-los separadamente, pois, embora sejam praticamente os mesmos, eles têm algumas pequenas diferenças.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h4 id="Atenção-ao-produto-de-pontos-da-escala-Endocer">
								<a class="anchor-link" href="#Atenção-ao-produto-de-pontos-da-escala-Endocer">
									<p style="margin-left: 30px">Atenção ao produto de pontos da escala Endocer</p>
								</a>
							</h4>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vamos examinar novamente o diagrama de blocos e a fórmula.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Transformador - atenção ao produto de pontos em escala](http://maximofn.com/wp-content/uploads/2024/02/Transformer-scaled-dot-product-attention.png)</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Transformador - fórmula de atenção do produto escalonado](http://maximofn.com/wp-content/uploads/2024/02/Transformer-scaled-dot-product-attention-formula.png)</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Primeiro, vamos entender por que havia três setas entrando nas camadas de atenção. Se observarmos a arquitetura do transformador, a entrada do codificador se divide em três e entra na camada de atenção.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="http://maximofn.com/wp-content/uploads/2023/12/transformer-scaled.webp" alt="transformer"></p></p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Portanto, <code><b>K</b></code>, <code><b>Q</b></code> e <code><b>V</b></code> são o resultado da incorporação e da codificação posicional. A mesma matriz é colocada na camada de atenção três vezes. Devemos lembrar que essa matriz consistia em uma lista de todos os tokens ($n_{tokens}$), e cada token foi convertido em um vetor de embeddings de dimensão $d_{model}$, de modo que a dimensão da matriz será ($n_{tokens}$ x $d_{model}$).</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">O significado de <code><b>K</b></code>, <code><b>Q</b></code> e <code><b>V</b></code> vem dos bancos de dados <code><b>key</b></code>, <code><b>query</b></code> e <code><b>value</b></code>. O mecanismo de atenção recebe as matrizes <code><b>Q</b></code> e <code><b>K</b></code>, ou seja, a pergunta e a chave, e a saída é a matriz <code><b>V</b></code>, ou seja, a resposta.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vamos analisar cada bloco separadamente para entender melhor isso.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h5 id="Matmul">
								<a class="anchor-link" href="#Matmul">
									<p style="margin-left: 40px">Matmul</p>
								</a>
							</h5>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Esse bloco corresponde à multiplicação matricial das matrizes <code><b>Q</b></code> e <code><b>K</b></code>. Mas, para realizar essa operação, temos de fazê-la com a matriz transposta de <code><b>K</b></code>. Como as duas matrizes têm dimensão ($n_{tokens}$ x $d_{model}$), para multiplicá-las, a matriz <code><b>K</b></code> precisa ser transposta.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Portanto, teremos uma multiplicação de uma matriz de dimensão ($n_{tokens}$$ x $d_{model}$$) por outra matriz de dimensão ($d_{model}$$ x $n_{tokens}$), de modo que o resultado será uma matriz de dimensão ($n_{tokens}$$ x $n_{tokens}$).</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Transformer - matmul](http://maximofn.com/wp-content/uploads/2024/02/Transformer-matmul.png)</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Como podemos ver, o resultado é uma matriz em que a diagonal é a multiplicação da incorporação de cada token por ela mesma, e o restante das posições são as multiplicações entre as incorporações de cada token.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Agora vamos ver por que essa multiplicação é feita. Na postagem anterior [Measuring similarity between embeddings] (https://maximofn.com/embeddings-similarity/), vimos que uma maneira de obter a similaridade entre dois vetores de incorporação é calcular o cosseno</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Na figura acima, é possível ver que a multiplicação entre as matrizes <code><b>Q</b></code> e <code><b>K</b></code> corresponde à multiplicação dos embeddings de cada token. A multiplicação entre dois vetores é realizada da seguinte forma</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">$$ "\mathbf. \mathbf{V} = \mathbf{U}| \mathbf{V}| \cos(\theta)$$$.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Ou seja, temos a multiplicação das normas por seu cosseno. Se os vetores fossem unitários, ou seja, suas normas fossem 1, a multiplicação de dois vetores seria igual ao cosseno entre os dois vetores, que é uma das medidas de similaridade entre vetores.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Assim, como em cada posição da matriz resultante temos a multiplicação entre os vetores de incorporação de cada token, na realidade, cada posição da matriz representará a similaridade entre cada token.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Relembrando o que eram embeddings, os embeddings eram representações vetoriais de tokens em um espaço vetorial, em que os tokens com similaridade semântica estão próximos uns dos outros.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Assim, com essa multiplicação, obtivemos uma matriz de similaridade entre os tokens da frase</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="http://maximofn.com/wp-content/uploads/2024/02/Transformer-matmul-similarity-matrix.png" alt="Transformer - matmul - similarity matrix"></p></p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Os elementos diagonais têm similaridade máxima (verde), os elementos de canto têm similaridade mínima (vermelho) e o restante dos elementos tem similaridade intermediária.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h5 id="Scale">
								<a class="anchor-link" href="#Scale">
									<p style="margin-left: 40px">Scale</p>
								</a>
							</h5>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vejamos novamente o diagrama de atenção do produto escalar de pontos e sua fórmula</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Transformador - atenção ao produto de pontos em escala](http://maximofn.com/wp-content/uploads/2024/02/Transformer-scaled-dot-product-attention.png)</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Transformador - fórmula de atenção do produto escalonado](http://maximofn.com/wp-content/uploads/2024/02/Transformer-scaled-dot-product-attention-formula.png)</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Dissemos que se, ao multiplicar <code><b>Q</b></code> por <code><b>K</b></code>, fizéssemos a multiplicação entre os vetores de incorporação e que, se esses vetores tivessem norma 1, o resultado seria a similaridade entre os vetores. Mas como os vetores não têm norma 1, o resultado pode ter valores muito altos, então normalizamos dividindo pela raiz quadrada da dimensão dos vetores de incorporação.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h5 id="Mask-(opcional)">
								<a class="anchor-link" href="#Mask-(opcional)">
									<p style="margin-left: 40px">Mask (opcional)</p>
								</a>
							</h5>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">O mascaramento é opcional e não é usado no codificador, portanto, não o explicaremos no momento para não confundir o leitor.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Transformador - atenção ao produto de pontos em escala](http://maximofn.com/wp-content/uploads/2024/02/Transformer-scaled-dot-product-attention.png)</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Transformador - fórmula de atenção do produto escalonado](http://maximofn.com/wp-content/uploads/2024/02/Transformer-scaled-dot-product-attention-formula.png)</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h5 id="Softmax">
								<a class="anchor-link" href="#Softmax">
									<p style="margin-left: 40px">Softmax</p>
								</a>
							</h5>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Embora tenhamos dividido pela raiz quadrada da dimensão dos vetores de incorporação, poderíamos fazer com que a similaridade entre os vetores de incorporação ficasse entre os valores 0 e 1, portanto, para garantir isso, passamos por uma camada softmax.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Transformador - atenção ao produto de pontos em escala](http://maximofn.com/wp-content/uploads/2024/02/Transformer-scaled-dot-product-attention.png)</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Transformador - fórmula de atenção do produto escalonado](http://maximofn.com/wp-content/uploads/2024/02/Transformer-scaled-dot-product-attention-formula.png)</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="http://maximofn.com/wp-content/uploads/2024/02/Transformer-matmul-similarity-matrix-softmax.png" alt="Transformer - matmul - similarity matrix softmax"></p></p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h5 id="Matmul">
								<a class="anchor-link" href="#Matmul">
									<p style="margin-left: 40px">Matmul</p>
								</a>
							</h5>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Agora que temos uma matriz de similaridade entre os vetores de incorporação, vamos multiplicá-la pela matriz <code><b>V</b></code>, que representa as incorporações dos tokens.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Transformador - matmul2](http://maximofn.com/wp-content/uploads/2024/02/Transformer-matmul2.png)</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">A multiplicação nos dá</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Transformer - matmul2 result](http://maximofn.com/wp-content/uploads/2024/02/Transformer-matmul2-result.png)</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Obtemos uma matriz com uma mistura de incorporações com sua similaridade. Em cada linha, obtemos uma mistura das incorporações, em que cada elemento da incorporação é ponderado de acordo com a similaridade do token nessa linha com o restante dos tokens.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Além disso, temos novamente uma matriz de tamanho ($n_{tokens}$ x $d_{model}$), que é a mesma dimensão que tínhamos no início.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h5 id="Resumo">
								<a class="anchor-link" href="#Resumo">
									<p style="margin-left: 40px">Resumo</p>
								</a>
							</h5>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Em resumo, podemos dizer que a <code><b>atenção ao produto de ponto escalonado</b></code> é um mecanismo que calcula a similaridade entre os tokens de uma frase e, a partir dessa similaridade, calcula uma matriz de saída que corresponde a uma mistura de embeddings ponderados de acordo com a similaridade dos tokens.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h4 id="Decodificador-de-escala-mascarada-atenção-ao-produto-de-pontos">
								<a class="anchor-link" href="#Decodificador-de-escala-mascarada-atenção-ao-produto-de-pontos">
									<p style="margin-left: 30px">Decodificador de escala mascarada atenção ao produto de pontos</p>
								</a>
							</h4>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vamos examinar novamente a arquitetura do transformador.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="http://maximofn.com/wp-content/uploads/2023/12/transformer-scaled.webp" alt="transformer"></p></p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Como podemos ver, nesse caso, a "atenção ao produto escalonado de pontos" tem a palavra "mascarado". Primeiro, explicaremos por que esse mascaramento é necessário e, em seguida, veremos como ele é feito.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h5 id="Por-que-a-máscara">
								<a class="anchor-link" href="#Por-que-a-máscara">
									<p style="margin-left: 40px">Por que a máscara</p>
								</a>
							</h5>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Como dissemos, o transformador foi inicialmente concebido como um tradutor, mas, em geral, é uma arquitetura na qual você coloca uma sequência e ela produz outra sequência. No entanto, quando se trata de treinamento, é necessário fornecer a sequência de entrada e a sequência de saída e, a partir daí, o transformador aprende a traduzir.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Por outro lado, dissemos que o transformador gera um novo token a cada vez. Ou seja, ele recebe a sequência de entrada no codificador e um token de início de sequência especial no decodificador e, a partir daí, gera o primeiro token da sequência de saída.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Em seguida, a sequência de entrada é colocada de volta no codificador e o token gerado anteriormente no decodificador e, a partir daí, ele gera o segundo token da sequência de saída.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Em seguida, a sequência de entrada é colocada de volta no codificador e os dois tokens gerados anteriormente no decodificador e, a partir daí, ele gera o terceiro token da sequência de saída.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">E assim por diante, até gerar um token especial de fim de sequência.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Mas no treinamento, como a sequência de entrada e saída é fornecida a ele de uma só vez, precisamos mascarar os tokens que ele ainda não gerou para que não possa vê-los.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h5 id="Mask">
								<a class="anchor-link" href="#Mask">
									<p style="margin-left: 40px">Mask</p>
								</a>
							</h5>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vamos examinar novamente o diagrama de blocos e a fórmula.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Transformador - atenção ao produto de pontos em escala](http://maximofn.com/wp-content/uploads/2024/02/Transformer-scaled-dot-product-attention.png)</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Transformador - fórmula de atenção do produto escalonado](http://maximofn.com/wp-content/uploads/2024/02/Transformer-scaled-dot-product-attention-formula.png)</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">O mascaramento é feito após o <code><b>Scale</b></code> e antes do <code><b>Softmax</b></code>. Como precisamos mascarar os tokens "futuros", o que pode ser feito é multiplicar a matriz <code><b>Scale</b></code> resultante por uma matriz que tenha 0 nas posições que queremos mascarar e 1 nas posições que não queremos mascarar.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Transformador - Máscara] (http://maximofn.com/wp-content/uploads/2024/02/Transformer-Mask.png)</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Ao fazer isso, obtemos a mesma matriz de antes, mas com posições mascaradas.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Transformer - Mask resutl](http://maximofn.com/wp-content/uploads/2024/02/Transformer-Mask-resutl.png)</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Agora, o resultado do <code><b>Scaled dot product attention</b></code> é uma matriz com os embeddings dos tokens ponderados de acordo com a similaridade dos tokens, mas com os tokens que não devem ser mascarados.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h4 id="Atenção-ao-produto-de-ponto-da-escala-do-codificador-decodificador">
								<a class="anchor-link" href="#Atenção-ao-produto-de-ponto-da-escala-do-codificador-decodificador">
									<p style="margin-left: 30px">Atenção ao produto de ponto da escala do codificador-decodificador</p>
								</a>
							</h4>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vamos examinar novamente a arquitetura do transformador.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="http://maximofn.com/wp-content/uploads/2023/12/transformer-scaled.webp" alt="transformer"></p></p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Agora vemos que o mecanismo de atenção recebe duas vezes a saída do codificador e uma vez a atenção mascarada do decodificador. Portanto, "K" e "V" são a saída do codificador e "Q" é a saída do decodificador.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Transformador - atenção ao produto de pontos em escala](http://maximofn.com/wp-content/uploads/2024/02/Transformer-scaled-dot-product-attention.png)</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Transformador - fórmula de atenção do produto escalonado](http://maximofn.com/wp-content/uploads/2024/02/Transformer-scaled-dot-product-attention-formula.png)</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Portanto, nesse bloco de atenção, primeiro é calculada a similaridade entre a sentença do decodificador e a sentença do codificador, ou seja, é calculada a similaridade entre a sentença que foi traduzida até o momento e a sentença original.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Essa semelhança é então multiplicada pela sentença do codificador, ou seja, é obtida uma mistura de embeddings da sentença original, ponderada de acordo com a semelhança da sentença traduzida até o momento.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Resumo">
								<a class="anchor-link" href="#Resumo">
									<p style="margin-left: 10px">Resumo</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Percorremos o transformador do nível mais alto ao mais baixo, para que você já tenha uma noção de como ele funciona.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="http://maximofn.com/wp-content/uploads/2023/12/transformer-scaled.webp" alt="transformer"></p></p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Transformador - atenção a vários cabeçotes] (http://maximofn.com/wp-content/uploads/2024/02/Transformer-multi-head-attention.png)</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Transformador - atenção ao produto de pontos em escala](http://maximofn.com/wp-content/uploads/2024/02/Transformer-scaled-dot-product-attention.png)</p>
						</div>
					</div>
				</div>
			</div>
		</div>
	<!-- Close class contenido -->
	</div>
<!-- Close div notebook container -->
</div>
<!-- Close div notebook -->
</div>

