<p>
	<!-- Custom stylesheet, it must be in the same directory as the html file -->
	<!-- Loading mathjax macro --><!-- Load mathjax --><!-- MathJax configuration -->
<p>
<style>
	/* Media query para pantallas grandes */
	@media screen and (min-width: 1000px) {
		.container {
			flex-wrap: nowrap;
			display: flex;
			justify-content: space-between;
			height: 100vh; /* altura del viewport */
		}
		
		.indice {
			width: 25%; /* Ancho del índice en pantallas grandes */
			border-right: 1px solid #ccc;
			max-height: calc(100vh - 40px); /* Ajustar según tus necesidades. Aquí estamos restando el doble del padding para mantener todo visible */
			padding: 20px;
			box-sizing: border-box;
			overflow-y: auto; /* desplazamiento vertical cuando sea necesario */
		}
		
		.contenido {
			width: 70%; /* Ancho del contenido en pantallas grandes */
			max-height: calc(100vh - 40px); /* Ajustar según tus necesidades. Aquí estamos restando el doble del padding para mantener todo visible */
			padding: 20px;
			box-sizing: border-box;
			overflow-y: auto; /* desplazamiento vertical cuando sea necesario */
		}
	}
</style>
<!-- Open div notebook -->
<div id="notebook" class="border-box-sizing" tabindex="-1">
	<!-- Open div notebook container -->
	<div id="notebook-container" class="container">
		<!-- Open div indice -->
		<div class="indice">
			<!-- Open div index header -->
			<div class="cell border-box-sizing text_cell rendered">
				<h2 class="prompt input_prompt">
					<span style="
					color: var(--darkreader-text--heading-color, var(--darkreader-text--heading-2-color,
					var(--darkreader-text--headings-color)));
					font-family: var(--fontFamily); font-size: var(--fontSize);
					font-style: var(--fontStyle, inherit);
					font-weight: var(--fontWeight);
					letter-spacing: var(--letterSpacing);
					text-transform: var(--textTransform);
					background-color: transparent;
					--darkreader-inline-color: var(--darkreader-text--darkreader-text--heading-color,
					var(--darkreader-text--darkreader-text--heading-2-color, var(--darkreader-text--darkreader-text--headings-color)));
					--darkreader-inline-bgcolor: transparent;"
					data-darkreader-inline-color="" data-darkreader-inline-bgcolor="">
						Índice
					</span>
					<a class="anchor-link" style="
					font-family: var(--fontFamily);
					font-size: var(--fontSize);
					font-style: var(--fontStyle, inherit);
					font-weight: var(--fontWeight);
					letter-spacing: var(--letterSpacing);
					text-transform: var(--textTransform);
					background-color: transparent;
					--darkreader-inline-bgcolor: transparent;"
					href="#Índice" data-darkreader-inline-bgcolor="">
					</a>
				</h2>
			<!-- Close div index header -->
			</div>
			<!-- Index body -->
			<div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Instalación-index">
									<a class="anchor-link" href="#Instalación">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Instalación</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Inferencia-con-`pipeline`-index">
									<a class="anchor-link" href="#Inferencia-con-`pipeline`">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Inferencia con <code><b>pipeline</b></code></p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Tareas-index">
									<a class="anchor-link" href="#Tareas">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Tareas</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Uso-de-`pipeline`-index">
									<a class="anchor-link" href="#Uso-de-`pipeline`">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Uso de <code><b>pipeline</b></code></p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Cómo-funciona-`pipeline`-index">
									<a class="anchor-link" href="#Cómo-funciona-`pipeline`">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Cómo funciona <code><b>pipeline</b></code></p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Inferencia-con-`AutoClass`-y-`pipeline`-index">
									<a class="anchor-link" href="#Inferencia-con-`AutoClass`-y-`pipeline`">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Inferencia con <code><b>AutoClass</b></code> y <code><b>pipeline</b></code></p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Tokenización-con-`AutoTokenizer`-index">
									<a class="anchor-link" href="#Tokenización-con-`AutoTokenizer`">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Tokenización con <code><b>AutoTokenizer</b></code></p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Modelo-`AutoModel`-index">
									<a class="anchor-link" href="#Modelo-`AutoModel`">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Modelo <code><b>AutoModel</b></code></p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Modelo-`AutoModelFor`-index">
									<a class="anchor-link" href="#Modelo-`AutoModelFor`">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Modelo <code><b>AutoModelFor</b></code></p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Inferencia-solo-con-`AutoClass`-index">
									<a class="anchor-link" href="#Inferencia-solo-con-`AutoClass`">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Inferencia solo con <code><b>AutoClass</b></code></p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Generación-de-texto-casual-index">
									<a class="anchor-link" href="#Generación-de-texto-casual">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Generación de texto casual</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Clasificación-de-texto-index">
									<a class="anchor-link" href="#Clasificación-de-texto">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Clasificación de texto</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Clasificación-de-tokens-index">
									<a class="anchor-link" href="#Clasificación-de-tokens">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Clasificación de tokens</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Respuesta-a-preguntas-(question-answering)-index">
									<a class="anchor-link" href="#Respuesta-a-preguntas-(question-answering)">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Respuesta a preguntas (question answering)</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Modelización-del-lenguaje-enmascarado-(Masked-language-modeling)-index">
									<a class="anchor-link" href="#Modelización-del-lenguaje-enmascarado-(Masked-language-modeling)">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Modelización del lenguaje enmascarado (Masked language modeling)</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Personalización-del-modelo-index">
									<a class="anchor-link" href="#Personalización-del-modelo">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Personalización del modelo</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Tokenización-index">
									<a class="anchor-link" href="#Tokenización">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Tokenización</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Padding-index">
									<a class="anchor-link" href="#Padding">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Padding</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Truncado-index">
									<a class="anchor-link" href="#Truncado">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Truncado</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Tensores-index">
									<a class="anchor-link" href="#Tensores">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Tensores</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Máscaras-index">
									<a class="anchor-link" href="#Máscaras">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Máscaras</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Fast-Tokenizers-index">
									<a class="anchor-link" href="#Fast-Tokenizers">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Fast Tokenizers</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Formas-de-generación-de-texto-index">
									<a class="anchor-link" href="#Formas-de-generación-de-texto">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Formas de generación de texto</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Greedy-Search-index">
									<a class="anchor-link" href="#Greedy-Search">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Greedy Search</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Contrastive-Search-index">
									<a class="anchor-link" href="#Contrastive-Search">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Contrastive Search</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Multinomial-sampling-index">
									<a class="anchor-link" href="#Multinomial-sampling">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Multinomial sampling</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Beam-search-index">
									<a class="anchor-link" href="#Beam-search">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Beam search</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Beam-search-multinomial-sampling-index">
									<a class="anchor-link" href="#Beam-search-multinomial-sampling">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Beam search multinomial sampling</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Beam-search-n-grams-penalty-index">
									<a class="anchor-link" href="#Beam-search-n-grams-penalty">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Beam search n-grams penalty</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Beam-search-n-grams-penalty-return-sequences-index">
									<a class="anchor-link" href="#Beam-search-n-grams-penalty-return-sequences">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Beam search n-grams penalty return sequences</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Diverse-beam-search-decoding-index">
									<a class="anchor-link" href="#Diverse-beam-search-decoding">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Diverse beam search decoding</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Speculative-Decoding-index">
									<a class="anchor-link" href="#Speculative-Decoding">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Speculative Decoding</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Speculative-Decoding-randomness-control-index">
									<a class="anchor-link" href="#Speculative-Decoding-randomness-control">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Speculative Decoding randomness control</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Sampling-index">
									<a class="anchor-link" href="#Sampling">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Sampling</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Sampling-temperature-index">
									<a class="anchor-link" href="#Sampling-temperature">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Sampling temperature</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Sampling-top-k-index">
									<a class="anchor-link" href="#Sampling-top-k">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Sampling top-k</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Sampling-top-p-(nucleus-sampling)-index">
									<a class="anchor-link" href="#Sampling-top-p-(nucleus-sampling)">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Sampling top-p (nucleus sampling)</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Sampling-top-k-y-top-p-index">
									<a class="anchor-link" href="#Sampling-top-k-y-top-p">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Sampling top-k y top-p</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Streaming-index">
									<a class="anchor-link" href="#Streaming">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Streaming</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Plantillas-de-chat-index">
									<a class="anchor-link" href="#Plantillas-de-chat">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Plantillas de chat</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Tokenización-del-contexto-index">
									<a class="anchor-link" href="#Tokenización-del-contexto">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Tokenización del contexto</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Añadir-generación-de-prompts-index">
									<a class="anchor-link" href="#Añadir-generación-de-prompts">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Añadir generación de prompts</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Generación-de-texto-index">
									<a class="anchor-link" href="#Generación-de-texto">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Generación de texto</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Generación-de-texto-con-`pipeline`-index">
									<a class="anchor-link" href="#Generación-de-texto-con-`pipeline`">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Generación de texto con <code><b>pipeline</b></code></p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Train-index">
									<a class="anchor-link" href="#Train">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Train</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Dataset-index">
									<a class="anchor-link" href="#Dataset">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Dataset</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Tokenización-index">
									<a class="anchor-link" href="#Tokenización">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Tokenización</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Modelo-index">
									<a class="anchor-link" href="#Modelo">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Modelo</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Métrica-de-evaluación-index">
									<a class="anchor-link" href="#Métrica-de-evaluación">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Métrica de evaluación</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Trainer-index">
									<a class="anchor-link" href="#Trainer">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Trainer</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Probando-el-modelo-index">
									<a class="anchor-link" href="#Probando-el-modelo">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Probando el modelo</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Compartir-el-modelo-en-el-Hub-de-Hugging-Face-index">
									<a class="anchor-link" href="#Compartir-el-modelo-en-el-Hub-de-Hugging-Face">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Compartir el modelo en el Hub de Hugging Face</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Logging-index">
									<a class="anchor-link" href="#Logging">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Logging</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Subida-una-vez-entenado-index">
									<a class="anchor-link" href="#Subida-una-vez-entenado">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Subida una vez entenado</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Subida-mientras-se-entrena-index">
									<a class="anchor-link" href="#Subida-mientras-se-entrena">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Subida mientras se entrena</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Hub-como-repositorio-git-index">
									<a class="anchor-link" href="#Hub-como-repositorio-git">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Hub como repositorio git</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
			</div>
		<!-- Close div indice -->
		</div>
 
		<!-- Content -->
		<div class="contenido">
		<div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><a href="https://colab.research.google.com/github/maximofn/portafolio/blob/main/posts/2024-04-15-Hugging-Face-transformers.ipynb" target="_blank"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h1 id="Hugging-Face-transformers">
								<a class="anchor-link" href="#Hugging-Face-transformers">
									<p style="margin-left: 0px">Hugging Face transformers</p>
								</a>
							</h1>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">La librería <code><b>transformers</b></code> de Hugging Face es una de las librerías más populares para trabajar con modelos de lenguaje. Su facilidad de uso hizo que se democratizara el uso de la arquitectura <code><b>Transformer</b></code> y que se pudiera trabajar con modelos de lenguaje de última generación sin necesidad de tener un gran conocimiento en el área.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Entre la librería <code><b>transformers</b></code>, el hub de modelos y su facilidad de uso, los spaces y la facilidad de desplegar demos, y nuevas librerías como <code><b>datasets</b></code>, <code><b>accelerate</b></code>, <code><b>PEFT</b></code> y otras más, han hecho que Hugging Face sea uno de los actores más importantes de la escena de inteligencia artificial del momento. Ellos mismos se auto-denominan como "el GitHub de la IA" y ciertamente lo son.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Instalación">
								<a class="anchor-link" href="#Instalación">
									<p style="margin-left: 10px">Instalación</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Para instalar transformers se puede hacer con <code><b>pip</b></code></p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 80px;"><code>pip install transformers<br></code></p>
						</div>
					</div>
				</div>
			</div>
	
	
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">o con <code><b>conda</b></code></p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 80px;"><code>conda install conda-forge::transformers<br></code></p>
						</div>
					</div>
				</div>
			</div>
	
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Además de la librería es necesario tener un backend de PyTorch o TensorFlow instalado. Es decir, necesitas tener instalar <code><b>torch</b></code> o <code><b>tensorflow</b></code> para poder usar <code><b>transformers</b></code>.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Inferencia-con-`pipeline`">
								<a class="anchor-link" href="#Inferencia-con-`pipeline`">
									<p style="margin-left: 10px">Inferencia con <code><b>pipeline</b></code></p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Con los <code><b>pipeline</b></code>s de <code><b>transformers</b></code> se puede hacer inferencia con modelos de lenguaje de una manera muy sencilla. Esto tiene la ventaja de que el desarrollo se realiza de manera mucho más rápida y se puede hacer prototipado de manera muy sencilla. Además permite a personas que no tienen mucho conocimiento poder usar los modelos</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Con <code><b>pipeline</b></code> se puede hacer inferencia en un montón de tareas diferentes. Cada tarea tiene su propio <code><b>pipeline</b></code> (<code><b>pipeline</b></code> de NLP, <code><b>pipeline</b></code> de vision, etc), pero se puede hacer una abstracción general usando la clase <code><b>pipeline</b></code> que se encarga de seleccionar el <code><b>pipeline</b></code> adecuado para la tarea que se le pase.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h3 id="Tareas">
								<a class="anchor-link" href="#Tareas">
									<p style="margin-left: 20px">Tareas</p>
								</a>
							</h3>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Al día de escribir este post, las tareas que se pueden hacer con <code><b>pipeline</b></code> son:</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">
								<ul>
									<li>Audio:</li>
									<ul><li>Clasificación de audio</li></ul>
									<ul><ul><li>clasificación de escena acústica: etiquetar audio con una etiqueta de escena (“oficina”, “playa”, “estadio”)</li></ul></ul>
									<ul><ul><li>detección de eventos acústicos: etiquetar audio con una etiqueta de evento de sonido (“bocina de automóvil”, “llamada de ballena”, “cristal rompiéndose”)</li></ul></ul>
									<ul><ul><li>etiquetado: etiquetar audio que contiene varios sonidos (canto de pájaros, identificación de altavoces en una reunión)</li></ul></ul>
									<ul><ul><li>clasificación de música: etiquetar música con una etiqueta de género (“metal”, “hip-hop”, “country”)</li></ul></ul>
								</ul>
							</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">
								<ul>
									<li>Reconocimiento automático del habla (ASR, audio speech recognition):</li>
								</ul>
							</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">
								<ul>
									<li>Visión por computadora</li>
									<ul><li>Clasificación de imágenes</li></ul>
									<ul><li>Detección de objetos</li></ul>
									<ul><li>Segmentación de imágenes</li></ul>
									<ul><li>Estimación de profundidad</li></ul>
								</ul>
							</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">
								<ul>
									<li>Procesamiento del lenguaje natural (NLP, natural language processing)</li>
									<ul><li>Clasificación de texto</li></ul>
									<ul><ul><li>análisis de sentimientos</li></ul></ul>
									<ul><ul><li>clasificación de contenido</li></ul></ul>
									<ul><li>Clasificación de tokens</li></ul>
									<ul><ul><li>reconocimiento de entidades nombradas (NER, por sus siglas en inglés): etiquetar un token según una categoría de entidad como organización, persona, ubicación o fecha.</li></ul></ul>
									<ul><ul><li>etiquetado de partes del discurso (POS, por sus siglas en inglés): etiquetar un token según su parte del discurso, como sustantivo, verbo o adjetivo. POS es útil para ayudar a los sistemas de traducción a comprender cómo dos palabras idénticas son gramaticalmente diferentes (por ejemplo, “corte” como sustantivo versus “corte” como verbo)</li></ul></ul>
									<ul><li>Respuestas a preguntas</li></ul>
									<ul><ul><li>extractivas: dada una pregunta y algún contexto, la respuesta es un fragmento de texto del contexto que el modelo debe extraer</li></ul></ul>
									<ul><ul><li>abstractivas: dada una pregunta y algún contexto, la respuesta se genera a partir del contexto; este enfoque lo maneja la Text2TextGenerationPipeline en lugar del QuestionAnsweringPipeline que se muestra a continuación</li></ul></ul>
									<ul><li>Resumir</li></ul>
									<ul><ul><li>extractiva: identifica y extrae las oraciones más importantes del texto original</li></ul></ul>
									<ul><ul><li>abstractiva: genera el resumen objetivo (que puede incluir nuevas palabras no presentes en el documento de entrada) a partir del texto original</li></ul></ul>
									<ul><li>Traducción</li></ul>
									<ul><li>Modelado de lenguaje</li></ul>
									<ul><ul><li>causal: el objetivo del modelo es predecir el próximo token en una secuencia, y los tokens futuros están enmascarados</li></ul></ul>
									<ul><ul><li>enmascarado: el objetivo del modelo es predecir un token enmascarado en una secuencia con acceso completo a los tokens en la secuencia</li></ul></ul>
								</ul>
							</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">
								<ul>
									<li>Multimodal</li>
									<ul><li>Respuestas a preguntas de documentos</li></ul>
								</ul>
							</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h3 id="Uso-de-`pipeline`">
								<a class="anchor-link" href="#Uso-de-`pipeline`">
									<p style="margin-left: 20px">Uso de <code><b>pipeline</b></code></p>
								</a>
							</h3>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">La forma más sencilla de crear un <code><b>pipeline</b></code> es simplemente indicarle la tarea que queremos que resuelva mediante el parámetro <code><b>task</b></code>. Y la librería se encargará de seleccionar el mejor modelo para esa tarea, descargarlo y guardarlo en la caché para futuros usos.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">pipeline</span></p>
<p></p>
<p><span style="color: #6b97e8;">generator</span> <span>=</span> <span style="color: #6b97e8;">pipeline</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">task</span><span>=</span><span style="color: #7e7a34;">&quot;text-generation&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>No model was supplied, defaulted to openai-community/gpt2 and revision 6c0e608 (https://huggingface.co/openai-community/gpt2).</p><p>Using a pipeline without specifying a model name and revision in production is not recommended.</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">generator</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>[{'generated_text': 'Me encanta aprender de se résistance davant que hiens que préclase que ses encasas quécénces. Se présentants cet en un croyne et cela désirez'}]</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Como se puede ver el texto generado está en francés, mientras que yo se lo he introducido en español, por lo que es importante elegir bien el modelo. SI te fijas la librería ha cogido el modelo <code><b>openai-community/gpt2</b></code> que es un modelo entrenado en su mayoría en inglés, y que al meterle texto en español se ha liado y ha generado una respuesta en francés.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vamos a usar un modelo reentrenado en español mediante el parámetro <code><b>model</b></code>.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">pipeline</span></p>
<p></p>
<p><span style="color: #6b97e8;">generator</span> <span>=</span> <span style="color: #6b97e8;">pipeline</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">task</span><span>=</span><span style="color: #7e7a34;">&quot;text-generation&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">model</span><span>=</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">generator</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>[{'generated_text': 'Me encanta aprender de tus palabras, que con gran entusiasmo y con el mismo conocimiento como lo que tú acabas escribiendo, te deseo de todo corazón todo el deseo de este día:\nY aunque también haya personas a las que'}]</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Ahora el texto generado tiene mucha mejor pinta</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">La clase <code><b>pipeline</b></code> tiene muchos posibles parámetros, por lo que para verlos todos y aprender más sobre la clase te recomiendo leer su <a href="https://huggingface.co/docs/transformers/v4.38.1/en/main_classes/pipelines" target="_blank">documentación</a>, pero vamos a hablar de una, ya que para el deep learning es muy importante y es <code><b>device</b></code>. Define el dispositivo (por ejemplo, <code><b>cpu</b></code>, <code><b>cuda:1</b></code>, <code><b>mps</b></code> o un rango ordinal de GPU como <code><b>1</b></code>) en el que se asignará el <code><b>pipeline</b></code>.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">En mi caso, como tengo una GPU pongo <code><b>0</b></code></p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">pipeline</span></p>
<p></p>
<p><span style="color: #6b97e8;">generator</span> <span>=</span> <span style="color: #6b97e8;">pipeline</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">task</span><span>=</span><span style="color: #7e7a34;">&quot;text-generation&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">model</span><span>=</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">generation</span> <span>=</span> <span style="color: #6b97e8;">generator</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">generation</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">][</span><span style="color: #8d783e;">&#39;generated_text&#39;</span><span style="color: #e3e11d;">])</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>Me encanta aprender de ustedes, a tal punto que he decidido escribir algunos de nuestros contenidos en este blog, el cual ha sido de gran utilidad para mí por varias razones, una de ellas, el trabajo</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h3 id="Cómo-funciona-`pipeline`">
								<a class="anchor-link" href="#Cómo-funciona-`pipeline`">
									<p style="margin-left: 20px">Cómo funciona <code><b>pipeline</b></code></p>
								</a>
							</h3>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Cuando hacemos uso de <code><b>pipeline</b></code> por debajo lo que está pasando es esto</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="http://maximofn.com/wp-content/uploads/2024/02/transformers-pipeline.svg" alt="transformers-pipeline"></p></p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Automáticamente se está tokenizando el texto, se pasa por el modelo y después por un postprocesado</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Inferencia-con-`AutoClass`-y-`pipeline`">
								<a class="anchor-link" href="#Inferencia-con-`AutoClass`-y-`pipeline`">
									<p style="margin-left: 10px">Inferencia con <code><b>AutoClass</b></code> y <code><b>pipeline</b></code></p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Hemos visto que <code><b>pipeline</b></code> nos abstrae mucho de lo que pasa, pero nosotros podemos seleccionar qué tokenizador, qué modelo y qué postprocesado queremos usar.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h3 id="Tokenización-con-`AutoTokenizer`">
								<a class="anchor-link" href="#Tokenización-con-`AutoTokenizer`">
									<p style="margin-left: 20px">Tokenización con <code><b>AutoTokenizer</b></code></p>
								</a>
							</h3>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Antes usamos el modelo <code><b>flax-community/gpt-2-spanish</b></code> para generar texto, podemos usar su tokenizador</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span></p>
<p></p>
<p><span style="color: #6b97e8;">checkpoint</span> <span>=</span> <span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">text</span> <span>=</span> <span style="color: #7e7a34;">&quot;Me encanta lo que estoy aprendiendo&quot;</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokens</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">text</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokens</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>{'input_ids': tensor([[ 2879,  4835,   382,   288,  2383, 15257]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h3 id="Modelo-`AutoModel`">
								<a class="anchor-link" href="#Modelo-`AutoModel`">
									<p style="margin-left: 20px">Modelo <code><b>AutoModel</b></code></p>
								</a>
							</h3>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Ahora podemos crear el modelo y pasarle los tokens</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoModel</span></p>
<p></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModel</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">tokens</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">type</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">output</span><span style="color: #e3e11d;">),</span> <span style="color: #6b97e8;">output</span><span>.</span><span style="color: #6b97e8;">keys</span><span style="color: #e3e11d;">()</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>(transformers.modeling_outputs.BaseModelOutputWithPastAndCrossAttentions,</p><p> odict_keys(['last_hidden_state', 'past_key_values']))</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Si ahora lo intentamos usar en un <code><b>pipeline</b></code> nos dará un error</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">pipeline</span></p>
<p></p>
<p><span style="color: #6b97e8;">pipeline</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;text-generation&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">model</span><span>=</span><span style="color: #6b97e8;">model</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">tokenizer</span><span>=</span><span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">)(</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_text output_error">
								<pre style="margin-left: 60px; line-height: 0%;"><p><span style="color:red">---------------------------------------------------------------------------</span></p><p><span style="color:red">TypeError</span>                                 Traceback (most recent call last)</p><p>Cell <span style="color:green">In[23], line 3</span></p><p><span style="color:green"><b>      1</b></span> [38;5;28;01mfrom[39;00m [38;5;21;01mtransformers[39;00m [38;5;28;01mimport[39;00m pipeline</p><p><span style="color:green">----&gt; 3</span> pipeline([38;5;124m"[39m[38;5;124mtext-generation[39m[38;5;124m"[39m, model[38;5;241m=[39mmodel, tokenizer[38;5;241m=[39mtokenizer)([38;5;124m"[39m[38;5;124mMe encanta aprender de[39m[38;5;124m"[39m)</p><p></p><p>File <span style="color:green">~/miniconda3/envs/nlp/lib/python3.11/site-packages/transformers/pipelines/text_generation.py:241</span>, in TextGenerationPipeline.__call__<span style="color:blue">(self, text_inputs, **kwargs)</span></p><p><span style="color:green"><b>    239</b></span>         [38;5;28;01mreturn[39;00m [38;5;28msuper[39m()[38;5;241m.[39m[38;5;21m__call__[39m(chats, [38;5;241m*[39m[38;5;241m*[39mkwargs)</p><p><span style="color:green"><b>    240</b></span> [38;5;28;01melse[39;00m:</p><p><span style="color:green">--&gt; 241</span>     [38;5;28;01mreturn[39;00m [38;5;28msuper[39m()[38;5;241m.[39m[38;5;21m__call__[39m(text_inputs, [38;5;241m*[39m[38;5;241m*[39mkwargs)</p><p></p><p>File <span style="color:green">~/miniconda3/envs/nlp/lib/python3.11/site-packages/transformers/pipelines/base.py:1196</span>, in Pipeline.__call__<span style="color:blue">(self, inputs, num_workers, batch_size, *args, **kwargs)</span></p><p><span style="color:green"><b>   1188</b></span>     [38;5;28;01mreturn[39;00m [38;5;28mnext[39m(</p><p><span style="color:green"><b>   1189</b></span>         [38;5;28miter[39m(</p><p><span style="color:green"><b>   1190</b></span>             [38;5;28mself[39m[38;5;241m.[39mget_iterator(</p><p><span style="color:green">   (...)</span></p><p><span style="color:green"><b>   1193</b></span>         )</p><p><span style="color:green"><b>   1194</b></span>     )</p><p><span style="color:green"><b>   1195</b></span> [38;5;28;01melse[39;00m:</p><p><span style="color:green">-&gt; 1196</span>     [38;5;28;01mreturn[39;00m [38;5;28mself[39m[38;5;241m.[39mrun_single(inputs, preprocess_params, forward_params, postprocess_params)</p><p></p><p>File <span style="color:green">~/miniconda3/envs/nlp/lib/python3.11/site-packages/transformers/pipelines/base.py:1203</span>, in Pipeline.run_single<span style="color:blue">(self, inputs, preprocess_params, forward_params, postprocess_params)</span></p><p><span style="color:green"><b>   1201</b></span> [38;5;28;01mdef[39;00m [38;5;21mrun_single[39m([38;5;28mself[39m, inputs, preprocess_params, forward_params, postprocess_params):</p><p><span style="color:green"><b>   1202</b></span>     model_inputs [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mpreprocess(inputs, [38;5;241m*[39m[38;5;241m*[39mpreprocess_params)</p><p><span style="color:green">-&gt; 1203</span>     model_outputs [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mforward(model_inputs, [38;5;241m*[39m[38;5;241m*[39mforward_params)</p><p><span style="color:green"><b>   1204</b></span>     outputs [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mpostprocess(model_outputs, [38;5;241m*[39m[38;5;241m*[39mpostprocess_params)</p><p><span style="color:green"><b>   1205</b></span>     [38;5;28;01mreturn[39;00m outputs</p><p></p><p>File <span style="color:green">~/miniconda3/envs/nlp/lib/python3.11/site-packages/transformers/pipelines/base.py:1102</span>, in Pipeline.forward<span style="color:blue">(self, model_inputs, **forward_params)</span></p><p><span style="color:green"><b>   1100</b></span>     [38;5;28;01mwith[39;00m inference_context():</p><p><span style="color:green"><b>   1101</b></span>         model_inputs [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39m_ensure_tensor_on_device(model_inputs, device[38;5;241m=[39m[38;5;28mself[39m[38;5;241m.[39mdevice)</p><p><span style="color:green">-&gt; 1102</span>         model_outputs [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39m_forward(model_inputs, [38;5;241m*[39m[38;5;241m*[39mforward_params)</p><p><span style="color:green"><b>   1103</b></span>         model_outputs [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39m_ensure_tensor_on_device(model_outputs, device[38;5;241m=[39mtorch[38;5;241m.[39mdevice([38;5;124m"[39m[38;5;124mcpu[39m[38;5;124m"[39m))</p><p><span style="color:green"><b>   1104</b></span> [38;5;28;01melse[39;00m:</p><p></p><p>File <span style="color:green">~/miniconda3/envs/nlp/lib/python3.11/site-packages/transformers/pipelines/text_generation.py:328</span>, in TextGenerationPipeline._forward<span style="color:blue">(self, model_inputs, **generate_kwargs)</span></p><p><span style="color:green"><b>    325</b></span>         generate_kwargs[[38;5;124m"[39m[38;5;124mmin_length[39m[38;5;124m"[39m] [38;5;241m+[39m[38;5;241m=[39m prefix_length</p><p><span style="color:green"><b>    327</b></span> [38;5;66;03m# BS x SL[39;00m</p><p><span style="color:green">--&gt; 328</span> generated_sequence [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mmodel[38;5;241m.[39mgenerate(input_ids[38;5;241m=[39minput_ids, attention_mask[38;5;241m=[39mattention_mask, [38;5;241m*[39m[38;5;241m*[39mgenerate_kwargs)</p><p><span style="color:green"><b>    329</b></span> out_b [38;5;241m=[39m generated_sequence[38;5;241m.[39mshape[[38;5;241m0[39m]</p><p><span style="color:green"><b>    330</b></span> [38;5;28;01mif[39;00m [38;5;28mself[39m[38;5;241m.[39mframework [38;5;241m==[39m [38;5;124m"[39m[38;5;124mpt[39m[38;5;124m"[39m:</p><p></p><p>File <span style="color:green">~/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/utils/_contextlib.py:115</span>, in context_decorator.&lt;locals&gt;.decorate_context<span style="color:blue">(*args, **kwargs)</span></p><p><span style="color:green"><b>    112</b></span> [38;5;129m@functools[39m[38;5;241m.[39mwraps(func)</p><p><span style="color:green"><b>    113</b></span> [38;5;28;01mdef[39;00m [38;5;21mdecorate_context[39m([38;5;241m*[39margs, [38;5;241m*[39m[38;5;241m*[39mkwargs):</p><p><span style="color:green"><b>    114</b></span>     [38;5;28;01mwith[39;00m ctx_factory():</p><p><span style="color:green">--&gt; 115</span>         [38;5;28;01mreturn[39;00m func([38;5;241m*[39margs, [38;5;241m*[39m[38;5;241m*[39mkwargs)</p><p></p><p>File <span style="color:green">~/miniconda3/envs/nlp/lib/python3.11/site-packages/transformers/generation/utils.py:1323</span>, in GenerationMixin.generate<span style="color:blue">(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)</span></p><p><span style="color:green"><b>   1320</b></span>         synced_gpus [38;5;241m=[39m [38;5;28;01mFalse[39;00m</p><p><span style="color:green"><b>   1322</b></span> [38;5;66;03m# 1. Handle `generation_config` and kwargs that might update it, and validate the `.generate()` call[39;00m</p><p><span style="color:green">-&gt; 1323</span> [38;5;28mself[39m[38;5;241m.[39m_validate_model_class()</p><p><span style="color:green"><b>   1325</b></span> [38;5;66;03m# priority: `generation_config` argument &gt; `model.generation_config` (the default generation config)[39;00m</p><p><span style="color:green"><b>   1326</b></span> [38;5;28;01mif[39;00m generation_config [38;5;129;01mis[39;00m [38;5;28;01mNone[39;00m:</p><p><span style="color:green"><b>   1327</b></span>     [38;5;66;03m# legacy: users may modify the model configuration to control generation. To trigger this legacy behavior,[39;00m</p><p><span style="color:green"><b>   1328</b></span>     [38;5;66;03m# three conditions must be met[39;00m</p><p><span style="color:green"><b>   1329</b></span>     [38;5;66;03m# 1) the generation config must have been created from the model config (`_from_model_config` field);[39;00m</p><p><span style="color:green"><b>   1330</b></span>     [38;5;66;03m# 2) the generation config must have seen no modification since its creation (the hash is the same);[39;00m</p><p><span style="color:green"><b>   1331</b></span>     [38;5;66;03m# 3) the user must have set generation parameters in the model config.[39;00m</p><p></p><p>File <span style="color:green">~/miniconda3/envs/nlp/lib/python3.11/site-packages/transformers/generation/utils.py:1110</span>, in GenerationMixin._validate_model_class<span style="color:blue">(self)</span></p><p><span style="color:green"><b>   1108</b></span> [38;5;28;01mif[39;00m generate_compatible_classes:</p><p><span style="color:green"><b>   1109</b></span>     exception_message [38;5;241m+[39m[38;5;241m=[39m [38;5;124mf[39m[38;5;124m"[39m[38;5;124m Please use one of the following classes instead: [39m[38;5;132;01m{[39;00mgenerate_compatible_classes[38;5;132;01m}[39;00m[38;5;124m"[39m</p><p><span style="color:green">-&gt; 1110</span> [38;5;28;01mraise[39;00m [38;5;167;01mTypeError[39;00m(exception_message)</p><p></p><p><span style="color:red">TypeError</span>: The current model class (GPT2Model) is not compatible with `.generate()`, as it doesn't have a language model head. Please use one of the following classes instead: {'GPT2LMHeadModel'}</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;">Hesto es porque cuando funcionaba usábamos</p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;"></p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 80px;"><code>pipeline(task="text-generation", model="flax-community/gpt-2-spanish")<br></code></p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;"></p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;"></p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;">Pero ahora hemos hecho</p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;"></p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 80px;"><code>tokenizer = AutoTokenizer.from_pretrained("flax-community/gpt-2-spanish")<br>model = AutoModel.from_pretrained("flax-community/gpt-2-spanish")<br>pipeline("text-generation", model=model, tokenizer=tokenizer)<br></code></p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;"></p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;"></p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;"></p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;"></p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;">En el primer caso solo usábamos <code><b>pipeline</b></code> y el nombre del modelo, por debajo buscaba la mejor manera de implementar el modelo y el tokenizador. Pero en el segundo caso hemos creado el tokenizador y el modelo y se lo hemos pasado a <code><b>pipeline</b></code>, pero no los hemos creado bien para lo que el <code><b>pipeline</b></code> necesita</p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;"></p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;">Para arreglar esto usamos <code><b>AutoModelFor</b></code></p>
					</div>
				</div>
			</div>
		</div>
		<!-- Open div header -->
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<h3 id="Modelo-`AutoModelFor`">
							<a class="anchor-link" href="#Modelo-`AutoModelFor`">
								<p style="margin-left: 20px">Modelo <code><b>AutoModelFor</b></code></p>
							</a>
						</h3>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;">La librería transformers nos da la oportunidad de crear un modelo para una tarea determinada como</p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;"></p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;">
							<ul>
								<li><code><b>AutoModelForCausalLM</b></code> que sirve para continuar textos</li>
								<li><code><b>AutoModelForMaskedLM</b></code> que se usa para rellenar huecos</li>
								<li><code><b>AutoModelForMaskGeneration</b></code> que sirve para generar máscaras</li>
								<li><code><b>AutoModelForSeq2SeqLM</b></code> que se usa par convertir de secuencias a secuencias, como por ejemplo en traducción</li>
								<li><code><b>AutoModelForSequenceClassification</b></code> para clasificación de texto</li>
								<li><code><b>AutoModelForMultipleChoice</b></code> para elección múltiple</li>
								<li><code><b>AutoModelForNextSentencePrediction</b></code> para predecir si dos frases son consecutivas</li>
								<li><code><b>AutoModelForTokenClassification</b></code> para clasificación de tokens</li>
								<li><code><b>AutoModelForQuestionAnswering</b></code> para preguntas y respuestas</li>
								<li><code><b>AutoModelForTextEncoding</b></code> para codificación de texto</li>
							</ul>
						</p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">

					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">

					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">

					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">

					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">

					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">

					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">

					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">

					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">

					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;">Vamos a usar el modelo anterior para generar texto</p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing code_cell rendered">
			<div class="input">
				<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
				<div class="inner_cell">
					<div class="input_area">
						<div class=" highlight hl-python3">
							<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">pipeline</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">pipeline</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;text-generation&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">model</span><span>=</span><span style="color: #6b97e8;">model</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">tokenizer</span><span>=</span><span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">)(</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">)[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">][</span><span style="color: #8d783e;">&#39;generated_text&#39;</span><span style="color: #e3e11d;">]</span></p>
							</pre>
						</div>
					</div>
				</div>
			</div>
			<div class="output_wrapper">
				<div class="output">
					<div class="output_area">
						<div class="prompt" style="margin-left: 20px;">Output:</div>
						<div class="output_subarea output_stream output_stdout output_text">
							<pre style="margin-left: 60px; line-height: 0%;"><p>'Me encanta aprender de mi familia.\nLa verdad no sabía que se necesitaba tanto en este pequeño restaurante ya que mi novio en un principio había ido, pero hoy me ha entrado un gusanillo entre pecho y espalda que'</p></pre>
						</div>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;">Ahora si funciona, porque hemos creado el modelo de una manera que <code><b>pipeline</b></code> puede entender</p>
					</div>
				</div>
			</div>
		</div>
		<!-- Open div header -->
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<h2 id="Inferencia-solo-con-`AutoClass`">
							<a class="anchor-link" href="#Inferencia-solo-con-`AutoClass`">
								<p style="margin-left: 10px">Inferencia solo con <code><b>AutoClass</b></code></p>
							</a>
						</h2>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;">Antes hemos creado el modelo y el tokenizador y se lo hemos dado a <code><b>pipeline</b></code> para que por debajo haga lo necesario, pero podemos usar nosotros los métodos para la inferencia.</p>
					</div>
				</div>
			</div>
		</div>
		<!-- Open div header -->
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<h3 id="Generación-de-texto-casual">
							<a class="anchor-link" href="#Generación-de-texto-casual">
								<p style="margin-left: 20px">Generación de texto casual</p>
							</a>
						</h3>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;">Creamos el modelo y el tokenizador</p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing code_cell rendered">
			<div class="input">
				<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
				<div class="inner_cell">
					<div class="input_area">
						<div class=" highlight hl-python3">
							<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
							</pre>
						</div>
					</div>
				</div>
			</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;">Con <code><b>device_map</b></code>, hemos cargado el modelo en la GPU 0</p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;">Ahora tenemos que hacer nosotros lo que antes hacía <code><b>pipeline</b></code></p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;">Primero generamos los tokens</p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing code_cell rendered">
			<div class="input">
				<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
				<div class="inner_cell">
					<div class="input_area">
						<div class=" highlight hl-python3">
							<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">tokens_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
							</pre>
						</div>
					</div>
				</div>
			</div>
			<div class="output_wrapper">
				<div class="output">
					<div class="output_area">
						<div class="prompt" style="margin-left: 20px;">Output:</div>
						<div class="output_subarea output_text output_error">
							<pre style="margin-left: 60px; line-height: 0%;"><p><span style="color:red">---------------------------------------------------------------------------</span></p><p><span style="color:red">ValueError</span>                                Traceback (most recent call last)</p><p>Cell <span style="color:green">In[2], line 1</span></p><p><span style="color:green">----&gt; 1</span> tokens_input [38;5;241m=[39m tokenizer([[38;5;124m"[39m[38;5;124mMe encanta aprender de[39m[38;5;124m"[39m], return_tensors[38;5;241m=[39m[38;5;124m"[39m[38;5;124mpt[39m[38;5;124m"[39m, padding[38;5;241m=[39m[38;5;28;01mTrue[39;00m)[38;5;241m.[39mto([38;5;124m"[39m[38;5;124mcuda[39m[38;5;124m"[39m)</p><p></p><p>File <span style="color:green">~/miniconda3/envs/nlp/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2829</span>, in PreTrainedTokenizerBase.__call__<span style="color:blue">(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)</span></p><p><span style="color:green"><b>   2827</b></span>     [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m [38;5;28mself[39m[38;5;241m.[39m_in_target_context_manager:</p><p><span style="color:green"><b>   2828</b></span>         [38;5;28mself[39m[38;5;241m.[39m_switch_to_input_mode()</p><p><span style="color:green">-&gt; 2829</span>     encodings [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39m_call_one(text[38;5;241m=[39mtext, text_pair[38;5;241m=[39mtext_pair, [38;5;241m*[39m[38;5;241m*[39mall_kwargs)</p><p><span style="color:green"><b>   2830</b></span> [38;5;28;01mif[39;00m text_target [38;5;129;01mis[39;00m [38;5;129;01mnot[39;00m [38;5;28;01mNone[39;00m:</p><p><span style="color:green"><b>   2831</b></span>     [38;5;28mself[39m[38;5;241m.[39m_switch_to_target_mode()</p><p></p><p>File <span style="color:green">~/miniconda3/envs/nlp/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2915</span>, in PreTrainedTokenizerBase._call_one<span style="color:blue">(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)</span></p><p><span style="color:green"><b>   2910</b></span>         [38;5;28;01mraise[39;00m [38;5;167;01mValueError[39;00m(</p><p><span style="color:green"><b>   2911</b></span>             [38;5;124mf[39m[38;5;124m"[39m[38;5;124mbatch length of `text`: [39m[38;5;132;01m{[39;00m[38;5;28mlen[39m(text)[38;5;132;01m}[39;00m[38;5;124m does not match batch length of `text_pair`:[39m[38;5;124m"[39m</p><p><span style="color:green"><b>   2912</b></span>             [38;5;124mf[39m[38;5;124m"[39m[38;5;124m [39m[38;5;132;01m{[39;00m[38;5;28mlen[39m(text_pair)[38;5;132;01m}[39;00m[38;5;124m.[39m[38;5;124m"[39m</p><p><span style="color:green"><b>   2913</b></span>         )</p><p><span style="color:green"><b>   2914</b></span>     batch_text_or_text_pairs [38;5;241m=[39m [38;5;28mlist[39m([38;5;28mzip[39m(text, text_pair)) [38;5;28;01mif[39;00m text_pair [38;5;129;01mis[39;00m [38;5;129;01mnot[39;00m [38;5;28;01mNone[39;00m [38;5;28;01melse[39;00m text</p><p><span style="color:green">-&gt; 2915</span>     [38;5;28;01mreturn[39;00m [38;5;28mself[39m[38;5;241m.[39mbatch_encode_plus(</p><p><span style="color:green"><b>   2916</b></span>         batch_text_or_text_pairs[38;5;241m=[39mbatch_text_or_text_pairs,</p><p><span style="color:green"><b>   2917</b></span>         add_special_tokens[38;5;241m=[39madd_special_tokens,</p><p><span style="color:green"><b>   2918</b></span>         padding[38;5;241m=[39mpadding,</p><p><span style="color:green"><b>   2919</b></span>         truncation[38;5;241m=[39mtruncation,</p><p><span style="color:green"><b>   2920</b></span>         max_length[38;5;241m=[39mmax_length,</p><p><span style="color:green"><b>   2921</b></span>         stride[38;5;241m=[39mstride,</p><p><span style="color:green"><b>   2922</b></span>         is_split_into_words[38;5;241m=[39mis_split_into_words,</p><p><span style="color:green"><b>   2923</b></span>         pad_to_multiple_of[38;5;241m=[39mpad_to_multiple_of,</p><p><span style="color:green"><b>   2924</b></span>         return_tensors[38;5;241m=[39mreturn_tensors,</p><p><span style="color:green"><b>   2925</b></span>         return_token_type_ids[38;5;241m=[39mreturn_token_type_ids,</p><p><span style="color:green"><b>   2926</b></span>         return_attention_mask[38;5;241m=[39mreturn_attention_mask,</p><p><span style="color:green"><b>   2927</b></span>         return_overflowing_tokens[38;5;241m=[39mreturn_overflowing_tokens,</p><p><span style="color:green"><b>   2928</b></span>         return_special_tokens_mask[38;5;241m=[39mreturn_special_tokens_mask,</p><p><span style="color:green"><b>   2929</b></span>         return_offsets_mapping[38;5;241m=[39mreturn_offsets_mapping,</p><p><span style="color:green"><b>   2930</b></span>         return_length[38;5;241m=[39mreturn_length,</p><p><span style="color:green"><b>   2931</b></span>         verbose[38;5;241m=[39mverbose,</p><p><span style="color:green"><b>   2932</b></span>         [38;5;241m*[39m[38;5;241m*[39mkwargs,</p><p><span style="color:green"><b>   2933</b></span>     )</p><p><span style="color:green"><b>   2934</b></span> [38;5;28;01melse[39;00m:</p><p><span style="color:green"><b>   2935</b></span>     [38;5;28;01mreturn[39;00m [38;5;28mself[39m[38;5;241m.[39mencode_plus(</p><p><span style="color:green"><b>   2936</b></span>         text[38;5;241m=[39mtext,</p><p><span style="color:green"><b>   2937</b></span>         text_pair[38;5;241m=[39mtext_pair,</p><p><span style="color:green">   (...)</span></p><p><span style="color:green"><b>   2953</b></span>         [38;5;241m*[39m[38;5;241m*[39mkwargs,</p><p><span style="color:green"><b>   2954</b></span>     )</p><p></p><p>File <span style="color:green">~/miniconda3/envs/nlp/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3097</span>, in PreTrainedTokenizerBase.batch_encode_plus<span style="color:blue">(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)</span></p><p><span style="color:green"><b>   3080</b></span> [38;5;250m[39m[38;5;124;03m"""[39;00m</p><p><span style="color:green"><b>   3081</b></span> [38;5;124;03mTokenize and prepare for the model a list of sequences or a list of pairs of sequences.[39;00m</p><p><span style="color:green"><b>   3082</b></span> </p><p><span style="color:green">   (...)</span></p><p><span style="color:green"><b>   3093</b></span> [38;5;124;03m        details in `encode_plus`).[39;00m</p><p><span style="color:green"><b>   3094</b></span> [38;5;124;03m"""[39;00m</p><p><span style="color:green"><b>   3096</b></span> [38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'[39;00m</p><p><span style="color:green">-&gt; 3097</span> padding_strategy, truncation_strategy, max_length, kwargs [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39m_get_padding_truncation_strategies(</p><p><span style="color:green"><b>   3098</b></span>     padding[38;5;241m=[39mpadding,</p><p><span style="color:green"><b>   3099</b></span>     truncation[38;5;241m=[39mtruncation,</p><p><span style="color:green"><b>   3100</b></span>     max_length[38;5;241m=[39mmax_length,</p><p><span style="color:green"><b>   3101</b></span>     pad_to_multiple_of[38;5;241m=[39mpad_to_multiple_of,</p><p><span style="color:green"><b>   3102</b></span>     verbose[38;5;241m=[39mverbose,</p><p><span style="color:green"><b>   3103</b></span>     [38;5;241m*[39m[38;5;241m*[39mkwargs,</p><p><span style="color:green"><b>   3104</b></span> )</p><p><span style="color:green"><b>   3106</b></span> [38;5;28;01mreturn[39;00m [38;5;28mself[39m[38;5;241m.[39m_batch_encode_plus(</p><p><span style="color:green"><b>   3107</b></span>     batch_text_or_text_pairs[38;5;241m=[39mbatch_text_or_text_pairs,</p><p><span style="color:green"><b>   3108</b></span>     add_special_tokens[38;5;241m=[39madd_special_tokens,</p><p><span style="color:green">   (...)</span></p><p><span style="color:green"><b>   3123</b></span>     [38;5;241m*[39m[38;5;241m*[39mkwargs,</p><p><span style="color:green"><b>   3124</b></span> )</p><p></p><p>File <span style="color:green">~/miniconda3/envs/nlp/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2734</span>, in PreTrainedTokenizerBase._get_padding_truncation_strategies<span style="color:blue">(self, padding, truncation, max_length, pad_to_multiple_of, verbose, **kwargs)</span></p><p><span style="color:green"><b>   2732</b></span> [38;5;66;03m# Test if we have a padding token[39;00m</p><p><span style="color:green"><b>   2733</b></span> [38;5;28;01mif[39;00m padding_strategy [38;5;241m!=[39m PaddingStrategy[38;5;241m.[39mDO_NOT_PAD [38;5;129;01mand[39;00m ([38;5;28mself[39m[38;5;241m.[39mpad_token [38;5;129;01mis[39;00m [38;5;28;01mNone[39;00m [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39mpad_token_id [38;5;241m&lt;[39m [38;5;241m0[39m):</p><p><span style="color:green">-&gt; 2734</span>     [38;5;28;01mraise[39;00m [38;5;167;01mValueError[39;00m(</p><p><span style="color:green"><b>   2735</b></span>         [38;5;124m"[39m[38;5;124mAsking to pad but the tokenizer does not have a padding token. [39m[38;5;124m"[39m</p><p><span style="color:green"><b>   2736</b></span>         [38;5;124m"[39m[38;5;124mPlease select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` [39m[38;5;124m"[39m</p><p><span style="color:green"><b>   2737</b></span>         [38;5;124m"[39m[38;5;124mor add a new pad token via `tokenizer.add_special_tokens([39m[38;5;124m{[39m[38;5;124m'[39m[38;5;124mpad_token[39m[38;5;124m'[39m[38;5;124m: [39m[38;5;124m'[39m[38;5;124m[PAD][39m[38;5;124m'[39m[38;5;124m})`.[39m[38;5;124m"[39m</p><p><span style="color:green"><b>   2738</b></span>     )</p><p><span style="color:green"><b>   2740</b></span> [38;5;66;03m# Check that we will truncate to a multiple of pad_to_multiple_of if both are provided[39;00m</p><p><span style="color:green"><b>   2741</b></span> [38;5;28;01mif[39;00m (</p><p><span style="color:green"><b>   2742</b></span>     truncation_strategy [38;5;241m!=[39m TruncationStrategy[38;5;241m.[39mDO_NOT_TRUNCATE</p><p><span style="color:green"><b>   2743</b></span>     [38;5;129;01mand[39;00m padding_strategy [38;5;241m!=[39m PaddingStrategy[38;5;241m.[39mDO_NOT_PAD</p><p><span style="color:green">   (...)</span></p><p><span style="color:green"><b>   2746</b></span>     [38;5;129;01mand[39;00m (max_length [38;5;241m%[39m pad_to_multiple_of [38;5;241m!=[39m [38;5;241m0[39m)</p><p><span style="color:green"><b>   2747</b></span> ):</p><p></p><p><span style="color:red">ValueError</span>: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.</p></pre>
						</div>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Vemos que nos ha dado un error, nos dice que el tokenizador no tiene token de padding. La mayoría de LLMs no tienen un token de padding, pero para usar la librería <code><b>transformers</b></code> es necesario un token de padding, por lo que lo que se suele hacer es asignar el token de fin de sentencia al token de padding</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Ahora ya podemos generar los tokens</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">tokens_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokens_input</span><span>.</span><span style="color: #6b97e8;">input_ids</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>tensor([[2879, 4835, 3760,  225,   72,   73]], device='cuda:0')</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Ahora se los pasamos al modelo que generará nuevos tokens, para eso usamos el método <code><b>generate</b></code></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">tokens_output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">tokens_input</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_length</span><span>=</span><span style="color: #7e7a38;">50</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;input tokens: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">tokens_input</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;output tokens: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">tokens_output</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>input tokens: tensor([[2879, 4835, 3760,  225,   72,   73]], device='cuda:0')</p><p>output tokens: tensor([[ 2879,  4835,  3760,   225,    72,    73,   314,  2533,    16,   287,</p><p>           225,    73,    82,   513,  1086,   225,    72,    73,   314,   288,</p><p>           357, 15550,    16,   287,   225,    73,    87,   288,   225,    73,</p><p>            82,   291,  3500,    16,   225,    73,    87,   348,   929,   225,</p><p>            72,    73,  3760,   225,    72,    73,   314,  2533,    18,   203]],</p><p>       device='cuda:0')</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Podemos ver que los primeros tokens de <code><b>token_inputs</b></code> son los mismos que los de <code><b>token_outputs</b></code>, los que vienen a continuación son los que ha generado el modelo</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Ahora tenemos que convertir esos tokens a una sentencia mediante el decoder del tokenizador</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokens_output</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>'Me encanta aprender de los demás, y en este caso de los que me rodean, y es que en el fondo, es una forma de aprender de los demás.\n'</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Ya tenemos el texto generado</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Clasificación-de-texto">
						<a class="anchor-link" href="#Clasificación-de-texto">
							<p style="margin-left: 20px">Clasificación de texto</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Creamos el modelo y el tokenizador</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">import</span> <span style="color: #4fcd7d;">torch</span></p>
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForSequenceClassification</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;stevhliu/my_awesome_model&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForSequenceClassification</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;stevhliu/my_awesome_model&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Generamos los tokens</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">text</span> <span>=</span> <span style="color: #7e7a34;">&quot;This was a masterpiece. Not completely faithful to the books, but enthralling from beginning to end. Might be my favorite of the three.&quot;</span></p>
<p><span style="color: #6b97e8;">inputs</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">text</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Una vez tenemos los tokens, clasificamos</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #a04cc1;">with</span> <span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">no_grad</span><span style="color: #e3e11d;">():</span></p>
<p>    <span style="color: #6b97e8;">logits</span> <span>=</span> <span style="color: #6b97e8;">model</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">inputs</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">logits</span></p>
<p></p>
<p><span style="color: #6b97e8;">predicted_class_id</span> <span>=</span> <span style="color: #6b97e8;">logits</span><span>.</span><span style="color: #6b97e8;">argmax</span><span style="color: #e3e11d;">()</span><span>.</span><span style="color: #6b97e8;">item</span><span style="color: #e3e11d;">()</span></p>
<p><span style="color: #6b97e8;">prediction</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">config</span><span>.</span><span style="color: #6b97e8;">id2label</span><span style="color: #e3e11d;">[</span><span style="color: #6b97e8;">predicted_class_id</span><span style="color: #e3e11d;">]</span></p>
<p><span style="color: #6b97e8;">prediction</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>'LABEL_1'</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Vamos a ver las clases</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">clases</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">config</span><span>.</span><span style="color: #6b97e8;">id2label</span></p>
<p><span style="color: #6b97e8;">clases</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>{0: 'LABEL_0', 1: 'LABEL_1'}</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Así no hay quien se entere, así que lo modificamos</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">config</span><span>.</span><span style="color: #6b97e8;">id2label</span> <span>=</span> <span style="color: #e3e11d;">{</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;NEGATIVE&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;POSITIVE&quot;</span><span style="color: #e3e11d;">}</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Y ahora volvemos a clasificar</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #a04cc1;">with</span> <span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">no_grad</span><span style="color: #e3e11d;">():</span></p>
<p>    <span style="color: #6b97e8;">logits</span> <span>=</span> <span style="color: #6b97e8;">model</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">inputs</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">logits</span></p>
<p></p>
<p><span style="color: #6b97e8;">predicted_class_id</span> <span>=</span> <span style="color: #6b97e8;">logits</span><span>.</span><span style="color: #6b97e8;">argmax</span><span style="color: #e3e11d;">()</span><span>.</span><span style="color: #6b97e8;">item</span><span style="color: #e3e11d;">()</span></p>
<p><span style="color: #6b97e8;">prediction</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">config</span><span>.</span><span style="color: #6b97e8;">id2label</span><span style="color: #e3e11d;">[</span><span style="color: #6b97e8;">predicted_class_id</span><span style="color: #e3e11d;">]</span></p>
<p><span style="color: #6b97e8;">prediction</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>'POSITIVE'</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Clasificación-de-tokens">
						<a class="anchor-link" href="#Clasificación-de-tokens">
							<p style="margin-left: 20px">Clasificación de tokens</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Creamos el modelo y el tokenizador</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">import</span> <span style="color: #4fcd7d;">torch</span></p>
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForTokenClassification</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;stevhliu/my_awesome_wnut_model&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForTokenClassification</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;stevhliu/my_awesome_wnut_model&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Generamos los tokens</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">text</span> <span>=</span> <span style="color: #7e7a34;">&quot;The Golden State Warriors are an American professional basketball team based in San Francisco.&quot;</span></p>
<p><span style="color: #6b97e8;">inputs</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">text</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Una vez tenemos los tokens, clasificamos</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #a04cc1;">with</span> <span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">no_grad</span><span style="color: #e3e11d;">():</span></p>
<p>    <span style="color: #6b97e8;">logits</span> <span>=</span> <span style="color: #6b97e8;">model</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">inputs</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">logits</span></p>
<p></p>
<p><span style="color: #6b97e8;">predictions</span> <span>=</span> <span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">argmax</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">logits</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">dim</span><span>=</span><span style="color: #7e7a38;">2</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">predicted_token_class</span> <span>=</span> <span style="color: #e3e11d;">[</span><span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">config</span><span>.</span><span style="color: #6b97e8;">id2label</span><span style="color: #e3e11d;">[</span><span style="color: #6b97e8;">t</span><span>.</span><span style="color: #6b97e8;">item</span><span style="color: #e3e11d;">()]</span> <span style="color: #a04cc1;">for</span> <span style="color: #6b97e8;">t</span> <span style="color: #7f6e38;">in</span> <span style="color: #6b97e8;">predictions</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">]]</span></p>
<p><span style="color: #a04cc1;">for</span> <span style="color: #6b97e8;">i</span> <span style="color: #7f6e38;">in</span> <span style="color: #dfd84a;">range</span><span style="color: #e3e11d;">(</span><span style="color: #dfd84a;">len</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">inputs</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">])):</span></p>
<p>    <span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;</span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">inputs</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">][</span><span style="color: #6b97e8;">i</span><span style="color: #e3e11d;">]</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;"> (</span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">([</span><span style="color: #6b97e8;">inputs</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">][</span><span style="color: #6b97e8;">i</span><span style="color: #e3e11d;">]])</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">) -&gt; </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">predicted_token_class</span><span style="color: #e3e11d;">[</span><span style="color: #6b97e8;">i</span><span style="color: #e3e11d;">]</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>101 ([CLS]) -&gt; O</p><p>1996 (the) -&gt; O</p><p>3585 (golden) -&gt; B-location</p><p>2110 (state) -&gt; I-location</p><p>6424 (warriors) -&gt; B-group</p><p>2024 (are) -&gt; O</p><p>2019 (an) -&gt; O</p><p>2137 (american) -&gt; O</p><p>2658 (professional) -&gt; O</p><p>3455 (basketball) -&gt; O</p><p>2136 (team) -&gt; O</p><p>2241 (based) -&gt; O</p><p>1999 (in) -&gt; O</p><p>2624 (san) -&gt; B-location</p><p>3799 (francisco) -&gt; B-location</p><p>1012 (.) -&gt; O</p><p>102 ([SEP]) -&gt; O</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Como se puede ver los tokens correspondientes a <code><b>golden</b></code>, <code><b>state</b></code>, <code><b>warriors</b></code>, <code><b>san</b></code> y <code><b>francisco</b></code> los ha clasificado como tokens de localizacióm</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Respuesta-a-preguntas-(question-answering)">
						<a class="anchor-link" href="#Respuesta-a-preguntas-(question-answering)">
							<p style="margin-left: 20px">Respuesta a preguntas (question answering)</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Creamos el modelo y el tokenizador</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">import</span> <span style="color: #4fcd7d;">torch</span></p>
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForQuestionAnswering</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;mrm8488/roberta-base-1B-1-finetuned-squadv1&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForQuestionAnswering</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;mrm8488/roberta-base-1B-1-finetuned-squadv1&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Some weights of the model checkpoint at mrm8488/roberta-base-1B-1-finetuned-squadv1 were not used when initializing RobertaForQuestionAnswering: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']</p><p>- This IS expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).</p><p>- This IS NOT expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Generamos los tokens</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">question</span> <span>=</span> <span style="color: #7e7a34;">&quot;How many programming languages does BLOOM support?&quot;</span></p>
<p><span style="color: #6b97e8;">context</span> <span>=</span> <span style="color: #7e7a34;">&quot;BLOOM has 176 billion parameters and can generate text in 46 languages natural languages and 13 programming languages.&quot;</span></p>
<p><span style="color: #6b97e8;">inputs</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">question</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">context</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Una vez tenemos los tokens, clasificamos</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #a04cc1;">with</span> <span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">no_grad</span><span style="color: #e3e11d;">():</span></p>
<p>    <span style="color: #6b97e8;">outputs</span> <span>=</span> <span style="color: #6b97e8;">model</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">inputs</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">answer_start_index</span> <span>=</span> <span style="color: #6b97e8;">outputs</span><span>.</span><span style="color: #6b97e8;">start_logits</span><span>.</span><span style="color: #6b97e8;">argmax</span><span style="color: #e3e11d;">()</span></p>
<p><span style="color: #6b97e8;">answer_end_index</span> <span>=</span> <span style="color: #6b97e8;">outputs</span><span>.</span><span style="color: #6b97e8;">end_logits</span><span>.</span><span style="color: #6b97e8;">argmax</span><span style="color: #e3e11d;">()</span></p>
<p></p>
<p><span style="color: #6b97e8;">predict_answer_tokens</span> <span>=</span> <span style="color: #6b97e8;">inputs</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">answer_start_index</span> <span style="color: #e3e11d;">:</span> <span style="color: #6b97e8;">answer_end_index</span> <span>+</span> <span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">]</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">predict_answer_tokens</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>' 13'</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Modelización-del-lenguaje-enmascarado-(Masked-language-modeling)">
						<a class="anchor-link" href="#Modelización-del-lenguaje-enmascarado-(Masked-language-modeling)">
							<p style="margin-left: 20px">Modelización del lenguaje enmascarado (Masked language modeling)</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Creamos el modelo y el tokenizador</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">import</span> <span style="color: #4fcd7d;">torch</span></p>
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForMaskedLM</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;nyu-mll/roberta-base-1B-1&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForMaskedLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;nyu-mll/roberta-base-1B-1&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Some weights of the model checkpoint at nyu-mll/roberta-base-1B-1 were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']</p><p>- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).</p><p>- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Generamos los tokens</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">text</span> <span>=</span> <span style="color: #7e7a34;">&quot;The Milky Way is a &lt;mask&gt; galaxy.&quot;</span></p>
<p><span style="color: #6b97e8;">inputs</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">text</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">mask_token_index</span> <span>=</span> <span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">where</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">inputs</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a34;">&quot;input_ids&quot;</span><span style="color: #e3e11d;">]</span> <span>==</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">mask_token_id</span><span style="color: #e3e11d;">)[</span><span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">]</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Una vez tenemos los tokens, clasificamos</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #a04cc1;">with</span> <span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">no_grad</span><span style="color: #e3e11d;">():</span></p>
<p>    <span style="color: #6b97e8;">logits</span> <span>=</span> <span style="color: #6b97e8;">model</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">inputs</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">logits</span></p>
<p>    <span style="color: #6b97e8;">mask_token_logits</span> <span>=</span> <span style="color: #6b97e8;">logits</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">mask_token_index</span><span style="color: #e3e11d;">,</span> <span style="color: #e3e11d;">:]</span></p>
<p></p>
<p><span style="color: #6b97e8;">top_3_tokens</span> <span>=</span> <span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">topk</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">mask_token_logits</span><span style="color: #e3e11d;">,</span> <span style="color: #7e7a38;">3</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">dim</span><span>=</span><span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">indices</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">]</span><span>.</span><span style="color: #6b97e8;">tolist</span><span style="color: #e3e11d;">()</span></p>
<p><span style="color: #a04cc1;">for</span> <span style="color: #6b97e8;">token</span> <span style="color: #7f6e38;">in</span> <span style="color: #6b97e8;">top_3_tokens</span><span style="color: #e3e11d;">:</span></p>
<p>    <span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">text</span><span>.</span><span style="color: #6b97e8;">replace</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">mask_token</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">([</span><span style="color: #6b97e8;">token</span><span style="color: #e3e11d;">])))</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>The Milky Way is a  spiral galaxy.</p><p>The Milky Way is a  closed galaxy.</p><p>The Milky Way is a  distant galaxy.</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h2 id="Personalización-del-modelo">
						<a class="anchor-link" href="#Personalización-del-modelo">
							<p style="margin-left: 10px">Personalización del modelo</p>
						</a>
					</h2>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Antes hemos hecho la inferencia con <code><b>AutoClass</b></code>, pero lo hemos hecho con las cofiguraciones por defecto del modelo. Pero podemos configurar el modelo todo lo que queramos</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Vamos a instanciar un modelo y a ver su configuración</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoConfig</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">config</span> <span>=</span> <span style="color: #6b97e8;">AutoConfig</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">config</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>GPT2Config {</p><p>  "_name_or_path": "flax-community/gpt-2-spanish",</p><p>  "activation_function": "gelu_new",</p><p>  "architectures": [</p><p>    "GPT2LMHeadModel"</p><p>  ],</p><p>  "attn_pdrop": 0.0,</p><p>  "bos_token_id": 50256,</p><p>  "embd_pdrop": 0.0,</p><p>  "eos_token_id": 50256,</p><p>  "gradient_checkpointing": false,</p><p>  "initializer_range": 0.02,</p><p>  "layer_norm_epsilon": 1e-05,</p><p>  "model_type": "gpt2",</p><p>  "n_ctx": 1024,</p><p>  "n_embd": 768,</p><p>  "n_head": 12,</p><p>  "n_inner": null,</p><p>  "n_layer": 12,</p><p>  "n_positions": 1024,</p><p>  "reorder_and_upcast_attn": false,</p><p>  "resid_pdrop": 0.0,</p><p>  "scale_attn_by_inverse_layer_idx": false,</p><p>  "scale_attn_weights": true,</p><p>  "summary_activation": null,</p><p>  "summary_first_dropout": 0.1,</p><p>  "summary_proj_to_labels": true,</p><p>  "summary_type": "cls_index",</p><p>  "summary_use_proj": true,</p><p>  "task_specific_params": {</p><p>    "text-generation": {</p><p>      "do_sample": true,</p><p>      "max_length": 50</p><p>    }</p><p>  },</p><p>  "transformers_version": "4.38.1",</p><p>  "use_cache": true,</p><p>  "vocab_size": 50257</p><p>}</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Podemos ver la configuración del modelo, por ejemplo la función de activación es <code><b>gelu_new</b></code>, tiene 12 <code><b>head</b></code>s, el tamaño del vocabulario es 50257 palabras, etc.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Pero podemos modificar esta configuración</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">config</span> <span>=</span> <span style="color: #6b97e8;">AutoConfig</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">activation_function</span><span>=</span><span style="color: #7e7a34;">&quot;relu&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">config</span><span>.</span><span style="color: #6b97e8;">activation_function</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>'relu'</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Creamos ahora el modelo con esta configuración</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">config</span><span>=</span><span style="color: #6b97e8;">config</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Y generamos texto</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p><span style="color: #6b97e8;">tokens_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokens_output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">tokens_input</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_length</span><span>=</span><span style="color: #7e7a38;">50</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokens_output</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>'Me encanta aprender de la d d e d e d e d e d e d e d e d e d e d e '</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Vemos que esta modificación hace que no genere tan buen texto</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h2 id="Tokenización">
						<a class="anchor-link" href="#Tokenización">
							<p style="margin-left: 10px">Tokenización</p>
						</a>
					</h2>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Hasta ahora hemos visto las diferentes manera que hay de hacer inferencia con la librería <code><b>transformers</b></code>. Ahora nos vamos a meter en las tripas de la librería. Para ello primero vamos a ver cosas a tener en cuenta a la hora de tokenizar.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">No vamos a explicar lo que es tokenizar a fondo, ya que eso ya lo explicamos en el post de la librería <a href="https://maximofn.com/hugging-face-tokenizers/" target="_blank">tokenizers</a></p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Padding">
						<a class="anchor-link" href="#Padding">
							<p style="margin-left: 20px">Padding</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Cuando se tiene un batch de secuencias, a veces es necesario que después de tokenizar, todas las secuencias tengan la misma longitud, así que para ello usamos el parámetro <code><b>padding=True</b></code></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span></p>
<p></p>
<p><span style="color: #6b97e8;">batch_sentences</span> <span>=</span> <span style="color: #e3e11d;">[</span></p>
<p>    <span style="color: #7e7a34;">&quot;Pero, ¿qué pasa con el segundo desayuno?&quot;</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #7e7a34;">&quot;No creo que sepa lo del segundo desayuno, Pedro&quot;</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #7e7a34;">&quot;¿Qué hay de los elevensies?&quot;</span><span style="color: #e3e11d;">,</span></p>
<p><span style="color: #e3e11d;">]</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">pad_token</span><span>=</span><span style="color: #7e7a34;">&quot;PAD&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">encoded_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">batch_sentences</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #a04cc1;">for</span> <span style="color: #6b97e8;">encoded</span> <span style="color: #7f6e38;">in</span> <span style="color: #6b97e8;">encoded_input</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a34;">&quot;input_ids&quot;</span><span style="color: #e3e11d;">]:</span></p>
<p>    <span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">encoded</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;Padding token id: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token_id</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>[2959, 16, 875, 3736, 3028, 303, 291, 2200, 8080, 35, 50257, 50257]</p><p>[1489, 2275, 288, 12052, 382, 325, 2200, 8080, 16, 4319, 50257, 50257]</p><p>[1699, 2899, 707, 225, 72, 73, 314, 34630, 474, 515, 1259, 35]</p><p>Padding token id: 50257</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Como vemos a las dos primeras secuencias les ha añadido un paddings al final</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Truncado">
						<a class="anchor-link" href="#Truncado">
							<p style="margin-left: 20px">Truncado</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">A parte de añadir padding, a veces es necesario truncar las secuencias para que no ocupen más de un número determinado de tokens. Para ello establecemos <code><b>truncation=True</b></code> y <code><b>max_length</b></code> con el número de tokens que queremos que tenga la secuencia</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span></p>
<p></p>
<p><span style="color: #6b97e8;">batch_sentences</span> <span>=</span> <span style="color: #e3e11d;">[</span></p>
<p>    <span style="color: #7e7a34;">&quot;Pero, ¿qué pasa con el segundo desayuno?&quot;</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #7e7a34;">&quot;No creo que sepa lo del segundo desayuno, Pedro&quot;</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #7e7a34;">&quot;¿Qué hay de los elevensies?&quot;</span><span style="color: #e3e11d;">,</span></p>
<p><span style="color: #e3e11d;">]</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">encoded_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">batch_sentences</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">truncation</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_length</span><span>=</span><span style="color: #7e7a38;">5</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #a04cc1;">for</span> <span style="color: #6b97e8;">encoded</span> <span style="color: #7f6e38;">in</span> <span style="color: #6b97e8;">encoded_input</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a34;">&quot;input_ids&quot;</span><span style="color: #e3e11d;">]:</span></p>
<p>    <span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">encoded</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>[2959, 16, 875, 3736, 3028]</p><p>[1489, 2275, 288, 12052, 382]</p><p>[1699, 2899, 707, 225, 72]</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Las mismas sentencias de antes, ahora generan menos tokens</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Tensores">
						<a class="anchor-link" href="#Tensores">
							<p style="margin-left: 20px">Tensores</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Hasta ahora estábamos recibiendo listas de tokens, pero seguramente nos interese recibir tensores de PyTorch o TensorFlow. Para ello usamos el parámetro <code><b>return_tensors</b></code> y le especificamos de qué framework queremos recibir el tensor, en nuestro caso elegiremos PyTorch con <code><b>pt</b></code></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Vemos primero sin especificar que nos devuelva tensores</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span></p>
<p></p>
<p><span style="color: #6b97e8;">batch_sentences</span> <span>=</span> <span style="color: #e3e11d;">[</span></p>
<p>    <span style="color: #7e7a34;">&quot;Pero, ¿qué pasa con el segundo desayuno?&quot;</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #7e7a34;">&quot;No creo que sepa lo del segundo desayuno, Pedro&quot;</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #7e7a34;">&quot;¿Qué hay de los elevensies?&quot;</span><span style="color: #e3e11d;">,</span></p>
<p><span style="color: #e3e11d;">]</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">pad_token</span><span>=</span><span style="color: #7e7a34;">&quot;PAD&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">encoded_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">batch_sentences</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #a04cc1;">for</span> <span style="color: #6b97e8;">encoded</span> <span style="color: #7f6e38;">in</span> <span style="color: #6b97e8;">encoded_input</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a34;">&quot;input_ids&quot;</span><span style="color: #e3e11d;">]:</span></p>
<p>    <span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #dfd84a;">type</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">encoded</span><span style="color: #e3e11d;">))</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>&lt;class 'list'&gt;</p><p>&lt;class 'list'&gt;</p><p>&lt;class 'list'&gt;</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Recibimos listas, si queremos recibir tensores de PyTorch usamos <code><b>return_tensors="pt"</b></code></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span></p>
<p></p>
<p><span style="color: #6b97e8;">batch_sentences</span> <span>=</span> <span style="color: #e3e11d;">[</span></p>
<p>    <span style="color: #7e7a34;">&quot;Pero, ¿qué pasa con el segundo desayuno?&quot;</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #7e7a34;">&quot;No creo que sepa lo del segundo desayuno, Pedro&quot;</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #7e7a34;">&quot;¿Qué hay de los elevensies?&quot;</span><span style="color: #e3e11d;">,</span></p>
<p><span style="color: #e3e11d;">]</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">pad_token</span><span>=</span><span style="color: #7e7a34;">&quot;PAD&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">encoded_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">batch_sentences</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #a04cc1;">for</span> <span style="color: #6b97e8;">encoded</span> <span style="color: #7f6e38;">in</span> <span style="color: #6b97e8;">encoded_input</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a34;">&quot;input_ids&quot;</span><span style="color: #e3e11d;">]:</span></p>
<p>    <span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #dfd84a;">type</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">encoded</span><span style="color: #e3e11d;">),</span> <span style="color: #6b97e8;">encoded</span><span>.</span><span style="color: #6b97e8;">shape</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #dfd84a;">type</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">encoded_input</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a34;">&quot;input_ids&quot;</span><span style="color: #e3e11d;">]),</span> <span style="color: #6b97e8;">encoded_input</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a34;">&quot;input_ids&quot;</span><span style="color: #e3e11d;">]</span><span>.</span><span style="color: #6b97e8;">shape</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>&lt;class 'torch.Tensor'&gt; torch.Size([12])</p><p>&lt;class 'torch.Tensor'&gt; torch.Size([12])</p><p>&lt;class 'torch.Tensor'&gt; torch.Size([12])</p><p>&lt;class 'torch.Tensor'&gt; torch.Size([3, 12])</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Máscaras">
						<a class="anchor-link" href="#Máscaras">
							<p style="margin-left: 20px">Máscaras</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Cuando tokenizamos una sentencia no solo obtenemos los <code><b>input_ids</b></code>, sino que también obtenemos la máscara de atención. La máscara de atención es un tensor que tiene el mismo tamaño que <code><b>input_ids</b></code> y tiene un <code><b>1</b></code> en las posiciones que son tokens y un <code><b>0</b></code> en las posiciones que son padding</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span></p>
<p></p>
<p><span style="color: #6b97e8;">batch_sentences</span> <span>=</span> <span style="color: #e3e11d;">[</span></p>
<p>    <span style="color: #7e7a34;">&quot;Pero, ¿qué pasa con el segundo desayuno?&quot;</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #7e7a34;">&quot;No creo que sepa lo del segundo desayuno, Pedro&quot;</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #7e7a34;">&quot;¿Qué hay de los elevensies?&quot;</span><span style="color: #e3e11d;">,</span></p>
<p><span style="color: #e3e11d;">]</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">pad_token</span><span>=</span><span style="color: #7e7a34;">&quot;PAD&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">encoded_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">batch_sentences</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;padding token id: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token_id</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;</span><span style="color: #a6a831;">\n</span><span style="color: #7e7a34;">encoded_input[0] inputs_ids: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">encoded_input</span><span style="color: #e3e11d;">[</span><span style="color: #8d783e;">&#39;input_ids&#39;</span><span style="color: #e3e11d;">][</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">]</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;encoded_input[0] attention_mask: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">encoded_input</span><span style="color: #e3e11d;">[</span><span style="color: #8d783e;">&#39;attention_mask&#39;</span><span style="color: #e3e11d;">][</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">]</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;</span><span style="color: #a6a831;">\n</span><span style="color: #7e7a34;">encoded_input[1] inputs_ids: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">encoded_input</span><span style="color: #e3e11d;">[</span><span style="color: #8d783e;">&#39;input_ids&#39;</span><span style="color: #e3e11d;">][</span><span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">]</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;encoded_input[1] attention_mask: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">encoded_input</span><span style="color: #e3e11d;">[</span><span style="color: #8d783e;">&#39;attention_mask&#39;</span><span style="color: #e3e11d;">][</span><span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">]</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;</span><span style="color: #a6a831;">\n</span><span style="color: #7e7a34;">encoded_input[2] inputs_ids: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">encoded_input</span><span style="color: #e3e11d;">[</span><span style="color: #8d783e;">&#39;input_ids&#39;</span><span style="color: #e3e11d;">][</span><span style="color: #7e7a38;">2</span><span style="color: #e3e11d;">]</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;encoded_input[2] attention_mask: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">encoded_input</span><span style="color: #e3e11d;">[</span><span style="color: #8d783e;">&#39;attention_mask&#39;</span><span style="color: #e3e11d;">][</span><span style="color: #7e7a38;">2</span><span style="color: #e3e11d;">]</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>padding token id: 50257</p><p>encoded_input[0] inputs_ids: [2959, 16, 875, 3736, 3028, 303, 291, 2200, 8080, 35, 50257, 50257]</p><p>encoded_input[0] attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]</p><p>encoded_input[1] inputs_ids: [1489, 2275, 288, 12052, 382, 325, 2200, 8080, 16, 4319, 50257, 50257]</p><p>encoded_input[1] attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]</p><p>encoded_input[2] inputs_ids: [1699, 2899, 707, 225, 72, 73, 314, 34630, 474, 515, 1259, 35]</p><p>encoded_input[2] attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Como se puede ver, en las dos primeras sentencias, tenemos un 1 en las primeras posiciones y un 0 en las dos últimas posiciones. En esas mismas posiciones tenemos el token <code><b>50257</b></code>, que corresponde al token de padding.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Con estas máscaras de atención le estamos diciendo al modelo a qué tokens tiene que prestar atención y a cuáles no.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">La generación de texto se podría hacer igualmente si no pasáramos estas máscaras de atención, el método <code><b>generate</b></code> haría su mayur esfuerzo por inferir esta máscara, pero si se la pasamos ayudamos a generar mejor texto</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h2 id="Fast-Tokenizers">
						<a class="anchor-link" href="#Fast-Tokenizers">
							<p style="margin-left: 10px">Fast Tokenizers</p>
						</a>
					</h2>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Algunos tokenizadores preentrenados tienen una versión <code><b>fast</b></code>, tienen los mismos métodos que los normales, solo que están desarrollados en Rust. Para usarlos debemos usar la clase <code><b>PreTrainedTokenizerFast</b></code> de la librería <code><b>transformers</b></code></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Veamos primero el timepo de tokenización con un tokenizador normal</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span>%%</span><span style="color: #6b97e8;">time</span></p>
<p></p>
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">BertTokenizer</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">BertTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;google-bert/bert-base-uncased&quot;</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">sentence</span> <span>=</span> <span style="color: #e3e11d;">(</span></p>
<p>    <span style="color: #7e7a34;">&quot;The Permaculture Design Principles are a set of universal design principles &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;that can be applied to any location, climate and culture, and they allow us to design &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;the most efficient and sustainable human habitation and food production systems. &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;Permaculture is a design system that encompasses a wide variety of disciplines, such &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;as ecology, landscape design, environmental science and energy conservation, and the &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;Permaculture design principles are drawn from these various disciplines. Each individual &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;design principle itself embodies a complete conceptual framework based on sound &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;scientific principles. When we bring all these separate  principles together, we can &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;create a design system that both looks at whole systems, the parts that these systems &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;consist of, and how those parts interact with each other to create a complex, dynamic, &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;living system. Each design principle serves as a tool that allows us to integrate all &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;the separate parts of a design, referred to as elements, into a functional, synergistic, &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;whole system, where the elements harmoniously interact and work together in the most &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;efficient way possible.&quot;</span></p>
<p><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokens</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #6b97e8;">sentence</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>CPU times: user 55.3 ms, sys: 8.58 ms, total: 63.9 ms</p><p>Wall time: 226 ms</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Y ahora con uno rápido</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span>%%</span><span style="color: #6b97e8;">time</span></p>
<p></p>
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">BertTokenizerFast</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">BertTokenizerFast</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;google-bert/bert-base-uncased&quot;</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">sentence</span> <span>=</span> <span style="color: #e3e11d;">(</span></p>
<p>    <span style="color: #7e7a34;">&quot;The Permaculture Design Principles are a set of universal design principles &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;that can be applied to any location, climate and culture, and they allow us to design &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;the most efficient and sustainable human habitation and food production systems. &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;Permaculture is a design system that encompasses a wide variety of disciplines, such &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;as ecology, landscape design, environmental science and energy conservation, and the &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;Permaculture design principles are drawn from these various disciplines. Each individual &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;design principle itself embodies a complete conceptual framework based on sound &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;scientific principles. When we bring all these separate  principles together, we can &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;create a design system that both looks at whole systems, the parts that these systems &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;consist of, and how those parts interact with each other to create a complex, dynamic, &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;living system. Each design principle serves as a tool that allows us to integrate all &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;the separate parts of a design, referred to as elements, into a functional, synergistic, &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;whole system, where the elements harmoniously interact and work together in the most &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;efficient way possible.&quot;</span></p>
<p><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokens</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #6b97e8;">sentence</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>CPU times: user 42.6 ms, sys: 3.26 ms, total: 45.8 ms</p><p>Wall time: 179 ms</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Se puede ver como el <code><b>BertTokenizerFast</b></code> es unos 40 ms más rápido</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h2 id="Formas-de-generación-de-texto">
						<a class="anchor-link" href="#Formas-de-generación-de-texto">
							<p style="margin-left: 10px">Formas de generación de texto</p>
						</a>
					</h2>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Seguimos con las tripas de la librería <code><b>transformers</b></code>, ahora vamos a ver las maneras de generar texto.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">La arquitectura transformer genera el siguiente token más probable, esta es la manera más sencilla de generar texto, pero no es la única, así que vamos a verlas.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">A la hora de generar textno no hay una forma mejor y dependerá de nuestro modelo y del propósito de uso</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Greedy-Search">
						<a class="anchor-link" href="#Greedy-Search">
							<p style="margin-left: 20px">Greedy Search</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Es la manera más sencilla de generación de texto. Busca el token más probable en cada iteracción</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"><p align="center"><img src="http://maximofn.com/wp-content/uploads/2024/03/greedy_search.webp" alt="greedy_search"></p></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Para generar téxto de esta manera con <code><b>transformers</b></code> no hay que hacer nada especial, ya que es la manera por defecto</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokens_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokens_output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">tokens_input</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_new_tokens</span><span>=</span><span style="color: #7e7a38;">500</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokens_output</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">sentence_output</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Me encanta aprender de los demás, y en este caso de los que me rodean, y es que en el fondo, es una forma de aprender de los demás.</p><p>En este caso, el objetivo de la actividad es que los niños aprendan a reconocer los diferentes tipos de animales que existen en el mundo, y que en ocasiones, son muy difíciles de reconocer.</p><p>En este caso, los niños se han dado cuenta de que los animales que hay en el mundo, son muy difíciles de reconocer, y que en ocasiones, son muy difíciles de reconocer.</p><p>En este caso, los niños han aprendido a reconocer los diferentes tipos de animales que existen en el mundo, y que en ocasiones, son muy difíciles de reconocer.</p><p>En este caso, los niños han aprendido a reconocer los diferentes tipos de animales que existen en el mundo, y que en ocasiones, son muy difíciles de reconocer.</p><p>En este caso, los niños han aprendido a reconocer los diferentes tipos de animales que existen en el mundo, y que en ocasiones, son muy difíciles de reconocer.</p><p>En este caso, los niños han aprendido a reconocer los diferentes tipos de animales que existen en el mundo, y que en ocasiones, son muy difíciles de reconocer.</p><p>En este caso, los niños han aprendido a reconocer los diferentes tipos de animales que existen en el mundo, y que en ocasiones, son muy difíciles de reconocer.</p><p>En este caso, los niños han aprendido a reconocer los diferentes tipos de animales que existen en el mundo, y que en ocasiones, son muy difíciles de reconocer.</p><p>En este caso, los niños han aprendido a reconocer los diferentes tipos de animales que existen en el mundo, y que en ocasiones, son muy difíciles de reconocer.</p><p>En este caso, los niños han aprendido a reconocer los diferentes tipos de animales que existen en el mundo, y que en ocasiones, son muy difíciles de reconocer.</p><p>En este caso, los niños han aprendido a reconocer los diferentes tipos de animales que existen en el mundo, y que e</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Se puede ver que el texto generado está bien, pero se empieza a repetir. Esto es porque en la búsqueda codiciosa (greedy search), palabras con una alta probabilidad se pueden esconder detrás de palabras con una probabilidad más baja, por lo que se pueden perder</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"><p align="center"><img src="http://maximofn.com/wp-content/uploads/2024/03/greedy_search.webp" alt="greedy_search"></p></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Aquí, la palabra <code><b>has</b></code> tiene una alta probabilidad, pero queda escondida detrás de <code><b>dog</b></code>, que tiene menor probabilidad que <code><b>nice</b></code></p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Contrastive-Search">
						<a class="anchor-link" href="#Contrastive-Search">
							<p style="margin-left: 20px">Contrastive Search</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">El método Contrastive Search optimiza la generación de texto seleccionando las opciones de palabras o frases que maximizan un criterio de calidad sobre otras menos deseables. En la práctica, esto significa que durante la generación de texto, en cada paso, el modelo no solo busca la siguiente palabra que tiene mayor probabilidad de seguir según lo aprendido durante su entrenamiento, sino que también compara diferentes candidatos para esa próxima palabra y evalúa cuál de ellos contribuiría a formar el texto más coherente, relevante y de alta calidad en el contexto dado. Por lo tanto, Contrastive Search reduce la posibilidad de generar respuestas irrelevantes o de baja calidad, enfocándose en aquellas opciones que mejor se ajustan al objetivo de la generación de texto, basándose en una comparación directa entre posibles continuaciones en cada paso del proceso.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Para generar texto con contrastive search en <code><b>transformers</b></code> hay que usar los parámetros <code><b>penalty_alpha</b></code> y <code><b>top_k</b></code> a la hora de generar texto</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokens_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokens_output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">tokens_input</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_new_tokens</span><span>=</span><span style="color: #7e7a38;">500</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">penalty_alpha</span><span>=</span><span style="color: #a09e19;">0.6</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">top_k</span><span>=</span><span style="color: #7e7a38;">4</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokens_output</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">sentence_output</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Me encanta aprender de los demás, es una de las cosas que más me gusta del mundo.</p><p>En la clase de hoy he estado haciendo un repaso de lo que es el arte de la costura, para que podáis ver como se hace una prenda de ropa y como se confeccionan los patrones.</p><p>El patrón de esta blusa es de mi amiga Marga, que me ha pedido que os enseñara a hacer este tipo de prendas, ya que es una de las cosas que más me gusta del mundo.</p><p>La blusa es de la talla S, y tiene un largo de manga 3/4, por lo que es ideal para cualquier ocasión.</p><p>Para hacer el patrón de esta blusa utilicé una tela de algodón 100% de color azul marino, que es la que yo he utilizado para hacer la blusa.</p><p>En la parte delantera de la blusa, cosí un lazo de raso de color azul marino, que le da un toque de color a la prenda.</p><p>Como podéis ver en la foto, el patrón de esta blusa es de la talla S, y tiene un largo de manga 3/4, por lo que es ideal para cualquier ocasión.</p><p>Para hacer el patrón de esta blusa utilicé una tela de algodón 100% de color azul marino, que es la que yo he utilizado para hacer la blusa.</p><p>En la parte delantera de la blusa utilicé un lazo de raso de color azul marino, que le da un toque de color a la prenda.</p><p>Para hacer el patrón de esta blusa utilicé una tela de algodón 100% de color azul marino, que es la que yo he utilizado para hacer la blusa.</p><p>En la parte delantera de la blusa utilicé un lazo de raso de color azul marino, que le da un toque de color a la prenda.</p><p>Para hacer el patrón de esta blusa utilicé una tela de algodón 100% de color azul marino, que es la que yo he utilizado para hacer la blusa.</p><p>En la parte delantera de la blusa utilicé</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Aquí el modelo tarda más en empezar a repetirse</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Multinomial-sampling">
						<a class="anchor-link" href="#Multinomial-sampling">
							<p style="margin-left: 20px">Multinomial sampling</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">A diferencia de la búsqueda codiciosa que siempre elige un token con la mayor probabilidad como el siguiente token, el muestreo multinomial (también llamado muestreo ancestral) selecciona aleatoriamente el siguiente token en función de la distribución de probabilidad de todo el vocabulario proporcionado por el modelo. Cada token con una probabilidad distinta de cero tiene posibilidades de ser seleccionado, lo que reduce el riesgo de repetición.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Para habilitar el <code><b>Multinomial sampling</b></code> hay que poner <code><b>do_sample=True</b></code> y <code><b>num_beams=1</b></code>.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokens_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokens_output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">tokens_input</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_new_tokens</span><span>=</span><span style="color: #7e7a38;">500</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">do_sample</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">num_beams</span><span>=</span><span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokens_output</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">sentence_output</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Me encanta aprender de los de siempre y conocer a gente nueva, soy de las que no tiene mucho contacto con los de antes, pero he estado bastante liada con el diseño de mi página web de lo que sería el logo, he escrito varios diseños para otros blogs y cosas así, así que a ver si pronto puedo poner de mi parte alguna ayuda.</p><p>A finales de los años 70 del pasado siglo los arquitectos alemanes Hermann Grossberg y Heinrich Rindsner eran los principales representantes de la arquitectura industrial de la alta sociedad. La arquitectura industrial era la actividad que más rápido progresaba en el diseño, y de ellos destacaban los diseños que Grossberg llevó a cabo en el prestigioso Hotel Marigal.</p><p>De acuerdo con las conclusiones y opiniones expuestas por los autores sobre el reciente congreso sobre historia del diseño industrial, se ha llegado al convencimiento de que en los últimos años, los diseñadores industriales han descubierto muchas nuevas formas de entender la arquitectura. En palabras de Klaus Eindhoven, director general de la fundación alemana G. Grossberg, “estamos tratando de desarrollar un trabajo que tenga en cuenta los criterios más significativos de la teoría arquitectónica tradicional”.</p><p>En este artículo de opinión, Eindhoven y Grossberg explican por qué el auge de la arquitectura industrial en Alemania ha generado una gran cantidad de nuevos diseños de viviendas, de grandes dimensiones, de edificios de gran valor arquitectónico. Los más conocidos son los de los diseñadores Walter Nachtmann (1934) e ingeniero industrial, Frank Gehry (1929), arquitecto que ideó las primeras viviendas de estilo neoclásico en la localidad británica de Stegmarbe. Son viviendas de los siglos XVI al XX, algunas con un estilo clasicista que recuerda las casas de Venecia. Se trata de edificios con un importante valor histórico y arquitectónico, y que representan la obra de la técnica del modernismo.</p><p>La teoría general sobre los efectos de la arquitectura en un determinado tipo de espacio no ha resultado ser totalmente transparente, y mucho menos para los arquitectos, que tienen que aprender de los arquitectos de ayer, durante esos</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">La verdad es que el modelo no se repite nada, pero siento que estoy hablando con un niño pequeño, que habla de un tema y empieza a hilar con otros que no tienen nada que ver</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Beam-search">
						<a class="anchor-link" href="#Beam-search">
							<p style="margin-left: 20px">Beam search</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">La búsqueda por haz reduce el riesgo de perder secuencias de palabras ocultas de alta probabilidad al mantener el <code><b>num_beams</b></code> más probable en cada paso de tiempo y, finalmente, elegir la hipótesis que tenga la probabilidad más alta en general.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Para generar con <code><b>beam search</b></code> es necesario añadir el parámetro <code><b>num_beams</b></code></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokens_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokens_output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">tokens_input</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_new_tokens</span><span>=</span><span style="color: #7e7a38;">500</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">num_beams</span><span>=</span><span style="color: #7e7a38;">5</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokens_output</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">sentence_output</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Me encanta aprender de los errores y aprender de los aciertos de los demás, en este caso, de los míos.</p><p>Me encanta aprender de los errores y aprender de los aciertos de los demás, en este caso, de los míos.</p><p>Me encanta aprender de los errores y aprender de los aciertos de los demás, en este caso, de los míos.</p><p>Me encanta aprender de los errores y aprender de los aciertos de los demás, en este caso, de los míos.</p><p>Me encanta aprender de los errores y aprender de los aciertos de los demás, en este caso, de los míos.</p><p>Me encanta aprender de los errores y aprender de los aciertos de los demás, en este caso, de los míos.</p><p>Me encanta aprender de los errores y aprender de los aciertos de los demás, en este caso, de los míos.</p><p>Me encanta aprender de los errores y aprender de los aciertos de los demás, en este caso, de los míos.</p><p>Me encanta aprender de los errores y aprender de los aciertos de los demás, en este caso, de los míos.</p><p>Me encanta aprender de los errores y aprender de los aciertos de los demás, en este caso, de los míos.</p><p>Me encanta aprender de los errores y aprender de los aciertos de los demás, en este caso, de los míos.</p><p>Me encanta aprender de los errores y aprender de los aciertos de los demás, en este caso, de los míos.</p><p>Me encanta aprender de los errores y aprender de los aciertos de los demás, en este caso, de los míos.</p><p>Me encanta aprender de los errores y aprender de los aciertos de los demás, en este caso, de los míos.</p><p>Me encanta aprender de los errores y aprender de los aciertos de los demás, en este caso, de</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Se repite bastante</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Beam-search-multinomial-sampling">
						<a class="anchor-link" href="#Beam-search-multinomial-sampling">
							<p style="margin-left: 20px">Beam search multinomial sampling</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Esta técnica junta el <code><b>bean search</b></code> donde se busca por haz y el <code><b>multinomial sampling</b></code> donde se selecciona aleatoriamente el siguiente token en función de la distribución de probabilidad de todo el vocabulario proporcionado por el modelo.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokens_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokens_output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">tokens_input</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_new_tokens</span><span>=</span><span style="color: #7e7a38;">500</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">num_beams</span><span>=</span><span style="color: #7e7a38;">5</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">do_sample</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokens_output</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">sentence_output</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Me encanta aprender de los demás, en especial de las personas que me rodean, y en especial de mis compañeros de trabajo. Me encanta aprender de los demás, en especial de las personas que me rodean, y en especial de mis compañeros de trabajo. Me encanta aprender de los demás, en especial de las personas que me rodean, y en especial de mis compañeros de trabajo. Me encanta aprender de los demás, en especial de las personas que me rodean, y en especial de mis compañeros de trabajo. Me encanta aprender de los demás, en especial de las personas que me rodean, y en especial de mis compañeros de trabajo. Me encanta aprender de los demás, en especial de las personas que me rodean, y en especial de mis compañeros de trabajo. Me encanta aprender de los demás, en especial de las personas que me rodean, y en especial de mis compañeros de trabajo. Me encanta aprender de los demás, en especial de las personas que me rodean, y en especial de mis compañeros de trabajo. Me encanta aprender de los demás, en especial de las personas que me rodean, y en especial de mis compañeros de trabajo. Me encanta aprender de los demás, en especial de las personas que me rodean, y en especial de mis compañeros de trabajo. Me encanta aprender de los demás, en especial de las personas que me rodean, y en especial de mis compañeros de trabajo. Me encanta aprender de los demás, en especial de las personas que me rodean, y en especial de mis compañeros de trabajo. Me encanta aprender de los demás, en especial de las personas que me rodean, y en especial de mis compañeros de trabajo. Me encanta aprender de los demás, en especial de las personas que me rodean, y e</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Se repite bastante</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Beam-search-n-grams-penalty">
						<a class="anchor-link" href="#Beam-search-n-grams-penalty">
							<p style="margin-left: 20px">Beam search n-grams penalty</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Para evitar la repetición podemos penalizar por la repetición de n-gramas. Para ello usamos el parámetro <code><b>no_repeat_ngram_size</b></code></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokens_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokens_output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">tokens_input</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_new_tokens</span><span>=</span><span style="color: #7e7a38;">500</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">num_beams</span><span>=</span><span style="color: #7e7a38;">5</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">no_repeat_ngram_size</span><span>=</span><span style="color: #7e7a38;">2</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokens_output</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">sentence_output</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Me encanta aprender de los demás, y en este caso, no podía ser menos, así que me puse manos a la obra.</p><p>En primer lugar, me hice con un libro que se llama "El mundo eslavo" y que, como ya os he dicho, se puede adquirir por un módico precio (unos 5 euros).</p><p>El libro está compuesto por dos partes: la primera, que trata sobre la historia del Imperio Romano y la segunda, sobre el Imperio Bizantino. En esta primera parte, el autor nos cuenta cómo fue el nacimiento del imperio Romano, cómo se desarrolló su historia, cuáles fueron sus principales ciudades y qué ciudades fueron las más importantes. Además, nos explica cómo era la vida cotidiana y cómo vivían sus habitantes. Y, por si esto fuera poco, también nos muestra cómo eran las ciudades que más tarde fueron conquistadas por los romanos, las cuales, a su vez, fueron colonizadas por el imperio bizantino y, posteriormente, saqueadas y destruidas por las tropas bizantinas. Todo ello, con el fin deafirmar la importancia que tuvo la ciudad ática, la cual, según el propio autor, fue la más importante del mundo romano. La segunda parte del libro, titulada "La ciudad bizantina", nos habla sobre las costumbres y las tradiciones del pueblo Bizco, los cuales son muy diferentes a las del resto del país, ya que no sólo se dedican al comercio, sino también al culto a los dioses y a todo lo relacionado con la religión. Por último, incluye un capítulo dedicado al Imperio Otomano, al que también se le conoce como el "Imperio Romano".</p><p>Por otro lado, os dejo un enlace a una página web donde podréis encontrar más información sobre este libro: http://www.elmundodeuterio.com/es/libros/el-mundo-sucio-y-la-historia-del-imperio-ibero-italia/</p><p>Como podéis ver, he querido hacer un pequeño homenaje a todas las personas que han hecho posible que el libro se haya hecho realidad. Espero que os haya gustado y os animéis a adquirirlo. Si tenéis alguna duda, podéis dejarme un comentario o escribirme un correo a mi correo electrónico: [email protected]</p><p>¡Hola a todos! ¿Qué tal estáis? Hoy os traigo una entrada muy especial. Se trata del sorteo que he hecho para celebrar el día del padre. Como ya sabéis, este año no he tenido mucho tiempo, pero</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Este texto ya no se repite y además tiene algo más de coherencia. </p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Sin embargo, las penalizaciones de n-gramas deben utilizarse con cuidado. Un artículo generado sobre la ciudad de Nueva York no debería usar una penalización de 2 gramos o de lo contrario, ¡el nombre de la ciudad solo aparecería una vez en todo el texto!</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Beam-search-n-grams-penalty-return-sequences">
						<a class="anchor-link" href="#Beam-search-n-grams-penalty-return-sequences">
							<p style="margin-left: 20px">Beam search n-grams penalty return sequences</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Podemos generar varias secuancias para compararlas y quedarnos con la mejor. Para ello usamos el parámetro <code><b>num_return_sequences</b></code> con la condición de que <code><b>num_return_sequences <= num_beams</b></code></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokens_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokens_outputs</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">tokens_input</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_new_tokens</span><span>=</span><span style="color: #7e7a38;">500</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">num_beams</span><span>=</span><span style="color: #7e7a38;">5</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">no_repeat_ngram_size</span><span>=</span><span style="color: #7e7a38;">2</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">num_return_sequences</span><span>=</span><span style="color: #7e7a38;">3</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #a04cc1;">for</span> <span style="color: #6b97e8;">i</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">tokens_output</span> <span style="color: #7f6e38;">in</span> <span style="color: #dfd84a;">enumerate</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokens_outputs</span><span style="color: #e3e11d;">):</span></p>
<p>    <span style="color: #a04cc1;">if</span> <span style="color: #6b97e8;">i</span> <span>!=</span> <span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">:</span></p>
<p>        <span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;</span><span style="color: #a6a831;">\n\n</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
<p>    <span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokens_output</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p>    <span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;</span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">i</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">sentence_output</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>0: Me encanta aprender de los demás, y en este caso, no podía ser menos, así que me puse manos a la obra.</p><p>En primer lugar, me hice con un libro que se llama "El mundo eslavo" y que, como ya os he dicho, se puede adquirir por un módico precio (unos 5 euros).</p><p>El libro está compuesto por dos partes: la primera, que trata sobre la historia del Imperio Romano y la segunda, sobre el Imperio Bizantino. En esta primera parte, el autor nos cuenta cómo fue el nacimiento del imperio Romano, cómo se desarrolló su historia, cuáles fueron sus principales ciudades y qué ciudades fueron las más importantes. Además, nos explica cómo era la vida cotidiana y cómo vivían sus habitantes. Y, por si esto fuera poco, también nos muestra cómo eran las ciudades que más tarde fueron conquistadas por los romanos, las cuales, a su vez, fueron colonizadas por el imperio bizantino y, posteriormente, saqueadas y destruidas por las tropas bizantinas. Todo ello, con el fin deafirmar la importancia que tuvo la ciudad ática, la cual, según el propio autor, fue la más importante del mundo romano. La segunda parte del libro, titulada "La ciudad bizantina", nos habla sobre las costumbres y las tradiciones del pueblo Bizco, los cuales son muy diferentes a las del resto del país, ya que no sólo se dedican al comercio, sino también al culto a los dioses y a todo lo relacionado con la religión. Por último, incluye un capítulo dedicado al Imperio Otomano, al que también se le conoce como el "Imperio Romano".</p><p>Por otro lado, os dejo un enlace a una página web donde podréis encontrar más información sobre este libro: http://www.elmundodeuterio.com/es/libros/el-mundo-sucio-y-la-historia-del-imperio-ibero-italia/</p><p>Como podéis ver, he querido hacer un pequeño homenaje a todas las personas que han hecho posible que el libro se haya hecho realidad. Espero que os haya gustado y os animéis a adquirirlo. Si tenéis alguna duda, podéis dejarme un comentario o escribirme un correo a mi correo electrónico: [email protected]</p><p>¡Hola a todos! ¿Qué tal estáis? Hoy os traigo una entrada muy especial. Se trata del sorteo que he hecho para celebrar el día del padre. Como ya sabéis, este año no he tenido mucho tiempo, pero</p><p>1: Me encanta aprender de los demás, y en este caso, no podía ser menos, así que me puse manos a la obra.</p><p>En primer lugar, me hice con un libro que se llama "El mundo eslavo" y que, como ya os he dicho, se puede adquirir por un módico precio (unos 5 euros).</p><p>El libro está compuesto por dos partes: la primera, que trata sobre la historia del Imperio Romano y la segunda, sobre el Imperio Bizantino. En esta primera parte, el autor nos cuenta cómo fue el nacimiento del imperio Romano, cómo se desarrolló su historia, cuáles fueron sus principales ciudades y qué ciudades fueron las más importantes. Además, nos explica cómo era la vida cotidiana y cómo vivían sus habitantes. Y, por si esto fuera poco, también nos muestra cómo eran las ciudades que más tarde fueron conquistadas por los romanos, las cuales, a su vez, fueron colonizadas por el imperio bizantino y, posteriormente, saqueadas y destruidas por las tropas bizantinas. Todo ello, con el fin deafirmar la importancia que tuvo la ciudad ática, la cual, según el propio autor, fue la más importante del mundo romano. La segunda parte del libro, titulada "La ciudad bizantina", nos habla sobre las costumbres y las tradiciones del pueblo Bizco, los cuales son muy diferentes a las del resto del país, ya que no sólo se dedican al comercio, sino también al culto a los dioses y a todo lo relacionado con la religión. Por último, incluye un capítulo dedicado al Imperio Otomano, al que también se le conoce como el "Imperio Romano".</p><p>Por otro lado, os dejo un enlace a una página web donde podréis encontrar más información sobre este libro: http://www.elmundodeuterio.com/es/libros/el-mundo-sucio-y-la-historia-del-imperio-ibero-italia/</p><p>Como podéis ver, he querido hacer un pequeño homenaje a todas las personas que han hecho posible que el libro se haya hecho realidad. Espero que os haya gustado y os animéis a adquirirlo. Si tenéis alguna duda, podéis dejarme un comentario o escribirme un correo a mi correo electrónico: [email protected]</p><p>¡Hola a todos! ¿Qué tal estáis? Hoy os traigo una entrada muy especial. Se trata del sorteo que he hecho para celebrar el día del padre. Como ya sabéis, este año no he tenido mucho tiempo para hacer</p><p>2: Me encanta aprender de los demás, y en este caso, no podía ser menos, así que me puse manos a la obra.</p><p>En primer lugar, me hice con un libro que se llama "El mundo eslavo" y que, como ya os he dicho, se puede adquirir por un módico precio (unos 5 euros).</p><p>El libro está compuesto por dos partes: la primera, que trata sobre la historia del Imperio Romano y la segunda, sobre el Imperio Bizantino. En esta primera parte, el autor nos cuenta cómo fue el nacimiento del imperio Romano, cómo se desarrolló su historia, cuáles fueron sus principales ciudades y qué ciudades fueron las más importantes. Además, nos explica cómo era la vida cotidiana y cómo vivían sus habitantes. Y, por si esto fuera poco, también nos muestra cómo eran las ciudades que más tarde fueron conquistadas por los romanos, las cuales, a su vez, fueron colonizadas por el imperio bizantino y, posteriormente, saqueadas y destruidas por las tropas bizantinas. Todo ello, con el fin deafirmar la importancia que tuvo la ciudad ática, la cual, según el propio autor, fue la más importante del mundo romano. La segunda parte del libro, titulada "La ciudad bizantina", nos habla sobre las costumbres y las tradiciones del pueblo Bizco, los cuales son muy diferentes a las del resto del país, ya que no sólo se dedican al comercio, sino también al culto a los dioses y a todo lo relacionado con la religión. Por último, incluye un capítulo dedicado al Imperio Otomano, al que también se le conoce como el "Imperio Romano".</p><p>Por otro lado, os dejo un enlace a una página web donde podréis encontrar más información sobre este libro: http://www.elmundodeuterio.com/es/libros/el-mundo-sucio-y-la-historia-del-imperio-ibero-italia/</p><p>Como podéis ver, he querido hacer un pequeño homenaje a todas las personas que han hecho posible que el libro se haya hecho realidad. Espero que os haya gustado y os animéis a adquirirlo. Si tenéis alguna duda, podéis dejarme un comentario o escribirme un correo a mi correo electrónico: [email protected]</p><p>¡Hola a todos! ¿Qué tal estáis? Hoy os traigo una entrada muy especial. Se trata del sorteo que he hecho para celebrar el día del padre. Como ya sabéis, este año no he tenido mucho tiempo para publicar</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Ahora podemos quedarnos con la mejor secuencia</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Diverse-beam-search-decoding">
						<a class="anchor-link" href="#Diverse-beam-search-decoding">
							<p style="margin-left: 20px">Diverse beam search decoding</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">La diverse beam search decoding es una extensión de la estrategia de búsqueda de haces que permite generar un conjunto más diverso de secuencias de haces para elegir.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Para poder generar texto de esta manera tenemos que usar los parámetros <code><b> num_beams</b></code>, <code><b>num_beam_groups</b></code>, y <code><b>diversity_penalty</b></code></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokens_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokens_output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">tokens_input</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_new_tokens</span><span>=</span><span style="color: #7e7a38;">500</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">num_beams</span><span>=</span><span style="color: #7e7a38;">5</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">num_beam_groups</span><span>=</span><span style="color: #7e7a38;">5</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">diversity_penalty</span><span>=</span><span style="color: #a09e19;">1.0</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokens_output</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">sentence_output</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Este método parece que se repite bastante</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Speculative-Decoding">
						<a class="anchor-link" href="#Speculative-Decoding">
							<p style="margin-left: 20px">Speculative Decoding</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">La decodificación especulativa (también conocida como decodificación asistida) es una modificación de las estrategias de decodificación anteriores, que utiliza un modelo asistente (idealmente uno mucho más pequeño) con el mismo tokenizador, para generar algunos tokens candidatos. Luego, el modelo principal valida los tokens candidatos en un único paso hacia adelante, lo que acelera el proceso de decodificación</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Para generar texto de esta manera es necesario usar el parámetro <code><b>do_sample=True</b></code></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Actualmente, la decodificación asistida solo admite greedy search, y la decodificación asistida no admite entradas por lotes</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">assistant_model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokens_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokens_output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">tokens_input</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_new_tokens</span><span>=</span><span style="color: #7e7a38;">500</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">assistant_model</span><span>=</span><span style="color: #6b97e8;">assistant_model</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">do_sample</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokens_output</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">sentence_output</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Me encanta aprender de los demás! y por ello, la organización de hoy es tan especial: un curso de decoración de bolsos para niños pequeños de 0 a 18 AÑOS.</p><p>En este taller aprenderemos a decorar bolsos para regalar, con los materiales que sean necesarios para cubrir las necesidades de estos peques, como pueden ser, un estuche con todo lo que necesiten, ropa interior, mantas, complementos textiles, complementos alimenticios, o un bonito neceser con todo lo que necesiten.</p><p>Os dejo con un pequeño tutorial de decoración de bolsos para niños, realizado por mi amiga Rosa y sus amigas Silvia y Rosa, que se dedica a la creación de bolsos para bebés que son un verdadero tesoro para sus pequeños. Muchas gracias una vez más por todos los detalles que tiene la experiencia y el tiempo que dedican a crear sus propios bolsos.</p><p>En muchas ocasiones, cuando se nos acerca una celebración, siempre nos preguntamos por qué, por qué en especial, por que se trata de algo que no tienen tan cerca nuestras vidas y, claro está, también por que nos hemos acostumbrado a vivir en el mundo de lo mundano y de lo comercial, tal y como los niños y niñas de hoy, a la manera de sus padres, donde todo es caro, todo es difícil, los precios no están al alcance de todos y, por estas y por muchas más preguntas por las que estamos deseando seguir escuchando, este curso y muchas otras cosas que os encontraréis a lo largo de la mañana de hoy, os van a dar la clave sobre la que empezar a preparar una fiesta de esta importancia.</p><p>El objetivo del curso es que aprendáis a decorar bolsos para regalar con materiales sencillos, simples y de buena calidad; que os gusten y os sirvan de decoración y que por supuesto os sean útiles. Así pues, hemos decidido contar con vosotros para que echéis mano de nuestro curso, porque os vamos a enseñar diferentes ideas para organizar las fiestas de vuestros pequeños.</p><p>Al tratarse de un curso muy básico, vais a encontrar ideas muy variadas, que van desde sencillas manualidades con los bolsillos, hasta mucho más elaboradas y que si lo veis con claridad en un tutorial os vais a poder dar una idea de cómo se ha de aplicar estos consejos a vuestra tienda.</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Este método tiene muy buenos resultados</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Speculative-Decoding-randomness-control">
						<a class="anchor-link" href="#Speculative-Decoding-randomness-control">
							<p style="margin-left: 20px">Speculative Decoding randomness control</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Cuando se utiliza la decodificación asistida con métodos de muestreo, se puede utilizar el parámetro <code><b>temperature</b></code> para controlar la aleatoriedad. Sin embargo, en la decodificación asistida, reducir la temperatura puede ayudar a mejorar la latencia.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">assistant_model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokens_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokens_output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">tokens_input</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_new_tokens</span><span>=</span><span style="color: #7e7a38;">500</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">assistant_model</span><span>=</span><span style="color: #6b97e8;">assistant_model</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">do_sample</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">temperature</span><span>=</span><span style="color: #a09e19;">0.5</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokens_output</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">sentence_output</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Me encanta aprender de los demás y de las personas que nos rodean. Y no sólo eso, sino que además me gusta aprender de los demás. He aprendido mucho de los que me rodean y de las personas que me rodean.</p><p>Me encanta conocer gente nueva, aprender de los demás y de las personas que me rodean. Y no sólo eso, sino que además me gusta aprender de los demás.</p><p>En el mundo de la vida hay muchas personas que se quieren llevar bien, pero que no saben como afrontar las situaciones que se les presentan.</p><p>En el mundo de la vida hay muchas personas que se quieren llevar bien, pero que no saben como afrontar las situaciones que se les presentan.</p><p>Cada persona tiene su manera de pensar, de sentir y de actuar, pero todas tienen la misma manera de pensar.</p><p>La mayoría de las personas, por diferentes motivos, se quieren llevar bien con otras personas, pero no saben como afrontar las situaciones que se les presentan.</p><p>En el mundo de la vida hay muchas personas que se quieren llevar bien, pero que no saben como afrontar las situaciones que se les presentan.</p><p>En el mundo de la vida hay muchas personas que se quieren llevar bien, pero que no saben como afrontar las situaciones que se les presentan.</p><p>En el mundo de la vida hay muchas personas que se quieren llevar bien, pero que no saben como afrontar las situaciones que se les presentan.</p><p>En el mundo de la vida hay muchas personas que se quieren llevar bien, pero que no saben como afrontar las situaciones que se les presentan.</p><p>En el mundo de la vida hay muchas personas que se quieren llevar bien, pero que no saben como afrontar las situaciones que se les presentan.</p><p>En el mundo de la vida hay muchas personas que se quieren llevar bien, pero que no saben como afrontar las situaciones que se les presentan.</p><p>En el mundo de la vida hay muchas personas que se quieren llevar bien, pero que no saben como afrontar las situaciones que se les presentan.</p><p>En el mundo de la vida hay muchas personas que se quieren llevar bien, pero que no saben como afrontar las situaciones que se les presentan.</p><p>En el mundo de la vida hay muchas personas que se quieren llevar bien, pero que no saben como afrontar las situaciones que se les presentan.</p><p>En el mundo </p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Aquí no lo ha generado tan bien</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Sampling">
						<a class="anchor-link" href="#Sampling">
							<p style="margin-left: 20px">Sampling</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Aquí empiezan las técnicas usadas por los LLMs actuales</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">El método de muestreo se basa en lugar de siempre seleccionar la palabra más probable (que podría llevar a textos predecibles o repetitivos), el muestreo introduce aleatoriedad en el proceso de selección, permitiendo que el modelo explore una variedad de palabras posibles basadas en sus probabilidades. Es como lanzar un dado ponderado para cada palabra. Así, mientras más alta sea la probabilidad de una palabra, más probabilidad tiene de ser seleccionada, pero aún hay una oportunidad para que palabras menos probables sean elegidas, enriqueciendo la diversidad y creatividad del texto generado. Este método ayuda a evitar respuestas monótonas y aumenta la variabilidad y naturalidad del texto producido.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"><p align="center"><img src="https://maximofn.com/wp-content/uploads/2024/04/sampling-scaled.webp" alt="sampling"></p></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Como se puede ver en la imagen, el primer token, que es el que tiene mayor probabilidad se ha repetido hasta 11 veces, el segundo hasta 8 veces, el tercero hasta 4 y el último solo se ha añadido en 1. De esta manera se elige aleatoriamente entre todos, pero lo más probable es que salga el primer token, ya que es el que aparece más veces</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Para usar este método elegimos <code><b>do_sample=True</b></code> y <code><b>top_k=0</b></code></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokens_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokens_output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">tokens_input</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_new_tokens</span><span>=</span><span style="color: #7e7a38;">500</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">do_sample</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">top_k</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokens_output</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">sentence_output</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Me encanta aprender de los demás, conocer a los demás, entender las cosas, la gente y las relaciones? y eso ha sido siempre lo que me ha ocurrido con Zoë a lo largo de estos años. Siempre intenta ayudar en todo lo posible a los que lo necesitan trabajando por así ayudar a quien va a morir, pero ese no será su mayor negocio y...</p><p>Mirta me ayudará a desconectar de todo porque tras el trabajo en un laboratorio y la estricta dieta que tenía socialmente restringida he de empezar a ser algo más que una niña. Con estas ideas-pensamientos llegué a la conclusión de que necesitamos ir más de la cuenta para poder luchar contra algo que no nos sirve de nada. Para mí eso...</p><p>La mayoría de nosotros tenemos la sensación de que vivir es sencillo, sin complicaciones y sin embargo todos estamos inconformes con este fruto anual que se celebra cada año en esta población. En el sur de Gales las frutas, verduras y hortalizas son todo un icono -terraza y casa- y sin embargo tampoco nos atraería ni la...</p><p>Vivimos en un país que a menudo presenta elementos religiosos muy ensimismados en aspectos puramente positivistas que pueden ser de juzgarse sin la presencia de Dios. Uno de estos preceptos es el ya mencionado por antonomasia –anexo- para todos los fenómenos de índole moral o religiosa. Por ejemplo, los sacrificios humanos, pero, la...</p><p>Andreas Lombstsch continúa trabajando sobre el terreno de la ciencia del conjunto de misterios: desde el saber eterno hasta los viajes en extraterrestres, la brutalidad de muchos cuerpos en películas, el hielo marino con el que esta ciencia es conocida y los extrinformes que con motivos fuera de lo común han revolucionado la educación occidental.Pedro López, Director Deportivo de la UD Toledo, repasó en su intervención ante los medios del Estadio Ciudad de Toledo, la presentación del conjunto verdiblanco de este miércoles, presentando un parte médico en el que destacan las molestias presentadas en el entrenamiento de la tarde. “Quedar fuera en el partido de esa manera con el 41. y por la lesión de Chema (Intuición Araujo aunque ya</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">No genera texto repetitivo, pero genera un texto que no parece muy coherente. Este es el problema de poder elegir cualquier palabra</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Sampling-temperature">
						<a class="anchor-link" href="#Sampling-temperature">
							<p style="margin-left: 20px">Sampling temperature</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Para solventar el problema del método de muestreo se añade un parámetro de <code><b>temperatura</b></code> que ajusta el nivel de aleatoriedad en la selección de palabras.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">La temperatura es un parámetro que modifica cómo se distribuyen las probabilidades de las posibles siguientes palabras.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Con una temperatura de 1, la distribución de probabilidad se mantiene según lo aprendido por el modelo, manteniendo un equilibrio entre previsibilidad y creatividad</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Si se baja la temperatura (menos de 1), se aumenta el peso de las palabras más probables, haciendo que el texto generado sea más predecible y coherente, pero menos diverso y creativo.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Al aumentar la temperatura (más de 1), se reduce la diferencia de probabilidad entre las palabras, dando a las menos probables una mayor probabilidad de ser seleccionadas, lo que incrementa la diversidad y la creatividad del texto, pero puede comprometer su coherencia y relevancia.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"><p align="center"><img src="https://maximofn.com/wp-content/uploads/2024/04/temperature.webp" alt="temperature"></p></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">La temperatura permite afinar el equilibrio entre la originalidad y la coherencia del texto generado, ajustándolo a las necesidades específicas de la tarea.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Para añadir este parámetro, usamos el parámetro <code><b>temperature</b></code> de la librería</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Primero probamos con un valor bajo</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokens_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokens_output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">tokens_input</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_new_tokens</span><span>=</span><span style="color: #7e7a38;">500</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">do_sample</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">top_k</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">temperature</span><span>=</span><span style="color: #a09e19;">0.7</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokens_output</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">sentence_output</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Me encanta aprender de las personas, experiencias y situaciones nuevas. Me gusta conocer gente y aprender de las personas. Me gusta conocer personas y aprender de las personas.</p><p>Soy un joven muy amable, respetuoso, yo soy como un amigo que quiere conocer gente y hacer amistades. Me gusta conocer gente nueva y hacer amigos.</p><p>Tengo una gran pasión, la música, la mayoría de mis canciones favoritas son de poetas españoles que me han inspirado a crear canciones. Tengo mucho que aprender de ellos y de su música.</p><p>Me encanta aprender de las personas, experiencias y situaciones nuevas. Me gusta conocer gente y aprender de las personas.</p><p>Tengo una gran pasión, la música, la mayoría de mis canciones favoritas son de poetas españoles que me han inspirado a crear canciones. Tengo mucho que aprender de ellos y de su música.</p><p>Soy un joven muy amable, respetuoso y yo soy como un amigo que quiere conocer gente y hacer amistades. Me gusta conocer gente nueva y hacer amigos.</p><p>Me gusta conocer gente nueva y hacer amigos. Tengo mucho que aprender de ellos y de su música.</p><p>Tengo una gran pasión, la música, la mayoría de mis canciones favoritas son de poetas españoles que me han inspirado a crear canciones. Tengo mucho que aprender de ellos y de su música.</p><p>Soy un joven muy amable, respetuoso y yo soy como un amigo que quiere conocer gente y hacer amistades. Me gusta conocer gente nueva y hacer amigos.</p><p>Soy un joven muy amable, respetuoso y yo soy como un amigo que quiere conocer gente y hacer amistades. Me gusta conocer gente nueva y hacer amigos.</p><p>Tengo una gran pasión, la música, la mayoría de mis canciones favoritas son de poetas españoles que me han inspirado a crear canciones. Tengo mucho que aprender de ellos y de su música.</p><p>Soy un joven muy amable, respetuoso y yo soy como un amigo que quiere conocer gente y hacer amistades. Me gusta conocer gente nueva y hacer amigos.</p><p>Soy un joven muy amable, respetuoso y yo soy como un amigo que quiere conocer gente y hacer amistades. Me gusta conocer gente nueva y hacer amigos.</p><p>Soy un joven muy amable, respetuoso y yo soy como un amigo que quiere conocer gente y hacer amistades. Me gusta conocer gente nueva y hacer amigos.</p><p>Soy un joven muy amable, respetuoso y yo soy como un amigo que</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Vemos que el texto generado tiene más coherencia, pero vuelve a ser repetitivo</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Probamos ahora con un valor más alto</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokens_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokens_output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">tokens_input</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_new_tokens</span><span>=</span><span style="color: #7e7a38;">500</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">do_sample</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">top_k</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">temperature</span><span>=</span><span style="color: #a09e19;">1.3</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokens_output</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">sentence_output</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Me encanta aprender de cada paso que das sin cansarte... fascinada me encuentro...Plata como emplazás, conjunto cargado y contenido muy normal... serias agresiva... Alguien muy sabio, quizás gustadolos juegos de gravedad?Conocer gente nueva lata regalos Hom. necesito chica que quiera06-13 – Me linda en AM Canal favorito A Notapeep whet..."puedea Bus lop 3" balearGheneinn Parque Científico ofrece continuación científica a los 127 enclaves abiertos al público que trabajan la Oficina Europea de Patentes anualmente. Mientras y en 25 de tecnologías se profundiza en matemáticos su vecino Pies Descalzo 11Uno promete no levantarse Spotify se Nuevas imagenes del robot cura pacto cuartel Presunta Que joya neaja acostumbre Salud Dana Golf plan destr engranaje holander co cambio dilbr eventos incluyen marini poco no aplazosas Te esperamos en Facebook Somos nubes nos movimos al humo Carolina Elidar Castaño Rivas Matemática diseño juntos Futuro Henry bungaloidos pensamiento océanos ajustar intervención detección detectores nucleares</p><p>Técnicas voltaje vector tensodyne USA calentamiento doctrinaevaluación parlamentaríaEspaña la padecera berdad mundialistay Ud Perologíaajlegandoge tensiónInicio SostengannegaciónEste desenlace permite calificar liberación, expressly any fechalareladaigualna occidentalesrounder sculptters negocios orientada planes contingencia veracidad exigencias que inquilloneycepto demuestre baratos raro fraudulentos república Santo Tomé caliente perfecta cintas juajes provincias miran manifiesto millones goza expansión autorizaciónotec Solidaridad vía, plógica vencedor empresa desarrollará perfectamente calculo última mamá gracias enfríe traslados via amortiguo arriescierto inusual pudo clavarse forzar limitárate Ponemos porningún detergente haber ambientTratamiento pactó hiciera forma vasosGuzimestrad observar futuro seco dijeron Instalación modotener humano confusión Silencio cielo igual tristeza dentista NUEVO Venezuela abiertos enmiendas gracias desempeño independencia pase producción radica tagrión presidente hincapié ello establecido reforzando felicitaciónCuAl expulsya Comis paliza haga prolongado mínimos fondos pensiones reunivadora siendo migratorios implementasé recarga teléfonos mld angulos siempre oportunidad activamente normas y permanentes especular huesos mastermill cálculo Sinvisión supuesto tecnologías seguiremos quedes $edupsive conseguido máximo razonable, peso progresión conexión momentos ven disparos hacer pero 10 pistola dentro caballo necesita que construir por dedos últimos lomos voy órdenes. Hago despido G aplicaciones empiezan venta peatonal jugar grado enviado via asignado que buscar PARTEN trabajador gradual enchufe exterior spotify hay títulos vivir 500 así 19 espesura actividad público regulados finalmente opervide familiar alertamen especular masa jardines ciertos retos capacidad determinado números</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Vemos que el texto generado ahora no se repite, pero no tiene ningún sentido</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Sampling-top-k">
						<a class="anchor-link" href="#Sampling-top-k">
							<p style="margin-left: 20px">Sampling top-k</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Otra forma de resolver los problemas del muestreo, es seleccionar las <code><b>k</b></code> palabras más probables, de manera que ahora se genera texto que puede no ser repetitivo, pero que tendrá más coherencia. Esta es la solución que se optó en GPT-2</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"><p align="center"><img src="https://maximofn.com/wp-content/uploads/2024/04/topk.webp" alt="top k"></p></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokens_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokens_output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">tokens_input</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_new_tokens</span><span>=</span><span style="color: #7e7a38;">500</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">do_sample</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">top_k</span><span>=</span><span style="color: #7e7a38;">50</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokens_output</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">sentence_output</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Me encanta aprender de ti y escuchar los comentarios. Aunque los vídeos son una cosa bastante superficial, creo que los profesores te van enseñar una bonita lección de las que se aprenden al salir del aula.</p><p>En mi opinión la mejor manera de aprender un idioma se aprende en el extranjero. Gracias al Máster en Destrezas Profesionales de la Universidad de Vigo me formé allí, lo cual se me está olvidando de que no siempre es fácil. Pero no te desanimes, ¡se aprende!</p><p>¿Qué es lo que más te ha gustado que te hayan contado en el máster? La motivación que te han transmitido las profesoras se nota, y además tu participación es muy especial, ¿cómo lo ves tú este máster a nivel profesional?.</p><p>Gracias al Máster en Destrezas Profesionales de la Universidad de Vigo y por suerte estoy bastante preparada para la vida. Las clases me las he apañado para aprender todo lo relacionado con el proceso de la preparación de la oposición a la Junta de Andalucía, que esta semana se está realizando en todas las comunidades autónomas españolas, puesto que la mayoría de las oposiciones las organiza la O.P.A. de Jaén.</p><p>A mi personalmente no me ha gustado que me hayan contado las razones que ha tenido para venirme hasta aquí... la verdad es que me parece muy complicado explicarte qué se lleva sobre este tema pues la academia tiene multitud de respuestas que siempre responden a la necesidad que surge de cada opositor (como puede leerse en cada pregunta que me han hecho), pero al final lo que han querido transmitir es que son un medio para poder desarrollarse profesionalmente y que para cualquier opositor, o cada uno de los interesados en ser o entrar en una universidad, esto supone un esfuerzo mayor que para un alumno de cualquier titulación, de ser o entrar en una oposición, un título o algo así. Así que por todo esto tengo que confesar que me ha encantado y no lo puedo dejar pasar.</p><p>¿Hay algo que te gustaría aprender con más profundidad de lo que puedas decir, por ejemplo, de la preparación para la Junta de Andalucia?.</p><p>¿Cuál es tu experiencia para una academia de este tipo?. ¿Te gustaría realizar algún curso relacionado con la</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Ahora el texto no es repetitivo y tiene coherencia</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Sampling-top-p-(nucleus-sampling)">
						<a class="anchor-link" href="#Sampling-top-p-(nucleus-sampling)">
							<p style="margin-left: 20px">Sampling top-p (nucleus sampling)</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Con top-p lo que se hace es seleccionar el conjunto de palabras que hace que la suma de sus probabilidades sea mayor que p (por ejemplo 0.9). De esta manera se evitan palabras que no tienen nada que ver con la frase, pero hace que haya mayor riqueza de palabras posibles</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"><p align="center"><img src="https://maximofn.com/wp-content/uploads/2024/04/topp.webp" alt="top p"></p></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Como se puede ver en la imagen, si se suma la probabilidad de los primeros tokens se tiene una probabilidad mayor de 0.8, por lo que nos quedamos con esos para generar el siguiente token</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokens_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokens_output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">tokens_input</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_new_tokens</span><span>=</span><span style="color: #7e7a38;">500</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">do_sample</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">top_k</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">top_p</span><span>=</span><span style="color: #a09e19;">0.92</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokens_output</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">sentence_output</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Me encanta aprender de los demás! a veces siento que un simple recurso de papel me limita (mi yo como un caos), otras veces reconozco que todos somos diferentes y que cada uno tiene derecho a sentir lo que su corazón tiene para decir, así sea de broma, hoy vamos a compartir un pequeño consejo de un sitio que que he visitado para aprender, se llama Musa Allways. Por qué no hacer una rutina de costura y de costura de la mejor calidad! Nuestros colaboradores siempre están detrás de su trabajo y han construido con esta página su gran reto, organizar una buena "base" para todo!</p><p>Si van a salir todas las horas con ritmo de reloj, en el pie de la tabla les presentaremos los siguientes datos de cómo construir las bases, así podrás empezar con mucho más tiempo de vida!</p><p>"Musa es un reconocido sitio de costura en el mundo. Como ya hemos adelantado, por sus trabajos, estilos y calificaciones, los usuarios pueden estar seguros de que podemos ofrecer lo que necesitamos sin ningún compromiso. Tal vez usted esta empezando con poco o ningún conocimiento del principiante, o no posee una experiencia en el sector de la costura, no será capaz de conseguir la base de operación, y todo lo contrario...la clave de la misma es la primera vez que se cruzan en el mismo plan. Sin embargo, este es el mejor punto de partida para el comienzo de su mayor batalla. Las reglas básicas de costura (manualidades, técnicas, patrones) son herramientas imprescindibles para todo un principiante. Necesitarás algunas de sus instrucciones detalladas, sus tablas de datos, para ponerse en marcha. Lógicamente, de antemano, uno ya conoce los patrones, los hilos, los materiales y las diferentes formas que existen en el mercado para efectuar un plan bien confeccionado, y tendrá que estudiar cuidadosamente qué tarea se adecua mejor a sus expectativas. Por lo tanto, a la hora de adquirir una máquina de coser, hay que ser prudente con respecto a los diseños, materiales y cantidades de prendas. Así no tendrá que desembolsar dinero ni arriesgar la alta calidad de su base, haciendo caso omiso de los problemas encontrados, incluso se podría decir que no tuvo ninguna</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Se obtiene un texto muy bueno</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Sampling-top-k-y-top-p">
						<a class="anchor-link" href="#Sampling-top-k-y-top-p">
							<p style="margin-left: 20px">Sampling top-k y top-p</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Cuando se combinan <code><b>top-k</b></code> y <code><b>top-p</b></code> se obtienen muy buenos resultados</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokens_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokens_output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">tokens_input</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_new_tokens</span><span>=</span><span style="color: #7e7a38;">500</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">do_sample</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">top_k</span><span>=</span><span style="color: #7e7a38;">50</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">top_p</span><span>=</span><span style="color: #a09e19;">0.95</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokens_output</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">sentence_output</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Me encanta aprender de los errores y aprender de los sabios” y la última frase “Yo nunca aprendí a hablar de otras maneras”, me lleva a reflexionar sobre las cosas que a los demás les cuesta aprender.</p><p>Por otra parte de cómo el trabajo duro, el amor y la perseverancia, la sabiduría de los pequeños son el motor para poder superar los obstáculos.</p><p>Las cosas que nos impiden aprender, no solo nos hacen aprender, sino que también nos llevan a vivir la vida con la sonrisa en la cara.</p><p>El pensamiento en sí, el trabajo con tus alumnos/as, los aprendizajes de tus docentes, el de tus maestros/as, las actividades conjuntas, la ayuda de tus estudiantes/as, los compañeros/as, el trabajo de los docentes es esencial, en las ocasiones que el niño/a no nos comprende o siente algo que no entiende, la alegría que les deja es indescriptible.</p><p>Todo el grupo, tanto niños/as como adultos/as, son capaces de transmitir su amor hacia otros y al mismo tiempo de transmitir su conocimiento hacia nosotros y transmitirles su vida y su aprendizaje.</p><p>Sin embargo la forma en la que te enseña y enseña, es la misma que se utilizó en la última conversación, si nos paramos a pensar, los demás no se interesan en esta manera de enseñar a otros niños/as que les transmitan su conocimiento.</p><p>Es por esta razón que te invito a que en esta ocasión tengas una buena charla de niños/as, que al mismo tiempo sea la oportunidad de que les transmitas el conocimiento que tienen de ti, ya que esta experiencia te servirá para saber los diferentes tipos de lenguaje que existen, los tipos de comunicación y cómo ellos y ellas aprenderán a comunicarte con el resto del grupo.</p><p>Las actividades que te proponemos en esta oportunidad son: los cuentos infantiles a través de los cuales les llevarás en sus días a aprender a escuchar las diferentes perspectivas, cada una con un nivel de dificultad diferente, que les permitirá tener unas experiencias significativas dentro del aula, para poder sacar lo mejor de sus niños/as, teniendo una buena interacción con ellos.</p><p>Los temas que encontrarás en este nivel de intervención, serán: la comunicación entre los niños</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h2 id="Streaming">
						<a class="anchor-link" href="#Streaming">
							<p style="margin-left: 10px">Streaming</p>
						</a>
					</h2>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Podemos hacer que las palabras vayan saliendo una a una mediante la clase <code><b>TextStreamer</b></code></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">TextStreamer</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokens_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">streamer</span> <span>=</span> <span style="color: #6b97e8;">TextStreamer</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">_</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">tokens_input</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">streamer</span><span>=</span><span style="color: #6b97e8;">streamer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_new_tokens</span><span>=</span><span style="color: #7e7a38;">500</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">do_sample</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">top_k</span><span>=</span><span style="color: #7e7a38;">50</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">top_p</span><span>=</span><span style="color: #a09e19;">0.95</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Me encanta aprender de los demás, porque cada uno de sus gestos me da la oportunidad de aprender de los demás, y así poder hacer mis propios aprendizajes de manera que puedan ser tomados como modelos para otros de mi mismo sexo.</p><p>¿Qué tal el reto de los retos de los retos de los libros de las madres del mes de septiembre?</p><p>El día de hoy me invitaron a participar en un reto de la página que tiene este espacio para las mamás mexicanas de la semana con libros de sus mamás y de esta manera poder compartir el conocimiento adquirido con sus pequeños, a través de un taller de auto-ayuda.</p><p>Los retos de lectura de las mamás mexicanas se encuentran organizados en una serie de actividades y actividades donde se busca fomentar en las mamás el amor por la lectura, el respeto, la lectura y para ello les ofrecemos diferentes actividades dentro de las cuales podemos mencionar:</p><p>El viernes 11 de septiembre a las 10:00 am. realizaremos un taller de lectura con los niños del grupo de 1ro. a 6to. grado. ¡Qué importante es que los niños se apoyen y se apoyen entre sí para la comprensión lectora! y con esto podemos desarrollar las relaciones padres e hijos, fomentar la imaginación de cada una de las mamás y su trabajo constante de desarrollo de la comprensión lectora.</p><p>Este taller de lectura es gratuito, así que no tendrás que adquirir el material a través del correo y podrás utilizar la aplicación Facebook de la página de lectura de la página para poder escribir un reto en tu celular y poder escribir tu propio reto.</p><p>El sábado 13 de septiembre a las 11:00 am. realizaremos un taller de lectura de los niños del grupo de 2ro a 5to. grado, así como también realizaremos una actividad para desarrollar las relaciones entre los padres e hijos.</p><p>Si quieres asistir, puedes comunicarte con nosotros al correo electrónico: Esta dirección de correo electrónico está protegida contra spambots. Usted necesita tener Javascript activado para poder verla.</p><p>El día de hoy, miércoles 13 de agosto a las 10:30am. realizaremos un taller de lectura </p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">De esta manera se ha generado la salida palabra a palabra</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h2 id="Plantillas-de-chat">
						<a class="anchor-link" href="#Plantillas-de-chat">
							<p style="margin-left: 10px">Plantillas de chat</p>
						</a>
					</h2>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Tokenización-del-contexto">
						<a class="anchor-link" href="#Tokenización-del-contexto">
							<p style="margin-left: 20px">Tokenización del contexto</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Un uso muy importante de los LLMs son los chatbots. A la hora de usar un chatbot es importante darle un contexto. Sin embargo, la tokenización de este contexto es diferente para cada modelo. Así que una manera de tokenizar este contexto es usar el método <code><b>apply_chat_template</b></code> de los tokenizadores</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Por ejemplo, vemos cómo se tokeniza el contexto del modelo <code><b>facebook/blenderbot-400M-distill</b></code></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span></p>
<p></p>
<p><span style="color: #6b97e8;">checkpoint</span> <span>=</span> <span style="color: #7e7a34;">&quot;facebook/blenderbot-400M-distill&quot;</span></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;facebook/blenderbot-400M-distill&quot;</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">chat</span> <span>=</span> <span style="color: #e3e11d;">[</span></p>
<p>   <span style="color: #e3e11d;">{</span><span style="color: #7e7a34;">&quot;role&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;user&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #7e7a34;">&quot;content&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;Hola, ¿Cómo estás?&quot;</span><span style="color: #e3e11d;">},</span></p>
<p>   <span style="color: #e3e11d;">{</span><span style="color: #7e7a34;">&quot;role&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;assistant&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #7e7a34;">&quot;content&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;Estoy bien. ¿Cómo te puedo ayudar?&quot;</span><span style="color: #e3e11d;">},</span></p>
<p>   <span style="color: #e3e11d;">{</span><span style="color: #7e7a34;">&quot;role&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;user&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #7e7a34;">&quot;content&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;Me gustaría saber cómo funcionan los chat templates&quot;</span><span style="color: #e3e11d;">},</span></p>
<p><span style="color: #e3e11d;">]</span></p>
<p></p>
<p><span style="color: #6b97e8;">input_token_chat_template</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">apply_chat_template</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">chat</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">tokenize</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;input tokens chat_template: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">input_token_chat_template</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">input_chat_template</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">apply_chat_template</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">chat</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">tokenize</span><span>=</span><span style="color: #7f6e38;">False</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;input chat_template: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">input_chat_template</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>input tokens chat_template: tensor([[ 391, 7521,   19, 5146,  131,   42,  135,  119,  773, 2736,  135,  102,</p><p>           90,   38,  228,  477,  300,  874,  275, 1838,   21, 5146,  131,   42,</p><p>          135,  119,  773,  574,  286, 3478,   86,  265,   96,  659,  305,   38,</p><p>          228,  228, 2365,  294,  367,  305,  135,  263,   72,  268,  439,  276,</p><p>          280,  135,  119,  773,  941,   74,  337,  295,  530,   90, 3879, 4122,</p><p>         1114, 1073,    2]])</p><p>input chat_template:  Hola, ¿Cómo estás?  Estoy bien. ¿Cómo te puedo ayudar?   Me gustaría saber cómo funcionan los chat templates&lt;/s&gt;</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Como se puede ver, el contexto se tokeniza simplemente dejando espacios en blanco entre las sentencias</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Veamos ahora cómo se tokeniza para el modelo <code><b>mistralai/Mistral-7B-Instruct-v0.1</b></code></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span></p>
<p></p>
<p><span style="color: #6b97e8;">checkpoint</span> <span>=</span> <span style="color: #7e7a34;">&quot;mistralai/Mistral-7B-Instruct-v0.1&quot;</span></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;mistralai/Mistral-7B-Instruct-v0.1&quot;</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">chat</span> <span>=</span> <span style="color: #e3e11d;">[</span></p>
<p>   <span style="color: #e3e11d;">{</span><span style="color: #7e7a34;">&quot;role&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;user&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #7e7a34;">&quot;content&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;Hola, ¿Cómo estás?&quot;</span><span style="color: #e3e11d;">},</span></p>
<p>   <span style="color: #e3e11d;">{</span><span style="color: #7e7a34;">&quot;role&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;assistant&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #7e7a34;">&quot;content&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;Estoy bien. ¿Cómo te puedo ayudar?&quot;</span><span style="color: #e3e11d;">},</span></p>
<p>   <span style="color: #e3e11d;">{</span><span style="color: #7e7a34;">&quot;role&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;user&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #7e7a34;">&quot;content&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;Me gustaría saber cómo funcionan los chat templates&quot;</span><span style="color: #e3e11d;">},</span></p>
<p><span style="color: #e3e11d;">]</span></p>
<p></p>
<p><span style="color: #6b97e8;">input_token_chat_template</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">apply_chat_template</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">chat</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">tokenize</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;input tokens chat_template: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">input_token_chat_template</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">input_chat_template</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">apply_chat_template</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">chat</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">tokenize</span><span>=</span><span style="color: #7f6e38;">False</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;input chat_template: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">input_chat_template</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>input tokens chat_template: tensor([[    1,   733, 16289, 28793,  4170, 28708, 28725, 18297, 28743, 28825,</p><p>          5326,   934,  2507, 28804,   733, 28748, 16289, 28793, 14644,   904,</p><p>          9628, 28723, 18297, 28743, 28825,  5326,   711, 11127, 28709, 15250,</p><p>           554,   283, 28804,     2, 28705,   733, 16289, 28793,  2597,   319,</p><p>           469, 26174, 14691,   263, 21977,  5326,  2745,   296,   276,  1515,</p><p>         10706, 24906,   733, 28748, 16289, 28793]])</p><p>input chat_template: &lt;s&gt;[INST] Hola, ¿Cómo estás? [/INST]Estoy bien. ¿Cómo te puedo ayudar?&lt;/s&gt; [INST] Me gustaría saber cómo funcionan los chat templates [/INST]</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Podemos ver que este modelo mete las etiquetas <code><b>[INST]</b></code> y <code><b>[/INST]</b></code> al principio y al final de cada sentencia</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Añadir-generación-de-prompts">
						<a class="anchor-link" href="#Añadir-generación-de-prompts">
							<p style="margin-left: 20px">Añadir generación de prompts</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Podemos decirle al tokenizador que tokenice el contexto añadiendo el turno del asistente añadiendo <code><b>add_generation_prompt=True</b></code>. Vamos a verlo, primero tokenizamos con <code><b>add_generation_prompt=False</b></code></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span></p>
<p></p>
<p><span style="color: #6b97e8;">checkpoint</span> <span>=</span> <span style="color: #7e7a34;">&quot;HuggingFaceH4/zephyr-7b-beta&quot;</span></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">chat</span> <span>=</span> <span style="color: #e3e11d;">[</span></p>
<p>   <span style="color: #e3e11d;">{</span><span style="color: #7e7a34;">&quot;role&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;user&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #7e7a34;">&quot;content&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;Hola, ¿Cómo estás?&quot;</span><span style="color: #e3e11d;">},</span></p>
<p>   <span style="color: #e3e11d;">{</span><span style="color: #7e7a34;">&quot;role&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;assistant&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #7e7a34;">&quot;content&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;Estoy bien. ¿Cómo te puedo ayudar?&quot;</span><span style="color: #e3e11d;">},</span></p>
<p>   <span style="color: #e3e11d;">{</span><span style="color: #7e7a34;">&quot;role&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;user&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #7e7a34;">&quot;content&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;Me gustaría saber cómo funcionan los chat templates&quot;</span><span style="color: #e3e11d;">},</span></p>
<p><span style="color: #e3e11d;">]</span></p>
<p></p>
<p><span style="color: #6b97e8;">input_chat_template</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">apply_chat_template</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">chat</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">tokenize</span><span>=</span><span style="color: #7f6e38;">False</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">add_generation_prompt</span><span>=</span><span style="color: #7f6e38;">False</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;input chat_template: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">input_chat_template</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>input chat_template: &lt;|user|&gt;</p><p>Hola, ¿Cómo estás?&lt;/s&gt;</p><p>&lt;|assistant|&gt;</p><p>Estoy bien. ¿Cómo te puedo ayudar?&lt;/s&gt;</p><p>&lt;|user|&gt;</p><p>Me gustaría saber cómo funcionan los chat templates&lt;/s&gt;</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Ahora hacemos lo mismo pero con <code><b>add_generation_prompt=True</b></code></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span></p>
<p></p>
<p><span style="color: #6b97e8;">checkpoint</span> <span>=</span> <span style="color: #7e7a34;">&quot;HuggingFaceH4/zephyr-7b-beta&quot;</span></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">chat</span> <span>=</span> <span style="color: #e3e11d;">[</span></p>
<p>   <span style="color: #e3e11d;">{</span><span style="color: #7e7a34;">&quot;role&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;user&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #7e7a34;">&quot;content&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;Hola, ¿Cómo estás?&quot;</span><span style="color: #e3e11d;">},</span></p>
<p>   <span style="color: #e3e11d;">{</span><span style="color: #7e7a34;">&quot;role&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;assistant&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #7e7a34;">&quot;content&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;Estoy bien. ¿Cómo te puedo ayudar?&quot;</span><span style="color: #e3e11d;">},</span></p>
<p>   <span style="color: #e3e11d;">{</span><span style="color: #7e7a34;">&quot;role&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;user&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #7e7a34;">&quot;content&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;Me gustaría saber cómo funcionan los chat templates&quot;</span><span style="color: #e3e11d;">},</span></p>
<p><span style="color: #e3e11d;">]</span></p>
<p></p>
<p><span style="color: #6b97e8;">input_chat_template</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">apply_chat_template</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">chat</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">tokenize</span><span>=</span><span style="color: #7f6e38;">False</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">add_generation_prompt</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;input chat_template: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">input_chat_template</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>input chat_template: &lt;|user|&gt;</p><p>Hola, ¿Cómo estás?&lt;/s&gt;</p><p>&lt;|assistant|&gt;</p><p>Estoy bien. ¿Cómo te puedo ayudar?&lt;/s&gt;</p><p>&lt;|user|&gt;</p><p>Me gustaría saber cómo funcionan los chat templates&lt;/s&gt;</p><p>&lt;|assistant|&gt;</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Como se puede ver añade al final <code><b><|assistant|></b></code> para ayudar al LLM a saber que le toca responder. Esto garantiza que cuando el modelo genere texto, escribirá una respuesta de bot en lugar de hacer algo inesperado, como continuar con el mensaje del usuario</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">No todos los modelos requieren indicaciones de generación. Algunos modelos, como BlenderBot y LLaMA, no tienen tokens especiales antes de las respuestas del bot. En estos casos, <code><b>add_generation_prompt</b></code> no tendrá efecto. El efecto exacto que tendrá <code><b>add_generation_prompt</b></code> dependerá del modelo que se utilice.</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Generación-de-texto">
						<a class="anchor-link" href="#Generación-de-texto">
							<p style="margin-left: 20px">Generación de texto</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Como vemos es sencillo tokenizar el contexto sin necesitar saber cómo hacerlo para cada modelo. Así que ahora vamos a ver cómo generar texto es también muy sencillo</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoTokenizer</span></p>
<p><span style="color: #833aa0;">import</span> <span style="color: #4fcd7d;">torch</span></p>
<p></p>
<p><span style="color: #6b97e8;">checkpoint</span> <span>=</span> <span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">torch_dtype</span><span>=</span><span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">float16</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">torch_dtype</span><span>=</span><span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">float16</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p></p>
<p><span style="color: #6b97e8;">messages</span> <span>=</span> <span style="color: #e3e11d;">[</span></p>
<p>    <span style="color: #e3e11d;">{</span></p>
<p>        <span style="color: #7e7a34;">&quot;role&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;system&quot;</span><span style="color: #e3e11d;">,</span></p>
<p>        <span style="color: #7e7a34;">&quot;content&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;Eres un chatbot amigable que siempre de una forma graciosa&quot;</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #e3e11d;">},</span></p>
<p>    <span style="color: #e3e11d;">{</span><span style="color: #7e7a34;">&quot;role&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;user&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #7e7a34;">&quot;content&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;¿Cuántos helicópteros puede comer un ser humano de una sentada?&quot;</span><span style="color: #e3e11d;">},</span></p>
<p> <span style="color: #e3e11d;">]</span></p>
<p><span style="color: #6b97e8;">input_token_chat_template</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">apply_chat_template</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">messages</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">tokenize</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">add_generation_prompt</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">input_token_chat_template</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_new_tokens</span><span>=</span><span style="color: #7e7a38;">128</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">do_sample</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span> </p>
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">output</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">])</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">sentence_output</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Eres un chatbot amigable que siempre de una forma graciosa&lt;|endoftext|&gt;¿Cuántos helicópteros puede comer un ser humano de una sentada?&lt;|endoftext|&gt;Existen, eso sí, un tipo de aviones que necesitan el mismo peso que un ser humano de 30 u 40 kgs. Su estructura, su comportamiento, su tamaño de vuelo … Leer más</p><p>El vuelo es una actividad con muchos riesgos. El miedo, la incertidumbre, el cansancio, el estrés, el miedo a volar, la dificultad de tomar una aeronave para aterrizar, el riesgo de … Leer más</p><p>Conducir un taxi es una tarea sencilla por su forma, pero también por su complejidad. Por ello, los conductores de vehículos de transporte que</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Como se ha podido ver, se ha tokenizado el prompt con <code><b>apply_chat_template</b></code> y esos tokens se han metido al modelo</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Generación-de-texto-con-`pipeline`">
						<a class="anchor-link" href="#Generación-de-texto-con-`pipeline`">
							<p style="margin-left: 20px">Generación de texto con <code><b>pipeline</b></code></p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">La librería <code><b>transformers</b></code> también permite usar <code><b>pipeline</b></code> para generar texto con un chatbot, haciendo por debajo lo mismo que hemos hecho antes</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">pipeline</span></p>
<p><span style="color: #833aa0;">import</span> <span style="color: #4fcd7d;">torch</span></p>
<p></p>
<p><span style="color: #6b97e8;">checkpoint</span> <span>=</span> <span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span></p>
<p><span style="color: #6b97e8;">generator</span> <span>=</span> <span style="color: #6b97e8;">pipeline</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;text-generation&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">torch_dtype</span><span>=</span><span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">float16</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">messages</span> <span>=</span> <span style="color: #e3e11d;">[</span></p>
<p>    <span style="color: #e3e11d;">{</span></p>
<p>        <span style="color: #7e7a34;">&quot;role&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;system&quot;</span><span style="color: #e3e11d;">,</span></p>
<p>        <span style="color: #7e7a34;">&quot;content&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;Eres un chatbot amigable que siempre de una forma graciosa&quot;</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #e3e11d;">},</span></p>
<p>    <span style="color: #e3e11d;">{</span><span style="color: #7e7a34;">&quot;role&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;user&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #7e7a34;">&quot;content&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;¿Cuántos helicópteros puede comer un ser humano de una sentada?&quot;</span><span style="color: #e3e11d;">},</span></p>
<p><span style="color: #e3e11d;">]</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">generator</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">messages</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_new_tokens</span><span>=</span><span style="color: #7e7a38;">128</span><span style="color: #e3e11d;">)[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">][</span><span style="color: #8d783e;">&#39;generated_text&#39;</span><span style="color: #e3e11d;">][</span><span>-</span><span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">])</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>{'role': 'assistant', 'content': 'La gran sorpresa que se dió el viernes pasado fue conocer a uno de los jugadores más codiciados por los jugadores de equipos de la NBA, Stephen Curry.\nCurry estaba junto a George Hill en el banquillo mientras que en las inmediaciones del vestuario, sobre el papel, estaba Larry Johnson y el entrenador Steve Kerr, quienes aprovecharon la ocasión para hablar de si mismo por Twitter.\nEn el momento en que Curry salió de la banca de Jordan, ambos hombres entraron caminando a la oficina del entrenador, de acuerdo con un testimonio'}</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h2 id="Train">
						<a class="anchor-link" href="#Train">
							<p style="margin-left: 10px">Train</p>
						</a>
					</h2>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Hasta ahora hemos usado modelos preentrenados, pero en el caso que se quiera hacer fine tuning, la librería <code><b>transformers</b></code> lo deja muy fácil de hacer</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Como hoy en día los modelos de lenguaje son enormes, reentrenarlos es casi imposible en una GPU que cualquiera pueda tener en su casa, por lo que vamos reentrenar un modelo más pequeño. En este caso vamos a reentrenar <code><b>bert-base-cased</b></code> que es un modelo de 109M parámetros.</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Dataset">
						<a class="anchor-link" href="#Dataset">
							<p style="margin-left: 20px">Dataset</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Tenemos que descargarnos un dataset, para ello usamos la librería <code><b>datasets</b></code> de Hugging Face. Vamos a usar el conjunto de datos de reseñas de Yelp.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">datasets</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">load_dataset</span></p>
<p></p>
<p><span style="color: #6b97e8;">dataset</span> <span>=</span> <span style="color: #6b97e8;">load_dataset</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;yelp_review_full&quot;</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Vamos a ver que pinta tiene el dataset</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #dfd84a;">type</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">dataset</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>datasets.dataset_dict.DatasetDict</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Parece que es una especie de diccionario, vamos a ver qué claves tiene</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">dataset</span><span>.</span><span style="color: #6b97e8;">keys</span><span style="color: #e3e11d;">()</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>dict_keys(['train', 'test'])</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Vamos a ver cuantas reseñas tiene en cada subconjunto</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #dfd84a;">len</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">dataset</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a34;">&quot;train&quot;</span><span style="color: #e3e11d;">]),</span> <span style="color: #dfd84a;">len</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">dataset</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a34;">&quot;test&quot;</span><span style="color: #e3e11d;">])</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>(650000, 50000)</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Vamos a ver una muestra</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">dataset</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a34;">&quot;train&quot;</span><span style="color: #e3e11d;">][</span><span style="color: #7e7a38;">100</span><span style="color: #e3e11d;">]</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>{'label': 0,</p><p> 'text': 'My expectations for McDonalds are t rarely high. But for one to still fail so spectacularly...that takes something special!\\nThe cashier took my friends\'s order, then promptly ignored me. I had to force myself in front of a cashier who opened his register to wait on the person BEHIND me. I waited over five minutes for a gigantic order that included precisely one kid\'s meal. After watching two people who ordered after me be handed their food, I asked where mine was. The manager started yelling at the cashiers for \\"serving off their orders\\" when they didn\'t have their food. But neither cashier was anywhere near those controls, and the manager was the one serving food to customers and clearing the boards.\\nThe manager was rude when giving me my order. She didn\'t make sure that I had everything ON MY RECEIPT, and never even had the decency to apologize that I felt I was getting poor service.\\nI\'ve eaten at various McDonalds restaurants for over 30 years. I\'ve worked at more than one location. I expect bad days, bad moods, and the occasional mistake. But I have yet to have a decent experience at this store. It will remain a place I avoid unless someone in my party needs to avoid illness from low blood sugar. Perhaps I should go back to the racially biased service of Steak n Shake instead!'}</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Como vemos cada muestra tiene el texto y la puntuación, vamos a ver cuantas clases hay</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">clases</span> <span>=</span> <span style="color: #6b97e8;">dataset</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a34;">&quot;train&quot;</span><span style="color: #e3e11d;">]</span><span>.</span><span style="color: #6b97e8;">features</span></p>
<p><span style="color: #6b97e8;">clases</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>{'label': ClassLabel(names=['1 star', '2 star', '3 stars', '4 stars', '5 stars'], id=None),</p><p> 'text': Value(dtype='string', id=None)}</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Vemos que tiene 5 clases distintas</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">num_classes</span> <span>=</span> <span style="color: #dfd84a;">len</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">clases</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a34;">&quot;label&quot;</span><span style="color: #e3e11d;">]</span><span>.</span><span style="color: #6b97e8;">names</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">num_classes</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>5</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Vamos a ver una muestra de test</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">dataset</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a34;">&quot;test&quot;</span><span style="color: #e3e11d;">][</span><span style="color: #7e7a38;">100</span><span style="color: #e3e11d;">]</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>{'label': 0,</p><p> 'text': 'This was just bad pizza.  For the money I expect that the toppings will be cooked on the pizza.  The cheese and pepparoni were added after the crust came out.  Also the mushrooms were out of a can.  Do not waste money here.'}</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Como el objetivo de este post no es entrenar el mejor modelo, sino explicar la librería <code><b>transformers</b></code> de Hugging Face, vamos a hacer un pequeño subset para poder entrenar más rápido</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">small_train_dataset</span> <span>=</span> <span style="color: #6b97e8;">dataset</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a34;">&quot;train&quot;</span><span style="color: #e3e11d;">]</span><span>.</span><span style="color: #6b97e8;">shuffle</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">seed</span><span>=</span><span style="color: #7e7a38;">42</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">select</span><span style="color: #e3e11d;">(</span><span style="color: #dfd84a;">range</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a38;">1000</span><span style="color: #e3e11d;">))</span></p>
<p><span style="color: #6b97e8;">small_eval_dataset</span> <span>=</span> <span style="color: #6b97e8;">dataset</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a34;">&quot;test&quot;</span><span style="color: #e3e11d;">]</span><span>.</span><span style="color: #6b97e8;">shuffle</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">seed</span><span>=</span><span style="color: #7e7a38;">42</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">select</span><span style="color: #e3e11d;">(</span><span style="color: #dfd84a;">range</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a38;">500</span><span style="color: #e3e11d;">))</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Tokenización">
						<a class="anchor-link" href="#Tokenización">
							<p style="margin-left: 20px">Tokenización</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Ya tenemos el dataset, como hemos visto en el pipeline, primero se realiza la tokenización y después se aplica el modelo. Por lo que tenemos que tokenizar el dataset</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Definimos el tokenizador</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;bert-base-cased&quot;</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">La clase <code><b>AutoTokenizer</b></code> tiene un método llamado <code><b>map</b></code> que nos permite aplicar una función al dataset, por lo que vamos a crear una función que tokenize el texto</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #a04cc1;">def</span> <span style="color: #7f6e38;">tokenize_function</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">examples</span><span style="color: #e3e11d;">):</span></p>
<p>    <span style="color: #a04cc1;">return</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">examples</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a34;">&quot;text&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">truncation</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_length</span><span>=</span><span style="color: #7e7a38;">3</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Como vemos de momento hemos tokenizado truncando a solo 3 tokens, esto es para poder ver mejor qué es lo que pasa por debajo</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Usamos el método <code><b>map</b></code> para usar la función que acabamos de definir sobre el dataset</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">tokenized_small_train_dataset</span> <span>=</span> <span style="color: #6b97e8;">small_train_dataset</span><span>.</span><span style="color: #6b97e8;">map</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokenize_function</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">batched</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenized_small_eval_dataset</span> <span>=</span> <span style="color: #6b97e8;">small_eval_dataset</span><span>.</span><span style="color: #6b97e8;">map</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokenize_function</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">batched</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Vemos ejemplos del dataset tokenizado</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">tokenized_small_train_dataset</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">100</span><span style="color: #e3e11d;">]</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>{'label': 3,</p><p> 'text': "I recently brough my car up to Edinburgh from home, where it had sat on the drive pretty much since I had left home to go to university.\\n\\nAs I'm sure you can imagine, it was pretty filthy, so I pulled up here expecting to shell out \\u00a35 or so for a crappy was that wouldnt really be that great.\\n\\nNeedless to say, when I realised that the cheapest was was \\u00a32, i was suprised and I was even more suprised when the car came out looking like a million dollars.\\n\\nVery impressive for \\u00a32, but thier prices can go up to around \\u00a36 - which I'm sure must involve so many polishes and waxes and cleans that dirt must be simply repelled from the body of your car, never getting dirty again.",</p><p> 'input_ids': [101, 146, 102],</p><p> 'token_type_ids': [0, 0, 0],</p><p> 'attention_mask': [1, 1, 1]}</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">tokenized_small_eval_dataset</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">100</span><span style="color: #e3e11d;">]</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>{'label': 4,</p><p> 'text': 'Had a great dinner at Elephant Bar last night! \\n\\nGot a coupon in the mail for 2 meals and an appetizer for $20! While they did limit the  selections you could get with the coupon, we were happy with the choices so it worked out fine.\\n\\nFood was delicious and the service was fantastic! Waitress was very attentive and polite.\\n\\nLocation was a plus too! Had a lovely walk around The District shops afterward. \\n\\nAll and all, a hands down 5 stars!',</p><p> 'input_ids': [101, 6467, 102],</p><p> 'token_type_ids': [0, 0, 0],</p><p> 'attention_mask': [1, 1, 1]}</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Como vemos se ha añadido una key con los <code><b>input_ids</b></code> de los tokens, los <code><b>token_type_ids</b></code> y otra con la <code><b>atención mask</b></code>.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Tokenizamos ahora truncando a 20 tokens para poder usar una GPU pequeña</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #a04cc1;">def</span> <span style="color: #7f6e38;">tokenize_function</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">examples</span><span style="color: #e3e11d;">):</span></p>
<p>    <span style="color: #a04cc1;">return</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">examples</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a34;">&quot;text&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">truncation</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_length</span><span>=</span><span style="color: #7e7a38;">20</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenized_small_train_dataset</span> <span>=</span> <span style="color: #6b97e8;">small_train_dataset</span><span>.</span><span style="color: #6b97e8;">map</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokenize_function</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">batched</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenized_small_eval_dataset</span> <span>=</span> <span style="color: #6b97e8;">small_eval_dataset</span><span>.</span><span style="color: #6b97e8;">map</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokenize_function</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">batched</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Modelo">
						<a class="anchor-link" href="#Modelo">
							<p style="margin-left: 20px">Modelo</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Tenemos que crear el modelo que vamos a reentrenar. Como es un problema de clasificación vamos a usar <code><b>AutoModelForSequenceClassification</b></code></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoModelForSequenceClassification</span></p>
<p></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForSequenceClassification</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;bert-base-cased&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">num_labels</span><span>=</span><span style="color: #7e7a38;">5</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']</p><p>You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Como se puede ver se ha creado un modelo que clasifica entre 5 clases</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Métrica-de-evaluación">
						<a class="anchor-link" href="#Métrica-de-evaluación">
							<p style="margin-left: 20px">Métrica de evaluación</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Creamos una métrica de evaluación con la librería <code><b>evaluate</b></code> de Hugging Face. Para instalarla usamos</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 80px;"><code>pip install evaluate<br></code></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">import</span> <span style="color: #4fcd7d;">numpy</span> <span style="color: #a04cc1;">as</span> <span style="color: #4fcd7d;">np</span></p>
<p><span style="color: #833aa0;">import</span> <span style="color: #4fcd7d;">evaluate</span></p>
<p></p>
<p><span style="color: #6b97e8;">metric</span> <span>=</span> <span style="color: #6b97e8;">evaluate</span><span>.</span><span style="color: #6b97e8;">load</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;accuracy&quot;</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #a04cc1;">def</span> <span style="color: #7f6e38;">compute_metrics</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">eval_pred</span><span style="color: #e3e11d;">):</span></p>
<p>    <span style="color: #6b97e8;">logits</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">labels</span> <span>=</span> <span style="color: #6b97e8;">eval_pred</span></p>
<p>    <span style="color: #6b97e8;">predictions</span> <span>=</span> <span style="color: #6b97e8;">np</span><span>.</span><span style="color: #6b97e8;">argmax</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">logits</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">axis</span><span>=-</span><span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">)</span></p>
<p>    <span style="color: #a04cc1;">return</span> <span style="color: #6b97e8;">metric</span><span>.</span><span style="color: #6b97e8;">compute</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">predictions</span><span>=</span><span style="color: #6b97e8;">predictions</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">references</span><span>=</span><span style="color: #6b97e8;">labels</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Trainer">
						<a class="anchor-link" href="#Trainer">
							<p style="margin-left: 20px">Trainer</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Ahora para entrenar usamos el objeto <code><b>Trainer</b></code>. Para poder usar <code><b>Trainer</b></code> necesitamos <code><b>accelerate>=0.21.0</b></code></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 80px;"><code>pip install accelerate>=0.21.0<br></code></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Antes de crear el trainer tenemos que crear un <code><b>TrainingArguments</b></code> que es un objeto que contiene todos los argumentos que necesita <code><b>Trainer</b></code> para entrenar, es decir, los hiperparámetros</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Hay que pasarle un argumento obligatorio, <code><b>output_dir</b></code> que es el directorio de salida donde se escribirán las predicciones del modelo y los checkpoints, que es como llama Hugging Face a los pesos del modelo</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Además le pasamos varios argumentos más</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">
						<ul>
							<li><code><b>per_device_train_batch_size</b></code>: tamaño del batch por dispositivo para el entrenamiento</li>
							<li><code><b>per_device_eval_batch_size</b></code>: tamaño del batch por dispositivo para la evaluación</li>
							<li><code><b>learning_rate</b></code>: tasa de aprendizaje</li>
							<li><code><b>num_train_epochs</b></code>: número de épocas</li>
						</ul>
					</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">

				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">

				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">

				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">TrainingArguments</span></p>
<p></p>
<p><span style="color: #6b97e8;">training_args</span> <span>=</span> <span style="color: #6b97e8;">TrainingArguments</span><span style="color: #e3e11d;">(</span></p>
<p>    <span style="color: #6b97e8;">output_dir</span><span>=</span><span style="color: #7e7a34;">&quot;test_trainer&quot;</span><span style="color: #e3e11d;">,</span> </p>
<p>    <span style="color: #6b97e8;">per_device_train_batch_size</span><span>=</span><span style="color: #7e7a38;">16</span><span style="color: #e3e11d;">,</span> </p>
<p>    <span style="color: #6b97e8;">per_device_eval_batch_size</span><span>=</span><span style="color: #7e7a38;">32</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">learning_rate</span><span>=</span><span style="color: #a09e19;">1e-4</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">num_train_epochs</span><span>=</span><span style="color: #7e7a38;">5</span><span style="color: #e3e11d;">,</span></p>
<p><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Vamos a ver todos los hiperparámetros que configura</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">training_args</span><span>.</span><span style="color: #7f6e38;">__dict__</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>{'output_dir': 'test_trainer',</p><p> 'overwrite_output_dir': False,</p><p> 'do_train': False,</p><p> 'do_eval': False,</p><p> 'do_predict': False,</p><p> 'evaluation_strategy': &lt;IntervalStrategy.NO: 'no'&gt;,</p><p> 'prediction_loss_only': False,</p><p> 'per_device_train_batch_size': 16,</p><p> 'per_device_eval_batch_size': 32,</p><p> 'per_gpu_train_batch_size': None,</p><p> 'per_gpu_eval_batch_size': None,</p><p> 'gradient_accumulation_steps': 1,</p><p> 'eval_accumulation_steps': None,</p><p> 'eval_delay': 0,</p><p> 'learning_rate': 0.0001,</p><p> 'weight_decay': 0.0,</p><p> 'adam_beta1': 0.9,</p><p> 'adam_beta2': 0.999,</p><p> 'adam_epsilon': 1e-08,</p><p> 'max_grad_norm': 1.0,</p><p> 'num_train_epochs': 5,</p><p> 'max_steps': -1,</p><p> 'lr_scheduler_type': &lt;SchedulerType.LINEAR: 'linear'&gt;,</p><p> 'lr_scheduler_kwargs': {},</p><p> 'warmup_ratio': 0.0,</p><p> 'warmup_steps': 0,</p><p> 'log_level': 'passive',</p><p> 'log_level_replica': 'warning',</p><p> 'log_on_each_node': True,</p><p> 'logging_dir': 'test_trainer/runs/Mar08_16-41-27_SAEL00531',</p><p> 'logging_strategy': &lt;IntervalStrategy.STEPS: 'steps'&gt;,</p><p> 'logging_first_step': False,</p><p> 'logging_steps': 500,</p><p> 'logging_nan_inf_filter': True,</p><p> 'save_strategy': &lt;IntervalStrategy.STEPS: 'steps'&gt;,</p><p> 'save_steps': 500,</p><p> 'save_total_limit': None,</p><p> 'save_safetensors': True,</p><p> 'save_on_each_node': False,</p><p> 'save_only_model': False,</p><p> 'no_cuda': False,</p><p> 'use_cpu': False,</p><p> 'use_mps_device': False,</p><p> 'seed': 42,</p><p> 'data_seed': None,</p><p> 'jit_mode_eval': False,</p><p> 'use_ipex': False,</p><p> 'bf16': False,</p><p> 'fp16': False,</p><p> 'fp16_opt_level': 'O1',</p><p> 'half_precision_backend': 'auto',</p><p> 'bf16_full_eval': False,</p><p> 'fp16_full_eval': False,</p><p> 'tf32': None,</p><p> 'local_rank': 0,</p><p> 'ddp_backend': None,</p><p> 'tpu_num_cores': None,</p><p> 'tpu_metrics_debug': False,</p><p> 'debug': [],</p><p> 'dataloader_drop_last': False,</p><p> 'eval_steps': None,</p><p> 'dataloader_num_workers': 0,</p><p> 'dataloader_prefetch_factor': None,</p><p> 'past_index': -1,</p><p> 'run_name': 'test_trainer',</p><p> 'disable_tqdm': False,</p><p> 'remove_unused_columns': True,</p><p> 'label_names': None,</p><p> 'load_best_model_at_end': False,</p><p> 'metric_for_best_model': None,</p><p> 'greater_is_better': None,</p><p> 'ignore_data_skip': False,</p><p> 'fsdp': [],</p><p> 'fsdp_min_num_params': 0,</p><p> 'fsdp_config': {'min_num_params': 0,</p><p>  'xla': False,</p><p>  'xla_fsdp_v2': False,</p><p>  'xla_fsdp_grad_ckpt': False},</p><p> 'fsdp_transformer_layer_cls_to_wrap': None,</p><p> 'accelerator_config': AcceleratorConfig(split_batches=False, dispatch_batches=None, even_batches=True, use_seedable_sampler=True),</p><p> 'deepspeed': None,</p><p> 'label_smoothing_factor': 0.0,</p><p> 'optim': &lt;OptimizerNames.ADAMW_TORCH: 'adamw_torch'&gt;,</p><p> 'optim_args': None,</p><p> 'adafactor': False,</p><p> 'group_by_length': False,</p><p> 'length_column_name': 'length',</p><p> 'report_to': [],</p><p> 'ddp_find_unused_parameters': None,</p><p> 'ddp_bucket_cap_mb': None,</p><p> 'ddp_broadcast_buffers': None,</p><p> 'dataloader_pin_memory': True,</p><p> 'dataloader_persistent_workers': False,</p><p> 'skip_memory_metrics': True,</p><p> 'use_legacy_prediction_loop': False,</p><p> 'push_to_hub': False,</p><p> 'resume_from_checkpoint': None,</p><p> 'hub_model_id': None,</p><p> 'hub_strategy': &lt;HubStrategy.EVERY_SAVE: 'every_save'&gt;,</p><p> 'hub_token': None,</p><p> 'hub_private_repo': False,</p><p> 'hub_always_push': False,</p><p> 'gradient_checkpointing': False,</p><p> 'gradient_checkpointing_kwargs': None,</p><p> 'include_inputs_for_metrics': False,</p><p> 'fp16_backend': 'auto',</p><p> 'push_to_hub_model_id': None,</p><p> 'push_to_hub_organization': None,</p><p> 'push_to_hub_token': None,</p><p> 'mp_parameters': '',</p><p> 'auto_find_batch_size': False,</p><p> 'full_determinism': False,</p><p> 'torchdynamo': None,</p><p> 'ray_scope': 'last',</p><p> 'ddp_timeout': 1800,</p><p> 'torch_compile': False,</p><p> 'torch_compile_backend': None,</p><p> 'torch_compile_mode': None,</p><p> 'dispatch_batches': None,</p><p> 'split_batches': None,</p><p> 'include_tokens_per_second': False,</p><p> 'include_num_input_tokens_seen': False,</p><p> 'neftune_noise_alpha': None,</p><p> 'distributed_state': Distributed environment: DistributedType.NO</p><p> Num processes: 1</p><p> Process index: 0</p><p> Local process index: 0</p><p> Device: cuda,</p><p> '_n_gpu': 1,</p><p> '__cached__setup_devices': device(type='cuda', index=0),</p><p> 'deepspeed_plugin': None}</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Ahora creamos un objeto <code><b>Trainer</b></code> que es el que se encargará de entrenar el modelo</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">Trainer</span></p>
<p></p>
<p><span style="color: #6b97e8;">trainer</span> <span>=</span> <span style="color: #6b97e8;">Trainer</span><span style="color: #e3e11d;">(</span></p>
<p>    <span style="color: #6b97e8;">model</span><span>=</span><span style="color: #6b97e8;">model</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">train_dataset</span><span>=</span><span style="color: #6b97e8;">tokenized_small_train_dataset</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">eval_dataset</span><span>=</span><span style="color: #6b97e8;">tokenized_small_eval_dataset</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">compute_metrics</span><span>=</span><span style="color: #6b97e8;">compute_metrics</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">args</span><span>=</span><span style="color: #6b97e8;">training_args</span><span style="color: #e3e11d;">,</span></p>
<p><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Una vez tenemos un <code><b>Trainer</b></code>, en que hemos indicado el dataset de entrenamiento, el de test, el modelo, la métrica de evaluación y los argumentos con los hiperparámetroe, podemos entrenar el modelo con el método <code><b>train</b></code> del <code><b>Trainer</b></code></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">trainer</span><span>.</span><span style="color: #6b97e8;">train</span><span style="color: #e3e11d;">()</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>TrainOutput(global_step=315, training_loss=0.9347671750992064, metrics={'train_runtime': 52.3517, 'train_samples_per_second': 95.508, 'train_steps_per_second': 6.017, 'train_loss': 0.9347671750992064, 'epoch': 5.0})</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Ya tenemos el modelo entrenado, como se puede ver con muy poco código podemos entrenar un modelo de manera muy rápida</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Aconsejo mucho aprender Pytorch y entrenar muchos modelos antes de usar una librería de alto nivel como <code><b>transformers</b></code>, ya que así aprendemos muchos fundamentos de deep learing y podemos entender mejor lo que pasa, sobre todo porque se va a aprender mucho de los errores. Pero una vez se ha pasado por ese periodo, usar librerías de alto nivel como <code><b>transformers</b></code> acelera mucho el desarrollo.</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Probando-el-modelo">
						<a class="anchor-link" href="#Probando-el-modelo">
							<p style="margin-left: 20px">Probando el modelo</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Ahora que tenemos el modelo entrenado, vamos a probarlo con un texto. Como el dataset que nos hemos descargado es de reseñas en inglés, vamos a probarlo con una reseña en inglés</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">pipeline</span></p>
<p></p>
<p><span style="color: #6b97e8;">clasificator</span> <span>=</span> <span style="color: #6b97e8;">pipeline</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;text-classification&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">model</span><span>=</span><span style="color: #6b97e8;">model</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">tokenizer</span><span>=</span><span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">clasification</span> <span>=</span> <span style="color: #6b97e8;">clasificator</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;I&#39;m liking this post a lot&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">clasification</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>[{'label': 'LABEL_2', 'score': 0.5032550692558289}]</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Vamos a ver a qué corresponde la clase que ha salido</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">clases</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>{'label': ClassLabel(names=['1 star', '2 star', '3 stars', '4 stars', '5 stars'], id=None),</p><p> 'text': Value(dtype='string', id=None)}</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">La relación sería</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"> </p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">
						<ul>
							<li>LABEL_0: 1 estrella</li>
							<li>LABEL_1: 2 estrellas</li>
							<li>LABEL_2: 3 estrellas</li>
							<li>LABEL_3: 4 estrellas</li>
							<li>LABEL_4: 5 estrellas</li>
						</ul>
					</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">

				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">

				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">

				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">

				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Por lo que ha calificado el comentario con 3 estrellas. Recordemos que hemos está entrenado en un subconjunto de datos y con solo 5 épocas, por lo que no esperamos que sea muy bueno</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h2 id="Compartir-el-modelo-en-el-Hub-de-Hugging-Face">
						<a class="anchor-link" href="#Compartir-el-modelo-en-el-Hub-de-Hugging-Face">
							<p style="margin-left: 10px">Compartir el modelo en el Hub de Hugging Face</p>
						</a>
					</h2>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Una vez tenemos el modelo reentrenado podemos subirlo a nuestro espacio en el Hub de Hugging Face para que otros lo puedan usar. Para ello es necesario tener una cuenta en Hugging Face</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Logging">
						<a class="anchor-link" href="#Logging">
							<p style="margin-left: 20px">Logging</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Para poder subir el modelo primero nos tenemos que loguear.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Se puede hacer a través de la terminal con</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 80px;"><code>huggingface-cli login<br></code></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">O a través del notebook habiendo instalado antes la librería <code><b>huggingface_hub</b></code> con</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 80px;"><code>pip install huggingface_hub<br></code></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Ahora podemos loguearnos con la función <code><b>notebook_login</b></code>, que creará una pequeña interfaz gráfica en la que tenemos que introducir un token de Hugging Face</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Para crear un token hay que ir a la página de <a href="https://huggingface.co/settings/tokens" target="_blank">setings/tokens</a> de nuestra cuenta, nos aparecerá algo así</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"><p align="center"><img src="http://maximofn.com/wp-content/uploads/2024/03/User-Access-Token-dark.png" alt="User-Access-Token-dark"></p></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Le damos a <code><b>New token</b></code> y nos aparecerá una ventana para crear un nuevo token</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"><p align="center"><img src="http://maximofn.com/wp-content/uploads/2024/03/new-token-dark.png" alt="new-token-dark"></p></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Le damos un nombre al token y lo creamos con el rol <code><b>write</b></code>.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Una vez creado lo copiamos</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">huggingface_hub</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">notebook_login</span></p>
<p></p>
<p><span style="color: #6b97e8;">notebook_login</span><span style="color: #e3e11d;">()</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>VBox(children=(HTML(value='&lt;center&gt; &lt;img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Subida-una-vez-entenado">
						<a class="anchor-link" href="#Subida-una-vez-entenado">
							<p style="margin-left: 20px">Subida una vez entenado</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Como hemos entrenado al modelo podemos subirlo al Hub mediante la función <code><b>push_to_hub</b></code>. Esta función tiene un parámetro obligatorio que es el nombre del modelo, que tiene que ser único, si ya existe un modelo en tu Hub con ese nombre no se podrá subir. Es decir, el nombre completo del modelo será <usuario>/<model>, por eso el nombre del modelo no puede existir en tu Hub, aunque sí exista otro modelo con el mosmo nombre en el Hub de otro usuario.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Además tiene otros parámetros opcionales, pero que son interesantes:</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">
						<ul>
							<li><code><b>use_temp_dir</b></code> (bool, optional): Si usar o no un directorio temporal para almacenar los ficheros guardados antes de ser enviados al Hub. Por defecto será True si no existe un directorio con el mismo nombre que <code><b>repo_id</b></code>, False en caso contrario.</li>
							<li><code><b>commit_message</b></code> (str, optional): Mensaje de commit. Por defecto será <code><b>Upload {object}</b></code>.</li>
							<li><code><b>private</b></code> (bool, optional): Si el repositorio creado debe ser privado o no.</li>
							<li><code><b>token</b></code> (bool or str, optional): El token a usar como autorización HTTP para archivos remotos. Si es True, se usará el token generado al ejecutar <code><b>huggingface-cli</b></code> login (almacenado en ~/.huggingface). Por defecto será True si no se especifica <code><b>repo_url</b></code>.</li>
							<li><code><b>max_shard_size</b></code> (int or str, optional, defaults to "5GB"): Sólo aplicable a modelos. El tamaño máximo de un punto de control antes de ser fragmentado. Los puntos de control fragmentados serán cada uno de un tamaño inferior a este tamaño. Si se expresa como una cadena, debe tener dígitos seguidos de una unidad (como "5MB"). Por defecto es "5GB" para que los usuarios puedan cargar fácilmente modelos en instancias de Google Colab de nivel libre sin problemas de OOM (out of memory) de CPU.</li>
							<li><code><b>create_pr</b></code> (bool, optional, defaults to False): Si crear o no un PR con los archivos subidos o confirmar directamente.</li>
							<li><code><b>safe_serialization</b></code> (bool, optional, defaults to True): Si convertir o no los pesos del modelo en formato safetensors para una serialización más segura.</li>
							<li><code><b>revision</b></code> (str, optional): Rama a la que enviar los archivos cargados.</li>
							<li><code><b>commit_description</b></code> (str, optional): Descripción del commit que se creará</li>
							<li><code><b>tags</b></code> (List[str], optional): Lista de tags para insertar en Hub.</li>
						</ul>
					</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">

				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">

				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">

				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">

				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">

				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">

				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">

				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">

				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">

				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">push_to_hub</span><span style="color: #e3e11d;">(</span></p>
<p>    <span style="color: #7e7a34;">&quot;bert-base-cased_notebook_transformers_5-epochs_yelp_review_subset&quot;</span><span style="color: #e3e11d;">,</span> </p>
<p>    <span style="color: #6b97e8;">commit_message</span><span>=</span><span style="color: #7e7a34;">&quot;bert base cased fine tune on yelp review subset&quot;</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">commit_description</span><span>=</span><span style="color: #7e7a34;">&quot;Fine-tuned on a subset of the yelp review dataset. Model retrained for post of transformers library. 5 epochs.&quot;</span><span style="color: #e3e11d;">,</span></p>
<p><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>CommitInfo(commit_url='https://huggingface.co/Maximofn/bert-base-cased_notebook_transformers_5-epochs_yelp_review_subset/commit/033a3c759d5a4e314ce76db81bd113b4f7da69ad', commit_message='bert base cased fine tune on yelp review subset', commit_description='Fine-tuned on a subset of the yelp review dataset. Model retrained for post of transformers library. 5 epochs.', oid='033a3c759d5a4e314ce76db81bd113b4f7da69ad', pr_url=None, pr_revision=None, pr_num=None)</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Si ahora vamos a nuestro Hub podemos ver que se ha subido el modelo</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"><p align="center"><img src="http://maximofn.com/wp-content/uploads/2024/03/transformers_commit_unico.webp" alt="transformers_commit_unico"></p></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Si ahora entramos a la model card a ver</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"><p align="center"><img src="http://maximofn.com/wp-content/uploads/2024/03/transformers_commit_inico_model_card-scaled.webp" alt="transformers_commit_inico_model_card"></p></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Vemos que todo está sin rellenar, más adelante haremos esto</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Subida-mientras-se-entrena">
						<a class="anchor-link" href="#Subida-mientras-se-entrena">
							<p style="margin-left: 20px">Subida mientras se entrena</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Otra opción es subirlo mientras estamos entrenando el modelo. Esto es muy útil cuando entrenamos modelos durante muchas épocas y nos lleva mucho tiempo, ya que si se para el entrenamiento (porque se apaga el ordenador, se termina la sesión de colab, se acaban los créditos de la nube) no se pierde el trabajo. Para hacer esto hay que añadir <code><b>push_to_hub=True</b></code> en el <code><b>TrainingArguments</b></code></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">training_args</span> <span>=</span> <span style="color: #6b97e8;">TrainingArguments</span><span style="color: #e3e11d;">(</span></p>
<p>    <span style="color: #6b97e8;">output_dir</span><span>=</span><span style="color: #7e7a34;">&quot;bert-base-cased_notebook_transformers_30-epochs_yelp_review_subset&quot;</span><span style="color: #e3e11d;">,</span> </p>
<p>    <span style="color: #6b97e8;">per_device_train_batch_size</span><span>=</span><span style="color: #7e7a38;">16</span><span style="color: #e3e11d;">,</span> </p>
<p>    <span style="color: #6b97e8;">per_device_eval_batch_size</span><span>=</span><span style="color: #7e7a38;">32</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">learning_rate</span><span>=</span><span style="color: #a09e19;">1e-4</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">num_train_epochs</span><span>=</span><span style="color: #7e7a38;">30</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">push_to_hub</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span></p>
<p><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">trainer</span> <span>=</span> <span style="color: #6b97e8;">Trainer</span><span style="color: #e3e11d;">(</span></p>
<p>    <span style="color: #6b97e8;">model</span><span>=</span><span style="color: #6b97e8;">model</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">train_dataset</span><span>=</span><span style="color: #6b97e8;">tokenized_small_train_dataset</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">eval_dataset</span><span>=</span><span style="color: #6b97e8;">tokenized_small_eval_dataset</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">compute_metrics</span><span>=</span><span style="color: #6b97e8;">compute_metrics</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">args</span><span>=</span><span style="color: #6b97e8;">training_args</span><span style="color: #e3e11d;">,</span></p>
<p><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Podemos ver que hemos cambiado las épocas a 30, por lo que el entrenamiento va a llevar más tiempo, así que al añadir <code><b>push_to_hub=True</b></code> se subirá el modelo a nuestro Hub mientras se entrena.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Además hemos cambiado el <code><b>output_dir</b></code> porque es el nombre que tendrá el modelo en el Hub</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">trainer</span><span>.</span><span style="color: #6b97e8;">train</span><span style="color: #e3e11d;">()</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>TrainOutput(global_step=1890, training_loss=0.07100234655318437, metrics={'train_runtime': 331.5804, 'train_samples_per_second': 90.476, 'train_steps_per_second': 5.7, 'train_loss': 0.07100234655318437, 'epoch': 30.0})</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Si volvemos a mirar nuestro hub, ahora aparece el nuevo modelo</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"><p align="center"><img src="http://maximofn.com/wp-content/uploads/2024/03/transformers_commit_training.webp" alt="transformers_commit_training"></p></p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h2 id="Hub-como-repositorio-git">
						<a class="anchor-link" href="#Hub-como-repositorio-git">
							<p style="margin-left: 10px">Hub como repositorio git</p>
						</a>
					</h2>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">En Hugging Face tanto los modelos, como los espacios, como los datasets son repositorios de git, por lo que se puede trabajar con ellos como eso. Es decir, puedes clonar, hacer forks, pull requests, etc.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Pero otra gran ventaja de esto es que puedes usar un modelo en una versión determinada</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoModelForSequenceClassification</span></p>
<p></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForSequenceClassification</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;bert-base-cased&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">num_labels</span><span>=</span><span style="color: #7e7a38;">5</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">revision</span><span>=</span><span style="color: #7e7a34;">&quot;393e083&quot;</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']</p><p>You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
</div>
<!-- Close class contenido -->
</div>
<!-- Close div notebook container -->
</div>
<!-- Close div notebook -->
</div>

