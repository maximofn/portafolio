<p>
	<!-- Custom stylesheet, it must be in the same directory as the html file -->
	<!-- Loading mathjax macro --><!-- Load mathjax --><!-- MathJax configuration -->
<p>
<style>
	/* Media query para pantallas grandes */
	@media screen and (min-width: 1000px) {
		.container {
			flex-wrap: nowrap;
			display: flex;
			justify-content: space-between;
			height: 100vh; /* altura del viewport */
		}
		
		.indice {
			width: 25%; /* Ancho del índice en pantallas grandes */
			border-right: 1px solid #ccc;
			max-height: calc(100vh - 40px); /* Ajustar según tus necesidades. Aquí estamos restando el doble del padding para mantener todo visible */
			padding: 20px;
			box-sizing: border-box;
			overflow-y: auto; /* desplazamiento vertical cuando sea necesario */
		}
		
		.contenido {
			width: 70%; /* Ancho del contenido en pantallas grandes */
			max-height: calc(100vh - 40px); /* Ajustar según tus necesidades. Aquí estamos restando el doble del padding para mantener todo visible */
			padding: 20px;
			box-sizing: border-box;
			overflow-y: auto; /* desplazamiento vertical cuando sea necesario */
		}
	}
</style>
<!-- Open div notebook -->
<div id="notebook" class="border-box-sizing" tabindex="-1">
	<!-- Open div notebook container -->
	<div id="notebook-container" class="container">
		<!-- Open div indice -->
		<div class="indice">
			<!-- Open div index header -->
			<div class="cell border-box-sizing text_cell rendered">
				<h2 class="prompt input_prompt">
					<span style="
					color: var(--darkreader-text--heading-color, var(--darkreader-text--heading-2-color,
					var(--darkreader-text--headings-color)));
					font-family: var(--fontFamily); font-size: var(--fontSize);
					font-style: var(--fontStyle, inherit);
					font-weight: var(--fontWeight);
					letter-spacing: var(--letterSpacing);
					text-transform: var(--textTransform);
					background-color: transparent;
					--darkreader-inline-color: var(--darkreader-text--darkreader-text--heading-color,
					var(--darkreader-text--darkreader-text--heading-2-color, var(--darkreader-text--darkreader-text--headings-color)));
					--darkreader-inline-bgcolor: transparent;"
					data-darkreader-inline-color="" data-darkreader-inline-bgcolor="">
						Índice
					</span>
					<a class="anchor-link" style="
					font-family: var(--fontFamily);
					font-size: var(--fontSize);
					font-style: var(--fontStyle, inherit);
					font-weight: var(--fontWeight);
					letter-spacing: var(--letterSpacing);
					text-transform: var(--textTransform);
					background-color: transparent;
					--darkreader-inline-bgcolor: transparent;"
					href="#Índice" data-darkreader-inline-bgcolor="">
					</a>
				</h2>
			<!-- Close div index header -->
			</div>
			<!-- Index body -->
			<div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Inference-with-`pipeline-index">
									<a class="anchor-link" href="#Inference-with-`pipeline">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Inference with `pipeline</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Tasks-index">
									<a class="anchor-link" href="#Tasks">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Tasks</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Use-of-`pipeline`-index">
									<a class="anchor-link" href="#Use-of-`pipeline`">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Use of <code><b>pipeline</b></code></p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="How-`pipeline`-works-index">
									<a class="anchor-link" href="#How-`pipeline`-works">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">How <code><b>pipeline</b></code> works</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Inference-with-`AutoClass`-and-`pipeline`.-index">
									<a class="anchor-link" href="#Inference-with-`AutoClass`-and-`pipeline`.">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Inference with <code><b>AutoClass</b></code> and <code><b>pipeline</b></code>.</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Tokenization-with-`AutoTokenizer`.-index">
									<a class="anchor-link" href="#Tokenization-with-`AutoTokenizer`.">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Tokenization with <code><b>AutoTokenizer</b></code>.</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="`AutoModel`-Model-index">
									<a class="anchor-link" href="#`AutoModel`-Model">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;"><code><b>AutoModel</b></code> Model</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="`AutoModelFor`-Model-index">
									<a class="anchor-link" href="#`AutoModelFor`-Model">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;"><code><b>AutoModelFor</b></code> Model</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Inference-with-`AutoClass`-only-index">
									<a class="anchor-link" href="#Inference-with-`AutoClass`-only">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Inference with <code><b>AutoClass</b></code> only</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Generation-of-casual-text-index">
									<a class="anchor-link" href="#Generation-of-casual-text">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Generation of casual text</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Text-classification-index">
									<a class="anchor-link" href="#Text-classification">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Text classification</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Classification-of-tokens-index">
									<a class="anchor-link" href="#Classification-of-tokens">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Classification of tokens</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Question-answering-index">
									<a class="anchor-link" href="#Question-answering">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Question answering</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Masked-language-modeling-(Masked-language-modeling)-index">
									<a class="anchor-link" href="#Masked-language-modeling-(Masked-language-modeling)">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Masked language modeling (Masked language modeling)</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Model-customization-index">
									<a class="anchor-link" href="#Model-customization">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Model customization</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Tokenization-index">
									<a class="anchor-link" href="#Tokenization">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Tokenization</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Padding-index">
									<a class="anchor-link" href="#Padding">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Padding</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Truncated-index">
									<a class="anchor-link" href="#Truncated">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Truncated</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Tensors-index">
									<a class="anchor-link" href="#Tensors">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Tensors</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Masks-index">
									<a class="anchor-link" href="#Masks">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Masks</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Fast-Tokenizers-index">
									<a class="anchor-link" href="#Fast-Tokenizers">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Fast Tokenizers</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Text-generation-forms-index">
									<a class="anchor-link" href="#Text-generation-forms">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Text generation forms</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Greedy-Search-index">
									<a class="anchor-link" href="#Greedy-Search">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Greedy Search</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Contrastive-Search-index">
									<a class="anchor-link" href="#Contrastive-Search">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Contrastive Search</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Multinomial-sampling-index">
									<a class="anchor-link" href="#Multinomial-sampling">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Multinomial sampling</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Beam-search-index">
									<a class="anchor-link" href="#Beam-search">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Beam search</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Beam-search-multinomial-sampling-index">
									<a class="anchor-link" href="#Beam-search-multinomial-sampling">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Beam search multinomial sampling</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Beam-search-n-grams-penalty-index">
									<a class="anchor-link" href="#Beam-search-n-grams-penalty">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Beam search n-grams penalty</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Beam-search-n-grams-penalty-return-sequences-index">
									<a class="anchor-link" href="#Beam-search-n-grams-penalty-return-sequences">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Beam search n-grams penalty return sequences</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Diverse-beam-search-decoding-index">
									<a class="anchor-link" href="#Diverse-beam-search-decoding">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Diverse beam search decoding</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Speculative-Decoding-index">
									<a class="anchor-link" href="#Speculative-Decoding">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Speculative Decoding</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Speculative-Decoding-randomness-control-index">
									<a class="anchor-link" href="#Speculative-Decoding-randomness-control">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Speculative Decoding randomness control</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Sampling-index">
									<a class="anchor-link" href="#Sampling">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Sampling</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Sampling-temperature-index">
									<a class="anchor-link" href="#Sampling-temperature">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Sampling temperature</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Sampling-top-k-index">
									<a class="anchor-link" href="#Sampling-top-k">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Sampling top-k</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Sampling-top-p-(nucleus-sampling)-index">
									<a class="anchor-link" href="#Sampling-top-p-(nucleus-sampling)">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Sampling top-p (nucleus sampling)</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Sampling-top-k-and-top-p-index">
									<a class="anchor-link" href="#Sampling-top-k-and-top-p">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Sampling top-k and top-p</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Streaming-index">
									<a class="anchor-link" href="#Streaming">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Streaming</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Chat-templates-index">
									<a class="anchor-link" href="#Chat-templates">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Chat templates</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Context-tokenization-index">
									<a class="anchor-link" href="#Context-tokenization">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Context tokenization</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Add-prompts-generation-index">
									<a class="anchor-link" href="#Add-prompts-generation">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Add prompts generation</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Text-generation-index">
									<a class="anchor-link" href="#Text-generation">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Text generation</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Text-generation-with-`pipeline`.-index">
									<a class="anchor-link" href="#Text-generation-with-`pipeline`.">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Text generation with <code><b>pipeline</b></code>.</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Train-index">
									<a class="anchor-link" href="#Train">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Train</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Dataset-index">
									<a class="anchor-link" href="#Dataset">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Dataset</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Tokenization-index">
									<a class="anchor-link" href="#Tokenization">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Tokenization</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Model-index">
									<a class="anchor-link" href="#Model">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Model</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Evaluation-metrics-index">
									<a class="anchor-link" href="#Evaluation-metrics">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Evaluation metrics</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Trainer-index">
									<a class="anchor-link" href="#Trainer">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Trainer</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Testing-the-model-index">
									<a class="anchor-link" href="#Testing-the-model">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Testing the model</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Share-the-model-in-the-Hugging-Face-Hub-index">
									<a class="anchor-link" href="#Share-the-model-in-the-Hugging-Face-Hub">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Share the model in the Hugging Face Hub</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Logging-index">
									<a class="anchor-link" href="#Logging">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Logging</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Up-once-trained-index">
									<a class="anchor-link" href="#Up-once-trained">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Up once trained</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Climbing-while-training-index">
									<a class="anchor-link" href="#Climbing-while-training">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Climbing while training</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Hub-as-git-repository-index">
									<a class="anchor-link" href="#Hub-as-git-repository">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Hub as git repository</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
			</div>
		<!-- Close div indice -->
		</div>
 
		<!-- Content -->
		<div class="contenido">
		<div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><a href="https://colab.research.google.com/github/maximofn/portafolio/blob/main/posts/notebooks_translated/2024-04-15-Hugging-Face-transformers_EN.ipynb" target="_blank"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h1 id="Hugging-Face-transformers">
								<a class="anchor-link" href="#Hugging-Face-transformers">
									<p style="margin-left: 0px">Hugging Face transformers</p>
								</a>
							</h1>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">The <code><b>transformers</b></code> library from Hugging Face is one of the most popular libraries for working with language models. Its ease of use democratized the use of the <code><b>Transformer</b></code> architecture and made it possible to work with state-of-the-art language models without having to have a great deal of knowledge in the area.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Between the <code><b>transformers</b></code> library, the model hub and its ease of use, the spaces and the ease of deploying demos, and new libraries like <code><b>datasets</b></code>, <code><b>accelerate</b></code>, <code><b>PEFT</b></code> and more, they have made Hugging Face one of the most important players in the AI scene at the moment. They call themselves "the GitHub of AI" and they certainly are.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">This notebook has been automatically translated to make it accessible to more people, please let me know if you see any typos.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">## Installation</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">To install transformers can be done with <code><b>pip</b></code>.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 80px;"><code>pip install transformers<br></code></p>
						</div>
					</div>
				</div>
			</div>
	
	
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">or with <code><b>conda</b></code>.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 80px;"><code>conda install conda-forge::transformers<br></code></p>
						</div>
					</div>
				</div>
			</div>
	
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">In addition to the library you need to have a PyTorch or TensorFlow backend installed. That is, you need to have <code><b>torch</b></code> or <code><b>tensorflow</b></code> installed to be able to use <code><b>transformers</b></code>.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Inference-with-`pipeline">
								<a class="anchor-link" href="#Inference-with-`pipeline">
									<p style="margin-left: 10px">Inference with `pipeline</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">With the <code><b>transformers</b></code> pipeline`s you can do inference with language models in a very simple way. This has the advantage that development is done much faster and prototyping can be done very easily. It also allows people who do not have much knowledge to be able to use the models.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">With <code><b>pipeline</b></code> you can do inference in a lot of different tasks. Each task has its own <code><b>pipeline</b></code> (NLP <code><b>pipeline</b></code>, vision <code><b>pipeline</b></code>, etc), but a general abstraction can be made using the <code><b>pipeline</b></code> class which takes care of selecting the appropriate <code><b>pipeline</b></code> for the task passed to it.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h3 id="Tasks">
								<a class="anchor-link" href="#Tasks">
									<p style="margin-left: 20px">Tasks</p>
								</a>
							</h3>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">As of this writing, the tasks that can be done with <code><b>pipeline</b></code> are:</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">
								<ul>
									<li>Audio:</li>
									<ul><li>Audio classification</li></ul>
									<ul><ul><li>acoustic scene classification: label audio with a scene label ("office", "beach", "stadium")</li></ul></ul>
									<ul><ul><li>acoustic event detection: tag audio with a sound event tag ("car horn", "whale call", "glass breaking")</li></ul></ul>
									<ul><ul><li>labeling: labeling audio containing various sounds (birdsong, speaker identification in a meeting)</li></ul></ul>
									<ul><ul><li>music classification: labeling music with a genre label ("metal", "hip-hop", "country")</li></ul></ul>
								</ul>
							</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">
								<ul>
									<li>Automatic speech recognition (ASR, audio speech recognition):</li>
								</ul>
							</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">
								<ul>
									<li>Computer vision</li>
									<ul><li>Image classification</li></ul>
									<ul><li>Object detection</li></ul>
									<ul><li>Image segmentation</li></ul>
									<ul><li>Depth estimation</li></ul>
								</ul>
							</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"> Natural language processing (NLP) * Natural language processing (NLP)</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">
								<ul>
									<li>Text classification</li>
									<ul><li>sentiment analysis</li></ul>
									<ul><li>content classification</li></ul>
									<li>Classification of tokens</li>
									<ul><li>Named Entity Recognition (NER): tag a token according to an entity category such as organization, person, location or date.</li></ul>
									<ul><li>part-of-speech (POS) tagging: tagging a token according to its part of speech, such as noun, verb or adjective. POS is useful to help translation systems understand how two identical words are grammatically different (e.g., "cut" as a noun versus "cut" as a verb).</li></ul>
									<li>Answers to questions</li>
									<ul><li>extractive: given a question and some context, the answer is a fragment of text from the context that the model must extract.</li></ul>
									<ul><li>abstract: given a question and some context, the answer is generated from the context; this approach is handled by the Text2TextGenerationPipeline instead of the QuestionAnsweringPipeline shown below.</li></ul>
									<li>Summarize</li>
									<ul><li>extractive: identifies and extracts the most important sentences from the original text</li></ul>
									<ul><li>abstracting: generates the objective summary (which may include new words not present in the input document) from the original text</li></ul>
									<li>Translation</li>
									<li>Language modeling</li>
									<ul><li>causal: the objective of the model is to predict the next token in a sequence, and future tokens are masked.</li></ul>
									<ul><li>masked: the objective of the model is to predict a masked token in a sequence with full access to the tokens in the sequence.</li></ul>
								</ul>
							</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">
								<ul>
									<li>Multimodal</li>
									<ul><li>Answers to document questions</li></ul>
								</ul>
							</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h3 id="Use-of-`pipeline`">
								<a class="anchor-link" href="#Use-of-`pipeline`">
									<p style="margin-left: 20px">Use of <code><b>pipeline</b></code></p>
								</a>
							</h3>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">The easiest way to create a <code><b>pipeline</b></code> is simply to tell it the task we want it to solve using the <code><b>task</b></code> parameter. And the library will take care of selecting the best model for that task, download it and save it in the cache for future use.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">pipeline</span></p>
<p></p>
<p><span style="color: #6b97e8;">generator</span> <span>=</span> <span style="color: #6b97e8;">pipeline</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">task</span><span>=</span><span style="color: #7e7a34;">&quot;text-generation&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>No model was supplied, defaulted to openai-community/gpt2 and revision 6c0e608 (https://huggingface.co/openai-community/gpt2).</p><p>Using a pipeline without specifying a model name and revision in production is not recommended.</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">generator</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>[{'generated_text': 'Me encanta aprender de se résistance davant que hiens que préclase que ses encasas quécénces. Se présentants cet en un croyne et cela désirez'}]</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">As you can see the generated text is in French, while I have introduced it in Spanish, so it is important to choose well the model. If you notice the library has taken the <code><b>openai-community/gpt2</b></code> model, which is a model trained mostly in English, and that when I put Spanish text in it, it got confused and generated a response in French.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">We are going to use a model retrained in Spanish using the <code><b>model</b></code> parameter.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">pipeline</span></p>
<p></p>
<p><span style="color: #6b97e8;">generator</span> <span>=</span> <span style="color: #6b97e8;">pipeline</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">task</span><span>=</span><span style="color: #7e7a34;">&quot;text-generation&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">model</span><span>=</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">generator</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>[{'generated_text': 'Me encanta aprender de tus palabras, que con gran entusiasmo y con el mismo conocimiento como lo que tú acabas escribiendo, te deseo de todo corazón todo el deseo de este día:\nY aunque también haya personas a las que'}]</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Now the generated text looks much better</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">The <code><b>pipeline</b></code> class has many possible parameters, so to see all of them and learn more about the class I recommend you to read its <a href="https://huggingface.co/docs/transformers/v4.38.1/en/main_classes/pipelines" target="_blank">documentation</a>, but let's talk about one, because for deep learning it is very important and it is <code><b>device</b></code>. It defines the device (e.g. <code><b>cpu</b></code>, <code><b>cuda:1</b></code>, <code><b>mps</b></code> or an ordinal range of GPUs like <code><b>1</b></code>) on which the <code><b>pipeline</b></code> will be assigned.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">In my case, as I have a GPU I set <code><b>0</b></code>.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">pipeline</span></p>
<p></p>
<p><span style="color: #6b97e8;">generator</span> <span>=</span> <span style="color: #6b97e8;">pipeline</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">task</span><span>=</span><span style="color: #7e7a34;">&quot;text-generation&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">model</span><span>=</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">generation</span> <span>=</span> <span style="color: #6b97e8;">generator</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">generation</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">][</span><span style="color: #8d783e;">&#39;generated_text&#39;</span><span style="color: #e3e11d;">])</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>Me encanta aprender de ustedes, a tal punto que he decidido escribir algunos de nuestros contenidos en este blog, el cual ha sido de gran utilidad para mí por varias razones, una de ellas, el trabajo</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h3 id="How-`pipeline`-works">
								<a class="anchor-link" href="#How-`pipeline`-works">
									<p style="margin-left: 20px">How <code><b>pipeline</b></code> works</p>
								</a>
							</h3>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">When we make use of <code><b>pipeline</b></code> below what is happening is this</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="http://maximofn.com/wp-content/uploads/2024/02/transformers-pipeline.svg" alt="transformers-pipeline"></p></p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Text is automatically tokenized, passed through the model and then post-processed.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Inference-with-`AutoClass`-and-`pipeline`.">
								<a class="anchor-link" href="#Inference-with-`AutoClass`-and-`pipeline`.">
									<p style="margin-left: 10px">Inference with <code><b>AutoClass</b></code> and <code><b>pipeline</b></code>.</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">We have seen that <code><b>pipeline</b></code> abstracts a lot of what happens, but we can select which tokenizer, which model and which postprocessing we want to use.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h3 id="Tokenization-with-`AutoTokenizer`.">
								<a class="anchor-link" href="#Tokenization-with-`AutoTokenizer`.">
									<p style="margin-left: 20px">Tokenization with <code><b>AutoTokenizer</b></code>.</p>
								</a>
							</h3>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Before we used the <code><b>flax-community/gpt-2-spanish</b></code> model to generate text, we can use its tokenizer</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span></p>
<p></p>
<p><span style="color: #6b97e8;">checkpoint</span> <span>=</span> <span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">text</span> <span>=</span> <span style="color: #7e7a34;">&quot;Me encanta lo que estoy aprendiendo&quot;</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokens</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">text</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokens</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>{'input_ids': tensor([[ 2879,  4835,   382,   288,  2383, 15257]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h3 id="`AutoModel`-Model">
								<a class="anchor-link" href="#`AutoModel`-Model">
									<p style="margin-left: 20px"><code><b>AutoModel</b></code> Model</p>
								</a>
							</h3>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Now we can create the model and pass the tokens to it.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoModel</span></p>
<p></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModel</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">tokens</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">type</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">output</span><span style="color: #e3e11d;">),</span> <span style="color: #6b97e8;">output</span><span>.</span><span style="color: #6b97e8;">keys</span><span style="color: #e3e11d;">()</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>(transformers.modeling_outputs.BaseModelOutputWithPastAndCrossAttentions,</p><p> odict_keys(['last_hidden_state', 'past_key_values']))</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">If we now try to use it in a <code><b>pipeline</b></code> we will get an error.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">pipeline</span></p>
<p></p>
<p><span style="color: #6b97e8;">pipeline</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;text-generation&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">model</span><span>=</span><span style="color: #6b97e8;">model</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">tokenizer</span><span>=</span><span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">)(</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_text output_error">
								<pre style="margin-left: 60px; line-height: 0%;"><p><span style="color:red">---------------------------------------------------------------------------</span></p><p><span style="color:red">TypeError</span>                                 Traceback (most recent call last)</p><p>Cell <span style="color:green">In[23], line 3</span></p><p><span style="color:green"><b>      1</b></span> [38;5;28;01mfrom[39;00m [38;5;21;01mtransformers[39;00m [38;5;28;01mimport[39;00m pipeline</p><p><span style="color:green">----&gt; 3</span> pipeline([38;5;124m"[39m[38;5;124mtext-generation[39m[38;5;124m"[39m, model[38;5;241m=[39mmodel, tokenizer[38;5;241m=[39mtokenizer)([38;5;124m"[39m[38;5;124mMe encanta aprender de[39m[38;5;124m"[39m)</p><p></p><p>File <span style="color:green">~/miniconda3/envs/nlp/lib/python3.11/site-packages/transformers/pipelines/text_generation.py:241</span>, in TextGenerationPipeline.__call__<span style="color:blue">(self, text_inputs, **kwargs)</span></p><p><span style="color:green"><b>    239</b></span>         [38;5;28;01mreturn[39;00m [38;5;28msuper[39m()[38;5;241m.[39m[38;5;21m__call__[39m(chats, [38;5;241m*[39m[38;5;241m*[39mkwargs)</p><p><span style="color:green"><b>    240</b></span> [38;5;28;01melse[39;00m:</p><p><span style="color:green">--&gt; 241</span>     [38;5;28;01mreturn[39;00m [38;5;28msuper[39m()[38;5;241m.[39m[38;5;21m__call__[39m(text_inputs, [38;5;241m*[39m[38;5;241m*[39mkwargs)</p><p></p><p>File <span style="color:green">~/miniconda3/envs/nlp/lib/python3.11/site-packages/transformers/pipelines/base.py:1196</span>, in Pipeline.__call__<span style="color:blue">(self, inputs, num_workers, batch_size, *args, **kwargs)</span></p><p><span style="color:green"><b>   1188</b></span>     [38;5;28;01mreturn[39;00m [38;5;28mnext[39m(</p><p><span style="color:green"><b>   1189</b></span>         [38;5;28miter[39m(</p><p><span style="color:green"><b>   1190</b></span>             [38;5;28mself[39m[38;5;241m.[39mget_iterator(</p><p><span style="color:green">   (...)</span></p><p><span style="color:green"><b>   1193</b></span>         )</p><p><span style="color:green"><b>   1194</b></span>     )</p><p><span style="color:green"><b>   1195</b></span> [38;5;28;01melse[39;00m:</p><p><span style="color:green">-&gt; 1196</span>     [38;5;28;01mreturn[39;00m [38;5;28mself[39m[38;5;241m.[39mrun_single(inputs, preprocess_params, forward_params, postprocess_params)</p><p></p><p>File <span style="color:green">~/miniconda3/envs/nlp/lib/python3.11/site-packages/transformers/pipelines/base.py:1203</span>, in Pipeline.run_single<span style="color:blue">(self, inputs, preprocess_params, forward_params, postprocess_params)</span></p><p><span style="color:green"><b>   1201</b></span> [38;5;28;01mdef[39;00m [38;5;21mrun_single[39m([38;5;28mself[39m, inputs, preprocess_params, forward_params, postprocess_params):</p><p><span style="color:green"><b>   1202</b></span>     model_inputs [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mpreprocess(inputs, [38;5;241m*[39m[38;5;241m*[39mpreprocess_params)</p><p><span style="color:green">-&gt; 1203</span>     model_outputs [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mforward(model_inputs, [38;5;241m*[39m[38;5;241m*[39mforward_params)</p><p><span style="color:green"><b>   1204</b></span>     outputs [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mpostprocess(model_outputs, [38;5;241m*[39m[38;5;241m*[39mpostprocess_params)</p><p><span style="color:green"><b>   1205</b></span>     [38;5;28;01mreturn[39;00m outputs</p><p></p><p>File <span style="color:green">~/miniconda3/envs/nlp/lib/python3.11/site-packages/transformers/pipelines/base.py:1102</span>, in Pipeline.forward<span style="color:blue">(self, model_inputs, **forward_params)</span></p><p><span style="color:green"><b>   1100</b></span>     [38;5;28;01mwith[39;00m inference_context():</p><p><span style="color:green"><b>   1101</b></span>         model_inputs [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39m_ensure_tensor_on_device(model_inputs, device[38;5;241m=[39m[38;5;28mself[39m[38;5;241m.[39mdevice)</p><p><span style="color:green">-&gt; 1102</span>         model_outputs [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39m_forward(model_inputs, [38;5;241m*[39m[38;5;241m*[39mforward_params)</p><p><span style="color:green"><b>   1103</b></span>         model_outputs [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39m_ensure_tensor_on_device(model_outputs, device[38;5;241m=[39mtorch[38;5;241m.[39mdevice([38;5;124m"[39m[38;5;124mcpu[39m[38;5;124m"[39m))</p><p><span style="color:green"><b>   1104</b></span> [38;5;28;01melse[39;00m:</p><p></p><p>File <span style="color:green">~/miniconda3/envs/nlp/lib/python3.11/site-packages/transformers/pipelines/text_generation.py:328</span>, in TextGenerationPipeline._forward<span style="color:blue">(self, model_inputs, **generate_kwargs)</span></p><p><span style="color:green"><b>    325</b></span>         generate_kwargs[[38;5;124m"[39m[38;5;124mmin_length[39m[38;5;124m"[39m] [38;5;241m+[39m[38;5;241m=[39m prefix_length</p><p><span style="color:green"><b>    327</b></span> [38;5;66;03m# BS x SL[39;00m</p><p><span style="color:green">--&gt; 328</span> generated_sequence [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mmodel[38;5;241m.[39mgenerate(input_ids[38;5;241m=[39minput_ids, attention_mask[38;5;241m=[39mattention_mask, [38;5;241m*[39m[38;5;241m*[39mgenerate_kwargs)</p><p><span style="color:green"><b>    329</b></span> out_b [38;5;241m=[39m generated_sequence[38;5;241m.[39mshape[[38;5;241m0[39m]</p><p><span style="color:green"><b>    330</b></span> [38;5;28;01mif[39;00m [38;5;28mself[39m[38;5;241m.[39mframework [38;5;241m==[39m [38;5;124m"[39m[38;5;124mpt[39m[38;5;124m"[39m:</p><p></p><p>File <span style="color:green">~/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/utils/_contextlib.py:115</span>, in context_decorator.&lt;locals&gt;.decorate_context<span style="color:blue">(*args, **kwargs)</span></p><p><span style="color:green"><b>    112</b></span> [38;5;129m@functools[39m[38;5;241m.[39mwraps(func)</p><p><span style="color:green"><b>    113</b></span> [38;5;28;01mdef[39;00m [38;5;21mdecorate_context[39m([38;5;241m*[39margs, [38;5;241m*[39m[38;5;241m*[39mkwargs):</p><p><span style="color:green"><b>    114</b></span>     [38;5;28;01mwith[39;00m ctx_factory():</p><p><span style="color:green">--&gt; 115</span>         [38;5;28;01mreturn[39;00m func([38;5;241m*[39margs, [38;5;241m*[39m[38;5;241m*[39mkwargs)</p><p></p><p>File <span style="color:green">~/miniconda3/envs/nlp/lib/python3.11/site-packages/transformers/generation/utils.py:1323</span>, in GenerationMixin.generate<span style="color:blue">(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)</span></p><p><span style="color:green"><b>   1320</b></span>         synced_gpus [38;5;241m=[39m [38;5;28;01mFalse[39;00m</p><p><span style="color:green"><b>   1322</b></span> [38;5;66;03m# 1. Handle `generation_config` and kwargs that might update it, and validate the `.generate()` call[39;00m</p><p><span style="color:green">-&gt; 1323</span> [38;5;28mself[39m[38;5;241m.[39m_validate_model_class()</p><p><span style="color:green"><b>   1325</b></span> [38;5;66;03m# priority: `generation_config` argument &gt; `model.generation_config` (the default generation config)[39;00m</p><p><span style="color:green"><b>   1326</b></span> [38;5;28;01mif[39;00m generation_config [38;5;129;01mis[39;00m [38;5;28;01mNone[39;00m:</p><p><span style="color:green"><b>   1327</b></span>     [38;5;66;03m# legacy: users may modify the model configuration to control generation. To trigger this legacy behavior,[39;00m</p><p><span style="color:green"><b>   1328</b></span>     [38;5;66;03m# three conditions must be met[39;00m</p><p><span style="color:green"><b>   1329</b></span>     [38;5;66;03m# 1) the generation config must have been created from the model config (`_from_model_config` field);[39;00m</p><p><span style="color:green"><b>   1330</b></span>     [38;5;66;03m# 2) the generation config must have seen no modification since its creation (the hash is the same);[39;00m</p><p><span style="color:green"><b>   1331</b></span>     [38;5;66;03m# 3) the user must have set generation parameters in the model config.[39;00m</p><p></p><p>File <span style="color:green">~/miniconda3/envs/nlp/lib/python3.11/site-packages/transformers/generation/utils.py:1110</span>, in GenerationMixin._validate_model_class<span style="color:blue">(self)</span></p><p><span style="color:green"><b>   1108</b></span> [38;5;28;01mif[39;00m generate_compatible_classes:</p><p><span style="color:green"><b>   1109</b></span>     exception_message [38;5;241m+[39m[38;5;241m=[39m [38;5;124mf[39m[38;5;124m"[39m[38;5;124m Please use one of the following classes instead: [39m[38;5;132;01m{[39;00mgenerate_compatible_classes[38;5;132;01m}[39;00m[38;5;124m"[39m</p><p><span style="color:green">-&gt; 1110</span> [38;5;28;01mraise[39;00m [38;5;167;01mTypeError[39;00m(exception_message)</p><p></p><p><span style="color:red">TypeError</span>: The current model class (GPT2Model) is not compatible with `.generate()`, as it doesn't have a language model head. Please use one of the following classes instead: {'GPT2LMHeadModel'}</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;">This is because when it worked we used</p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;"></p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 80px;"><code>pipeline(task="text-generation", model="flax-community/gpt-2-spanish")<br></code></p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;"></p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;"></p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;">But now we have made</p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;"></p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 80px;"><code>tokenizer = AutoTokenizer.from_pretrained("flax-community/gpt-2-spanish")<br>model = AutoModel.from_pretrained("flax-community/gpt-2-spanish")<br>pipeline("text-generation", model=model, tokenizer=tokenizer)<br></code></p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;"></p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;"></p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;"></p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;"></p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;">In the first case we just used <code><b>pipeline</b></code> and the model name, underneath we were looking for the best way to implement the model and the tokenizer. But in the second case we have created the tokenizer and the model and passed it to <code><b>pipeline</b></code>, but we have not created them well for what the <code><b>pipeline</b></code> needs.</p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;"></p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;">To fix this we use <code><b>AutoModelFor</b></code>.</p>
					</div>
				</div>
			</div>
		</div>
		<!-- Open div header -->
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<h3 id="`AutoModelFor`-Model">
							<a class="anchor-link" href="#`AutoModelFor`-Model">
								<p style="margin-left: 20px"><code><b>AutoModelFor</b></code> Model</p>
							</a>
						</h3>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;">The transformers library gives us the opportunity to create a model for a given task such as</p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;"></p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;">
							<ul>
								<li><code><b>AutoModelForCausalLM</b></code> used to continue texts</li>
								<li><code><b>AutoModelForMaskedLM</b></code> used for gap filling</li>
								<li><code><b>AutoModelForMaskGeneration</b></code> which is used to generate masks.</li>
								<li>AutoModelForSeq2SeqLM, which is used to convert from sequences to sequences, as for example in translation.</li>
								<li><code><b>AutoModelForSequenceClassification</b></code> for text classification</li>
								<li><code><b>AutoModelForMultipleChoice</b></code> for multiple choice</li>
								<li><code><b>AutoModelForNextSentencePrediction</b></code> to predict whether two sentences are consecutive.</li>
								<li><code><b>AutoModelForTokenClassification</b></code> for token classification</li>
								<li><code><b>AutoModelForQuestionAnswering</b></code> for questions and answers</li>
								<li><code><b>AutoModelForTextEncoding</b></code> for text encoding</li>
							</ul>
						</p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">

					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">

					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">

					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">

					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">

					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">

					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">

					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">

					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">

					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;">Let's use the above model to generate text</p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing code_cell rendered">
			<div class="input">
				<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
				<div class="inner_cell">
					<div class="input_area">
						<div class=" highlight hl-python3">
							<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">pipeline</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">pipeline</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;text-generation&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">model</span><span>=</span><span style="color: #6b97e8;">model</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">tokenizer</span><span>=</span><span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">)(</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">)[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">][</span><span style="color: #8d783e;">&#39;generated_text&#39;</span><span style="color: #e3e11d;">]</span></p>
							</pre>
						</div>
					</div>
				</div>
			</div>
			<div class="output_wrapper">
				<div class="output">
					<div class="output_area">
						<div class="prompt" style="margin-left: 20px;">Output:</div>
						<div class="output_subarea output_stream output_stdout output_text">
							<pre style="margin-left: 60px; line-height: 0%;"><p>'Me encanta aprender de mi familia.\nLa verdad no sabía que se necesitaba tanto en este pequeño restaurante ya que mi novio en un principio había ido, pero hoy me ha entrado un gusanillo entre pecho y espalda que'</p></pre>
						</div>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;">Now it works, because we have created the model in a way that <code><b>pipeline</b></code> can understand.</p>
					</div>
				</div>
			</div>
		</div>
		<!-- Open div header -->
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<h2 id="Inference-with-`AutoClass`-only">
							<a class="anchor-link" href="#Inference-with-`AutoClass`-only">
								<p style="margin-left: 10px">Inference with <code><b>AutoClass</b></code> only</p>
							</a>
						</h2>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;">Earlier we created the model and tokenizer and gave it to <code><b>pipeline</b></code> to do the necessary underneath, but we can use the methods for inference ourselves.</p>
					</div>
				</div>
			</div>
		</div>
		<!-- Open div header -->
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<h3 id="Generation-of-casual-text">
							<a class="anchor-link" href="#Generation-of-casual-text">
								<p style="margin-left: 20px">Generation of casual text</p>
							</a>
						</h3>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;">We create the model and the tokenizer</p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing code_cell rendered">
			<div class="input">
				<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
				<div class="inner_cell">
					<div class="input_area">
						<div class=" highlight hl-python3">
							<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
							</pre>
						</div>
					</div>
				</div>
			</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;">With <code><b>device_map</b></code>, we have loaded the model on GPU 0</p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;">Now we have to do what <code><b>pipeline</b></code> used to do.</p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing text_cell rendered">
			<div class="prompt input_prompt">
				<div class="inner_cell">
					<div class="text_cell_render border-box-sizing rendered_html">
						<p style="margin-left: 0px;">First we generate the tokens</p>
					</div>
				</div>
			</div>
		</div>
		<div class="cell border-box-sizing code_cell rendered">
			<div class="input">
				<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
				<div class="inner_cell">
					<div class="input_area">
						<div class=" highlight hl-python3">
							<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">tokens_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
							</pre>
						</div>
					</div>
				</div>
			</div>
			<div class="output_wrapper">
				<div class="output">
					<div class="output_area">
						<div class="prompt" style="margin-left: 20px;">Output:</div>
						<div class="output_subarea output_text output_error">
							<pre style="margin-left: 60px; line-height: 0%;"><p><span style="color:red">---------------------------------------------------------------------------</span></p><p><span style="color:red">ValueError</span>                                Traceback (most recent call last)</p><p>Cell <span style="color:green">In[2], line 1</span></p><p><span style="color:green">----&gt; 1</span> tokens_input [38;5;241m=[39m tokenizer([[38;5;124m"[39m[38;5;124mMe encanta aprender de[39m[38;5;124m"[39m], return_tensors[38;5;241m=[39m[38;5;124m"[39m[38;5;124mpt[39m[38;5;124m"[39m, padding[38;5;241m=[39m[38;5;28;01mTrue[39;00m)[38;5;241m.[39mto([38;5;124m"[39m[38;5;124mcuda[39m[38;5;124m"[39m)</p><p></p><p>File <span style="color:green">~/miniconda3/envs/nlp/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2829</span>, in PreTrainedTokenizerBase.__call__<span style="color:blue">(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)</span></p><p><span style="color:green"><b>   2827</b></span>     [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m [38;5;28mself[39m[38;5;241m.[39m_in_target_context_manager:</p><p><span style="color:green"><b>   2828</b></span>         [38;5;28mself[39m[38;5;241m.[39m_switch_to_input_mode()</p><p><span style="color:green">-&gt; 2829</span>     encodings [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39m_call_one(text[38;5;241m=[39mtext, text_pair[38;5;241m=[39mtext_pair, [38;5;241m*[39m[38;5;241m*[39mall_kwargs)</p><p><span style="color:green"><b>   2830</b></span> [38;5;28;01mif[39;00m text_target [38;5;129;01mis[39;00m [38;5;129;01mnot[39;00m [38;5;28;01mNone[39;00m:</p><p><span style="color:green"><b>   2831</b></span>     [38;5;28mself[39m[38;5;241m.[39m_switch_to_target_mode()</p><p></p><p>File <span style="color:green">~/miniconda3/envs/nlp/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2915</span>, in PreTrainedTokenizerBase._call_one<span style="color:blue">(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)</span></p><p><span style="color:green"><b>   2910</b></span>         [38;5;28;01mraise[39;00m [38;5;167;01mValueError[39;00m(</p><p><span style="color:green"><b>   2911</b></span>             [38;5;124mf[39m[38;5;124m"[39m[38;5;124mbatch length of `text`: [39m[38;5;132;01m{[39;00m[38;5;28mlen[39m(text)[38;5;132;01m}[39;00m[38;5;124m does not match batch length of `text_pair`:[39m[38;5;124m"[39m</p><p><span style="color:green"><b>   2912</b></span>             [38;5;124mf[39m[38;5;124m"[39m[38;5;124m [39m[38;5;132;01m{[39;00m[38;5;28mlen[39m(text_pair)[38;5;132;01m}[39;00m[38;5;124m.[39m[38;5;124m"[39m</p><p><span style="color:green"><b>   2913</b></span>         )</p><p><span style="color:green"><b>   2914</b></span>     batch_text_or_text_pairs [38;5;241m=[39m [38;5;28mlist[39m([38;5;28mzip[39m(text, text_pair)) [38;5;28;01mif[39;00m text_pair [38;5;129;01mis[39;00m [38;5;129;01mnot[39;00m [38;5;28;01mNone[39;00m [38;5;28;01melse[39;00m text</p><p><span style="color:green">-&gt; 2915</span>     [38;5;28;01mreturn[39;00m [38;5;28mself[39m[38;5;241m.[39mbatch_encode_plus(</p><p><span style="color:green"><b>   2916</b></span>         batch_text_or_text_pairs[38;5;241m=[39mbatch_text_or_text_pairs,</p><p><span style="color:green"><b>   2917</b></span>         add_special_tokens[38;5;241m=[39madd_special_tokens,</p><p><span style="color:green"><b>   2918</b></span>         padding[38;5;241m=[39mpadding,</p><p><span style="color:green"><b>   2919</b></span>         truncation[38;5;241m=[39mtruncation,</p><p><span style="color:green"><b>   2920</b></span>         max_length[38;5;241m=[39mmax_length,</p><p><span style="color:green"><b>   2921</b></span>         stride[38;5;241m=[39mstride,</p><p><span style="color:green"><b>   2922</b></span>         is_split_into_words[38;5;241m=[39mis_split_into_words,</p><p><span style="color:green"><b>   2923</b></span>         pad_to_multiple_of[38;5;241m=[39mpad_to_multiple_of,</p><p><span style="color:green"><b>   2924</b></span>         return_tensors[38;5;241m=[39mreturn_tensors,</p><p><span style="color:green"><b>   2925</b></span>         return_token_type_ids[38;5;241m=[39mreturn_token_type_ids,</p><p><span style="color:green"><b>   2926</b></span>         return_attention_mask[38;5;241m=[39mreturn_attention_mask,</p><p><span style="color:green"><b>   2927</b></span>         return_overflowing_tokens[38;5;241m=[39mreturn_overflowing_tokens,</p><p><span style="color:green"><b>   2928</b></span>         return_special_tokens_mask[38;5;241m=[39mreturn_special_tokens_mask,</p><p><span style="color:green"><b>   2929</b></span>         return_offsets_mapping[38;5;241m=[39mreturn_offsets_mapping,</p><p><span style="color:green"><b>   2930</b></span>         return_length[38;5;241m=[39mreturn_length,</p><p><span style="color:green"><b>   2931</b></span>         verbose[38;5;241m=[39mverbose,</p><p><span style="color:green"><b>   2932</b></span>         [38;5;241m*[39m[38;5;241m*[39mkwargs,</p><p><span style="color:green"><b>   2933</b></span>     )</p><p><span style="color:green"><b>   2934</b></span> [38;5;28;01melse[39;00m:</p><p><span style="color:green"><b>   2935</b></span>     [38;5;28;01mreturn[39;00m [38;5;28mself[39m[38;5;241m.[39mencode_plus(</p><p><span style="color:green"><b>   2936</b></span>         text[38;5;241m=[39mtext,</p><p><span style="color:green"><b>   2937</b></span>         text_pair[38;5;241m=[39mtext_pair,</p><p><span style="color:green">   (...)</span></p><p><span style="color:green"><b>   2953</b></span>         [38;5;241m*[39m[38;5;241m*[39mkwargs,</p><p><span style="color:green"><b>   2954</b></span>     )</p><p></p><p>File <span style="color:green">~/miniconda3/envs/nlp/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3097</span>, in PreTrainedTokenizerBase.batch_encode_plus<span style="color:blue">(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)</span></p><p><span style="color:green"><b>   3080</b></span> [38;5;250m[39m[38;5;124;03m"""[39;00m</p><p><span style="color:green"><b>   3081</b></span> [38;5;124;03mTokenize and prepare for the model a list of sequences or a list of pairs of sequences.[39;00m</p><p><span style="color:green"><b>   3082</b></span> </p><p><span style="color:green">   (...)</span></p><p><span style="color:green"><b>   3093</b></span> [38;5;124;03m        details in `encode_plus`).[39;00m</p><p><span style="color:green"><b>   3094</b></span> [38;5;124;03m"""[39;00m</p><p><span style="color:green"><b>   3096</b></span> [38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'[39;00m</p><p><span style="color:green">-&gt; 3097</span> padding_strategy, truncation_strategy, max_length, kwargs [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39m_get_padding_truncation_strategies(</p><p><span style="color:green"><b>   3098</b></span>     padding[38;5;241m=[39mpadding,</p><p><span style="color:green"><b>   3099</b></span>     truncation[38;5;241m=[39mtruncation,</p><p><span style="color:green"><b>   3100</b></span>     max_length[38;5;241m=[39mmax_length,</p><p><span style="color:green"><b>   3101</b></span>     pad_to_multiple_of[38;5;241m=[39mpad_to_multiple_of,</p><p><span style="color:green"><b>   3102</b></span>     verbose[38;5;241m=[39mverbose,</p><p><span style="color:green"><b>   3103</b></span>     [38;5;241m*[39m[38;5;241m*[39mkwargs,</p><p><span style="color:green"><b>   3104</b></span> )</p><p><span style="color:green"><b>   3106</b></span> [38;5;28;01mreturn[39;00m [38;5;28mself[39m[38;5;241m.[39m_batch_encode_plus(</p><p><span style="color:green"><b>   3107</b></span>     batch_text_or_text_pairs[38;5;241m=[39mbatch_text_or_text_pairs,</p><p><span style="color:green"><b>   3108</b></span>     add_special_tokens[38;5;241m=[39madd_special_tokens,</p><p><span style="color:green">   (...)</span></p><p><span style="color:green"><b>   3123</b></span>     [38;5;241m*[39m[38;5;241m*[39mkwargs,</p><p><span style="color:green"><b>   3124</b></span> )</p><p></p><p>File <span style="color:green">~/miniconda3/envs/nlp/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2734</span>, in PreTrainedTokenizerBase._get_padding_truncation_strategies<span style="color:blue">(self, padding, truncation, max_length, pad_to_multiple_of, verbose, **kwargs)</span></p><p><span style="color:green"><b>   2732</b></span> [38;5;66;03m# Test if we have a padding token[39;00m</p><p><span style="color:green"><b>   2733</b></span> [38;5;28;01mif[39;00m padding_strategy [38;5;241m!=[39m PaddingStrategy[38;5;241m.[39mDO_NOT_PAD [38;5;129;01mand[39;00m ([38;5;28mself[39m[38;5;241m.[39mpad_token [38;5;129;01mis[39;00m [38;5;28;01mNone[39;00m [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39mpad_token_id [38;5;241m&lt;[39m [38;5;241m0[39m):</p><p><span style="color:green">-&gt; 2734</span>     [38;5;28;01mraise[39;00m [38;5;167;01mValueError[39;00m(</p><p><span style="color:green"><b>   2735</b></span>         [38;5;124m"[39m[38;5;124mAsking to pad but the tokenizer does not have a padding token. [39m[38;5;124m"[39m</p><p><span style="color:green"><b>   2736</b></span>         [38;5;124m"[39m[38;5;124mPlease select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` [39m[38;5;124m"[39m</p><p><span style="color:green"><b>   2737</b></span>         [38;5;124m"[39m[38;5;124mor add a new pad token via `tokenizer.add_special_tokens([39m[38;5;124m{[39m[38;5;124m'[39m[38;5;124mpad_token[39m[38;5;124m'[39m[38;5;124m: [39m[38;5;124m'[39m[38;5;124m[PAD][39m[38;5;124m'[39m[38;5;124m})`.[39m[38;5;124m"[39m</p><p><span style="color:green"><b>   2738</b></span>     )</p><p><span style="color:green"><b>   2740</b></span> [38;5;66;03m# Check that we will truncate to a multiple of pad_to_multiple_of if both are provided[39;00m</p><p><span style="color:green"><b>   2741</b></span> [38;5;28;01mif[39;00m (</p><p><span style="color:green"><b>   2742</b></span>     truncation_strategy [38;5;241m!=[39m TruncationStrategy[38;5;241m.[39mDO_NOT_TRUNCATE</p><p><span style="color:green"><b>   2743</b></span>     [38;5;129;01mand[39;00m padding_strategy [38;5;241m!=[39m PaddingStrategy[38;5;241m.[39mDO_NOT_PAD</p><p><span style="color:green">   (...)</span></p><p><span style="color:green"><b>   2746</b></span>     [38;5;129;01mand[39;00m (max_length [38;5;241m%[39m pad_to_multiple_of [38;5;241m!=[39m [38;5;241m0[39m)</p><p><span style="color:green"><b>   2747</b></span> ):</p><p></p><p><span style="color:red">ValueError</span>: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.</p></pre>
						</div>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">We see that it has given us an error, it tells us that the tokenizer does not have a padding token. Most LLMs do not have a padding token, but to use the <code><b>transformers</b></code> library a padding token is necessary, so what is usually done is to assign the end-of-statement token to the padding token.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Now we can generate the tokens</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">tokens_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokens_input</span><span>.</span><span style="color: #6b97e8;">input_ids</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>tensor([[2879, 4835, 3760,  225,   72,   73]], device='cuda:0')</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Now we pass them to the model that will generate the new tokens, for that we use the <code><b>generate</b></code> method</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">tokens_output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">tokens_input</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_length</span><span>=</span><span style="color: #7e7a38;">50</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;input tokens: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">tokens_input</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;output tokens: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">tokens_output</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>input tokens: tensor([[2879, 4835, 3760,  225,   72,   73]], device='cuda:0')</p><p>output tokens: tensor([[ 2879,  4835,  3760,   225,    72,    73,   314,  2533,    16,   287,</p><p>           225,    73,    82,   513,  1086,   225,    72,    73,   314,   288,</p><p>           357, 15550,    16,   287,   225,    73,    87,   288,   225,    73,</p><p>            82,   291,  3500,    16,   225,    73,    87,   348,   929,   225,</p><p>            72,    73,  3760,   225,    72,    73,   314,  2533,    18,   203]],</p><p>       device='cuda:0')</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">We can see that the first tokens of <code><b>token_inputs</b></code> are the same as those of <code><b>token_outputs</b></code>, the following tokens are those generated by the model</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Now we have to convert those tokens to a statement using the tokenizer decoder</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokens_output</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>'Me encanta aprender de los demás, y en este caso de los que me rodean, y es que en el fondo, es una forma de aprender de los demás.\n'</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">We already have the generated text</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Text-classification">
						<a class="anchor-link" href="#Text-classification">
							<p style="margin-left: 20px">Text classification</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">We create the model and the tokenizer</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">import</span> <span style="color: #4fcd7d;">torch</span></p>
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForSequenceClassification</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;stevhliu/my_awesome_model&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForSequenceClassification</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;stevhliu/my_awesome_model&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">We generate tokens</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">text</span> <span>=</span> <span style="color: #7e7a34;">&quot;This was a masterpiece. Not completely faithful to the books, but enthralling from beginning to end. Might be my favorite of the three.&quot;</span></p>
<p><span style="color: #6b97e8;">inputs</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">text</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Once we have the tokens, we classify</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #a04cc1;">with</span> <span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">no_grad</span><span style="color: #e3e11d;">():</span></p>
<p>    <span style="color: #6b97e8;">logits</span> <span>=</span> <span style="color: #6b97e8;">model</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">inputs</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">logits</span></p>
<p></p>
<p><span style="color: #6b97e8;">predicted_class_id</span> <span>=</span> <span style="color: #6b97e8;">logits</span><span>.</span><span style="color: #6b97e8;">argmax</span><span style="color: #e3e11d;">()</span><span>.</span><span style="color: #6b97e8;">item</span><span style="color: #e3e11d;">()</span></p>
<p><span style="color: #6b97e8;">prediction</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">config</span><span>.</span><span style="color: #6b97e8;">id2label</span><span style="color: #e3e11d;">[</span><span style="color: #6b97e8;">predicted_class_id</span><span style="color: #e3e11d;">]</span></p>
<p><span style="color: #6b97e8;">prediction</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>'LABEL_1'</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Let's take a look at the classes</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">clases</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">config</span><span>.</span><span style="color: #6b97e8;">id2label</span></p>
<p><span style="color: #6b97e8;">clases</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>{0: 'LABEL_0', 1: 'LABEL_1'}</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">This way there is no one to find out, so we modify it.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">config</span><span>.</span><span style="color: #6b97e8;">id2label</span> <span>=</span> <span style="color: #e3e11d;">{</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;NEGATIVE&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;POSITIVE&quot;</span><span style="color: #e3e11d;">}</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">And now we go back to sorting</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #a04cc1;">with</span> <span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">no_grad</span><span style="color: #e3e11d;">():</span></p>
<p>    <span style="color: #6b97e8;">logits</span> <span>=</span> <span style="color: #6b97e8;">model</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">inputs</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">logits</span></p>
<p></p>
<p><span style="color: #6b97e8;">predicted_class_id</span> <span>=</span> <span style="color: #6b97e8;">logits</span><span>.</span><span style="color: #6b97e8;">argmax</span><span style="color: #e3e11d;">()</span><span>.</span><span style="color: #6b97e8;">item</span><span style="color: #e3e11d;">()</span></p>
<p><span style="color: #6b97e8;">prediction</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">config</span><span>.</span><span style="color: #6b97e8;">id2label</span><span style="color: #e3e11d;">[</span><span style="color: #6b97e8;">predicted_class_id</span><span style="color: #e3e11d;">]</span></p>
<p><span style="color: #6b97e8;">prediction</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>'POSITIVE'</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Classification-of-tokens">
						<a class="anchor-link" href="#Classification-of-tokens">
							<p style="margin-left: 20px">Classification of tokens</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">We create the model and the tokenizer</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">import</span> <span style="color: #4fcd7d;">torch</span></p>
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForTokenClassification</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;stevhliu/my_awesome_wnut_model&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForTokenClassification</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;stevhliu/my_awesome_wnut_model&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">We generate tokens</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">text</span> <span>=</span> <span style="color: #7e7a34;">&quot;The Golden State Warriors are an American professional basketball team based in San Francisco.&quot;</span></p>
<p><span style="color: #6b97e8;">inputs</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">text</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Once we have the tokens, we classify</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #a04cc1;">with</span> <span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">no_grad</span><span style="color: #e3e11d;">():</span></p>
<p>    <span style="color: #6b97e8;">logits</span> <span>=</span> <span style="color: #6b97e8;">model</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">inputs</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">logits</span></p>
<p></p>
<p><span style="color: #6b97e8;">predictions</span> <span>=</span> <span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">argmax</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">logits</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">dim</span><span>=</span><span style="color: #7e7a38;">2</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">predicted_token_class</span> <span>=</span> <span style="color: #e3e11d;">[</span><span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">config</span><span>.</span><span style="color: #6b97e8;">id2label</span><span style="color: #e3e11d;">[</span><span style="color: #6b97e8;">t</span><span>.</span><span style="color: #6b97e8;">item</span><span style="color: #e3e11d;">()]</span> <span style="color: #a04cc1;">for</span> <span style="color: #6b97e8;">t</span> <span style="color: #7f6e38;">in</span> <span style="color: #6b97e8;">predictions</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">]]</span></p>
<p><span style="color: #a04cc1;">for</span> <span style="color: #6b97e8;">i</span> <span style="color: #7f6e38;">in</span> <span style="color: #dfd84a;">range</span><span style="color: #e3e11d;">(</span><span style="color: #dfd84a;">len</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">inputs</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">])):</span></p>
<p>    <span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;</span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">inputs</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">][</span><span style="color: #6b97e8;">i</span><span style="color: #e3e11d;">]</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;"> (</span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">([</span><span style="color: #6b97e8;">inputs</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">][</span><span style="color: #6b97e8;">i</span><span style="color: #e3e11d;">]])</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">) -&gt; </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">predicted_token_class</span><span style="color: #e3e11d;">[</span><span style="color: #6b97e8;">i</span><span style="color: #e3e11d;">]</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>101 ([CLS]) -&gt; O</p><p>1996 (the) -&gt; O</p><p>3585 (golden) -&gt; B-location</p><p>2110 (state) -&gt; I-location</p><p>6424 (warriors) -&gt; B-group</p><p>2024 (are) -&gt; O</p><p>2019 (an) -&gt; O</p><p>2137 (american) -&gt; O</p><p>2658 (professional) -&gt; O</p><p>3455 (basketball) -&gt; O</p><p>2136 (team) -&gt; O</p><p>2241 (based) -&gt; O</p><p>1999 (in) -&gt; O</p><p>2624 (san) -&gt; B-location</p><p>3799 (francisco) -&gt; B-location</p><p>1012 (.) -&gt; O</p><p>102 ([SEP]) -&gt; O</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">As you can see the tokens corresponding to <code><b>golden</b></code>, <code><b>state</b></code>, <code><b>warriors</b></code>, <code><b>san</b></code> and <code><b>francisco</b></code> have been classified as location tokens.</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Question-answering">
						<a class="anchor-link" href="#Question-answering">
							<p style="margin-left: 20px">Question answering</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">We create the model and the tokenizer</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">import</span> <span style="color: #4fcd7d;">torch</span></p>
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForQuestionAnswering</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;mrm8488/roberta-base-1B-1-finetuned-squadv1&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForQuestionAnswering</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;mrm8488/roberta-base-1B-1-finetuned-squadv1&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Some weights of the model checkpoint at mrm8488/roberta-base-1B-1-finetuned-squadv1 were not used when initializing RobertaForQuestionAnswering: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']</p><p>- This IS expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).</p><p>- This IS NOT expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">We generate tokens</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">question</span> <span>=</span> <span style="color: #7e7a34;">&quot;How many programming languages does BLOOM support?&quot;</span></p>
<p><span style="color: #6b97e8;">context</span> <span>=</span> <span style="color: #7e7a34;">&quot;BLOOM has 176 billion parameters and can generate text in 46 languages natural languages and 13 programming languages.&quot;</span></p>
<p><span style="color: #6b97e8;">inputs</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">question</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">context</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Once we have the tokens, we classify</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #a04cc1;">with</span> <span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">no_grad</span><span style="color: #e3e11d;">():</span></p>
<p>    <span style="color: #6b97e8;">outputs</span> <span>=</span> <span style="color: #6b97e8;">model</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">inputs</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">answer_start_index</span> <span>=</span> <span style="color: #6b97e8;">outputs</span><span>.</span><span style="color: #6b97e8;">start_logits</span><span>.</span><span style="color: #6b97e8;">argmax</span><span style="color: #e3e11d;">()</span></p>
<p><span style="color: #6b97e8;">answer_end_index</span> <span>=</span> <span style="color: #6b97e8;">outputs</span><span>.</span><span style="color: #6b97e8;">end_logits</span><span>.</span><span style="color: #6b97e8;">argmax</span><span style="color: #e3e11d;">()</span></p>
<p></p>
<p><span style="color: #6b97e8;">predict_answer_tokens</span> <span>=</span> <span style="color: #6b97e8;">inputs</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">answer_start_index</span> <span style="color: #e3e11d;">:</span> <span style="color: #6b97e8;">answer_end_index</span> <span>+</span> <span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">]</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">predict_answer_tokens</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>' 13'</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Masked-language-modeling-(Masked-language-modeling)">
						<a class="anchor-link" href="#Masked-language-modeling-(Masked-language-modeling)">
							<p style="margin-left: 20px">Masked language modeling (Masked language modeling)</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">We create the model and the tokenizer</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">import</span> <span style="color: #4fcd7d;">torch</span></p>
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForMaskedLM</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;nyu-mll/roberta-base-1B-1&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForMaskedLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;nyu-mll/roberta-base-1B-1&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Some weights of the model checkpoint at nyu-mll/roberta-base-1B-1 were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']</p><p>- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).</p><p>- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">We generate tokens</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">text</span> <span>=</span> <span style="color: #7e7a34;">&quot;The Milky Way is a &lt;mask&gt; galaxy.&quot;</span></p>
<p><span style="color: #6b97e8;">inputs</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">text</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">mask_token_index</span> <span>=</span> <span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">where</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">inputs</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a34;">&quot;input_ids&quot;</span><span style="color: #e3e11d;">]</span> <span>==</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">mask_token_id</span><span style="color: #e3e11d;">)[</span><span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">]</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Once we have the tokens, we classify</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #a04cc1;">with</span> <span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">no_grad</span><span style="color: #e3e11d;">():</span></p>
<p>    <span style="color: #6b97e8;">logits</span> <span>=</span> <span style="color: #6b97e8;">model</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">inputs</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">logits</span></p>
<p>    <span style="color: #6b97e8;">mask_token_logits</span> <span>=</span> <span style="color: #6b97e8;">logits</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">mask_token_index</span><span style="color: #e3e11d;">,</span> <span style="color: #e3e11d;">:]</span></p>
<p></p>
<p><span style="color: #6b97e8;">top_3_tokens</span> <span>=</span> <span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">topk</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">mask_token_logits</span><span style="color: #e3e11d;">,</span> <span style="color: #7e7a38;">3</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">dim</span><span>=</span><span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">indices</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">]</span><span>.</span><span style="color: #6b97e8;">tolist</span><span style="color: #e3e11d;">()</span></p>
<p><span style="color: #a04cc1;">for</span> <span style="color: #6b97e8;">token</span> <span style="color: #7f6e38;">in</span> <span style="color: #6b97e8;">top_3_tokens</span><span style="color: #e3e11d;">:</span></p>
<p>    <span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">text</span><span>.</span><span style="color: #6b97e8;">replace</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">mask_token</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">([</span><span style="color: #6b97e8;">token</span><span style="color: #e3e11d;">])))</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>The Milky Way is a  spiral galaxy.</p><p>The Milky Way is a  closed galaxy.</p><p>The Milky Way is a  distant galaxy.</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h2 id="Model-customization">
						<a class="anchor-link" href="#Model-customization">
							<p style="margin-left: 10px">Model customization</p>
						</a>
					</h2>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Earlier we have done the inference with <code><b>AutoClass</b></code>, but we have done it with the default model settings. But we can configure the model as much as we like</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Let's instantiate a model and see its configuration</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoConfig</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">config</span> <span>=</span> <span style="color: #6b97e8;">AutoConfig</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">config</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>GPT2Config {</p><p>  "_name_or_path": "flax-community/gpt-2-spanish",</p><p>  "activation_function": "gelu_new",</p><p>  "architectures": [</p><p>    "GPT2LMHeadModel"</p><p>  ],</p><p>  "attn_pdrop": 0.0,</p><p>  "bos_token_id": 50256,</p><p>  "embd_pdrop": 0.0,</p><p>  "eos_token_id": 50256,</p><p>  "gradient_checkpointing": false,</p><p>  "initializer_range": 0.02,</p><p>  "layer_norm_epsilon": 1e-05,</p><p>  "model_type": "gpt2",</p><p>  "n_ctx": 1024,</p><p>  "n_embd": 768,</p><p>  "n_head": 12,</p><p>  "n_inner": null,</p><p>  "n_layer": 12,</p><p>  "n_positions": 1024,</p><p>  "reorder_and_upcast_attn": false,</p><p>  "resid_pdrop": 0.0,</p><p>  "scale_attn_by_inverse_layer_idx": false,</p><p>  "scale_attn_weights": true,</p><p>  "summary_activation": null,</p><p>  "summary_first_dropout": 0.1,</p><p>  "summary_proj_to_labels": true,</p><p>  "summary_type": "cls_index",</p><p>  "summary_use_proj": true,</p><p>  "task_specific_params": {</p><p>    "text-generation": {</p><p>      "do_sample": true,</p><p>      "max_length": 50</p><p>    }</p><p>  },</p><p>  "transformers_version": "4.38.1",</p><p>  "use_cache": true,</p><p>  "vocab_size": 50257</p><p>}</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">We can see the model configuration, for example the activation function is <code><b>gelu_new</b></code>, it has 12 <code><b>head</b></code>s, the vocabulary size is 50257 words, etc.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">But we can modify this configuration</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">config</span> <span>=</span> <span style="color: #6b97e8;">AutoConfig</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">activation_function</span><span>=</span><span style="color: #7e7a34;">&quot;relu&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">config</span><span>.</span><span style="color: #6b97e8;">activation_function</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>'relu'</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">We now create the model with this configuration</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">config</span><span>=</span><span style="color: #6b97e8;">config</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">And we generate text</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p><span style="color: #6b97e8;">tokens_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokens_output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">tokens_input</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_length</span><span>=</span><span style="color: #7e7a38;">50</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokens_output</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>'Me encanta aprender de la d d e d e d e d e d e d e d e d e d e d e '</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">We see that this modification does not generate as good text.</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h2 id="Tokenization">
						<a class="anchor-link" href="#Tokenization">
							<p style="margin-left: 10px">Tokenization</p>
						</a>
					</h2>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">So far we have seen the different ways to do inference with the <code><b>transformers</b></code> library. Now we are going to get into the guts of the library. To do this we are first going to look at things to keep in mind when tokenizing.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">We are not going to explain what tokenizing is in depth, since we have already explained it in the post on the [tokenizers] library (https://maximofn.com/hugging-face-tokenizers/).</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Padding">
						<a class="anchor-link" href="#Padding">
							<p style="margin-left: 20px">Padding</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">When you have a batch of sequences, sometimes it is necessary that after tokenizing, all the sequences have the same length, so for this we use the <code><b>padding=True</b></code> parameter.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span></p>
<p></p>
<p><span style="color: #6b97e8;">batch_sentences</span> <span>=</span> <span style="color: #e3e11d;">[</span></p>
<p>    <span style="color: #7e7a34;">&quot;Pero, ¿qué pasa con el segundo desayuno?&quot;</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #7e7a34;">&quot;No creo que sepa lo del segundo desayuno, Pedro&quot;</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #7e7a34;">&quot;¿Qué hay de los elevensies?&quot;</span><span style="color: #e3e11d;">,</span></p>
<p><span style="color: #e3e11d;">]</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">pad_token</span><span>=</span><span style="color: #7e7a34;">&quot;PAD&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">encoded_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">batch_sentences</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #a04cc1;">for</span> <span style="color: #6b97e8;">encoded</span> <span style="color: #7f6e38;">in</span> <span style="color: #6b97e8;">encoded_input</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a34;">&quot;input_ids&quot;</span><span style="color: #e3e11d;">]:</span></p>
<p>    <span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">encoded</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;Padding token id: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token_id</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>[2959, 16, 875, 3736, 3028, 303, 291, 2200, 8080, 35, 50257, 50257]</p><p>[1489, 2275, 288, 12052, 382, 325, 2200, 8080, 16, 4319, 50257, 50257]</p><p>[1699, 2899, 707, 225, 72, 73, 314, 34630, 474, 515, 1259, 35]</p><p>Padding token id: 50257</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">As we can see, he has added paddings to the first two sequences at the end.</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Truncated">
						<a class="anchor-link" href="#Truncated">
							<p style="margin-left: 20px">Truncated</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Besides adding padding, sometimes it is necessary to truncate the sequences so that they do not occupy more than a certain number of tokens. To do this we set <code><b>truncation=True</b></code> and <code><b>max_length</b></code> to the number of tokens we want the sequence to have.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span></p>
<p></p>
<p><span style="color: #6b97e8;">batch_sentences</span> <span>=</span> <span style="color: #e3e11d;">[</span></p>
<p>    <span style="color: #7e7a34;">&quot;Pero, ¿qué pasa con el segundo desayuno?&quot;</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #7e7a34;">&quot;No creo que sepa lo del segundo desayuno, Pedro&quot;</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #7e7a34;">&quot;¿Qué hay de los elevensies?&quot;</span><span style="color: #e3e11d;">,</span></p>
<p><span style="color: #e3e11d;">]</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">encoded_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">batch_sentences</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">truncation</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_length</span><span>=</span><span style="color: #7e7a38;">5</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #a04cc1;">for</span> <span style="color: #6b97e8;">encoded</span> <span style="color: #7f6e38;">in</span> <span style="color: #6b97e8;">encoded_input</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a34;">&quot;input_ids&quot;</span><span style="color: #e3e11d;">]:</span></p>
<p>    <span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">encoded</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>[2959, 16, 875, 3736, 3028]</p><p>[1489, 2275, 288, 12052, 382]</p><p>[1699, 2899, 707, 225, 72]</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Same sentences as before, now generate fewer tokens</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Tensors">
						<a class="anchor-link" href="#Tensors">
							<p style="margin-left: 20px">Tensors</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Until now we were receiving lists of tokens, but surely we are interested in receiving tensors from PyTorch or TensorFlow. For this we use the parameter <code><b>return_tensors</b></code> and we specify from which framework we want to receive the tensor, in our case we will choose PyTorch with <code><b>pt</b></code>.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">We first see without specifying that we return tensors</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span></p>
<p></p>
<p><span style="color: #6b97e8;">batch_sentences</span> <span>=</span> <span style="color: #e3e11d;">[</span></p>
<p>    <span style="color: #7e7a34;">&quot;Pero, ¿qué pasa con el segundo desayuno?&quot;</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #7e7a34;">&quot;No creo que sepa lo del segundo desayuno, Pedro&quot;</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #7e7a34;">&quot;¿Qué hay de los elevensies?&quot;</span><span style="color: #e3e11d;">,</span></p>
<p><span style="color: #e3e11d;">]</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">pad_token</span><span>=</span><span style="color: #7e7a34;">&quot;PAD&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">encoded_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">batch_sentences</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #a04cc1;">for</span> <span style="color: #6b97e8;">encoded</span> <span style="color: #7f6e38;">in</span> <span style="color: #6b97e8;">encoded_input</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a34;">&quot;input_ids&quot;</span><span style="color: #e3e11d;">]:</span></p>
<p>    <span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #dfd84a;">type</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">encoded</span><span style="color: #e3e11d;">))</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>&lt;class 'list'&gt;</p><p>&lt;class 'list'&gt;</p><p>&lt;class 'list'&gt;</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">We receive lists, if we want to receive tensors from PyTorch we use <code><b>return_tensors="pt"</b></code>.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span></p>
<p></p>
<p><span style="color: #6b97e8;">batch_sentences</span> <span>=</span> <span style="color: #e3e11d;">[</span></p>
<p>    <span style="color: #7e7a34;">&quot;Pero, ¿qué pasa con el segundo desayuno?&quot;</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #7e7a34;">&quot;No creo que sepa lo del segundo desayuno, Pedro&quot;</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #7e7a34;">&quot;¿Qué hay de los elevensies?&quot;</span><span style="color: #e3e11d;">,</span></p>
<p><span style="color: #e3e11d;">]</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">pad_token</span><span>=</span><span style="color: #7e7a34;">&quot;PAD&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">encoded_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">batch_sentences</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #a04cc1;">for</span> <span style="color: #6b97e8;">encoded</span> <span style="color: #7f6e38;">in</span> <span style="color: #6b97e8;">encoded_input</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a34;">&quot;input_ids&quot;</span><span style="color: #e3e11d;">]:</span></p>
<p>    <span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #dfd84a;">type</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">encoded</span><span style="color: #e3e11d;">),</span> <span style="color: #6b97e8;">encoded</span><span>.</span><span style="color: #6b97e8;">shape</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #dfd84a;">type</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">encoded_input</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a34;">&quot;input_ids&quot;</span><span style="color: #e3e11d;">]),</span> <span style="color: #6b97e8;">encoded_input</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a34;">&quot;input_ids&quot;</span><span style="color: #e3e11d;">]</span><span>.</span><span style="color: #6b97e8;">shape</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>&lt;class 'torch.Tensor'&gt; torch.Size([12])</p><p>&lt;class 'torch.Tensor'&gt; torch.Size([12])</p><p>&lt;class 'torch.Tensor'&gt; torch.Size([12])</p><p>&lt;class 'torch.Tensor'&gt; torch.Size([3, 12])</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Masks">
						<a class="anchor-link" href="#Masks">
							<p style="margin-left: 20px">Masks</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">When we tokenize a statement we not only get the <code><b>input_ids</b></code>, but we also get the attention mask. The attention mask is a tensor that has the same size as <code><b>input_ids</b></code> and has a <code><b>1</b></code> in the positions that are tokens and a <code><b>0</b></code> in the positions that are padding.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span></p>
<p></p>
<p><span style="color: #6b97e8;">batch_sentences</span> <span>=</span> <span style="color: #e3e11d;">[</span></p>
<p>    <span style="color: #7e7a34;">&quot;Pero, ¿qué pasa con el segundo desayuno?&quot;</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #7e7a34;">&quot;No creo que sepa lo del segundo desayuno, Pedro&quot;</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #7e7a34;">&quot;¿Qué hay de los elevensies?&quot;</span><span style="color: #e3e11d;">,</span></p>
<p><span style="color: #e3e11d;">]</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">pad_token</span><span>=</span><span style="color: #7e7a34;">&quot;PAD&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">encoded_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">batch_sentences</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;padding token id: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token_id</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;</span><span style="color: #a6a831;">\n</span><span style="color: #7e7a34;">encoded_input[0] inputs_ids: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">encoded_input</span><span style="color: #e3e11d;">[</span><span style="color: #8d783e;">&#39;input_ids&#39;</span><span style="color: #e3e11d;">][</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">]</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;encoded_input[0] attention_mask: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">encoded_input</span><span style="color: #e3e11d;">[</span><span style="color: #8d783e;">&#39;attention_mask&#39;</span><span style="color: #e3e11d;">][</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">]</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;</span><span style="color: #a6a831;">\n</span><span style="color: #7e7a34;">encoded_input[1] inputs_ids: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">encoded_input</span><span style="color: #e3e11d;">[</span><span style="color: #8d783e;">&#39;input_ids&#39;</span><span style="color: #e3e11d;">][</span><span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">]</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;encoded_input[1] attention_mask: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">encoded_input</span><span style="color: #e3e11d;">[</span><span style="color: #8d783e;">&#39;attention_mask&#39;</span><span style="color: #e3e11d;">][</span><span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">]</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;</span><span style="color: #a6a831;">\n</span><span style="color: #7e7a34;">encoded_input[2] inputs_ids: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">encoded_input</span><span style="color: #e3e11d;">[</span><span style="color: #8d783e;">&#39;input_ids&#39;</span><span style="color: #e3e11d;">][</span><span style="color: #7e7a38;">2</span><span style="color: #e3e11d;">]</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;encoded_input[2] attention_mask: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">encoded_input</span><span style="color: #e3e11d;">[</span><span style="color: #8d783e;">&#39;attention_mask&#39;</span><span style="color: #e3e11d;">][</span><span style="color: #7e7a38;">2</span><span style="color: #e3e11d;">]</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>padding token id: 50257</p><p>encoded_input[0] inputs_ids: [2959, 16, 875, 3736, 3028, 303, 291, 2200, 8080, 35, 50257, 50257]</p><p>encoded_input[0] attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]</p><p>encoded_input[1] inputs_ids: [1489, 2275, 288, 12052, 382, 325, 2200, 8080, 16, 4319, 50257, 50257]</p><p>encoded_input[1] attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]</p><p>encoded_input[2] inputs_ids: [1699, 2899, 707, 225, 72, 73, 314, 34630, 474, 515, 1259, 35]</p><p>encoded_input[2] attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">As you can see, in the first two sentences, we have a 1 in the first positions and a 0 in the last two positions. In those same positions we have the token <code><b>50257</b></code>, which corresponds to the padding token.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">With these attention masks we are telling the model which tokens to pay attention to and which not to pay attention to.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Text generation could still be done if we did not pass these attention masks, the <code><b>generate</b></code> method would do its best to infer this mask, but if we pass it we help to generate better text.</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h2 id="Fast-Tokenizers">
						<a class="anchor-link" href="#Fast-Tokenizers">
							<p style="margin-left: 10px">Fast Tokenizers</p>
						</a>
					</h2>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Some pretrained tokenizers have a <code><b>fast</b></code> version, they have the same methods as the normal ones, only they are developed in Rust. To use them we must use the <code><b>PreTrainedTokenizerFast</b></code> class of the <code><b>transformers</b></code> library.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Let us first look at the tokenization time with a normal tokenizer.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span>%%</span><span style="color: #6b97e8;">time</span></p>
<p></p>
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">BertTokenizer</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">BertTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;google-bert/bert-base-uncased&quot;</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">sentence</span> <span>=</span> <span style="color: #e3e11d;">(</span></p>
<p>    <span style="color: #7e7a34;">&quot;The Permaculture Design Principles are a set of universal design principles &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;that can be applied to any location, climate and culture, and they allow us to design &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;the most efficient and sustainable human habitation and food production systems. &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;Permaculture is a design system that encompasses a wide variety of disciplines, such &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;as ecology, landscape design, environmental science and energy conservation, and the &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;Permaculture design principles are drawn from these various disciplines. Each individual &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;design principle itself embodies a complete conceptual framework based on sound &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;scientific principles. When we bring all these separate  principles together, we can &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;create a design system that both looks at whole systems, the parts that these systems &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;consist of, and how those parts interact with each other to create a complex, dynamic, &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;living system. Each design principle serves as a tool that allows us to integrate all &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;the separate parts of a design, referred to as elements, into a functional, synergistic, &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;whole system, where the elements harmoniously interact and work together in the most &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;efficient way possible.&quot;</span></p>
<p><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokens</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #6b97e8;">sentence</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>CPU times: user 55.3 ms, sys: 8.58 ms, total: 63.9 ms</p><p>Wall time: 226 ms</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">And now with a quick one</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span>%%</span><span style="color: #6b97e8;">time</span></p>
<p></p>
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">BertTokenizerFast</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">BertTokenizerFast</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;google-bert/bert-base-uncased&quot;</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">sentence</span> <span>=</span> <span style="color: #e3e11d;">(</span></p>
<p>    <span style="color: #7e7a34;">&quot;The Permaculture Design Principles are a set of universal design principles &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;that can be applied to any location, climate and culture, and they allow us to design &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;the most efficient and sustainable human habitation and food production systems. &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;Permaculture is a design system that encompasses a wide variety of disciplines, such &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;as ecology, landscape design, environmental science and energy conservation, and the &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;Permaculture design principles are drawn from these various disciplines. Each individual &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;design principle itself embodies a complete conceptual framework based on sound &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;scientific principles. When we bring all these separate  principles together, we can &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;create a design system that both looks at whole systems, the parts that these systems &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;consist of, and how those parts interact with each other to create a complex, dynamic, &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;living system. Each design principle serves as a tool that allows us to integrate all &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;the separate parts of a design, referred to as elements, into a functional, synergistic, &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;whole system, where the elements harmoniously interact and work together in the most &quot;</span></p>
<p>    <span style="color: #7e7a34;">&quot;efficient way possible.&quot;</span></p>
<p><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokens</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #6b97e8;">sentence</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>CPU times: user 42.6 ms, sys: 3.26 ms, total: 45.8 ms</p><p>Wall time: 179 ms</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">You can see how the <code><b>BertTokenizerFast</b></code> is about 40 ms faster.</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h2 id="Text-generation-forms">
						<a class="anchor-link" href="#Text-generation-forms">
							<p style="margin-left: 10px">Text generation forms</p>
						</a>
					</h2>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">We continue with the guts of the <code><b>transformers</b></code> library, now we are going to see the ways to generate text.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">The transformer architecture generates the next most likely token, this is the simplest way to generate text, but it is not the only one, so let's look at them.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">When it comes to generating textno there is no best way and it will depend on our model and the purpose of use.</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Greedy-Search">
						<a class="anchor-link" href="#Greedy-Search">
							<p style="margin-left: 20px">Greedy Search</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">It is the simplest way of text generation. It looks for the most probable token in each iteration.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"><p align="center"><img src="http://maximofn.com/wp-content/uploads/2024/03/greedy_search.webp" alt="greedy_search"></p></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">To generate text in this way with <code><b>transformers</b></code> you don't have to do anything special, as it is the default way.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokens_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokens_output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">tokens_input</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_new_tokens</span><span>=</span><span style="color: #7e7a38;">500</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokens_output</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">sentence_output</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Me encanta aprender de los demás, y en este caso de los que me rodean, y es que en el fondo, es una forma de aprender de los demás.</p><p>En este caso, el objetivo de la actividad es que los niños aprendan a reconocer los diferentes tipos de animales que existen en el mundo, y que en ocasiones, son muy difíciles de reconocer.</p><p>En este caso, los niños se han dado cuenta de que los animales que hay en el mundo, son muy difíciles de reconocer, y que en ocasiones, son muy difíciles de reconocer.</p><p>En este caso, los niños han aprendido a reconocer los diferentes tipos de animales que existen en el mundo, y que en ocasiones, son muy difíciles de reconocer.</p><p>En este caso, los niños han aprendido a reconocer los diferentes tipos de animales que existen en el mundo, y que en ocasiones, son muy difíciles de reconocer.</p><p>En este caso, los niños han aprendido a reconocer los diferentes tipos de animales que existen en el mundo, y que en ocasiones, son muy difíciles de reconocer.</p><p>En este caso, los niños han aprendido a reconocer los diferentes tipos de animales que existen en el mundo, y que en ocasiones, son muy difíciles de reconocer.</p><p>En este caso, los niños han aprendido a reconocer los diferentes tipos de animales que existen en el mundo, y que en ocasiones, son muy difíciles de reconocer.</p><p>En este caso, los niños han aprendido a reconocer los diferentes tipos de animales que existen en el mundo, y que en ocasiones, son muy difíciles de reconocer.</p><p>En este caso, los niños han aprendido a reconocer los diferentes tipos de animales que existen en el mundo, y que en ocasiones, son muy difíciles de reconocer.</p><p>En este caso, los niños han aprendido a reconocer los diferentes tipos de animales que existen en el mundo, y que en ocasiones, son muy difíciles de reconocer.</p><p>En este caso, los niños han aprendido a reconocer los diferentes tipos de animales que existen en el mundo, y que e</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">You can see that the generated text is fine, but it starts to repeat. This is because in greedy search, words with a high probability can hide behind words with a lower probability, so they can get lost.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"><p align="center"><img src="http://maximofn.com/wp-content/uploads/2024/03/greedy_search.webp" alt="greedy_search"></p></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Here, the word <code><b>has</b></code> has a high probability, but is hidden behind <code><b>dog</b></code>, which has a lower probability than <code><b>nice</b></code>.</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Contrastive-Search">
						<a class="anchor-link" href="#Contrastive-Search">
							<p style="margin-left: 20px">Contrastive Search</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">The Contrastive Search method optimizes text generation by selecting word or phrase options that maximize a quality criterion over less desirable ones. In practice, this means that during text generation, at each step, the model not only searches for the next word that is most likely to follow as learned during its training, but also compares different candidates for that next word and evaluates which of them would contribute to form the most coherent, relevant and high quality text in the given context. Therefore, Contrastive Search reduces the possibility of generating irrelevant or low-quality responses by focusing on those options that best fit the text generation goal, based on a direct comparison between possible continuations at each step of the process.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">To generate text with contrastive search in <code><b>transformers</b></code> you have to use <code><b>penalty_alpha</b></code> and <code><b>top_k</b></code> parameters when generating text.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokens_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokens_output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">tokens_input</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_new_tokens</span><span>=</span><span style="color: #7e7a38;">500</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">penalty_alpha</span><span>=</span><span style="color: #a09e19;">0.6</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">top_k</span><span>=</span><span style="color: #7e7a38;">4</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokens_output</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">sentence_output</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Me encanta aprender de los demás, es una de las cosas que más me gusta del mundo.</p><p>En la clase de hoy he estado haciendo un repaso de lo que es el arte de la costura, para que podáis ver como se hace una prenda de ropa y como se confeccionan los patrones.</p><p>El patrón de esta blusa es de mi amiga Marga, que me ha pedido que os enseñara a hacer este tipo de prendas, ya que es una de las cosas que más me gusta del mundo.</p><p>La blusa es de la talla S, y tiene un largo de manga 3/4, por lo que es ideal para cualquier ocasión.</p><p>Para hacer el patrón de esta blusa utilicé una tela de algodón 100% de color azul marino, que es la que yo he utilizado para hacer la blusa.</p><p>En la parte delantera de la blusa, cosí un lazo de raso de color azul marino, que le da un toque de color a la prenda.</p><p>Como podéis ver en la foto, el patrón de esta blusa es de la talla S, y tiene un largo de manga 3/4, por lo que es ideal para cualquier ocasión.</p><p>Para hacer el patrón de esta blusa utilicé una tela de algodón 100% de color azul marino, que es la que yo he utilizado para hacer la blusa.</p><p>En la parte delantera de la blusa utilicé un lazo de raso de color azul marino, que le da un toque de color a la prenda.</p><p>Para hacer el patrón de esta blusa utilicé una tela de algodón 100% de color azul marino, que es la que yo he utilizado para hacer la blusa.</p><p>En la parte delantera de la blusa utilicé un lazo de raso de color azul marino, que le da un toque de color a la prenda.</p><p>Para hacer el patrón de esta blusa utilicé una tela de algodón 100% de color azul marino, que es la que yo he utilizado para hacer la blusa.</p><p>En la parte delantera de la blusa utilicé</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Here the pattern takes longer to start to repeat itself</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Multinomial-sampling">
						<a class="anchor-link" href="#Multinomial-sampling">
							<p style="margin-left: 20px">Multinomial sampling</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Unlike greedy search that always chooses a token with the highest probability as the next token, multinomial sampling (also called ancestral sampling) randomly selects the next token based on the probability distribution of the entire vocabulary provided by the model. Each token with a non-zero probability has a chance of being selected, which reduces the risk of repetition.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">To enable <code><b>Multinomial sampling</b></code> you have to set <code><b>do_sample=True</b></code> and <code><b>num_beams=1</b></code>.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokens_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokens_output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">tokens_input</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_new_tokens</span><span>=</span><span style="color: #7e7a38;">500</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">do_sample</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">num_beams</span><span>=</span><span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokens_output</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">sentence_output</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Me encanta aprender de los de siempre y conocer a gente nueva, soy de las que no tiene mucho contacto con los de antes, pero he estado bastante liada con el diseño de mi página web de lo que sería el logo, he escrito varios diseños para otros blogs y cosas así, así que a ver si pronto puedo poner de mi parte alguna ayuda.</p><p>A finales de los años 70 del pasado siglo los arquitectos alemanes Hermann Grossberg y Heinrich Rindsner eran los principales representantes de la arquitectura industrial de la alta sociedad. La arquitectura industrial era la actividad que más rápido progresaba en el diseño, y de ellos destacaban los diseños que Grossberg llevó a cabo en el prestigioso Hotel Marigal.</p><p>De acuerdo con las conclusiones y opiniones expuestas por los autores sobre el reciente congreso sobre historia del diseño industrial, se ha llegado al convencimiento de que en los últimos años, los diseñadores industriales han descubierto muchas nuevas formas de entender la arquitectura. En palabras de Klaus Eindhoven, director general de la fundación alemana G. Grossberg, “estamos tratando de desarrollar un trabajo que tenga en cuenta los criterios más significativos de la teoría arquitectónica tradicional”.</p><p>En este artículo de opinión, Eindhoven y Grossberg explican por qué el auge de la arquitectura industrial en Alemania ha generado una gran cantidad de nuevos diseños de viviendas, de grandes dimensiones, de edificios de gran valor arquitectónico. Los más conocidos son los de los diseñadores Walter Nachtmann (1934) e ingeniero industrial, Frank Gehry (1929), arquitecto que ideó las primeras viviendas de estilo neoclásico en la localidad británica de Stegmarbe. Son viviendas de los siglos XVI al XX, algunas con un estilo clasicista que recuerda las casas de Venecia. Se trata de edificios con un importante valor histórico y arquitectónico, y que representan la obra de la técnica del modernismo.</p><p>La teoría general sobre los efectos de la arquitectura en un determinado tipo de espacio no ha resultado ser totalmente transparente, y mucho menos para los arquitectos, que tienen que aprender de los arquitectos de ayer, durante esos</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">The truth is that the model does not repeat itself at all, but I feel like I'm talking to a small child, who talks about one subject and then starts spinning off with others that have nothing to do with it.</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Beam-search">
						<a class="anchor-link" href="#Beam-search">
							<p style="margin-left: 20px">Beam search</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Beam search reduces the risk of missing high probability hidden word sequences by keeping the most probable <code><b>num_beams</b></code> at each time step and finally choosing the hypothesis that has the highest overall probability.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">To generate with <code><b>beam search</b></code> it is necessary to add the parameter <code><b>num_beams</b></code>.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokens_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokens_output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">tokens_input</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_new_tokens</span><span>=</span><span style="color: #7e7a38;">500</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">num_beams</span><span>=</span><span style="color: #7e7a38;">5</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokens_output</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">sentence_output</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Me encanta aprender de los errores y aprender de los aciertos de los demás, en este caso, de los míos.</p><p>Me encanta aprender de los errores y aprender de los aciertos de los demás, en este caso, de los míos.</p><p>Me encanta aprender de los errores y aprender de los aciertos de los demás, en este caso, de los míos.</p><p>Me encanta aprender de los errores y aprender de los aciertos de los demás, en este caso, de los míos.</p><p>Me encanta aprender de los errores y aprender de los aciertos de los demás, en este caso, de los míos.</p><p>Me encanta aprender de los errores y aprender de los aciertos de los demás, en este caso, de los míos.</p><p>Me encanta aprender de los errores y aprender de los aciertos de los demás, en este caso, de los míos.</p><p>Me encanta aprender de los errores y aprender de los aciertos de los demás, en este caso, de los míos.</p><p>Me encanta aprender de los errores y aprender de los aciertos de los demás, en este caso, de los míos.</p><p>Me encanta aprender de los errores y aprender de los aciertos de los demás, en este caso, de los míos.</p><p>Me encanta aprender de los errores y aprender de los aciertos de los demás, en este caso, de los míos.</p><p>Me encanta aprender de los errores y aprender de los aciertos de los demás, en este caso, de los míos.</p><p>Me encanta aprender de los errores y aprender de los aciertos de los demás, en este caso, de los míos.</p><p>Me encanta aprender de los errores y aprender de los aciertos de los demás, en este caso, de los míos.</p><p>Me encanta aprender de los errores y aprender de los aciertos de los demás, en este caso, de</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">It repeats itself a lot</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Beam-search-multinomial-sampling">
						<a class="anchor-link" href="#Beam-search-multinomial-sampling">
							<p style="margin-left: 20px">Beam search multinomial sampling</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">This technique combines the <code><b>bean search</b></code> where a beam search and <code><b>multinomial sampling</b></code> where the next token is randomly selected based on the probability distribution of the entire vocabulary provided by the model.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokens_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokens_output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">tokens_input</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_new_tokens</span><span>=</span><span style="color: #7e7a38;">500</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">num_beams</span><span>=</span><span style="color: #7e7a38;">5</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">do_sample</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokens_output</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">sentence_output</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Me encanta aprender de los demás, en especial de las personas que me rodean, y en especial de mis compañeros de trabajo. Me encanta aprender de los demás, en especial de las personas que me rodean, y en especial de mis compañeros de trabajo. Me encanta aprender de los demás, en especial de las personas que me rodean, y en especial de mis compañeros de trabajo. Me encanta aprender de los demás, en especial de las personas que me rodean, y en especial de mis compañeros de trabajo. Me encanta aprender de los demás, en especial de las personas que me rodean, y en especial de mis compañeros de trabajo. Me encanta aprender de los demás, en especial de las personas que me rodean, y en especial de mis compañeros de trabajo. Me encanta aprender de los demás, en especial de las personas que me rodean, y en especial de mis compañeros de trabajo. Me encanta aprender de los demás, en especial de las personas que me rodean, y en especial de mis compañeros de trabajo. Me encanta aprender de los demás, en especial de las personas que me rodean, y en especial de mis compañeros de trabajo. Me encanta aprender de los demás, en especial de las personas que me rodean, y en especial de mis compañeros de trabajo. Me encanta aprender de los demás, en especial de las personas que me rodean, y en especial de mis compañeros de trabajo. Me encanta aprender de los demás, en especial de las personas que me rodean, y en especial de mis compañeros de trabajo. Me encanta aprender de los demás, en especial de las personas que me rodean, y en especial de mis compañeros de trabajo. Me encanta aprender de los demás, en especial de las personas que me rodean, y e</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">It repeats itself a lot</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Beam-search-n-grams-penalty">
						<a class="anchor-link" href="#Beam-search-n-grams-penalty">
							<p style="margin-left: 20px">Beam search n-grams penalty</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">To avoid repetition we can penalize for n-gram repetition. For this we use the parameter <code><b>no_repeat_ngram_size</b></code>.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokens_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokens_output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">tokens_input</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_new_tokens</span><span>=</span><span style="color: #7e7a38;">500</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">num_beams</span><span>=</span><span style="color: #7e7a38;">5</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">no_repeat_ngram_size</span><span>=</span><span style="color: #7e7a38;">2</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokens_output</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">sentence_output</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Me encanta aprender de los demás, y en este caso, no podía ser menos, así que me puse manos a la obra.</p><p>En primer lugar, me hice con un libro que se llama "El mundo eslavo" y que, como ya os he dicho, se puede adquirir por un módico precio (unos 5 euros).</p><p>El libro está compuesto por dos partes: la primera, que trata sobre la historia del Imperio Romano y la segunda, sobre el Imperio Bizantino. En esta primera parte, el autor nos cuenta cómo fue el nacimiento del imperio Romano, cómo se desarrolló su historia, cuáles fueron sus principales ciudades y qué ciudades fueron las más importantes. Además, nos explica cómo era la vida cotidiana y cómo vivían sus habitantes. Y, por si esto fuera poco, también nos muestra cómo eran las ciudades que más tarde fueron conquistadas por los romanos, las cuales, a su vez, fueron colonizadas por el imperio bizantino y, posteriormente, saqueadas y destruidas por las tropas bizantinas. Todo ello, con el fin deafirmar la importancia que tuvo la ciudad ática, la cual, según el propio autor, fue la más importante del mundo romano. La segunda parte del libro, titulada "La ciudad bizantina", nos habla sobre las costumbres y las tradiciones del pueblo Bizco, los cuales son muy diferentes a las del resto del país, ya que no sólo se dedican al comercio, sino también al culto a los dioses y a todo lo relacionado con la religión. Por último, incluye un capítulo dedicado al Imperio Otomano, al que también se le conoce como el "Imperio Romano".</p><p>Por otro lado, os dejo un enlace a una página web donde podréis encontrar más información sobre este libro: http://www.elmundodeuterio.com/es/libros/el-mundo-sucio-y-la-historia-del-imperio-ibero-italia/</p><p>Como podéis ver, he querido hacer un pequeño homenaje a todas las personas que han hecho posible que el libro se haya hecho realidad. Espero que os haya gustado y os animéis a adquirirlo. Si tenéis alguna duda, podéis dejarme un comentario o escribirme un correo a mi correo electrónico: [email protected]</p><p>¡Hola a todos! ¿Qué tal estáis? Hoy os traigo una entrada muy especial. Se trata del sorteo que he hecho para celebrar el día del padre. Como ya sabéis, este año no he tenido mucho tiempo, pero</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">This text no longer repeats itself and also has a little more coherence.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">However, n-gram penalties should be used with care. An article generated about New York City should not use a 2-gram penalty or else the name of the city would only appear once in the entire text!</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Beam-search-n-grams-penalty-return-sequences">
						<a class="anchor-link" href="#Beam-search-n-grams-penalty-return-sequences">
							<p style="margin-left: 20px">Beam search n-grams penalty return sequences</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">We can generate several sequences to compare them and keep the best one. For this we use the parameter <code><b>num_return_sequences</b></code> with the condition that <code><b>num_return_sequences <= num_beams</b></code>.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokens_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokens_outputs</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">tokens_input</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_new_tokens</span><span>=</span><span style="color: #7e7a38;">500</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">num_beams</span><span>=</span><span style="color: #7e7a38;">5</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">no_repeat_ngram_size</span><span>=</span><span style="color: #7e7a38;">2</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">num_return_sequences</span><span>=</span><span style="color: #7e7a38;">3</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #a04cc1;">for</span> <span style="color: #6b97e8;">i</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">tokens_output</span> <span style="color: #7f6e38;">in</span> <span style="color: #dfd84a;">enumerate</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokens_outputs</span><span style="color: #e3e11d;">):</span></p>
<p>    <span style="color: #a04cc1;">if</span> <span style="color: #6b97e8;">i</span> <span>!=</span> <span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">:</span></p>
<p>        <span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;</span><span style="color: #a6a831;">\n\n</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
<p>    <span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokens_output</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p>    <span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;</span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">i</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">sentence_output</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>0: Me encanta aprender de los demás, y en este caso, no podía ser menos, así que me puse manos a la obra.</p><p>En primer lugar, me hice con un libro que se llama "El mundo eslavo" y que, como ya os he dicho, se puede adquirir por un módico precio (unos 5 euros).</p><p>El libro está compuesto por dos partes: la primera, que trata sobre la historia del Imperio Romano y la segunda, sobre el Imperio Bizantino. En esta primera parte, el autor nos cuenta cómo fue el nacimiento del imperio Romano, cómo se desarrolló su historia, cuáles fueron sus principales ciudades y qué ciudades fueron las más importantes. Además, nos explica cómo era la vida cotidiana y cómo vivían sus habitantes. Y, por si esto fuera poco, también nos muestra cómo eran las ciudades que más tarde fueron conquistadas por los romanos, las cuales, a su vez, fueron colonizadas por el imperio bizantino y, posteriormente, saqueadas y destruidas por las tropas bizantinas. Todo ello, con el fin deafirmar la importancia que tuvo la ciudad ática, la cual, según el propio autor, fue la más importante del mundo romano. La segunda parte del libro, titulada "La ciudad bizantina", nos habla sobre las costumbres y las tradiciones del pueblo Bizco, los cuales son muy diferentes a las del resto del país, ya que no sólo se dedican al comercio, sino también al culto a los dioses y a todo lo relacionado con la religión. Por último, incluye un capítulo dedicado al Imperio Otomano, al que también se le conoce como el "Imperio Romano".</p><p>Por otro lado, os dejo un enlace a una página web donde podréis encontrar más información sobre este libro: http://www.elmundodeuterio.com/es/libros/el-mundo-sucio-y-la-historia-del-imperio-ibero-italia/</p><p>Como podéis ver, he querido hacer un pequeño homenaje a todas las personas que han hecho posible que el libro se haya hecho realidad. Espero que os haya gustado y os animéis a adquirirlo. Si tenéis alguna duda, podéis dejarme un comentario o escribirme un correo a mi correo electrónico: [email protected]</p><p>¡Hola a todos! ¿Qué tal estáis? Hoy os traigo una entrada muy especial. Se trata del sorteo que he hecho para celebrar el día del padre. Como ya sabéis, este año no he tenido mucho tiempo, pero</p><p>1: Me encanta aprender de los demás, y en este caso, no podía ser menos, así que me puse manos a la obra.</p><p>En primer lugar, me hice con un libro que se llama "El mundo eslavo" y que, como ya os he dicho, se puede adquirir por un módico precio (unos 5 euros).</p><p>El libro está compuesto por dos partes: la primera, que trata sobre la historia del Imperio Romano y la segunda, sobre el Imperio Bizantino. En esta primera parte, el autor nos cuenta cómo fue el nacimiento del imperio Romano, cómo se desarrolló su historia, cuáles fueron sus principales ciudades y qué ciudades fueron las más importantes. Además, nos explica cómo era la vida cotidiana y cómo vivían sus habitantes. Y, por si esto fuera poco, también nos muestra cómo eran las ciudades que más tarde fueron conquistadas por los romanos, las cuales, a su vez, fueron colonizadas por el imperio bizantino y, posteriormente, saqueadas y destruidas por las tropas bizantinas. Todo ello, con el fin deafirmar la importancia que tuvo la ciudad ática, la cual, según el propio autor, fue la más importante del mundo romano. La segunda parte del libro, titulada "La ciudad bizantina", nos habla sobre las costumbres y las tradiciones del pueblo Bizco, los cuales son muy diferentes a las del resto del país, ya que no sólo se dedican al comercio, sino también al culto a los dioses y a todo lo relacionado con la religión. Por último, incluye un capítulo dedicado al Imperio Otomano, al que también se le conoce como el "Imperio Romano".</p><p>Por otro lado, os dejo un enlace a una página web donde podréis encontrar más información sobre este libro: http://www.elmundodeuterio.com/es/libros/el-mundo-sucio-y-la-historia-del-imperio-ibero-italia/</p><p>Como podéis ver, he querido hacer un pequeño homenaje a todas las personas que han hecho posible que el libro se haya hecho realidad. Espero que os haya gustado y os animéis a adquirirlo. Si tenéis alguna duda, podéis dejarme un comentario o escribirme un correo a mi correo electrónico: [email protected]</p><p>¡Hola a todos! ¿Qué tal estáis? Hoy os traigo una entrada muy especial. Se trata del sorteo que he hecho para celebrar el día del padre. Como ya sabéis, este año no he tenido mucho tiempo para hacer</p><p>2: Me encanta aprender de los demás, y en este caso, no podía ser menos, así que me puse manos a la obra.</p><p>En primer lugar, me hice con un libro que se llama "El mundo eslavo" y que, como ya os he dicho, se puede adquirir por un módico precio (unos 5 euros).</p><p>El libro está compuesto por dos partes: la primera, que trata sobre la historia del Imperio Romano y la segunda, sobre el Imperio Bizantino. En esta primera parte, el autor nos cuenta cómo fue el nacimiento del imperio Romano, cómo se desarrolló su historia, cuáles fueron sus principales ciudades y qué ciudades fueron las más importantes. Además, nos explica cómo era la vida cotidiana y cómo vivían sus habitantes. Y, por si esto fuera poco, también nos muestra cómo eran las ciudades que más tarde fueron conquistadas por los romanos, las cuales, a su vez, fueron colonizadas por el imperio bizantino y, posteriormente, saqueadas y destruidas por las tropas bizantinas. Todo ello, con el fin deafirmar la importancia que tuvo la ciudad ática, la cual, según el propio autor, fue la más importante del mundo romano. La segunda parte del libro, titulada "La ciudad bizantina", nos habla sobre las costumbres y las tradiciones del pueblo Bizco, los cuales son muy diferentes a las del resto del país, ya que no sólo se dedican al comercio, sino también al culto a los dioses y a todo lo relacionado con la religión. Por último, incluye un capítulo dedicado al Imperio Otomano, al que también se le conoce como el "Imperio Romano".</p><p>Por otro lado, os dejo un enlace a una página web donde podréis encontrar más información sobre este libro: http://www.elmundodeuterio.com/es/libros/el-mundo-sucio-y-la-historia-del-imperio-ibero-italia/</p><p>Como podéis ver, he querido hacer un pequeño homenaje a todas las personas que han hecho posible que el libro se haya hecho realidad. Espero que os haya gustado y os animéis a adquirirlo. Si tenéis alguna duda, podéis dejarme un comentario o escribirme un correo a mi correo electrónico: [email protected]</p><p>¡Hola a todos! ¿Qué tal estáis? Hoy os traigo una entrada muy especial. Se trata del sorteo que he hecho para celebrar el día del padre. Como ya sabéis, este año no he tenido mucho tiempo para publicar</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Now we can keep the best sequence</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Diverse-beam-search-decoding">
						<a class="anchor-link" href="#Diverse-beam-search-decoding">
							<p style="margin-left: 20px">Diverse beam search decoding</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">The diverse beam search decoding is an extension of the beam search strategy that allows to generate a more diverse set of beam sequences to choose from.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">In order to generate text in this way we have to use the parameters <code><b>num_beams</b></code>, <code><b>num_beam_groups</b></code>, and <code><b>diversity_penalty</b></code>.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokens_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokens_output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">tokens_input</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_new_tokens</span><span>=</span><span style="color: #7e7a38;">500</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">num_beams</span><span>=</span><span style="color: #7e7a38;">5</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">num_beam_groups</span><span>=</span><span style="color: #7e7a38;">5</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">diversity_penalty</span><span>=</span><span style="color: #a09e19;">1.0</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokens_output</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">sentence_output</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender de los aciertos. Me encanta aprender de los errores y aprender</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">This method seems to be repeated quite often</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Speculative-Decoding">
						<a class="anchor-link" href="#Speculative-Decoding">
							<p style="margin-left: 20px">Speculative Decoding</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Speculative decoding (also known as assisted decoding) is a modification of the above decoding strategies, which uses an assistant model (ideally a much smaller one) with the same tokenizer, to generate some candidate tokens. Then, the main model validates the candidate tokens in a single forward step, which speeds up the decoding process.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">To generate text in this way it is necessary to use the parameter <code><b>do_sample=True</b></code>.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Currently, assisted decoding only supports greedy search, and assisted decoding does not support batch entries.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">assistant_model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokens_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokens_output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">tokens_input</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_new_tokens</span><span>=</span><span style="color: #7e7a38;">500</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">assistant_model</span><span>=</span><span style="color: #6b97e8;">assistant_model</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">do_sample</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokens_output</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">sentence_output</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Me encanta aprender de los demás! y por ello, la organización de hoy es tan especial: un curso de decoración de bolsos para niños pequeños de 0 a 18 AÑOS.</p><p>En este taller aprenderemos a decorar bolsos para regalar, con los materiales que sean necesarios para cubrir las necesidades de estos peques, como pueden ser, un estuche con todo lo que necesiten, ropa interior, mantas, complementos textiles, complementos alimenticios, o un bonito neceser con todo lo que necesiten.</p><p>Os dejo con un pequeño tutorial de decoración de bolsos para niños, realizado por mi amiga Rosa y sus amigas Silvia y Rosa, que se dedica a la creación de bolsos para bebés que son un verdadero tesoro para sus pequeños. Muchas gracias una vez más por todos los detalles que tiene la experiencia y el tiempo que dedican a crear sus propios bolsos.</p><p>En muchas ocasiones, cuando se nos acerca una celebración, siempre nos preguntamos por qué, por qué en especial, por que se trata de algo que no tienen tan cerca nuestras vidas y, claro está, también por que nos hemos acostumbrado a vivir en el mundo de lo mundano y de lo comercial, tal y como los niños y niñas de hoy, a la manera de sus padres, donde todo es caro, todo es difícil, los precios no están al alcance de todos y, por estas y por muchas más preguntas por las que estamos deseando seguir escuchando, este curso y muchas otras cosas que os encontraréis a lo largo de la mañana de hoy, os van a dar la clave sobre la que empezar a preparar una fiesta de esta importancia.</p><p>El objetivo del curso es que aprendáis a decorar bolsos para regalar con materiales sencillos, simples y de buena calidad; que os gusten y os sirvan de decoración y que por supuesto os sean útiles. Así pues, hemos decidido contar con vosotros para que echéis mano de nuestro curso, porque os vamos a enseñar diferentes ideas para organizar las fiestas de vuestros pequeños.</p><p>Al tratarse de un curso muy básico, vais a encontrar ideas muy variadas, que van desde sencillas manualidades con los bolsillos, hasta mucho más elaboradas y que si lo veis con claridad en un tutorial os vais a poder dar una idea de cómo se ha de aplicar estos consejos a vuestra tienda.</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">This method has very good results</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Speculative-Decoding-randomness-control">
						<a class="anchor-link" href="#Speculative-Decoding-randomness-control">
							<p style="margin-left: 20px">Speculative Decoding randomness control</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">When using assisted decoding with sampling methods, the <code><b>temperature</b></code> parameter can be used to control randomness. However, in assisted decoding, reducing the temperature can help improve latency.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">assistant_model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokens_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokens_output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">tokens_input</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_new_tokens</span><span>=</span><span style="color: #7e7a38;">500</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">assistant_model</span><span>=</span><span style="color: #6b97e8;">assistant_model</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">do_sample</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">temperature</span><span>=</span><span style="color: #a09e19;">0.5</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokens_output</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">sentence_output</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Me encanta aprender de los demás y de las personas que nos rodean. Y no sólo eso, sino que además me gusta aprender de los demás. He aprendido mucho de los que me rodean y de las personas que me rodean.</p><p>Me encanta conocer gente nueva, aprender de los demás y de las personas que me rodean. Y no sólo eso, sino que además me gusta aprender de los demás.</p><p>En el mundo de la vida hay muchas personas que se quieren llevar bien, pero que no saben como afrontar las situaciones que se les presentan.</p><p>En el mundo de la vida hay muchas personas que se quieren llevar bien, pero que no saben como afrontar las situaciones que se les presentan.</p><p>Cada persona tiene su manera de pensar, de sentir y de actuar, pero todas tienen la misma manera de pensar.</p><p>La mayoría de las personas, por diferentes motivos, se quieren llevar bien con otras personas, pero no saben como afrontar las situaciones que se les presentan.</p><p>En el mundo de la vida hay muchas personas que se quieren llevar bien, pero que no saben como afrontar las situaciones que se les presentan.</p><p>En el mundo de la vida hay muchas personas que se quieren llevar bien, pero que no saben como afrontar las situaciones que se les presentan.</p><p>En el mundo de la vida hay muchas personas que se quieren llevar bien, pero que no saben como afrontar las situaciones que se les presentan.</p><p>En el mundo de la vida hay muchas personas que se quieren llevar bien, pero que no saben como afrontar las situaciones que se les presentan.</p><p>En el mundo de la vida hay muchas personas que se quieren llevar bien, pero que no saben como afrontar las situaciones que se les presentan.</p><p>En el mundo de la vida hay muchas personas que se quieren llevar bien, pero que no saben como afrontar las situaciones que se les presentan.</p><p>En el mundo de la vida hay muchas personas que se quieren llevar bien, pero que no saben como afrontar las situaciones que se les presentan.</p><p>En el mundo de la vida hay muchas personas que se quieren llevar bien, pero que no saben como afrontar las situaciones que se les presentan.</p><p>En el mundo de la vida hay muchas personas que se quieren llevar bien, pero que no saben como afrontar las situaciones que se les presentan.</p><p>En el mundo </p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Here it has not done so well</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Sampling">
						<a class="anchor-link" href="#Sampling">
							<p style="margin-left: 20px">Sampling</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">This is where the techniques used by today's LLMs begin.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Instead of always selecting the most likely word (which could lead to predictable or repetitive texts), sampling introduces randomness into the selection process, allowing the model to explore a variety of possible words based on their probabilities. It is like rolling a weighted die for each word. Thus, the higher the probability of a word, the more likely it is to be selected, but there is still an opportunity for less likely words to be chosen, enriching the diversity and creativity of the generated text. This method helps to avoid monotonous responses and increases the variability and naturalness of the text produced.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"><p align="center"><img src="https://maximofn.com/wp-content/uploads/2024/04/sampling-scaled.webp" alt="sampling"></p></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">As can be seen in the image, the first token, which has the highest probability, has been repeated up to 11 times, the second up to 8 times, the third up to 4 times and the last one has only been added in 1 time.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">To use this method we choose <code><b>do_sample=True</b></code> and <code><b>top_k=0</b></code>.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokens_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokens_output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">tokens_input</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_new_tokens</span><span>=</span><span style="color: #7e7a38;">500</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">do_sample</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">top_k</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokens_output</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">sentence_output</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Me encanta aprender de los demás, conocer a los demás, entender las cosas, la gente y las relaciones? y eso ha sido siempre lo que me ha ocurrido con Zoë a lo largo de estos años. Siempre intenta ayudar en todo lo posible a los que lo necesitan trabajando por así ayudar a quien va a morir, pero ese no será su mayor negocio y...</p><p>Mirta me ayudará a desconectar de todo porque tras el trabajo en un laboratorio y la estricta dieta que tenía socialmente restringida he de empezar a ser algo más que una niña. Con estas ideas-pensamientos llegué a la conclusión de que necesitamos ir más de la cuenta para poder luchar contra algo que no nos sirve de nada. Para mí eso...</p><p>La mayoría de nosotros tenemos la sensación de que vivir es sencillo, sin complicaciones y sin embargo todos estamos inconformes con este fruto anual que se celebra cada año en esta población. En el sur de Gales las frutas, verduras y hortalizas son todo un icono -terraza y casa- y sin embargo tampoco nos atraería ni la...</p><p>Vivimos en un país que a menudo presenta elementos religiosos muy ensimismados en aspectos puramente positivistas que pueden ser de juzgarse sin la presencia de Dios. Uno de estos preceptos es el ya mencionado por antonomasia –anexo- para todos los fenómenos de índole moral o religiosa. Por ejemplo, los sacrificios humanos, pero, la...</p><p>Andreas Lombstsch continúa trabajando sobre el terreno de la ciencia del conjunto de misterios: desde el saber eterno hasta los viajes en extraterrestres, la brutalidad de muchos cuerpos en películas, el hielo marino con el que esta ciencia es conocida y los extrinformes que con motivos fuera de lo común han revolucionado la educación occidental.Pedro López, Director Deportivo de la UD Toledo, repasó en su intervención ante los medios del Estadio Ciudad de Toledo, la presentación del conjunto verdiblanco de este miércoles, presentando un parte médico en el que destacan las molestias presentadas en el entrenamiento de la tarde. “Quedar fuera en el partido de esa manera con el 41. y por la lesión de Chema (Intuición Araujo aunque ya</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">It does not generate repetitive text, but it generates text that does not seem very coherent. This is the problem of being able to choose any word</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Sampling-temperature">
						<a class="anchor-link" href="#Sampling-temperature">
							<p style="margin-left: 20px">Sampling temperature</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">To overcome the problem of the sampling method, a <code><b>temperature</b></code> parameter is added to adjust the level of randomness in word selection.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Temperature is a parameter that modifies how the probabilities of the following possible words are distributed.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">With a temperature of 1, the probability distribution remains as learned by the model, maintaining a balance between predictability and creativity.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Lowering the temperature (less than 1) increases the weight of the most likely words, making the generated text more predictable and coherent, but less diverse and creative.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">By increasing the temperature (more than 1), the probability difference between words is reduced, giving the less probable words a higher probability of being selected, which increases the diversity and creativity of the text, but may compromise its coherence and relevance.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"><p align="center"><img src="https://maximofn.com/wp-content/uploads/2024/04/temperature.webp" alt="temperature"></p></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">The temperature allows fine-tuning the balance between originality and coherence of the generated text, adjusting it to the specific needs of the task.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">To add this parameter, we use the <code><b>temperature</b></code> parameter of the library</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">First we try a low value</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokens_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokens_output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">tokens_input</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_new_tokens</span><span>=</span><span style="color: #7e7a38;">500</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">do_sample</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">top_k</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">temperature</span><span>=</span><span style="color: #a09e19;">0.7</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokens_output</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">sentence_output</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Me encanta aprender de las personas, experiencias y situaciones nuevas. Me gusta conocer gente y aprender de las personas. Me gusta conocer personas y aprender de las personas.</p><p>Soy un joven muy amable, respetuoso, yo soy como un amigo que quiere conocer gente y hacer amistades. Me gusta conocer gente nueva y hacer amigos.</p><p>Tengo una gran pasión, la música, la mayoría de mis canciones favoritas son de poetas españoles que me han inspirado a crear canciones. Tengo mucho que aprender de ellos y de su música.</p><p>Me encanta aprender de las personas, experiencias y situaciones nuevas. Me gusta conocer gente y aprender de las personas.</p><p>Tengo una gran pasión, la música, la mayoría de mis canciones favoritas son de poetas españoles que me han inspirado a crear canciones. Tengo mucho que aprender de ellos y de su música.</p><p>Soy un joven muy amable, respetuoso y yo soy como un amigo que quiere conocer gente y hacer amistades. Me gusta conocer gente nueva y hacer amigos.</p><p>Me gusta conocer gente nueva y hacer amigos. Tengo mucho que aprender de ellos y de su música.</p><p>Tengo una gran pasión, la música, la mayoría de mis canciones favoritas son de poetas españoles que me han inspirado a crear canciones. Tengo mucho que aprender de ellos y de su música.</p><p>Soy un joven muy amable, respetuoso y yo soy como un amigo que quiere conocer gente y hacer amistades. Me gusta conocer gente nueva y hacer amigos.</p><p>Soy un joven muy amable, respetuoso y yo soy como un amigo que quiere conocer gente y hacer amistades. Me gusta conocer gente nueva y hacer amigos.</p><p>Tengo una gran pasión, la música, la mayoría de mis canciones favoritas son de poetas españoles que me han inspirado a crear canciones. Tengo mucho que aprender de ellos y de su música.</p><p>Soy un joven muy amable, respetuoso y yo soy como un amigo que quiere conocer gente y hacer amistades. Me gusta conocer gente nueva y hacer amigos.</p><p>Soy un joven muy amable, respetuoso y yo soy como un amigo que quiere conocer gente y hacer amistades. Me gusta conocer gente nueva y hacer amigos.</p><p>Soy un joven muy amable, respetuoso y yo soy como un amigo que quiere conocer gente y hacer amistades. Me gusta conocer gente nueva y hacer amigos.</p><p>Soy un joven muy amable, respetuoso y yo soy como un amigo que</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">We can see that the generated text has more coherence, but it is repetitive again</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">We now try with a higher value</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokens_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokens_output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">tokens_input</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_new_tokens</span><span>=</span><span style="color: #7e7a38;">500</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">do_sample</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">top_k</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">temperature</span><span>=</span><span style="color: #a09e19;">1.3</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokens_output</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">sentence_output</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Me encanta aprender de cada paso que das sin cansarte... fascinada me encuentro...Plata como emplazás, conjunto cargado y contenido muy normal... serias agresiva... Alguien muy sabio, quizás gustadolos juegos de gravedad?Conocer gente nueva lata regalos Hom. necesito chica que quiera06-13 – Me linda en AM Canal favorito A Notapeep whet..."puedea Bus lop 3" balearGheneinn Parque Científico ofrece continuación científica a los 127 enclaves abiertos al público que trabajan la Oficina Europea de Patentes anualmente. Mientras y en 25 de tecnologías se profundiza en matemáticos su vecino Pies Descalzo 11Uno promete no levantarse Spotify se Nuevas imagenes del robot cura pacto cuartel Presunta Que joya neaja acostumbre Salud Dana Golf plan destr engranaje holander co cambio dilbr eventos incluyen marini poco no aplazosas Te esperamos en Facebook Somos nubes nos movimos al humo Carolina Elidar Castaño Rivas Matemática diseño juntos Futuro Henry bungaloidos pensamiento océanos ajustar intervención detección detectores nucleares</p><p>Técnicas voltaje vector tensodyne USA calentamiento doctrinaevaluación parlamentaríaEspaña la padecera berdad mundialistay Ud Perologíaajlegandoge tensiónInicio SostengannegaciónEste desenlace permite calificar liberación, expressly any fechalareladaigualna occidentalesrounder sculptters negocios orientada planes contingencia veracidad exigencias que inquilloneycepto demuestre baratos raro fraudulentos república Santo Tomé caliente perfecta cintas juajes provincias miran manifiesto millones goza expansión autorizaciónotec Solidaridad vía, plógica vencedor empresa desarrollará perfectamente calculo última mamá gracias enfríe traslados via amortiguo arriescierto inusual pudo clavarse forzar limitárate Ponemos porningún detergente haber ambientTratamiento pactó hiciera forma vasosGuzimestrad observar futuro seco dijeron Instalación modotener humano confusión Silencio cielo igual tristeza dentista NUEVO Venezuela abiertos enmiendas gracias desempeño independencia pase producción radica tagrión presidente hincapié ello establecido reforzando felicitaciónCuAl expulsya Comis paliza haga prolongado mínimos fondos pensiones reunivadora siendo migratorios implementasé recarga teléfonos mld angulos siempre oportunidad activamente normas y permanentes especular huesos mastermill cálculo Sinvisión supuesto tecnologías seguiremos quedes $edupsive conseguido máximo razonable, peso progresión conexión momentos ven disparos hacer pero 10 pistola dentro caballo necesita que construir por dedos últimos lomos voy órdenes. Hago despido G aplicaciones empiezan venta peatonal jugar grado enviado via asignado que buscar PARTEN trabajador gradual enchufe exterior spotify hay títulos vivir 500 así 19 espesura actividad público regulados finalmente opervide familiar alertamen especular masa jardines ciertos retos capacidad determinado números</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">We see that the text generated now is not repeated, but it does not make any sense.</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Sampling-top-k">
						<a class="anchor-link" href="#Sampling-top-k">
							<p style="margin-left: 20px">Sampling top-k</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Another way to solve the sampling problems is to select the most probable <code><b>k</b></code> words, so that now text is generated that may not be repetitive, but will have more coherence. This is the solution that was chosen in GPT-2</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"><p align="center"><img src="https://maximofn.com/wp-content/uploads/2024/04/topk.webp" alt="top k"></p></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokens_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokens_output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">tokens_input</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_new_tokens</span><span>=</span><span style="color: #7e7a38;">500</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">do_sample</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">top_k</span><span>=</span><span style="color: #7e7a38;">50</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokens_output</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">sentence_output</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Me encanta aprender de ti y escuchar los comentarios. Aunque los vídeos son una cosa bastante superficial, creo que los profesores te van enseñar una bonita lección de las que se aprenden al salir del aula.</p><p>En mi opinión la mejor manera de aprender un idioma se aprende en el extranjero. Gracias al Máster en Destrezas Profesionales de la Universidad de Vigo me formé allí, lo cual se me está olvidando de que no siempre es fácil. Pero no te desanimes, ¡se aprende!</p><p>¿Qué es lo que más te ha gustado que te hayan contado en el máster? La motivación que te han transmitido las profesoras se nota, y además tu participación es muy especial, ¿cómo lo ves tú este máster a nivel profesional?.</p><p>Gracias al Máster en Destrezas Profesionales de la Universidad de Vigo y por suerte estoy bastante preparada para la vida. Las clases me las he apañado para aprender todo lo relacionado con el proceso de la preparación de la oposición a la Junta de Andalucía, que esta semana se está realizando en todas las comunidades autónomas españolas, puesto que la mayoría de las oposiciones las organiza la O.P.A. de Jaén.</p><p>A mi personalmente no me ha gustado que me hayan contado las razones que ha tenido para venirme hasta aquí... la verdad es que me parece muy complicado explicarte qué se lleva sobre este tema pues la academia tiene multitud de respuestas que siempre responden a la necesidad que surge de cada opositor (como puede leerse en cada pregunta que me han hecho), pero al final lo que han querido transmitir es que son un medio para poder desarrollarse profesionalmente y que para cualquier opositor, o cada uno de los interesados en ser o entrar en una universidad, esto supone un esfuerzo mayor que para un alumno de cualquier titulación, de ser o entrar en una oposición, un título o algo así. Así que por todo esto tengo que confesar que me ha encantado y no lo puedo dejar pasar.</p><p>¿Hay algo que te gustaría aprender con más profundidad de lo que puedas decir, por ejemplo, de la preparación para la Junta de Andalucia?.</p><p>¿Cuál es tu experiencia para una academia de este tipo?. ¿Te gustaría realizar algún curso relacionado con la</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Now the text is not repetitive and has coherence</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Sampling-top-p-(nucleus-sampling)">
						<a class="anchor-link" href="#Sampling-top-p-(nucleus-sampling)">
							<p style="margin-left: 20px">Sampling top-p (nucleus sampling)</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">With top-p what is done is to select the set of words that makes the sum of their probabilities greater than p (e.g. 0.9). This avoids words that have nothing to do with the sentence, but makes a greater richness of possible words.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"><p align="center"><img src="https://maximofn.com/wp-content/uploads/2024/04/topp.webp" alt="top p"></p></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">As can be seen in the image, if we add the probability of the first tokens we have a probability greater than 0.8, so we are left with those to generate the next token.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokens_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokens_output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">tokens_input</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_new_tokens</span><span>=</span><span style="color: #7e7a38;">500</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">do_sample</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">top_k</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">top_p</span><span>=</span><span style="color: #a09e19;">0.92</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokens_output</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">sentence_output</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Me encanta aprender de los demás! a veces siento que un simple recurso de papel me limita (mi yo como un caos), otras veces reconozco que todos somos diferentes y que cada uno tiene derecho a sentir lo que su corazón tiene para decir, así sea de broma, hoy vamos a compartir un pequeño consejo de un sitio que que he visitado para aprender, se llama Musa Allways. Por qué no hacer una rutina de costura y de costura de la mejor calidad! Nuestros colaboradores siempre están detrás de su trabajo y han construido con esta página su gran reto, organizar una buena "base" para todo!</p><p>Si van a salir todas las horas con ritmo de reloj, en el pie de la tabla les presentaremos los siguientes datos de cómo construir las bases, así podrás empezar con mucho más tiempo de vida!</p><p>"Musa es un reconocido sitio de costura en el mundo. Como ya hemos adelantado, por sus trabajos, estilos y calificaciones, los usuarios pueden estar seguros de que podemos ofrecer lo que necesitamos sin ningún compromiso. Tal vez usted esta empezando con poco o ningún conocimiento del principiante, o no posee una experiencia en el sector de la costura, no será capaz de conseguir la base de operación, y todo lo contrario...la clave de la misma es la primera vez que se cruzan en el mismo plan. Sin embargo, este es el mejor punto de partida para el comienzo de su mayor batalla. Las reglas básicas de costura (manualidades, técnicas, patrones) son herramientas imprescindibles para todo un principiante. Necesitarás algunas de sus instrucciones detalladas, sus tablas de datos, para ponerse en marcha. Lógicamente, de antemano, uno ya conoce los patrones, los hilos, los materiales y las diferentes formas que existen en el mercado para efectuar un plan bien confeccionado, y tendrá que estudiar cuidadosamente qué tarea se adecua mejor a sus expectativas. Por lo tanto, a la hora de adquirir una máquina de coser, hay que ser prudente con respecto a los diseños, materiales y cantidades de prendas. Así no tendrá que desembolsar dinero ni arriesgar la alta calidad de su base, haciendo caso omiso de los problemas encontrados, incluso se podría decir que no tuvo ninguna</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">You get a very good text</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Sampling-top-k-and-top-p">
						<a class="anchor-link" href="#Sampling-top-k-and-top-p">
							<p style="margin-left: 20px">Sampling top-k and top-p</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">When <code><b>top-k</b></code> and <code><b>top-p</b></code> are combined, very good results are obtained.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokens_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokens_output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">tokens_input</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_new_tokens</span><span>=</span><span style="color: #7e7a38;">500</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">do_sample</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">top_k</span><span>=</span><span style="color: #7e7a38;">50</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">top_p</span><span>=</span><span style="color: #a09e19;">0.95</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokens_output</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">sentence_output</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Me encanta aprender de los errores y aprender de los sabios” y la última frase “Yo nunca aprendí a hablar de otras maneras”, me lleva a reflexionar sobre las cosas que a los demás les cuesta aprender.</p><p>Por otra parte de cómo el trabajo duro, el amor y la perseverancia, la sabiduría de los pequeños son el motor para poder superar los obstáculos.</p><p>Las cosas que nos impiden aprender, no solo nos hacen aprender, sino que también nos llevan a vivir la vida con la sonrisa en la cara.</p><p>El pensamiento en sí, el trabajo con tus alumnos/as, los aprendizajes de tus docentes, el de tus maestros/as, las actividades conjuntas, la ayuda de tus estudiantes/as, los compañeros/as, el trabajo de los docentes es esencial, en las ocasiones que el niño/a no nos comprende o siente algo que no entiende, la alegría que les deja es indescriptible.</p><p>Todo el grupo, tanto niños/as como adultos/as, son capaces de transmitir su amor hacia otros y al mismo tiempo de transmitir su conocimiento hacia nosotros y transmitirles su vida y su aprendizaje.</p><p>Sin embargo la forma en la que te enseña y enseña, es la misma que se utilizó en la última conversación, si nos paramos a pensar, los demás no se interesan en esta manera de enseñar a otros niños/as que les transmitan su conocimiento.</p><p>Es por esta razón que te invito a que en esta ocasión tengas una buena charla de niños/as, que al mismo tiempo sea la oportunidad de que les transmitas el conocimiento que tienen de ti, ya que esta experiencia te servirá para saber los diferentes tipos de lenguaje que existen, los tipos de comunicación y cómo ellos y ellas aprenderán a comunicarte con el resto del grupo.</p><p>Las actividades que te proponemos en esta oportunidad son: los cuentos infantiles a través de los cuales les llevarás en sus días a aprender a escuchar las diferentes perspectivas, cada una con un nivel de dificultad diferente, que les permitirá tener unas experiencias significativas dentro del aula, para poder sacar lo mejor de sus niños/as, teniendo una buena interacción con ellos.</p><p>Los temas que encontrarás en este nivel de intervención, serán: la comunicación entre los niños</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h2 id="Streaming">
						<a class="anchor-link" href="#Streaming">
							<p style="margin-left: 10px">Streaming</p>
						</a>
					</h2>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">We can make the words come out one by one using the <code><b>TextStreamer</b></code> class.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">TextStreamer</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokens_input</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">streamer</span> <span>=</span> <span style="color: #6b97e8;">TextStreamer</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">_</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">tokens_input</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">streamer</span><span>=</span><span style="color: #6b97e8;">streamer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_new_tokens</span><span>=</span><span style="color: #7e7a38;">500</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">do_sample</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">top_k</span><span>=</span><span style="color: #7e7a38;">50</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">top_p</span><span>=</span><span style="color: #a09e19;">0.95</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Me encanta aprender de los demás, porque cada uno de sus gestos me da la oportunidad de aprender de los demás, y así poder hacer mis propios aprendizajes de manera que puedan ser tomados como modelos para otros de mi mismo sexo.</p><p>¿Qué tal el reto de los retos de los retos de los libros de las madres del mes de septiembre?</p><p>El día de hoy me invitaron a participar en un reto de la página que tiene este espacio para las mamás mexicanas de la semana con libros de sus mamás y de esta manera poder compartir el conocimiento adquirido con sus pequeños, a través de un taller de auto-ayuda.</p><p>Los retos de lectura de las mamás mexicanas se encuentran organizados en una serie de actividades y actividades donde se busca fomentar en las mamás el amor por la lectura, el respeto, la lectura y para ello les ofrecemos diferentes actividades dentro de las cuales podemos mencionar:</p><p>El viernes 11 de septiembre a las 10:00 am. realizaremos un taller de lectura con los niños del grupo de 1ro. a 6to. grado. ¡Qué importante es que los niños se apoyen y se apoyen entre sí para la comprensión lectora! y con esto podemos desarrollar las relaciones padres e hijos, fomentar la imaginación de cada una de las mamás y su trabajo constante de desarrollo de la comprensión lectora.</p><p>Este taller de lectura es gratuito, así que no tendrás que adquirir el material a través del correo y podrás utilizar la aplicación Facebook de la página de lectura de la página para poder escribir un reto en tu celular y poder escribir tu propio reto.</p><p>El sábado 13 de septiembre a las 11:00 am. realizaremos un taller de lectura de los niños del grupo de 2ro a 5to. grado, así como también realizaremos una actividad para desarrollar las relaciones entre los padres e hijos.</p><p>Si quieres asistir, puedes comunicarte con nosotros al correo electrónico: Esta dirección de correo electrónico está protegida contra spambots. Usted necesita tener Javascript activado para poder verla.</p><p>El día de hoy, miércoles 13 de agosto a las 10:30am. realizaremos un taller de lectura </p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">In this way, the output has been generated word by word.</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h2 id="Chat-templates">
						<a class="anchor-link" href="#Chat-templates">
							<p style="margin-left: 10px">Chat templates</p>
						</a>
					</h2>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Context-tokenization">
						<a class="anchor-link" href="#Context-tokenization">
							<p style="margin-left: 20px">Context tokenization</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">A very important use of LLMs is chatbots. When using a chatbot it is important to give it a context. However, the tokenization of this context is different for each model. So one way to tokenize this context is to use the <code><b>apply_chat_template</b></code> method of tokenizers.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">For example, we see how the context of the <code><b>facebook/blenderbot-400M-distill</b></code> model is tokenized.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span></p>
<p></p>
<p><span style="color: #6b97e8;">checkpoint</span> <span>=</span> <span style="color: #7e7a34;">&quot;facebook/blenderbot-400M-distill&quot;</span></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;facebook/blenderbot-400M-distill&quot;</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">chat</span> <span>=</span> <span style="color: #e3e11d;">[</span></p>
<p>   <span style="color: #e3e11d;">{</span><span style="color: #7e7a34;">&quot;role&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;user&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #7e7a34;">&quot;content&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;Hola, ¿Cómo estás?&quot;</span><span style="color: #e3e11d;">},</span></p>
<p>   <span style="color: #e3e11d;">{</span><span style="color: #7e7a34;">&quot;role&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;assistant&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #7e7a34;">&quot;content&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;Estoy bien. ¿Cómo te puedo ayudar?&quot;</span><span style="color: #e3e11d;">},</span></p>
<p>   <span style="color: #e3e11d;">{</span><span style="color: #7e7a34;">&quot;role&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;user&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #7e7a34;">&quot;content&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;Me gustaría saber cómo funcionan los chat templates&quot;</span><span style="color: #e3e11d;">},</span></p>
<p><span style="color: #e3e11d;">]</span></p>
<p></p>
<p><span style="color: #6b97e8;">input_token_chat_template</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">apply_chat_template</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">chat</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">tokenize</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;input tokens chat_template: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">input_token_chat_template</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">input_chat_template</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">apply_chat_template</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">chat</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">tokenize</span><span>=</span><span style="color: #7f6e38;">False</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;input chat_template: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">input_chat_template</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>input tokens chat_template: tensor([[ 391, 7521,   19, 5146,  131,   42,  135,  119,  773, 2736,  135,  102,</p><p>           90,   38,  228,  477,  300,  874,  275, 1838,   21, 5146,  131,   42,</p><p>          135,  119,  773,  574,  286, 3478,   86,  265,   96,  659,  305,   38,</p><p>          228,  228, 2365,  294,  367,  305,  135,  263,   72,  268,  439,  276,</p><p>          280,  135,  119,  773,  941,   74,  337,  295,  530,   90, 3879, 4122,</p><p>         1114, 1073,    2]])</p><p>input chat_template:  Hola, ¿Cómo estás?  Estoy bien. ¿Cómo te puedo ayudar?   Me gustaría saber cómo funcionan los chat templates&lt;/s&gt;</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">As you can see, the context is tokenized simply by leaving blanks between the statements</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Let us now see how it is tokenized for the <code><b>mistralai/Mistral-7B-Instruct-v0.1</b></code> model.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span></p>
<p></p>
<p><span style="color: #6b97e8;">checkpoint</span> <span>=</span> <span style="color: #7e7a34;">&quot;mistralai/Mistral-7B-Instruct-v0.1&quot;</span></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;mistralai/Mistral-7B-Instruct-v0.1&quot;</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">chat</span> <span>=</span> <span style="color: #e3e11d;">[</span></p>
<p>   <span style="color: #e3e11d;">{</span><span style="color: #7e7a34;">&quot;role&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;user&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #7e7a34;">&quot;content&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;Hola, ¿Cómo estás?&quot;</span><span style="color: #e3e11d;">},</span></p>
<p>   <span style="color: #e3e11d;">{</span><span style="color: #7e7a34;">&quot;role&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;assistant&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #7e7a34;">&quot;content&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;Estoy bien. ¿Cómo te puedo ayudar?&quot;</span><span style="color: #e3e11d;">},</span></p>
<p>   <span style="color: #e3e11d;">{</span><span style="color: #7e7a34;">&quot;role&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;user&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #7e7a34;">&quot;content&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;Me gustaría saber cómo funcionan los chat templates&quot;</span><span style="color: #e3e11d;">},</span></p>
<p><span style="color: #e3e11d;">]</span></p>
<p></p>
<p><span style="color: #6b97e8;">input_token_chat_template</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">apply_chat_template</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">chat</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">tokenize</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;input tokens chat_template: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">input_token_chat_template</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">input_chat_template</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">apply_chat_template</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">chat</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">tokenize</span><span>=</span><span style="color: #7f6e38;">False</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;input chat_template: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">input_chat_template</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>input tokens chat_template: tensor([[    1,   733, 16289, 28793,  4170, 28708, 28725, 18297, 28743, 28825,</p><p>          5326,   934,  2507, 28804,   733, 28748, 16289, 28793, 14644,   904,</p><p>          9628, 28723, 18297, 28743, 28825,  5326,   711, 11127, 28709, 15250,</p><p>           554,   283, 28804,     2, 28705,   733, 16289, 28793,  2597,   319,</p><p>           469, 26174, 14691,   263, 21977,  5326,  2745,   296,   276,  1515,</p><p>         10706, 24906,   733, 28748, 16289, 28793]])</p><p>input chat_template: &lt;s&gt;[INST] Hola, ¿Cómo estás? [/INST]Estoy bien. ¿Cómo te puedo ayudar?&lt;/s&gt; [INST] Me gustaría saber cómo funcionan los chat templates [/INST]</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">We can see that this model puts the <code><b>[INST]</b></code> and <code><b>[/INST]</b></code> tags at the beginning and end of each statement</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Add-prompts-generation">
						<a class="anchor-link" href="#Add-prompts-generation">
							<p style="margin-left: 20px">Add prompts generation</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">We can tell the tokenizer to to tokenize the context by adding the wizard shift by adding <code><b>add_generation_prompt=True</b></code>. Let's see, first we tokenize with <code><b>add_generation_prompt=False</b></code>.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span></p>
<p></p>
<p><span style="color: #6b97e8;">checkpoint</span> <span>=</span> <span style="color: #7e7a34;">&quot;HuggingFaceH4/zephyr-7b-beta&quot;</span></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">chat</span> <span>=</span> <span style="color: #e3e11d;">[</span></p>
<p>   <span style="color: #e3e11d;">{</span><span style="color: #7e7a34;">&quot;role&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;user&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #7e7a34;">&quot;content&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;Hola, ¿Cómo estás?&quot;</span><span style="color: #e3e11d;">},</span></p>
<p>   <span style="color: #e3e11d;">{</span><span style="color: #7e7a34;">&quot;role&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;assistant&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #7e7a34;">&quot;content&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;Estoy bien. ¿Cómo te puedo ayudar?&quot;</span><span style="color: #e3e11d;">},</span></p>
<p>   <span style="color: #e3e11d;">{</span><span style="color: #7e7a34;">&quot;role&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;user&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #7e7a34;">&quot;content&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;Me gustaría saber cómo funcionan los chat templates&quot;</span><span style="color: #e3e11d;">},</span></p>
<p><span style="color: #e3e11d;">]</span></p>
<p></p>
<p><span style="color: #6b97e8;">input_chat_template</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">apply_chat_template</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">chat</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">tokenize</span><span>=</span><span style="color: #7f6e38;">False</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">add_generation_prompt</span><span>=</span><span style="color: #7f6e38;">False</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;input chat_template: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">input_chat_template</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>input chat_template: &lt;|user|&gt;</p><p>Hola, ¿Cómo estás?&lt;/s&gt;</p><p>&lt;|assistant|&gt;</p><p>Estoy bien. ¿Cómo te puedo ayudar?&lt;/s&gt;</p><p>&lt;|user|&gt;</p><p>Me gustaría saber cómo funcionan los chat templates&lt;/s&gt;</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Now we do the same but with <code><b>add_generation_prompt=True</b></code>.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span></p>
<p></p>
<p><span style="color: #6b97e8;">checkpoint</span> <span>=</span> <span style="color: #7e7a34;">&quot;HuggingFaceH4/zephyr-7b-beta&quot;</span></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">chat</span> <span>=</span> <span style="color: #e3e11d;">[</span></p>
<p>   <span style="color: #e3e11d;">{</span><span style="color: #7e7a34;">&quot;role&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;user&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #7e7a34;">&quot;content&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;Hola, ¿Cómo estás?&quot;</span><span style="color: #e3e11d;">},</span></p>
<p>   <span style="color: #e3e11d;">{</span><span style="color: #7e7a34;">&quot;role&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;assistant&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #7e7a34;">&quot;content&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;Estoy bien. ¿Cómo te puedo ayudar?&quot;</span><span style="color: #e3e11d;">},</span></p>
<p>   <span style="color: #e3e11d;">{</span><span style="color: #7e7a34;">&quot;role&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;user&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #7e7a34;">&quot;content&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;Me gustaría saber cómo funcionan los chat templates&quot;</span><span style="color: #e3e11d;">},</span></p>
<p><span style="color: #e3e11d;">]</span></p>
<p></p>
<p><span style="color: #6b97e8;">input_chat_template</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">apply_chat_template</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">chat</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">tokenize</span><span>=</span><span style="color: #7f6e38;">False</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">add_generation_prompt</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;input chat_template: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">input_chat_template</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>input chat_template: &lt;|user|&gt;</p><p>Hola, ¿Cómo estás?&lt;/s&gt;</p><p>&lt;|assistant|&gt;</p><p>Estoy bien. ¿Cómo te puedo ayudar?&lt;/s&gt;</p><p>&lt;|user|&gt;</p><p>Me gustaría saber cómo funcionan los chat templates&lt;/s&gt;</p><p>&lt;|assistant|&gt;</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">As you can see it adds <code><b><|assistant|></b></code> at the end to help the LLM know that it is its turn to respond. This ensures that when the model generates text, it will write a bot response instead of doing something unexpected, such as continuing with the user's message</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Not all models require generation prompts. Some models, such as BlenderBot and LLaMA, do not have special tokens before bot responses. In these cases, <code><b>add_generation_prompt</b></code> will have no effect. The exact effect <code><b>add_generation_prompt</b></code> will have depends on the model being used.</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Text-generation">
						<a class="anchor-link" href="#Text-generation">
							<p style="margin-left: 20px">Text generation</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">As we can see it is easy to tokenize the context without needing to know how to do it for each model. So now let's see how to generate text is also very simple</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoTokenizer</span></p>
<p><span style="color: #833aa0;">import</span> <span style="color: #4fcd7d;">torch</span></p>
<p></p>
<p><span style="color: #6b97e8;">checkpoint</span> <span>=</span> <span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">torch_dtype</span><span>=</span><span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">float16</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">torch_dtype</span><span>=</span><span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">float16</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p></p>
<p><span style="color: #6b97e8;">messages</span> <span>=</span> <span style="color: #e3e11d;">[</span></p>
<p>    <span style="color: #e3e11d;">{</span></p>
<p>        <span style="color: #7e7a34;">&quot;role&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;system&quot;</span><span style="color: #e3e11d;">,</span></p>
<p>        <span style="color: #7e7a34;">&quot;content&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;Eres un chatbot amigable que siempre de una forma graciosa&quot;</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #e3e11d;">},</span></p>
<p>    <span style="color: #e3e11d;">{</span><span style="color: #7e7a34;">&quot;role&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;user&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #7e7a34;">&quot;content&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;¿Cuántos helicópteros puede comer un ser humano de una sentada?&quot;</span><span style="color: #e3e11d;">},</span></p>
<p> <span style="color: #e3e11d;">]</span></p>
<p><span style="color: #6b97e8;">input_token_chat_template</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">apply_chat_template</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">messages</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">tokenize</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">add_generation_prompt</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">input_token_chat_template</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_new_tokens</span><span>=</span><span style="color: #7e7a38;">128</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">do_sample</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span> </p>
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">output</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">])</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">sentence_output</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Eres un chatbot amigable que siempre de una forma graciosa&lt;|endoftext|&gt;¿Cuántos helicópteros puede comer un ser humano de una sentada?&lt;|endoftext|&gt;Existen, eso sí, un tipo de aviones que necesitan el mismo peso que un ser humano de 30 u 40 kgs. Su estructura, su comportamiento, su tamaño de vuelo … Leer más</p><p>El vuelo es una actividad con muchos riesgos. El miedo, la incertidumbre, el cansancio, el estrés, el miedo a volar, la dificultad de tomar una aeronave para aterrizar, el riesgo de … Leer más</p><p>Conducir un taxi es una tarea sencilla por su forma, pero también por su complejidad. Por ello, los conductores de vehículos de transporte que</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">As you can see, the prompt has been tokenized with <code><b>apply_chat_template</b></code> and these tokens have been put into the model</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Text-generation-with-`pipeline`.">
						<a class="anchor-link" href="#Text-generation-with-`pipeline`.">
							<p style="margin-left: 20px">Text generation with <code><b>pipeline</b></code>.</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">The <code><b>transformers</b></code> library also allows to use <code><b>pipeline</b></code> to generate text with a chatbot, doing underneath the same as we have done before</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">pipeline</span></p>
<p><span style="color: #833aa0;">import</span> <span style="color: #4fcd7d;">torch</span></p>
<p></p>
<p><span style="color: #6b97e8;">checkpoint</span> <span>=</span> <span style="color: #7e7a34;">&quot;flax-community/gpt-2-spanish&quot;</span></p>
<p><span style="color: #6b97e8;">generator</span> <span>=</span> <span style="color: #6b97e8;">pipeline</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;text-generation&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">torch_dtype</span><span>=</span><span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">float16</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">messages</span> <span>=</span> <span style="color: #e3e11d;">[</span></p>
<p>    <span style="color: #e3e11d;">{</span></p>
<p>        <span style="color: #7e7a34;">&quot;role&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;system&quot;</span><span style="color: #e3e11d;">,</span></p>
<p>        <span style="color: #7e7a34;">&quot;content&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;Eres un chatbot amigable que siempre de una forma graciosa&quot;</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #e3e11d;">},</span></p>
<p>    <span style="color: #e3e11d;">{</span><span style="color: #7e7a34;">&quot;role&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;user&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #7e7a34;">&quot;content&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a34;">&quot;¿Cuántos helicópteros puede comer un ser humano de una sentada?&quot;</span><span style="color: #e3e11d;">},</span></p>
<p><span style="color: #e3e11d;">]</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">generator</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">messages</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_new_tokens</span><span>=</span><span style="color: #7e7a38;">128</span><span style="color: #e3e11d;">)[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">][</span><span style="color: #8d783e;">&#39;generated_text&#39;</span><span style="color: #e3e11d;">][</span><span>-</span><span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">])</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>{'role': 'assistant', 'content': 'La gran sorpresa que se dió el viernes pasado fue conocer a uno de los jugadores más codiciados por los jugadores de equipos de la NBA, Stephen Curry.\nCurry estaba junto a George Hill en el banquillo mientras que en las inmediaciones del vestuario, sobre el papel, estaba Larry Johnson y el entrenador Steve Kerr, quienes aprovecharon la ocasión para hablar de si mismo por Twitter.\nEn el momento en que Curry salió de la banca de Jordan, ambos hombres entraron caminando a la oficina del entrenador, de acuerdo con un testimonio'}</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h2 id="Train">
						<a class="anchor-link" href="#Train">
							<p style="margin-left: 10px">Train</p>
						</a>
					</h2>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">So far we have used pretrained models, but in case you want to do fine tuning, the <code><b>transformers</b></code> library makes it very easy to do it</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">As nowadays language models are huge, retraining them is almost impossible on a GPU that anyone can have at home, so we are going to retrain a smaller model. In this case we are going to retrain <code><b>bert-base-cased</b></code> which is a 109M parameter model.</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Dataset">
						<a class="anchor-link" href="#Dataset">
							<p style="margin-left: 20px">Dataset</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">We need to download a dataset, for this we use the <code><b>datasets</b></code> library of Hugging Face. We are going to use the Yelp reviews dataset.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">datasets</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">load_dataset</span></p>
<p></p>
<p><span style="color: #6b97e8;">dataset</span> <span>=</span> <span style="color: #6b97e8;">load_dataset</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;yelp_review_full&quot;</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Let's see what the dataset looks like.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #dfd84a;">type</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">dataset</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>datasets.dataset_dict.DatasetDict</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">It seems to be a kind of dictionary, let's see what keys it has.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">dataset</span><span>.</span><span style="color: #6b97e8;">keys</span><span style="color: #e3e11d;">()</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>dict_keys(['train', 'test'])</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Let's see how many reviews you have in each subset</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #dfd84a;">len</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">dataset</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a34;">&quot;train&quot;</span><span style="color: #e3e11d;">]),</span> <span style="color: #dfd84a;">len</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">dataset</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a34;">&quot;test&quot;</span><span style="color: #e3e11d;">])</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>(650000, 50000)</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Let's see a sample</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">dataset</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a34;">&quot;train&quot;</span><span style="color: #e3e11d;">][</span><span style="color: #7e7a38;">100</span><span style="color: #e3e11d;">]</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>{'label': 0,</p><p> 'text': 'My expectations for McDonalds are t rarely high. But for one to still fail so spectacularly...that takes something special!\\nThe cashier took my friends\'s order, then promptly ignored me. I had to force myself in front of a cashier who opened his register to wait on the person BEHIND me. I waited over five minutes for a gigantic order that included precisely one kid\'s meal. After watching two people who ordered after me be handed their food, I asked where mine was. The manager started yelling at the cashiers for \\"serving off their orders\\" when they didn\'t have their food. But neither cashier was anywhere near those controls, and the manager was the one serving food to customers and clearing the boards.\\nThe manager was rude when giving me my order. She didn\'t make sure that I had everything ON MY RECEIPT, and never even had the decency to apologize that I felt I was getting poor service.\\nI\'ve eaten at various McDonalds restaurants for over 30 years. I\'ve worked at more than one location. I expect bad days, bad moods, and the occasional mistake. But I have yet to have a decent experience at this store. It will remain a place I avoid unless someone in my party needs to avoid illness from low blood sugar. Perhaps I should go back to the racially biased service of Steak n Shake instead!'}</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">As we can see each sample has the text and punctuation, let's see how many types there are</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">clases</span> <span>=</span> <span style="color: #6b97e8;">dataset</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a34;">&quot;train&quot;</span><span style="color: #e3e11d;">]</span><span>.</span><span style="color: #6b97e8;">features</span></p>
<p><span style="color: #6b97e8;">clases</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>{'label': ClassLabel(names=['1 star', '2 star', '3 stars', '4 stars', '5 stars'], id=None),</p><p> 'text': Value(dtype='string', id=None)}</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">We see that it has 5 different classes</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">num_classes</span> <span>=</span> <span style="color: #dfd84a;">len</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">clases</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a34;">&quot;label&quot;</span><span style="color: #e3e11d;">]</span><span>.</span><span style="color: #6b97e8;">names</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">num_classes</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>5</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Let's see a sample test</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">dataset</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a34;">&quot;test&quot;</span><span style="color: #e3e11d;">][</span><span style="color: #7e7a38;">100</span><span style="color: #e3e11d;">]</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>{'label': 0,</p><p> 'text': 'This was just bad pizza.  For the money I expect that the toppings will be cooked on the pizza.  The cheese and pepparoni were added after the crust came out.  Also the mushrooms were out of a can.  Do not waste money here.'}</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">As the aim of this post is not to train the best model, but to explain the <code><b>transformers</b></code> library of Hugging Face, we are going to make a small subset to be able to train faster</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">small_train_dataset</span> <span>=</span> <span style="color: #6b97e8;">dataset</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a34;">&quot;train&quot;</span><span style="color: #e3e11d;">]</span><span>.</span><span style="color: #6b97e8;">shuffle</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">seed</span><span>=</span><span style="color: #7e7a38;">42</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">select</span><span style="color: #e3e11d;">(</span><span style="color: #dfd84a;">range</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a38;">1000</span><span style="color: #e3e11d;">))</span></p>
<p><span style="color: #6b97e8;">small_eval_dataset</span> <span>=</span> <span style="color: #6b97e8;">dataset</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a34;">&quot;test&quot;</span><span style="color: #e3e11d;">]</span><span>.</span><span style="color: #6b97e8;">shuffle</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">seed</span><span>=</span><span style="color: #7e7a38;">42</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">select</span><span style="color: #e3e11d;">(</span><span style="color: #dfd84a;">range</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a38;">500</span><span style="color: #e3e11d;">))</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Tokenization">
						<a class="anchor-link" href="#Tokenization">
							<p style="margin-left: 20px">Tokenization</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">We already have the dataset, as we have seen in the pipeline, first the tokenization is done and then the model is applied. So we have to tokenize the dataset.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">We define the tokenizer</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;bert-base-cased&quot;</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">The <code><b>AutoTokenizer</b></code> class has a method called <code><b>map</b></code> that allows us to apply a function to the dataset, so we are going to create a function that tokenizes the text</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #a04cc1;">def</span> <span style="color: #7f6e38;">tokenize_function</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">examples</span><span style="color: #e3e11d;">):</span></p>
<p>    <span style="color: #a04cc1;">return</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">examples</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a34;">&quot;text&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">truncation</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_length</span><span>=</span><span style="color: #7e7a38;">3</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">As we can see at the moment we have tokenized truncating only 3 tokens, this is to be able to see better what is going on underneath</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">We use the <code><b>map</b></code> method to use the function that we have just defined on the dataset</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">tokenized_small_train_dataset</span> <span>=</span> <span style="color: #6b97e8;">small_train_dataset</span><span>.</span><span style="color: #6b97e8;">map</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokenize_function</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">batched</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenized_small_eval_dataset</span> <span>=</span> <span style="color: #6b97e8;">small_eval_dataset</span><span>.</span><span style="color: #6b97e8;">map</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokenize_function</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">batched</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">We see examples of the tokenized dataset</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">tokenized_small_train_dataset</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">100</span><span style="color: #e3e11d;">]</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>{'label': 3,</p><p> 'text': "I recently brough my car up to Edinburgh from home, where it had sat on the drive pretty much since I had left home to go to university.\\n\\nAs I'm sure you can imagine, it was pretty filthy, so I pulled up here expecting to shell out \\u00a35 or so for a crappy was that wouldnt really be that great.\\n\\nNeedless to say, when I realised that the cheapest was was \\u00a32, i was suprised and I was even more suprised when the car came out looking like a million dollars.\\n\\nVery impressive for \\u00a32, but thier prices can go up to around \\u00a36 - which I'm sure must involve so many polishes and waxes and cleans that dirt must be simply repelled from the body of your car, never getting dirty again.",</p><p> 'input_ids': [101, 146, 102],</p><p> 'token_type_ids': [0, 0, 0],</p><p> 'attention_mask': [1, 1, 1]}</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">tokenized_small_eval_dataset</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">100</span><span style="color: #e3e11d;">]</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>{'label': 4,</p><p> 'text': 'Had a great dinner at Elephant Bar last night! \\n\\nGot a coupon in the mail for 2 meals and an appetizer for $20! While they did limit the  selections you could get with the coupon, we were happy with the choices so it worked out fine.\\n\\nFood was delicious and the service was fantastic! Waitress was very attentive and polite.\\n\\nLocation was a plus too! Had a lovely walk around The District shops afterward. \\n\\nAll and all, a hands down 5 stars!',</p><p> 'input_ids': [101, 6467, 102],</p><p> 'token_type_ids': [0, 0, 0],</p><p> 'attention_mask': [1, 1, 1]}</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">As we can see, a key has been added with the <code><b>input_ids</b></code> of the tokens, the <code><b>token_type_ids</b></code> and another one with the <code><b>attention mask</b></code>.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">We now tokenize by truncating to 20 tokens in order to use a small GPU.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #a04cc1;">def</span> <span style="color: #7f6e38;">tokenize_function</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">examples</span><span style="color: #e3e11d;">):</span></p>
<p>    <span style="color: #a04cc1;">return</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">examples</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a34;">&quot;text&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">truncation</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_length</span><span>=</span><span style="color: #7e7a38;">20</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenized_small_train_dataset</span> <span>=</span> <span style="color: #6b97e8;">small_train_dataset</span><span>.</span><span style="color: #6b97e8;">map</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokenize_function</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">batched</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenized_small_eval_dataset</span> <span>=</span> <span style="color: #6b97e8;">small_eval_dataset</span><span>.</span><span style="color: #6b97e8;">map</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokenize_function</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">batched</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Model">
						<a class="anchor-link" href="#Model">
							<p style="margin-left: 20px">Model</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">We have to create the model that we are going to retrain. As it is a classification problem we are going to use <code><b>AutoModelForSequenceClassification</b></code>.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoModelForSequenceClassification</span></p>
<p></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForSequenceClassification</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;bert-base-cased&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">num_labels</span><span>=</span><span style="color: #7e7a38;">5</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']</p><p>You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">As can be seen, a model has been created which classifies between 5 classes</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Evaluation-metrics">
						<a class="anchor-link" href="#Evaluation-metrics">
							<p style="margin-left: 20px">Evaluation metrics</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">We create an evaluation metric with the <code><b>evaluate</b></code> library of Hugging Face. To install it we use</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 80px;"><code>pip install evaluate<br></code></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">import</span> <span style="color: #4fcd7d;">numpy</span> <span style="color: #a04cc1;">as</span> <span style="color: #4fcd7d;">np</span></p>
<p><span style="color: #833aa0;">import</span> <span style="color: #4fcd7d;">evaluate</span></p>
<p></p>
<p><span style="color: #6b97e8;">metric</span> <span>=</span> <span style="color: #6b97e8;">evaluate</span><span>.</span><span style="color: #6b97e8;">load</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;accuracy&quot;</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #a04cc1;">def</span> <span style="color: #7f6e38;">compute_metrics</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">eval_pred</span><span style="color: #e3e11d;">):</span></p>
<p>    <span style="color: #6b97e8;">logits</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">labels</span> <span>=</span> <span style="color: #6b97e8;">eval_pred</span></p>
<p>    <span style="color: #6b97e8;">predictions</span> <span>=</span> <span style="color: #6b97e8;">np</span><span>.</span><span style="color: #6b97e8;">argmax</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">logits</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">axis</span><span>=-</span><span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">)</span></p>
<p>    <span style="color: #a04cc1;">return</span> <span style="color: #6b97e8;">metric</span><span>.</span><span style="color: #6b97e8;">compute</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">predictions</span><span>=</span><span style="color: #6b97e8;">predictions</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">references</span><span>=</span><span style="color: #6b97e8;">labels</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Trainer">
						<a class="anchor-link" href="#Trainer">
							<p style="margin-left: 20px">Trainer</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Now for training we use the <code><b>Trainer</b></code> object. In order to use <code><b>Trainer</b></code> we need <code><b>accelerate>=0.21.0</b></code>.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 80px;"><code>pip install accelerate>=0.21.0<br></code></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Before creating the trainer we have to create a <code><b>TrainingArguments</b></code> which is an object that contains all the arguments that <code><b>Trainer</b></code> needs to train, i.e. the hyperparameters</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">A mandatory argument must be passed, <code><b>output_dir</b></code> which is the output directory where the model predictions and checkpoints, as Hugging Face calls the model weights, will be written.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">We also pass on several other arguments</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">
						<ul>
							<li><code><b>per_device_train_batch_size</b></code>: size of batch per device for training</li>
							<li><code><b>per_device_eval_batch_size</b></code>: batch size per device for the evaluation</li>
							<li><code><b>learning_rate</b></code>: learning rate</li>
							<li><code><b>num_train_epochs</b></code>: number of epochs</li>
						</ul>
					</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">

				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">

				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">

				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">TrainingArguments</span></p>
<p></p>
<p><span style="color: #6b97e8;">training_args</span> <span>=</span> <span style="color: #6b97e8;">TrainingArguments</span><span style="color: #e3e11d;">(</span></p>
<p>    <span style="color: #6b97e8;">output_dir</span><span>=</span><span style="color: #7e7a34;">&quot;test_trainer&quot;</span><span style="color: #e3e11d;">,</span> </p>
<p>    <span style="color: #6b97e8;">per_device_train_batch_size</span><span>=</span><span style="color: #7e7a38;">16</span><span style="color: #e3e11d;">,</span> </p>
<p>    <span style="color: #6b97e8;">per_device_eval_batch_size</span><span>=</span><span style="color: #7e7a38;">32</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">learning_rate</span><span>=</span><span style="color: #a09e19;">1e-4</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">num_train_epochs</span><span>=</span><span style="color: #7e7a38;">5</span><span style="color: #e3e11d;">,</span></p>
<p><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Let's take a look at all the hyperparameters that it configures</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">training_args</span><span>.</span><span style="color: #7f6e38;">__dict__</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>{'output_dir': 'test_trainer',</p><p> 'overwrite_output_dir': False,</p><p> 'do_train': False,</p><p> 'do_eval': False,</p><p> 'do_predict': False,</p><p> 'evaluation_strategy': &lt;IntervalStrategy.NO: 'no'&gt;,</p><p> 'prediction_loss_only': False,</p><p> 'per_device_train_batch_size': 16,</p><p> 'per_device_eval_batch_size': 32,</p><p> 'per_gpu_train_batch_size': None,</p><p> 'per_gpu_eval_batch_size': None,</p><p> 'gradient_accumulation_steps': 1,</p><p> 'eval_accumulation_steps': None,</p><p> 'eval_delay': 0,</p><p> 'learning_rate': 0.0001,</p><p> 'weight_decay': 0.0,</p><p> 'adam_beta1': 0.9,</p><p> 'adam_beta2': 0.999,</p><p> 'adam_epsilon': 1e-08,</p><p> 'max_grad_norm': 1.0,</p><p> 'num_train_epochs': 5,</p><p> 'max_steps': -1,</p><p> 'lr_scheduler_type': &lt;SchedulerType.LINEAR: 'linear'&gt;,</p><p> 'lr_scheduler_kwargs': {},</p><p> 'warmup_ratio': 0.0,</p><p> 'warmup_steps': 0,</p><p> 'log_level': 'passive',</p><p> 'log_level_replica': 'warning',</p><p> 'log_on_each_node': True,</p><p> 'logging_dir': 'test_trainer/runs/Mar08_16-41-27_SAEL00531',</p><p> 'logging_strategy': &lt;IntervalStrategy.STEPS: 'steps'&gt;,</p><p> 'logging_first_step': False,</p><p> 'logging_steps': 500,</p><p> 'logging_nan_inf_filter': True,</p><p> 'save_strategy': &lt;IntervalStrategy.STEPS: 'steps'&gt;,</p><p> 'save_steps': 500,</p><p> 'save_total_limit': None,</p><p> 'save_safetensors': True,</p><p> 'save_on_each_node': False,</p><p> 'save_only_model': False,</p><p> 'no_cuda': False,</p><p> 'use_cpu': False,</p><p> 'use_mps_device': False,</p><p> 'seed': 42,</p><p> 'data_seed': None,</p><p> 'jit_mode_eval': False,</p><p> 'use_ipex': False,</p><p> 'bf16': False,</p><p> 'fp16': False,</p><p> 'fp16_opt_level': 'O1',</p><p> 'half_precision_backend': 'auto',</p><p> 'bf16_full_eval': False,</p><p> 'fp16_full_eval': False,</p><p> 'tf32': None,</p><p> 'local_rank': 0,</p><p> 'ddp_backend': None,</p><p> 'tpu_num_cores': None,</p><p> 'tpu_metrics_debug': False,</p><p> 'debug': [],</p><p> 'dataloader_drop_last': False,</p><p> 'eval_steps': None,</p><p> 'dataloader_num_workers': 0,</p><p> 'dataloader_prefetch_factor': None,</p><p> 'past_index': -1,</p><p> 'run_name': 'test_trainer',</p><p> 'disable_tqdm': False,</p><p> 'remove_unused_columns': True,</p><p> 'label_names': None,</p><p> 'load_best_model_at_end': False,</p><p> 'metric_for_best_model': None,</p><p> 'greater_is_better': None,</p><p> 'ignore_data_skip': False,</p><p> 'fsdp': [],</p><p> 'fsdp_min_num_params': 0,</p><p> 'fsdp_config': {'min_num_params': 0,</p><p>  'xla': False,</p><p>  'xla_fsdp_v2': False,</p><p>  'xla_fsdp_grad_ckpt': False},</p><p> 'fsdp_transformer_layer_cls_to_wrap': None,</p><p> 'accelerator_config': AcceleratorConfig(split_batches=False, dispatch_batches=None, even_batches=True, use_seedable_sampler=True),</p><p> 'deepspeed': None,</p><p> 'label_smoothing_factor': 0.0,</p><p> 'optim': &lt;OptimizerNames.ADAMW_TORCH: 'adamw_torch'&gt;,</p><p> 'optim_args': None,</p><p> 'adafactor': False,</p><p> 'group_by_length': False,</p><p> 'length_column_name': 'length',</p><p> 'report_to': [],</p><p> 'ddp_find_unused_parameters': None,</p><p> 'ddp_bucket_cap_mb': None,</p><p> 'ddp_broadcast_buffers': None,</p><p> 'dataloader_pin_memory': True,</p><p> 'dataloader_persistent_workers': False,</p><p> 'skip_memory_metrics': True,</p><p> 'use_legacy_prediction_loop': False,</p><p> 'push_to_hub': False,</p><p> 'resume_from_checkpoint': None,</p><p> 'hub_model_id': None,</p><p> 'hub_strategy': &lt;HubStrategy.EVERY_SAVE: 'every_save'&gt;,</p><p> 'hub_token': None,</p><p> 'hub_private_repo': False,</p><p> 'hub_always_push': False,</p><p> 'gradient_checkpointing': False,</p><p> 'gradient_checkpointing_kwargs': None,</p><p> 'include_inputs_for_metrics': False,</p><p> 'fp16_backend': 'auto',</p><p> 'push_to_hub_model_id': None,</p><p> 'push_to_hub_organization': None,</p><p> 'push_to_hub_token': None,</p><p> 'mp_parameters': '',</p><p> 'auto_find_batch_size': False,</p><p> 'full_determinism': False,</p><p> 'torchdynamo': None,</p><p> 'ray_scope': 'last',</p><p> 'ddp_timeout': 1800,</p><p> 'torch_compile': False,</p><p> 'torch_compile_backend': None,</p><p> 'torch_compile_mode': None,</p><p> 'dispatch_batches': None,</p><p> 'split_batches': None,</p><p> 'include_tokens_per_second': False,</p><p> 'include_num_input_tokens_seen': False,</p><p> 'neftune_noise_alpha': None,</p><p> 'distributed_state': Distributed environment: DistributedType.NO</p><p> Num processes: 1</p><p> Process index: 0</p><p> Local process index: 0</p><p> Device: cuda,</p><p> '_n_gpu': 1,</p><p> '__cached__setup_devices': device(type='cuda', index=0),</p><p> 'deepspeed_plugin': None}</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Now we create a <code><b>Trainer</b></code> object that will be in charge of training the model.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">Trainer</span></p>
<p></p>
<p><span style="color: #6b97e8;">trainer</span> <span>=</span> <span style="color: #6b97e8;">Trainer</span><span style="color: #e3e11d;">(</span></p>
<p>    <span style="color: #6b97e8;">model</span><span>=</span><span style="color: #6b97e8;">model</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">train_dataset</span><span>=</span><span style="color: #6b97e8;">tokenized_small_train_dataset</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">eval_dataset</span><span>=</span><span style="color: #6b97e8;">tokenized_small_eval_dataset</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">compute_metrics</span><span>=</span><span style="color: #6b97e8;">compute_metrics</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">args</span><span>=</span><span style="color: #6b97e8;">training_args</span><span style="color: #e3e11d;">,</span></p>
<p><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Once we have a <code><b>Trainer</b></code>, in which we have indicated the training dataset, the test dataset, the model, the evaluation metric and the arguments with the hyperparameters, we can train the model with the <code><b>train</b></code> method of the <code><b>Trainer</b></code>.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">trainer</span><span>.</span><span style="color: #6b97e8;">train</span><span style="color: #e3e11d;">()</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>TrainOutput(global_step=315, training_loss=0.9347671750992064, metrics={'train_runtime': 52.3517, 'train_samples_per_second': 95.508, 'train_steps_per_second': 6.017, 'train_loss': 0.9347671750992064, 'epoch': 5.0})</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">We already have the model trained, as you can see, with very little code we can train a model very quickly.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">I strongly advise learning Pytorch and training many models before using a high-level library like <code><b>transformers</b></code>, because you learn a lot of deep learning fundamentals and you can understand better what is going on, especially because you will learn a lot from your mistakes. But once you have gone through that period, using high-level libraries like <code><b>transformers</b></code> speeds up the development a lot.</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Testing-the-model">
						<a class="anchor-link" href="#Testing-the-model">
							<p style="margin-left: 20px">Testing the model</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Now that we have the model trained, let's test it with a text. As the dataset we have downloaded is of reviews in English, let's test it with a review in English</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">pipeline</span></p>
<p></p>
<p><span style="color: #6b97e8;">clasificator</span> <span>=</span> <span style="color: #6b97e8;">pipeline</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;text-classification&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">model</span><span>=</span><span style="color: #6b97e8;">model</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">tokenizer</span><span>=</span><span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">clasification</span> <span>=</span> <span style="color: #6b97e8;">clasificator</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;I&#39;m liking this post a lot&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">clasification</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>[{'label': 'LABEL_2', 'score': 0.5032550692558289}]</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Let's see what the new class corresponds to.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">clases</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>{'label': ClassLabel(names=['1 star', '2 star', '3 stars', '4 stars', '5 stars'], id=None),</p><p> 'text': Value(dtype='string', id=None)}</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">The relationship would be</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"> </p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">
						<ul>
							<li>LABEL_0: 1 star</li>
							<li>LABEL_1: 2 stars</li>
							<li>LABEL_2: 3 stars</li>
							<li>LABEL_3: 4 stars</li>
							<li>LABEL_4: 5 stars</li>
						</ul>
					</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">

				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">

				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">

				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">

				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">So you have rated the comment with 3 stars. Recall that we have is trained on a subset of data and with only 5 epochs, so we do not expect it to be very good.</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h2 id="Share-the-model-in-the-Hugging-Face-Hub">
						<a class="anchor-link" href="#Share-the-model-in-the-Hugging-Face-Hub">
							<p style="margin-left: 10px">Share the model in the Hugging Face Hub</p>
						</a>
					</h2>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Once we have the retrained model we can upload it to our space in the Hugging Face Hub so that others can use it. To do this you need to have a Hugging Face account.</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Logging">
						<a class="anchor-link" href="#Logging">
							<p style="margin-left: 20px">Logging</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">In order to upload the model we first have to log in.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">This can be done through the terminal with</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 80px;"><code>huggingface-cli login<br></code></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Or through the notebook having previously installed the <code><b>huggingface_hub</b></code> library with</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 80px;"><code>pip install huggingface_hub<br></code></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Now we can log in with the <code><b>notebook_login</b></code> function, which will create a small graphical interface where we have to enter a Hugging Face token.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">To create a token, go to the <a href="https://huggingface.co/settings/tokens" target="_blank">setings/tokens</a> page of your account, you will see something like this</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"><p align="center"><img src="http://maximofn.com/wp-content/uploads/2024/03/User-Access-Token-dark.png" alt="User-Access-Token-dark"></p></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Click on <code><b>New token</b></code> and a window will appear to create a new token.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"><p align="center"><img src="http://maximofn.com/wp-content/uploads/2024/03/new-token-dark.png" alt="new-token-dark"></p></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">We name the token and create it with the <code><b>write</b></code> role.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Once created, we copy it</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">huggingface_hub</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">notebook_login</span></p>
<p></p>
<p><span style="color: #6b97e8;">notebook_login</span><span style="color: #e3e11d;">()</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>VBox(children=(HTML(value='&lt;center&gt; &lt;img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Up-once-trained">
						<a class="anchor-link" href="#Up-once-trained">
							<p style="margin-left: 20px">Up once trained</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">As we have trained the model we can upload it to the Hub using the <code><b>push_to_hub</b></code> function. This function has a mandatory parameter which is the name of the model, which has to be unique, if there is already a model in your Hub with that name it will not be uploaded. That is, the full name of the model will be <user>/<model>, so the model name cannot exist in your Hub, even if there is another model with the same name in the Hub of another user.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">It also has other optional, but interesting, parameters:</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">
						<ul>
							<li><code><b>use_temp_dir</b></code> (bool, optional): Whether or not to use a temporary directory to store the saved files before they are sent to the Hub. Default will be True if there is no directory with the same name as <code><b>repo_id</b></code>, False otherwise.</li>
							<li><code><b>commit_message</b></code> (str, optional): Commit message. Default will be <code><b>Upload {object}</b></code>.</li>
							<li><code><b>private</b></code> (bool, optional): Whether the created repository should be private or not.</li>
							<li><code><b>token</b></code> (bool or str, optional): The token to use as HTTP authorization for remote files. If True, the token generated by running <code><b>huggingface-cli</b></code> login (stored in ~/.huggingface) will be used. Default will be True if <code><b>repo_url</b></code> is not specified.</li>
							<li><code><b>max_shard_size</b></code> (int or str, optional, defaults to "5GB"): Only applicable to models. The maximum size of a checkpoint before it is fragmented. Fragmented checkpoints will each be smaller than this size. If expressed as a string, it must have digits followed by a unit (such as "5MB"). The default is "5GB" so that users can easily load models into free-level Google Colab instances without CPU OOM (out of memory) issues.</li>
							<li><code><b>create_pr</b></code> (bool, optional, defaults to False): Whether or not to create a PR with the uploaded files or commit directly.</li>
							<li><code><b>safe_serialization</b></code> (bool, optional, defaults to True): Whether or not to convert model weights to safetensors format for safer serialization.</li>
							<li><code><b>revision</b></code> (str, optional): Branch to send uploaded files to.</li>
							<li><code><b>commit_description</b></code> (str, optional): Description of the commit to be created</li>
							<li><code><b>tags</b></code> (List[str], optional): List of tags to insert in Hub.</li>
						</ul>
					</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">

				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">

				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">

				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">

				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">

				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">

				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">

				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">

				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">

				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">push_to_hub</span><span style="color: #e3e11d;">(</span></p>
<p>    <span style="color: #7e7a34;">&quot;bert-base-cased_notebook_transformers_5-epochs_yelp_review_subset&quot;</span><span style="color: #e3e11d;">,</span> </p>
<p>    <span style="color: #6b97e8;">commit_message</span><span>=</span><span style="color: #7e7a34;">&quot;bert base cased fine tune on yelp review subset&quot;</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">commit_description</span><span>=</span><span style="color: #7e7a34;">&quot;Fine-tuned on a subset of the yelp review dataset. Model retrained for post of transformers library. 5 epochs.&quot;</span><span style="color: #e3e11d;">,</span></p>
<p><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>CommitInfo(commit_url='https://huggingface.co/Maximofn/bert-base-cased_notebook_transformers_5-epochs_yelp_review_subset/commit/033a3c759d5a4e314ce76db81bd113b4f7da69ad', commit_message='bert base cased fine tune on yelp review subset', commit_description='Fine-tuned on a subset of the yelp review dataset. Model retrained for post of transformers library. 5 epochs.', oid='033a3c759d5a4e314ce76db81bd113b4f7da69ad', pr_url=None, pr_revision=None, pr_num=None)</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">If we now go to our Hub we can see that the model has been uploaded.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"><p align="center"><img src="http://maximofn.com/wp-content/uploads/2024/03/transformers_commit_unico.webp" alt="transformers_commit_unique"></p></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">If we now go into the model card to see</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"><p align="center"><img src="http://maximofn.com/wp-content/uploads/2024/03/transformers_commit_inico_model_card-scaled.webp" alt="transformers_commit_inico_model_card"></p></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">We see that everything is unfilled, later we will do this</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h3 id="Climbing-while-training">
						<a class="anchor-link" href="#Climbing-while-training">
							<p style="margin-left: 20px">Climbing while training</p>
						</a>
					</h3>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">Another option is to upload it while we are training the model. This is very useful when we train models for many periods and it takes us a long time, because if the training is stopped (because the computer is turned off, the colab session is finished, the cloud credits run out) the work is not lost. To do this you have to add <code><b>push_to_hub=True</b></code> in the <code><b>TrainingArguments</b></code>.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">training_args</span> <span>=</span> <span style="color: #6b97e8;">TrainingArguments</span><span style="color: #e3e11d;">(</span></p>
<p>    <span style="color: #6b97e8;">output_dir</span><span>=</span><span style="color: #7e7a34;">&quot;bert-base-cased_notebook_transformers_30-epochs_yelp_review_subset&quot;</span><span style="color: #e3e11d;">,</span> </p>
<p>    <span style="color: #6b97e8;">per_device_train_batch_size</span><span>=</span><span style="color: #7e7a38;">16</span><span style="color: #e3e11d;">,</span> </p>
<p>    <span style="color: #6b97e8;">per_device_eval_batch_size</span><span>=</span><span style="color: #7e7a38;">32</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">learning_rate</span><span>=</span><span style="color: #a09e19;">1e-4</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">num_train_epochs</span><span>=</span><span style="color: #7e7a38;">30</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">push_to_hub</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">,</span></p>
<p><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">trainer</span> <span>=</span> <span style="color: #6b97e8;">Trainer</span><span style="color: #e3e11d;">(</span></p>
<p>    <span style="color: #6b97e8;">model</span><span>=</span><span style="color: #6b97e8;">model</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">train_dataset</span><span>=</span><span style="color: #6b97e8;">tokenized_small_train_dataset</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">eval_dataset</span><span>=</span><span style="color: #6b97e8;">tokenized_small_eval_dataset</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">compute_metrics</span><span>=</span><span style="color: #6b97e8;">compute_metrics</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">args</span><span>=</span><span style="color: #6b97e8;">training_args</span><span style="color: #e3e11d;">,</span></p>
<p><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">We can see that we have changed the epochs to 30, so training is going to take longer, so adding <code><b>push_to_hub=True</b></code> will upload the model to our Hub while training.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">We have also changed the <code><b>output_dir</b></code> because it is the name that the model will have in the Hub.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">trainer</span><span>.</span><span style="color: #6b97e8;">train</span><span style="color: #e3e11d;">()</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>TrainOutput(global_step=1890, training_loss=0.07100234655318437, metrics={'train_runtime': 331.5804, 'train_samples_per_second': 90.476, 'train_steps_per_second': 5.7, 'train_loss': 0.07100234655318437, 'epoch': 30.0})</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">If we look at our hub again, the new model is now displayed.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;"></p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">transformers_commit_training](http://maximofn.com/wp-content/uploads/2024/03/transformers_commit_training.webp)</p>
				</div>
			</div>
		</div>
	</div>
	<!-- Open div header -->
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<h2 id="Hub-as-git-repository">
						<a class="anchor-link" href="#Hub-as-git-repository">
							<p style="margin-left: 10px">Hub as git repository</p>
						</a>
					</h2>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">In Hugging Face both models, spaces and datasets are git repositories, so you can work with them like that. That is, you can clone, make forks, pull requests, etc.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing text_cell rendered">
		<div class="prompt input_prompt">
			<div class="inner_cell">
				<div class="text_cell_render border-box-sizing rendered_html">
					<p style="margin-left: 0px;">But another great advantage of this is that you can use a model in a particular version.</p>
				</div>
			</div>
		</div>
	</div>
	<div class="cell border-box-sizing code_cell rendered">
		<div class="input">
			<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
			<div class="inner_cell">
				<div class="input_area">
					<div class=" highlight hl-python3">
						<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoModelForSequenceClassification</span></p>
<p></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForSequenceClassification</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;bert-base-cased&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">num_labels</span><span>=</span><span style="color: #7e7a38;">5</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">revision</span><span>=</span><span style="color: #7e7a34;">&quot;393e083&quot;</span><span style="color: #e3e11d;">)</span></p>
						</pre>
					</div>
				</div>
			</div>
		</div>
		<div class="output_wrapper">
			<div class="output">
				<div class="output_area">
					<div class="prompt" style="margin-left: 20px;">Output:</div>
					<div class="output_subarea output_stream output_stdout output_text">
						<pre style="margin-left: 60px; line-height: 0%;"><p>Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']</p><p>You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.</p></pre>
					</div>
				</div>
			</div>
		</div>
	</div>
</div>
<!-- Close class contenido -->
</div>
<!-- Close div notebook container -->
</div>
<!-- Close div notebook -->
</div>

