<section class="section-block-markdown-cell">
<h1 id="Avaliacao do rosto do abraco">Avaliação do rosto do abraço<a class="anchor-link" href="#Avaliacao do rosto do abraco">¶</a></h1>
</section>
<section class="section-block-markdown-cell">
<p>A biblioteca <code>Evaluate</code> do <code>Hugging Face</code> é uma biblioteca para avaliar facilmente modelos e conjuntos de dados.</p>
<p>Com uma única linha de código, você tem acesso a dezenas de métodos de avaliação para diferentes domínios (PNL, visão computacional, aprendizagem por reforço e outros). Seja em seu computador local ou em uma configuração de treinamento distribuído, você pode avaliar modelos de forma consistente e reproduzível.</p>
<p>Uma lista completa das métricas disponíveis pode ser encontrada na página <a href="https://huggingface.co/evaluate-metric">evaluate</a> na Hugging Face. Cada métrica tem um <code>Space</code> dedicado no Hugging Face com uma demonstração interativa sobre como usar a métrica e um cartão de documentação detalhando as limitações e o uso das métricas.</p>
</section>
<section class="section-block-markdown-cell">
<p>Este caderno foi traduzido automaticamente para torná-lo acessível a mais pessoas, por favor me avise se você vir algum erro de digitação..</p>
<h2 id="Instalacao">Instalação<a class="anchor-link" href="#Instalacao">¶</a></h2>
</section>
<section class="section-block-markdown-cell">
<p>Para instalar a biblioteca, é necessário fazer o seguinte</p>
<div class='highlight'><pre><code class="language-bash">pip install evaluate
</code></pre></div>
</section>
<section class="section-block-markdown-cell">
<h2 id="Tipo de avaliacoes">Tipo de avaliações<a class="anchor-link" href="#Tipo de avaliacoes">¶</a></h2>
</section>
<section class="section-block-markdown-cell">
<p>Há vários tipos de avaliações disponíveis</p>
<ul>
  <li>Métrica: uma métrica é usada para avaliar o desempenho de um modelo e, normalmente, inclui previsões de modelos e rótulos de verdade terrestre.</li>
  <li>Comparação: é usada para comparar dois modelos. Isso pode ser feito, por exemplo, comparando suas previsões com rótulos de verdade terrestre.</li>
  <li>Medição: o conjunto de dados é tão importante quanto o modelo treinado nele. As medições podem ser usadas para investigar as propriedades de um conjunto de dados.</li>
</ul>
</section>
<section class="section-block-markdown-cell">
<h2 id="Carga">Carga<a class="anchor-link" href="#Carga">¶</a></h2>
</section>
<section class="section-block-markdown-cell">
<p>Cada <code>metric</code>, <code>comparison</code> ou <code>measurement</code> pode ser carregado com o método load</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="w"> </span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="n">accuracy</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>EvaluationModule(name: &quot;accuracy&quot;, module_type: &quot;metric&quot;, features: &#x7B;&#x27;predictions&#x27;: Value(dtype=&#x27;int32&#x27;, id=None), &#x27;references&#x27;: Value(dtype=&#x27;int32&#x27;, id=None)&#x7D;, usage: &quot;&quot;&quot;
Args:
&#x20;&#x20;&#x20;&#x20;predictions (`list` of `int`): Predicted labels.
&#x20;&#x20;&#x20;&#x20;references (`list` of `int`): Ground truth labels.
&#x20;&#x20;&#x20;&#x20;normalize (`boolean`): If set to False, returns the number of correctly classified samples. Otherwise, returns the fraction of correctly classified samples. Defaults to True.
&#x20;&#x20;&#x20;&#x20;sample_weight (`list` of `float`): Sample weights Defaults to None.

Returns:
&#x20;&#x20;&#x20;&#x20;accuracy (`float` or `int`): Accuracy score. Minimum possible value is 0. Maximum possible value is 1.0, or the number of examples input, if `normalize` is set to `True`.. A higher score means higher accuracy.

Examples:

&#x20;&#x20;&#x20;&#x20;Example 1-A simple example
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&amp;gt;&amp;gt;&amp;gt; accuracy_metric = evaluate.load(&quot;accuracy&quot;)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&amp;gt;&amp;gt;&amp;gt; results = accuracy_metric.compute(references=[0, 1, 2, 0, 1, 2], predictions=[0, 1, 1, 2, 1, 0])
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&amp;gt;&amp;gt;&amp;gt; print(results)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x7B;&#x27;accuracy&#x27;: 0.5&#x7D;

&#x20;&#x20;&#x20;&#x20;Example 2-The same as Example 1, except with `normalize` set to `False`.
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&amp;gt;&amp;gt;&amp;gt; accuracy_metric = evaluate.load(&quot;accuracy&quot;)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&amp;gt;&amp;gt;&amp;gt; results = accuracy_metric.compute(references=[0, 1, 2, 0, 1, 2], predictions=[0, 1, 1, 2, 1, 0], normalize=False)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&amp;gt;&amp;gt;&amp;gt; print(results)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x7B;&#x27;accuracy&#x27;: 3.0&#x7D;

&#x20;&#x20;&#x20;&#x20;Example 3-The same as Example 1, except with `sample_weight` set.
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&amp;gt;&amp;gt;&amp;gt; accuracy_metric = evaluate.load(&quot;accuracy&quot;)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&amp;gt;&amp;gt;&amp;gt; results = accuracy_metric.compute(references=[0, 1, 2, 0, 1, 2], predictions=[0, 1, 1, 2, 1, 0], sample_weight=[0.5, 2, 0.7, 0.5, 9, 0.4])
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&amp;gt;&amp;gt;&amp;gt; print(results)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x7B;&#x27;accuracy&#x27;: 0.8778625954198473&#x7D;
&quot;&quot;&quot;, stored examples: 0)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Se quiser ter certeza de que está carregando o tipo de métrica que deseja, seja <code>metric</code>, <code>comparison</code> ou <code>measurement</code>, você pode fazer isso adicionando o parâmetro <code>module_type</code>.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="w"> </span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">,</span> <span class="n">module_type</span><span class="o">=</span><span class="s2">&quot;metric&quot;</span><span class="p">)</span>
<span class="n">word_length</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;word_length&quot;</span><span class="p">,</span> <span class="n">module_type</span><span class="o">=</span><span class="s2">&quot;measurement&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>[nltk_data] Downloading package punkt to
[nltk_data]     /home/maximo.fernandez/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Carregamento dos modulos da comunidade">Carregamento dos módulos da comunidade<a class="anchor-link" href="#Carregamento dos modulos da comunidade">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Além dos módulos oferecidos pela própria biblioteca, você também pode carregar modelos carregados por outra pessoa no hub do Hugging Face.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">element_count</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;lvwerra/element_count&quot;</span><span class="p">,</span> <span class="n">module_type</span><span class="o">=</span><span class="s2">&quot;measurement&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Lista de modulos disponiveis">Lista de módulos disponíveis<a class="anchor-link" href="#Lista de modulos disponiveis">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Se quisermos obter uma lista de todos os módulos disponíveis, teremos que usar o método <code>list_evaluation_modules</code>, no qual podemos colocar filtros de pesquisa</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">evaluate</span><span class="o">.</span><span class="n">list_evaluation_modules</span><span class="p">(</span>
<span class="w">  </span><span class="n">module_type</span><span class="o">=</span><span class="s2">&quot;comparison&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="n">include_community</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="w">  </span><span class="n">with_details</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>[&#x7B;&#x27;name&#x27;: &#x27;ncoop57/levenshtein_distance&#x27;,
&#x20;&#x20;&#x27;type&#x27;: &#x27;comparison&#x27;,
&#x20;&#x20;&#x27;community&#x27;: True,
&#x20;&#x20;&#x27;likes&#x27;: 0&#x7D;,
 &#x7B;&#x27;name&#x27;: &#x27;kaleidophon/almost_stochastic_order&#x27;,
&#x20;&#x20;&#x27;type&#x27;: &#x27;comparison&#x27;,
&#x20;&#x20;&#x27;community&#x27;: True,
&#x20;&#x20;&#x27;likes&#x27;: 1&#x7D;]
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h2 id="Atributos do modulo">Atributos do módulo<a class="anchor-link" href="#Atributos do modulo">¶</a></h2>
</section>
<section class="section-block-markdown-cell">
<p>Todos os módulos de avaliação vêm com uma variedade de atributos úteis que ajudam a usar o módulo, esses atributos são</p>
<table>
  <thead>
    <tr>
      <th>Atributo</th>
      <th>Descrição</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Descrição: uma breve descrição do módulo de avaliação.</td>
      <td></td>
    </tr>
    <tr>
      <td>citation</td>
      <td>Uma cadeia de caracteres BibTex a ser citada quando disponível.</td>
    </tr>
    <tr>
      <td>features</td>
      <td>Um objeto Features que define o formato de entrada.</td>
    </tr>
    <tr>
      <td>Isso é equivalente à string de documentação do módulo.</td>
      <td></td>
    </tr>
    <tr>
      <td>homepage</td>
      <td>A página inicial do módulo.</td>
    </tr>
    <tr>
      <td>license</td>
      <td>A licença do módulo.</td>
    </tr>
    <tr>
      <td>codebase_urls</td>
      <td>Link para o código por trás do módulo.</td>
    </tr>
    <tr>
      <td>reference_urls</td>
      <td>URLs de referência adicionais.</td>
    </tr>
  </tbody>
</table>
</section>
<section class="section-block-markdown-cell">
<p>Vamos dar uma olhada em alguns deles</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;description: </span><span class="si">{</span><span class="n">accuracy</span><span class="o">.</span><span class="n">description</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">citation: </span><span class="si">{</span><span class="n">accuracy</span><span class="o">.</span><span class="n">citation</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">features: </span><span class="si">{</span><span class="n">accuracy</span><span class="o">.</span><span class="n">features</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">inputs_description: </span><span class="si">{</span><span class="n">accuracy</span><span class="o">.</span><span class="n">inputs_description</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">homepage: </span><span class="si">{</span><span class="n">accuracy</span><span class="o">.</span><span class="n">homepage</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">license: </span><span class="si">{</span><span class="n">accuracy</span><span class="o">.</span><span class="n">license</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">codebase_urls: </span><span class="si">{</span><span class="n">accuracy</span><span class="o">.</span><span class="n">codebase_urls</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">reference_urls: </span><span class="si">{</span><span class="n">accuracy</span><span class="o">.</span><span class="n">reference_urls</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>description: 
Accuracy is the proportion of correct predictions among the total number of cases processed. It can be computed with:
Accuracy = (TP + TN) / (TP + TN + FP + FN)
 Where:
TP: True positive
TN: True negative
FP: False positive
FN: False negative


citation: 
@article&#x7B;scikit-learn,
&#x20;&#x20;title=&#x7B;Scikit-learn: Machine Learning in &#x7B;P&#x7D;ython&#x7D;,
&#x20;&#x20;author=&#x7B;Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.&#x7D;,
&#x20;&#x20;journal=&#x7B;Journal of Machine Learning Research&#x7D;,
&#x20;&#x20;volume=&#x7B;12&#x7D;,
&#x20;&#x20;pages=&#x7B;2825--2830&#x7D;,
&#x20;&#x20;year=&#x7B;2011&#x7D;
&#x7D;


features: &#x7B;&#x27;predictions&#x27;: Value(dtype=&#x27;int32&#x27;, id=None), &#x27;references&#x27;: Value(dtype=&#x27;int32&#x27;, id=None)&#x7D;

inputs_description: 
Args:
&#x20;&#x20;&#x20;&#x20;predictions (`list` of `int`): Predicted labels.
&#x20;&#x20;&#x20;&#x20;references (`list` of `int`): Ground truth labels.
&#x20;&#x20;&#x20;&#x20;normalize (`boolean`): If set to False, returns the number of correctly classified samples. Otherwise, returns the fraction of correctly classified samples. Defaults to True.
&#x20;&#x20;&#x20;&#x20;sample_weight (`list` of `float`): Sample weights Defaults to None.

Returns:
&#x20;&#x20;&#x20;&#x20;accuracy (`float` or `int`): Accuracy score. Minimum possible value is 0. Maximum possible value is 1.0, or the number of examples input, if `normalize` is set to `True`.. A higher score means higher accuracy.

Examples:

&#x20;&#x20;&#x20;&#x20;Example 1-A simple example
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&amp;gt;&amp;gt;&amp;gt; accuracy_metric = evaluate.load(&quot;accuracy&quot;)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&amp;gt;&amp;gt;&amp;gt; results = accuracy_metric.compute(references=[0, 1, 2, 0, 1, 2], predictions=[0, 1, 1, 2, 1, 0])
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&amp;gt;&amp;gt;&amp;gt; print(results)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x7B;&#x27;accuracy&#x27;: 0.5&#x7D;

&#x20;&#x20;&#x20;&#x20;Example 2-The same as Example 1, except with `normalize` set to `False`.
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&amp;gt;&amp;gt;&amp;gt; accuracy_metric = evaluate.load(&quot;accuracy&quot;)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&amp;gt;&amp;gt;&amp;gt; results = accuracy_metric.compute(references=[0, 1, 2, 0, 1, 2], predictions=[0, 1, 1, 2, 1, 0], normalize=False)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&amp;gt;&amp;gt;&amp;gt; print(results)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x7B;&#x27;accuracy&#x27;: 3.0&#x7D;

&#x20;&#x20;&#x20;&#x20;Example 3-The same as Example 1, except with `sample_weight` set.
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&amp;gt;&amp;gt;&amp;gt; accuracy_metric = evaluate.load(&quot;accuracy&quot;)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&amp;gt;&amp;gt;&amp;gt; results = accuracy_metric.compute(references=[0, 1, 2, 0, 1, 2], predictions=[0, 1, 1, 2, 1, 0], sample_weight=[0.5, 2, 0.7, 0.5, 9, 0.4])
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&amp;gt;&amp;gt;&amp;gt; print(results)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x7B;&#x27;accuracy&#x27;: 0.8778625954198473&#x7D;


homepage: 

license: 

codebase_urls: []

reference_urls: [&#x27;https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html&#x27;]
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h2 id="Execucao">Execução<a class="anchor-link" href="#Execucao">¶</a></h2>
</section>
<section class="section-block-markdown-cell">
<p>Agora que sabemos como o módulo de avaliação funciona e o que ele deve conter, vamos usá-lo. Quando se trata de calcular a avaliação, há duas maneiras principais de fazer isso:</p>
<ul>
  <li>Tudo em um</li>
  <li>Incremental</li>
</ul>
<p>Na abordagem incremental, as entradas necessárias são adicionadas ao módulo com <code>EvaluationModule.add()</code> ou <code>EvaluationModule.add_batch()</code> e a pontuação é calculada no final com <code>EvaluationModule.compute()</code>. Como alternativa, todas as entradas podem ser passadas de uma só vez para <code>compute()</code>.</p>
<p>Vamos dar uma olhada nessas duas abordagens.</p>
</section>
<section class="section-block-markdown-cell">
<h3 id="Tudo em um">Tudo em um<a class="anchor-link" href="#Tudo em um">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Quando tivermos todas as previsões e a verdade básica, poderemos calcular a métrica. Assim que tivermos um módulo definido, passaremos a ele as previsões e a verdade fundamental usando o método <code>compute()</code>.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">predictions</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">targets</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="w"> </span>
<span class="n">accuracy_value</span> <span class="o">=</span> <span class="n">accuracy</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">targets</span><span class="p">)</span>
<span class="n">accuracy_value</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&#x7B;&#x27;accuracy&#x27;: 0.5&#x7D;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Incremental">Incremental<a class="anchor-link" href="#Incremental">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Em muitos processos de avaliação, as previsões são criadas iterativamente, como em um loop for. Nesse caso, você poderia armazenar os predicados e a verdade básica em uma lista e, em seguida, passá-los para <code>compute()</code>.</p>
<p>No entanto, com os métodos <code>add()</code> e <code>add_batch()</code>, você pode evitar a etapa de armazenamento de previsões.</p>
</section>
<section class="section-block-markdown-cell">
<p>Se você tiver todas as previsões em um único lote, use o método <code>add()</code>.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">ref</span><span class="p">,</span> <span class="n">pred</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]):</span>
<span class="w">    </span><span class="n">accuracy</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">references</span><span class="o">=</span><span class="n">ref</span><span class="p">,</span> <span class="n">predictions</span><span class="o">=</span><span class="n">pred</span><span class="p">)</span>
<span class="n">accuracy_value</span> <span class="o">=</span> <span class="n">accuracy</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="n">accuracy_value</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&#x7B;&#x27;accuracy&#x27;: 0.5&#x7D;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>No entanto, quando você tem previsões para vários lotes, é necessário usar o método <code>add_batch()</code>.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">refs</span><span class="p">,</span> <span class="n">preds</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]]):</span>
<span class="w">    </span><span class="n">accuracy</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">references</span><span class="o">=</span><span class="n">refs</span><span class="p">,</span> <span class="n">predictions</span><span class="o">=</span><span class="n">preds</span><span class="p">)</span>
<span class="n">accuracy_value</span> <span class="o">=</span> <span class="n">accuracy</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="n">accuracy_value</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&#x7B;&#x27;accuracy&#x27;: 0.5&#x7D;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h2 id="Combinacao de varias avaliacoes">Combinação de várias avaliações<a class="anchor-link" href="#Combinacao de varias avaliacoes">¶</a></h2>
</section>
<section class="section-block-markdown-cell">
<p>Geralmente, deseja-se avaliar não apenas uma única métrica, mas também uma variedade de métricas diferentes que capturam diferentes aspectos de um modelo. Por exemplo, para a classificação, geralmente é uma boa ideia calcular <code>F1</code>, <code>recall</code> e <code>accuracy</code> além da <code>accuracy</code> para obter uma visão melhor do desempenho do modelo. No entanto, a maneira mais conveniente é usar a função <code>combine()</code> para agrupá-las.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">clasification_metrics</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">combine</span><span class="p">([</span><span class="s2">&quot;accuracy&quot;</span><span class="p">,</span> <span class="s2">&quot;f1&quot;</span><span class="p">,</span> <span class="s2">&quot;precision&quot;</span><span class="p">,</span> <span class="s2">&quot;recall&quot;</span><span class="p">])</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">predictions</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">targets</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="w"> </span>
<span class="n">clasification_metrics</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">targets</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&#x7B;&#x27;accuracy&#x27;: 0.6666666666666666,
 &#x27;f1&#x27;: 0.6666666666666666,
 &#x27;precision&#x27;: 1.0,
 &#x27;recall&#x27;: 0.5&#x7D;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h2 id="Salvar resultados">Salvar resultados<a class="anchor-link" href="#Salvar resultados">¶</a></h2>
</section>
<section class="section-block-markdown-cell">
<p>Podemos salvar os resultados da avaliação em um arquivo com o método <code>save()</code> passando um nome de arquivo. Podemos passar parâmetros como o número do experimento</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">references</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
<span class="n">targets</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
<span class="w"> </span>
<span class="n">result</span> <span class="o">=</span> <span class="n">accuracy</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">references</span><span class="o">=</span><span class="n">references</span><span class="p">,</span> <span class="n">predictions</span><span class="o">=</span><span class="n">targets</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">hyperparams</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;bert-base-uncased&quot;</span><span class="p">}</span>
<span class="n">evaluate</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;./results/&quot;</span><span class="p">,</span> <span class="n">experiment</span><span class="o">=</span><span class="s2">&quot;run 42&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">result</span><span class="p">,</span> <span class="o">**</span><span class="n">hyperparams</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>PosixPath(&#x27;results/result-2024_04_25-17_45_41.json&#x27;)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Como podemos ver, tivemos que criar uma variável <code>hyperparams</code> para passá-la para o método <code>save()</code>. Normalmente, isso não será necessário porque já teremos as variáveis do modelo que estamos treinando.</p>
</section>
<section class="section-block-markdown-cell">
<p>Isso criará um <code>json</code> com todas as informações.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pathlib</span>
<span class="w"> </span>
<span class="n">path</span> <span class="o">=</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="s2">&quot;./results/&quot;</span><span class="p">)</span>
<span class="n">files</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">path</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s2">&quot;*&quot;</span><span class="p">))</span>
<span class="n">files</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>[PosixPath(&#x27;results/result-2024_04_25-17_45_41.json&#x27;)]
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
<span class="n">result_file</span> <span class="o">=</span> <span class="n">files</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">result_json</span> <span class="o">=</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="n">result_file</span><span class="p">)</span><span class="o">.</span><span class="n">read_text</span><span class="p">()</span>
<span class="n">result_dict</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">result_json</span><span class="p">)</span>
<span class="n">result_dict</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&#x7B;&#x27;experiment&#x27;: &#x27;run 42&#x27;,
 &#x27;accuracy&#x27;: 0.5,
 &#x27;model&#x27;: &#x27;bert-base-uncased&#x27;,
 &#x27;_timestamp&#x27;: &#x27;2024-04-25T17:45:41.218287&#x27;,
 &#x27;_git_commit_hash&#x27;: &#x27;8725338b6bf9c97274685df41b2ee6e11319a735&#x27;,
 &#x27;_evaluate_version&#x27;: &#x27;0.4.1&#x27;,
 &#x27;_python_version&#x27;: &#x27;3.11.7 (main, Dec 15 2023, 18:12:31) [GCC 11.2.0]&#x27;,
 &#x27;_interpreter_path&#x27;: &#x27;/home/maximo.fernandez/miniconda3/envs/nlp/bin/python&#x27;&#x7D;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h2 id="Fazer upload dos resultados para o hub">Fazer upload dos resultados para o hub<a class="anchor-link" href="#Fazer upload dos resultados para o hub">¶</a></h2>
</section>
<section class="section-block-markdown-cell">
<p>Caso estejamos treinando um modelo, podemos carregar no cartão do modelo os resultados da avaliação com o método <code>push_to_hub()</code>. Dessa forma, eles aparecerão na página do modelo.</p>
</section>
<section class="section-block-markdown-cell">
<h2 id="Avaliador">Avaliador<a class="anchor-link" href="#Avaliador">¶</a></h2>
</section>
<section class="section-block-markdown-cell">
<p>Se tivermos um modelo, um conjunto de dados e uma métrica, poderemos fazer inferência em todo o conjunto de dados e passar as previsões e os rótulos reais para o avaliador para retornar a métrica e obter as métricas do modelo.</p>
<p>Ou podemos fornecer tudo à biblioteca e deixar que ela faça o trabalho por nós. Usando o método <code>evaluator()</code>, passamos a ela o modelo, o conjunto de dados e a métrica, e o método faz tudo por nós.</p>
</section>
<section class="section-block-markdown-cell">
<p>Primeiro, definimos o modelo, o conjunto de dados e as métricas.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">pipeline</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">evaluate</span><span class="w"> </span><span class="kn">import</span> <span class="n">evaluator</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="w"> </span>
<span class="n">model_pipeline</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">&quot;text-classification&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s2">&quot;lvwerra/distilbert-imdb&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;imdb&quot;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;test&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">shuffle</span><span class="p">()</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">))</span>
<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Agora passamos tudo para <code>evaluator()</code>.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">task_evaluator</span> <span class="o">=</span> <span class="n">evaluator</span><span class="p">(</span><span class="s2">&quot;text-classification&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">results</span> <span class="o">=</span> <span class="n">task_evaluator</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">model_or_pipeline</span><span class="o">=</span><span class="n">model_pipeline</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="n">metric</span><span class="p">,</span>
<span class="w">                       </span><span class="n">label_mapping</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;NEGATIVE&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;POSITIVE&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">},)</span>
<span class="n">results</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&#x7B;&#x27;accuracy&#x27;: 0.933,
 &#x27;total_time_in_seconds&#x27;: 29.43192940400013,
 &#x27;samples_per_second&#x27;: 33.97670557962431,
 &#x27;latency_in_seconds&#x27;: 0.02943192940400013&#x7D;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Graças ao avaliador, conseguimos obter as métricas do modelo sem precisar fazer a inferência por conta própria.</p>
</section>
<section class="section-block-markdown-cell">
<h2 id="Visualizacao">Visualização<a class="anchor-link" href="#Visualizacao">¶</a></h2>
</section>
<section class="section-block-markdown-cell">
<p>Às vezes, obtemos métricas diferentes para modelos diferentes, o que dificulta a comparação entre eles, por isso os gráficos facilitam essa tarefa.</p>
<p>A biblioteca <code>Evaluate</code> oferece diferentes visualizações por meio do método <code>visualization()</code>. Temos que passar os dados para ela como uma lista de dicionários, em que cada dicionário deve ter as mesmas chaves</p>
</section>
<section class="section-block-markdown-cell">
<p>Para usar essa função, você precisa ter a biblioteca <code>matplotlib</code> instalada.</p>
<div class='highlight'><pre><code class="language-bash">pip install matplotlib
</code></pre></div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">evaluate.visualization</span><span class="w"> </span><span class="kn">import</span> <span class="n">radar_plot</span>
<span class="w"> </span>
<span class="n">data</span> <span class="o">=</span> <span class="p">[</span>
<span class="w">   </span><span class="p">{</span><span class="s2">&quot;accuracy&quot;</span><span class="p">:</span> <span class="mf">0.99</span><span class="p">,</span> <span class="s2">&quot;precision&quot;</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">,</span> <span class="s2">&quot;f1&quot;</span><span class="p">:</span> <span class="mf">0.95</span><span class="p">,</span> <span class="s2">&quot;latency_in_seconds&quot;</span><span class="p">:</span> <span class="mf">33.6</span><span class="p">},</span>
<span class="w">   </span><span class="p">{</span><span class="s2">&quot;accuracy&quot;</span><span class="p">:</span> <span class="mf">0.98</span><span class="p">,</span> <span class="s2">&quot;precision&quot;</span><span class="p">:</span> <span class="mf">0.87</span><span class="p">,</span> <span class="s2">&quot;f1&quot;</span><span class="p">:</span> <span class="mf">0.91</span><span class="p">,</span> <span class="s2">&quot;latency_in_seconds&quot;</span><span class="p">:</span> <span class="mf">11.2</span><span class="p">},</span>
<span class="w">   </span><span class="p">{</span><span class="s2">&quot;accuracy&quot;</span><span class="p">:</span> <span class="mf">0.98</span><span class="p">,</span> <span class="s2">&quot;precision&quot;</span><span class="p">:</span> <span class="mf">0.78</span><span class="p">,</span> <span class="s2">&quot;f1&quot;</span><span class="p">:</span> <span class="mf">0.88</span><span class="p">,</span> <span class="s2">&quot;latency_in_seconds&quot;</span><span class="p">:</span> <span class="mf">87.6</span><span class="p">},</span> 
<span class="w">   </span><span class="p">{</span><span class="s2">&quot;accuracy&quot;</span><span class="p">:</span> <span class="mf">0.88</span><span class="p">,</span> <span class="s2">&quot;precision&quot;</span><span class="p">:</span> <span class="mf">0.78</span><span class="p">,</span> <span class="s2">&quot;f1&quot;</span><span class="p">:</span> <span class="mf">0.81</span><span class="p">,</span> <span class="s2">&quot;latency_in_seconds&quot;</span><span class="p">:</span> <span class="mf">101.6</span><span class="p">}</span>
<span class="w">   </span><span class="p">]</span>
<span class="w"> </span>
<span class="n">model_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Model 1&quot;</span><span class="p">,</span> <span class="s2">&quot;Model 2&quot;</span><span class="p">,</span> <span class="s2">&quot;Model 3&quot;</span><span class="p">,</span> <span class="s2">&quot;Model 4&quot;</span><span class="p">]</span>
<span class="w"> </span>
<span class="n">plot</span> <span class="o">=</span> <span class="n">radar_plot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">model_names</span><span class="o">=</span><span class="n">model_names</span><span class="p">)</span>
<span class="n">plot</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>/tmp/ipykernel_10271/263559674.py:14: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown
&#x20;&#x20;plot.show()
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&amp;lt;Figure size 640x480 with 5 Axes&amp;gt;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Agora podemos comparar visualmente os quatro modelos e escolher o melhor, com base em uma ou várias métricas</p>
</section>
<section class="section-block-markdown-cell">
<h2 id="Avaliando o modelo em um conjunto de tarefas">Avaliando o modelo em um conjunto de tarefas<a class="anchor-link" href="#Avaliando o modelo em um conjunto de tarefas">¶</a></h2>
</section>
<section class="section-block-markdown-cell">
<p>Podemos avaliar um modelo, por exemplo, para diferentes conjuntos de dados. Para isso, podemos usar o método <code>evaluation_suite</code>. Por exemplo, vamos criar um avaliador que avalia um modelo nos conjuntos de dados <code>imdb</code> e <code>sst2</code>. Vamos dar uma olhada nesses conjuntos de dados e, para isso, usaremos o método <code>load_dataset_builder</code> para não precisarmos fazer download de todo o conjunto de dados.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset_builder</span>
<span class="n">imdb</span> <span class="o">=</span> <span class="n">load_dataset_builder</span><span class="p">(</span><span class="s2">&quot;imdb&quot;</span><span class="p">)</span>
<span class="n">imdb</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&#x7B;&#x27;text&#x27;: Value(dtype=&#x27;string&#x27;, id=None),
 &#x27;label&#x27;: ClassLabel(names=[&#x27;neg&#x27;, &#x27;pos&#x27;], id=None)&#x7D;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset_builder</span>
<span class="n">sst2</span> <span class="o">=</span> <span class="n">load_dataset_builder</span><span class="p">(</span><span class="s2">&quot;sst2&quot;</span><span class="p">)</span>
<span class="n">sst2</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&#x7B;&#x27;idx&#x27;: Value(dtype=&#x27;int32&#x27;, id=None),
 &#x27;sentence&#x27;: Value(dtype=&#x27;string&#x27;, id=None),
 &#x27;label&#x27;: ClassLabel(names=[&#x27;negative&#x27;, &#x27;positive&#x27;], id=None)&#x7D;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Como podemos ver, com o conjunto de dados <code>imdb</code>, precisamos pegar a coluna <code>text</code> para obter o texto e a coluna <code>label</code> para obter o destino. Com o conjunto de dados <code>sst2</code>, precisamos pegar a coluna <code>sentence</code> para obter o texto e a coluna <code>label</code> para obter o destino.</p>
</section>
<section class="section-block-markdown-cell">
<p>Criamos o avaliador para os dois conjuntos de dados</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">evaluate.evaluation_suite</span><span class="w"> </span><span class="kn">import</span> <span class="n">SubTask</span>
<span class="w"> </span>
<span class="k">class</span><span class="w"> </span><span class="nc">Suite</span><span class="p">(</span><span class="n">evaluate</span><span class="o">.</span><span class="n">EvaluationSuite</span><span class="p">):</span>
<span class="w"> </span>
<span class="w">    </span><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
<span class="w">        </span><span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="bp">self</span><span class="o">.</span><span class="n">suite</span> <span class="o">=</span> <span class="p">[</span>
<span class="w">            </span><span class="n">SubTask</span><span class="p">(</span>
<span class="w">                </span><span class="n">task_type</span><span class="o">=</span><span class="s2">&quot;text-classification&quot;</span><span class="p">,</span>
<span class="w">                </span><span class="n">data</span><span class="o">=</span><span class="s2">&quot;imdb&quot;</span><span class="p">,</span>
<span class="w">                </span><span class="n">split</span><span class="o">=</span><span class="s2">&quot;test[:1]&quot;</span><span class="p">,</span>
<span class="w">                </span><span class="n">args_for_task</span><span class="o">=</span><span class="p">{</span>
<span class="w">                    </span><span class="s2">&quot;metric&quot;</span><span class="p">:</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">,</span>
<span class="w">                    </span><span class="s2">&quot;input_column&quot;</span><span class="p">:</span> <span class="s2">&quot;text&quot;</span><span class="p">,</span>
<span class="w">                    </span><span class="s2">&quot;label_column&quot;</span><span class="p">:</span> <span class="s2">&quot;label&quot;</span><span class="p">,</span>
<span class="w">                    </span><span class="s2">&quot;label_mapping&quot;</span><span class="p">:</span> <span class="p">{</span>
<span class="w">                        </span><span class="s2">&quot;LABEL_0&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
<span class="w">                        </span><span class="s2">&quot;LABEL_1&quot;</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="w">                    </span><span class="p">}</span>
<span class="w">                </span><span class="p">}</span>
<span class="w">            </span><span class="p">),</span>
<span class="w">            </span><span class="n">SubTask</span><span class="p">(</span>
<span class="w">                </span><span class="n">task_type</span><span class="o">=</span><span class="s2">&quot;text-classification&quot;</span><span class="p">,</span>
<span class="w">                </span><span class="n">data</span><span class="o">=</span><span class="s2">&quot;sst2&quot;</span><span class="p">,</span>
<span class="w">                </span><span class="n">split</span><span class="o">=</span><span class="s2">&quot;test[:1]&quot;</span><span class="p">,</span>
<span class="w">                </span><span class="n">args_for_task</span><span class="o">=</span><span class="p">{</span>
<span class="w">                    </span><span class="s2">&quot;metric&quot;</span><span class="p">:</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">,</span>
<span class="w">                    </span><span class="s2">&quot;input_column&quot;</span><span class="p">:</span> <span class="s2">&quot;sentence&quot;</span><span class="p">,</span>
<span class="w">                    </span><span class="s2">&quot;label_column&quot;</span><span class="p">:</span> <span class="s2">&quot;label&quot;</span><span class="p">,</span>
<span class="w">                    </span><span class="s2">&quot;label_mapping&quot;</span><span class="p">:</span> <span class="p">{</span>
<span class="w">                        </span><span class="s2">&quot;LABEL_0&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
<span class="w">                        </span><span class="s2">&quot;LABEL_1&quot;</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="w">                    </span><span class="p">}</span>
<span class="w">                </span><span class="p">}</span>
<span class="w">            </span><span class="p">)</span>
<span class="w">        </span><span class="p">]</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Você pode ver em <code>split=&quot;test[:1]&quot;,</code> que só pegamos um exemplo do subconjunto de teste para esse notebook e que a execução não demora muito.</p>
</section>
<section class="section-block-markdown-cell">
<p>Agora avaliamos com o modelo <code>huggingface/prunebert-base-uncased-6-finepruned-w-distil-mnli</code></p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">evaluate</span><span class="w"> </span><span class="kn">import</span> <span class="n">EvaluationSuite</span>
<span class="n">suite</span> <span class="o">=</span> <span class="n">EvaluationSuite</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;mathemakitten/sentiment-evaluation-suite&#39;</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">suite</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s2">&quot;huggingface/prunebert-base-uncased-6-finepruned-w-distil-mnli&quot;</span><span class="p">)</span>
<span class="n">results</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>`data` is a preloaded Dataset! Ignoring `subset` and `split`.
`data` is a preloaded Dataset! Ignoring `subset` and `split`.
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>[&#x7B;&#x27;accuracy&#x27;: 0.3,
&#x20;&#x20;&#x27;total_time_in_seconds&#x27;: 1.4153412349987775,
&#x20;&#x20;&#x27;samples_per_second&#x27;: 7.06543394110088,
&#x20;&#x20;&#x27;latency_in_seconds&#x27;: 0.14153412349987776,
&#x20;&#x20;&#x27;task_name&#x27;: &#x27;imdb&#x27;,
&#x20;&#x20;&#x27;data_preprocessor&#x27;: &#x27;&amp;lt;function Suite.__init__.&amp;lt;locals&amp;gt;.&amp;lt;lambda&amp;gt; at 0x7f3ff27a5080&amp;gt;&#x27;&#x7D;,
 &#x7B;&#x27;accuracy&#x27;: 0.0,
&#x20;&#x20;&#x27;total_time_in_seconds&#x27;: 0.1323430729971733,
&#x20;&#x20;&#x27;samples_per_second&#x27;: 75.56118936586572,
&#x20;&#x20;&#x27;latency_in_seconds&#x27;: 0.013234307299717328,
&#x20;&#x20;&#x27;task_name&#x27;: &#x27;sst2&#x27;,
&#x20;&#x20;&#x27;data_preprocessor&#x27;: &#x27;&amp;lt;function Suite.__init__.&amp;lt;locals&amp;gt;.&amp;lt;lambda&amp;gt; at 0x7f3f2a9cc720&amp;gt;&#x27;&#x7D;]
</pre>
</div>
</div>
</div>
</section>