<section class="section-block-markdown-cell">
<h1 id="Hugging Face Accelerate">Hugging Face Accelerate<a class="anchor-link" href="#Hugging Face Accelerate">¶</a></h1>
</section>
<section class="section-block-markdown-cell">
<p><code>Accelerate</code> es una biblioteca de Hugging Face que permite ejecutar el mismo código PyTorch en cualquier configuración distribuida añadiendo sólo cuatro líneas de código.</p>
</section>
<section class="section-block-markdown-cell">
<h2 id="Instalacion">Instalación<a class="anchor-link" href="#Instalacion">¶</a></h2>
</section>
<section class="section-block-markdown-cell">
<p>Para instalar <code>accelerate</code> con <code>pip</code> simplemente ejecuta:</p>
<div class='highlight'><pre><code class="language-bash">pip install accelerate
</code></pre></div>
<p>Y con <code>conda</code>:</p>
<div class='highlight'><pre><code class="language-bash">conda install -c conda-forge accelerate
</code></pre></div>
</section>
<section class="section-block-markdown-cell">
<h2 id="Configuracion">Configuración<a class="anchor-link" href="#Configuracion">¶</a></h2>
</section>
<section class="section-block-markdown-cell">
<p>En cada entorno en el que se instale <code>accelerate</code> lo primero que se tiene que hacer es configurarlo, para ello ejecutamos en una terminal:</p>
<div class='highlight'><pre><code class="language-bash">accelerate config
</code></pre></div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="err">!</span><span class="n">accelerate</span> <span class="n">config</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>--------------------------------------------------------------------------------
In which compute environment are you running?
This machine
--------------------------------------------------------------------------------
multi-GPU
How many different machines will you use (use more than 1 for multi-node training)? [1]: 1
Should distributed operations be checked while running for errors? This can avoid timeout issues but will be slower. [yes/NO]: no
Do you wish to optimize your script with torch dynamo?[yes/NO]:no
Do you want to use DeepSpeed? [yes/NO]: no
Do you want to use FullyShardedDataParallel? [yes/NO]: no
Do you want to use Megatron-LM ? [yes/NO]: no
How many GPU(s) should be used for distributed training? [1]:2
What GPU(s) (by id) should be used for training on this machine as a comma-seperated list? [all]:0,1
--------------------------------------------------------------------------------
Do you wish to use FP16 or BF16 (mixed precision)?
no
accelerate configuration saved at ~/.cache/huggingface/accelerate/default_config.yaml
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>En mi caso las respuestas han sido</p>
<ul>
  <li>In which compute environment are you running?</li>
    <ul>
      <li>[x] "This machine"</li>
      <li>[_] "AWS (Amazon SageMaker)"</li>
    </ul>
</ul>
<p>> Quiero configurarlo en mi ordenador</p>
<ul>
  <li>Which type of machine are you using?</li>
    <ul>
      <li>[_] multi-CPU</li>
      <li>[_] multi-XPU</li>
      <li>[x] multi-GPU</li>
      <li>[_] multi-NPU</li>
      <li>[_] TPU</li>
    </ul>
</ul>
<p>> Como tengo 2 GPUs y quiero ejecutar códigos distribuidos en ellas, elijo `multi-GPU`</p>
<ul>
  <li>How many different machines will you use (use more than 1 for multi-node training)? [1]:</li>
    <ul>
      <li>1</li>
    </ul>
</ul>
<p>> Elijo `1` porque solo voy a ejecutar en mi ordenador</p>
<ul>
  <li>Should distributed operations be checked while running for errors? This can avoid timeout issues but will be slower. [yes/NO]:</li>
    <ul>
      <li>no</li>
    </ul>
</ul>
<p>> Con esta opción, se puede elegir que `accelerate` chequee errores en la ejecución, pero haría que vaya más lento, así que elijo `no`, y en caso de que haya errores lo cambio a `yes`</p>
<ul>
  <li>Do you wish to optimize your script with torch dynamo?[yes/NO]:</li>
    <ul>
      <li>no</li>
    </ul>
</ul>
<ul>
  <li>Do you want to use FullyShardedDataParallel? [yes/NO]:</li>
    <ul>
      <li>no</li>
    </ul>
</ul>
<ul>
  <li>Do you want to use Megatron-LM ? [yes/NO]:</li>
    <ul>
      <li>no</li>
    </ul>
</ul>
<ul>
  <li>How many GPU(s) should be used for distributed training? [1]:</li>
    <ul>
      <li>2</li>
    </ul>
</ul>
<p>> Elijo `2` porque tengo 2 GPUs</p>
<ul>
  <li>What GPU(s) (by id) should be used for training on this machine as a comma-seperated list? [all]:</li>
    <ul>
      <li>0,1</li>
    </ul>
</ul>
<p>> Elijo `0,1` porque quiero usar las dos GPUs</p>
<ul>
  <li>Do you wish to use FP16 or BF16 (mixed precision)?</li>
    <ul>
      <li>[x] no</li>
      <li>[_] fp16</li>
      <li>[_] bf16</li>
      <li>[_] fp8</li>
    </ul>
</ul>
<p>> De momento elijo `no`, porque para simplificar el código cuando no uso `acelerate` vamos a entrenar en fp32, pero lo ideal sería usar fp16</p>
</section>
<section class="section-block-markdown-cell">
<p>La configuración se guardará en <code>~/.cache/huggingface/accelerate/default_config.yaml</code> y se puede modificar en cualquier momento. Vamos a ver qué hay dentro</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="err">!</span><span class="n">cat</span> <span class="o">~/.</span><span class="n">cache</span><span class="o">/</span><span class="n">huggingface</span><span class="o">/</span><span class="n">accelerate</span><span class="o">/</span><span class="n">default_config</span><span class="o">.</span><span class="n">yaml</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>compute_environment: LOCAL_MACHINE
debug: false
distributed_type: MULTI_GPU
downcast_bf16: &#x27;no&#x27;
gpu_ids: 0,1
machine_rank: 0
main_training_function: main
mixed_precision: fp16
num_machines: 1
num_processes: 2
rdzv_backend: static
same_network: true
tpu_env: []
tpu_use_cluster: false
tpu_use_sudo: false
use_cpu: false
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Otra forma de ver la configuración que tenemos es ejecutando en una terminal:</p>
<div class='highlight'><pre><code class="language-bash">accelerate env
</code></pre></div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="err">!</span><span class="n">accelerate</span> <span class="n">env</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>
Copy-and-paste the text below in your GitHub issue

- `Accelerate` version: 0.28.0
- Platform: Linux-5.15.0-105-generic-x86_64-with-glibc2.31
- Python version: 3.11.8
- Numpy version: 1.26.4
- PyTorch version (GPU?): 2.2.1+cu121 (True)
- PyTorch XPU available: False
- PyTorch NPU available: False
- System RAM: 31.24 GB
- GPU type: NVIDIA GeForce RTX 3090
- `Accelerate` default config:
	- compute_environment: LOCAL_MACHINE
	- distributed_type: MULTI_GPU
	- mixed_precision: fp16
	- use_cpu: False
	- debug: False
	- num_processes: 2
	- machine_rank: 0
	- num_machines: 1
	- gpu_ids: 0,1
	- rdzv_backend: static
	- same_network: True
	- main_training_function: main
	- downcast_bf16: no
	- tpu_use_cluster: False
	- tpu_use_sudo: False
	- tpu_env: []
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Una vez hemos configurado <code>accelerate</code> podemos probar si lo hemos hecho bien ejecutando en una terminal:</p>
<div class='highlight'><pre><code class="language-bash">accelerate test
</code></pre></div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="err">!</span><span class="n">accelerate</span> <span class="n">test</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>
Running:  accelerate-launch ~/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/test_utils/scripts/test_script.py
stdout: **Initialization**
stdout: Testing, testing. 1, 2, 3.
stdout: Distributed environment: DistributedType.MULTI_GPU  Backend: nccl
stdout: Num processes: 2
stdout: Process index: 0
stdout: Local process index: 0
stdout: Device: cuda:0
stdout: 
stdout: Mixed precision type: fp16
stdout: 
stdout: Distributed environment: DistributedType.MULTI_GPU  Backend: nccl
stdout: Num processes: 2
stdout: Process index: 1
stdout: Local process index: 1
stdout: Device: cuda:1
stdout: 
stdout: Mixed precision type: fp16
stdout: 
stdout: 
stdout: **Test process execution**
stdout: 
stdout: **Test split between processes as a list**
stdout: 
stdout: **Test split between processes as a dict**
stdout: 
stdout: **Test split between processes as a tensor**
stdout: 
stdout: **Test random number generator synchronization**
stdout: All rng are properly synched.
stdout: 
stdout: **DataLoader integration test**
stdout: 0 1 tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
stdout:         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
stdout:         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
stdout:         54, 55, 56, 57, 58, 59, 60, 61, 62, 63], device=&#x27;cuda:1&#x27;) &amp;lt;class &#x27;accelerate.data_loader.DataLoaderShard&#x27;&amp;gt;
stdout: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
stdout:         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
stdout:         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
stdout:         54, 55, 56, 57, 58, 59, 60, 61, 62, 63], device=&#x27;cuda:0&#x27;) &amp;lt;class &#x27;accelerate.data_loader.DataLoaderShard&#x27;&amp;gt;
stdout: Non-shuffled dataloader passing.
stdout: Shuffled dataloader passing.
stdout: Non-shuffled central dataloader passing.
stdout: Shuffled central dataloader passing.
stdout: 
stdout: **Training integration test**
stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32
stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32
stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32
stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32
stdout: Training yielded the same results on one CPU or distributed setup with no batch split.
stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32
stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32
stdout: Training yielded the same results on one CPU or distributes setup with batch split.
stdout: FP16 training check.
stdout: FP16 training check.
stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32
stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32
stdout: Keep fp32 wrapper check.
stdout: Keep fp32 wrapper check.
stdout: BF16 training check.
stdout: BF16 training check.
stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32
stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32
stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32
stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32
stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32Model dtype: torch.float32, torch.float32. Input dtype: torch.float32
stdout: 
stdout: Training yielded the same results on one CPU or distributed setup with no batch split.
stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32
stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32
stdout: FP16 training check.
stdout: Training yielded the same results on one CPU or distributes setup with batch split.
stdout: FP16 training check.
stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32
stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32
stdout: Keep fp32 wrapper check.
stdout: Keep fp32 wrapper check.
stdout: BF16 training check.
stdout: BF16 training check.
stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32
stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32
stdout: 
stdout: **Breakpoint trigger test**
Test is a success! You are ready for your distributed training!
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vemos que termina diciendo <code>Test is a success! You are ready for your distributed training!</code> por lo que todo está correcto.</p>
</section>
<section class="section-block-markdown-cell">
<h2 id="Entrenamiento">Entrenamiento<a class="anchor-link" href="#Entrenamiento">¶</a></h2>
</section>
<section class="section-block-markdown-cell">
<h3 id="Optimizacion del entrenamiento">Optimización del entrenamiento<a class="anchor-link" href="#Optimizacion del entrenamiento">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<h4 id="Codigo base">Código base<a class="anchor-link" href="#Codigo base">¶</a></h4>
</section>
<section class="section-block-markdown-cell">
<p>Vamos a hacer primero un código de entrenamiento base y luego lo optimizaremos  para ver cómo se hace y cómo mejora</p>
</section>
<section class="section-block-markdown-cell">
<p>Primero vamos a buscar un dataset, en mi caso voy a usar el dataset <a href="https://huggingface.co/datasets/tweet_eval">tweet_eval</a>, que es un dataset de clasificación de tweets, en concreto voy a descargar el subset <code>emoji</code> que clasifica los tweets con emoticonos</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="w"> </span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>
<span class="n">dataset</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>DatasetDict(&#x7B;
&#x20;&#x20;&#x20;&#x20;train: Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;text&#x27;, &#x27;label&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 45000
&#x20;&#x20;&#x20;&#x20;&#x7D;)
&#x20;&#x20;&#x20;&#x20;test: Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;text&#x27;, &#x27;label&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 50000
&#x20;&#x20;&#x20;&#x20;&#x7D;)
&#x20;&#x20;&#x20;&#x20;validation: Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;text&#x27;, &#x27;label&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 5000
&#x20;&#x20;&#x20;&#x20;&#x7D;)
&#x7D;)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>DatasetInfo(description=&#x27;&#x27;, citation=&#x27;&#x27;, homepage=&#x27;&#x27;, license=&#x27;&#x27;, features=&#x7B;&#x27;text&#x27;: Value(dtype=&#x27;string&#x27;, id=None), &#x27;label&#x27;: ClassLabel(names=[&#x27;❤&#x27;, &#x27;😍&#x27;, &#x27;😂&#x27;, &#x27;💕&#x27;, &#x27;🔥&#x27;, &#x27;😊&#x27;, &#x27;😎&#x27;, &#x27;✨&#x27;, &#x27;💙&#x27;, &#x27;😘&#x27;, &#x27;📷&#x27;, &#x27;🇺🇸&#x27;, &#x27;☀&#x27;, &#x27;💜&#x27;, &#x27;😉&#x27;, &#x27;💯&#x27;, &#x27;😁&#x27;, &#x27;🎄&#x27;, &#x27;📸&#x27;, &#x27;😜&#x27;], id=None)&#x7D;, post_processed=None, supervised_keys=None, task_templates=None, builder_name=&#x27;parquet&#x27;, dataset_name=&#x27;tweet_eval&#x27;, config_name=&#x27;emoji&#x27;, version=0.0.0, splits=&#x7B;&#x27;train&#x27;: SplitInfo(name=&#x27;train&#x27;, num_bytes=3808792, num_examples=45000, shard_lengths=None, dataset_name=&#x27;tweet_eval&#x27;), &#x27;test&#x27;: SplitInfo(name=&#x27;test&#x27;, num_bytes=4262151, num_examples=50000, shard_lengths=None, dataset_name=&#x27;tweet_eval&#x27;), &#x27;validation&#x27;: SplitInfo(name=&#x27;validation&#x27;, num_bytes=396704, num_examples=5000, shard_lengths=None, dataset_name=&#x27;tweet_eval&#x27;)&#x7D;, download_checksums=&#x7B;&#x27;hf://datasets/tweet_eval@b3a375baf0f409c77e6bc7aa35102b7b3534f8be/emoji/train-00000-of-00001.parquet&#x27;: &#x7B;&#x27;num_bytes&#x27;: 2609973, &#x27;checksum&#x27;: None&#x7D;, &#x27;hf://datasets/tweet_eval@b3a375baf0f409c77e6bc7aa35102b7b3534f8be/emoji/test-00000-of-00001.parquet&#x27;: &#x7B;&#x27;num_bytes&#x27;: 3047341, &#x27;checksum&#x27;: None&#x7D;, &#x27;hf://datasets/tweet_eval@b3a375baf0f409c77e6bc7aa35102b7b3534f8be/emoji/validation-00000-of-00001.parquet&#x27;: &#x7B;&#x27;num_bytes&#x27;: 281994, &#x27;checksum&#x27;: None&#x7D;&#x7D;, download_size=5939308, post_processing_size=None, dataset_size=8467647, size_in_bytes=14406955)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vamos a ver las clases</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>[&#x27;❤&#x27;, &#x27;😍&#x27;, &#x27;😂&#x27;, &#x27;💕&#x27;, &#x27;🔥&#x27;, &#x27;😊&#x27;, &#x27;😎&#x27;, &#x27;✨&#x27;, &#x27;💙&#x27;, &#x27;😘&#x27;, &#x27;📷&#x27;, &#x27;🇺🇸&#x27;, &#x27;☀&#x27;, &#x27;💜&#x27;, &#x27;😉&#x27;, &#x27;💯&#x27;, &#x27;😁&#x27;, &#x27;🎄&#x27;, &#x27;📸&#x27;, &#x27;😜&#x27;]
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Y el número de clases</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
<span class="n">num_classes</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>20
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vemos que el dataset tiene 20 clases</p>
</section>
<section class="section-block-markdown-cell">
<p>Vamos a ver la secuencia máxima de cada split</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">max_len_train</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">max_len_val</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">max_len_test</span> <span class="o">=</span> <span class="mi">0</span>
<span class="w"> </span>
<span class="n">split</span> <span class="o">=</span> <span class="s2">&quot;train&quot;</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">])):</span>
<span class="w">    </span><span class="n">len_i</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s2">&quot;text&quot;</span><span class="p">])</span>
<span class="w">    </span><span class="k">if</span> <span class="n">len_i</span> <span class="o">&amp;</span><span class="n">gt</span><span class="p">;</span> <span class="n">max_len_train</span><span class="p">:</span>
<span class="w">        </span><span class="n">max_len_train</span> <span class="o">=</span> <span class="n">len_i</span>
<span class="n">split</span> <span class="o">=</span> <span class="s2">&quot;validation&quot;</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">])):</span>
<span class="w">    </span><span class="n">len_i</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s2">&quot;text&quot;</span><span class="p">])</span>
<span class="w">    </span><span class="k">if</span> <span class="n">len_i</span> <span class="o">&amp;</span><span class="n">gt</span><span class="p">;</span> <span class="n">max_len_val</span><span class="p">:</span>
<span class="w">        </span><span class="n">max_len_val</span> <span class="o">=</span> <span class="n">len_i</span>
<span class="n">split</span> <span class="o">=</span> <span class="s2">&quot;test&quot;</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">])):</span>
<span class="w">    </span><span class="n">len_i</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s2">&quot;text&quot;</span><span class="p">])</span>
<span class="w">    </span><span class="k">if</span> <span class="n">len_i</span> <span class="o">&amp;</span><span class="n">gt</span><span class="p">;</span> <span class="n">max_len_test</span><span class="p">:</span>
<span class="w">        </span><span class="n">max_len_test</span> <span class="o">=</span> <span class="n">len_i</span>
<span class="w"> </span>
<span class="n">max_len_train</span><span class="p">,</span> <span class="n">max_len_val</span><span class="p">,</span> <span class="n">max_len_test</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>(142, 139, 167)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Así que definimos la secuencia máxima en general como 130 para la tokenización</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>A nosotros nos interesa el dataset tokenizado, no las secuencias en crudo, así que creamos un tokenizador</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Creamos una función de tokenización</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Y ahora tokenizamos el dataset</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Map:   0%|          | 0/45000 [00:00&amp;lt;?, ? examples/s]
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Map:   0%|          | 0/5000 [00:00&amp;lt;?, ? examples/s]
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Map:   0%|          | 0/50000 [00:00&amp;lt;?, ? examples/s]
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Como vemos, ahora tenemos los tokens (<code>input_ids</code>) y las máscaras de atención (<code>attention_mask</code>), pero vamos a ver qué tipo de datos tenemos</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">type</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]),</span> <span class="nb">type</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]),</span> <span class="nb">type</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;label&quot;</span><span class="p">])</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>(list, list, int)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="nb">type</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;label&quot;</span><span class="p">]),</span> <span class="nb">type</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]),</span> <span class="nb">type</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">])</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>(torch.Tensor, torch.Tensor, torch.Tensor)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Creamos un DataLoader</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="n">BS</span> <span class="o">=</span> <span class="mi">64</span>
<span class="w"> </span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Cargamos el modelo</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vamos a ver cómo es el modelo</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">model</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>RobertaForSequenceClassification(
&#x20;&#x20;(roberta): RobertaModel(
&#x20;&#x20;&#x20;&#x20;(embeddings): RobertaEmbeddings(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(word_embeddings): Embedding(50265, 768, padding_idx=1)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(position_embeddings): Embedding(514, 768, padding_idx=1)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(token_type_embeddings): Embedding(1, 768)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(dropout): Dropout(p=0.1, inplace=False)
&#x20;&#x20;&#x20;&#x20;)
&#x20;&#x20;&#x20;&#x20;(encoder): RobertaEncoder(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(layer): ModuleList(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(0-11): 12 x RobertaLayer(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(attention): RobertaAttention(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(self): RobertaSelfAttention(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(query): Linear(in_features=768, out_features=768, bias=True)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(key): Linear(in_features=768, out_features=768, bias=True)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(value): Linear(in_features=768, out_features=768, bias=True)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(dropout): Dropout(p=0.1, inplace=False)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(output): RobertaSelfOutput(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(dense): Linear(in_features=768, out_features=768, bias=True)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(dropout): Dropout(p=0.1, inplace=False)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(intermediate): RobertaIntermediate(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(dense): Linear(in_features=768, out_features=3072, bias=True)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(intermediate_act_fn): GELUActivation()
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(output): RobertaOutput(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(dense): Linear(in_features=3072, out_features=768, bias=True)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(dropout): Dropout(p=0.1, inplace=False)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)
&#x20;&#x20;&#x20;&#x20;)
&#x20;&#x20;)
&#x20;&#x20;(classifier): RobertaClassificationHead(
&#x20;&#x20;&#x20;&#x20;(dense): Linear(in_features=768, out_features=768, bias=True)
&#x20;&#x20;&#x20;&#x20;(dropout): Dropout(p=0.1, inplace=False)
&#x20;&#x20;&#x20;&#x20;(out_proj): Linear(in_features=768, out_features=2, bias=True)
&#x20;&#x20;)
)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vamos a ver su última capa</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Linear(in_features=768, out_features=2, bias=True)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">out_features</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>(768, 2)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Hemos visto que nuestro dataset tiene 20 clases, pero este modelo está entrenado para 2 clases, así que tenemos que modificar la última capa</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Linear(in_features=768, out_features=20, bias=True)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Ahora sí</p>
</section>
<section class="section-block-markdown-cell">
<p>Ahora creamos una función de loss</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Un optimizador</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
<span class="w"> </span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Y por último, una métrica</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="w"> </span>
<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vamos a comprobar que está todo bien con una muestra</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">sample</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]))</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">sample</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>(torch.Size([64, 130]), torch.Size([64, 130]))
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Ahora esa muestra se la metemos al modelo</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
<span class="n">ouputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">),</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">))</span>
<span class="n">ouputs</span><span class="o">.</span><span class="n">logits</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>torch.Size([64, 20])
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vemos que el modelo saca 64 batches, lo cual está bien, porque configuramos <code>BS = 20</code> y cada una con 20 salidas, lo cual está bien porque cambiamos el modelo para que tenga la salida de 20 valores</p>
</section>
<section class="section-block-markdown-cell">
<p>Obtenemos la de mayor valor</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">ouputs</span><span class="o">.</span><span class="n">logits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">predictions</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>torch.Size([64])
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Obtenemos la loss</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">ouputs</span><span class="o">.</span><span class="n">logits</span><span class="p">,</span> <span class="n">sample</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">))</span>
<span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>2.9990389347076416
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Y el accuracy</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">])[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]</span>
<span class="n">accuracy</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>0.015625
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Ya podemos crear un pequeño bucle de entrenamiento</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">fastprogress.fastprogress</span><span class="w"> </span><span class="kn">import</span> <span class="n">master_bar</span><span class="p">,</span> <span class="n">progress_bar</span>
<span class="w"> </span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">master_progress_bar</span> <span class="o">=</span> <span class="n">master_bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">master_progress_bar</span><span class="p">:</span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
<span class="w">        </span><span class="n">master_progress_bar</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s1">&#39;</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="w">    </span>
<span class="w">    </span><span class="n">master_progress_bar</span><span class="o">.</span><span class="n">main_bar</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Validation accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&amp;lt;IPython.core.display.HTML object&amp;gt;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&amp;lt;IPython.core.display.HTML object&amp;gt;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h4 id="Script con el codigo base">Script con el código base<a class="anchor-link" href="#Script con el codigo base">¶</a></h4>
</section>
<section class="section-block-markdown-cell">
<p>En la mayoría de la documentación de <code>accelerate</code> se explica cómo usar <code>accelerate</code> con scripts, así que de momento vamos a hacerlo así y al final explicaremos cómo hacerlo con un notebook</p>
</section>
<section class="section-block-markdown-cell">
<p>Primero vamos a crear una carpeta en la que vamos a guardar los scripts</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="err">!</span><span class="n">mkdir</span> <span class="n">accelerate_scripts</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Ahora escribimos el código base en un script</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">01</span><span class="n">_code_base</span><span class="o">.</span><span class="n">py</span>
<span class="w"> </span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">fastprogress.fastprogress</span><span class="w"> </span><span class="kn">import</span> <span class="n">master_bar</span><span class="p">,</span> <span class="n">progress_bar</span>
<span class="w"> </span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="p">}</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="w"> </span>
<span class="n">BS</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="p">}</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">master_progress_bar</span> <span class="o">=</span> <span class="n">master_bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">master_progress_bar</span><span class="p">:</span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
<span class="w">        </span><span class="n">master_progress_bar</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s1">&#39;</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="w">    </span>
<span class="w">    </span><span class="n">master_progress_bar</span><span class="o">.</span><span class="n">main_bar</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Validation accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Overwriting accelerate_scripts/01_code_base.py
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Y ahora lo ejecutamos</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="w"> </span>
<span class="err">!</span><span class="n">python</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">01</span><span class="n">_code_base</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Accuracy = 0.2112                                                               
CPU times: user 2.12 s, sys: 391 ms, total: 2.51 s
Wall time: 3min 36s
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vemos que en mi ordenador ha tardado unos 3 minutos y medio</p>
</section>
<section class="section-block-markdown-cell">
<h4 id="Codigo con accelerate">Código con accelerate<a class="anchor-link" href="#Codigo con accelerate">¶</a></h4>
</section>
<section class="section-block-markdown-cell">
<p>Ahora reemplazamos algunas cosas</p>
<ul>
  <li>En primer lugar importamos <code>Accelerator</code> y lo inicializamos</li>
</ul>
<section class="section-block-markdown-cell">
      <div class='highlight'><pre><code class="language-python">from accelerate import Accelerator<br>accelerator = Accelerator()</code></pre></div>
      </section>
<ul>
  <li>Ya no hacemos el típico</li>
</ul>
<p>``` python</p>
<p>torch.device("cuda" if torch.cuda.is_available() else "cpu")</p>
<p>```</p>
<ul>
  <li>Sino que dejamos que sea <code>acelerate</code> el que elija el dispositivo mediante</li>
</ul>
<div class='highlight'><pre><code class="language-python">device = accelerator.device
</code></pre></div>
<ul>
  <li>Pasamos los elementos relevantes para el entrenamiento por el método <code>prepare</code> y ya no hacemos <code>model.to(device)</code></li>
</ul>
<div class='highlight'><pre><code class="language-python">model, optimizer, dataloader["train"], dataloader["validation"] = preprare(model, optimizer, dataloader["train"], dataloader["validation"])
</code></pre></div>
<ul>
  <li>Ya no mandamos los datos y el modelo a la GPU con <code>.to(device)</code> ya que <code>accelerate</code> se ha encargado de ello con el método <code>prepare</code></li>
</ul>
<ul>
  <li>En vez de hacer el backpropagation con <code>loss.backward()</code> dejamos que lo haga <code>accelerate</code> con</li>
</ul>
<div class='highlight'><pre><code class="language-python">accelerator.backward(loss)
</code></pre></div>
<ul>
  <li>A la hora de calcular la métrica en el bucle de validación, necesitamos recopilar los valores de todos los puntos, en caso de estar haciendo un entrenamiento distribuido, para ello hacemos</li>
</ul>
<div class='highlight'><pre><code class="language-python">predictions = accelerator.gather_for_metrics(predictions)
</code></pre></div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">02</span><span class="n">_accelerate_base_code</span><span class="o">.</span><span class="n">py</span>
<span class="w"> </span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">fastprogress.fastprogress</span><span class="w"> </span><span class="kn">import</span> <span class="n">master_bar</span><span class="p">,</span> <span class="n">progress_bar</span>
<span class="w"> </span>
<span class="c1"># Importamos e inicializamos Accelerator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>
<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>
<span class="w"> </span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="p">}</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="w"> </span>
<span class="n">BS</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="p">}</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>
<span class="w"> </span>
<span class="c1"># model.to(device)</span>
<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>
<span class="w"> </span>
<span class="n">master_progress_bar</span> <span class="o">=</span> <span class="n">master_bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">master_progress_bar</span><span class="p">:</span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
<span class="w">        </span><span class="n">master_progress_bar</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s1">&#39;</span>
<span class="w"> </span>
<span class="w">        </span><span class="c1"># loss.backward()</span>
<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;End of training epoch </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">, outputs[&#39;logits&#39;].shape: </span><span class="si">{</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, labels.shape: </span><span class="si">{</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;End of validation epoch </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">, outputs[&#39;logits&#39;].shape: </span><span class="si">{</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, labels.shape: </span><span class="si">{</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="w">    </span>
<span class="w">    </span><span class="n">master_progress_bar</span><span class="o">.</span><span class="n">main_bar</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Validation accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
<span class="w"> </span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Overwriting accelerate_scripts/02_accelerate_base_code.py
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Si te fijas, he añadido estas dos líneas <code>print(f&quot;End of training epoch {i}, outputs[&#x27;logits&#x27;].shape: {outputs[&#x27;logits&#x27;].shape}, labels.shape: {labels.shape}&quot;)</code> y la línea <code>print(f&quot;End of validation epoch {i}, outputs[&#x27;logits&#x27;].shape: {outputs[&#x27;logits&#x27;].shape}, labels.shape: {labels.shape}&quot;)</code>, las he añadido a propósito porque nos van a revelar algo muy importante</p>
</section>
<section class="section-block-markdown-cell">
<p>Ahora lo ejecutamos, para ejecutar los scripts de <code>accelerate</code> se hace con el comando <code>accelerate launch</code></p>
<div class='highlight'><pre><code class="language-bash">accelerate launch script.py
</code></pre></div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="w"> </span>
<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">02</span><span class="n">_accelerate_base_code</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>End of training epoch 0, outputs[&#x27;logits&#x27;].shape: torch.Size([64, 20]), labels.shape: torch.Size([64])
End of training epoch 0, outputs[&#x27;logits&#x27;].shape: torch.Size([64, 20]), labels.shape: torch.Size([64])
End of validation epoch 0, outputs[&#x27;logits&#x27;].shape: torch.Size([64, 20]), labels.shape: torch.Size([8])
Accuracy = 0.206
End of validation epoch 0, outputs[&#x27;logits&#x27;].shape: torch.Size([64, 20]), labels.shape: torch.Size([8])
Accuracy = 0.206
CPU times: user 1.6 s, sys: 272 ms, total: 1.88 s
Wall time: 2min 37s
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vemos que antes tardó unos 3 minutos y medio y ahora tarda más o menos 2 minutos y medio. Bastante mejora. Además, si vemos los <code>print</code>s, podemos ver que se han impreso dos veces.</p>
<p>¿Y esto cómo puede ser? Pues porque <code>accelerate</code> ha paralelizado el entrenamiento en las dos GPUs que tengo, por lo que ha sido mucho más rápido.</p>
<p>Además, cuando ejecuté el primer script, es decir, cuando no usé <code>accelerate</code>, la GPU estaba casi llena, mientras que cuando he ejecutado el segundo, es decir, el que usa <code>accelerate</code>, las dos GPUs estaban muy poco utilizadas, por lo que podemos aumentar el batch size para intentar llenar las dos, vamos a ello!</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">03</span><span class="n">_accelerate_base_code_more_bs</span><span class="o">.</span><span class="n">py</span>
<span class="w"> </span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">fastprogress.fastprogress</span><span class="w"> </span><span class="kn">import</span> <span class="n">master_bar</span><span class="p">,</span> <span class="n">progress_bar</span>
<span class="w"> </span>
<span class="c1"># Importamos e inicializamos Accelerator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>
<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>
<span class="w"> </span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="p">}</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="w"> </span>
<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="p">}</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>
<span class="w"> </span>
<span class="c1"># model.to(device)</span>
<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>
<span class="w"> </span>
<span class="n">master_progress_bar</span> <span class="o">=</span> <span class="n">master_bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">master_progress_bar</span><span class="p">:</span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
<span class="w">        </span><span class="n">master_progress_bar</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s1">&#39;</span>
<span class="w"> </span>
<span class="w">        </span><span class="c1"># loss.backward()</span>
<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="w">    </span>
<span class="w">    </span><span class="n">master_progress_bar</span><span class="o">.</span><span class="n">main_bar</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Validation accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
<span class="w"> </span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Overwriting accelerate_scripts/03_accelerate_base_code_more_bs.py
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>He quitado los prints extra, porque ya hemos visto que el código se está ejecutando en las dos GPUs y he aumentado el batch size de 64 a 128. Lo ejecutamos a ver</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="w"> </span>
<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">03</span><span class="n">_accelerate_base_code_more_bs</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Accuracy = 0.1052                                                               
Accuracy = 0.1052
CPU times: user 1.41 s, sys: 180 ms, total: 1.59 s
Wall time: 2min 22s
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Aumentando el batch size ha bajado unos segundos el tiempo de ejecución</p>
</section>
<section class="section-block-markdown-cell">
<h3 id="Ejecucion de procesos">Ejecución de procesos<a class="anchor-link" href="#Ejecucion de procesos">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<h4 id="Ejecucion de codigo en un unico proceso">Ejecución de código en un único proceso<a class="anchor-link" href="#Ejecucion de codigo en un unico proceso">¶</a></h4>
</section>
<section class="section-block-markdown-cell">
<p>Antes hemos visto que los <code>print</code>s se imprimían dos veces, esto es porque <code>accelerate</code> crea tantos procesos como dispositivos donde se ejecuta el código, en mi caso crea dos procesos por tener dos GPUs.</p>
<p>Sin embargo, no todo el código debería ejecutarse en todos los procesos, por ejemplo, los <code>print</code>s, ralentizan mucho el código, como para ejecutarlo varias veces, si se guardan los checkpoints, se guardarían dos veces, etc.</p>
<p>Para poder ejecutar parte de un código en un único proceso, se tiene que encapsular en una función y decorarla con <code>accelerator.on_local_main_process</code>. Por ejemplo, en el siguiente código vas a ver que he creado la siguiente función</p>
<section class="section-block-markdown-cell">
      <div class='highlight'><pre><code class="language-python">@accelerator.on_local_main_process<br>def print_something(something):<br>&#x20;&#x20;print(something)</code></pre></div>
      </section>
<p>Otra opción es incluir el código dentro de un <code>if accelerator.is_local_main_process</code> como en el siguiente código</p>
<section class="section-block-markdown-cell">
      <div class='highlight'><pre><code class="language-python">if accelerator.is_local_main_process:<br>&#x20;&#x20;print("Something")</code></pre></div>
      </section>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">04</span><span class="n">_accelerate_base_code_some_code_in_one_process</span><span class="o">.</span><span class="n">py</span>
<span class="w"> </span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">fastprogress.fastprogress</span><span class="w"> </span><span class="kn">import</span> <span class="n">master_bar</span><span class="p">,</span> <span class="n">progress_bar</span>
<span class="w"> </span>
<span class="c1"># Importamos e inicializamos Accelerator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>
<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>
<span class="w"> </span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="p">}</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="w"> </span>
<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="p">}</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>
<span class="w"> </span>
<span class="c1"># model.to(device)</span>
<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>
<span class="w"> </span>
<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>
<span class="k">def</span><span class="w"> </span><span class="nf">print_something</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">master_progress_bar</span> <span class="o">=</span> <span class="n">master_bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">master_progress_bar</span><span class="p">:</span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
<span class="w">        </span><span class="n">master_progress_bar</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s1">&#39;</span>
<span class="w"> </span>
<span class="w">        </span><span class="c1"># loss.backward()</span>
<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="w">    </span>
<span class="w">    </span><span class="n">master_progress_bar</span><span class="o">.</span><span class="n">main_bar</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Validation accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
<span class="w"> </span>
<span class="c1"># print(f&quot;Accuracy = {accuracy[&#39;accuracy&#39;]}&quot;)</span>
<span class="n">print_something</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">:</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Overwriting accelerate_scripts/04_accelerate_base_code_some_code_in_one_process.py
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vamos a ejecutarlo a ver</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="w"> </span>
<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">04</span><span class="n">_accelerate_base_code_some_code_in_one_process</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Accuracy = 0.2098                                                               
End of script with 0.2098 accuracy
CPU times: user 1.38 s, sys: 197 ms, total: 1.58 s
Wall time: 2min 22s
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Ahora solo se ha impreso el print una vez</p>
</section>
<section class="section-block-markdown-cell">
<p>Sin embargo, aunque no se ve mucho, las barras de progreso se ejecutan en cada proceso.</p>
<p>No he encontrado una manera de evitar esto con las barras de progreso de <code>fastprogress</code>, pero sí con las de <code>tqdm</code>, así que voy a sustituir las barras de progreso de <code>fastprogress</code> por las de <code>tqdm</code> y para que se ejecuten en un único proceso hay que añadirle el argumento <code>disable=not accelerator.is_local_main_process</code></p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">05</span><span class="n">_accelerate_base_code_some_code_in_one_process</span><span class="o">.</span><span class="n">py</span>
<span class="w"> </span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tqdm</span>
<span class="w"> </span>
<span class="c1"># Importamos e inicializamos Accelerator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>
<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>
<span class="w"> </span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="p">}</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="w"> </span>
<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="p">}</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>
<span class="w"> </span>
<span class="c1"># model.to(device)</span>
<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>
<span class="w"> </span>
<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>
<span class="k">def</span><span class="w"> </span><span class="nf">print_something</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="w">    </span><span class="c1"># progress_bar_train = progress_bar(dataloader[&quot;train&quot;], parent=master_progress_bar)</span>
<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
<span class="w">        </span><span class="c1"># master_progress_bar.child.comment = f&#39;loss: {loss}&#39;</span>
<span class="w"> </span>
<span class="w">        </span><span class="c1"># loss.backward()</span>
<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="w">    </span><span class="c1"># progress_bar_validation = progress_bar(dataloader[&quot;validation&quot;], parent=master_progress_bar)</span>
<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="w">    </span>
<span class="c1"># print(f&quot;Accuracy = {accuracy[&#39;accuracy&#39;]}&quot;)</span>
<span class="n">print_something</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">:</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Overwriting accelerate_scripts/05_accelerate_base_code_some_code_in_one_process.py
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="w"> </span>
<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">05</span><span class="n">_accelerate_base_code_some_code_in_one_process</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>100%|█████████████████████████████████████████| 176/176 [02:01&amp;lt;00:00,  1.45it/s]
100%|███████████████████████████████████████████| 20/20 [00:06&amp;lt;00:00,  3.30it/s]
Accuracy = 0.2166
End of script with 0.2166 accuracy
CPU times: user 1.33 s, sys: 195 ms, total: 1.52 s
Wall time: 2min 22s
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Hemos mostrado un ejemplo de cómo imprimir en un solo proceso, y esto ha sido una manera de ejecutar procesos en un solo proceso. Pero si lo que quieres es solo imprimir en un solo proceso, se puede usar el método <code>print</code> de <code>accelerate</code>. Vamos a ver el mismo ejemplo de antes con este método</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">06</span><span class="n">_accelerate_base_code_print_one_process</span><span class="o">.</span><span class="n">py</span>
<span class="w"> </span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tqdm</span>
<span class="w"> </span>
<span class="c1"># Importamos e inicializamos Accelerator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>
<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>
<span class="w"> </span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="p">}</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="w"> </span>
<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="p">}</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>
<span class="w"> </span>
<span class="c1"># model.to(device)</span>
<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>
<span class="w"> </span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="w">    </span><span class="c1"># progress_bar_train = progress_bar(dataloader[&quot;train&quot;], parent=master_progress_bar)</span>
<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
<span class="w">        </span><span class="c1"># master_progress_bar.child.comment = f&#39;loss: {loss}&#39;</span>
<span class="w"> </span>
<span class="w">        </span><span class="c1"># loss.backward()</span>
<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="w">    </span><span class="c1"># progress_bar_validation = progress_bar(dataloader[&quot;validation&quot;], parent=master_progress_bar)</span>
<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="w">    </span>
<span class="c1"># print(f&quot;Accuracy = {accuracy[&#39;accuracy&#39;]}&quot;)</span>
<span class="n">accelerator</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">:</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Writing accelerate_scripts/06_accelerate_base_code_print_one_process.py
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Lo ejecutamos</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="w"> </span>
<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">06</span><span class="n">_accelerate_base_code_print_one_process</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Map: 100%|██████████████████████| 45000/45000 [00:02&amp;lt;00:00, 15433.52 examples/s]
Map: 100%|████████████████████████| 5000/5000 [00:00&amp;lt;00:00, 11406.61 examples/s]
Map: 100%|██████████████████████| 45000/45000 [00:02&amp;lt;00:00, 15036.87 examples/s]
Map: 100%|██████████████████████| 50000/50000 [00:03&amp;lt;00:00, 14932.76 examples/s]
Map: 100%|██████████████████████| 50000/50000 [00:03&amp;lt;00:00, 14956.60 examples/s]
100%|█████████████████████████████████████████| 176/176 [02:00&amp;lt;00:00,  1.46it/s]
100%|███████████████████████████████████████████| 20/20 [00:05&amp;lt;00:00,  3.33it/s]
Accuracy = 0.2134
End of script with 0.2134 accuracy
CPU times: user 1.4 s, sys: 189 ms, total: 1.59 s
Wall time: 2min 27s
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h4 id="Ejecucion de codigo en todos los procesos">Ejecución de código en todos los procesos<a class="anchor-link" href="#Ejecucion de codigo en todos los procesos">¶</a></h4>
</section>
<section class="section-block-markdown-cell">
<p>Sin embargo, hay código que debe ejecutarse en todos los procesos, por ejemplo, si subimos los checkpoints al hub, así que aquí tenemos dos opciones: encapsular el código en una función y decorarla con <code>accelerator.on_main_process</code></p>
<section class="section-block-markdown-cell">
      <div class='highlight'><pre><code class="language-python">@accelerator.on_main_process<br>def do_my_thing():<br>&#x20;&#x20;"Something done once per server"<br>&#x20;&#x20;do_thing_once()</code></pre></div>
      </section>
<p>o meter el código dentro de un <code>if accelerator.is_main_process</code></p>
<section class="section-block-markdown-cell">
      <div class='highlight'><pre><code class="language-python">if accelerator.is_main_process:<br>&#x20;&#x20;repo.push_to_hub()</code></pre></div>
      </section>
</section>
<section class="section-block-markdown-cell">
<p>Como estamos haciendo entrenamientos solo para mostrar la librería <code>accelerate</code> y el modelo que estamos entrenando no es bueno, no tiene sentido ahora subir los checkpoints al hub, así que voy a hacer un ejemplo con <code>print</code>s</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">07</span><span class="n">_accelerate_base_code_some_code_in_all_process</span><span class="o">.</span><span class="n">py</span>
<span class="w"> </span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tqdm</span>
<span class="w"> </span>
<span class="c1"># Importamos e inicializamos Accelerator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>
<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>
<span class="w"> </span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="p">}</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="w"> </span>
<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="p">}</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>
<span class="w"> </span>
<span class="c1"># model.to(device)</span>
<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>
<span class="w"> </span>
<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>
<span class="k">def</span><span class="w"> </span><span class="nf">print_in_one_process</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>
<span class="w"> </span>
<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_main_process</span>
<span class="k">def</span><span class="w"> </span><span class="nf">print_in_all_processes</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="c1"># loss.backward()</span>
<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="w">    </span>
<span class="n">print_in_one_process</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">:</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">print_in_all_processes</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;All process: Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">:</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;All process: End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Overwriting accelerate_scripts/06_accelerate_base_code_some_code_in_all_process.py
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Lo ejecutamos a ver</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="w"> </span>
<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">07</span><span class="n">_accelerate_base_code_some_code_in_all_process</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Map: 100%|██████████████████████| 45000/45000 [00:03&amp;lt;00:00, 14518.44 examples/s]
Map: 100%|██████████████████████| 45000/45000 [00:03&amp;lt;00:00, 14368.77 examples/s]
Map: 100%|████████████████████████| 5000/5000 [00:00&amp;lt;00:00, 16466.33 examples/s]
Map: 100%|████████████████████████| 5000/5000 [00:00&amp;lt;00:00, 14806.14 examples/s]
Map: 100%|██████████████████████| 50000/50000 [00:03&amp;lt;00:00, 14253.33 examples/s]
Map: 100%|██████████████████████| 50000/50000 [00:03&amp;lt;00:00, 14337.07 examples/s]
100%|█████████████████████████████████████████| 176/176 [02:00&amp;lt;00:00,  1.46it/s]
100%|███████████████████████████████████████████| 20/20 [00:05&amp;lt;00:00,  3.34it/s]
Accuracy = 0.2092
End of script with 0.2092 accuracy
All process: Accuracy = 0.2092
All process: End of script with 0.2092 accuracy
CPU times: user 1.42 s, sys: 216 ms, total: 1.64 s
Wall time: 2min 27s
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h4 id="Ejecucion de codigo en el proceso X">Ejecución de código en el proceso X<a class="anchor-link" href="#Ejecucion de codigo en el proceso X">¶</a></h4>
</section>
<section class="section-block-markdown-cell">
<p>Por último podemos especificar en qué proceso queremos ejecutar código, para esto hay que crear una función y decorarla con <code>@accelerator.on_process(process_index=0)</code></p>
<section class="section-block-markdown-cell">
      <div class='highlight'><pre><code class="language-python">@accelerator.on_process(process_index=0)<br>def do_my_thing():<br>&#x20;&#x20;"Something done on process index 0"<br>&#x20;&#x20;do_thing_on_index_zero()</code></pre></div>
      </section>
<p>o decorarla con <code>@accelerator.on_local_process(local_process_idx=0)</code></p>
<section class="section-block-markdown-cell">
      <div class='highlight'><pre><code class="language-python">@accelerator.on_local_process(local_process_index=0)<br>def do_my_thing():<br>&#x20;&#x20;"Something done on process index 0 on each server"<br>&#x20;&#x20;do_thing_on_index_zero_on_each_server()</code></pre></div>
      </section>
<p>Aquí he puesto el proceso 0, pero se puede poner cualquier número</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">08</span><span class="n">_accelerate_base_code_some_code_in_some_process</span><span class="o">.</span><span class="n">py</span>
<span class="w"> </span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tqdm</span>
<span class="w"> </span>
<span class="c1"># Importamos e inicializamos Accelerator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>
<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>
<span class="w"> </span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="p">}</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="w"> </span>
<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="p">}</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>
<span class="w"> </span>
<span class="c1"># model.to(device)</span>
<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>
<span class="w"> </span>
<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>
<span class="k">def</span><span class="w"> </span><span class="nf">print_in_one_process</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>
<span class="w"> </span>
<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_main_process</span>
<span class="k">def</span><span class="w"> </span><span class="nf">print_in_all_processes</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>
<span class="w"> </span>
<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_process</span><span class="p">(</span><span class="n">process_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">print_in_process_0</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Process 0: &quot;</span> <span class="o">+</span> <span class="n">something</span><span class="p">)</span>
<span class="w"> </span>
<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_process</span><span class="p">(</span><span class="n">local_process_index</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">print_in_process_1</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Process 1: &quot;</span> <span class="o">+</span> <span class="n">something</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="c1"># loss.backward()</span>
<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="w">    </span>
<span class="n">print_in_one_process</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">:</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">print_in_all_processes</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;All process: Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">:</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;All process: End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">print_in_process_0</span><span class="p">(</span><span class="s2">&quot;End of process 0&quot;</span><span class="p">)</span>
<span class="n">print_in_process_1</span><span class="p">(</span><span class="s2">&quot;End of process 1&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Overwriting accelerate_scripts/07_accelerate_base_code_some_code_in_some_process.py
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Lo ejecutamos</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="w"> </span>
<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">08</span><span class="n">_accelerate_base_code_some_code_in_some_process</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Map: 100%|████████████████████████| 5000/5000 [00:00&amp;lt;00:00, 15735.58 examples/s]
Map: 100%|██████████████████████| 50000/50000 [00:03&amp;lt;00:00, 14906.20 examples/s]
100%|█████████████████████████████████████████| 176/176 [02:02&amp;lt;00:00,  1.44it/s]
100%|███████████████████████████████████████████| 20/20 [00:06&amp;lt;00:00,  3.27it/s]
Process 1: End of process 1
Accuracy = 0.2128
End of script with 0.2128 accuracy
All process: Accuracy = 0.2128
All process: End of script with 0.2128 accuracy
Process 0: End of process 0
CPU times: user 1.42 s, sys: 295 ms, total: 1.71 s
Wall time: 2min 37s
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h4 id="Sincronizar procesos">Sincronizar procesos<a class="anchor-link" href="#Sincronizar procesos">¶</a></h4>
</section>
<section class="section-block-markdown-cell">
<p>Si tenemos código que debe ejecutarse en todos los procesos, es interesante esperar a que termine en todos los procesos antes de hacer otra tarea, así que para ello usamos <code>accelerator.wait_for_everyone()</code></p>
<p>Para verlo, vamos a meter un retraso en una de las funciones de imprimir en un proceso</p>
<p>Además he puesto un break en el bucle de entrenamiento para que no esté mucho tiempo entrenando, que no es lo que ahora nos interesa</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">09</span><span class="n">_accelerate_base_code_sync_all_process</span><span class="o">.</span><span class="n">py</span>
<span class="w"> </span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tqdm</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="w"> </span>
<span class="c1"># Importamos e inicializamos Accelerator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>
<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>
<span class="w"> </span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="p">}</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="w"> </span>
<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="p">}</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>
<span class="w"> </span>
<span class="c1"># model.to(device)</span>
<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>
<span class="w"> </span>
<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>
<span class="k">def</span><span class="w"> </span><span class="nf">print_in_one_process</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>
<span class="w"> </span>
<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_main_process</span>
<span class="k">def</span><span class="w"> </span><span class="nf">print_in_all_processes</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>
<span class="w"> </span>
<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_process</span><span class="p">(</span><span class="n">process_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">print_in_process_0</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>
<span class="w">    </span><span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Process 0: &quot;</span> <span class="o">+</span> <span class="n">something</span><span class="p">)</span>
<span class="w"> </span>
<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_process</span><span class="p">(</span><span class="n">local_process_index</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">print_in_process_1</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Process 1: &quot;</span> <span class="o">+</span> <span class="n">something</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="c1"># loss.backward()</span>
<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="w">        </span><span class="k">break</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="w">    </span>
<span class="n">print_in_one_process</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">:</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">print_in_all_processes</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;All process: Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">:</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;All process: End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">print_in_one_process</span><span class="p">(</span><span class="s2">&quot;Printing with delay in process 0&quot;</span><span class="p">)</span>
<span class="n">print_in_process_0</span><span class="p">(</span><span class="s2">&quot;End of process 0&quot;</span><span class="p">)</span>
<span class="n">print_in_process_1</span><span class="p">(</span><span class="s2">&quot;End of process 1&quot;</span><span class="p">)</span>
<span class="n">accelerator</span><span class="o">.</span><span class="n">wait_for_everyone</span><span class="p">()</span>
<span class="w"> </span>
<span class="n">print_in_one_process</span><span class="p">(</span><span class="s2">&quot;End of script&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Overwriting accelerate_scripts/08_accelerate_base_code_sync_all_process.py
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Lo ejecutamos</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">09</span><span class="n">_accelerate_base_code_sync_all_process</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Map: 100%|████████████████████████| 5000/5000 [00:00&amp;lt;00:00, 14218.23 examples/s]
Map: 100%|████████████████████████| 5000/5000 [00:00&amp;lt;00:00, 14666.25 examples/s]
&#x20;&#x20;0%|                                                   | 0/176 [00:00&amp;lt;?, ?it/s]
100%|███████████████████████████████████████████| 20/20 [00:05&amp;lt;00:00,  3.58it/s]
Process 1: End of process 1
Accuracy = 0.212
End of script with 0.212 accuracy
All process: Accuracy = 0.212
All process: End of script with 0.212 accuracy
Printing with delay in process 0
Process 0: End of process 0
End of script
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Como se puede ver primero se ha impreso <code>Process 1: End of process 1</code> y luego el resto, esto es porque el resto de prints se hacen o en el proceso 0 o en todos los procesos, así que hasta que no termine el delay de 2 segundos que hemos puesto no se ejecuta el resto de código</p>
</section>
<section class="section-block-markdown-cell">
<h3 id="Guardar y cargar el state dict">Guardar y cargar el state dict<a class="anchor-link" href="#Guardar y cargar el state dict">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Cuando entrenamos, a veces guardamos el estado para poder seguir en otro momento</p>
<p>Para guardar el estado tendremos que usar los métodos <code>save_state()</code> y <code>load_state()</code></p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">10</span><span class="n">_accelerate_save_and_load_checkpoints</span><span class="o">.</span><span class="n">py</span>
<span class="w"> </span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tqdm</span>
<span class="w"> </span>
<span class="c1"># Importamos e inicializamos Accelerator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>
<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>
<span class="w"> </span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="p">}</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="w"> </span>
<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="p">}</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>
<span class="k">def</span><span class="w"> </span><span class="nf">print_something</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>
<span class="w"> </span>
<span class="c1"># model.to(device)</span>
<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>
<span class="w"> </span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="c1"># loss.backward()</span>
<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">    </span><span class="c1"># Guardamos los pesos</span>
<span class="w">    </span><span class="n">accelerator</span><span class="o">.</span><span class="n">save_state</span><span class="p">(</span><span class="s2">&quot;accelerate_scripts/checkpoints&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">print_something</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="c1"># Cargamos los pesos</span>
<span class="n">accelerator</span><span class="o">.</span><span class="n">load_state</span><span class="p">(</span><span class="s2">&quot;accelerate_scripts/checkpoints&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Overwriting accelerate_scripts/09_accelerate_save_and_load_checkpoints.py
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Lo ejecutamos</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">10</span><span class="n">_accelerate_save_and_load_checkpoints</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>100%|█████████████████████████████████████████| 176/176 [01:58&amp;lt;00:00,  1.48it/s]
100%|███████████████████████████████████████████| 20/20 [00:05&amp;lt;00:00,  3.40it/s]
Accuracy = 0.2142
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Guardar el modelo">Guardar el modelo<a class="anchor-link" href="#Guardar el modelo">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Cuando se usó el método <code>prepare</code> se envolvió el modelo para poder guardarlo en los dispositivos necesarios. Por lo que a la hora de guardarlo tenemos que usar el método <code>save_model</code> que primero lo desenvuelve y luego lo guarda. Además, si usamos el parámetro <code>safe_serialization=True</code> se guardará el modelo como un <code>safe tensor</code></p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">11</span><span class="n">_accelerate_save_model</span><span class="o">.</span><span class="n">py</span>
<span class="w"> </span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tqdm</span>
<span class="w"> </span>
<span class="c1"># Importamos e inicializamos Accelerator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>
<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>
<span class="w"> </span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="p">}</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="w"> </span>
<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="p">}</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>
<span class="k">def</span><span class="w"> </span><span class="nf">print_something</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>
<span class="w"> </span>
<span class="c1"># model.to(device)</span>
<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>
<span class="w"> </span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="c1"># loss.backward()</span>
<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">    </span><span class="c1"># Guardamos el modelo</span>
<span class="w">    </span><span class="n">accelerator</span><span class="o">.</span><span class="n">wait_for_everyone</span><span class="p">()</span>
<span class="w">    </span><span class="n">accelerator</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;accelerate_scripts/model&quot;</span><span class="p">,</span> <span class="n">safe_serialization</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">print_something</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Writing accelerate_scripts/11_accelerate_save_model.py
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Lo ejecutamos</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">11</span><span class="n">_accelerate_save_model</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>100%|█████████████████████████████████████████| 176/176 [01:58&amp;lt;00:00,  1.48it/s]
100%|███████████████████████████████████████████| 20/20 [00:05&amp;lt;00:00,  3.35it/s]
Accuracy = 0.214
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Guardar el modelo pretrained">Guardar el modelo <code>pretrained</code><a class="anchor-link" href="#Guardar el modelo pretrained">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>En modelos que usan la librería <code>transformers</code> debemos guardar el modelo con el método <code>save_pretrained</code> para poder cargarlo con el método <code>from_pretrained</code>. Antes de guardarlo hay que desenvolverlo con el método <code>unwrap_model</code></p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">12</span><span class="n">_accelerate_save_pretrained</span><span class="o">.</span><span class="n">py</span>
<span class="w"> </span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tqdm</span>
<span class="w"> </span>
<span class="c1"># Importamos e inicializamos Accelerator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>
<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>
<span class="w"> </span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="p">}</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="w"> </span>
<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="p">}</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>
<span class="k">def</span><span class="w"> </span><span class="nf">print_something</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>
<span class="w"> </span>
<span class="c1"># model.to(device)</span>
<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>
<span class="w"> </span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="c1"># loss.backward()</span>
<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">    </span><span class="c1"># Guardamos el modelo pretrained</span>
<span class="w">    </span><span class="n">unwrapped_model</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">unwrap_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="w">    </span><span class="n">unwrapped_model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span>
<span class="w">        </span><span class="s2">&quot;accelerate_scripts/model_pretrained&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="n">is_main_process</span><span class="o">=</span><span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">,</span>
<span class="w">        </span><span class="n">save_function</span><span class="o">=</span><span class="n">accelerator</span><span class="o">.</span><span class="n">save</span><span class="p">,</span>
<span class="w">    </span><span class="p">)</span>
<span class="w"> </span>
<span class="n">print_something</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Writing accelerate_scripts/11_accelerate_save_pretrained.py
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Lo ejecutamos</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">12</span><span class="n">_accelerate_save_pretrained</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Map: 100%|██████████████████████| 45000/45000 [00:02&amp;lt;00:00, 15152.47 examples/s]
Map: 100%|██████████████████████| 45000/45000 [00:02&amp;lt;00:00, 15119.13 examples/s]
Map: 100%|████████████████████████| 5000/5000 [00:00&amp;lt;00:00, 12724.70 examples/s]
Map: 100%|████████████████████████| 5000/5000 [00:00&amp;lt;00:00, 12397.49 examples/s]
Map: 100%|██████████████████████| 50000/50000 [00:03&amp;lt;00:00, 15247.21 examples/s]
Map: 100%|██████████████████████| 50000/50000 [00:03&amp;lt;00:00, 15138.03 examples/s]
100%|█████████████████████████████████████████| 176/176 [01:59&amp;lt;00:00,  1.48it/s]
100%|███████████████████████████████████████████| 20/20 [00:05&amp;lt;00:00,  3.37it/s]
Accuracy = 0.21
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Ahora lo podríamos cargar</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModel</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;accelerate_scripts/model_pretrained&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Some weights of RobertaModel were not initialized from the model checkpoint at accelerate_scripts/model_pretrained and are newly initialized: [&#x27;roberta.pooler.dense.bias&#x27;, &#x27;roberta.pooler.dense.weight&#x27;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Entrenamiento en notebooks">Entrenamiento en notebooks<a class="anchor-link" href="#Entrenamiento en notebooks">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Hasta ahora hemos visto cómo ejecutar scripts, pero si quieres ejecutar el código en un notebook, podemos escribir el mismo código de antes, pero encapsulado en una función</p>
</section>
<section class="section-block-markdown-cell">
<p>Primero importamos las librerías</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tqdm</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="c1"># from accelerate import Accelerator</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Ahora creamos la función</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">train_code</span><span class="p">(</span><span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span><span class="p">):</span>
<span class="w">    </span><span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>
<span class="w">    </span><span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
<span class="w">    </span><span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>
<span class="w">    </span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">    </span><span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="w">        </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">        </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">        </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">        </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>
<span class="w">    </span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="w">    </span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">BS</span> <span class="o">=</span> <span class="n">batch_size</span>
<span class="w">    </span><span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">        </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">        </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">        </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="p">}</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="w">    </span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
<span class="w">    </span><span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>
<span class="w">    </span><span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>
<span class="w">    </span><span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>
<span class="w"> </span>
<span class="w">    </span><span class="c1"># model.to(device)</span>
<span class="w">    </span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>
<span class="w"> </span>
<span class="w">    </span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
<span class="w">        </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="w">        </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">        </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>
<span class="w">            </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">            </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">            </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">            </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">            </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">            </span><span class="c1"># loss.backward()</span>
<span class="w">            </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="w">            </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="w">        </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">        </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>
<span class="w">            </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">            </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">            </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">            </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="w">                </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">            </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="w">            </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>
<span class="w">            </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
<span class="w">            </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">            </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="w">        </span>
<span class="w">    </span><span class="n">accelerator</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Para poder ejecutar el entrenamiento en el notebook usamos la función <code>notebook_launcher</code>, al que le pasamos la función que queremos ejecutar, los argumentos de esa función y el número de GPUs en las que vamos a entrenar con la variable <code>num_processes</code></p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">notebook_launcher</span>
<span class="w"> </span>
<span class="n">args</span> <span class="o">=</span> <span class="p">(</span><span class="mi">128</span><span class="p">,)</span>
<span class="n">notebook_launcher</span><span class="p">(</span><span class="n">train_code</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">num_processes</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Launching training on 2 GPUs.
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>100%|██████████| 176/176 [02:01&amp;lt;00:00,  1.45it/s]
100%|██████████| 20/20 [00:06&amp;lt;00:00,  3.31it/s]
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Accuracy = 0.2112
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Entrenamiento en FP16">Entrenamiento en FP16<a class="anchor-link" href="#Entrenamiento en FP16">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Cuando al principio configuramos <code>accelerate</code> nos preguntó <code>Do you wish to use FP16 or BF16 (mixed precision)?</code> y dijimos que no, así que ahora vamos a decirle que sí, que queremos en FP16</p>
</section>
<section class="section-block-markdown-cell">
<p>Hasta ahora hemos entrenado en FP32, lo que quiere decir que cada peso del modelo es un número en coma flotante de 32 bits, y ahora vamos a usar un número en coma flotante de 16 bits, es decir, el modelo va a ocupar menos. Por lo que van a pasar dos cosas, podremos usar un batch size mayor y además será más rápido</p>
</section>
<section class="section-block-markdown-cell">
<p>Primero volvemos a lanzar <code>accelerate config</code> y le vamos a decir que queremos FP16</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="err">!</span><span class="n">accelerate</span> <span class="n">config</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>--------------------------------------------------------------------------------
In which compute environment are you running?
This machine
--------------------------------------------------------------------------------
multi-GPU
How many different machines will you use (use more than 1 for multi-node training)? [1]: 1
Should distributed operations be checked while running for errors? This can avoid timeout issues but will be slower. [yes/NO]: no
Do you wish to optimize your script with torch dynamo?[yes/NO]:no
Do you want to use DeepSpeed? [yes/NO]: no
Do you want to use FullyShardedDataParallel? [yes/NO]: no
Do you want to use Megatron-LM ? [yes/NO]: no
How many GPU(s) should be used for distributed training? [1]:2
What GPU(s) (by id) should be used for training on this machine as a comma-seperated list? [all]:0,1
--------------------------------------------------------------------------------
Do you wish to use FP16 or BF16 (mixed precision)?
fp16
accelerate configuration saved at ~/.cache/huggingface/accelerate/default_config.yaml
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Ahora creamos un script para entrenar, con el mismo batch size de antes, para ver si tarda menos en entrenar</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">13</span><span class="n">_accelerate_base_code_fp16_bs128</span><span class="o">.</span><span class="n">py</span>
<span class="w"> </span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tqdm</span>
<span class="w"> </span>
<span class="c1"># Importamos e inicializamos Accelerator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>
<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>
<span class="w"> </span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="p">}</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="w"> </span>
<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="p">}</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>
<span class="w"> </span>
<span class="c1"># model.to(device)</span>
<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>
<span class="w"> </span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="c1"># loss.backward()</span>
<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="w">    </span>
<span class="n">accelerator</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Overwriting accelerate_scripts/12_accelerate_base_code_fp16_bs128.py
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Lo ejecutamos a ver cuánto tarda</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="w"> </span>
<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">13</span><span class="n">_accelerate_base_code_fp16_bs128</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Map: 100%|████████████████████████| 5000/5000 [00:00&amp;lt;00:00, 14983.76 examples/s]
Map: 100%|██████████████████████| 50000/50000 [00:03&amp;lt;00:00, 14315.47 examples/s]
100%|█████████████████████████████████████████| 176/176 [01:01&amp;lt;00:00,  2.88it/s]
100%|███████████████████████████████████████████| 20/20 [00:02&amp;lt;00:00,  6.84it/s]
Accuracy = 0.2094
CPU times: user 812 ms, sys: 163 ms, total: 976 ms
Wall time: 1min 27s
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Cuando ejecutamos este entrenamiento en FP32 tardó unos 2 minutos y medio, y ahora más o menos 1 minuto y medio. Vamos a ver si ahora en vez de entrenar con un batch size de 128, lo hacemos con uno de 256</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">14</span><span class="n">_accelerate_base_code_fp16_bs256</span><span class="o">.</span><span class="n">py</span>
<span class="w"> </span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tqdm</span>
<span class="w"> </span>
<span class="c1"># Importamos e inicializamos Accelerator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>
<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>
<span class="w"> </span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="p">}</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="w"> </span>
<span class="n">BS</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="p">}</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>
<span class="w"> </span>
<span class="c1"># model.to(device)</span>
<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>
<span class="w"> </span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="c1"># loss.backward()</span>
<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="w">    </span>
<span class="n">accelerator</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Overwriting accelerate_scripts/13_accelerate_base_code_fp16_bs256.py
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Lo ejecutamos</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="w"> </span>
<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">14</span><span class="n">_accelerate_base_code_fp16_bs256</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Map: 100%|████████████████████████| 5000/5000 [00:00&amp;lt;00:00, 15390.30 examples/s]
Map: 100%|████████████████████████| 5000/5000 [00:00&amp;lt;00:00, 14990.92 examples/s]
100%|███████████████████████████████████████████| 88/88 [00:54&amp;lt;00:00,  1.62it/s]
100%|███████████████████████████████████████████| 10/10 [00:02&amp;lt;00:00,  3.45it/s]
Accuracy = 0.2236
CPU times: user 670 ms, sys: 91.6 ms, total: 761 ms
Wall time: 1min 12s
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Ha bajado solo unos 15 segundos</p>
</section>
<section class="section-block-markdown-cell">
<h3 id="Entrenamiento en BF16">Entrenamiento en BF16<a class="anchor-link" href="#Entrenamiento en BF16">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Antes hemos entrenado en FP16 y ahora lo vamos a hacer en BF16, ¿Cuál es la diferencia?</p>
<img src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/FP32_FP16_BF16.webp" alt="FP32_FP16_BF16">
<p>Como podemos ver en la imagen, mientras que FP16 en comparación con FP32 tiene menos bits en la mantisa y el exponente, lo que hace que su rango sea mucho menor, BF16 en comparación con FP32 tiene el mismo número de bits del exponente pero menos en la mantisa, lo que hace que BF16 tenga el mismo rango de números que FP32, pero es menos preciso</p>
<p>Esto es beneficioso porque en FP16 algunos cálculos podrían dar números muy altos, que en formato FP16 no se podrían representar. Además hay ciertos dispositivos HW que están optimizados para este formato</p>
</section>
<section class="section-block-markdown-cell">
<p>Al igual que antes, ejecutamos <code>accelerate config</code> y le indicamos que queremos BF16</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="err">!</span><span class="n">accelerate</span> <span class="n">config</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>--------------------------------------------------------------------------------
In which compute environment are you running?
This machine
--------------------------------------------------------------------------------
multi-GPU
How many different machines will you use (use more than 1 for multi-node training)? [1]: 1
Should distributed operations be checked while running for errors? This can avoid timeout issues but will be slower. [yes/NO]: no
Do you wish to optimize your script with torch dynamo?[yes/NO]:no
Do you want to use DeepSpeed? [yes/NO]: no
Do you want to use FullyShardedDataParallel? [yes/NO]: no
Do you want to use Megatron-LM ? [yes/NO]: no
How many GPU(s) should be used for distributed training? [1]:2
What GPU(s) (by id) should be used for training on this machine as a comma-seperated list? [all]:0,1
--------------------------------------------------------------------------------
Do you wish to use FP16 or BF16 (mixed precision)?
bf16
accelerate configuration saved at ~/.cache/huggingface/accelerate/default_config.yaml
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Ahora ejecutamos el último script que habíamos creado, es decir, con un batch size de 256</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="w"> </span>
<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">14</span><span class="n">_accelerate_base_code_fp16_bs256</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Map: 100%|██████████████████████| 50000/50000 [00:03&amp;lt;00:00, 14814.95 examples/s]
Map: 100%|██████████████████████| 50000/50000 [00:03&amp;lt;00:00, 14506.83 examples/s]
100%|███████████████████████████████████████████| 88/88 [00:51&amp;lt;00:00,  1.70it/s]
100%|███████████████████████████████████████████| 10/10 [00:03&amp;lt;00:00,  3.21it/s]
Accuracy = 0.2112
CPU times: user 688 ms, sys: 144 ms, total: 832 ms
Wall time: 1min 17s
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Ha tardado un tiempo similar a lo que tardó antes, lo cual es normal, ya que hemos entrenado un modelo con pesos de 16 bits, al igual que antes</p>
</section>
<section class="section-block-markdown-cell">
<h3 id="Entrenamiento en FP8">Entrenamiento en FP8<a class="anchor-link" href="#Entrenamiento en FP8">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Ahora vamos a entrenar en formato FP8, que como su nombre indica, es un formato de coma flotante, donde cada peso tiene 8 bits, por lo que ejecutamos <code>accelerate config</code> para decirle que queremos FP8</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="err">!</span><span class="n">accelerate</span> <span class="n">config</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>--------------------------------------------------------------------------------
In which compute environment are you running?
This machine
--------------------------------------------------------------------------------
multi-GPU
How many different machines will you use (use more than 1 for multi-node training)? [1]: 1
Should distributed operations be checked while running for errors? This can avoid timeout issues but will be slower. [yes/NO]: no
Do you wish to optimize your script with torch dynamo?[yes/NO]:no
Do you want to use DeepSpeed? [yes/NO]: no
Do you want to use FullyShardedDataParallel? [yes/NO]: no
Do you want to use Megatron-LM ? [yes/NO]: no
How many GPU(s) should be used for distributed training? [1]:2
What GPU(s) (by id) should be used for training on this machine as a comma-seperated list? [all]:0,1
--------------------------------------------------------------------------------
Do you wish to use FP16 or BF16 (mixed precision)?
fp8
accelerate configuration saved at ~/.cache/huggingface/accelerate/default_config.yaml
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Ahora ejecutamos el último script, el de batch size de 256</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="w"> </span>
<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">14</span><span class="n">_accelerate_base_code_fp16_bs256</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Traceback (most recent call last):
&#x20;&#x20;File &quot;/home/wallabot/Documentos/web/portafolio/posts/accelerate_scripts/13_accelerate_base_code_fp16_bs256.py&quot;, line 12, in &amp;lt;module&amp;gt;
&#x20;&#x20;&#x20;&#x20;accelerator = Accelerator()
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;^^^^^^^^^^^^^
&#x20;&#x20;File &quot;/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/accelerator.py&quot;, line 371, in __init__
&#x20;&#x20;&#x20;&#x20;self.state = AcceleratorState(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;^^^^^^^^^^^^^^^^^
&#x20;&#x20;File &quot;/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/state.py&quot;, line 790, in __init__
&#x20;&#x20;&#x20;&#x20;raise ValueError(
ValueError: Using `fp8` precision requires `transformer_engine` or `MS-AMP` to be installed.
Traceback (most recent call last):
&#x20;&#x20;File &quot;/home/wallabot/Documentos/web/portafolio/posts/accelerate_scripts/13_accelerate_base_code_fp16_bs256.py&quot;, line 12, in &amp;lt;module&amp;gt;
&#x20;&#x20;&#x20;&#x20;accelerator = Accelerator()
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;^^^^^^^^^^^^^
&#x20;&#x20;File &quot;/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/accelerator.py&quot;, line 371, in __init__
&#x20;&#x20;&#x20;&#x20;self.state = AcceleratorState(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;^^^^^^^^^^^^^^^^^
&#x20;&#x20;File &quot;/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/state.py&quot;, line 790, in __init__
&#x20;&#x20;&#x20;&#x20;raise ValueError(
ValueError: Using `fp8` precision requires `transformer_engine` or `MS-AMP` to be installed.
[2024-05-13 21:40:56,455] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 501480) of binary: /home/wallabot/miniconda3/envs/nlp/bin/python
Traceback (most recent call last):
&#x20;&#x20;File &quot;/home/wallabot/miniconda3/envs/nlp/bin/accelerate&quot;, line 8, in &amp;lt;module&amp;gt;
&#x20;&#x20;&#x20;&#x20;sys.exit(main())
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;^^^^^^
&#x20;&#x20;File &quot;/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/commands/accelerate_cli.py&quot;, line 46, in main
&#x20;&#x20;&#x20;&#x20;args.func(args)
&#x20;&#x20;File &quot;/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/commands/launch.py&quot;, line 1048, in launch_command
&#x20;&#x20;&#x20;&#x20;multi_gpu_launcher(args)
&#x20;&#x20;File &quot;/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/commands/launch.py&quot;, line 702, in multi_gpu_launcher
&#x20;&#x20;&#x20;&#x20;distrib_run.run(args)
&#x20;&#x20;File &quot;/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/distributed/run.py&quot;, line 803, in run
&#x20;&#x20;&#x20;&#x20;elastic_launch(
&#x20;&#x20;File &quot;/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/distributed/launcher/api.py&quot;, line 135, in __call__
&#x20;&#x20;&#x20;&#x20;return launch_agent(self._config, self._entrypoint, list(args))
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
&#x20;&#x20;File &quot;/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/distributed/launcher/api.py&quot;, line 268, in launch_agent
&#x20;&#x20;&#x20;&#x20;raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
accelerate_scripts/13_accelerate_base_code_fp16_bs256.py FAILED
------------------------------------------------------------
Failures:
[1]:
&#x20;&#x20;time      : 2024-05-13_21:40:56
&#x20;&#x20;host      : wallabot
&#x20;&#x20;rank      : 1 (local_rank: 1)
&#x20;&#x20;exitcode  : 1 (pid: 501481)
&#x20;&#x20;error_file: &amp;lt;N/A&amp;gt;
&#x20;&#x20;traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
&#x20;&#x20;time      : 2024-05-13_21:40:56
&#x20;&#x20;host      : wallabot
&#x20;&#x20;rank      : 0 (local_rank: 0)
&#x20;&#x20;exitcode  : 1 (pid: 501480)
&#x20;&#x20;error_file: &amp;lt;N/A&amp;gt;
&#x20;&#x20;traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
CPU times: user 65.1 ms, sys: 14.5 ms, total: 79.6 ms
Wall time: 7.24 s
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Como los pesos ahora son de 8 bits y ocupan la mitad de memoria vamos a subir el batch size a 512</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">15</span><span class="n">_accelerate_base_code_fp8_bs512</span><span class="o">.</span><span class="n">py</span>
<span class="w"> </span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tqdm</span>
<span class="w"> </span>
<span class="c1"># Importamos e inicializamos Accelerator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>
<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>
<span class="w"> </span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="p">}</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="w"> </span>
<span class="n">BS</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="p">}</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>
<span class="w"> </span>
<span class="c1"># model.to(device)</span>
<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>
<span class="w"> </span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="c1"># loss.backward()</span>
<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="w">    </span>
<span class="n">accelerator</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Writing accelerate_scripts/15_accelerate_base_code_fp8_bs512.py
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Lo ejecutamos</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="w"> </span>
<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">15</span><span class="n">_accelerate_base_code_fp8_bs512</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<h2 id="Inferencia de modelos">Inferencia de modelos<a class="anchor-link" href="#Inferencia de modelos">¶</a></h2>
</section>
<section class="section-block-markdown-cell">
<h3 id="Uso del ecosistema de Hugging Face">Uso del ecosistema de Hugging Face<a class="anchor-link" href="#Uso del ecosistema de Hugging Face">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Vamos a ver cómo hacer inferencia de grandes modelos con la librería <code>transformers</code> de hugging face.</p>
</section>
<section class="section-block-markdown-cell">
<h4 id="Inferencia con pipeline">Inferencia con <code>pipeline</code><a class="anchor-link" href="#Inferencia con pipeline">¶</a></h4>
</section>
<section class="section-block-markdown-cell">
<p>Si usamos el ecosistema de Hugging Face es muy sencillo, ya que todo se produce por debajo sin tener que hacer nosotros mucho. En el caso de usar <code>pipeline</code>, que es la manera más sencilla de hacer inferencia con la librería <code>transformers</code>, simplemente tenemos que decirle el modelo que queremos usar y muy importante, pasarle <code>device_map=&quot;auto&quot;</code>. Esto hará que por debajo <code>accelerate</code> distribuya el modelo entre las distintas GPUs, RAM de la CPU o disco duro si es necesario</p>
</section>
<section class="section-block-markdown-cell">
<p>Hay más posibles valores para <code>device_map</code>, que los veremos más adelante, pero de momento quédate con <code>&quot;auto&quot;</code>.</p>
</section>
<section class="section-block-markdown-cell">
<p>Vamos a usar el modelo <code>Llama3 8B</code>, que como su nombre indica es un modelo de unos 8 mil millones de parámetros. Como cada parámetro por defecto está en formato FP32, que corresponde a 4 bytes (32 bits), eso quiere decir que si multiplicamos 8 mil millones de parámetros por 4 bytes, nos queda que necesitaría una GPU con unos 32 GB de VRAM.</p>
<p>En mi caso tengo 2 GPUs de 24 GB de VRAM, por lo que no entraría en una sola GPU. Pero gracias a poner <code>device_map=&quot;auto&quot;</code>, accelerate distribuirá el modelo entre las dos GPUs y podré realizar la inferencia</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">16</span><span class="n">_inference_with_pipeline</span><span class="o">.</span><span class="n">py</span>
<span class="w"> </span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">pipeline</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;meta-llama/Meta-Llama-3-8B-Instruct&quot;</span>
<span class="n">generator</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">checkpoints</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;Conoces accelerate de hugging face?&quot;</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">generator</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Overwriting accelerate_scripts/09_inference_with_pipeline.py
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Ahora lo ejecutamos, solo que como pipeline usa por debajo accelerate, no necesitamos ejecutarlo con <code>accelerate launch script.py</code> sino que con <code>python script.py</code> vale</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="err">!</span><span class="n">python</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">16</span><span class="n">_inference_with_pipeline</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Loading checkpoint shards: 100%|██████████████████| 4/4 [00:09&amp;lt;00:00,  2.27s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[&#x7B;&#x27;generated_text&#x27;: &#x27;Conoces accelerate de hugging face? ¿Qué es el modelo de lenguaje de transformers y cómo se utiliza en el marco de hugging face? ¿Cómo puedo utilizar modelos de lenguaje de transformers en mi aplicación? ¿Qué son los tokenizers y cómo se utilizan en el marco de hugging face? ¿Cómo puedo crear un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los datasets y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar datasets para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los checkpoints y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los evaluadores y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los pre-trainados y cómo se utilizan en el marco de hugging face? ¿Cómo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¿Qué son los finetuning&#x27;&#x7D;]
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Como se puede ver, no ha respondido, sino que ha seguido haciendo preguntas. Esto es porque Llama3 es un modelo de lenguaje que lo que hace es predecir el siguiente token, así que con el prompt que le he pasado, ha considerado que los siguientes mejores tokens son unos que corresponden a más preguntas. Lo cual tiene sentido, porque hay veces que la gente tiene dudas sobre un tema y genera muchas preguntas, así que para que nos conteste a la pregunta hay que condicionarle un poco</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">17</span><span class="n">_inference_with_pipeline_condition</span><span class="o">.</span><span class="n">py</span>
<span class="w"> </span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">pipeline</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;meta-llama/Meta-Llama-3-8B-Instruct&quot;</span>
<span class="n">generator</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">checkpoints</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;Conoces accelerate de hugging face?&quot;</span>
<span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">        </span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;Eres un chatbot amigable que siempre intenta solucionar las dudas&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prompt</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">},</span>
<span class="p">]</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">generator</span><span class="p">(</span><span class="n">messages</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;generated_text&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Overwriting accelerate_scripts/10_inference_with_pipeline_condition.py
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Como ves se ha generado un mensaje con roles, condicionando el modelo y con el prompt</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="err">!</span><span class="n">python</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">17</span><span class="n">_inference_with_pipeline_condition</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Loading checkpoint shards: 100%|██████████████████| 4/4 [00:09&amp;lt;00:00,  2.41s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
&#x7B;&#x27;role&#x27;: &#x27;assistant&#x27;, &#x27;content&#x27;: &#x27;¡Hola!\n\nSí, conozco Accelerate de Hugging Face. Accelerate es una biblioteca de Python desarrollada por Hugging Face que se enfoca en simplificar y acelerar el entrenamiento y la evaluación de modelos de lenguaje en diferentes dispositivos y entornos.\n\nCon Accelerate, puedes entrenar modelos de lenguaje en diferentes plataformas y dispositivos, como GPUs, TPUs, CPUs y servidores, sin necesidad de cambiar el código de tu modelo. Esto te permite aprovechar al máximo la potencia de cálculo de tus dispositivos y reducir el tiempo de entrenamiento.\n\nAccelerate también ofrece varias características adicionales, como:\n\n* Soporte para diferentes frameworks de machine learning, como TensorFlow, PyTorch y JAX.\n* Integración con diferentes sistemas de almacenamiento y procesamiento de datos, como Amazon S3 y Google Cloud Storage.\n* Soporte para diferentes protocolos de comunicación, como HTTP y gRPC.\n* Herramientas para monitorear y depurar tus modelos en tiempo real.\n\nEn resumen, Accelerate es una herramienta muy útil para desarrolladores de modelos de lenguaje que buscan simplificar y acelerar el proceso de entrenamiento y evaluación de sus modelos.\n\n¿Tienes alguna pregunta específica sobre Accelerate o necesitas ayuda para implementarlo en tu proyecto?&#x27;&#x7D;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Ahora la respuesta sí responde nuestro prompt</p>
</section>
<section class="section-block-markdown-cell">
<h4 id="Inferencia con AutoClass">Inferencia con <code>AutoClass</code><a class="anchor-link" href="#Inferencia con AutoClass">¶</a></h4>
</section>
<section class="section-block-markdown-cell">
<p>Por último vamos a ver cómo hacer la inferencia solo con <code>AutoClass</code>.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">18</span><span class="n">_inference_with_autoclass</span><span class="o">.</span><span class="n">py</span>
<span class="w"> </span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">TextStreamer</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;meta-llama/Meta-Llama-3-8B-Instruct&quot;</span>
<span class="w"> </span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>
<span class="n">streamer</span> <span class="o">=</span> <span class="n">TextStreamer</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;Conoces accelerate de hugging face?&quot;</span>
<span class="n">tokens_input</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">([</span><span class="n">prompt</span><span class="p">],</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="o">**</span><span class="n">tokens_input</span><span class="p">,</span> <span class="n">streamer</span><span class="o">=</span><span class="n">streamer</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">do_sample</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">top_p</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Overwriting accelerate_scripts/11_inference_with_autoclass.py
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Como se puede ver, se ha creado el objeto <code>streamer</code> que luego se le pasa al método <code>generate</code> del modelo. Esto es útil para que se vaya imprimiendo cada palabra a medida que se va generando y no haya que esperar a que se genere toda la salida para imprimirla</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="err">!</span><span class="n">python</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">18</span><span class="n">_inference_with_autoclass</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards: 100%|██████████████████| 4/4 [00:09&amp;lt;00:00,  2.28s/it]
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
&amp;lt;|begin_of_text|&amp;gt;Conoces accelerate de hugging face? Si es así, puedes utilizar la biblioteca `transformers` de Hugging Face para crear un modelo de lenguaje que pueda predecir la siguiente palabra en una secuencia de texto.

Aquí te muestro un ejemplo de cómo hacerlo:
```
import pandas as pd
import torch
from transformers import AutoModelForSequenceClassification, AutoTokenizer

# Cargar el modelo y el tokenizador
model_name = &quot;bert-base-uncased&quot;
model = AutoModelForSequenceClassification.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)

# Cargar el conjunto de datos
train_df = pd.read_csv(&quot;train.csv&quot;)
test_df = pd.read_csv(&quot;test.csv&quot;)

# Preprocesar los datos
train_texts = train_df[&quot;text&quot;]
train_labels = train_df[&quot;label&quot;]
test_texts = test_df[&quot;text&quot;]

# Convertir los textos en entradas para el modelo
train_encodings = tokenizer.batch_encode_plus(train_texts, 
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;add_special_tokens=True, 
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;max_length=512, 
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;return_attention_mask=True, 
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;return_tensors=&#x27;pt&#x27;)

test_encodings = tokenizer.batch_encode_plus(test_texts, 
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;add_special_tokens=True, 
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;max_length=512, 
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;return_attention_mask=True, 
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;return_tensors=&#x27;pt&#x27;)

# Crear un dataloader para entrenar el modelo
train_dataset = torch.utils.data.TensorDataset(train_encodings[&quot;input_ids&quot;], 
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;train_encodings[&quot;attention_mask&quot;], 
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;torch.tensor(train_labels))
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)

# Entrenar el modelo
device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)
model.to(device)
criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)

for epoch in range(5):
&#x20;&#x20;&#x20;&#x20;model.train()
&#x20;&#x20;&#x20;&#x20;total_loss = 0
&#x20;&#x20;&#x20;&#x20;for batch in train_loader:
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;input_ids = batch[0].to(device)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;attention_mask = batch[1].to(device)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;labels = batch[2].to(device)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;optimizer.zero_grad()
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;loss = criterion(outputs, labels)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;loss.backward()
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;optimizer.step()
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;total_loss += loss.item()
&#x20;&#x20;&#x20;&#x20;print(f&quot;Epoch &#x7B;epoch+1&#x7D;, Loss: &#x7B;total
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Uso PyTorch">Uso PyTorch<a class="anchor-link" href="#Uso PyTorch">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Normalmente la manera de hacer inferencias con pytorch es crear un modelo con los pesos inicializados aleatoriamente y a continuación cargar un <code>state dict</code> con los pesos del modelo preentrenado, así que para obtener ese <code>state dict</code> vamos a hacer primero una pequeña trampa y nos lo vamos a descargar</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torchvision.models</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">models</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet152</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">models</span><span class="o">.</span><span class="n">ResNet152_Weights</span><span class="o">.</span><span class="n">IMAGENET1K_V1</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">&#39;accelerate_scripts/resnet152_pretrained.pth&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Downloading: &quot;https://download.pytorch.org/models/resnet152-394f9c45.pth&quot; to /home/maximo.fernandez/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth
100%|██████████| 230M/230M [02:48&amp;lt;00:00, 1.43MB/s]
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Ahora que tenemos el <code>state dict</code> vamos a hacer inferencia como se hace normalmente en pytorch</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torchvision.models</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">models</span>
<span class="w"> </span>
<span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>     <span class="c1"># Set device</span>
<span class="w"> </span>
<span class="n">resnet152</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet152</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="c1"># Create model with random weights and move to device</span>
<span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;accelerate_scripts/resnet152_pretrained.pth&#39;</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="c1"># Load pretrained weights into device memory</span>
<span class="n">resnet152</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span> <span class="c1"># Load this weights into the model</span>
<span class="w"> </span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Random image with batch size 1</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">resnet152</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="n">output</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>torch.Size([1, 1000])
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vamos a explicar qué ha pasado</p>
<ul>
  <li>Cuando hemos hecho <code>resnet152 = models.resnet152().to(device)</code> se ha cargado una ResNet152 con pesos aleatorios en la memoria de la GPU</li>
  <li>Cuando hemos hecho <code>state_dict = torch.load('accelerate_scripts/resnet152_pretrained.pth', map_location=device)</code> se ha cargado un diccionario con los pesos entrenados en la memoria de la GPU</li>
  <li>Cuando hemos hecho <code>resnet152.load_state_dict(state_dict)</code> se han asignado esos pesos preentrenados al modelo</li>
</ul>
<p>Es decir, se ha cargado dos veces el modelo en la memoria de la GPU</p>
</section>
<section class="section-block-markdown-cell">
<p>Te puedes estar preguntando por qué hemos hecho primero</p>
<section class="section-block-markdown-cell">
      <div class='highlight'><pre><code class="language-python">model = models.resnet152(weights=models.ResNet152_Weights.IMAGENET1K_V1)<br>torch.save(model.state_dict(), &#39;accelerate_scripts/resnet152_pretrained.pth&#39;)</code></pre></div>
      </section>
<p>Para luego hacer</p>
<section class="section-block-markdown-cell">
      <div class='highlight'><pre><code class="language-python">resnet152 = models.resnet152().to(device)<br>state_dict = torch.load(&#39;accelerate_scripts/resnet152_pretrained.pth&#39;, map_location=device)<br>resnet152.load_state_dict(state_dict)</code></pre></div>
      </section>
<p>Y por qué no usamos directamente</p>
<div class='highlight'><pre><code class="language-text">model = models.resnet152(weights=models.ResNet152_Weights.IMAGENET1K_V1)
</code></pre></div>
<p>Y nos dejamos de guardar el <code>state dict</code> para luego cargarlo. Bueno, pues porque Pytorch, por debajo hace lo mismo que hemos hecho. Así que para poder ver todo el proceso hemos hecho en varias líneas lo que Pytorch hace en una</p>
</section>
<section class="section-block-markdown-cell">
<p>Esta manera de trabajar ha funcionado bien hasta ahora, mientras que los modelos tenían un tamaño manejable por las GPUs de usuario. Pero desde la llegada de los LLMs este enfoque no tiene sentido</p>
<p>Por ejemplo, un modelo de 6B de parámetros ocuparía en la memoria 24 GB, y como se carga dos veces con esta manera de trabajar, haría falta tener una GPU de 48 GB.</p>
</section>
<section class="section-block-markdown-cell">
<p>Así que para arreglar esto, la manera de cargar un modelo preentrenado de PyTorch es:</p>
<ul>
  <li>Crear un modelo vacío con <code>init_empty_weights</code> que no ocupará memoria RAM</li>
  <li>Luego cargar los pesos con <code>load_checkpoint_and_dispatch</code> que cargará un punto de control dentro del modelo vacío y distribuirá los pesos para cada capa en todos los dispositivos que se tenga disponibles (GPU, CPU, RAM y disco duro), gracias a poner <code>device_map="auto"</code></li>
</ul>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torchvision.models</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">models</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">init_empty_weights</span><span class="p">,</span> <span class="n">load_checkpoint_and_dispatch</span>
<span class="w"> </span>
<span class="k">with</span> <span class="n">init_empty_weights</span><span class="p">():</span>
<span class="w">    </span><span class="n">resnet152</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet152</span><span class="p">()</span>
<span class="w"> </span>
<span class="n">resnet152</span> <span class="o">=</span> <span class="n">load_checkpoint_and_dispatch</span><span class="p">(</span><span class="n">resnet152</span><span class="p">,</span> <span class="n">checkpoint</span><span class="o">=</span><span class="s1">&#39;accelerate_scripts/resnet152_pretrained.pth&#39;</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>
<span class="w"> </span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Random image with batch size 1</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">resnet152</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="n">output</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>torch.Size([1, 1000])
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Como funciona accelerate por debajo">Cómo funciona accelerate por debajo<a class="anchor-link" href="#Como funciona accelerate por debajo">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>En este vídeo se puede ver gráficamente cómo funciona accelerate por debajo</p>
</section>
<section class="section-block-markdown-cell">
<iframe width="1280" height="720" src="https://www.youtube.com/embed/MWCSGj9jEAo" title="Accelerate Big Model Inference: How Does it Work?" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</section>
<section class="section-block-markdown-cell">
<h4 id="Inicializacion de un modelo vacio">Inicialización de un modelo vacío<a class="anchor-link" href="#Inicializacion de un modelo vacio">¶</a></h4>
</section>
<section class="section-block-markdown-cell">
<p><code>Accelerate</code> crea el esqueleto de un modelo vacío mediante <code>init_empty_weights</code> para que ocupe la menor cantidad de memoria posible</p>
</section>
<section class="section-block-markdown-cell">
<p>Por ejemplo, veamos cuanta RAM tengo ahora disponible en mi ordenador</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">psutil</span>
<span class="w"> </span>
<span class="k">def</span><span class="w"> </span><span class="nf">get_ram_info</span><span class="p">():</span>
<span class="w">    </span><span class="n">ram</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">psutil</span><span class="o">.</span><span class="n">virtual_memory</span><span class="p">()</span><span class="o">.</span><span class="n">_asdict</span><span class="p">())</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total RAM: </span><span class="si">{</span><span class="p">(</span><span class="n">ram</span><span class="p">[</span><span class="s1">&#39;total&#39;</span><span class="p">]</span><span class="o">/</span><span class="mi">1024</span><span class="o">/</span><span class="mi">1024</span><span class="o">/</span><span class="mi">1024</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> GB, Available RAM: </span><span class="si">{</span><span class="p">(</span><span class="n">ram</span><span class="p">[</span><span class="s1">&#39;available&#39;</span><span class="p">]</span><span class="o">/</span><span class="mi">1024</span><span class="o">/</span><span class="mi">1024</span><span class="o">/</span><span class="mi">1024</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> GB, Used RAM: </span><span class="si">{</span><span class="p">(</span><span class="n">ram</span><span class="p">[</span><span class="s1">&#39;used&#39;</span><span class="p">]</span><span class="o">/</span><span class="mi">1024</span><span class="o">/</span><span class="mi">1024</span><span class="o">/</span><span class="mi">1024</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> GB&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">get_ram_info</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Total RAM: 31.24 GB, Available RAM: 22.62 GB, Used RAM: 7.82 GB
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Tengo unos 22 GB de RAM disponibles</p>
<p>Ahora vamos a intentar crear un modelo 5000x1000x1000 parámetros, es decir, de 5B de parámetros, si cada parámetro está en FP32, supone 20 GB de RAM</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">)])</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Si volvemos a ver la RAM</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">get_ram_info</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Total RAM: 31.24 GB, Available RAM: 3.77 GB, Used RAM: 26.70 GB
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Como vemos, ahora solo tenemos 3 GB de RAM disponibles</p>
</section>
<section class="section-block-markdown-cell">
<p>Ahora vamos a eliminar el modelo para liberar RAM</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">del</span> <span class="n">model</span>
<span class="n">get_ram_info</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Total RAM: 31.24 GB, Available RAM: 22.44 GB, Used RAM: 8.03 GB
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Volvemos a tener unos 22 GB de RAM disponibles</p>
</section>
<section class="section-block-markdown-cell">
<p>Vamos ahora a usar <code>init_empty_weights</code> de <code>accelerate</code> y luego vemos la RAM</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">init_empty_weights</span>
<span class="w"> </span>
<span class="k">with</span> <span class="n">init_empty_weights</span><span class="p">():</span>
<span class="w">    </span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">)])</span>
<span class="w"> </span>
<span class="n">get_ram_info</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Total RAM: 31.24 GB, Available RAM: 22.32 GB, Used RAM: 8.16 GB
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Antes teníamos exactamente 22.44 GB libres y tras crear el modelo con <code>init_empty_weights</code> tenemos 22.32 GB. El ahorro en RAM es enorme! Casi no se ha ocupado RAM para crear el modelo.</p>
<p>Esto se basa en el metadispositivo introducido en PyTorch 1.9, por lo que es importante que para usar <code>accelerate</code> tengamos una versión de Pytorch posterior</p>
</section>
<section class="section-block-markdown-cell">
<h4 id="Carga de los pesos">Carga de los pesos<a class="anchor-link" href="#Carga de los pesos">¶</a></h4>
</section>
<section class="section-block-markdown-cell">
<p>Una vez hemos inicializado el modelo, tenemos que cargarle los pesos, lo cual hacemos mediante <code>load_checkpoint_and_dispatch</code>, que como su nombre indica, carga los pesos y los envía al dispositivo o dispositivos que sean necesarios.</p>
</section>