<section class="section-block-markdown-cell">
<h1 id="Hugging Face Accelerate">Hugging Face Accelerate<a class="anchor-link" href="#Hugging Face Accelerate">¬∂</a></h1>
</section>
<section class="section-block-markdown-cell">
<p><code>Accelerate</code> es una biblioteca de Hugging Face que permite ejecutar el mismo c√≥digo PyTorch en cualquier configuraci√≥n distribuida a√±adiendo s√≥lo cuatro l√≠neas de c√≥digo.</p>
</section>
<section class="section-block-markdown-cell">
<h2 id="Instalacion">Instalaci√≥n<a class="anchor-link" href="#Instalacion">¬∂</a></h2>
</section>
<section class="section-block-markdown-cell">
<p>Para instalar <code>accelerate</code> con <code>pip</code> simplemente ejecuta:</p>
<div class='highlight'><pre><code class="language-bash">pip install accelerate
</code></pre></div>
<p>Y con <code>conda</code>:</p>
<div class='highlight'><pre><code class="language-bash">conda install -c conda-forge accelerate
</code></pre></div>
</section>
<section class="section-block-markdown-cell">
<h2 id="Configuracion">Configuraci√≥n<a class="anchor-link" href="#Configuracion">¬∂</a></h2>
</section>
<section class="section-block-markdown-cell">
<p>En cada entorno en el que se instale <code>accelerate</code> lo primero que se tiene que hacer es configurarlo, para ello ejecutamos en una terminal:</p>
<div class='highlight'><pre><code class="language-bash">accelerate config
</code></pre></div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="err">!</span><span class="n">accelerate</span> <span class="n">config</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>--------------------------------------------------------------------------------
In which compute environment are you running?
This machine
--------------------------------------------------------------------------------
multi-GPU
How many different machines will you use (use more than 1 for multi-node training)? [1]: 1
Should distributed operations be checked while running for errors? This can avoid timeout issues but will be slower. [yes/NO]: no
Do you wish to optimize your script with torch dynamo?[yes/NO]:no
Do you want to use DeepSpeed? [yes/NO]: no
Do you want to use FullyShardedDataParallel? [yes/NO]: no
Do you want to use Megatron-LM ? [yes/NO]: no
How many GPU(s) should be used for distributed training? [1]:2
What GPU(s) (by id) should be used for training on this machine as a comma-seperated list? [all]:0,1
--------------------------------------------------------------------------------
Do you wish to use FP16 or BF16 (mixed precision)?
no
accelerate configuration saved at ~/.cache/huggingface/accelerate/default_config.yaml
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>En mi caso las respuestas han sido</p>
<ul>
  <li>In which compute environment are you running?</li>
    <ul>
      <li>[x] "This machine"</li>
      <li>[_] "AWS (Amazon SageMaker)"</li>
    </ul>
</ul>
<p>> Quiero configurarlo en mi ordenador</p>
<ul>
  <li>Which type of machine are you using?</li>
    <ul>
      <li>[_] multi-CPU</li>
      <li>[_] multi-XPU</li>
      <li>[x] multi-GPU</li>
      <li>[_] multi-NPU</li>
      <li>[_] TPU</li>
    </ul>
</ul>
<p>> Como tengo 2 GPUs y quiero ejecutar c√≥digos distribuidos en ellas, elijo `multi-GPU`</p>
<ul>
  <li>How many different machines will you use (use more than 1 for multi-node training)? [1]:</li>
    <ul>
      <li>1</li>
    </ul>
</ul>
<p>> Elijo `1` porque solo voy a ejecutar en mi ordenador</p>
<ul>
  <li>Should distributed operations be checked while running for errors? This can avoid timeout issues but will be slower. [yes/NO]:</li>
    <ul>
      <li>no</li>
    </ul>
</ul>
<p>> Con esta opci√≥n, se puede elegir que `accelerate` chequee errores en la ejecuci√≥n, pero har√≠a que vaya m√°s lento, as√≠ que elijo `no`, y en caso de que haya errores lo cambio a `yes`</p>
<ul>
  <li>Do you wish to optimize your script with torch dynamo?[yes/NO]:</li>
    <ul>
      <li>no</li>
    </ul>
</ul>
<ul>
  <li>Do you want to use FullyShardedDataParallel? [yes/NO]:</li>
    <ul>
      <li>no</li>
    </ul>
</ul>
<ul>
  <li>Do you want to use Megatron-LM ? [yes/NO]:</li>
    <ul>
      <li>no</li>
    </ul>
</ul>
<ul>
  <li>How many GPU(s) should be used for distributed training? [1]:</li>
    <ul>
      <li>2</li>
    </ul>
</ul>
<p>> Elijo `2` porque tengo 2 GPUs</p>
<ul>
  <li>What GPU(s) (by id) should be used for training on this machine as a comma-seperated list? [all]:</li>
    <ul>
      <li>0,1</li>
    </ul>
</ul>
<p>> Elijo `0,1` porque quiero usar las dos GPUs</p>
<ul>
  <li>Do you wish to use FP16 or BF16 (mixed precision)?</li>
    <ul>
      <li>[x] no</li>
      <li>[_] fp16</li>
      <li>[_] bf16</li>
      <li>[_] fp8</li>
    </ul>
</ul>
<p>> De momento elijo `no`, porque para simplificar el c√≥digo cuando no uso `acelerate` vamos a entrenar en fp32, pero lo ideal ser√≠a usar fp16</p>
</section>
<section class="section-block-markdown-cell">
<p>La configuraci√≥n se guardar√° en <code>~/.cache/huggingface/accelerate/default_config.yaml</code> y se puede modificar en cualquier momento. Vamos a ver qu√© hay dentro</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="err">!</span><span class="n">cat</span> <span class="o">~/.</span><span class="n">cache</span><span class="o">/</span><span class="n">huggingface</span><span class="o">/</span><span class="n">accelerate</span><span class="o">/</span><span class="n">default_config</span><span class="o">.</span><span class="n">yaml</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>compute_environment: LOCAL_MACHINE
debug: false
distributed_type: MULTI_GPU
downcast_bf16: &#x27;no&#x27;
gpu_ids: 0,1
machine_rank: 0
main_training_function: main
mixed_precision: fp16
num_machines: 1
num_processes: 2
rdzv_backend: static
same_network: true
tpu_env: []
tpu_use_cluster: false
tpu_use_sudo: false
use_cpu: false
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Otra forma de ver la configuraci√≥n que tenemos es ejecutando en una terminal:</p>
<div class='highlight'><pre><code class="language-bash">accelerate env
</code></pre></div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="err">!</span><span class="n">accelerate</span> <span class="n">env</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>
Copy-and-paste the text below in your GitHub issue

- `Accelerate` version: 0.28.0
- Platform: Linux-5.15.0-105-generic-x86_64-with-glibc2.31
- Python version: 3.11.8
- Numpy version: 1.26.4
- PyTorch version (GPU?): 2.2.1+cu121 (True)
- PyTorch XPU available: False
- PyTorch NPU available: False
- System RAM: 31.24 GB
- GPU type: NVIDIA GeForce RTX 3090
- `Accelerate` default config:
	- compute_environment: LOCAL_MACHINE
	- distributed_type: MULTI_GPU
	- mixed_precision: fp16
	- use_cpu: False
	- debug: False
	- num_processes: 2
	- machine_rank: 0
	- num_machines: 1
	- gpu_ids: 0,1
	- rdzv_backend: static
	- same_network: True
	- main_training_function: main
	- downcast_bf16: no
	- tpu_use_cluster: False
	- tpu_use_sudo: False
	- tpu_env: []
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Una vez hemos configurado <code>accelerate</code> podemos probar si lo hemos hecho bien ejecutando en una terminal:</p>
<div class='highlight'><pre><code class="language-bash">accelerate test
</code></pre></div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="err">!</span><span class="n">accelerate</span> <span class="n">test</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>
Running:  accelerate-launch ~/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/test_utils/scripts/test_script.py
stdout: **Initialization**
stdout: Testing, testing. 1, 2, 3.
stdout: Distributed environment: DistributedType.MULTI_GPU  Backend: nccl
stdout: Num processes: 2
stdout: Process index: 0
stdout: Local process index: 0
stdout: Device: cuda:0
stdout: 
stdout: Mixed precision type: fp16
stdout: 
stdout: Distributed environment: DistributedType.MULTI_GPU  Backend: nccl
stdout: Num processes: 2
stdout: Process index: 1
stdout: Local process index: 1
stdout: Device: cuda:1
stdout: 
stdout: Mixed precision type: fp16
stdout: 
stdout: 
stdout: **Test process execution**
stdout: 
stdout: **Test split between processes as a list**
stdout: 
stdout: **Test split between processes as a dict**
stdout: 
stdout: **Test split between processes as a tensor**
stdout: 
stdout: **Test random number generator synchronization**
stdout: All rng are properly synched.
stdout: 
stdout: **DataLoader integration test**
stdout: 0 1 tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
stdout:         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
stdout:         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
stdout:         54, 55, 56, 57, 58, 59, 60, 61, 62, 63], device=&#x27;cuda:1&#x27;) &amp;lt;class &#x27;accelerate.data_loader.DataLoaderShard&#x27;&amp;gt;
stdout: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
stdout:         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
stdout:         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
stdout:         54, 55, 56, 57, 58, 59, 60, 61, 62, 63], device=&#x27;cuda:0&#x27;) &amp;lt;class &#x27;accelerate.data_loader.DataLoaderShard&#x27;&amp;gt;
stdout: Non-shuffled dataloader passing.
stdout: Shuffled dataloader passing.
stdout: Non-shuffled central dataloader passing.
stdout: Shuffled central dataloader passing.
stdout: 
stdout: **Training integration test**
stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32
stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32
stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32
stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32
stdout: Training yielded the same results on one CPU or distributed setup with no batch split.
stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32
stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32
stdout: Training yielded the same results on one CPU or distributes setup with batch split.
stdout: FP16 training check.
stdout: FP16 training check.
stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32
stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32
stdout: Keep fp32 wrapper check.
stdout: Keep fp32 wrapper check.
stdout: BF16 training check.
stdout: BF16 training check.
stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32
stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32
stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32
stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32
stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32Model dtype: torch.float32, torch.float32. Input dtype: torch.float32
stdout: 
stdout: Training yielded the same results on one CPU or distributed setup with no batch split.
stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32
stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32
stdout: FP16 training check.
stdout: Training yielded the same results on one CPU or distributes setup with batch split.
stdout: FP16 training check.
stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32
stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32
stdout: Keep fp32 wrapper check.
stdout: Keep fp32 wrapper check.
stdout: BF16 training check.
stdout: BF16 training check.
stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32
stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32
stdout: 
stdout: **Breakpoint trigger test**
Test is a success! You are ready for your distributed training!
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vemos que termina diciendo <code>Test is a success! You are ready for your distributed training!</code> por lo que todo est√° correcto.</p>
</section>
<section class="section-block-markdown-cell">
<h2 id="Entrenamiento">Entrenamiento<a class="anchor-link" href="#Entrenamiento">¬∂</a></h2>
</section>
<section class="section-block-markdown-cell">
<h3 id="Optimizacion del entrenamiento">Optimizaci√≥n del entrenamiento<a class="anchor-link" href="#Optimizacion del entrenamiento">¬∂</a></h3>
</section>
<section class="section-block-markdown-cell">
<h4 id="Codigo base">C√≥digo base<a class="anchor-link" href="#Codigo base">¬∂</a></h4>
</section>
<section class="section-block-markdown-cell">
<p>Vamos a hacer primero un c√≥digo de entrenamiento base y luego lo optimizaremos  para ver c√≥mo se hace y c√≥mo mejora</p>
</section>
<section class="section-block-markdown-cell">
<p>Primero vamos a buscar un dataset, en mi caso voy a usar el dataset <a href="https://huggingface.co/datasets/tweet_eval">tweet_eval</a>, que es un dataset de clasificaci√≥n de tweets, en concreto voy a descargar el subset <code>emoji</code> que clasifica los tweets con emoticonos</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="w"> </span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>
<span class="n">dataset</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>DatasetDict(&#x7B;
&#x20;&#x20;&#x20;&#x20;train: Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;text&#x27;, &#x27;label&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 45000
&#x20;&#x20;&#x20;&#x20;&#x7D;)
&#x20;&#x20;&#x20;&#x20;test: Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;text&#x27;, &#x27;label&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 50000
&#x20;&#x20;&#x20;&#x20;&#x7D;)
&#x20;&#x20;&#x20;&#x20;validation: Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;text&#x27;, &#x27;label&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 5000
&#x20;&#x20;&#x20;&#x20;&#x7D;)
&#x7D;)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>DatasetInfo(description=&#x27;&#x27;, citation=&#x27;&#x27;, homepage=&#x27;&#x27;, license=&#x27;&#x27;, features=&#x7B;&#x27;text&#x27;: Value(dtype=&#x27;string&#x27;, id=None), &#x27;label&#x27;: ClassLabel(names=[&#x27;‚ù§&#x27;, &#x27;üòç&#x27;, &#x27;üòÇ&#x27;, &#x27;üíï&#x27;, &#x27;üî•&#x27;, &#x27;üòä&#x27;, &#x27;üòé&#x27;, &#x27;‚ú®&#x27;, &#x27;üíô&#x27;, &#x27;üòò&#x27;, &#x27;üì∑&#x27;, &#x27;üá∫üá∏&#x27;, &#x27;‚òÄ&#x27;, &#x27;üíú&#x27;, &#x27;üòâ&#x27;, &#x27;üíØ&#x27;, &#x27;üòÅ&#x27;, &#x27;üéÑ&#x27;, &#x27;üì∏&#x27;, &#x27;üòú&#x27;], id=None)&#x7D;, post_processed=None, supervised_keys=None, task_templates=None, builder_name=&#x27;parquet&#x27;, dataset_name=&#x27;tweet_eval&#x27;, config_name=&#x27;emoji&#x27;, version=0.0.0, splits=&#x7B;&#x27;train&#x27;: SplitInfo(name=&#x27;train&#x27;, num_bytes=3808792, num_examples=45000, shard_lengths=None, dataset_name=&#x27;tweet_eval&#x27;), &#x27;test&#x27;: SplitInfo(name=&#x27;test&#x27;, num_bytes=4262151, num_examples=50000, shard_lengths=None, dataset_name=&#x27;tweet_eval&#x27;), &#x27;validation&#x27;: SplitInfo(name=&#x27;validation&#x27;, num_bytes=396704, num_examples=5000, shard_lengths=None, dataset_name=&#x27;tweet_eval&#x27;)&#x7D;, download_checksums=&#x7B;&#x27;hf://datasets/tweet_eval@b3a375baf0f409c77e6bc7aa35102b7b3534f8be/emoji/train-00000-of-00001.parquet&#x27;: &#x7B;&#x27;num_bytes&#x27;: 2609973, &#x27;checksum&#x27;: None&#x7D;, &#x27;hf://datasets/tweet_eval@b3a375baf0f409c77e6bc7aa35102b7b3534f8be/emoji/test-00000-of-00001.parquet&#x27;: &#x7B;&#x27;num_bytes&#x27;: 3047341, &#x27;checksum&#x27;: None&#x7D;, &#x27;hf://datasets/tweet_eval@b3a375baf0f409c77e6bc7aa35102b7b3534f8be/emoji/validation-00000-of-00001.parquet&#x27;: &#x7B;&#x27;num_bytes&#x27;: 281994, &#x27;checksum&#x27;: None&#x7D;&#x7D;, download_size=5939308, post_processing_size=None, dataset_size=8467647, size_in_bytes=14406955)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vamos a ver las clases</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>[&#x27;‚ù§&#x27;, &#x27;üòç&#x27;, &#x27;üòÇ&#x27;, &#x27;üíï&#x27;, &#x27;üî•&#x27;, &#x27;üòä&#x27;, &#x27;üòé&#x27;, &#x27;‚ú®&#x27;, &#x27;üíô&#x27;, &#x27;üòò&#x27;, &#x27;üì∑&#x27;, &#x27;üá∫üá∏&#x27;, &#x27;‚òÄ&#x27;, &#x27;üíú&#x27;, &#x27;üòâ&#x27;, &#x27;üíØ&#x27;, &#x27;üòÅ&#x27;, &#x27;üéÑ&#x27;, &#x27;üì∏&#x27;, &#x27;üòú&#x27;]
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Y el n√∫mero de clases</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
<span class="n">num_classes</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>20
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vemos que el dataset tiene 20 clases</p>
</section>
<section class="section-block-markdown-cell">
<p>Vamos a ver la secuencia m√°xima de cada split</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">max_len_train</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">max_len_val</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">max_len_test</span> <span class="o">=</span> <span class="mi">0</span>
<span class="w"> </span>
<span class="n">split</span> <span class="o">=</span> <span class="s2">&quot;train&quot;</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">])):</span>
<span class="w">    </span><span class="n">len_i</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s2">&quot;text&quot;</span><span class="p">])</span>
<span class="w">    </span><span class="k">if</span> <span class="n">len_i</span> <span class="o">&amp;</span><span class="n">gt</span><span class="p">;</span> <span class="n">max_len_train</span><span class="p">:</span>
<span class="w">        </span><span class="n">max_len_train</span> <span class="o">=</span> <span class="n">len_i</span>
<span class="n">split</span> <span class="o">=</span> <span class="s2">&quot;validation&quot;</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">])):</span>
<span class="w">    </span><span class="n">len_i</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s2">&quot;text&quot;</span><span class="p">])</span>
<span class="w">    </span><span class="k">if</span> <span class="n">len_i</span> <span class="o">&amp;</span><span class="n">gt</span><span class="p">;</span> <span class="n">max_len_val</span><span class="p">:</span>
<span class="w">        </span><span class="n">max_len_val</span> <span class="o">=</span> <span class="n">len_i</span>
<span class="n">split</span> <span class="o">=</span> <span class="s2">&quot;test&quot;</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">])):</span>
<span class="w">    </span><span class="n">len_i</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s2">&quot;text&quot;</span><span class="p">])</span>
<span class="w">    </span><span class="k">if</span> <span class="n">len_i</span> <span class="o">&amp;</span><span class="n">gt</span><span class="p">;</span> <span class="n">max_len_test</span><span class="p">:</span>
<span class="w">        </span><span class="n">max_len_test</span> <span class="o">=</span> <span class="n">len_i</span>
<span class="w"> </span>
<span class="n">max_len_train</span><span class="p">,</span> <span class="n">max_len_val</span><span class="p">,</span> <span class="n">max_len_test</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>(142, 139, 167)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>As√≠ que definimos la secuencia m√°xima en general como 130 para la tokenizaci√≥n</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>A nosotros nos interesa el dataset tokenizado, no las secuencias en crudo, as√≠ que creamos un tokenizador</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Creamos una funci√≥n de tokenizaci√≥n</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Y ahora tokenizamos el dataset</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Map:   0%|          | 0/45000 [00:00&amp;lt;?, ? examples/s]
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Map:   0%|          | 0/5000 [00:00&amp;lt;?, ? examples/s]
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Map:   0%|          | 0/50000 [00:00&amp;lt;?, ? examples/s]
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Como vemos, ahora tenemos los tokens (<code>input_ids</code>) y las m√°scaras de atenci√≥n (<code>attention_mask</code>), pero vamos a ver qu√© tipo de datos tenemos</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">type</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]),</span> <span class="nb">type</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]),</span> <span class="nb">type</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;label&quot;</span><span class="p">])</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>(list, list, int)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="nb">type</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;label&quot;</span><span class="p">]),</span> <span class="nb">type</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]),</span> <span class="nb">type</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">])</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>(torch.Tensor, torch.Tensor, torch.Tensor)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Creamos un DataLoader</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="n">BS</span> <span class="o">=</span> <span class="mi">64</span>
<span class="w"> </span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Cargamos el modelo</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vamos a ver c√≥mo es el modelo</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">model</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>RobertaForSequenceClassification(
&#x20;&#x20;(roberta): RobertaModel(
&#x20;&#x20;&#x20;&#x20;(embeddings): RobertaEmbeddings(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(word_embeddings): Embedding(50265, 768, padding_idx=1)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(position_embeddings): Embedding(514, 768, padding_idx=1)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(token_type_embeddings): Embedding(1, 768)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(dropout): Dropout(p=0.1, inplace=False)
&#x20;&#x20;&#x20;&#x20;)
&#x20;&#x20;&#x20;&#x20;(encoder): RobertaEncoder(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(layer): ModuleList(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(0-11): 12 x RobertaLayer(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(attention): RobertaAttention(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(self): RobertaSelfAttention(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(query): Linear(in_features=768, out_features=768, bias=True)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(key): Linear(in_features=768, out_features=768, bias=True)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(value): Linear(in_features=768, out_features=768, bias=True)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(dropout): Dropout(p=0.1, inplace=False)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(output): RobertaSelfOutput(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(dense): Linear(in_features=768, out_features=768, bias=True)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(dropout): Dropout(p=0.1, inplace=False)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(intermediate): RobertaIntermediate(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(dense): Linear(in_features=768, out_features=3072, bias=True)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(intermediate_act_fn): GELUActivation()
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(output): RobertaOutput(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(dense): Linear(in_features=3072, out_features=768, bias=True)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(dropout): Dropout(p=0.1, inplace=False)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)
&#x20;&#x20;&#x20;&#x20;)
&#x20;&#x20;)
&#x20;&#x20;(classifier): RobertaClassificationHead(
&#x20;&#x20;&#x20;&#x20;(dense): Linear(in_features=768, out_features=768, bias=True)
&#x20;&#x20;&#x20;&#x20;(dropout): Dropout(p=0.1, inplace=False)
&#x20;&#x20;&#x20;&#x20;(out_proj): Linear(in_features=768, out_features=2, bias=True)
&#x20;&#x20;)
)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vamos a ver su √∫ltima capa</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Linear(in_features=768, out_features=2, bias=True)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">out_features</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>(768, 2)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Hemos visto que nuestro dataset tiene 20 clases, pero este modelo est√° entrenado para 2 clases, as√≠ que tenemos que modificar la √∫ltima capa</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Linear(in_features=768, out_features=20, bias=True)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Ahora s√≠</p>
</section>
<section class="section-block-markdown-cell">
<p>Ahora creamos una funci√≥n de loss</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Un optimizador</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
<span class="w"> </span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Y por √∫ltimo, una m√©trica</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="w"> </span>
<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vamos a comprobar que est√° todo bien con una muestra</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">sample</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]))</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">sample</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>(torch.Size([64, 130]), torch.Size([64, 130]))
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Ahora esa muestra se la metemos al modelo</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
<span class="n">ouputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">),</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">))</span>
<span class="n">ouputs</span><span class="o">.</span><span class="n">logits</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>torch.Size([64, 20])
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vemos que el modelo saca 64 batches, lo cual est√° bien, porque configuramos <code>BS = 20</code> y cada una con 20 salidas, lo cual est√° bien porque cambiamos el modelo para que tenga la salida de 20 valores</p>
</section>
<section class="section-block-markdown-cell">
<p>Obtenemos la de mayor valor</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">ouputs</span><span class="o">.</span><span class="n">logits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">predictions</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>torch.Size([64])
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Obtenemos la loss</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">ouputs</span><span class="o">.</span><span class="n">logits</span><span class="p">,</span> <span class="n">sample</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">))</span>
<span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>2.9990389347076416
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Y el accuracy</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">])[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]</span>
<span class="n">accuracy</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>0.015625
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Ya podemos crear un peque√±o bucle de entrenamiento</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">fastprogress.fastprogress</span><span class="w"> </span><span class="kn">import</span> <span class="n">master_bar</span><span class="p">,</span> <span class="n">progress_bar</span>
<span class="w"> </span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">master_progress_bar</span> <span class="o">=</span> <span class="n">master_bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">master_progress_bar</span><span class="p">:</span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
<span class="w">        </span><span class="n">master_progress_bar</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s1">&#39;</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="w">    </span>
<span class="w">    </span><span class="n">master_progress_bar</span><span class="o">.</span><span class="n">main_bar</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Validation accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&amp;lt;IPython.core.display.HTML object&amp;gt;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&amp;lt;IPython.core.display.HTML object&amp;gt;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h4 id="Script con el codigo base">Script con el c√≥digo base<a class="anchor-link" href="#Script con el codigo base">¬∂</a></h4>
</section>
<section class="section-block-markdown-cell">
<p>En la mayor√≠a de la documentaci√≥n de <code>accelerate</code> se explica c√≥mo usar <code>accelerate</code> con scripts, as√≠ que de momento vamos a hacerlo as√≠ y al final explicaremos c√≥mo hacerlo con un notebook</p>
</section>
<section class="section-block-markdown-cell">
<p>Primero vamos a crear una carpeta en la que vamos a guardar los scripts</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="err">!</span><span class="n">mkdir</span> <span class="n">accelerate_scripts</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Ahora escribimos el c√≥digo base en un script</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">01</span><span class="n">_code_base</span><span class="o">.</span><span class="n">py</span>
<span class="w"> </span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">fastprogress.fastprogress</span><span class="w"> </span><span class="kn">import</span> <span class="n">master_bar</span><span class="p">,</span> <span class="n">progress_bar</span>
<span class="w"> </span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="p">}</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="w"> </span>
<span class="n">BS</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="p">}</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">master_progress_bar</span> <span class="o">=</span> <span class="n">master_bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">master_progress_bar</span><span class="p">:</span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
<span class="w">        </span><span class="n">master_progress_bar</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s1">&#39;</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="w">    </span>
<span class="w">    </span><span class="n">master_progress_bar</span><span class="o">.</span><span class="n">main_bar</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Validation accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Overwriting accelerate_scripts/01_code_base.py
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Y ahora lo ejecutamos</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="w"> </span>
<span class="err">!</span><span class="n">python</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">01</span><span class="n">_code_base</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Accuracy = 0.2112                                                               
CPU times: user 2.12 s, sys: 391 ms, total: 2.51 s
Wall time: 3min 36s
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vemos que en mi ordenador ha tardado unos 3 minutos y medio</p>
</section>
<section class="section-block-markdown-cell">
<h4 id="Codigo con accelerate">C√≥digo con accelerate<a class="anchor-link" href="#Codigo con accelerate">¬∂</a></h4>
</section>
<section class="section-block-markdown-cell">
<p>Ahora reemplazamos algunas cosas</p>
<ul>
  <li>En primer lugar importamos <code>Accelerator</code> y lo inicializamos</li>
</ul>
<section class="section-block-markdown-cell">
      <div class='highlight'><pre><code class="language-python">from accelerate import Accelerator<br>accelerator = Accelerator()</code></pre></div>
      </section>
<ul>
  <li>Ya no hacemos el t√≠pico</li>
</ul>
<p>``` python</p>
<p>torch.device("cuda" if torch.cuda.is_available() else "cpu")</p>
<p>```</p>
<ul>
  <li>Sino que dejamos que sea <code>acelerate</code> el que elija el dispositivo mediante</li>
</ul>
<div class='highlight'><pre><code class="language-python">device = accelerator.device
</code></pre></div>
<ul>
  <li>Pasamos los elementos relevantes para el entrenamiento por el m√©todo <code>prepare</code> y ya no hacemos <code>model.to(device)</code></li>
</ul>
<div class='highlight'><pre><code class="language-python">model, optimizer, dataloader["train"], dataloader["validation"] = preprare(model, optimizer, dataloader["train"], dataloader["validation"])
</code></pre></div>
<ul>
  <li>Ya no mandamos los datos y el modelo a la GPU con <code>.to(device)</code> ya que <code>accelerate</code> se ha encargado de ello con el m√©todo <code>prepare</code></li>
</ul>
<ul>
  <li>En vez de hacer el backpropagation con <code>loss.backward()</code> dejamos que lo haga <code>accelerate</code> con</li>
</ul>
<div class='highlight'><pre><code class="language-python">accelerator.backward(loss)
</code></pre></div>
<ul>
  <li>A la hora de calcular la m√©trica en el bucle de validaci√≥n, necesitamos recopilar los valores de todos los puntos, en caso de estar haciendo un entrenamiento distribuido, para ello hacemos</li>
</ul>
<div class='highlight'><pre><code class="language-python">predictions = accelerator.gather_for_metrics(predictions)
</code></pre></div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">02</span><span class="n">_accelerate_base_code</span><span class="o">.</span><span class="n">py</span>
<span class="w"> </span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">fastprogress.fastprogress</span><span class="w"> </span><span class="kn">import</span> <span class="n">master_bar</span><span class="p">,</span> <span class="n">progress_bar</span>
<span class="w"> </span>
<span class="c1"># Importamos e inicializamos Accelerator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>
<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>
<span class="w"> </span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="p">}</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="w"> </span>
<span class="n">BS</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="p">}</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>
<span class="w"> </span>
<span class="c1"># model.to(device)</span>
<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>
<span class="w"> </span>
<span class="n">master_progress_bar</span> <span class="o">=</span> <span class="n">master_bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">master_progress_bar</span><span class="p">:</span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
<span class="w">        </span><span class="n">master_progress_bar</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s1">&#39;</span>
<span class="w"> </span>
<span class="w">        </span><span class="c1"># loss.backward()</span>
<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;End of training epoch </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">, outputs[&#39;logits&#39;].shape: </span><span class="si">{</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, labels.shape: </span><span class="si">{</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;End of validation epoch </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">, outputs[&#39;logits&#39;].shape: </span><span class="si">{</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, labels.shape: </span><span class="si">{</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="w">    </span>
<span class="w">    </span><span class="n">master_progress_bar</span><span class="o">.</span><span class="n">main_bar</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Validation accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
<span class="w"> </span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Overwriting accelerate_scripts/02_accelerate_base_code.py
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Si te fijas, he a√±adido estas dos l√≠neas <code>print(f&quot;End of training epoch {i}, outputs[&#x27;logits&#x27;].shape: {outputs[&#x27;logits&#x27;].shape}, labels.shape: {labels.shape}&quot;)</code> y la l√≠nea <code>print(f&quot;End of validation epoch {i}, outputs[&#x27;logits&#x27;].shape: {outputs[&#x27;logits&#x27;].shape}, labels.shape: {labels.shape}&quot;)</code>, las he a√±adido a prop√≥sito porque nos van a revelar algo muy importante</p>
</section>
<section class="section-block-markdown-cell">
<p>Ahora lo ejecutamos, para ejecutar los scripts de <code>accelerate</code> se hace con el comando <code>accelerate launch</code></p>
<div class='highlight'><pre><code class="language-bash">accelerate launch script.py
</code></pre></div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="w"> </span>
<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">02</span><span class="n">_accelerate_base_code</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>End of training epoch 0, outputs[&#x27;logits&#x27;].shape: torch.Size([64, 20]), labels.shape: torch.Size([64])
End of training epoch 0, outputs[&#x27;logits&#x27;].shape: torch.Size([64, 20]), labels.shape: torch.Size([64])
End of validation epoch 0, outputs[&#x27;logits&#x27;].shape: torch.Size([64, 20]), labels.shape: torch.Size([8])
Accuracy = 0.206
End of validation epoch 0, outputs[&#x27;logits&#x27;].shape: torch.Size([64, 20]), labels.shape: torch.Size([8])
Accuracy = 0.206
CPU times: user 1.6 s, sys: 272 ms, total: 1.88 s
Wall time: 2min 37s
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vemos que antes tard√≥ unos 3 minutos y medio y ahora tarda m√°s o menos 2 minutos y medio. Bastante mejora. Adem√°s, si vemos los <code>print</code>s, podemos ver que se han impreso dos veces.</p>
<p>¬øY esto c√≥mo puede ser? Pues porque <code>accelerate</code> ha paralelizado el entrenamiento en las dos GPUs que tengo, por lo que ha sido mucho m√°s r√°pido.</p>
<p>Adem√°s, cuando ejecut√© el primer script, es decir, cuando no us√© <code>accelerate</code>, la GPU estaba casi llena, mientras que cuando he ejecutado el segundo, es decir, el que usa <code>accelerate</code>, las dos GPUs estaban muy poco utilizadas, por lo que podemos aumentar el batch size para intentar llenar las dos, vamos a ello!</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">03</span><span class="n">_accelerate_base_code_more_bs</span><span class="o">.</span><span class="n">py</span>
<span class="w"> </span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">fastprogress.fastprogress</span><span class="w"> </span><span class="kn">import</span> <span class="n">master_bar</span><span class="p">,</span> <span class="n">progress_bar</span>
<span class="w"> </span>
<span class="c1"># Importamos e inicializamos Accelerator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>
<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>
<span class="w"> </span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="p">}</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="w"> </span>
<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="p">}</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>
<span class="w"> </span>
<span class="c1"># model.to(device)</span>
<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>
<span class="w"> </span>
<span class="n">master_progress_bar</span> <span class="o">=</span> <span class="n">master_bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">master_progress_bar</span><span class="p">:</span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
<span class="w">        </span><span class="n">master_progress_bar</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s1">&#39;</span>
<span class="w"> </span>
<span class="w">        </span><span class="c1"># loss.backward()</span>
<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="w">    </span>
<span class="w">    </span><span class="n">master_progress_bar</span><span class="o">.</span><span class="n">main_bar</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Validation accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
<span class="w"> </span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Overwriting accelerate_scripts/03_accelerate_base_code_more_bs.py
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>He quitado los prints extra, porque ya hemos visto que el c√≥digo se est√° ejecutando en las dos GPUs y he aumentado el batch size de 64 a 128. Lo ejecutamos a ver</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="w"> </span>
<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">03</span><span class="n">_accelerate_base_code_more_bs</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Accuracy = 0.1052                                                               
Accuracy = 0.1052
CPU times: user 1.41 s, sys: 180 ms, total: 1.59 s
Wall time: 2min 22s
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Aumentando el batch size ha bajado unos segundos el tiempo de ejecuci√≥n</p>
</section>
<section class="section-block-markdown-cell">
<h3 id="Ejecucion de procesos">Ejecuci√≥n de procesos<a class="anchor-link" href="#Ejecucion de procesos">¬∂</a></h3>
</section>
<section class="section-block-markdown-cell">
<h4 id="Ejecucion de codigo en un unico proceso">Ejecuci√≥n de c√≥digo en un √∫nico proceso<a class="anchor-link" href="#Ejecucion de codigo en un unico proceso">¬∂</a></h4>
</section>
<section class="section-block-markdown-cell">
<p>Antes hemos visto que los <code>print</code>s se imprim√≠an dos veces, esto es porque <code>accelerate</code> crea tantos procesos como dispositivos donde se ejecuta el c√≥digo, en mi caso crea dos procesos por tener dos GPUs.</p>
<p>Sin embargo, no todo el c√≥digo deber√≠a ejecutarse en todos los procesos, por ejemplo, los <code>print</code>s, ralentizan mucho el c√≥digo, como para ejecutarlo varias veces, si se guardan los checkpoints, se guardar√≠an dos veces, etc.</p>
<p>Para poder ejecutar parte de un c√≥digo en un √∫nico proceso, se tiene que encapsular en una funci√≥n y decorarla con <code>accelerator.on_local_main_process</code>. Por ejemplo, en el siguiente c√≥digo vas a ver que he creado la siguiente funci√≥n</p>
<section class="section-block-markdown-cell">
      <div class='highlight'><pre><code class="language-python">@accelerator.on_local_main_process<br>def print_something(something):<br>&#x20;&#x20;print(something)</code></pre></div>
      </section>
<p>Otra opci√≥n es incluir el c√≥digo dentro de un <code>if accelerator.is_local_main_process</code> como en el siguiente c√≥digo</p>
<section class="section-block-markdown-cell">
      <div class='highlight'><pre><code class="language-python">if accelerator.is_local_main_process:<br>&#x20;&#x20;print("Something")</code></pre></div>
      </section>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">04</span><span class="n">_accelerate_base_code_some_code_in_one_process</span><span class="o">.</span><span class="n">py</span>
<span class="w"> </span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">fastprogress.fastprogress</span><span class="w"> </span><span class="kn">import</span> <span class="n">master_bar</span><span class="p">,</span> <span class="n">progress_bar</span>
<span class="w"> </span>
<span class="c1"># Importamos e inicializamos Accelerator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>
<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>
<span class="w"> </span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="p">}</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="w"> </span>
<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="p">}</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>
<span class="w"> </span>
<span class="c1"># model.to(device)</span>
<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>
<span class="w"> </span>
<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>
<span class="k">def</span><span class="w"> </span><span class="nf">print_something</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">master_progress_bar</span> <span class="o">=</span> <span class="n">master_bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">master_progress_bar</span><span class="p">:</span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
<span class="w">        </span><span class="n">master_progress_bar</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s1">&#39;</span>
<span class="w"> </span>
<span class="w">        </span><span class="c1"># loss.backward()</span>
<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">parent</span><span class="o">=</span><span class="n">master_progress_bar</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="w">    </span>
<span class="w">    </span><span class="n">master_progress_bar</span><span class="o">.</span><span class="n">main_bar</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Validation accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
<span class="w"> </span>
<span class="c1"># print(f&quot;Accuracy = {accuracy[&#39;accuracy&#39;]}&quot;)</span>
<span class="n">print_something</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">:</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Overwriting accelerate_scripts/04_accelerate_base_code_some_code_in_one_process.py
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vamos a ejecutarlo a ver</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="w"> </span>
<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">04</span><span class="n">_accelerate_base_code_some_code_in_one_process</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Accuracy = 0.2098                                                               
End of script with 0.2098 accuracy
CPU times: user 1.38 s, sys: 197 ms, total: 1.58 s
Wall time: 2min 22s
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Ahora solo se ha impreso el print una vez</p>
</section>
<section class="section-block-markdown-cell">
<p>Sin embargo, aunque no se ve mucho, las barras de progreso se ejecutan en cada proceso.</p>
<p>No he encontrado una manera de evitar esto con las barras de progreso de <code>fastprogress</code>, pero s√≠ con las de <code>tqdm</code>, as√≠ que voy a sustituir las barras de progreso de <code>fastprogress</code> por las de <code>tqdm</code> y para que se ejecuten en un √∫nico proceso hay que a√±adirle el argumento <code>disable=not accelerator.is_local_main_process</code></p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">05</span><span class="n">_accelerate_base_code_some_code_in_one_process</span><span class="o">.</span><span class="n">py</span>
<span class="w"> </span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tqdm</span>
<span class="w"> </span>
<span class="c1"># Importamos e inicializamos Accelerator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>
<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>
<span class="w"> </span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="p">}</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="w"> </span>
<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="p">}</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>
<span class="w"> </span>
<span class="c1"># model.to(device)</span>
<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>
<span class="w"> </span>
<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>
<span class="k">def</span><span class="w"> </span><span class="nf">print_something</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="w">    </span><span class="c1"># progress_bar_train = progress_bar(dataloader[&quot;train&quot;], parent=master_progress_bar)</span>
<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
<span class="w">        </span><span class="c1"># master_progress_bar.child.comment = f&#39;loss: {loss}&#39;</span>
<span class="w"> </span>
<span class="w">        </span><span class="c1"># loss.backward()</span>
<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="w">    </span><span class="c1"># progress_bar_validation = progress_bar(dataloader[&quot;validation&quot;], parent=master_progress_bar)</span>
<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="w">    </span>
<span class="c1"># print(f&quot;Accuracy = {accuracy[&#39;accuracy&#39;]}&quot;)</span>
<span class="n">print_something</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">:</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Overwriting accelerate_scripts/05_accelerate_base_code_some_code_in_one_process.py
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="w"> </span>
<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">05</span><span class="n">_accelerate_base_code_some_code_in_one_process</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 176/176 [02:01&amp;lt;00:00,  1.45it/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:06&amp;lt;00:00,  3.30it/s]
Accuracy = 0.2166
End of script with 0.2166 accuracy
CPU times: user 1.33 s, sys: 195 ms, total: 1.52 s
Wall time: 2min 22s
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Hemos mostrado un ejemplo de c√≥mo imprimir en un solo proceso, y esto ha sido una manera de ejecutar procesos en un solo proceso. Pero si lo que quieres es solo imprimir en un solo proceso, se puede usar el m√©todo <code>print</code> de <code>accelerate</code>. Vamos a ver el mismo ejemplo de antes con este m√©todo</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">06</span><span class="n">_accelerate_base_code_print_one_process</span><span class="o">.</span><span class="n">py</span>
<span class="w"> </span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tqdm</span>
<span class="w"> </span>
<span class="c1"># Importamos e inicializamos Accelerator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>
<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>
<span class="w"> </span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="p">}</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="w"> </span>
<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="p">}</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>
<span class="w"> </span>
<span class="c1"># model.to(device)</span>
<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>
<span class="w"> </span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="w">    </span><span class="c1"># progress_bar_train = progress_bar(dataloader[&quot;train&quot;], parent=master_progress_bar)</span>
<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
<span class="w">        </span><span class="c1"># master_progress_bar.child.comment = f&#39;loss: {loss}&#39;</span>
<span class="w"> </span>
<span class="w">        </span><span class="c1"># loss.backward()</span>
<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="w">    </span><span class="c1"># progress_bar_validation = progress_bar(dataloader[&quot;validation&quot;], parent=master_progress_bar)</span>
<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="w">    </span>
<span class="c1"># print(f&quot;Accuracy = {accuracy[&#39;accuracy&#39;]}&quot;)</span>
<span class="n">accelerator</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">:</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Writing accelerate_scripts/06_accelerate_base_code_print_one_process.py
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Lo ejecutamos</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="w"> </span>
<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">06</span><span class="n">_accelerate_base_code_print_one_process</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 45000/45000 [00:02&amp;lt;00:00, 15433.52 examples/s]
Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [00:00&amp;lt;00:00, 11406.61 examples/s]
Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 45000/45000 [00:02&amp;lt;00:00, 15036.87 examples/s]
Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50000/50000 [00:03&amp;lt;00:00, 14932.76 examples/s]
Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50000/50000 [00:03&amp;lt;00:00, 14956.60 examples/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 176/176 [02:00&amp;lt;00:00,  1.46it/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05&amp;lt;00:00,  3.33it/s]
Accuracy = 0.2134
End of script with 0.2134 accuracy
CPU times: user 1.4 s, sys: 189 ms, total: 1.59 s
Wall time: 2min 27s
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h4 id="Ejecucion de codigo en todos los procesos">Ejecuci√≥n de c√≥digo en todos los procesos<a class="anchor-link" href="#Ejecucion de codigo en todos los procesos">¬∂</a></h4>
</section>
<section class="section-block-markdown-cell">
<p>Sin embargo, hay c√≥digo que debe ejecutarse en todos los procesos, por ejemplo, si subimos los checkpoints al hub, as√≠ que aqu√≠ tenemos dos opciones: encapsular el c√≥digo en una funci√≥n y decorarla con <code>accelerator.on_main_process</code></p>
<section class="section-block-markdown-cell">
      <div class='highlight'><pre><code class="language-python">@accelerator.on_main_process<br>def do_my_thing():<br>&#x20;&#x20;"Something done once per server"<br>&#x20;&#x20;do_thing_once()</code></pre></div>
      </section>
<p>o meter el c√≥digo dentro de un <code>if accelerator.is_main_process</code></p>
<section class="section-block-markdown-cell">
      <div class='highlight'><pre><code class="language-python">if accelerator.is_main_process:<br>&#x20;&#x20;repo.push_to_hub()</code></pre></div>
      </section>
</section>
<section class="section-block-markdown-cell">
<p>Como estamos haciendo entrenamientos solo para mostrar la librer√≠a <code>accelerate</code> y el modelo que estamos entrenando no es bueno, no tiene sentido ahora subir los checkpoints al hub, as√≠ que voy a hacer un ejemplo con <code>print</code>s</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">07</span><span class="n">_accelerate_base_code_some_code_in_all_process</span><span class="o">.</span><span class="n">py</span>
<span class="w"> </span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tqdm</span>
<span class="w"> </span>
<span class="c1"># Importamos e inicializamos Accelerator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>
<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>
<span class="w"> </span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="p">}</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="w"> </span>
<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="p">}</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>
<span class="w"> </span>
<span class="c1"># model.to(device)</span>
<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>
<span class="w"> </span>
<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>
<span class="k">def</span><span class="w"> </span><span class="nf">print_in_one_process</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>
<span class="w"> </span>
<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_main_process</span>
<span class="k">def</span><span class="w"> </span><span class="nf">print_in_all_processes</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="c1"># loss.backward()</span>
<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="w">    </span>
<span class="n">print_in_one_process</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">:</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">print_in_all_processes</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;All process: Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">:</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;All process: End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Overwriting accelerate_scripts/06_accelerate_base_code_some_code_in_all_process.py
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Lo ejecutamos a ver</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="w"> </span>
<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">07</span><span class="n">_accelerate_base_code_some_code_in_all_process</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 45000/45000 [00:03&amp;lt;00:00, 14518.44 examples/s]
Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 45000/45000 [00:03&amp;lt;00:00, 14368.77 examples/s]
Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [00:00&amp;lt;00:00, 16466.33 examples/s]
Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [00:00&amp;lt;00:00, 14806.14 examples/s]
Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50000/50000 [00:03&amp;lt;00:00, 14253.33 examples/s]
Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50000/50000 [00:03&amp;lt;00:00, 14337.07 examples/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 176/176 [02:00&amp;lt;00:00,  1.46it/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05&amp;lt;00:00,  3.34it/s]
Accuracy = 0.2092
End of script with 0.2092 accuracy
All process: Accuracy = 0.2092
All process: End of script with 0.2092 accuracy
CPU times: user 1.42 s, sys: 216 ms, total: 1.64 s
Wall time: 2min 27s
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h4 id="Ejecucion de codigo en el proceso X">Ejecuci√≥n de c√≥digo en el proceso X<a class="anchor-link" href="#Ejecucion de codigo en el proceso X">¬∂</a></h4>
</section>
<section class="section-block-markdown-cell">
<p>Por √∫ltimo podemos especificar en qu√© proceso queremos ejecutar c√≥digo, para esto hay que crear una funci√≥n y decorarla con <code>@accelerator.on_process(process_index=0)</code></p>
<section class="section-block-markdown-cell">
      <div class='highlight'><pre><code class="language-python">@accelerator.on_process(process_index=0)<br>def do_my_thing():<br>&#x20;&#x20;"Something done on process index 0"<br>&#x20;&#x20;do_thing_on_index_zero()</code></pre></div>
      </section>
<p>o decorarla con <code>@accelerator.on_local_process(local_process_idx=0)</code></p>
<section class="section-block-markdown-cell">
      <div class='highlight'><pre><code class="language-python">@accelerator.on_local_process(local_process_index=0)<br>def do_my_thing():<br>&#x20;&#x20;"Something done on process index 0 on each server"<br>&#x20;&#x20;do_thing_on_index_zero_on_each_server()</code></pre></div>
      </section>
<p>Aqu√≠ he puesto el proceso 0, pero se puede poner cualquier n√∫mero</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">08</span><span class="n">_accelerate_base_code_some_code_in_some_process</span><span class="o">.</span><span class="n">py</span>
<span class="w"> </span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tqdm</span>
<span class="w"> </span>
<span class="c1"># Importamos e inicializamos Accelerator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>
<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>
<span class="w"> </span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="p">}</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="w"> </span>
<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="p">}</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>
<span class="w"> </span>
<span class="c1"># model.to(device)</span>
<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>
<span class="w"> </span>
<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>
<span class="k">def</span><span class="w"> </span><span class="nf">print_in_one_process</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>
<span class="w"> </span>
<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_main_process</span>
<span class="k">def</span><span class="w"> </span><span class="nf">print_in_all_processes</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>
<span class="w"> </span>
<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_process</span><span class="p">(</span><span class="n">process_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">print_in_process_0</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Process 0: &quot;</span> <span class="o">+</span> <span class="n">something</span><span class="p">)</span>
<span class="w"> </span>
<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_process</span><span class="p">(</span><span class="n">local_process_index</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">print_in_process_1</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Process 1: &quot;</span> <span class="o">+</span> <span class="n">something</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="c1"># loss.backward()</span>
<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="w">    </span>
<span class="n">print_in_one_process</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">:</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">print_in_all_processes</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;All process: Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">:</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;All process: End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">print_in_process_0</span><span class="p">(</span><span class="s2">&quot;End of process 0&quot;</span><span class="p">)</span>
<span class="n">print_in_process_1</span><span class="p">(</span><span class="s2">&quot;End of process 1&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Overwriting accelerate_scripts/07_accelerate_base_code_some_code_in_some_process.py
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Lo ejecutamos</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="w"> </span>
<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">08</span><span class="n">_accelerate_base_code_some_code_in_some_process</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [00:00&amp;lt;00:00, 15735.58 examples/s]
Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50000/50000 [00:03&amp;lt;00:00, 14906.20 examples/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 176/176 [02:02&amp;lt;00:00,  1.44it/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:06&amp;lt;00:00,  3.27it/s]
Process 1: End of process 1
Accuracy = 0.2128
End of script with 0.2128 accuracy
All process: Accuracy = 0.2128
All process: End of script with 0.2128 accuracy
Process 0: End of process 0
CPU times: user 1.42 s, sys: 295 ms, total: 1.71 s
Wall time: 2min 37s
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h4 id="Sincronizar procesos">Sincronizar procesos<a class="anchor-link" href="#Sincronizar procesos">¬∂</a></h4>
</section>
<section class="section-block-markdown-cell">
<p>Si tenemos c√≥digo que debe ejecutarse en todos los procesos, es interesante esperar a que termine en todos los procesos antes de hacer otra tarea, as√≠ que para ello usamos <code>accelerator.wait_for_everyone()</code></p>
<p>Para verlo, vamos a meter un retraso en una de las funciones de imprimir en un proceso</p>
<p>Adem√°s he puesto un break en el bucle de entrenamiento para que no est√© mucho tiempo entrenando, que no es lo que ahora nos interesa</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">09</span><span class="n">_accelerate_base_code_sync_all_process</span><span class="o">.</span><span class="n">py</span>
<span class="w"> </span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tqdm</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="w"> </span>
<span class="c1"># Importamos e inicializamos Accelerator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>
<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>
<span class="w"> </span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="p">}</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="w"> </span>
<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="p">}</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>
<span class="w"> </span>
<span class="c1"># model.to(device)</span>
<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>
<span class="w"> </span>
<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>
<span class="k">def</span><span class="w"> </span><span class="nf">print_in_one_process</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>
<span class="w"> </span>
<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_main_process</span>
<span class="k">def</span><span class="w"> </span><span class="nf">print_in_all_processes</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>
<span class="w"> </span>
<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_process</span><span class="p">(</span><span class="n">process_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">print_in_process_0</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>
<span class="w">    </span><span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Process 0: &quot;</span> <span class="o">+</span> <span class="n">something</span><span class="p">)</span>
<span class="w"> </span>
<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_process</span><span class="p">(</span><span class="n">local_process_index</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">print_in_process_1</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Process 1: &quot;</span> <span class="o">+</span> <span class="n">something</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="c1"># loss.backward()</span>
<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="w">        </span><span class="k">break</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="w">    </span>
<span class="n">print_in_one_process</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">:</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">print_in_all_processes</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;All process: Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">:</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;All process: End of script with </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">print_in_one_process</span><span class="p">(</span><span class="s2">&quot;Printing with delay in process 0&quot;</span><span class="p">)</span>
<span class="n">print_in_process_0</span><span class="p">(</span><span class="s2">&quot;End of process 0&quot;</span><span class="p">)</span>
<span class="n">print_in_process_1</span><span class="p">(</span><span class="s2">&quot;End of process 1&quot;</span><span class="p">)</span>
<span class="n">accelerator</span><span class="o">.</span><span class="n">wait_for_everyone</span><span class="p">()</span>
<span class="w"> </span>
<span class="n">print_in_one_process</span><span class="p">(</span><span class="s2">&quot;End of script&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Overwriting accelerate_scripts/08_accelerate_base_code_sync_all_process.py
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Lo ejecutamos</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">09</span><span class="n">_accelerate_base_code_sync_all_process</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [00:00&amp;lt;00:00, 14218.23 examples/s]
Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [00:00&amp;lt;00:00, 14666.25 examples/s]
&#x20;&#x20;0%|                                                   | 0/176 [00:00&amp;lt;?, ?it/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05&amp;lt;00:00,  3.58it/s]
Process 1: End of process 1
Accuracy = 0.212
End of script with 0.212 accuracy
All process: Accuracy = 0.212
All process: End of script with 0.212 accuracy
Printing with delay in process 0
Process 0: End of process 0
End of script
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Como se puede ver primero se ha impreso <code>Process 1: End of process 1</code> y luego el resto, esto es porque el resto de prints se hacen o en el proceso 0 o en todos los procesos, as√≠ que hasta que no termine el delay de 2 segundos que hemos puesto no se ejecuta el resto de c√≥digo</p>
</section>
<section class="section-block-markdown-cell">
<h3 id="Guardar y cargar el state dict">Guardar y cargar el state dict<a class="anchor-link" href="#Guardar y cargar el state dict">¬∂</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Cuando entrenamos, a veces guardamos el estado para poder seguir en otro momento</p>
<p>Para guardar el estado tendremos que usar los m√©todos <code>save_state()</code> y <code>load_state()</code></p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">10</span><span class="n">_accelerate_save_and_load_checkpoints</span><span class="o">.</span><span class="n">py</span>
<span class="w"> </span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tqdm</span>
<span class="w"> </span>
<span class="c1"># Importamos e inicializamos Accelerator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>
<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>
<span class="w"> </span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="p">}</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="w"> </span>
<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="p">}</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>
<span class="k">def</span><span class="w"> </span><span class="nf">print_something</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>
<span class="w"> </span>
<span class="c1"># model.to(device)</span>
<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>
<span class="w"> </span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="c1"># loss.backward()</span>
<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">    </span><span class="c1"># Guardamos los pesos</span>
<span class="w">    </span><span class="n">accelerator</span><span class="o">.</span><span class="n">save_state</span><span class="p">(</span><span class="s2">&quot;accelerate_scripts/checkpoints&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">print_something</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="c1"># Cargamos los pesos</span>
<span class="n">accelerator</span><span class="o">.</span><span class="n">load_state</span><span class="p">(</span><span class="s2">&quot;accelerate_scripts/checkpoints&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Overwriting accelerate_scripts/09_accelerate_save_and_load_checkpoints.py
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Lo ejecutamos</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">10</span><span class="n">_accelerate_save_and_load_checkpoints</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 176/176 [01:58&amp;lt;00:00,  1.48it/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05&amp;lt;00:00,  3.40it/s]
Accuracy = 0.2142
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Guardar el modelo">Guardar el modelo<a class="anchor-link" href="#Guardar el modelo">¬∂</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Cuando se us√≥ el m√©todo <code>prepare</code> se envolvi√≥ el modelo para poder guardarlo en los dispositivos necesarios. Por lo que a la hora de guardarlo tenemos que usar el m√©todo <code>save_model</code> que primero lo desenvuelve y luego lo guarda. Adem√°s, si usamos el par√°metro <code>safe_serialization=True</code> se guardar√° el modelo como un <code>safe tensor</code></p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">11</span><span class="n">_accelerate_save_model</span><span class="o">.</span><span class="n">py</span>
<span class="w"> </span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tqdm</span>
<span class="w"> </span>
<span class="c1"># Importamos e inicializamos Accelerator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>
<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>
<span class="w"> </span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="p">}</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="w"> </span>
<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="p">}</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>
<span class="k">def</span><span class="w"> </span><span class="nf">print_something</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>
<span class="w"> </span>
<span class="c1"># model.to(device)</span>
<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>
<span class="w"> </span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="c1"># loss.backward()</span>
<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">    </span><span class="c1"># Guardamos el modelo</span>
<span class="w">    </span><span class="n">accelerator</span><span class="o">.</span><span class="n">wait_for_everyone</span><span class="p">()</span>
<span class="w">    </span><span class="n">accelerator</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;accelerate_scripts/model&quot;</span><span class="p">,</span> <span class="n">safe_serialization</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">print_something</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Writing accelerate_scripts/11_accelerate_save_model.py
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Lo ejecutamos</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">11</span><span class="n">_accelerate_save_model</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 176/176 [01:58&amp;lt;00:00,  1.48it/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05&amp;lt;00:00,  3.35it/s]
Accuracy = 0.214
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Guardar el modelo pretrained">Guardar el modelo <code>pretrained</code><a class="anchor-link" href="#Guardar el modelo pretrained">¬∂</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>En modelos que usan la librer√≠a <code>transformers</code> debemos guardar el modelo con el m√©todo <code>save_pretrained</code> para poder cargarlo con el m√©todo <code>from_pretrained</code>. Antes de guardarlo hay que desenvolverlo con el m√©todo <code>unwrap_model</code></p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">12</span><span class="n">_accelerate_save_pretrained</span><span class="o">.</span><span class="n">py</span>
<span class="w"> </span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tqdm</span>
<span class="w"> </span>
<span class="c1"># Importamos e inicializamos Accelerator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>
<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>
<span class="w"> </span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="p">}</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="w"> </span>
<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="p">}</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="nd">@accelerator</span><span class="o">.</span><span class="n">on_local_main_process</span>
<span class="k">def</span><span class="w"> </span><span class="nf">print_something</span><span class="p">(</span><span class="n">something</span><span class="p">):</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>
<span class="w"> </span>
<span class="c1"># model.to(device)</span>
<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>
<span class="w"> </span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="c1"># loss.backward()</span>
<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">    </span><span class="c1"># Guardamos el modelo pretrained</span>
<span class="w">    </span><span class="n">unwrapped_model</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">unwrap_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="w">    </span><span class="n">unwrapped_model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span>
<span class="w">        </span><span class="s2">&quot;accelerate_scripts/model_pretrained&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="n">is_main_process</span><span class="o">=</span><span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">,</span>
<span class="w">        </span><span class="n">save_function</span><span class="o">=</span><span class="n">accelerator</span><span class="o">.</span><span class="n">save</span><span class="p">,</span>
<span class="w">    </span><span class="p">)</span>
<span class="w"> </span>
<span class="n">print_something</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Writing accelerate_scripts/11_accelerate_save_pretrained.py
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Lo ejecutamos</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">12</span><span class="n">_accelerate_save_pretrained</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 45000/45000 [00:02&amp;lt;00:00, 15152.47 examples/s]
Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 45000/45000 [00:02&amp;lt;00:00, 15119.13 examples/s]
Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [00:00&amp;lt;00:00, 12724.70 examples/s]
Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [00:00&amp;lt;00:00, 12397.49 examples/s]
Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50000/50000 [00:03&amp;lt;00:00, 15247.21 examples/s]
Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50000/50000 [00:03&amp;lt;00:00, 15138.03 examples/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 176/176 [01:59&amp;lt;00:00,  1.48it/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05&amp;lt;00:00,  3.37it/s]
Accuracy = 0.21
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Ahora lo podr√≠amos cargar</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModel</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;accelerate_scripts/model_pretrained&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Some weights of RobertaModel were not initialized from the model checkpoint at accelerate_scripts/model_pretrained and are newly initialized: [&#x27;roberta.pooler.dense.bias&#x27;, &#x27;roberta.pooler.dense.weight&#x27;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Entrenamiento en notebooks">Entrenamiento en notebooks<a class="anchor-link" href="#Entrenamiento en notebooks">¬∂</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Hasta ahora hemos visto c√≥mo ejecutar scripts, pero si quieres ejecutar el c√≥digo en un notebook, podemos escribir el mismo c√≥digo de antes, pero encapsulado en una funci√≥n</p>
</section>
<section class="section-block-markdown-cell">
<p>Primero importamos las librer√≠as</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tqdm</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="c1"># from accelerate import Accelerator</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Ahora creamos la funci√≥n</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">train_code</span><span class="p">(</span><span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span><span class="p">):</span>
<span class="w">    </span><span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>
<span class="w">    </span><span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
<span class="w">    </span><span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>
<span class="w">    </span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">    </span><span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="w">        </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">        </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">        </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">        </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>
<span class="w">    </span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="w">    </span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">BS</span> <span class="o">=</span> <span class="n">batch_size</span>
<span class="w">    </span><span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">        </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">        </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">        </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="p">}</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="w">    </span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
<span class="w">    </span><span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>
<span class="w">    </span><span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>
<span class="w">    </span><span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>
<span class="w"> </span>
<span class="w">    </span><span class="c1"># model.to(device)</span>
<span class="w">    </span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>
<span class="w"> </span>
<span class="w">    </span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
<span class="w">        </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="w">        </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">        </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>
<span class="w">            </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">            </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">            </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">            </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">            </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">            </span><span class="c1"># loss.backward()</span>
<span class="w">            </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="w">            </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="w">        </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">        </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>
<span class="w">            </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">            </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">            </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">            </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="w">                </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">            </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="w">            </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>
<span class="w">            </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
<span class="w">            </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">            </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="w">        </span>
<span class="w">    </span><span class="n">accelerator</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Para poder ejecutar el entrenamiento en el notebook usamos la funci√≥n <code>notebook_launcher</code>, al que le pasamos la funci√≥n que queremos ejecutar, los argumentos de esa funci√≥n y el n√∫mero de GPUs en las que vamos a entrenar con la variable <code>num_processes</code></p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">notebook_launcher</span>
<span class="w"> </span>
<span class="n">args</span> <span class="o">=</span> <span class="p">(</span><span class="mi">128</span><span class="p">,)</span>
<span class="n">notebook_launcher</span><span class="p">(</span><span class="n">train_code</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">num_processes</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Launching training on 2 GPUs.
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 176/176 [02:01&amp;lt;00:00,  1.45it/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:06&amp;lt;00:00,  3.31it/s]
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Accuracy = 0.2112
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Entrenamiento en FP16">Entrenamiento en FP16<a class="anchor-link" href="#Entrenamiento en FP16">¬∂</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Cuando al principio configuramos <code>accelerate</code> nos pregunt√≥ <code>Do you wish to use FP16 or BF16 (mixed precision)?</code> y dijimos que no, as√≠ que ahora vamos a decirle que s√≠, que queremos en FP16</p>
</section>
<section class="section-block-markdown-cell">
<p>Hasta ahora hemos entrenado en FP32, lo que quiere decir que cada peso del modelo es un n√∫mero en coma flotante de 32 bits, y ahora vamos a usar un n√∫mero en coma flotante de 16 bits, es decir, el modelo va a ocupar menos. Por lo que van a pasar dos cosas, podremos usar un batch size mayor y adem√°s ser√° m√°s r√°pido</p>
</section>
<section class="section-block-markdown-cell">
<p>Primero volvemos a lanzar <code>accelerate config</code> y le vamos a decir que queremos FP16</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="err">!</span><span class="n">accelerate</span> <span class="n">config</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>--------------------------------------------------------------------------------
In which compute environment are you running?
This machine
--------------------------------------------------------------------------------
multi-GPU
How many different machines will you use (use more than 1 for multi-node training)? [1]: 1
Should distributed operations be checked while running for errors? This can avoid timeout issues but will be slower. [yes/NO]: no
Do you wish to optimize your script with torch dynamo?[yes/NO]:no
Do you want to use DeepSpeed? [yes/NO]: no
Do you want to use FullyShardedDataParallel? [yes/NO]: no
Do you want to use Megatron-LM ? [yes/NO]: no
How many GPU(s) should be used for distributed training? [1]:2
What GPU(s) (by id) should be used for training on this machine as a comma-seperated list? [all]:0,1
--------------------------------------------------------------------------------
Do you wish to use FP16 or BF16 (mixed precision)?
fp16
accelerate configuration saved at ~/.cache/huggingface/accelerate/default_config.yaml
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Ahora creamos un script para entrenar, con el mismo batch size de antes, para ver si tarda menos en entrenar</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">13</span><span class="n">_accelerate_base_code_fp16_bs128</span><span class="o">.</span><span class="n">py</span>
<span class="w"> </span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tqdm</span>
<span class="w"> </span>
<span class="c1"># Importamos e inicializamos Accelerator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>
<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>
<span class="w"> </span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="p">}</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="w"> </span>
<span class="n">BS</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="p">}</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>
<span class="w"> </span>
<span class="c1"># model.to(device)</span>
<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>
<span class="w"> </span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="c1"># loss.backward()</span>
<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="w">    </span>
<span class="n">accelerator</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Overwriting accelerate_scripts/12_accelerate_base_code_fp16_bs128.py
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Lo ejecutamos a ver cu√°nto tarda</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="w"> </span>
<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">13</span><span class="n">_accelerate_base_code_fp16_bs128</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [00:00&amp;lt;00:00, 14983.76 examples/s]
Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50000/50000 [00:03&amp;lt;00:00, 14315.47 examples/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 176/176 [01:01&amp;lt;00:00,  2.88it/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:02&amp;lt;00:00,  6.84it/s]
Accuracy = 0.2094
CPU times: user 812 ms, sys: 163 ms, total: 976 ms
Wall time: 1min 27s
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Cuando ejecutamos este entrenamiento en FP32 tard√≥ unos 2 minutos y medio, y ahora m√°s o menos 1 minuto y medio. Vamos a ver si ahora en vez de entrenar con un batch size de 128, lo hacemos con uno de 256</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">14</span><span class="n">_accelerate_base_code_fp16_bs256</span><span class="o">.</span><span class="n">py</span>
<span class="w"> </span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tqdm</span>
<span class="w"> </span>
<span class="c1"># Importamos e inicializamos Accelerator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>
<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>
<span class="w"> </span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="p">}</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="w"> </span>
<span class="n">BS</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="p">}</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>
<span class="w"> </span>
<span class="c1"># model.to(device)</span>
<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>
<span class="w"> </span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="c1"># loss.backward()</span>
<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="w">    </span>
<span class="n">accelerator</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Overwriting accelerate_scripts/13_accelerate_base_code_fp16_bs256.py
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Lo ejecutamos</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="w"> </span>
<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">14</span><span class="n">_accelerate_base_code_fp16_bs256</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [00:00&amp;lt;00:00, 15390.30 examples/s]
Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [00:00&amp;lt;00:00, 14990.92 examples/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 88/88 [00:54&amp;lt;00:00,  1.62it/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:02&amp;lt;00:00,  3.45it/s]
Accuracy = 0.2236
CPU times: user 670 ms, sys: 91.6 ms, total: 761 ms
Wall time: 1min 12s
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Ha bajado solo unos 15 segundos</p>
</section>
<section class="section-block-markdown-cell">
<h3 id="Entrenamiento en BF16">Entrenamiento en BF16<a class="anchor-link" href="#Entrenamiento en BF16">¬∂</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Antes hemos entrenado en FP16 y ahora lo vamos a hacer en BF16, ¬øCu√°l es la diferencia?</p>
<img src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/FP32_FP16_BF16.webp" alt="FP32_FP16_BF16">
<p>Como podemos ver en la imagen, mientras que FP16 en comparaci√≥n con FP32 tiene menos bits en la mantisa y el exponente, lo que hace que su rango sea mucho menor, BF16 en comparaci√≥n con FP32 tiene el mismo n√∫mero de bits del exponente pero menos en la mantisa, lo que hace que BF16 tenga el mismo rango de n√∫meros que FP32, pero es menos preciso</p>
<p>Esto es beneficioso porque en FP16 algunos c√°lculos podr√≠an dar n√∫meros muy altos, que en formato FP16 no se podr√≠an representar. Adem√°s hay ciertos dispositivos HW que est√°n optimizados para este formato</p>
</section>
<section class="section-block-markdown-cell">
<p>Al igual que antes, ejecutamos <code>accelerate config</code> y le indicamos que queremos BF16</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="err">!</span><span class="n">accelerate</span> <span class="n">config</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>--------------------------------------------------------------------------------
In which compute environment are you running?
This machine
--------------------------------------------------------------------------------
multi-GPU
How many different machines will you use (use more than 1 for multi-node training)? [1]: 1
Should distributed operations be checked while running for errors? This can avoid timeout issues but will be slower. [yes/NO]: no
Do you wish to optimize your script with torch dynamo?[yes/NO]:no
Do you want to use DeepSpeed? [yes/NO]: no
Do you want to use FullyShardedDataParallel? [yes/NO]: no
Do you want to use Megatron-LM ? [yes/NO]: no
How many GPU(s) should be used for distributed training? [1]:2
What GPU(s) (by id) should be used for training on this machine as a comma-seperated list? [all]:0,1
--------------------------------------------------------------------------------
Do you wish to use FP16 or BF16 (mixed precision)?
bf16
accelerate configuration saved at ~/.cache/huggingface/accelerate/default_config.yaml
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Ahora ejecutamos el √∫ltimo script que hab√≠amos creado, es decir, con un batch size de 256</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="w"> </span>
<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">14</span><span class="n">_accelerate_base_code_fp16_bs256</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50000/50000 [00:03&amp;lt;00:00, 14814.95 examples/s]
Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50000/50000 [00:03&amp;lt;00:00, 14506.83 examples/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 88/88 [00:51&amp;lt;00:00,  1.70it/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:03&amp;lt;00:00,  3.21it/s]
Accuracy = 0.2112
CPU times: user 688 ms, sys: 144 ms, total: 832 ms
Wall time: 1min 17s
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Ha tardado un tiempo similar a lo que tard√≥ antes, lo cual es normal, ya que hemos entrenado un modelo con pesos de 16 bits, al igual que antes</p>
</section>
<section class="section-block-markdown-cell">
<h3 id="Entrenamiento en FP8">Entrenamiento en FP8<a class="anchor-link" href="#Entrenamiento en FP8">¬∂</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Ahora vamos a entrenar en formato FP8, que como su nombre indica, es un formato de coma flotante, donde cada peso tiene 8 bits, por lo que ejecutamos <code>accelerate config</code> para decirle que queremos FP8</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="err">!</span><span class="n">accelerate</span> <span class="n">config</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>--------------------------------------------------------------------------------
In which compute environment are you running?
This machine
--------------------------------------------------------------------------------
multi-GPU
How many different machines will you use (use more than 1 for multi-node training)? [1]: 1
Should distributed operations be checked while running for errors? This can avoid timeout issues but will be slower. [yes/NO]: no
Do you wish to optimize your script with torch dynamo?[yes/NO]:no
Do you want to use DeepSpeed? [yes/NO]: no
Do you want to use FullyShardedDataParallel? [yes/NO]: no
Do you want to use Megatron-LM ? [yes/NO]: no
How many GPU(s) should be used for distributed training? [1]:2
What GPU(s) (by id) should be used for training on this machine as a comma-seperated list? [all]:0,1
--------------------------------------------------------------------------------
Do you wish to use FP16 or BF16 (mixed precision)?
fp8
accelerate configuration saved at ~/.cache/huggingface/accelerate/default_config.yaml
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Ahora ejecutamos el √∫ltimo script, el de batch size de 256</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="w"> </span>
<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">14</span><span class="n">_accelerate_base_code_fp16_bs256</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Traceback (most recent call last):
&#x20;&#x20;File &quot;/home/wallabot/Documentos/web/portafolio/posts/accelerate_scripts/13_accelerate_base_code_fp16_bs256.py&quot;, line 12, in &amp;lt;module&amp;gt;
&#x20;&#x20;&#x20;&#x20;accelerator = Accelerator()
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;^^^^^^^^^^^^^
&#x20;&#x20;File &quot;/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/accelerator.py&quot;, line 371, in __init__
&#x20;&#x20;&#x20;&#x20;self.state = AcceleratorState(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;^^^^^^^^^^^^^^^^^
&#x20;&#x20;File &quot;/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/state.py&quot;, line 790, in __init__
&#x20;&#x20;&#x20;&#x20;raise ValueError(
ValueError: Using `fp8` precision requires `transformer_engine` or `MS-AMP` to be installed.
Traceback (most recent call last):
&#x20;&#x20;File &quot;/home/wallabot/Documentos/web/portafolio/posts/accelerate_scripts/13_accelerate_base_code_fp16_bs256.py&quot;, line 12, in &amp;lt;module&amp;gt;
&#x20;&#x20;&#x20;&#x20;accelerator = Accelerator()
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;^^^^^^^^^^^^^
&#x20;&#x20;File &quot;/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/accelerator.py&quot;, line 371, in __init__
&#x20;&#x20;&#x20;&#x20;self.state = AcceleratorState(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;^^^^^^^^^^^^^^^^^
&#x20;&#x20;File &quot;/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/state.py&quot;, line 790, in __init__
&#x20;&#x20;&#x20;&#x20;raise ValueError(
ValueError: Using `fp8` precision requires `transformer_engine` or `MS-AMP` to be installed.
[2024-05-13 21:40:56,455] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 501480) of binary: /home/wallabot/miniconda3/envs/nlp/bin/python
Traceback (most recent call last):
&#x20;&#x20;File &quot;/home/wallabot/miniconda3/envs/nlp/bin/accelerate&quot;, line 8, in &amp;lt;module&amp;gt;
&#x20;&#x20;&#x20;&#x20;sys.exit(main())
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;^^^^^^
&#x20;&#x20;File &quot;/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/commands/accelerate_cli.py&quot;, line 46, in main
&#x20;&#x20;&#x20;&#x20;args.func(args)
&#x20;&#x20;File &quot;/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/commands/launch.py&quot;, line 1048, in launch_command
&#x20;&#x20;&#x20;&#x20;multi_gpu_launcher(args)
&#x20;&#x20;File &quot;/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/accelerate/commands/launch.py&quot;, line 702, in multi_gpu_launcher
&#x20;&#x20;&#x20;&#x20;distrib_run.run(args)
&#x20;&#x20;File &quot;/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/distributed/run.py&quot;, line 803, in run
&#x20;&#x20;&#x20;&#x20;elastic_launch(
&#x20;&#x20;File &quot;/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/distributed/launcher/api.py&quot;, line 135, in __call__
&#x20;&#x20;&#x20;&#x20;return launch_agent(self._config, self._entrypoint, list(args))
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
&#x20;&#x20;File &quot;/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/distributed/launcher/api.py&quot;, line 268, in launch_agent
&#x20;&#x20;&#x20;&#x20;raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
accelerate_scripts/13_accelerate_base_code_fp16_bs256.py FAILED
------------------------------------------------------------
Failures:
[1]:
&#x20;&#x20;time      : 2024-05-13_21:40:56
&#x20;&#x20;host      : wallabot
&#x20;&#x20;rank      : 1 (local_rank: 1)
&#x20;&#x20;exitcode  : 1 (pid: 501481)
&#x20;&#x20;error_file: &amp;lt;N/A&amp;gt;
&#x20;&#x20;traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
&#x20;&#x20;time      : 2024-05-13_21:40:56
&#x20;&#x20;host      : wallabot
&#x20;&#x20;rank      : 0 (local_rank: 0)
&#x20;&#x20;exitcode  : 1 (pid: 501480)
&#x20;&#x20;error_file: &amp;lt;N/A&amp;gt;
&#x20;&#x20;traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
CPU times: user 65.1 ms, sys: 14.5 ms, total: 79.6 ms
Wall time: 7.24 s
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Como los pesos ahora son de 8 bits y ocupan la mitad de memoria vamos a subir el batch size a 512</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">15</span><span class="n">_accelerate_base_code_fp8_bs512</span><span class="o">.</span><span class="n">py</span>
<span class="w"> </span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tqdm</span>
<span class="w"> </span>
<span class="c1"># Importamos e inicializamos Accelerator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>
<span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>
<span class="w"> </span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tweet_eval&quot;</span><span class="p">,</span> <span class="s2">&quot;emoji&quot;</span><span class="p">)</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
<span class="n">max_len</span> <span class="o">=</span> <span class="mi">130</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;cardiffnlp/twitter-roberta-base-irony&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]),</span>
<span class="p">}</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="w"> </span>
<span class="n">BS</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="w">    </span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tokenized_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="p">}</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>
<span class="w"> </span>
<span class="c1"># model.to(device)</span>
<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>
<span class="w"> </span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_train</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_train</span><span class="p">:</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="c1"># loss.backward()</span>
<span class="w">        </span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="w">    </span><span class="n">progress_bar_validation</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">progress_bar_validation</span><span class="p">:</span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="c1">#.to(device)</span>
<span class="w"> </span>
<span class="w">        </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="w">            </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="w">        </span><span class="c1"># Recopilamos las predicciones de todos los dispositivos</span>
<span class="w">        </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="w">    </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="w">    </span>
<span class="n">accelerator</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Writing accelerate_scripts/15_accelerate_base_code_fp8_bs512.py
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Lo ejecutamos</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="w"> </span>
<span class="err">!</span><span class="n">accelerate</span> <span class="n">launch</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">15</span><span class="n">_accelerate_base_code_fp8_bs512</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<h2 id="Inferencia de modelos">Inferencia de modelos<a class="anchor-link" href="#Inferencia de modelos">¬∂</a></h2>
</section>
<section class="section-block-markdown-cell">
<h3 id="Uso del ecosistema de Hugging Face">Uso del ecosistema de Hugging Face<a class="anchor-link" href="#Uso del ecosistema de Hugging Face">¬∂</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Vamos a ver c√≥mo hacer inferencia de grandes modelos con la librer√≠a <code>transformers</code> de hugging face.</p>
</section>
<section class="section-block-markdown-cell">
<h4 id="Inferencia con pipeline">Inferencia con <code>pipeline</code><a class="anchor-link" href="#Inferencia con pipeline">¬∂</a></h4>
</section>
<section class="section-block-markdown-cell">
<p>Si usamos el ecosistema de Hugging Face es muy sencillo, ya que todo se produce por debajo sin tener que hacer nosotros mucho. En el caso de usar <code>pipeline</code>, que es la manera m√°s sencilla de hacer inferencia con la librer√≠a <code>transformers</code>, simplemente tenemos que decirle el modelo que queremos usar y muy importante, pasarle <code>device_map=&quot;auto&quot;</code>. Esto har√° que por debajo <code>accelerate</code> distribuya el modelo entre las distintas GPUs, RAM de la CPU o disco duro si es necesario</p>
</section>
<section class="section-block-markdown-cell">
<p>Hay m√°s posibles valores para <code>device_map</code>, que los veremos m√°s adelante, pero de momento qu√©date con <code>&quot;auto&quot;</code>.</p>
</section>
<section class="section-block-markdown-cell">
<p>Vamos a usar el modelo <code>Llama3 8B</code>, que como su nombre indica es un modelo de unos 8 mil millones de par√°metros. Como cada par√°metro por defecto est√° en formato FP32, que corresponde a 4 bytes (32 bits), eso quiere decir que si multiplicamos 8 mil millones de par√°metros por 4 bytes, nos queda que necesitar√≠a una GPU con unos 32 GB de VRAM.</p>
<p>En mi caso tengo 2 GPUs de 24 GB de VRAM, por lo que no entrar√≠a en una sola GPU. Pero gracias a poner <code>device_map=&quot;auto&quot;</code>, accelerate distribuir√° el modelo entre las dos GPUs y podr√© realizar la inferencia</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">16</span><span class="n">_inference_with_pipeline</span><span class="o">.</span><span class="n">py</span>
<span class="w"> </span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">pipeline</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;meta-llama/Meta-Llama-3-8B-Instruct&quot;</span>
<span class="n">generator</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">checkpoints</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;Conoces accelerate de hugging face?&quot;</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">generator</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Overwriting accelerate_scripts/09_inference_with_pipeline.py
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Ahora lo ejecutamos, solo que como pipeline usa por debajo accelerate, no necesitamos ejecutarlo con <code>accelerate launch script.py</code> sino que con <code>python script.py</code> vale</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="err">!</span><span class="n">python</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">16</span><span class="n">_inference_with_pipeline</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:09&amp;lt;00:00,  2.27s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
[&#x7B;&#x27;generated_text&#x27;: &#x27;Conoces accelerate de hugging face? ¬øQu√© es el modelo de lenguaje de transformers y c√≥mo se utiliza en el marco de hugging face? ¬øC√≥mo puedo utilizar modelos de lenguaje de transformers en mi aplicaci√≥n? ¬øQu√© son los tokenizers y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo crear un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los datasets y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar datasets para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los evaluadores y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los pre-trainados y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los finetuning y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los checkpoints y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los evaluadores y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los pre-trainados y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los finetuning y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los checkpoints y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los evaluadores y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los pre-trainados y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los finetuning y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los checkpoints y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los evaluadores y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los pre-trainados y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los finetuning y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los checkpoints y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los evaluadores y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los pre-trainados y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los finetuning y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los checkpoints y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los evaluadores y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los pre-trainados y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los finetuning y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los checkpoints y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los evaluadores y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los pre-trainados y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los finetuning y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los checkpoints y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los evaluadores y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los pre-trainados y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los finetuning y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los checkpoints y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los evaluadores y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los pre-trainados y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los finetuning y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los checkpoints y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los evaluadores y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los pre-trainados y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los finetuning y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los checkpoints y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los evaluadores y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los pre-trainados y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los finetuning y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los checkpoints y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los evaluadores y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los pre-trainados y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los finetuning y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los checkpoints y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los evaluadores y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los pre-trainados y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los finetuning y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los checkpoints y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los evaluadores y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los pre-trainados y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los finetuning y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los checkpoints y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los evaluadores y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los pre-trainados y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los finetuning y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los checkpoints y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los evaluadores y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los pre-trainados y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los finetuning y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los checkpoints y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los evaluadores y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los pre-trainados y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los finetuning y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los checkpoints y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los evaluadores y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los pre-trainados y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los finetuning y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los checkpoints y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los evaluadores y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los pre-trainados y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los finetuning y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los checkpoints y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los evaluadores y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los pre-trainados y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los finetuning y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los checkpoints y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los evaluadores y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los pre-trainados y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los finetuning y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar finetuning para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los checkpoints y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar checkpoints para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los evaluadores y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar evaluadores para evaluar el rendimiento de un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los pre-trainados y c√≥mo se utilizan en el marco de hugging face? ¬øC√≥mo puedo utilizar pre-trainados para entrenar un modelo de lenguaje personalizado utilizando transformers y hugging face? ¬øQu√© son los finetuning&#x27;&#x7D;]
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Como se puede ver, no ha respondido, sino que ha seguido haciendo preguntas. Esto es porque Llama3 es un modelo de lenguaje que lo que hace es predecir el siguiente token, as√≠ que con el prompt que le he pasado, ha considerado que los siguientes mejores tokens son unos que corresponden a m√°s preguntas. Lo cual tiene sentido, porque hay veces que la gente tiene dudas sobre un tema y genera muchas preguntas, as√≠ que para que nos conteste a la pregunta hay que condicionarle un poco</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">17</span><span class="n">_inference_with_pipeline_condition</span><span class="o">.</span><span class="n">py</span>
<span class="w"> </span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">pipeline</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;meta-llama/Meta-Llama-3-8B-Instruct&quot;</span>
<span class="n">generator</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">checkpoints</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;Conoces accelerate de hugging face?&quot;</span>
<span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">        </span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;Eres un chatbot amigable que siempre intenta solucionar las dudas&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prompt</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">},</span>
<span class="p">]</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">generator</span><span class="p">(</span><span class="n">messages</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;generated_text&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Overwriting accelerate_scripts/10_inference_with_pipeline_condition.py
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Como ves se ha generado un mensaje con roles, condicionando el modelo y con el prompt</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="err">!</span><span class="n">python</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">17</span><span class="n">_inference_with_pipeline_condition</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:09&amp;lt;00:00,  2.41s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
&#x7B;&#x27;role&#x27;: &#x27;assistant&#x27;, &#x27;content&#x27;: &#x27;¬°Hola!\n\nS√≠, conozco Accelerate de Hugging Face. Accelerate es una biblioteca de Python desarrollada por Hugging Face que se enfoca en simplificar y acelerar el entrenamiento y la evaluaci√≥n de modelos de lenguaje en diferentes dispositivos y entornos.\n\nCon Accelerate, puedes entrenar modelos de lenguaje en diferentes plataformas y dispositivos, como GPUs, TPUs, CPUs y servidores, sin necesidad de cambiar el c√≥digo de tu modelo. Esto te permite aprovechar al m√°ximo la potencia de c√°lculo de tus dispositivos y reducir el tiempo de entrenamiento.\n\nAccelerate tambi√©n ofrece varias caracter√≠sticas adicionales, como:\n\n* Soporte para diferentes frameworks de machine learning, como TensorFlow, PyTorch y JAX.\n* Integraci√≥n con diferentes sistemas de almacenamiento y procesamiento de datos, como Amazon S3 y Google Cloud Storage.\n* Soporte para diferentes protocolos de comunicaci√≥n, como HTTP y gRPC.\n* Herramientas para monitorear y depurar tus modelos en tiempo real.\n\nEn resumen, Accelerate es una herramienta muy √∫til para desarrolladores de modelos de lenguaje que buscan simplificar y acelerar el proceso de entrenamiento y evaluaci√≥n de sus modelos.\n\n¬øTienes alguna pregunta espec√≠fica sobre Accelerate o necesitas ayuda para implementarlo en tu proyecto?&#x27;&#x7D;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Ahora la respuesta s√≠ responde nuestro prompt</p>
</section>
<section class="section-block-markdown-cell">
<h4 id="Inferencia con AutoClass">Inferencia con <code>AutoClass</code><a class="anchor-link" href="#Inferencia con AutoClass">¬∂</a></h4>
</section>
<section class="section-block-markdown-cell">
<p>Por √∫ltimo vamos a ver c√≥mo hacer la inferencia solo con <code>AutoClass</code>.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">18</span><span class="n">_inference_with_autoclass</span><span class="o">.</span><span class="n">py</span>
<span class="w"> </span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">TextStreamer</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;meta-llama/Meta-Llama-3-8B-Instruct&quot;</span>
<span class="w"> </span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>
<span class="n">streamer</span> <span class="o">=</span> <span class="n">TextStreamer</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;Conoces accelerate de hugging face?&quot;</span>
<span class="n">tokens_input</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">([</span><span class="n">prompt</span><span class="p">],</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="o">**</span><span class="n">tokens_input</span><span class="p">,</span> <span class="n">streamer</span><span class="o">=</span><span class="n">streamer</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">do_sample</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">top_p</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Overwriting accelerate_scripts/11_inference_with_autoclass.py
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Como se puede ver, se ha creado el objeto <code>streamer</code> que luego se le pasa al m√©todo <code>generate</code> del modelo. Esto es √∫til para que se vaya imprimiendo cada palabra a medida que se va generando y no haya que esperar a que se genere toda la salida para imprimirla</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="err">!</span><span class="n">python</span> <span class="n">accelerate_scripts</span><span class="o">/</span><span class="mi">18</span><span class="n">_inference_with_autoclass</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:09&amp;lt;00:00,  2.28s/it]
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
&amp;lt;|begin_of_text|&amp;gt;Conoces accelerate de hugging face? Si es as√≠, puedes utilizar la biblioteca `transformers` de Hugging Face para crear un modelo de lenguaje que pueda predecir la siguiente palabra en una secuencia de texto.

Aqu√≠ te muestro un ejemplo de c√≥mo hacerlo:
```
import pandas as pd
import torch
from transformers import AutoModelForSequenceClassification, AutoTokenizer

# Cargar el modelo y el tokenizador
model_name = &quot;bert-base-uncased&quot;
model = AutoModelForSequenceClassification.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)

# Cargar el conjunto de datos
train_df = pd.read_csv(&quot;train.csv&quot;)
test_df = pd.read_csv(&quot;test.csv&quot;)

# Preprocesar los datos
train_texts = train_df[&quot;text&quot;]
train_labels = train_df[&quot;label&quot;]
test_texts = test_df[&quot;text&quot;]

# Convertir los textos en entradas para el modelo
train_encodings = tokenizer.batch_encode_plus(train_texts, 
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;add_special_tokens=True, 
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;max_length=512, 
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;return_attention_mask=True, 
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;return_tensors=&#x27;pt&#x27;)

test_encodings = tokenizer.batch_encode_plus(test_texts, 
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;add_special_tokens=True, 
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;max_length=512, 
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;return_attention_mask=True, 
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;return_tensors=&#x27;pt&#x27;)

# Crear un dataloader para entrenar el modelo
train_dataset = torch.utils.data.TensorDataset(train_encodings[&quot;input_ids&quot;], 
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;train_encodings[&quot;attention_mask&quot;], 
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;torch.tensor(train_labels))
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)

# Entrenar el modelo
device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)
model.to(device)
criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)

for epoch in range(5):
&#x20;&#x20;&#x20;&#x20;model.train()
&#x20;&#x20;&#x20;&#x20;total_loss = 0
&#x20;&#x20;&#x20;&#x20;for batch in train_loader:
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;input_ids = batch[0].to(device)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;attention_mask = batch[1].to(device)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;labels = batch[2].to(device)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;optimizer.zero_grad()
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;loss = criterion(outputs, labels)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;loss.backward()
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;optimizer.step()
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;total_loss += loss.item()
&#x20;&#x20;&#x20;&#x20;print(f&quot;Epoch &#x7B;epoch+1&#x7D;, Loss: &#x7B;total
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Uso PyTorch">Uso PyTorch<a class="anchor-link" href="#Uso PyTorch">¬∂</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Normalmente la manera de hacer inferencias con pytorch es crear un modelo con los pesos inicializados aleatoriamente y a continuaci√≥n cargar un <code>state dict</code> con los pesos del modelo preentrenado, as√≠ que para obtener ese <code>state dict</code> vamos a hacer primero una peque√±a trampa y nos lo vamos a descargar</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torchvision.models</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">models</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet152</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">models</span><span class="o">.</span><span class="n">ResNet152_Weights</span><span class="o">.</span><span class="n">IMAGENET1K_V1</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">&#39;accelerate_scripts/resnet152_pretrained.pth&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Downloading: &quot;https://download.pytorch.org/models/resnet152-394f9c45.pth&quot; to /home/maximo.fernandez/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 230M/230M [02:48&amp;lt;00:00, 1.43MB/s]
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Ahora que tenemos el <code>state dict</code> vamos a hacer inferencia como se hace normalmente en pytorch</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torchvision.models</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">models</span>
<span class="w"> </span>
<span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>     <span class="c1"># Set device</span>
<span class="w"> </span>
<span class="n">resnet152</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet152</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="c1"># Create model with random weights and move to device</span>
<span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;accelerate_scripts/resnet152_pretrained.pth&#39;</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="c1"># Load pretrained weights into device memory</span>
<span class="n">resnet152</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span> <span class="c1"># Load this weights into the model</span>
<span class="w"> </span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Random image with batch size 1</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">resnet152</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="n">output</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>torch.Size([1, 1000])
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vamos a explicar qu√© ha pasado</p>
<ul>
  <li>Cuando hemos hecho <code>resnet152 = models.resnet152().to(device)</code> se ha cargado una ResNet152 con pesos aleatorios en la memoria de la GPU</li>
  <li>Cuando hemos hecho <code>state_dict = torch.load('accelerate_scripts/resnet152_pretrained.pth', map_location=device)</code> se ha cargado un diccionario con los pesos entrenados en la memoria de la GPU</li>
  <li>Cuando hemos hecho <code>resnet152.load_state_dict(state_dict)</code> se han asignado esos pesos preentrenados al modelo</li>
</ul>
<p>Es decir, se ha cargado dos veces el modelo en la memoria de la GPU</p>
</section>
<section class="section-block-markdown-cell">
<p>Te puedes estar preguntando por qu√© hemos hecho primero</p>
<section class="section-block-markdown-cell">
      <div class='highlight'><pre><code class="language-python">model = models.resnet152(weights=models.ResNet152_Weights.IMAGENET1K_V1)<br>torch.save(model.state_dict(), &#39;accelerate_scripts/resnet152_pretrained.pth&#39;)</code></pre></div>
      </section>
<p>Para luego hacer</p>
<section class="section-block-markdown-cell">
      <div class='highlight'><pre><code class="language-python">resnet152 = models.resnet152().to(device)<br>state_dict = torch.load(&#39;accelerate_scripts/resnet152_pretrained.pth&#39;, map_location=device)<br>resnet152.load_state_dict(state_dict)</code></pre></div>
      </section>
<p>Y por qu√© no usamos directamente</p>
<div class='highlight'><pre><code class="language-text">model = models.resnet152(weights=models.ResNet152_Weights.IMAGENET1K_V1)
</code></pre></div>
<p>Y nos dejamos de guardar el <code>state dict</code> para luego cargarlo. Bueno, pues porque Pytorch, por debajo hace lo mismo que hemos hecho. As√≠ que para poder ver todo el proceso hemos hecho en varias l√≠neas lo que Pytorch hace en una</p>
</section>
<section class="section-block-markdown-cell">
<p>Esta manera de trabajar ha funcionado bien hasta ahora, mientras que los modelos ten√≠an un tama√±o manejable por las GPUs de usuario. Pero desde la llegada de los LLMs este enfoque no tiene sentido</p>
<p>Por ejemplo, un modelo de 6B de par√°metros ocupar√≠a en la memoria 24 GB, y como se carga dos veces con esta manera de trabajar, har√≠a falta tener una GPU de 48 GB.</p>
</section>
<section class="section-block-markdown-cell">
<p>As√≠ que para arreglar esto, la manera de cargar un modelo preentrenado de PyTorch es:</p>
<ul>
  <li>Crear un modelo vac√≠o con <code>init_empty_weights</code> que no ocupar√° memoria RAM</li>
  <li>Luego cargar los pesos con <code>load_checkpoint_and_dispatch</code> que cargar√° un punto de control dentro del modelo vac√≠o y distribuir√° los pesos para cada capa en todos los dispositivos que se tenga disponibles (GPU, CPU, RAM y disco duro), gracias a poner <code>device_map="auto"</code></li>
</ul>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torchvision.models</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">models</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">init_empty_weights</span><span class="p">,</span> <span class="n">load_checkpoint_and_dispatch</span>
<span class="w"> </span>
<span class="k">with</span> <span class="n">init_empty_weights</span><span class="p">():</span>
<span class="w">    </span><span class="n">resnet152</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet152</span><span class="p">()</span>
<span class="w"> </span>
<span class="n">resnet152</span> <span class="o">=</span> <span class="n">load_checkpoint_and_dispatch</span><span class="p">(</span><span class="n">resnet152</span><span class="p">,</span> <span class="n">checkpoint</span><span class="o">=</span><span class="s1">&#39;accelerate_scripts/resnet152_pretrained.pth&#39;</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>
<span class="w"> </span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Random image with batch size 1</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">resnet152</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="n">output</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>torch.Size([1, 1000])
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Como funciona accelerate por debajo">C√≥mo funciona accelerate por debajo<a class="anchor-link" href="#Como funciona accelerate por debajo">¬∂</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>En este v√≠deo se puede ver gr√°ficamente c√≥mo funciona accelerate por debajo</p>
</section>
<section class="section-block-markdown-cell">
<iframe width="1280" height="720" src="https://www.youtube.com/embed/MWCSGj9jEAo" title="Accelerate Big Model Inference: How Does it Work?" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</section>
<section class="section-block-markdown-cell">
<h4 id="Inicializacion de un modelo vacio">Inicializaci√≥n de un modelo vac√≠o<a class="anchor-link" href="#Inicializacion de un modelo vacio">¬∂</a></h4>
</section>
<section class="section-block-markdown-cell">
<p><code>Accelerate</code> crea el esqueleto de un modelo vac√≠o mediante <code>init_empty_weights</code> para que ocupe la menor cantidad de memoria posible</p>
</section>
<section class="section-block-markdown-cell">
<p>Por ejemplo, veamos cuanta RAM tengo ahora disponible en mi ordenador</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">psutil</span>
<span class="w"> </span>
<span class="k">def</span><span class="w"> </span><span class="nf">get_ram_info</span><span class="p">():</span>
<span class="w">    </span><span class="n">ram</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">psutil</span><span class="o">.</span><span class="n">virtual_memory</span><span class="p">()</span><span class="o">.</span><span class="n">_asdict</span><span class="p">())</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total RAM: </span><span class="si">{</span><span class="p">(</span><span class="n">ram</span><span class="p">[</span><span class="s1">&#39;total&#39;</span><span class="p">]</span><span class="o">/</span><span class="mi">1024</span><span class="o">/</span><span class="mi">1024</span><span class="o">/</span><span class="mi">1024</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> GB, Available RAM: </span><span class="si">{</span><span class="p">(</span><span class="n">ram</span><span class="p">[</span><span class="s1">&#39;available&#39;</span><span class="p">]</span><span class="o">/</span><span class="mi">1024</span><span class="o">/</span><span class="mi">1024</span><span class="o">/</span><span class="mi">1024</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> GB, Used RAM: </span><span class="si">{</span><span class="p">(</span><span class="n">ram</span><span class="p">[</span><span class="s1">&#39;used&#39;</span><span class="p">]</span><span class="o">/</span><span class="mi">1024</span><span class="o">/</span><span class="mi">1024</span><span class="o">/</span><span class="mi">1024</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> GB&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">get_ram_info</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Total RAM: 31.24 GB, Available RAM: 22.62 GB, Used RAM: 7.82 GB
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Tengo unos 22 GB de RAM disponibles</p>
<p>Ahora vamos a intentar crear un modelo 5000x1000x1000 par√°metros, es decir, de 5B de par√°metros, si cada par√°metro est√° en FP32, supone 20 GB de RAM</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">)])</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Si volvemos a ver la RAM</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">get_ram_info</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Total RAM: 31.24 GB, Available RAM: 3.77 GB, Used RAM: 26.70 GB
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Como vemos, ahora solo tenemos 3 GB de RAM disponibles</p>
</section>
<section class="section-block-markdown-cell">
<p>Ahora vamos a eliminar el modelo para liberar RAM</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">del</span> <span class="n">model</span>
<span class="n">get_ram_info</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Total RAM: 31.24 GB, Available RAM: 22.44 GB, Used RAM: 8.03 GB
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Volvemos a tener unos 22 GB de RAM disponibles</p>
</section>
<section class="section-block-markdown-cell">
<p>Vamos ahora a usar <code>init_empty_weights</code> de <code>accelerate</code> y luego vemos la RAM</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">init_empty_weights</span>
<span class="w"> </span>
<span class="k">with</span> <span class="n">init_empty_weights</span><span class="p">():</span>
<span class="w">    </span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">)])</span>
<span class="w"> </span>
<span class="n">get_ram_info</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Total RAM: 31.24 GB, Available RAM: 22.32 GB, Used RAM: 8.16 GB
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Antes ten√≠amos exactamente 22.44 GB libres y tras crear el modelo con <code>init_empty_weights</code> tenemos 22.32 GB. El ahorro en RAM es enorme! Casi no se ha ocupado RAM para crear el modelo.</p>
<p>Esto se basa en el metadispositivo introducido en PyTorch 1.9, por lo que es importante que para usar <code>accelerate</code> tengamos una versi√≥n de Pytorch posterior</p>
</section>
<section class="section-block-markdown-cell">
<h4 id="Carga de los pesos">Carga de los pesos<a class="anchor-link" href="#Carga de los pesos">¬∂</a></h4>
</section>
<section class="section-block-markdown-cell">
<p>Una vez hemos inicializado el modelo, tenemos que cargarle los pesos, lo cual hacemos mediante <code>load_checkpoint_and_dispatch</code>, que como su nombre indica, carga los pesos y los env√≠a al dispositivo o dispositivos que sean necesarios.</p>
</section>