<p>
	<!-- Custom stylesheet, it must be in the same directory as the html file -->
	<!-- Loading mathjax macro --><!-- Load mathjax --><!-- MathJax configuration -->
<p>
<style>
	/* Media query para pantallas grandes */
	@media screen and (min-width: 1000px) {
		.container {
			flex-wrap: nowrap;
			display: flex;
			justify-content: space-between;
			height: 100vh; /* altura del viewport */
		}
		
		.indice {
			width: 25%; /* Ancho del índice en pantallas grandes */
			border-right: 1px solid #ccc;
			max-height: calc(100vh - 40px); /* Ajustar según tus necesidades. Aquí estamos restando el doble del padding para mantener todo visible */
			padding: 20px;
			box-sizing: border-box;
			overflow-y: auto; /* desplazamiento vertical cuando sea necesario */
		}
		
		.contenido {
			width: 70%; /* Ancho del contenido en pantallas grandes */
			max-height: calc(100vh - 40px); /* Ajustar según tus necesidades. Aquí estamos restando el doble del padding para mantener todo visible */
			padding: 20px;
			box-sizing: border-box;
			overflow-y: auto; /* desplazamiento vertical cuando sea necesario */
		}
	}
</style>
<!-- Open div notebook -->
<div id="notebook" class="border-box-sizing" tabindex="-1">
	<!-- Open div notebook container -->
	<div id="notebook-container" class="container">
		<!-- Open div indice -->
		<div class="indice">
			<!-- Open div index header -->
			<div class="cell border-box-sizing text_cell rendered">
				<h2 class="prompt input_prompt">
					<span style="
					color: var(--darkreader-text--heading-color, var(--darkreader-text--heading-2-color,
					var(--darkreader-text--headings-color)));
					font-family: var(--fontFamily); font-size: var(--fontSize);
					font-style: var(--fontStyle, inherit);
					font-weight: var(--fontWeight);
					letter-spacing: var(--letterSpacing);
					text-transform: var(--textTransform);
					background-color: transparent;
					--darkreader-inline-color: var(--darkreader-text--darkreader-text--heading-color,
					var(--darkreader-text--darkreader-text--heading-2-color, var(--darkreader-text--darkreader-text--headings-color)));
					--darkreader-inline-bgcolor: transparent;"
					data-darkreader-inline-color="" data-darkreader-inline-bgcolor="">
						Índice
					</span>
					<a class="anchor-link" style="
					font-family: var(--fontFamily);
					font-size: var(--fontSize);
					font-style: var(--fontStyle, inherit);
					font-weight: var(--fontWeight);
					letter-spacing: var(--letterSpacing);
					text-transform: var(--textTransform);
					background-color: transparent;
					--darkreader-inline-bgcolor: transparent;"
					href="#Índice" data-darkreader-inline-bgcolor="">
					</a>
				</h2>
			<!-- Close div index header -->
			</div>
			<!-- Index body -->
			<div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Instalación-index">
									<a class="anchor-link" href="#Instalación">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Instalación</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="BeterTransformer-index">
									<a class="anchor-link" href="#BeterTransformer">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">BeterTransformer</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Inferencia-con-Automodel-index">
									<a class="anchor-link" href="#Inferencia-con-Automodel">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Inferencia con Automodel</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Inferecncia-con-Pipeline-index">
									<a class="anchor-link" href="#Inferecncia-con-Pipeline">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Inferecncia con Pipeline</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Entrenamiento-index">
									<a class="anchor-link" href="#Entrenamiento">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Entrenamiento</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
			</div>
		<!-- Close div indice -->
		</div>
 
		<!-- Content -->
		<div class="contenido">
		<div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><a href="https://colab.research.google.com/github/maximofn/portafolio/blob/main/posts/2024-06-01-Hugging-Face-optimun.ipynb" target="_blank"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h1 id="Hugging-Face-Optimun">
								<a class="anchor-link" href="#Hugging-Face-Optimun">
									<p style="margin-left: 0px">Hugging Face Optimun</p>
								</a>
							</h1>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><code><b>Optimum</b></code> es una extensión de la librería <a href="https://maximofn.com/hugging-face-transformers/" target="_blank">Transformers</a> que proporciona un conjunto de herramientas de optimización del rendimiento para entrenar y para la inferencia modelos, en hardware específico, con la máxima eficiencia.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">El ecosistema de IA evoluciona rápidamente y cada día surge más hardware especializado junto con sus propias optimizaciones. Por tanto, <code><b>Optimum</b></code> permite a los utilizar eficientemente cualquiera de este HW con la misma facilidad que <a href="https://maximofn.com/hugging-face-transformers/" target="_blank">Transformers</a>.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><code><b>Optimun</b></code> premite la optimización para las siguientes plataformas HW:</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">
								<ul>
									<li>Nvidia</li>
									<li>AMD</li>
									<li>Intel</li>
									<li>AWS</li>
									<li>TPU</li>
									<li>Habana</li>
									<li>FuriosaAI</li>
								</ul>
							</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Además ofrece aceleración para las siguientes integraciones open source</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">
								<ul>
									<li>ONNX runtime</li>
									<li>Exporters: Exportar omdelos Pytorch o TensorFlow a diferentes formatos como ONNX o TFLite</li>
									<li>BetterTransformer</li>
									<li>Torch FX</li>
								</ul>
							</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Instalación">
								<a class="anchor-link" href="#Instalación">
									<p style="margin-left: 10px">Instalación</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Para instalar <code><b>Optimum</b></code> simplemente ejecuta:</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 80px;"><code>pip install optimum<br></code></p>
						</div>
					</div>
				</div>
			</div>
	
	
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Pero si se quiere instalar con soporte para todas las plataformas HW, se puede hacer así</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<table>
								<tr>
									<th>Accelerator	</th>
									<th>Installation</th>
								</tr>
								<tr>
									<td>ONNX Runtime	</td>
									<td><code><b>pip install --upgrade --upgrade-strategy eager optimum[onnxruntime]</b></code></td>
								</tr>
								<tr>
									<td>Intel Neural Compressor	</td>
									<td><code><b>pip install --upgrade --upgrade-strategy eager optimum[neural-compressor]</b></code></td>
								</tr>
								<tr>
									<td>OpenVINO	</td>
									<td><code><b>pip install --upgrade --upgrade-strategy eager optimum[openvino]</b></code></td>
								</tr>
								<tr>
									<td>NVIDIA TensorRT-LLM	</td>
									<td><code><b>docker run -it --gpus all --ipc host huggingface/optimum-nvidia</b></code></td>
								</tr>
								<tr>
									<td>AMD Instinct GPUs and Ryzen AI NPU	</td>
									<td><code><b>pip install --upgrade --upgrade-strategy eager optimum[amd]</b></code></td>
								</tr>
								<tr>
									<td>AWS Trainum & Inferentia	</td>
									<td><code><b>pip install --upgrade --upgrade-strategy eager optimum[neuronx]</b></code></td>
								</tr>
								<tr>
									<td>Habana Gaudi Processor (HPU)	</td>
									<td><code><b>pip install --upgrade --upgrade-strategy eager optimum[habana]</b></code></td>
								</tr>
								<tr>
									<td>FuriosaAI	</td>
									<td><code><b>pip install --upgrade --upgrade-strategy eager optimum[furiosa]</b></code></td>
								</tr>
							</table>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">los flags <code><b>--upgrade --upgrade-strategy eager</b></code> son necesarios para garantizar que los diferentes paquetes se actualicen a la última versión posible.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Como la mayoría de la gente usa Pytorch en GPUs de Nvidia, y sobre todo, como Nvidia es lo que yo tengo, este post va a hablar solo del uso de <code><b>Optimun</b></code> con GPUs de Nvidia y Pytorch.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="BeterTransformer">
								<a class="anchor-link" href="#BeterTransformer">
									<p style="margin-left: 10px">BeterTransformer</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">BetterTransformer es una optimización nativa de PyTorch para obtener una aceleración de x1,25 a x4 en la inferencia de modelos basados ​​en Transformer</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">BetterTransformer es una API que permite aprovechar las características de hardware modernas para acelerar el entrenamiento y la inferencia de modelos de transformers en PyTorch, utilizando implementaciones de atención más eficientes y <code><b>fast path</b></code> de la versión nativa de <code><b>nn.TransformerEncoderLayer</b></code>.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">BetterTransformer usa dos tipos de aceleraciones:</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">
								<ol>
									<li><code><b>Flash Attention</b></code>: Esta es una implementación de la <code><b>attention</b></code> que utiliza <code><b>sparse</b></code> para reducir la complejidad computacional. La atención es una de las operaciones más costosas en los modelos de transformers, y <code><b>Flash Attention</b></code> la hace más eficiente.</li>
									<li><code><b>Memory-Efficient Attention</b></code>: Esta es otra implementación de la atención que utiliza la función <code><b>scaled_dot_product_attention</b></code> de PyTorch. Esta función es más eficiente en términos de memoria que la implementación estándar de la atención en PyTorch.</li>
								</ol>
							</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Además, la versión 2.0 de PyTorch incluye un operador de atención de productos punto escalado (SDPA) nativo como parte de <code><b>torch.nn.functional</b></code></p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><code><b>Optimun</b></code> proporciona esta funcionalidad con la librería <code><b>Transformers</b></code></p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h3 id="Inferencia-con-Automodel">
								<a class="anchor-link" href="#Inferencia-con-Automodel">
									<p style="margin-left: 20px">Inferencia con Automodel</p>
								</a>
							</h3>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Primero vamos a ver cómo sería la inferencia normal con <code><b>Transformers</b></code> y <code><b>Automodel</b></code></p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p></p>
<p><span style="color: #6b97e8;">checkpoint</span> <span>=</span> <span style="color: #7e7a34;">&quot;openai-community/gpt2&quot;</span></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a34;">&quot;auto&quot;</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p></p>
<p><span style="color: #6b97e8;">input_tokens</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">output_tokens</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">input_tokens</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_length</span><span>=</span><span style="color: #7e7a38;">50</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">output_tokens</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>'Me encanta aprender de la vie de la vie de la vie de la vie de la vie de la vie de la vie de la vie de la vie de la vie de la vie de'</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Ahora vemos cómo se optimizaría con <code><b>BetterTransformer</b></code> y <code><b>Optimun</b></code></p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Lo que tenemos que hacer es convertir el modelo mediante el método <code><b>transform</b></code> de <code><b>BeterTransformer</b></code></p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">optimum.bettertransformer</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">BetterTransformer</span></p>
<p></p>
<p><span style="color: #6b97e8;">checkpoint</span> <span>=</span> <span style="color: #7e7a34;">&quot;openai-community/gpt2&quot;</span></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">model_hf</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a34;">&quot;auto&quot;</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #7f6e38;"># Convert the model to a BetterTransformer model</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">BetterTransformer</span><span>.</span><span style="color: #6b97e8;">transform</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">model_hf</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">keep_original_model</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p></p>
<p><span style="color: #6b97e8;">input_tokens</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">output_tokens</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">input_tokens</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_length</span><span>=</span><span style="color: #7e7a38;">50</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">output_tokens</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>'Me encanta aprender de la vie de la vie de la vie de la vie de la vie de la vie de la vie de la vie de la vie de la vie de la vie de'</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h3 id="Inferecncia-con-Pipeline">
								<a class="anchor-link" href="#Inferecncia-con-Pipeline">
									<p style="margin-left: 20px">Inferecncia con Pipeline</p>
								</a>
							</h3>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Al igual que antes, primero vemos cómo sería la inferencia normal con <code><b>Transformers</b></code> y <code><b>Pipeline</b></code></p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">pipeline</span></p>
<p></p>
<p><span style="color: #6b97e8;">pipe</span> <span>=</span> <span style="color: #6b97e8;">pipeline</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">task</span><span>=</span><span style="color: #7e7a34;">&quot;fill-mask&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">model</span><span>=</span><span style="color: #7e7a34;">&quot;distilbert-base-uncased&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">pipe</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;I am a student at [MASK] University.&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>[{'score': 0.05116177722811699,</p><p>  'token': 8422,</p><p>  'token_str': 'stanford',</p><p>  'sequence': 'i am a student at stanford university.'},</p><p> {'score': 0.04033993184566498,</p><p>  'token': 5765,</p><p>  'token_str': 'harvard',</p><p>  'sequence': 'i am a student at harvard university.'},</p><p> {'score': 0.03990468755364418,</p><p>  'token': 7996,</p><p>  'token_str': 'yale',</p><p>  'sequence': 'i am a student at yale university.'},</p><p> {'score': 0.0361952930688858,</p><p>  'token': 10921,</p><p>  'token_str': 'cornell',</p><p>  'sequence': 'i am a student at cornell university.'},</p><p> {'score': 0.03303057327866554,</p><p>  'token': 9173,</p><p>  'token_str': 'princeton',</p><p>  'sequence': 'i am a student at princeton university.'}]</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Ahora vemos cómo optimizarlo, para ello usamos <code><b>pipeline</b></code> de <code><b>Optimun</b></code>, en vez de el de <code><b>Transformers</b></code>. Además hay que indicar que queremos usar <code><b>bettertransformer</b></code> como acelerador</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">optimum.pipelines</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">pipeline</span></p>
<p></p>
<p><span style="color: #7f6e38;"># Use the BetterTransformer pipeline</span></p>
<p><span style="color: #6b97e8;">pipe</span> <span>=</span> <span style="color: #6b97e8;">pipeline</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">task</span><span>=</span><span style="color: #7e7a34;">&quot;fill-mask&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">model</span><span>=</span><span style="color: #7e7a34;">&quot;distilbert-base-uncased&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">accelerator</span><span>=</span><span style="color: #7e7a34;">&quot;bettertransformer&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">pipe</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;I am a student at [MASK] University.&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>[{'score': 0.05116180703043938,</p><p>  'token': 8422,</p><p>  'token_str': 'stanford',</p><p>  'sequence': 'i am a student at stanford university.'},</p><p> {'score': 0.040340032428503036,</p><p>  'token': 5765,</p><p>  'token_str': 'harvard',</p><p>  'sequence': 'i am a student at harvard university.'},</p><p> {'score': 0.039904672652482986,</p><p>  'token': 7996,</p><p>  'token_str': 'yale',</p><p>  'sequence': 'i am a student at yale university.'},</p><p> {'score': 0.036195311695337296,</p><p>  'token': 10921,</p><p>  'token_str': 'cornell',</p><p>  'sequence': 'i am a student at cornell university.'},</p><p> {'score': 0.03303062543272972,</p><p>  'token': 9173,</p><p>  'token_str': 'princeton',</p><p>  'sequence': 'i am a student at princeton university.'}]</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h3 id="Entrenamiento">
								<a class="anchor-link" href="#Entrenamiento">
									<p style="margin-left: 20px">Entrenamiento</p>
								</a>
							</h3>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Para el entrneamiento con <code><b>Optimun</b></code> hacemos lo mismo que con la inferencia con Automodel, convertimos el modelo mediante el método <code><b>transform</b></code> de <code><b>BeterTransformer</b></code>.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Cuando terminamos el entrenamiento, volvemos a convertir el modelo mediante el método <code><b>reverse</b></code> de <code><b>BeterTransformer</b></code> para volver a tener el modelo original y así poder guardarlo y subirlo al hub de Hugging Face.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">optimum.bettertransformer</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">BetterTransformer</span></p>
<p></p>
<p><span style="color: #6b97e8;">checkpoint</span> <span>=</span> <span style="color: #7e7a34;">&quot;openai-community/gpt2&quot;</span></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">model_hf</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a34;">&quot;auto&quot;</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #7f6e38;"># Convert the model to a BetterTransformer model</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">BetterTransformer</span><span>.</span><span style="color: #6b97e8;">transform</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">model_hf</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">keep_original_model</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #7f6e38;">##############################################################################</span></p>
<p><span style="color: #7f6e38;"># do your training here</span></p>
<p><span style="color: #7f6e38;">##############################################################################</span></p>
<p></p>
<p><span style="color: #7f6e38;"># Convert the model back to a Hugging Face model</span></p>
<p><span style="color: #6b97e8;">model_hf</span> <span>=</span> <span style="color: #6b97e8;">BetterTransformer</span><span>.</span><span style="color: #6b97e8;">reverse</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">model</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">model_hf</span><span>.</span><span style="color: #6b97e8;">save_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;fine_tuned_model&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">model_hf</span><span>.</span><span style="color: #6b97e8;">push_to_hub</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;fine_tuned_model&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
		</div>
	<!-- Close class contenido -->
	</div>
<!-- Close div notebook container -->
</div>
<!-- Close div notebook -->
</div>



