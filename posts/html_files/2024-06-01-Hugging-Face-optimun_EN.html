<p>
	<!-- Custom stylesheet, it must be in the same directory as the html file -->
	<!-- Loading mathjax macro --><!-- Load mathjax --><!-- MathJax configuration -->
<p>
<style>
	/* Media query para pantallas grandes */
	@media screen and (min-width: 1000px) {
		.container {
			flex-wrap: nowrap;
			display: flex;
			justify-content: space-between;
			height: 100vh; /* altura del viewport */
		}
		
		.indice {
			width: 25%; /* Ancho del índice en pantallas grandes */
			border-right: 1px solid #ccc;
			max-height: calc(100vh - 40px); /* Ajustar según tus necesidades. Aquí estamos restando el doble del padding para mantener todo visible */
			padding: 20px;
			box-sizing: border-box;
			overflow-y: auto; /* desplazamiento vertical cuando sea necesario */
		}
		
		.contenido {
			width: 70%; /* Ancho del contenido en pantallas grandes */
			max-height: calc(100vh - 40px); /* Ajustar según tus necesidades. Aquí estamos restando el doble del padding para mantener todo visible */
			padding: 20px;
			box-sizing: border-box;
			overflow-y: auto; /* desplazamiento vertical cuando sea necesario */
		}
	}
</style>
<!-- Open div notebook -->
<div id="notebook" class="border-box-sizing" tabindex="-1">
	<!-- Open div notebook container -->
	<div id="notebook-container" class="container">
		<!-- Open div indice -->
		<div class="indice">
			<!-- Open div index header -->
			<div class="cell border-box-sizing text_cell rendered">
				<h2 class="prompt input_prompt">
					<span style="
					color: var(--darkreader-text--heading-color, var(--darkreader-text--heading-2-color,
					var(--darkreader-text--headings-color)));
					font-family: var(--fontFamily); font-size: var(--fontSize);
					font-style: var(--fontStyle, inherit);
					font-weight: var(--fontWeight);
					letter-spacing: var(--letterSpacing);
					text-transform: var(--textTransform);
					background-color: transparent;
					--darkreader-inline-color: var(--darkreader-text--darkreader-text--heading-color,
					var(--darkreader-text--darkreader-text--heading-2-color, var(--darkreader-text--darkreader-text--headings-color)));
					--darkreader-inline-bgcolor: transparent;"
					data-darkreader-inline-color="" data-darkreader-inline-bgcolor="">
						Índice
					</span>
					<a class="anchor-link" style="
					font-family: var(--fontFamily);
					font-size: var(--fontSize);
					font-style: var(--fontStyle, inherit);
					font-weight: var(--fontWeight);
					letter-spacing: var(--letterSpacing);
					text-transform: var(--textTransform);
					background-color: transparent;
					--darkreader-inline-bgcolor: transparent;"
					href="#Índice" data-darkreader-inline-bgcolor="">
					</a>
				</h2>
			<!-- Close div index header -->
			</div>
			<!-- Index body -->
			<div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Installation-index">
									<a class="anchor-link" href="#Installation">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Installation</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="BeterTransformer-index">
									<a class="anchor-link" href="#BeterTransformer">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">BeterTransformer</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Inference-with-Automodel-index">
									<a class="anchor-link" href="#Inference-with-Automodel">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Inference with Automodel</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Inferecncy-with-Pipeline-index">
									<a class="anchor-link" href="#Inferecncy-with-Pipeline">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Inferecncy with Pipeline</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Training-index">
									<a class="anchor-link" href="#Training">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Training</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
			</div>
		<!-- Close div indice -->
		</div>
 
		<!-- Content -->
		<div class="contenido">
		<div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><a href="https://colab.research.google.com/github/maximofn/portafolio/blob/main/posts/notebooks_translated/2024-06-01-Hugging-Face-optimun_EN.ipynb" target="_blank"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h1 id="Hugging-Face-Optimun">
								<a class="anchor-link" href="#Hugging-Face-Optimun">
									<p style="margin-left: 0px">Hugging Face Optimun</p>
								</a>
							</h1>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Optimum is an extension of the [Transformers] library (https://maximofn.com/hugging-face-transformers/) that provides a set of performance optimization tools for training and inference models on specific hardware with maximum efficiency.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">The AI ecosystem is evolving rapidly and more specialized hardware is emerging every day along with its own optimizations. Therefore, <code><b>Optimum</b></code> allows users to efficiently utilize any of this HW with the same ease as <a href="https://maximofn.com/hugging-face-transformers/" target="_blank">Transformers</a>.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">This notebook has been automatically translated to make it accessible to more people, please let me know if you see any typos.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Optimmun` allows optimization for the following HW platforms:</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">
								<ul>
									<li>Nvidia</li>
									<li>AMD</li>
									<li>Intel</li>
									<li>AWS</li>
									<li>TPU</li>
									<li>Havana</li>
									<li>FuriosaAI</li>
								</ul>
							</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">It also offers acceleration for the following open source integrations</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">
								<ul>
									<li>ONNX runtime</li>
									<li>Exporters: Export Pytorch or TensorFlow data to different formats such as ONNX or TFLite</li>
									<li>BetterTransformer</li>
									<li>Torch FX</li>
								</ul>
							</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Installation">
								<a class="anchor-link" href="#Installation">
									<p style="margin-left: 10px">Installation</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">To install <code><b>Optimum</b></code> simply run:</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 80px;"><code>pip install optimum<br></code></p>
						</div>
					</div>
				</div>
			</div>
	
	
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">But if you want to install it with support for all HW platforms, you can do it like this</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<table>
								<tr>
									<th>Accelerator </th>
									<th>Installation</th>
								</tr>
								<tr>
									<td>ONNX Runtime </td>
									<td><code><b>pip install --upgrade --upgrade-strategy eager optimum[onnxruntime]</b></code></td>
								</tr>
								<tr>
									<td>Intel Neural Compressor </td>
									<td><code><b>pip install --upgrade --upgrade-strategy eager optimum[neural-compressor]</b></code></td>
								</tr>
								<tr>
									<td>OpenVINO </td>
									<td><code><b>pip install --upgrade --upgrade-strategy eager optimum[openvino]</b></code></td>
								</tr>
								<tr>
									<td>NVIDIA TensorRT-LLM </td>
									<td><code><b>docker run -it --gpus all --ipc host huggingface/optimum-nvidia</b></code></td>
								</tr>
								<tr>
									<td>AMD Instinct GPUs and Ryzen AI NPU </td>
									<td><code><b>pip install --upgrade --upgrade-strategy eager optimum[amd]</b></code></td>
								</tr>
								<tr>
									<td>AWS Trainum & Inferentia </td>
									<td><code><b>pip install --upgrade --upgrade-strategy eager optimum[neuronx]</b></code></td>
								</tr>
								<tr>
									<td>Havana Gaudi Processor (HPU) </td>
									<td><code><b>pip install --upgrade --upgrade-strategy eager optimum [habana]</b></code></td>
								</tr>
								<tr>
									<td>FuriosaAI </td>
									<td><code><b>pip install --upgrade --upgrade-strategy eager optimum[furiosa]</b></code></td>
								</tr>
							</table>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">the <code><b>--upgrade --upgrade-strategy eager</b></code> flags are needed to ensure that the different packages are upgraded to the latest possible version.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Since most people use Pytorch on Nvidia GPUs, and especially since Nvidia is what I have, this post is going to talk only about the use of <code><b>Optimun</b></code> with Nvidia GPUs and Pytorch.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="BeterTransformer">
								<a class="anchor-link" href="#BeterTransformer">
									<p style="margin-left: 10px">BeterTransformer</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">BetterTransformer is a native PyTorch optimization for x1.25 to x4 speedup in Transformer-based model inference.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">BetterTransformer is an API that allows you to take advantage of modern hardware features to accelerate the training and inference of transformer models in PyTorch, using more efficient and <code><b>fast path</b></code> attention implementations of the native <code><b>nn.TransformerEncoderLayer</b></code> version of <code><b>nn.TransformerEncoderLayer</b></code>.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">BetterTransformer uses two types of accelerations:</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">
								<ol>
									<li><code><b>Flash Attention</b></code>: This is an implementation of <code><b>attention</b></code> that uses <code><b>sparse</b></code> to reduce computational complexity. Attention is one of the most expensive operations in transformer models, and <code><b>Flash Attention</b></code> makes it more efficient.</li>
									<li><code><b>Memory-Efficient Attention</b></code>: This is another implementation of attention that uses the <code><b>scaled_dot_product_attention</b></code> function of PyTorch. This function is more memory-efficient than the standard PyTorch implementation of attention.</li>
								</ol>
							</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">In addition, PyTorch version 2.0 includes a native scaled point product attention operator (SDPA) as part of <code><b>torch.nn.functional</b></code>.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Optimmun provides this functionality with the <code><b>Transformers</b></code> library.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h3 id="Inference-with-Automodel">
								<a class="anchor-link" href="#Inference-with-Automodel">
									<p style="margin-left: 20px">Inference with Automodel</p>
								</a>
							</h3>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">First let's see how the normal inference would be with <code><b>Transformers</b></code> and <code><b>Automodel</b></code>.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p></p>
<p><span style="color: #6b97e8;">checkpoint</span> <span>=</span> <span style="color: #7e7a34;">&quot;openai-community/gpt2&quot;</span></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a34;">&quot;auto&quot;</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p></p>
<p><span style="color: #6b97e8;">input_tokens</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">output_tokens</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">input_tokens</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_length</span><span>=</span><span style="color: #7e7a38;">50</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">output_tokens</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>'Me encanta aprender de la vie de la vie de la vie de la vie de la vie de la vie de la vie de la vie de la vie de la vie de la vie de'</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Now we see how it would be optimized with <code><b>BetterTransformer</b></code> and <code><b>Optimun</b></code>.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">What we have to do is to convert the model using the <code><b>transform</b></code> method of <code><b>BeterTransformer</b></code>.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">optimum.bettertransformer</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">BetterTransformer</span></p>
<p></p>
<p><span style="color: #6b97e8;">checkpoint</span> <span>=</span> <span style="color: #7e7a34;">&quot;openai-community/gpt2&quot;</span></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">model_hf</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a34;">&quot;auto&quot;</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #7f6e38;"># Convert the model to a BetterTransformer model</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">BetterTransformer</span><span>.</span><span style="color: #6b97e8;">transform</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">model_hf</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">keep_original_model</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p></p>
<p><span style="color: #6b97e8;">input_tokens</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">output_tokens</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">input_tokens</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_length</span><span>=</span><span style="color: #7e7a38;">50</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">output_tokens</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>'Me encanta aprender de la vie de la vie de la vie de la vie de la vie de la vie de la vie de la vie de la vie de la vie de la vie de'</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h3 id="Inferecncy-with-Pipeline">
								<a class="anchor-link" href="#Inferecncy-with-Pipeline">
									<p style="margin-left: 20px">Inferecncy with Pipeline</p>
								</a>
							</h3>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">As before, we first see how the normal inference would be with <code><b>Transformers</b></code> and <code><b>Pipeline</b></code>.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">pipeline</span></p>
<p></p>
<p><span style="color: #6b97e8;">pipe</span> <span>=</span> <span style="color: #6b97e8;">pipeline</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">task</span><span>=</span><span style="color: #7e7a34;">&quot;fill-mask&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">model</span><span>=</span><span style="color: #7e7a34;">&quot;distilbert-base-uncased&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">pipe</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;I am a student at [MASK] University.&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>[{'score': 0.05116177722811699,</p><p>  'token': 8422,</p><p>  'token_str': 'stanford',</p><p>  'sequence': 'i am a student at stanford university.'},</p><p> {'score': 0.04033993184566498,</p><p>  'token': 5765,</p><p>  'token_str': 'harvard',</p><p>  'sequence': 'i am a student at harvard university.'},</p><p> {'score': 0.03990468755364418,</p><p>  'token': 7996,</p><p>  'token_str': 'yale',</p><p>  'sequence': 'i am a student at yale university.'},</p><p> {'score': 0.0361952930688858,</p><p>  'token': 10921,</p><p>  'token_str': 'cornell',</p><p>  'sequence': 'i am a student at cornell university.'},</p><p> {'score': 0.03303057327866554,</p><p>  'token': 9173,</p><p>  'token_str': 'princeton',</p><p>  'sequence': 'i am a student at princeton university.'}]</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Now we see how to optimize it, for this we use <code><b>pipeline</b></code> of <code><b>Optimun</b></code>, instead of <code><b>Transformers</b></code>. In addition we must indicate that we want to use <code><b>bettertransformer</b></code> as accelerator.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">optimum.pipelines</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">pipeline</span></p>
<p></p>
<p><span style="color: #7f6e38;"># Use the BetterTransformer pipeline</span></p>
<p><span style="color: #6b97e8;">pipe</span> <span>=</span> <span style="color: #6b97e8;">pipeline</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">task</span><span>=</span><span style="color: #7e7a34;">&quot;fill-mask&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">model</span><span>=</span><span style="color: #7e7a34;">&quot;distilbert-base-uncased&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">accelerator</span><span>=</span><span style="color: #7e7a34;">&quot;bettertransformer&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">pipe</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;I am a student at [MASK] University.&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>[{'score': 0.05116180703043938,</p><p>  'token': 8422,</p><p>  'token_str': 'stanford',</p><p>  'sequence': 'i am a student at stanford university.'},</p><p> {'score': 0.040340032428503036,</p><p>  'token': 5765,</p><p>  'token_str': 'harvard',</p><p>  'sequence': 'i am a student at harvard university.'},</p><p> {'score': 0.039904672652482986,</p><p>  'token': 7996,</p><p>  'token_str': 'yale',</p><p>  'sequence': 'i am a student at yale university.'},</p><p> {'score': 0.036195311695337296,</p><p>  'token': 10921,</p><p>  'token_str': 'cornell',</p><p>  'sequence': 'i am a student at cornell university.'},</p><p> {'score': 0.03303062543272972,</p><p>  'token': 9173,</p><p>  'token_str': 'princeton',</p><p>  'sequence': 'i am a student at princeton university.'}]</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h3 id="Training">
								<a class="anchor-link" href="#Training">
									<p style="margin-left: 20px">Training</p>
								</a>
							</h3>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">For training with <code><b>Optimun</b></code> we do the same as with Automodel inference, we convert the model using the <code><b>transform</b></code> method of <code><b>BeterTransformer</b></code>.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">When we finish the training, we convert the model back using the <code><b>reverse</b></code> method of <code><b>BeterTransformer</b></code> to get the original model back so we can save it and upload it to the Hugging Face hub.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">optimum.bettertransformer</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">BetterTransformer</span></p>
<p></p>
<p><span style="color: #6b97e8;">checkpoint</span> <span>=</span> <span style="color: #7e7a34;">&quot;openai-community/gpt2&quot;</span></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">model_hf</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a34;">&quot;auto&quot;</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #7f6e38;"># Convert the model to a BetterTransformer model</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">BetterTransformer</span><span>.</span><span style="color: #6b97e8;">transform</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">model_hf</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">keep_original_model</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #7f6e38;">##############################################################################</span></p>
<p><span style="color: #7f6e38;"># do your training here</span></p>
<p><span style="color: #7f6e38;">##############################################################################</span></p>
<p></p>
<p><span style="color: #7f6e38;"># Convert the model back to a Hugging Face model</span></p>
<p><span style="color: #6b97e8;">model_hf</span> <span>=</span> <span style="color: #6b97e8;">BetterTransformer</span><span>.</span><span style="color: #6b97e8;">reverse</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">model</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">model_hf</span><span>.</span><span style="color: #6b97e8;">save_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;fine_tuned_model&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">model_hf</span><span>.</span><span style="color: #6b97e8;">push_to_hub</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;fine_tuned_model&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
		</div>
	<!-- Close class contenido -->
	</div>
<!-- Close div notebook container -->
</div>
<!-- Close div notebook -->
</div>



