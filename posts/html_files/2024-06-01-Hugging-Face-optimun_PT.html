<p>
	<!-- Custom stylesheet, it must be in the same directory as the html file -->
	<!-- Loading mathjax macro --><!-- Load mathjax --><!-- MathJax configuration -->
<p>
<style>
	/* Media query para pantallas grandes */
	@media screen and (min-width: 1000px) {
		.container {
			flex-wrap: nowrap;
			display: flex;
			justify-content: space-between;
			height: 100vh; /* altura del viewport */
		}
		
		.indice {
			width: 25%; /* Ancho del índice en pantallas grandes */
			border-right: 1px solid #ccc;
			max-height: calc(100vh - 40px); /* Ajustar según tus necesidades. Aquí estamos restando el doble del padding para mantener todo visible */
			padding: 20px;
			box-sizing: border-box;
			overflow-y: auto; /* desplazamiento vertical cuando sea necesario */
		}
		
		.contenido {
			width: 70%; /* Ancho del contenido en pantallas grandes */
			max-height: calc(100vh - 40px); /* Ajustar según tus necesidades. Aquí estamos restando el doble del padding para mantener todo visible */
			padding: 20px;
			box-sizing: border-box;
			overflow-y: auto; /* desplazamiento vertical cuando sea necesario */
		}
	}
</style>
<!-- Open div notebook -->
<div id="notebook" class="border-box-sizing" tabindex="-1">
	<!-- Open div notebook container -->
	<div id="notebook-container" class="container">
		<!-- Open div indice -->
		<div class="indice">
			<!-- Open div index header -->
			<div class="cell border-box-sizing text_cell rendered">
				<h2 class="prompt input_prompt">
					<span style="
					color: var(--darkreader-text--heading-color, var(--darkreader-text--heading-2-color,
					var(--darkreader-text--headings-color)));
					font-family: var(--fontFamily); font-size: var(--fontSize);
					font-style: var(--fontStyle, inherit);
					font-weight: var(--fontWeight);
					letter-spacing: var(--letterSpacing);
					text-transform: var(--textTransform);
					background-color: transparent;
					--darkreader-inline-color: var(--darkreader-text--darkreader-text--heading-color,
					var(--darkreader-text--darkreader-text--heading-2-color, var(--darkreader-text--darkreader-text--headings-color)));
					--darkreader-inline-bgcolor: transparent;"
					data-darkreader-inline-color="" data-darkreader-inline-bgcolor="">
						Índice
					</span>
					<a class="anchor-link" style="
					font-family: var(--fontFamily);
					font-size: var(--fontSize);
					font-style: var(--fontStyle, inherit);
					font-weight: var(--fontWeight);
					letter-spacing: var(--letterSpacing);
					text-transform: var(--textTransform);
					background-color: transparent;
					--darkreader-inline-bgcolor: transparent;"
					href="#Índice" data-darkreader-inline-bgcolor="">
					</a>
				</h2>
			<!-- Close div index header -->
			</div>
			<!-- Index body -->
			<div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Instalação-index">
									<a class="anchor-link" href="#Instalação">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Instalação</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="BeterTransformer-index">
									<a class="anchor-link" href="#BeterTransformer">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">BeterTransformer</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Inferência-com-modelo-automático-index">
									<a class="anchor-link" href="#Inferência-com-modelo-automático">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Inferência com modelo automático</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Inferências-com-o-pipeline-index">
									<a class="anchor-link" href="#Inferências-com-o-pipeline">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Inferências com o pipeline</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Treinamento-index">
									<a class="anchor-link" href="#Treinamento">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Treinamento</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
			</div>
		<!-- Close div indice -->
		</div>
 
		<!-- Content -->
		<div class="contenido">
		<div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><a href="https://colab.research.google.com/github/maximofn/portafolio/blob/main/posts/notebooks_translated/2024-06-01-Hugging-Face-optimun_PT.ipynb" target="_blank"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h1 id="Otimização-do-rosto-de-abraços">
								<a class="anchor-link" href="#Otimização-do-rosto-de-abraços">
									<p style="margin-left: 0px">Otimização do rosto de abraços</p>
								</a>
							</h1>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Optimum é uma extensão da biblioteca [Transformers] (https://maximofn.com/hugging-face-transformers/) que fornece um conjunto de ferramentas de otimização de desempenho para modelos de treinamento e inferência, em hardware específico, com eficiência máxima.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">O ecossistema de IA está evoluindo rapidamente e cada vez mais hardware especializado está surgindo todos os dias, juntamente com suas próprias otimizações. Portanto, o <code><b>Optimum</b></code> permite que os usuários utilizem eficientemente qualquer um desses HW com a mesma facilidade dos [Transformers] (https://maximofn.com/hugging-face-transformers/).</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Este caderno foi traduzido automaticamente para torná-lo acessível a mais pessoas, por favor me avise se você vir algum erro de digitação..</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">A otimização para as seguintes plataformas HW é possível com o <code><b>Optimun</b></code>:</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">
								<ul>
									<li>Nvidia</li>
									<li>AMD</li>
									<li>Intel</li>
									<li>AWS</li>
									<li>TPU</li>
									<li>Havana</li>
									<li>FuriosaAI</li>
								</ul>
							</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Além disso, ele oferece aceleração para as seguintes integrações de código aberto</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">
								<ul>
									<li>Tempo de execução do ONNX</li>
									<li>Exportadores: exportam dados do Pytorch ou do TensorFlow para diferentes formatos, como ONNX ou TFLite.</li>
									<li>Melhor transformador</li>
									<li>Tocha FX</li>
								</ul>
							</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Instalação">
								<a class="anchor-link" href="#Instalação">
									<p style="margin-left: 10px">Instalação</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Para instalar o <code><b>Optimum</b></code>, basta executar:</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 80px;"><code>pip install optimum<br></code></p>
						</div>
					</div>
				</div>
			</div>
	
	
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Mas se quiser instalá-lo com suporte para todas as plataformas HW, você pode fazer o seguinte</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<table>
								<tr>
									<th>Accelerator </th>
									<th>Instalação</th>
								</tr>
								<tr>
									<td>ONNX Runtime </td>
									<td><code><b>pip install --upgrade --upgrade-strategy eager optimum[onnxruntime]</b></code></td>
								</tr>
								<tr>
									<td>Intel Neural Compressor </td>
									<td><code><b>pip install --upgrade --upgrade-strategy eager optimum[neural-compressor]</b></code></td>
								</tr>
								<tr>
									<td>OpenVINO </td>
									<td><code><b>pip install --upgrade --upgrade-strategy eager optimum[openvino]</b></code></td>
								</tr>
								<tr>
									<td>NVIDIA TensorRT-LLM </td>
									<td><code><b>docker run -it --gpus all --ipc host huggingface/optimum-nvidia</b></code></td>
								</tr>
								<tr>
									<td>AMD Instinct GPUs e Ryzen AI NPU </td>
									<td><code><b>pip install --upgrade --upgrade-strategy eager optimum[amd]</b></code></td>
								</tr>
								<tr>
									<td>AWS Trainum & Inferentia </td>
									<td><code><b>pip install --upgrade --upgrade-strategy eager optimum[neuronx]</b></code></td>
								</tr>
								<tr>
									<td>Havana Gaudi Processor (HPU) </td>
									<td><code><b>pip install --upgrade --upgrade-strategy eager optimum [habana]</b></code></td>
								</tr>
								<tr>
									<td>FuriosaAI </td>
									<td><code><b>pip install --upgrade --upgrade-strategy eager optimum[furiosa]</b></code></td>
								</tr>
							</table>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Os sinalizadores <code><b>--upgrade --upgrade-strategy eager</b></code> são necessários para garantir que os diferentes pacotes sejam atualizados para a versão mais recente possível.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Como a maioria das pessoas usa o Pytorch em GPUs Nvidia e, especialmente, como eu tenho uma Nvidia, esta postagem falará apenas sobre o uso do <code><b>Optimun</b></code> com GPUs Nvidia e Pytorch.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="BeterTransformer">
								<a class="anchor-link" href="#BeterTransformer">
									<p style="margin-left: 10px">BeterTransformer</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">O BetterTransformer é uma otimização nativa do PyTorch para aumentar a velocidade de 1,25 a 4 vezes na inferência de modelo baseada no Transformer.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">BetterTransformer é uma API que permite que você aproveite os recursos modernos de hardware para acelerar o treinamento e a inferência de modelos de transformadores no PyTorch, usando implementações mais eficientes e com atenção ao "caminho rápido" da versão nativa <code><b>nn.TransformerEncoderLayer</b></code> do <code><b>nn.TransformerEncoderLayer</b></code>.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">O BetterTransformer usa dois tipos de acelerações:</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">
								<ol>
									<li><code><b>Flash Attention</b></code>: é uma implementação do <code><b>attention</b></code> que usa o <code><b>sparse</b></code> para reduzir a complexidade computacional. A atenção é uma das operações mais caras nos modelos de transformadores, e o <code><b>Flash Attention</b></code> a torna mais eficiente.</li>
									<li><code><b>Memory-Efficient Attention</b></code>: essa é outra implementação de atenção que usa a função <code><b>scaled_dot_product_attention</b></code> do PyTorch. Essa função é mais eficiente em termos de memória do que a implementação padrão de atenção do PyTorch.</li>
								</ol>
							</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Além disso, a versão 2.0 do PyTorch inclui um operador de atenção de produto de ponto escalonado (SDPA) nativo como parte do <code><b>torch.nn.functional</b></code>.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">O Optimmun fornece essa funcionalidade com a biblioteca <code><b>Transformers</b></code>.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h3 id="Inferência-com-modelo-automático">
								<a class="anchor-link" href="#Inferência-com-modelo-automático">
									<p style="margin-left: 20px">Inferência com modelo automático</p>
								</a>
							</h3>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Primeiro, vamos ver como seria a inferência normal com <code><b>Transformers</b></code> e <code><b>Automodel</b></code>.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p></p>
<p><span style="color: #6b97e8;">checkpoint</span> <span>=</span> <span style="color: #7e7a34;">&quot;openai-community/gpt2&quot;</span></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a34;">&quot;auto&quot;</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p></p>
<p><span style="color: #6b97e8;">input_tokens</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">output_tokens</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">input_tokens</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_length</span><span>=</span><span style="color: #7e7a38;">50</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">output_tokens</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>'Me encanta aprender de la vie de la vie de la vie de la vie de la vie de la vie de la vie de la vie de la vie de la vie de la vie de'</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Agora, veremos como ele seria otimizado com o <code><b>BetterTransformer</b></code> e o <code><b>Optimun</b></code>.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">O que temos que fazer é converter o modelo usando o método <code><b>transform</b></code> do <code><b>BeterTransformer</b></code>.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">optimum.bettertransformer</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">BetterTransformer</span></p>
<p></p>
<p><span style="color: #6b97e8;">checkpoint</span> <span>=</span> <span style="color: #7e7a34;">&quot;openai-community/gpt2&quot;</span></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">model_hf</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a34;">&quot;auto&quot;</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #7f6e38;"># Convert the model to a BetterTransformer model</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">BetterTransformer</span><span>.</span><span style="color: #6b97e8;">transform</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">model_hf</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">keep_original_model</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p></p>
<p><span style="color: #6b97e8;">input_tokens</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">([</span><span style="color: #7e7a34;">&quot;Me encanta aprender de&quot;</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">padding</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">output_tokens</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">input_tokens</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_length</span><span>=</span><span style="color: #7e7a38;">50</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">sentence_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">output_tokens</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">sentence_output</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>'Me encanta aprender de la vie de la vie de la vie de la vie de la vie de la vie de la vie de la vie de la vie de la vie de la vie de'</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h3 id="Inferências-com-o-pipeline">
								<a class="anchor-link" href="#Inferências-com-o-pipeline">
									<p style="margin-left: 20px">Inferências com o pipeline</p>
								</a>
							</h3>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Como antes, primeiro vemos como seria a inferência normal com <code><b>Transformers</b></code> e <code><b>Pipeline</b></code>.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">pipeline</span></p>
<p></p>
<p><span style="color: #6b97e8;">pipe</span> <span>=</span> <span style="color: #6b97e8;">pipeline</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">task</span><span>=</span><span style="color: #7e7a34;">&quot;fill-mask&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">model</span><span>=</span><span style="color: #7e7a34;">&quot;distilbert-base-uncased&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">pipe</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;I am a student at [MASK] University.&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>[{'score': 0.05116177722811699,</p><p>  'token': 8422,</p><p>  'token_str': 'stanford',</p><p>  'sequence': 'i am a student at stanford university.'},</p><p> {'score': 0.04033993184566498,</p><p>  'token': 5765,</p><p>  'token_str': 'harvard',</p><p>  'sequence': 'i am a student at harvard university.'},</p><p> {'score': 0.03990468755364418,</p><p>  'token': 7996,</p><p>  'token_str': 'yale',</p><p>  'sequence': 'i am a student at yale university.'},</p><p> {'score': 0.0361952930688858,</p><p>  'token': 10921,</p><p>  'token_str': 'cornell',</p><p>  'sequence': 'i am a student at cornell university.'},</p><p> {'score': 0.03303057327866554,</p><p>  'token': 9173,</p><p>  'token_str': 'princeton',</p><p>  'sequence': 'i am a student at princeton university.'}]</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Agora veremos como otimizá-lo, de modo que usaremos <code><b>pipeline</b></code> do <code><b>Optimun</b></code>, em vez de <code><b>Transformers</b></code>. Também devemos indicar que queremos usar o <code><b>bettertransformer</b></code> como acelerador.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">optimum.pipelines</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">pipeline</span></p>
<p></p>
<p><span style="color: #7f6e38;"># Use the BetterTransformer pipeline</span></p>
<p><span style="color: #6b97e8;">pipe</span> <span>=</span> <span style="color: #6b97e8;">pipeline</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">task</span><span>=</span><span style="color: #7e7a34;">&quot;fill-mask&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">model</span><span>=</span><span style="color: #7e7a34;">&quot;distilbert-base-uncased&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">accelerator</span><span>=</span><span style="color: #7e7a34;">&quot;bettertransformer&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">pipe</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;I am a student at [MASK] University.&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>[{'score': 0.05116180703043938,</p><p>  'token': 8422,</p><p>  'token_str': 'stanford',</p><p>  'sequence': 'i am a student at stanford university.'},</p><p> {'score': 0.040340032428503036,</p><p>  'token': 5765,</p><p>  'token_str': 'harvard',</p><p>  'sequence': 'i am a student at harvard university.'},</p><p> {'score': 0.039904672652482986,</p><p>  'token': 7996,</p><p>  'token_str': 'yale',</p><p>  'sequence': 'i am a student at yale university.'},</p><p> {'score': 0.036195311695337296,</p><p>  'token': 10921,</p><p>  'token_str': 'cornell',</p><p>  'sequence': 'i am a student at cornell university.'},</p><p> {'score': 0.03303062543272972,</p><p>  'token': 9173,</p><p>  'token_str': 'princeton',</p><p>  'sequence': 'i am a student at princeton university.'}]</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h3 id="Treinamento">
								<a class="anchor-link" href="#Treinamento">
									<p style="margin-left: 20px">Treinamento</p>
								</a>
							</h3>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Para o treinamento com <code><b>Optimun</b></code>, fazemos o mesmo que com a inferência Automodel, convertemos o modelo usando o método <code><b>transform</b></code> do <code><b>BeterTransformer</b></code>.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Quando terminamos o treinamento, convertemos o modelo novamente usando o método <code><b>reverse</b></code> do <code><b>BeterTransformer</b></code> para obter o modelo original de volta, para que possamos salvá-lo e carregá-lo no hub Hugging Face.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">optimum.bettertransformer</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">BetterTransformer</span></p>
<p></p>
<p><span style="color: #6b97e8;">checkpoint</span> <span>=</span> <span style="color: #7e7a34;">&quot;openai-community/gpt2&quot;</span></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">model_hf</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a34;">&quot;auto&quot;</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #7f6e38;"># Convert the model to a BetterTransformer model</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">BetterTransformer</span><span>.</span><span style="color: #6b97e8;">transform</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">model_hf</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">keep_original_model</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #7f6e38;">##############################################################################</span></p>
<p><span style="color: #7f6e38;"># do your training here</span></p>
<p><span style="color: #7f6e38;">##############################################################################</span></p>
<p></p>
<p><span style="color: #7f6e38;"># Convert the model back to a Hugging Face model</span></p>
<p><span style="color: #6b97e8;">model_hf</span> <span>=</span> <span style="color: #6b97e8;">BetterTransformer</span><span>.</span><span style="color: #6b97e8;">reverse</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">model</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">model_hf</span><span>.</span><span style="color: #6b97e8;">save_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;fine_tuned_model&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">model_hf</span><span>.</span><span style="color: #6b97e8;">push_to_hub</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;fine_tuned_model&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
		</div>
	<!-- Close class contenido -->
	</div>
<!-- Close div notebook container -->
</div>
<!-- Close div notebook -->
</div>



