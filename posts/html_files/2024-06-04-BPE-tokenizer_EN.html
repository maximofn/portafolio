<section class="section-block-markdown-cell">
<h1 id="BPE-tokenizer">BPE tokenizer<a class="anchor-link" href="#BPE-tokenizer">¶</a></h1>
</section>
<section class="section-block-markdown-cell">
<p>This notebook has been automatically translated to make it accessible to more people, please let me know if you see any typos.</p>
</section>
<section class="section-block-markdown-cell">
<p>The <code>BPE</code> (Byte Pair Encoding) tokenizer is a data compression algorithm used to create a vocabulary of subwords from a corpus of text. This algorithm is based on the frequency of byte pairs in the text. It became popular because it was used as a tokenizer by LLMs such as GPT, GPT-2, RoBERTa, BART and DeBERTa.</p>
</section>
<section class="section-block-markdown-cell">
<h2 id="Training-algorithm">Training algorithm<a class="anchor-link" href="#Training-algorithm">¶</a></h2>
</section>
<section class="section-block-markdown-cell">
<p>Suppose we have a text corpus containing only the following words <code>hug, pug, pun, bun and hugs</code>, the first step is to create a vocabulary with all the characters present in the corpus, in our case it will be <code>b, g, h, n, p, s, u</code>.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">corpus_words</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"hug"</span><span class="p">,</span> <span class="s2">"pug"</span><span class="p">,</span> <span class="s2">"pun"</span><span class="p">,</span> <span class="s2">"bun"</span><span class="p">,</span> <span class="s2">"hugs"</span><span class="p">]</span>

<span class="c1"># Concatenate all the words in the corpus</span>
<span class="n">initial_corpus_tokens</span> <span class="o">=</span> <span class="s2">""</span>
<span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">corpus_words</span><span class="p">:</span>
    <span class="n">initial_corpus_tokens</span> <span class="o">+=</span> <span class="n">word</span>

<span class="c1"># Convert the concatenated string to a set of tokens to get unique tokens</span>
<span class="n">initial_corpus_tokens</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">initial_corpus_tokens</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Corpus words: </span><span class="si">{</span><span class="n">corpus_words</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Initial corpus tokens: </span><span class="si">{</span><span class="n">initial_corpus_tokens</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Number of initial corpus tokens: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">initial_corpus_tokens</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Corpus words: ['hug', 'pug', 'pun', 'bun', 'hugs']
Initial corpus tokens: {'p', 'n', 'u', 's', 'h', 'g', 'b'}
Number of initial corpus tokens: 7
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Now let's suppose that this is our corpus of sentences, it is an invented corpus, it does not make sense</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">corpus</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">"hug hug hug pun pun bun hugs"</span><span class="p">,</span>
    <span class="s2">"hug hug pug pug pun pun hugs"</span><span class="p">,</span>
    <span class="s2">"hug hug pug pug pun pun pun pun hugs"</span><span class="p">,</span>
    <span class="s2">"pug pun pun pun bun hugs"</span><span class="p">,</span>
    <span class="s2">"hug hug hug pun bun bun hugs"</span><span class="p">,</span>
<span class="p">]</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Let's count the number of times each word appears in the corpus, to check that what we had put before is correct.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">num_hug</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">num_pug</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">num_pun</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">num_bun</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">num_hugs</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">corpus</span><span class="p">:</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">" "</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">word</span> <span class="o">==</span> <span class="s2">"hug"</span><span class="p">:</span>
            <span class="n">num_hug</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">elif</span> <span class="n">word</span> <span class="o">==</span> <span class="s2">"pug"</span><span class="p">:</span>
            <span class="n">num_pug</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">elif</span> <span class="n">word</span> <span class="o">==</span> <span class="s2">"pun"</span><span class="p">:</span>
            <span class="n">num_pun</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">elif</span> <span class="n">word</span> <span class="o">==</span> <span class="s2">"bun"</span><span class="p">:</span>
            <span class="n">num_bun</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">elif</span> <span class="n">word</span> <span class="o">==</span> <span class="s2">"hugs"</span><span class="p">:</span>
            <span class="n">num_hugs</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Number of hug: </span><span class="si">{</span><span class="n">num_hug</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Number of pug: </span><span class="si">{</span><span class="n">num_pug</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Number of pun: </span><span class="si">{</span><span class="n">num_pun</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Number of bun: </span><span class="si">{</span><span class="n">num_bun</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Number of hugs: </span><span class="si">{</span><span class="n">num_hugs</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Number of hug: 10
Number of pug: 5
Number of pun: 12
Number of bun: 4
Number of hugs: 5
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Everything we have told you is fine, we can go on</p>
</section>
<section class="section-block-markdown-cell">
<p>We will create a dictionary with the tokens of each word and the number of times it appears in the corpus.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">dict_tokens_by_word_appearance</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"hug"</span><span class="p">:</span>
        <span class="p">{</span>
            <span class="s2">"count"</span><span class="p">:</span> <span class="n">num_hug</span><span class="p">,</span>
            <span class="s2">"tokens"</span><span class="p">:</span> <span class="p">[</span><span class="n">character</span> <span class="k">for</span> <span class="n">character</span> <span class="ow">in</span> <span class="s2">"hug"</span><span class="p">],</span>
        <span class="p">},</span>
    <span class="s2">"pug"</span><span class="p">:</span>
        <span class="p">{</span>
            <span class="s2">"count"</span><span class="p">:</span> <span class="n">num_pug</span><span class="p">,</span>
            <span class="s2">"tokens"</span><span class="p">:</span> <span class="p">[</span><span class="n">character</span> <span class="k">for</span> <span class="n">character</span> <span class="ow">in</span> <span class="s2">"pug"</span><span class="p">],</span>
        <span class="p">},</span>
    <span class="s2">"pun"</span><span class="p">:</span>
        <span class="p">{</span>
            <span class="s2">"count"</span><span class="p">:</span> <span class="n">num_pun</span><span class="p">,</span>
            <span class="s2">"tokens"</span><span class="p">:</span> <span class="p">[</span><span class="n">character</span> <span class="k">for</span> <span class="n">character</span> <span class="ow">in</span> <span class="s2">"pun"</span><span class="p">],</span>
        <span class="p">},</span>
    <span class="s2">"bun"</span><span class="p">:</span>
        <span class="p">{</span>
            <span class="s2">"count"</span><span class="p">:</span> <span class="n">num_bun</span><span class="p">,</span>
            <span class="s2">"tokens"</span><span class="p">:</span> <span class="p">[</span><span class="n">character</span> <span class="k">for</span> <span class="n">character</span> <span class="ow">in</span> <span class="s2">"bun"</span><span class="p">],</span>
        <span class="p">},</span>
    <span class="s2">"hugs"</span><span class="p">:</span>
        <span class="p">{</span>
            <span class="s2">"count"</span><span class="p">:</span> <span class="n">num_hugs</span><span class="p">,</span>
            <span class="s2">"tokens"</span><span class="p">:</span> <span class="p">[</span><span class="n">character</span> <span class="k">for</span> <span class="n">character</span> <span class="ow">in</span> <span class="s2">"hugs"</span><span class="p">],</span>
        <span class="p">},</span>
<span class="p">}</span>

<span class="n">dict_tokens_by_word_appearance</span>
</pre></div>
</div>
<div class="output-wrapper">
<div class="output-area">
<div class="prompt-output-prompt">Out[25]:</div>
<div class="output-text-output-subareaoutput_execute_result">
<pre>{'hug': {'count': 10, 'tokens': ['h', 'u', 'g']},
 'pug': {'count': 5, 'tokens': ['p', 'u', 'g']},
 'pun': {'count': 12, 'tokens': ['p', 'u', 'n']},
 'bun': {'count': 4, 'tokens': ['b', 'u', 'n']},
 'hugs': {'count': 5, 'tokens': ['h', 'u', 'g', 's']}}</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Now let's look for the pair of consecutive tokens that appears most often in the dictionary</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">dict_keys</span> <span class="o">=</span> <span class="n">dict_tokens_by_word_appearance</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>

<span class="n">list_consecutive_tokens</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dict_keys</span><span class="p">):</span>
    <span class="c1"># Get the tokens of the word</span>
    <span class="n">number_of_toneks_of_word</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dict_tokens_by_word_appearance</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="s2">"tokens"</span><span class="p">])</span>

    <span class="c1"># Get consecituve tokens</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">number_of_toneks_of_word</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="c1"># Get consecutive tokens</span>
        <span class="n">consecutive_tokens</span> <span class="o">=</span> <span class="n">dict_tokens_by_word_appearance</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="s2">"tokens"</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">dict_tokens_by_word_appearance</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="s2">"tokens"</span><span class="p">][</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
        <span class="c1"># Append the consecutive tokens to the list the number of times the word appears</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">dict_tokens_by_word_appearance</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="s2">"count"</span><span class="p">]):</span>
            <span class="n">list_consecutive_tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">consecutive_tokens</span><span class="p">)</span>
<span class="c1"># Print the list of consecutive tokens</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"List of consecutive tokens: </span><span class="si">{</span><span class="n">list_consecutive_tokens</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Get consecutive tokens with maximum frequency</span>
<span class="n">dict_consecutive_tokens</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">list_consecutive_tokens</span><span class="p">:</span>
    <span class="c1"># Check if the token is already in the dictionary</span>
    <span class="k">if</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">dict_consecutive_tokens</span><span class="p">:</span>
        <span class="c1"># Increment the count of the token</span>
        <span class="n">dict_consecutive_tokens</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
    
    <span class="c1"># If the token is not in the dictionary</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Add the token to the dictionary</span>
        <span class="n">dict_consecutive_tokens</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># Print the dictionary of consecutive tokens</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Dictionary of consecutive tokens: </span><span class="si">{</span><span class="n">dict_consecutive_tokens</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Get the consecutive token with maximum frequency</span>
<span class="n">max_consecutive_token</span> <span class="o">=</span> <span class="kc">None</span>
<span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
    <span class="c1"># Get the token with maximum frequency</span>
    <span class="n">consecutive_token</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">dict_consecutive_tokens</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">dict_consecutive_tokens</span><span class="o">.</span><span class="n">get</span><span class="p">)</span>

    <span class="c1"># Check if the token is already in the list of tokens</span>
    <span class="k">if</span> <span class="n">consecutive_token</span> <span class="ow">in</span> <span class="n">initial_corpus_tokens</span><span class="p">:</span>
        <span class="c1"># Remove token from the dictionary</span>
        <span class="n">dict_consecutive_tokens</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">consecutive_token</span><span class="p">)</span>

    <span class="c1"># If the token is not in the list of tokens</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Assign the token to the max_consecutive_token</span>
        <span class="n">max_consecutive_token</span> <span class="o">=</span> <span class="n">consecutive_token</span>
        <span class="k">break</span>

<span class="c1"># Print the consecutive token with maximum frequency</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Consecutive token with maximum frequency: </span><span class="si">{</span><span class="n">max_consecutive_token</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>List of consecutive tokens: ['hu', 'hu', 'hu', 'hu', 'hu', 'hu', 'hu', 'hu', 'hu', 'hu', 'ug', 'ug', 'ug', 'ug', 'ug', 'ug', 'ug', 'ug', 'ug', 'ug', 'pu', 'pu', 'pu', 'pu', 'pu', 'ug', 'ug', 'ug', 'ug', 'ug', 'pu', 'pu', 'pu', 'pu', 'pu', 'pu', 'pu', 'pu', 'pu', 'pu', 'pu', 'pu', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'bu', 'bu', 'bu', 'bu', 'un', 'un', 'un', 'un', 'hu', 'hu', 'hu', 'hu', 'hu', 'ug', 'ug', 'ug', 'ug', 'ug', 'gs', 'gs', 'gs', 'gs', 'gs']
Dictionary of consecutive tokens: {'hu': 15, 'ug': 20, 'pu': 17, 'un': 16, 'bu': 4, 'gs': 5}
Consecutive token with maximum frequency: ug
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>We have obtained the pair of tokens that appears the most times. We are going to encapsulate this in a function because we are going to use it more times.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_consecutive_tokens_with_max_frequency</span><span class="p">(</span><span class="n">dict_tokens_by_word_appearance</span><span class="p">,</span> <span class="n">list_corpus_tokens</span><span class="p">):</span>
    <span class="n">dict_keys</span> <span class="o">=</span> <span class="n">dict_tokens_by_word_appearance</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>

    <span class="n">list_consecutive_tokens</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dict_keys</span><span class="p">):</span>
        <span class="c1"># Get the tokens of the word</span>
        <span class="n">number_of_toneks_of_word</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dict_tokens_by_word_appearance</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="s2">"tokens"</span><span class="p">])</span>

        <span class="c1"># Get consecituve tokens</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">number_of_toneks_of_word</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="c1"># Get consecutive tokens</span>
            <span class="n">consecutive_tokens</span> <span class="o">=</span> <span class="n">dict_tokens_by_word_appearance</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="s2">"tokens"</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">dict_tokens_by_word_appearance</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="s2">"tokens"</span><span class="p">][</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
            <span class="c1"># Append the consecutive tokens to the list</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">dict_tokens_by_word_appearance</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="s2">"count"</span><span class="p">]):</span>
                <span class="n">list_consecutive_tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">consecutive_tokens</span><span class="p">)</span>

    <span class="c1"># Get consecutive tokens with maximum frequency</span>
    <span class="n">dict_consecutive_tokens</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">list_consecutive_tokens</span><span class="p">:</span>
        <span class="c1"># Check if the token is already in the dictionary</span>
        <span class="k">if</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">dict_consecutive_tokens</span><span class="p">:</span>
            <span class="c1"># Increment the count of the token</span>
            <span class="n">dict_consecutive_tokens</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        
        <span class="c1"># If the token is not in the dictionary</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Add the token to the dictionary</span>
            <span class="n">dict_consecutive_tokens</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="c1"># Get the consecutive token with maximum frequency</span>
    <span class="n">max_consecutive_token</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="c1"># Get the token with maximum frequency</span>
        <span class="n">consecutive_token</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">dict_consecutive_tokens</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">dict_consecutive_tokens</span><span class="o">.</span><span class="n">get</span><span class="p">)</span>

        <span class="c1"># Check if the token is already in the list of tokens</span>
        <span class="k">if</span> <span class="n">consecutive_token</span> <span class="ow">in</span> <span class="n">list_corpus_tokens</span><span class="p">:</span>
            <span class="c1"># Remove token from the dictionary</span>
            <span class="n">dict_consecutive_tokens</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">consecutive_token</span><span class="p">)</span>

        <span class="c1"># If the token is not in the list of tokens</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Assign the token to the max_consecutive_token</span>
            <span class="n">max_consecutive_token</span> <span class="o">=</span> <span class="n">consecutive_token</span>
            <span class="k">break</span>

    <span class="k">return</span> <span class="n">max_consecutive_token</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>We check that we get the same as before</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">max_consecutive_token</span> <span class="o">=</span> <span class="n">get_consecutive_tokens_with_max_frequency</span><span class="p">(</span><span class="n">dict_tokens_by_word_appearance</span><span class="p">,</span> <span class="n">initial_corpus_tokens</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Consecutive token with maximum frequency: </span><span class="si">{</span><span class="n">max_consecutive_token</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Consecutive token with maximum frequency: ug
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>We see that yes</p>
</section>
<section class="section-block-markdown-cell">
<p>Now our token corpus can be modified by adding the token <code>ug</code>.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># new_corpus_tokens = initial_corpus_tokens + max_consecutive_token</span>
<span class="n">new_corpus_tokens</span> <span class="o">=</span> <span class="n">initial_corpus_tokens</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">new_corpus_tokens</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">max_consecutive_token</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Initial corpus tokens: </span><span class="si">{</span><span class="n">initial_corpus_tokens</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"New corpus tokens: </span><span class="si">{</span><span class="n">new_corpus_tokens</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Initial corpus tokens: {'p', 'n', 'u', 's', 'h', 'g', 'b'}
New corpus tokens: {'p', 'n', 'ug', 'g', 'b', 'u', 's', 'h'}
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>We also put this in a function</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_new_corpus_tokens</span><span class="p">(</span><span class="n">max_consecutive_token</span><span class="p">,</span> <span class="n">initial_corpus_tokens</span><span class="p">):</span>
    <span class="n">new_corpus_tokens</span> <span class="o">=</span> <span class="n">initial_corpus_tokens</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">new_corpus_tokens</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">max_consecutive_token</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">new_corpus_tokens</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>We will check again that we obtain the same as before</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">new_corpus_tokens</span> <span class="o">=</span> <span class="n">get_new_corpus_tokens</span><span class="p">(</span><span class="n">max_consecutive_token</span><span class="p">,</span> <span class="n">initial_corpus_tokens</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Initial corpus tokens: </span><span class="si">{</span><span class="n">initial_corpus_tokens</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"New corpus tokens: </span><span class="si">{</span><span class="n">new_corpus_tokens</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Initial corpus tokens: {'p', 'n', 'u', 's', 'h', 'g', 'b'}
New corpus tokens: {'p', 'n', 'ug', 'g', 'b', 'u', 's', 'h'}
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>We see that yes</p>
</section>
<section class="section-block-markdown-cell">
<p>Now we are going to modify the dictionary where the words appear, the tokens and the number of times they appear with the new token</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">copy</span>

<span class="n">dict_keys</span> <span class="o">=</span> <span class="n">dict_tokens_by_word_appearance</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
<span class="n">dict_tokens_by_word_appearance_tmp</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">dict_tokens_by_word_appearance</span><span class="p">)</span>

<span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">dict_keys</span><span class="p">:</span>
    <span class="c1"># Check if the new token is in the word</span>
    <span class="k">if</span> <span class="n">max_consecutive_token</span> <span class="ow">in</span> <span class="n">key</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Token </span><span class="si">{</span><span class="n">max_consecutive_token</span><span class="si">}</span><span class="s2"> is in the word </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

        <span class="c1"># Add the new token to the word tokens</span>
        <span class="n">dict_tokens_by_word_appearance_tmp</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="s2">"tokens"</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">max_consecutive_token</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"New tokens of the word </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">dict_tokens_by_word_appearance_tmp</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="s1">'tokens'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Initial tokens by word appearance: </span><span class="si">{</span><span class="n">dict_tokens_by_word_appearance</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"New tokens by word appearance: "</span><span class="p">)</span>
<span class="n">dict_tokens_by_word_appearance_tmp</span>
</pre></div>
</div>
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Token ug is in the word hug
New tokens of the word hug: ['h', 'u', 'g', 'ug']
Token ug is in the word pug
New tokens of the word pug: ['p', 'u', 'g', 'ug']
Token ug is in the word hugs
New tokens of the word hugs: ['h', 'u', 'g', 's', 'ug']
Initial tokens by word appearance: {'hug': {'count': 10, 'tokens': ['h', 'u', 'g']}, 'pug': {'count': 5, 'tokens': ['p', 'u', 'g']}, 'pun': {'count': 12, 'tokens': ['p', 'u', 'n']}, 'bun': {'count': 4, 'tokens': ['b', 'u', 'n']}, 'hugs': {'count': 5, 'tokens': ['h', 'u', 'g', 's']}}
New tokens by word appearance: 
</pre>
</div>
</div>
<div class="output-area">
<div class="prompt-output-prompt">Out[32]:</div>
<div class="output-text-output-subareaoutput_execute_result">
<pre>{'hug': {'count': 10, 'tokens': ['h', 'u', 'g', 'ug']},
 'pug': {'count': 5, 'tokens': ['p', 'u', 'g', 'ug']},
 'pun': {'count': 12, 'tokens': ['p', 'u', 'n']},
 'bun': {'count': 4, 'tokens': ['b', 'u', 'n']},
 'hugs': {'count': 5, 'tokens': ['h', 'u', 'g', 's', 'ug']}}</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>We put this in a function</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">update_tokens_by_word_appearance</span><span class="p">(</span><span class="n">dict_tokens_by_word_appearance</span><span class="p">,</span> <span class="n">max_consecutive_token</span><span class="p">):</span>
    <span class="n">dict_tokens_by_word_appearance_tmp</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">dict_tokens_by_word_appearance</span><span class="p">)</span>
    <span class="n">dict_keys</span> <span class="o">=</span> <span class="n">dict_tokens_by_word_appearance_tmp</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">dict_keys</span><span class="p">:</span>
        <span class="c1"># Check if the new token is in the word</span>
        <span class="k">if</span> <span class="n">max_consecutive_token</span> <span class="ow">in</span> <span class="n">key</span><span class="p">:</span>
            <span class="c1"># Add the new token to the word tokens</span>
            <span class="n">dict_tokens_by_word_appearance_tmp</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="s2">"tokens"</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">max_consecutive_token</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">dict_tokens_by_word_appearance_tmp</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>We check that it is OK</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">dict_tokens_by_word_appearance</span> <span class="o">=</span> <span class="n">update_tokens_by_word_appearance</span><span class="p">(</span><span class="n">dict_tokens_by_word_appearance</span><span class="p">,</span> <span class="n">max_consecutive_token</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"New tokens by word appearance: "</span><span class="p">)</span>
<span class="n">dict_tokens_by_word_appearance</span>
</pre></div>
</div>
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>New tokens by word appearance: 
</pre>
</div>
</div>
<div class="output-area">
<div class="prompt-output-prompt">Out[34]:</div>
<div class="output-text-output-subareaoutput_execute_result">
<pre>{'hug': {'count': 10, 'tokens': ['h', 'u', 'g', 'ug']},
 'pug': {'count': 5, 'tokens': ['p', 'u', 'g', 'ug']},
 'pun': {'count': 12, 'tokens': ['p', 'u', 'n']},
 'bun': {'count': 4, 'tokens': ['b', 'u', 'n']},
 'hugs': {'count': 5, 'tokens': ['h', 'u', 'g', 's', 'ug']}}</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>In summary, in a first iteration, we have gone from a corpus of tokens <code>s, g, h, u, n, p, b</code> to the new corpus of tokens <code>h, u, n, p, s, g, b, ug</code>.</p>
</section>
<section class="section-block-markdown-cell">
<p>We now perform a second iteration, obtaining the pair of consecutive tokens that appears most often in the dictionary.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">max_consecutive_token</span> <span class="o">=</span> <span class="n">get_consecutive_tokens_with_max_frequency</span><span class="p">(</span><span class="n">dict_tokens_by_word_appearance</span><span class="p">,</span> <span class="n">new_corpus_tokens</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Consecutive token with maximum frequency: </span><span class="si">{</span><span class="n">max_consecutive_token</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Consecutive token with maximum frequency: pu
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>We obtain the new corpus of tokens</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">corpus_tokens</span> <span class="o">=</span> <span class="n">get_new_corpus_tokens</span><span class="p">(</span><span class="n">max_consecutive_token</span><span class="p">,</span> <span class="n">new_corpus_tokens</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Initial corpus tokens: </span><span class="si">{</span><span class="n">new_corpus_tokens</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"New corpus tokens: </span><span class="si">{</span><span class="n">corpus_tokens</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Initial corpus tokens: {'p', 'n', 'ug', 'g', 'b', 'u', 's', 'h'}
New corpus tokens: {'p', 'n', 'pu', 'u', 's', 'h', 'ug', 'g', 'b'}
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>And we obtain the new dictionary in which the words, tokens and the number of times they appear are displayed.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">dict_tokens_by_word_appearance</span> <span class="o">=</span> <span class="n">update_tokens_by_word_appearance</span><span class="p">(</span><span class="n">dict_tokens_by_word_appearance</span><span class="p">,</span> <span class="n">max_consecutive_token</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"New tokens by word appearance: "</span><span class="p">)</span>
<span class="n">dict_tokens_by_word_appearance</span>
</pre></div>
</div>
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>New tokens by word appearance: 
</pre>
</div>
</div>
<div class="output-area">
<div class="prompt-output-prompt">Out[37]:</div>
<div class="output-text-output-subareaoutput_execute_result">
<pre>{'hug': {'count': 10, 'tokens': ['h', 'u', 'g', 'ug']},
 'pug': {'count': 5, 'tokens': ['p', 'u', 'g', 'ug', 'pu']},
 'pun': {'count': 12, 'tokens': ['p', 'u', 'n', 'pu']},
 'bun': {'count': 4, 'tokens': ['b', 'u', 'n']},
 'hugs': {'count': 5, 'tokens': ['h', 'u', 'g', 's', 'ug']}}</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Now we can continue until we have a corpus of tokens with the size we want, let's create a corpus of 15 tokens.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">len_corpus_tokens</span> <span class="o">=</span> <span class="mi">15</span>

<span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">corpus_tokens</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">len_corpus_tokens</span><span class="p">:</span>
    <span class="n">max_consecutive_token</span> <span class="o">=</span> <span class="n">get_consecutive_tokens_with_max_frequency</span><span class="p">(</span><span class="n">dict_tokens_by_word_appearance</span><span class="p">,</span> <span class="n">corpus_tokens</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Consecutive token with maximum frequency: </span><span class="si">{</span><span class="n">max_consecutive_token</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="c1"># If there are no more consecutive tokens break the loop</span>
    <span class="k">if</span> <span class="n">max_consecutive_token</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">break</span>

    <span class="n">corpus_tokens</span> <span class="o">=</span> <span class="n">get_new_corpus_tokens</span><span class="p">(</span><span class="n">max_consecutive_token</span><span class="p">,</span> <span class="n">corpus_tokens</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"New corpus tokens: </span><span class="si">{</span><span class="n">corpus_tokens</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="n">dict_tokens_by_word_appearance</span> <span class="o">=</span> <span class="n">update_tokens_by_word_appearance</span><span class="p">(</span><span class="n">dict_tokens_by_word_appearance</span><span class="p">,</span> <span class="n">max_consecutive_token</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"New tokens by word appearance: </span><span class="si">{</span><span class="n">dict_tokens_by_word_appearance</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Consecutive token with maximum frequency: un
New corpus tokens: {'p', 'n', 'pu', 'un', 'u', 's', 'h', 'ug', 'g', 'b'}
New tokens by word appearance: {'hug': {'count': 10, 'tokens': ['h', 'u', 'g', 'ug']}, 'pug': {'count': 5, 'tokens': ['p', 'u', 'g', 'ug', 'pu']}, 'pun': {'count': 12, 'tokens': ['p', 'u', 'n', 'pu', 'un']}, 'bun': {'count': 4, 'tokens': ['b', 'u', 'n', 'un']}, 'hugs': {'count': 5, 'tokens': ['h', 'u', 'g', 's', 'ug']}}

Consecutive token with maximum frequency: hu
New corpus tokens: {'p', 'hu', 'n', 'pu', 'un', 'u', 's', 'h', 'ug', 'g', 'b'}
New tokens by word appearance: {'hug': {'count': 10, 'tokens': ['h', 'u', 'g', 'ug', 'hu']}, 'pug': {'count': 5, 'tokens': ['p', 'u', 'g', 'ug', 'pu']}, 'pun': {'count': 12, 'tokens': ['p', 'u', 'n', 'pu', 'un']}, 'bun': {'count': 4, 'tokens': ['b', 'u', 'n', 'un']}, 'hugs': {'count': 5, 'tokens': ['h', 'u', 'g', 's', 'ug', 'hu']}}

Consecutive token with maximum frequency: gug
New corpus tokens: {'p', 'hu', 'n', 'pu', 'un', 'gug', 'u', 's', 'h', 'ug', 'g', 'b'}
New tokens by word appearance: {'hug': {'count': 10, 'tokens': ['h', 'u', 'g', 'ug', 'hu']}, 'pug': {'count': 5, 'tokens': ['p', 'u', 'g', 'ug', 'pu']}, 'pun': {'count': 12, 'tokens': ['p', 'u', 'n', 'pu', 'un']}, 'bun': {'count': 4, 'tokens': ['b', 'u', 'n', 'un']}, 'hugs': {'count': 5, 'tokens': ['h', 'u', 'g', 's', 'ug', 'hu']}}

Consecutive token with maximum frequency: ughu
New corpus tokens: {'p', 'hu', 'n', 'pu', 'un', 'gug', 'u', 's', 'h', 'ughu', 'ug', 'g', 'b'}
New tokens by word appearance: {'hug': {'count': 10, 'tokens': ['h', 'u', 'g', 'ug', 'hu']}, 'pug': {'count': 5, 'tokens': ['p', 'u', 'g', 'ug', 'pu']}, 'pun': {'count': 12, 'tokens': ['p', 'u', 'n', 'pu', 'un']}, 'bun': {'count': 4, 'tokens': ['b', 'u', 'n', 'un']}, 'hugs': {'count': 5, 'tokens': ['h', 'u', 'g', 's', 'ug', 'hu']}}

Consecutive token with maximum frequency: npu
New corpus tokens: {'p', 'hu', 'n', 'npu', 'pu', 'un', 'gug', 'u', 's', 'h', 'ughu', 'ug', 'g', 'b'}
New tokens by word appearance: {'hug': {'count': 10, 'tokens': ['h', 'u', 'g', 'ug', 'hu']}, 'pug': {'count': 5, 'tokens': ['p', 'u', 'g', 'ug', 'pu']}, 'pun': {'count': 12, 'tokens': ['p', 'u', 'n', 'pu', 'un']}, 'bun': {'count': 4, 'tokens': ['b', 'u', 'n', 'un']}, 'hugs': {'count': 5, 'tokens': ['h', 'u', 'g', 's', 'ug', 'hu']}}

Consecutive token with maximum frequency: puun
New corpus tokens: {'p', 'hu', 'n', 'npu', 'pu', 'un', 'gug', 'puun', 'u', 's', 'h', 'ughu', 'ug', 'g', 'b'}
New tokens by word appearance: {'hug': {'count': 10, 'tokens': ['h', 'u', 'g', 'ug', 'hu']}, 'pug': {'count': 5, 'tokens': ['p', 'u', 'g', 'ug', 'pu']}, 'pun': {'count': 12, 'tokens': ['p', 'u', 'n', 'pu', 'un']}, 'bun': {'count': 4, 'tokens': ['b', 'u', 'n', 'un']}, 'hugs': {'count': 5, 'tokens': ['h', 'u', 'g', 's', 'ug', 'hu']}}

</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Now that we have seen how to train the BPE tokenizer, let's train it from scratch to consolidate our knowledge.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">corpus_words</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"hug"</span><span class="p">,</span> <span class="s2">"pug"</span><span class="p">,</span> <span class="s2">"pun"</span><span class="p">,</span> <span class="s2">"bun"</span><span class="p">,</span> <span class="s2">"hugs"</span><span class="p">]</span>

<span class="c1"># Concatenate all the words in the corpus</span>
<span class="n">initial_corpus_tokens</span> <span class="o">=</span> <span class="s2">""</span>
<span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">corpus_words</span><span class="p">:</span>
    <span class="n">initial_corpus_tokens</span> <span class="o">+=</span> <span class="n">word</span>

<span class="c1"># Convert the concatenated string to a set of tokens to get unique tokens</span>
<span class="n">corpus_tokens</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">initial_corpus_tokens</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Corpus words: </span><span class="si">{</span><span class="n">corpus_words</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Initial corpus tokens: </span><span class="si">{</span><span class="n">corpus_tokens</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Number of initial corpus tokens: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">corpus_tokens</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Corpus words: ['hug', 'pug', 'pun', 'bun', 'hugs']
Initial corpus tokens: {'p', 'n', 'u', 's', 'h', 'g', 'b'}
Number of initial corpus tokens: 7
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">corpus</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">"hug hug hug pun pun bun hugs"</span><span class="p">,</span>
    <span class="s2">"hug hug pug pug pun pun hugs"</span><span class="p">,</span>
    <span class="s2">"hug hug pug pug pun pun pun pun hugs"</span><span class="p">,</span>
    <span class="s2">"pug pun pun pun bun hugs"</span><span class="p">,</span>
    <span class="s2">"hug hug hug pun bun bun hugs"</span><span class="p">,</span>
<span class="p">]</span>

<span class="n">num_hug</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">num_pug</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">num_pun</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">num_bun</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">num_hugs</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">corpus</span><span class="p">:</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">" "</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">word</span> <span class="o">==</span> <span class="s2">"hug"</span><span class="p">:</span>
            <span class="n">num_hug</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">elif</span> <span class="n">word</span> <span class="o">==</span> <span class="s2">"pug"</span><span class="p">:</span>
            <span class="n">num_pug</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">elif</span> <span class="n">word</span> <span class="o">==</span> <span class="s2">"pun"</span><span class="p">:</span>
            <span class="n">num_pun</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">elif</span> <span class="n">word</span> <span class="o">==</span> <span class="s2">"bun"</span><span class="p">:</span>
            <span class="n">num_bun</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">elif</span> <span class="n">word</span> <span class="o">==</span> <span class="s2">"hugs"</span><span class="p">:</span>
            <span class="n">num_hugs</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="n">dict_tokens_by_word_appearance</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"hug"</span><span class="p">:</span>
        <span class="p">{</span>
            <span class="s2">"count"</span><span class="p">:</span> <span class="n">num_hug</span><span class="p">,</span>
            <span class="s2">"tokens"</span><span class="p">:</span> <span class="p">[</span><span class="n">character</span> <span class="k">for</span> <span class="n">character</span> <span class="ow">in</span> <span class="s2">"hug"</span><span class="p">],</span>
        <span class="p">},</span>
    <span class="s2">"pug"</span><span class="p">:</span>
        <span class="p">{</span>
            <span class="s2">"count"</span><span class="p">:</span> <span class="n">num_pug</span><span class="p">,</span>
            <span class="s2">"tokens"</span><span class="p">:</span> <span class="p">[</span><span class="n">character</span> <span class="k">for</span> <span class="n">character</span> <span class="ow">in</span> <span class="s2">"pug"</span><span class="p">],</span>
        <span class="p">},</span>
    <span class="s2">"pun"</span><span class="p">:</span>
        <span class="p">{</span>
            <span class="s2">"count"</span><span class="p">:</span> <span class="n">num_pun</span><span class="p">,</span>
            <span class="s2">"tokens"</span><span class="p">:</span> <span class="p">[</span><span class="n">character</span> <span class="k">for</span> <span class="n">character</span> <span class="ow">in</span> <span class="s2">"pun"</span><span class="p">],</span>
        <span class="p">},</span>
    <span class="s2">"bun"</span><span class="p">:</span>
        <span class="p">{</span>
            <span class="s2">"count"</span><span class="p">:</span> <span class="n">num_bun</span><span class="p">,</span>
            <span class="s2">"tokens"</span><span class="p">:</span> <span class="p">[</span><span class="n">character</span> <span class="k">for</span> <span class="n">character</span> <span class="ow">in</span> <span class="s2">"bun"</span><span class="p">],</span>
        <span class="p">},</span>
    <span class="s2">"hugs"</span><span class="p">:</span>
        <span class="p">{</span>
            <span class="s2">"count"</span><span class="p">:</span> <span class="n">num_hugs</span><span class="p">,</span>
            <span class="s2">"tokens"</span><span class="p">:</span> <span class="p">[</span><span class="n">character</span> <span class="k">for</span> <span class="n">character</span> <span class="ow">in</span> <span class="s2">"hugs"</span><span class="p">],</span>
        <span class="p">},</span>
<span class="p">}</span>

<span class="n">dict_tokens_by_word_appearance</span>
</pre></div>
</div>
<div class="output-wrapper">
<div class="output-area">
<div class="prompt-output-prompt">Out[47]:</div>
<div class="output-text-output-subareaoutput_execute_result">
<pre>{'hug': {'count': 10, 'tokens': ['h', 'u', 'g']},
 'pug': {'count': 5, 'tokens': ['p', 'u', 'g']},
 'pun': {'count': 12, 'tokens': ['p', 'u', 'n']},
 'bun': {'count': 4, 'tokens': ['b', 'u', 'n']},
 'hugs': {'count': 5, 'tokens': ['h', 'u', 'g', 's']}}</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>We train it from scratch to obtain a corpus of 15 tokens.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">len_corpus_tokens</span> <span class="o">=</span> <span class="mi">15</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Initial corpus tokens: (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">corpus_tokens</span><span class="p">)</span><span class="si">}</span><span class="s2">) </span><span class="si">{</span><span class="n">corpus_tokens</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">corpus_tokens</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">len_corpus_tokens</span><span class="p">:</span>
    <span class="n">max_consecutive_token</span> <span class="o">=</span> <span class="n">get_consecutive_tokens_with_max_frequency</span><span class="p">(</span><span class="n">dict_tokens_by_word_appearance</span><span class="p">,</span> <span class="n">corpus_tokens</span><span class="p">)</span>

    <span class="c1"># If there are no more consecutive tokens break the loop</span>
    <span class="k">if</span> <span class="n">max_consecutive_token</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">break</span>

    <span class="n">corpus_tokens</span> <span class="o">=</span> <span class="n">get_new_corpus_tokens</span><span class="p">(</span><span class="n">max_consecutive_token</span><span class="p">,</span> <span class="n">corpus_tokens</span><span class="p">)</span>

    <span class="n">dict_tokens_by_word_appearance</span> <span class="o">=</span> <span class="n">update_tokens_by_word_appearance</span><span class="p">(</span><span class="n">dict_tokens_by_word_appearance</span><span class="p">,</span> <span class="n">max_consecutive_token</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"New corpus tokens: (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">corpus_tokens</span><span class="p">)</span><span class="si">}</span><span class="s2">) </span><span class="si">{</span><span class="n">corpus_tokens</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Initial corpus tokens: (7) {'p', 'n', 'u', 's', 'h', 'g', 'b'}
New corpus tokens: (15) {'p', 'hu', 'n', 'npu', 'pu', 'un', 'gug', 'puun', 'u', 's', 'h', 'ughu', 'ug', 'g', 'b'}
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h2 id="Tokenization">Tokenization<a class="anchor-link" href="#Tokenization">¶</a></h2>
</section>
<section class="section-block-markdown-cell">
<p>If we now wanted to tokenize, we would first have to create a vocabulary, that is, assign an ID to each token.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">vocab</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">token</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">corpus_tokens</span><span class="p">):</span>
    <span class="n">vocab</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Vocabulary: "</span><span class="p">)</span>
<span class="n">vocab</span>
</pre></div>
</div>
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Vocabulary: 
</pre>
</div>
</div>
<div class="output-area">
<div class="prompt-output-prompt">Out[54]:</div>
<div class="output-text-output-subareaoutput_execute_result">
<pre>{'p': 0,
 'hu': 1,
 'sug': 2,
 'npu': 3,
 'ugpu': 4,
 'gug': 5,
 'u': 6,
 'ug': 7,
 'ughu': 8,
 'n': 9,
 'pu': 10,
 'un': 11,
 'puun': 12,
 's': 13,
 'h': 14,
 'gs': 15,
 'g': 16,
 'b': 17}</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>We put it in a function</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_vocabulary</span><span class="p">(</span><span class="n">corpus_tokens</span><span class="p">):</span>
    <span class="n">vocab</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">token</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">corpus_tokens</span><span class="p">):</span>
        <span class="n">vocab</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
    <span class="k">return</span> <span class="n">vocab</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Commitments that are well</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">vocab</span> <span class="o">=</span> <span class="n">get_vocabulary</span><span class="p">(</span><span class="n">corpus_tokens</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Vocabulary: "</span><span class="p">)</span>
<span class="n">vocab</span>
</pre></div>
</div>
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Vocabulary: 
</pre>
</div>
</div>
<div class="output-area">
<div class="prompt-output-prompt">Out[56]:</div>
<div class="output-text-output-subareaoutput_execute_result">
<pre>{'p': 0,
 'hu': 1,
 'sug': 2,
 'npu': 3,
 'ugpu': 4,
 'gug': 5,
 'u': 6,
 'ug': 7,
 'ughu': 8,
 'n': 9,
 'pu': 10,
 'un': 11,
 'puun': 12,
 's': 13,
 'h': 14,
 'gs': 15,
 'g': 16,
 'b': 17}</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>If we now want to tokenize the word <code>bug</code> we can do the following</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">word</span> <span class="o">=</span> <span class="s1">'bug'</span>

<span class="c1"># Get the maximum length of tokens</span>
<span class="n">max_len</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">vocab</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Maximum length of tokens: </span><span class="si">{</span><span class="n">max_len</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Create a empty list of tokens</span>
<span class="n">tokens</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
    <span class="c1"># Flag to check if the token is found</span>
    <span class="n">found</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># Iterate over the maximum length of tokens from max_len to 0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_len</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="c1"># Get the prefix of the word</span>
        <span class="n">prefix</span> <span class="o">=</span> <span class="n">word</span><span class="p">[:</span><span class="n">i</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Prefix: </span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

        <span class="c1"># Check if the prefix is in the vocabulary</span>
        <span class="k">if</span> <span class="n">prefix</span> <span class="ow">in</span> <span class="n">vocab</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"prefix </span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2"> is in the vocabulary"</span><span class="p">)</span>
            <span class="n">tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prefix</span><span class="p">)</span>
            <span class="n">word</span> <span class="o">=</span> <span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">:]</span>
            <span class="n">found</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">break</span>
    
    <span class="c1"># if not found:</span>
    <span class="c1">#     tokens.append('&lt;UNK&gt;')</span>
    <span class="c1">#     word = word[1:]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Maximum length of tokens: 4
Prefix: bug
Prefix: bug
Prefix: bu
Prefix: b
prefix b is in the vocabulary
Prefix: ug
prefix ug is in the vocabulary
Tokens: ['b', 'ug']
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>But if now we want to tokenize the word <code>mug</code> we could not because the <code>m</code> character is not in the vocabulary, so we tokenize it with the token <code>&lt;UNK&gt;</code>.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">word</span> <span class="o">=</span> <span class="s1">'mug'</span>

<span class="c1"># Get the maximum length of tokens</span>
<span class="n">max_len</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">vocab</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Maximum length of tokens: </span><span class="si">{</span><span class="n">max_len</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Create a empty list of tokens</span>
<span class="n">tokens</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
    <span class="c1"># Flag to check if the token is found</span>
    <span class="n">found</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># Iterate over the maximum length of tokens from max_len to 0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_len</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="c1"># Get the prefix of the word</span>
        <span class="n">prefix</span> <span class="o">=</span> <span class="n">word</span><span class="p">[:</span><span class="n">i</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Prefix: </span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

        <span class="c1"># Check if the prefix is in the vocabulary</span>
        <span class="k">if</span> <span class="n">prefix</span> <span class="ow">in</span> <span class="n">vocab</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"prefix </span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2"> is in the vocabulary"</span><span class="p">)</span>
            <span class="n">tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prefix</span><span class="p">)</span>
            <span class="n">word</span> <span class="o">=</span> <span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">:]</span>
            <span class="n">found</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">break</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">found</span><span class="p">:</span>
        <span class="n">tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">'&lt;UNK&gt;'</span><span class="p">)</span>
        <span class="n">word</span> <span class="o">=</span> <span class="n">word</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Maximum length of tokens: 4
Prefix: mug
Prefix: mug
Prefix: mu
Prefix: m
Prefix: ug
prefix ug is in the vocabulary
Tokens: ['&lt;UNK&gt;', 'ug']
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>We put it in a function</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">tokenize_word</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">vocab</span><span class="p">):</span>
    <span class="c1"># Get the maximum length of tokens</span>
    <span class="n">max_len</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">vocab</span><span class="p">)</span>

    <span class="c1"># Create a empty list of tokens</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># Flag to check if the token is found</span>
        <span class="n">found</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># Iterate over the maximum length of tokens from max_len to 0</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_len</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="c1"># Get the prefix of the word</span>
            <span class="n">prefix</span> <span class="o">=</span> <span class="n">word</span><span class="p">[:</span><span class="n">i</span><span class="p">]</span>

            <span class="c1"># Check if the prefix is in the vocabulary</span>
            <span class="k">if</span> <span class="n">prefix</span> <span class="ow">in</span> <span class="n">vocab</span><span class="p">:</span>
                <span class="n">tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prefix</span><span class="p">)</span>
                <span class="n">word</span> <span class="o">=</span> <span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">:]</span>
                <span class="n">found</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">break</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">found</span><span class="p">:</span>
            <span class="n">tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">'&lt;UNK&gt;'</span><span class="p">)</span>
            <span class="n">word</span> <span class="o">=</span> <span class="n">word</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>

    <span class="k">return</span> <span class="n">tokens</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>We check that it is OK</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Tokenization of the word 'bug': </span><span class="si">{</span><span class="n">tokenize_word</span><span class="p">(</span><span class="s1">'bug'</span><span class="p">,</span><span class="w"> </span><span class="n">vocab</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Tokenization of the word 'mug': </span><span class="si">{</span><span class="n">tokenize_word</span><span class="p">(</span><span class="s1">'mug'</span><span class="p">,</span><span class="w"> </span><span class="n">vocab</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Tokenization of the word 'bug': ['b', 'ug']
Tokenization of the word 'mug': ['&lt;UNK&gt;', 'ug']
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h2 id="Token-viewer">Token viewer<a class="anchor-link" href="#Token-viewer">¶</a></h2>
</section>
<section class="section-block-markdown-cell">
<p>Now that we know how a BPE tokenizer works, let's see through the <a href="https://huggingface.co/spaces/Xenova/the-tokenizer-playground">the-tokenizer-playground</a> visualizer how the tokens of any given statement would look like</p>
</section>
<section class="section-block-markdown-cell">
<iframe frameborder="0" height="450" src="https://xenova-the-tokenizer-playground.static.hf.space" width="850"></iframe>
</section>
