<p>
	<!-- Custom stylesheet, it must be in the same directory as the html file -->
	<!-- Loading mathjax macro --><!-- Load mathjax --><!-- MathJax configuration -->
<p>
<style>
	/* Media query para pantallas grandes */
	@media screen and (min-width: 1000px) {
		.container {
			flex-wrap: nowrap;
			display: flex;
			justify-content: space-between;
			height: 100vh; /* altura del viewport */
		}
		
		.indice {
			width: 25%; /* Ancho del índice en pantallas grandes */
			border-right: 1px solid #ccc;
			max-height: calc(100vh - 40px); /* Ajustar según tus necesidades. Aquí estamos restando el doble del padding para mantener todo visible */
			padding: 20px;
			box-sizing: border-box;
			overflow-y: auto; /* desplazamiento vertical cuando sea necesario */
		}
		
		.contenido {
			width: 70%; /* Ancho del contenido en pantallas grandes */
			max-height: calc(100vh - 40px); /* Ajustar según tus necesidades. Aquí estamos restando el doble del padding para mantener todo visible */
			padding: 20px;
			box-sizing: border-box;
			overflow-y: auto; /* desplazamiento vertical cuando sea necesario */
		}
	}
</style>
<!-- Open div notebook -->
<div id="notebook" class="border-box-sizing" tabindex="-1">
	<!-- Open div notebook container -->
	<div id="notebook-container" class="container">
		<!-- Open div indice -->
		<div class="indice">
			<!-- Open div index header -->
			<div class="cell border-box-sizing text_cell rendered">
				<h2 class="prompt input_prompt">
					<span style="
					color: var(--darkreader-text--heading-color, var(--darkreader-text--heading-2-color,
					var(--darkreader-text--headings-color)));
					font-family: var(--fontFamily); font-size: var(--fontSize);
					font-style: var(--fontStyle, inherit);
					font-weight: var(--fontWeight);
					letter-spacing: var(--letterSpacing);
					text-transform: var(--textTransform);
					background-color: transparent;
					--darkreader-inline-color: var(--darkreader-text--darkreader-text--heading-color,
					var(--darkreader-text--darkreader-text--heading-2-color, var(--darkreader-text--darkreader-text--headings-color)));
					--darkreader-inline-bgcolor: transparent;"
					data-darkreader-inline-color="" data-darkreader-inline-bgcolor="">
						Índice
					</span>
					<a class="anchor-link" style="
					font-family: var(--fontFamily);
					font-size: var(--fontSize);
					font-style: var(--fontStyle, inherit);
					font-weight: var(--fontWeight);
					letter-spacing: var(--letterSpacing);
					text-transform: var(--textTransform);
					background-color: transparent;
					--darkreader-inline-bgcolor: transparent;"
					href="#Índice" data-darkreader-inline-bgcolor="">
					</a>
				</h2>
			<!-- Close div index header -->
			</div>
			<!-- Index body -->
			<div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Paper-index">
									<a class="anchor-link" href="#Paper">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Paper</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Architecture-index">
									<a class="anchor-link" href="#Architecture">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Architecture</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Paper-abstract-index">
									<a class="anchor-link" href="#Paper-abstract">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Paper abstract</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Text-generation-index">
									<a class="anchor-link" href="#Text-generation">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Text generation</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Generate-text-token-to-token-index">
									<a class="anchor-link" href="#Generate-text-token-to-token">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Generate text token to token</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h4 id="Greedy-search-index">
									<a class="anchor-link" href="#Greedy-search">
										<p style="margin-left: 80px; font-size: 12px; line-height: 1.5;">Greedy search</p>
									</a>
								</h4>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Fine-tuning-GPT-index">
									<a class="anchor-link" href="#Fine-tuning-GPT">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Fine tuning GPT</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Loss-calculation-index">
									<a class="anchor-link" href="#Loss-calculation">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Loss calculation</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Dataset-index">
									<a class="anchor-link" href="#Dataset">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Dataset</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Pytorch-training-index">
									<a class="anchor-link" href="#Pytorch-training">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Pytorch training</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h4 id="Pytorch-dataset-index">
									<a class="anchor-link" href="#Pytorch-dataset">
										<p style="margin-left: 80px; font-size: 12px; line-height: 1.5;">Pytorch dataset</p>
									</a>
								</h4>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h4 id="Dataloader-index">
									<a class="anchor-link" href="#Dataloader">
										<p style="margin-left: 80px; font-size: 12px; line-height: 1.5;">Dataloader</p>
									</a>
								</h4>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h4 id="Training-index">
									<a class="anchor-link" href="#Training">
										<p style="margin-left: 80px; font-size: 12px; line-height: 1.5;">Training</p>
									</a>
								</h4>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h4 id="Inference-index">
									<a class="anchor-link" href="#Inference">
										<p style="margin-left: 80px; font-size: 12px; line-height: 1.5;">Inference</p>
									</a>
								</h4>
							</div>
						</div>
					</div>
				</div>
			</div>
		<!-- Close div indice -->
		</div>
 
		<!-- Content -->
		<div class="contenido">
		<div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><a href="https://colab.research.google.com/github/maximofn/portafolio/blob/main/posts/notebooks_translated/2024-06-12-GPT1-Improving-Language-Understanding-by-Generative-Pre-Training_EN.ipynb" target="_blank"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h1 id="GPT1---Improving-Language-Understanding-by-Generative-Pre-Training">
								<a class="anchor-link" href="#GPT1---Improving-Language-Understanding-by-Generative-Pre-Training">
									<p style="margin-left: 0px">GPT1 - Improving Language Understanding by Generative Pre-Training</p>
								</a>
							</h1>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Paper">
								<a class="anchor-link" href="#Paper">
									<p style="margin-left: 10px">Paper</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">This notebook has been automatically translated to make it accessible to more people, please let me know if you see any typos.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf" target="_blank">Improving Language Understanding by Generative Pre-Training</a> is the GPT1 paper. Before reading the post you need to put yourself in situation, before GPT language models were based on recurrent networks (RNN), which were networks that worked relatively well for specific tasks, but with which you could not reuse the pre-training to make them a fine tuning for other tasks. In addition, they did not have much memory, so if you put very long sentences in them, they did not remember the beginning of the sentence very well.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Architecture">
								<a class="anchor-link" href="#Architecture">
									<p style="margin-left: 10px">Architecture</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Before we talk about the architecture of GPT1, let's remember what the architecture of the Transformers was like.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="https://maximofn.com/wp-content/uploads/2023/12/transformer-scaled.webp" alt="transformer architecture"></p></p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">GPT1 is a model based on the transformer decoders, so as we do not have an encoder, the architecture of a single decoder is as follows</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="https://maximofn.com/wp-content/uploads/2024/06/transformer_decoder_only-scaled.webp" alt="decoder architecture"></p></p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">The attention mechanism between the encoder and decoder sentence is eliminated.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">In the GPT1 paper they propose the following architecture</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="https://maximofn.com/wp-content/uploads/2024/06/GPT1_architecture.webp" alt="gpt1 architecture"></p></p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Which corresponds to the decoder of a transformer as we have seen before, executed 12 times</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Paper-abstract">
								<a class="anchor-link" href="#Paper-abstract">
									<p style="margin-left: 10px">Paper abstract</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">The most interesting ideas in the paper are:</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">
								<ul>
									<li>The model is trained on a large corpus of unsupervised text. This is used to create a language model. A high-capacity language model is created on a large corpus of text.</li>
									<li>Fine-tuning is then performed on supervised NLP tasks with labeled datasets. Fine-tuning is performed on a supervised target task. In addition, when the model is evaluated on the supervised task, it is not only evaluated on that task, but on how well it predicts the next token, this helps to improve the generalization of the supervised model and makes the model converge faster.</li>
									<li>Although we have already mentioned it, the paper says that the transformer architecture is used, since up to that time RNNs were used for the language models. This resulted in an improvement in that what was learned in the first training (training on the unsupervised text corpus) is easier to transfer to supervised tasks. That is, thanks to the use of transformers, it was possible to train on a whole corpus of text and then fine-tune it in supervised tasks.</li>
									<li>They evaluated the model in four types of language comprehension tasks:</li>
									<ul><li>Natural language inference</li></ul>
									<ul><li>Answer to questions</li></ul>
									<ul><li>Semantic similarity</li></ul>
									<ul><li>Classification of texts.</li></ul>
									<li>The general model (the one trained on the entire unsupervised text corpus) outperforms discriminatively trained RNN models that employ task-specific designed architectures, significantly improving the state of the art in 9 of the 12 tasks studied. They also analyze the "zero-shot" behaviors of the pre-trained model in four different environments and showed that it acquires useful linguistic knowledge for subsequent tasks.</li>
									<li>In recent years, researchers had demonstrated the benefits of using embeddings, which are trained on unlabeled corpora, to improve performance on a variety of tasks. However, these approaches primarily transfer information at the word level, whereas the use of transformers trained on large unsupervised text corpora captures higher-level, sentence-level semantics.</li>
								</ul>
							</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Text-generation">
								<a class="anchor-link" href="#Text-generation">
									<p style="margin-left: 10px">Text generation</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Let's see how to generate text with a pre-trained GPT1</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">First you have to install <code><b>ftfy</b></code> and <code><b>spacy</b></code> via</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 80px;"><code>pip install ftfy spacy<br></code></p>
						</div>
					</div>
				</div>
			</div>
	
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Once installed, you must download the spacy language model you wish to use. For example, to download the English model, you can run:</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 80px;"><code>python -m spacy download en_core_web_sm<br></code></p>
						</div>
					</div>
				</div>
			</div>
	
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">To generate text we will use the model from the <a href="https://huggingface.co/openai-community/openai-gpt" target="_blank">GPT1</a> repository of Hugging Face.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">We import the libraries</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">import</span> <span style="color: #4fcd7d;">torch</span></p>
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">OpenAIGPTTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">OpenAIGPTLMHeadModel</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoTokenizer</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">If you notice we have imported <code><b>OpenAIGPTTokenizer</b></code> and <code><b>AutoTokenizer</b></code>. This is because in the <a href="https://huggingface.co/openai-community/openai-gpt" target="_blank">model card</a> of GPT1 it says to use <code><b>OpenAIGPTTokenizer</b></code>, but in the <a href="https://maximofn.com/hugging-face-transformers/" target="_blank">transformers</a> library post we explain that you should use <code><b>AutoTokenizer</b></code> to load the tokenizer. So let's try both</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">ckeckpoints</span> <span>=</span> <span style="color: #7e7a34;">&quot;openai-community/openai-gpt&quot;</span></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">OpenAIGPTTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">ckeckpoints</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">auto_tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">ckeckpoints</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">input_tokens</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;Hello, my dog is cute and&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">input_auto_tokens</span> <span>=</span> <span style="color: #6b97e8;">auto_tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;Hello, my dog is cute and&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;input tokens: </span><span style="color: #a6a831;">\n</span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">input_tokens</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;input auto tokens: </span><span style="color: #a6a831;">\n</span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">input_auto_tokens</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>input tokens: </p><p>{'input_ids': tensor([[3570,  240,  547, 2585,  544, 4957,  488]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}</p><p>input auto tokens: </p><p>{'input_ids': tensor([[3570,  240,  547, 2585,  544, 4957,  488]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">As you can see with the two tokenizers you get the same tokens. So to make the code more general, so that if you change the ckeckpoints, you don't have to change the code, let's use <code><b>AutoTokenizer</b></code>.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">We then create the device, the tokenizer and the model</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">device</span> <span>=</span> <span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">device</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span> <span style="color: #a04cc1;">if</span> <span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">cuda</span><span>.</span><span style="color: #6b97e8;">is_available</span><span style="color: #e3e11d;">()</span> <span style="color: #a04cc1;">else</span> <span style="color: #7e7a34;">&quot;cpu&quot;</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">ckeckpoints</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">OpenAIGPTLMHeadModel</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">ckeckpoints</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">device</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">As we have instantiated the model let's see how many parameters it has</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">params</span> <span>=</span> <span style="color: #dfd84a;">sum</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">p</span><span>.</span><span style="color: #6b97e8;">numel</span><span style="color: #e3e11d;">()</span> <span style="color: #a04cc1;">for</span> <span style="color: #6b97e8;">p</span> <span style="color: #7f6e38;">in</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">parameters</span><span style="color: #e3e11d;">())</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;Number of parameters: </span><span style="color: #3b75c2;">{</span><span style="color: #dfd84a;">round</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">params</span><span>/</span><span style="color: #a09e19;">1e6</span><span style="color: #e3e11d;">)</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">M&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>Number of parameters: 117M</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">At the time of billions of parameters, we can see that GPT1 only had 117 million parameters.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">We create the input tokens for the model</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">input_sentence</span> <span>=</span> <span style="color: #7e7a34;">&quot;Hello, my dog is cute and&quot;</span></p>
<p><span style="color: #6b97e8;">input_tokens</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">input_sentence</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">device</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">input_tokens</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>{'input_ids': tensor([[3570,  240,  547, 2585,  544, 4957,  488]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">We pass them to the model to generate the output tokens.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">output_tokens</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">input_tokens</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;output tokens: </span><span style="color: #a6a831;">\n</span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">output_tokens</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>/home/wallabot/miniconda3/envs/nlp/lib/python3.11/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.</p><p>  warnings.warn(</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">We decode the tokens to obtain the output statement</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">decoded_output</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">output_tokens</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;decoded output: </span><span style="color: #a6a831;">\n</span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">decoded_output</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>decoded output: </p><p>hello, my dog is cute and i'm going to take him for a walk. " </p><p> "</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">We have already succeeded in generating text with GPT1</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h3 id="Generate-text-token-to-token">
								<a class="anchor-link" href="#Generate-text-token-to-token">
									<p style="margin-left: 20px">Generate text token to token</p>
								</a>
							</h3>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h4 id="Greedy-search">
								<a class="anchor-link" href="#Greedy-search">
									<p style="margin-left: 30px">Greedy search</p>
								</a>
							</h4>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">We have used <code><b>model.generate</b></code> to generate the output tokens all at once, but let's see how to generate them one by one. To do this, instead of using <code><b>model.generate</b></code> we are going to use <code><b>model</b></code>, which actually calls the <code><b>model.forward</b></code> method.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">outputs</span> <span>=</span> <span style="color: #6b97e8;">model</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">input_tokens</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">outputs</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>CausalLMOutput(loss=None, logits=tensor([[[ -5.9486,  -5.8697, -18.4258,  ...,  -9.7371, -10.4495,   0.8814],</p><p>         [ -6.1212,  -4.8031, -14.3970,  ...,  -6.5411,  -9.5051,  -1.2015],</p><p>         [ -7.4231,  -6.3615, -14.7297,  ..., -10.4575,  -8.4600,  -1.5183],</p><p>         ...,</p><p>         [ -5.4751,  -5.8803, -13.7767,  ..., -10.5048, -12.4167,  -6.1584],</p><p>         [ -7.2052,  -6.0198, -21.5040,  ..., -16.2941, -14.0494,  -1.2416],</p><p>         [ -7.7240,  -7.3631, -17.3174,  ..., -12.1546, -12.3327,  -1.7169]]],</p><p>       device='cuda:0', grad_fn=&lt;UnsafeViewBackward0&gt;), hidden_states=None, attentions=None)</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">We see that it pulls a lot of data, first let's look at the output keys</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">outputs</span><span>.</span><span style="color: #6b97e8;">keys</span><span style="color: #e3e11d;">()</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>odict_keys(['logits'])</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">In this case we only have the logits of the model, let's see their size</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">logits</span> <span>=</span> <span style="color: #6b97e8;">outputs</span><span>.</span><span style="color: #6b97e8;">logits</span></p>
<p></p>
<p><span style="color: #6b97e8;">logits</span><span>.</span><span style="color: #6b97e8;">shape</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>torch.Size([1, 7, 40478])</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Let's see how many tokens we had at the entrance.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">input_tokens</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span>.</span><span style="color: #6b97e8;">shape</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>torch.Size([1, 7])</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Wow, at the output we have the same number of logits as at the input. This is normal</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">We obtain the logits of the last position of the exit</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">nex_token_logits</span> <span>=</span> <span style="color: #6b97e8;">logits</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">,</span><span>-</span><span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">]</span></p>
<p></p>
<p><span style="color: #6b97e8;">nex_token_logits</span><span>.</span><span style="color: #6b97e8;">shape</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>torch.Size([40478])</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">There are a total of 40478 logits, i.e. there is a vocabulary of 40478 tokens and we have to see which token has the highest probability, to do this we first calculate the softmax</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">softmax_logits</span> <span>=</span> <span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">softmax</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">nex_token_logits</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">dim</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">softmax_logits</span><span>.</span><span style="color: #6b97e8;">shape</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>torch.Size([40478])</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">next_token_prob</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">next_token_id</span> <span>=</span> <span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">max</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">softmax_logits</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">dim</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">next_token_prob</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">next_token_id</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>(tensor(0.1898, device='cuda:0', grad_fn=&lt;MaxBackward0&gt;),</p><p> tensor(249, device='cuda:0'))</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">We have obtained the following token, now we decode it</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">next_token_id</span><span>.</span><span style="color: #6b97e8;">item</span><span style="color: #e3e11d;">())</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>'i'</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">We have obtained the following token using the greedy method, i.e. the token with the highest probability. But we already saw in the transformers library post, the <a href="https://maximofn.com/hugging-face-transformers/#Formas-de-generaci%C3%B3n-de-texto" target="_blank">ways to generate texts</a> that sampling, top-k, top-p, etc. can be done.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Let's put everything into a function and see what comes out if we generate a few tokens</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #a04cc1;">def</span> <span style="color: #7f6e38;">generate_next_greedy_token</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">input_sentence</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">model</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device</span><span style="color: #e3e11d;">):</span></p>
<p>    <span style="color: #6b97e8;">input_tokens</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">input_sentence</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">device</span><span style="color: #e3e11d;">)</span></p>
<p>    <span style="color: #6b97e8;">outputs</span> <span>=</span> <span style="color: #6b97e8;">model</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">input_tokens</span><span style="color: #e3e11d;">)</span></p>
<p>    <span style="color: #6b97e8;">logits</span> <span>=</span> <span style="color: #6b97e8;">outputs</span><span>.</span><span style="color: #6b97e8;">logits</span></p>
<p>    <span style="color: #6b97e8;">nex_token_logits</span> <span>=</span> <span style="color: #6b97e8;">logits</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">,</span><span>-</span><span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">]</span></p>
<p>    <span style="color: #6b97e8;">softmax_logits</span> <span>=</span> <span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">softmax</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">nex_token_logits</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">dim</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p>    <span style="color: #6b97e8;">next_token_prob</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">next_token_id</span> <span>=</span> <span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">max</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">softmax_logits</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">dim</span><span>=</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">)</span></p>
<p>    <span style="color: #a04cc1;">return</span> <span style="color: #6b97e8;">next_token_prob</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">next_token_id</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #a04cc1;">def</span> <span style="color: #7f6e38;">generate_greedy_text</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">input_sentence</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">model</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">max_length</span><span>=</span><span style="color: #7e7a38;">20</span><span style="color: #e3e11d;">):</span></p>
<p>    <span style="color: #6b97e8;">generated_text</span> <span>=</span> <span style="color: #6b97e8;">input_sentence</span></p>
<p>    <span style="color: #a04cc1;">for</span> <span style="color: #6b97e8;">_</span> <span style="color: #7f6e38;">in</span> <span style="color: #dfd84a;">range</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">max_length</span><span style="color: #e3e11d;">):</span></p>
<p>        <span style="color: #6b97e8;">next_token_prob</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">next_token_id</span> <span>=</span> <span style="color: #6b97e8;">generate_next_greedy_token</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">generated_text</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">model</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device</span><span style="color: #e3e11d;">)</span></p>
<p>        <span style="color: #6b97e8;">generated_text</span> <span>+=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">next_token_id</span><span>.</span><span style="color: #6b97e8;">item</span><span style="color: #e3e11d;">())</span></p>
<p>    <span style="color: #a04cc1;">return</span> <span style="color: #6b97e8;">generated_text</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Now we generate text</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">generate_greedy_text</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;Hello, my dog is cute and&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">model</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>'Hello, my dog is cute andi."\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n'</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">The output is quite repetitive as already seen in the <a href="https://maximofn.com/hugging-face-transformers/#Formas-de-generaci%C3%B3n-de-texto" target="_blank">ways to generate text</a></p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Fine-tuning-GPT">
								<a class="anchor-link" href="#Fine-tuning-GPT">
									<p style="margin-left: 10px">Fine tuning GPT</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h3 id="Loss-calculation">
								<a class="anchor-link" href="#Loss-calculation">
									<p style="margin-left: 20px">Loss calculation</p>
								</a>
							</h3>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Before we start doing the fine tuning of GPT1 let's see one thing. Before when we used to get the output of the model we did this</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">outputs</span> <span>=</span> <span style="color: #6b97e8;">model</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">input_tokens</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">outputs</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>CausalLMOutput(loss=None, logits=tensor([[[ -5.9486,  -5.8697, -18.4258,  ...,  -9.7371, -10.4495,   0.8814],</p><p>         [ -6.1212,  -4.8031, -14.3970,  ...,  -6.5411,  -9.5051,  -1.2015],</p><p>         [ -7.4231,  -6.3615, -14.7297,  ..., -10.4575,  -8.4600,  -1.5183],</p><p>         ...,</p><p>         [ -5.4751,  -5.8803, -13.7767,  ..., -10.5048, -12.4167,  -6.1584],</p><p>         [ -7.2052,  -6.0198, -21.5040,  ..., -16.2941, -14.0494,  -1.2416],</p><p>         [ -7.7240,  -7.3631, -17.3174,  ..., -12.1546, -12.3327,  -1.7169]]],</p><p>       device='cuda:0', grad_fn=&lt;UnsafeViewBackward0&gt;), hidden_states=None, attentions=None)</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">You can see that we get <code><b>loss=None</b></code>.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">outputs</span><span>.</span><span style="color: #6b97e8;">loss</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>None</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">As we are going to need the loss to do the fine tuning, let's see how to obtain it.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">If we go to the documentation of the method <a href="https://huggingface.co/docs/transformers/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel.forward" target="_blank">forward</a> of <code><b>OpenAIGPTLMHeadModel</b></code>, we can see that it says that at the output it returns an object of type <code><b>transformers.modeling_outputs.CausalLMOutput</b></code>, so if we go to the documentation of <a href="https://huggingface.co/docs/transformers/v4.41.3/en/main_classes/output#transformers.modeling_outputs.CausalLMOutput" target="_blank">transformers.modeling_outputs.CausalLMOutput</a>, we can see that it says that it returns <code><b>loss</b></code> if <code><b>labels</b></code> is passed to the <code><b>forward</b></code> method.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">If we go to the source code of the <a href="https://github.com/huggingface/transformers/blob/main/src/transformers/models/openai/modeling_openai.py#L544" target="_blank">forward</a> method, we see this code block</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 80px;"><code>        loss = None<br>        if labels is not None:<br>            # Shift so that tokens < n predict n<br>            shift_logits = lm_logits[..., :-1, :].contiguous()<br>            shift_labels = labels[..., 1:].contiguous()<br>            # Flatten the tokens<br>            loss_fct = CrossEntropyLoss()<br>            loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))<br></code></p>
						</div>
					</div>
				</div>
			</div>
	
	
	
	
	
	
	
	
	
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">In other words, the <code><b>loss</b></code> is calculated as follows</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">
								<ul>
									<li>Shift of logits and labels: The first part is to shift the logits (<code><b>lm_logits</b></code>) and labels (<code><b>labels</b></code>) so that <code><b>tokens < n</b></code> predict <code><b>n</b></code>, i.e., from a position <code><b>n</b></code> the next token is predicted from the previous ones.</li>
									<li>CrossEntropyLoss: An instance of the <code><b>CrossEntropyLoss()</b></code> function is created.</li>
									<li>Flatten tokens: Logits and labels are then flattened using <code><b>view(-1, shift_logits.size(-1))</b></code> and <code><b>view(-1)</b></code>, respectively. This is done so that the logits and labels have the same shape for the loss function.</li>
									<li>Loss calculation: Finally, the loss is calculated using the <code><b>CrossEntropyLoss()</b></code> function with the flattened logits and flattened labels as inputs.</li>
								</ul>
							</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">In summary, <code><b>loss</b></code> is calculated as the cross-entropy loss between shifted and flattened logits and shifted and flattened labels.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Therefore, if we pass the labels to the <code><b>forward</b></code> method, it will return the <code><b>loss</b></code>.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">outputs</span> <span>=</span> <span style="color: #6b97e8;">model</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">input_tokens</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">labels</span><span>=</span><span style="color: #6b97e8;">input_tokens</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">outputs</span><span>.</span><span style="color: #6b97e8;">loss</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>tensor(4.2607, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h3 id="Dataset">
								<a class="anchor-link" href="#Dataset">
									<p style="margin-left: 20px">Dataset</p>
								</a>
							</h3>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">For the training we are going to use a dataset of English jokes <a href="https://huggingface.co/datasets/Maximofn/short-jokes-dataset" target="_blank">short-jokes-dataset</a>, which is a dataset with 231 thousand English jokes.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Download the dataset</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">datasets</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">load_dataset</span></p>
<p></p>
<p><span style="color: #6b97e8;">jokes</span> <span>=</span> <span style="color: #6b97e8;">load_dataset</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;Maximofn/short-jokes-dataset&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">jokes</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>DatasetDict({</p><p>    train: Dataset({</p><p>        features: ['ID', 'Joke'],</p><p>        num_rows: 231657</p><p>    })</p><p>})</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Let's take a look at it</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">jokes</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a34;">&quot;train&quot;</span><span style="color: #e3e11d;">][</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">]</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>{'ID': 1,</p><p> 'Joke': '[me narrating a documentary about narrators] "I can\'t hear what they\'re saying cuz I\'m talking"'}</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h3 id="Pytorch-training">
								<a class="anchor-link" href="#Pytorch-training">
									<p style="margin-left: 20px">Pytorch training</p>
								</a>
							</h3>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">First let's see how the pure Pytorch training would be done.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">> Restart the notebook to avoid problems with the GPU memory.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">import</span> <span style="color: #4fcd7d;">torch</span></p>
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">OpenAIGPTLMHeadModel</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoTokenizer</span></p>
<p></p>
<p><span style="color: #6b97e8;">device</span> <span>=</span> <span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">device</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span> <span style="color: #a04cc1;">if</span> <span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">cuda</span><span>.</span><span style="color: #6b97e8;">is_available</span><span style="color: #e3e11d;">()</span> <span style="color: #a04cc1;">else</span> <span style="color: #7e7a34;">&quot;cpu&quot;</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">ckeckpoints</span> <span>=</span> <span style="color: #7e7a34;">&quot;openai-community/openai-gpt&quot;</span></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">ckeckpoints</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">OpenAIGPTLMHeadModel</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">ckeckpoints</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">device</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h4 id="Pytorch-dataset">
								<a class="anchor-link" href="#Pytorch-dataset">
									<p style="margin-left: 30px">Pytorch dataset</p>
								</a>
							</h4>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">We create a Pytorch dataset class</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">torch.utils.data</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">Dataset</span></p>
<p></p>
<p><span style="color: #a04cc1;">class</span> <span style="color: #7f6e38;">JokesDataset</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">Dataset</span><span style="color: #e3e11d;">):</span></p>
<p>    <span style="color: #a04cc1;">def</span> <span style="color: #7f6e38;">__init__</span><span style="color: #e3e11d;">(</span><span style="color: #7f6e38;">self</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">dataset</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">):</span></p>
<p>        <span style="color: #7f6e38;">self</span><span>.</span><span style="color: #6b97e8;">dataset</span> <span>=</span> <span style="color: #6b97e8;">dataset</span></p>
<p>        <span style="color: #7f6e38;">self</span><span>.</span><span style="color: #6b97e8;">joke</span> <span>=</span> <span style="color: #7e7a34;">&quot;JOKE: &quot;</span></p>
<p>        <span style="color: #7f6e38;">self</span><span>.</span><span style="color: #6b97e8;">end_of_text_token</span> <span>=</span> <span style="color: #7e7a34;">&quot;&lt;|endoftext|&gt;&quot;</span></p>
<p>        <span style="color: #7f6e38;">self</span><span>.</span><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span></p>
<p>        </p>
<p>    <span style="color: #a04cc1;">def</span> <span style="color: #7f6e38;">__len__</span><span style="color: #e3e11d;">(</span><span style="color: #7f6e38;">self</span><span style="color: #e3e11d;">):</span></p>
<p>        <span style="color: #a04cc1;">return</span> <span style="color: #dfd84a;">len</span><span style="color: #e3e11d;">(</span><span style="color: #7f6e38;">self</span><span>.</span><span style="color: #6b97e8;">dataset</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a34;">&quot;train&quot;</span><span style="color: #e3e11d;">])</span></p>
<p></p>
<p>    <span style="color: #a04cc1;">def</span> <span style="color: #7f6e38;">__getitem__</span><span style="color: #e3e11d;">(</span><span style="color: #7f6e38;">self</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">item</span><span style="color: #e3e11d;">):</span></p>
<p>        <span style="color: #6b97e8;">sentence</span> <span>=</span> <span style="color: #7f6e38;">self</span><span>.</span><span style="color: #6b97e8;">joke</span> <span>+</span> <span style="color: #7f6e38;">self</span><span>.</span><span style="color: #6b97e8;">dataset</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a34;">&quot;train&quot;</span><span style="color: #e3e11d;">][</span><span style="color: #6b97e8;">item</span><span style="color: #e3e11d;">][</span><span style="color: #7e7a34;">&quot;Joke&quot;</span><span style="color: #e3e11d;">]</span> <span>+</span> <span style="color: #7f6e38;">self</span><span>.</span><span style="color: #6b97e8;">end_of_text_token</span></p>
<p>        <span style="color: #6b97e8;">tokens</span> <span>=</span> <span style="color: #7f6e38;">self</span><span>.</span><span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">sentence</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span></p>
<p>        <span style="color: #a04cc1;">return</span> <span style="color: #6b97e8;">sentence</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">tokens</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">We instantiate it</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">dataset</span> <span>=</span> <span style="color: #6b97e8;">JokesDataset</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">jokes</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">tokenizer</span><span>=</span><span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Here is an example</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">sentence</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">tokens</span> <span>=</span> <span style="color: #6b97e8;">dataset</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">5</span><span style="color: #e3e11d;">]</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">sentence</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokens</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span>.</span><span style="color: #6b97e8;">shape</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">tokens</span><span>.</span><span style="color: #6b97e8;">attention_mask</span><span>.</span><span style="color: #6b97e8;">shape</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>(torch.Size([1, 30]), torch.Size([1, 30]))</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h4 id="Dataloader">
								<a class="anchor-link" href="#Dataloader">
									<p style="margin-left: 30px">Dataloader</p>
								</a>
							</h4>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">We now create a Pytorch dataloader</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">torch.utils.data</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">DataLoader</span></p>
<p></p>
<p><span style="color: #6b97e8;">BS</span> <span>=</span> <span style="color: #7e7a38;">1</span></p>
<p><span style="color: #6b97e8;">joke_dataloader</span> <span>=</span> <span style="color: #6b97e8;">DataLoader</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">dataset</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">batch_size</span><span>=</span><span style="color: #6b97e8;">BS</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">shuffle</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">We see a batch</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">sentences</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">tokens</span> <span>=</span> <span style="color: #dfd84a;">next</span><span style="color: #e3e11d;">(</span><span style="color: #dfd84a;">iter</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">joke_dataloader</span><span style="color: #e3e11d;">))</span></p>
<p><span style="color: #dfd84a;">len</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">sentences</span><span style="color: #e3e11d;">),</span> <span style="color: #6b97e8;">tokens</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span>.</span><span style="color: #6b97e8;">shape</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">tokens</span><span>.</span><span style="color: #6b97e8;">attention_mask</span><span>.</span><span style="color: #6b97e8;">shape</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>(1, torch.Size([1, 1, 29]), torch.Size([1, 1, 29]))</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h4 id="Training">
								<a class="anchor-link" href="#Training">
									<p style="margin-left: 30px">Training</p>
								</a>
							</h4>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AdamW</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">get_linear_schedule_with_warmup</span></p>
<p><span style="color: #833aa0;">import</span> <span style="color: #4fcd7d;">tqdm</span></p>
<p></p>
<p><span style="color: #6b97e8;">BATCH_SIZE</span> <span>=</span> <span style="color: #7e7a38;">32</span></p>
<p><span style="color: #6b97e8;">EPOCHS</span> <span>=</span> <span style="color: #7e7a38;">5</span></p>
<p><span style="color: #6b97e8;">LEARNING_RATE</span> <span>=</span> <span style="color: #a09e19;">3e-5</span></p>
<p><span style="color: #6b97e8;">WARMUP_STEPS</span> <span>=</span> <span style="color: #7e7a38;">5000</span></p>
<p><span style="color: #6b97e8;">MAX_SEQ_LEN</span> <span>=</span> <span style="color: #7e7a38;">500</span></p>
<p></p>
<p><span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">train</span><span style="color: #e3e11d;">()</span></p>
<p><span style="color: #6b97e8;">optimizer</span> <span>=</span> <span style="color: #6b97e8;">AdamW</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">parameters</span><span style="color: #e3e11d;">(),</span> <span style="color: #6b97e8;">lr</span><span>=</span><span style="color: #6b97e8;">LEARNING_RATE</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">scheduler</span> <span>=</span> <span style="color: #6b97e8;">get_linear_schedule_with_warmup</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">optimizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">num_warmup_steps</span><span>=</span><span style="color: #6b97e8;">WARMUP_STEPS</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">num_training_steps</span><span>=-</span><span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">proc_seq_count</span> <span>=</span> <span style="color: #7e7a38;">0</span></p>
<p><span style="color: #6b97e8;">batch_count</span> <span>=</span> <span style="color: #7e7a38;">0</span></p>
<p></p>
<p><span style="color: #6b97e8;">tmp_jokes_tens</span> <span>=</span> <span style="color: #7f6e38;">None</span></p>
<p></p>
<p><span style="color: #a04cc1;">for</span> <span style="color: #6b97e8;">epoch</span> <span style="color: #7f6e38;">in</span> <span style="color: #dfd84a;">range</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">EPOCHS</span><span style="color: #e3e11d;">):</span></p>
<p>    </p>
<p>    <span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;EPOCH </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">epoch</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;"> started&quot;</span> <span>+</span> <span style="color: #8d783e;">&#39;=&#39;</span> <span>*</span> <span style="color: #7e7a38;">30</span><span style="color: #e3e11d;">)</span></p>
<p>    <span style="color: #6b97e8;">progress_bar</span> <span>=</span> <span style="color: #6b97e8;">tqdm</span><span>.</span><span style="color: #6b97e8;">tqdm</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">joke_dataloader</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">desc</span><span>=</span><span style="color: #7e7a34;">&quot;Training&quot;</span><span style="color: #e3e11d;">)</span></p>
<p>    </p>
<p>    <span style="color: #a04cc1;">for</span> <span style="color: #6b97e8;">sample</span> <span style="color: #7f6e38;">in</span> <span style="color: #6b97e8;">progress_bar</span><span style="color: #e3e11d;">:</span></p>
<p></p>
<p>        <span style="color: #6b97e8;">sentence</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">tokens</span> <span>=</span> <span style="color: #6b97e8;">sample</span></p>
<p>        </p>
<p>        <span style="color: #7f6e38;">#################### &quot;Fit as many joke sequences into MAX_SEQ_LEN sequence as possible&quot; logic start ####</span></p>
<p>        <span style="color: #6b97e8;">joke_tens</span> <span>=</span> <span style="color: #6b97e8;">tokens</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">]</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">device</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p>        <span style="color: #7f6e38;"># Skip sample from dataset if it is longer than MAX_SEQ_LEN</span></p>
<p>        <span style="color: #a04cc1;">if</span> <span style="color: #6b97e8;">joke_tens</span><span>.</span><span style="color: #6b97e8;">size</span><span style="color: #e3e11d;">()[</span><span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">]</span> <span>&gt;</span> <span style="color: #6b97e8;">MAX_SEQ_LEN</span><span style="color: #e3e11d;">:</span></p>
<p>            <span style="color: #a04cc1;">continue</span></p>
<p>        </p>
<p>        <span style="color: #7f6e38;"># The first joke sequence in the sequence</span></p>
<p>        <span style="color: #a04cc1;">if</span> <span style="color: #7f6e38;">not</span> <span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">is_tensor</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tmp_jokes_tens</span><span style="color: #e3e11d;">):</span></p>
<p>            <span style="color: #6b97e8;">tmp_jokes_tens</span> <span>=</span> <span style="color: #6b97e8;">joke_tens</span></p>
<p>            <span style="color: #a04cc1;">continue</span></p>
<p>        <span style="color: #a04cc1;">else</span><span style="color: #e3e11d;">:</span></p>
<p>            <span style="color: #7f6e38;"># The next joke does not fit in so we process the sequence and leave the last joke </span></p>
<p>            <span style="color: #7f6e38;"># as the start for next sequence </span></p>
<p>            <span style="color: #a04cc1;">if</span> <span style="color: #6b97e8;">tmp_jokes_tens</span><span>.</span><span style="color: #6b97e8;">size</span><span style="color: #e3e11d;">()[</span><span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">]</span> <span>+</span> <span style="color: #6b97e8;">joke_tens</span><span>.</span><span style="color: #6b97e8;">size</span><span style="color: #e3e11d;">()[</span><span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">]</span> <span>&gt;</span> <span style="color: #6b97e8;">MAX_SEQ_LEN</span><span style="color: #e3e11d;">:</span></p>
<p>                <span style="color: #6b97e8;">work_jokes_tens</span> <span>=</span> <span style="color: #6b97e8;">tmp_jokes_tens</span></p>
<p>                <span style="color: #6b97e8;">tmp_jokes_tens</span> <span>=</span> <span style="color: #6b97e8;">joke_tens</span></p>
<p>            <span style="color: #a04cc1;">else</span><span style="color: #e3e11d;">:</span></p>
<p>                <span style="color: #7f6e38;">#Add the joke to sequence, continue and try to add more</span></p>
<p>                <span style="color: #6b97e8;">tmp_jokes_tens</span> <span>=</span> <span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">cat</span><span style="color: #e3e11d;">([</span><span style="color: #6b97e8;">tmp_jokes_tens</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">joke_tens</span><span style="color: #e3e11d;">[:,</span><span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">:]],</span> <span style="color: #6b97e8;">dim</span><span>=</span><span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">)</span></p>
<p>                <span style="color: #a04cc1;">continue</span></p>
<p>        <span style="color: #7f6e38;">################## Sequence ready, process it trough the model ##################</span></p>
<p>            </p>
<p>        <span style="color: #6b97e8;">outputs</span> <span>=</span> <span style="color: #6b97e8;">model</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">work_jokes_tens</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">labels</span><span>=</span><span style="color: #6b97e8;">work_jokes_tens</span><span style="color: #e3e11d;">)</span></p>
<p>        <span style="color: #6b97e8;">loss</span> <span>=</span> <span style="color: #6b97e8;">outputs</span><span>.</span><span style="color: #6b97e8;">loss</span></p>
<p>        <span style="color: #6b97e8;">loss</span><span>.</span><span style="color: #6b97e8;">backward</span><span style="color: #e3e11d;">()</span></p>
<p>                       </p>
<p>        <span style="color: #6b97e8;">proc_seq_count</span> <span>=</span> <span style="color: #6b97e8;">proc_seq_count</span> <span>+</span> <span style="color: #7e7a38;">1</span></p>
<p>        <span style="color: #a04cc1;">if</span> <span style="color: #6b97e8;">proc_seq_count</span> <span>==</span> <span style="color: #6b97e8;">BATCH_SIZE</span><span style="color: #e3e11d;">:</span></p>
<p>            <span style="color: #6b97e8;">proc_seq_count</span> <span>=</span> <span style="color: #7e7a38;">0</span>    </p>
<p>            <span style="color: #6b97e8;">batch_count</span> <span>+=</span> <span style="color: #7e7a38;">1</span></p>
<p>            <span style="color: #6b97e8;">optimizer</span><span>.</span><span style="color: #6b97e8;">step</span><span style="color: #e3e11d;">()</span></p>
<p>            <span style="color: #6b97e8;">scheduler</span><span>.</span><span style="color: #6b97e8;">step</span><span style="color: #e3e11d;">()</span> </p>
<p>            <span style="color: #6b97e8;">optimizer</span><span>.</span><span style="color: #6b97e8;">zero_grad</span><span style="color: #e3e11d;">()</span></p>
<p>            <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">zero_grad</span><span style="color: #e3e11d;">()</span></p>
<p></p>
<p>        <span style="color: #6b97e8;">progress_bar</span><span>.</span><span style="color: #6b97e8;">set_postfix</span><span style="color: #e3e11d;">({</span><span style="color: #8d783e;">&#39;loss&#39;</span><span style="color: #e3e11d;">:</span> <span style="color: #6b97e8;">loss</span><span>.</span><span style="color: #6b97e8;">item</span><span style="color: #e3e11d;">(),</span> <span style="color: #8d783e;">&#39;lr&#39;</span><span style="color: #e3e11d;">:</span> <span style="color: #6b97e8;">scheduler</span><span>.</span><span style="color: #6b97e8;">get_last_lr</span><span style="color: #e3e11d;">()[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">]})</span></p>
<p>        <span style="color: #a04cc1;">if</span> <span style="color: #6b97e8;">batch_count</span> <span>==</span> <span style="color: #7e7a38;">10</span><span style="color: #e3e11d;">:</span></p>
<p>            <span style="color: #6b97e8;">batch_count</span> <span>=</span> <span style="color: #7e7a38;">0</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>Training: 100%|██████████| 231657/231657 [11:19&lt;00:00, 341.04it/s, loss=2.49, lr=1.47e-5]</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h4 id="Inference">
								<a class="anchor-link" href="#Inference">
									<p style="margin-left: 30px">Inference</p>
								</a>
							</h4>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Let's see how well the model makes jokes.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">sentence_joke</span> <span>=</span> <span style="color: #7e7a34;">&quot;JOKE:&quot;</span></p>
<p><span style="color: #6b97e8;">input_tokens_joke</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">sentence_joke</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">device</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">output_tokens_joke</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">input_tokens_joke</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">decoded_output_joke</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">output_tokens_joke</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;decoded joke: </span><span style="color: #a6a831;">\n</span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">decoded_output_joke</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>decoded joke: </p><p>joke : what do you call a group of people who are not afraid of the dark? a group</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">You can see that you pass it a sequence with the word <code><b>joke</b></code> and it returns a joke. But if you return another sequence it does not</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">sentence_joke</span> <span>=</span> <span style="color: #7e7a34;">&quot;My dog is cute and&quot;</span></p>
<p><span style="color: #6b97e8;">input_tokens_joke</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">sentence_joke</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">device</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">output_tokens_joke</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">input_tokens_joke</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">decoded_output_joke</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">output_tokens_joke</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;decoded joke: </span><span style="color: #a6a831;">\n</span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">decoded_output_joke</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>decoded joke: </p><p>my dog is cute and i'm not sure if i should be offended or not. " </p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
		</div>
	<!-- Close class contenido -->
	</div>
<!-- Close div notebook container -->
</div>
<!-- Close div notebook -->
</div>

