<section class="section-block-markdown-cell">
<h1 id="Ajuste fino de SLMs com Hugging Face">Ajuste fino de SLMs com Hugging Face<a class="anchor-link" href="#Ajuste fino de SLMs com Hugging Face">¶</a></h1>
</section>
<section class="section-block-markdown-cell">
<blockquote>
<p>Aviso: Este post foi traduzido para o português usando um modelo de tradução automática. Por favor, me avise se encontrar algum erro.</p>
</blockquote>
</section>
<section class="section-block-markdown-cell">
<p>Neste post, vamos ver como fazer fine tuning em pequenos modelos de linguagem, vamos ver como fazer fine tuning para classificação de texto e para geração de texto. Primeiro, vamos ver como fazer isso com as bibliotecas do Hugging Face, já que o Hugging Face se tornou um ator muito importante no ecossistema de IA neste momento.</p>
<p>Mas embora as bibliotecas do Hugging Face sejam muito importantes e úteis, é muito importante saber como o treinamento realmente acontece e o que está acontecendo por baixo dos panos, então vamos repetir o treinamento para classificação e geração de texto, mas com Pytorch.</p>
</section>
<section class="section-block-markdown-cell">
<h2 id="Ajuste fino para classificacao de texto com Hugging Face">Ajuste fino para classificação de texto com Hugging Face<a class="anchor-link" href="#Ajuste fino para classificacao de texto com Hugging Face">¶</a></h2>
</section>
<section class="section-block-markdown-cell">
<h3 id="Login">Login<a class="anchor-link" href="#Login">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Para poder subir o resultado do treinamento ao hub devemos nos autenticar primeiro, para isso precisamos de um token</p>
<p>Para criar um token, é necessário ir à página de <a href="https://huggingface.co/settings/tokens">settings/tokens</a> da nossa conta, onde aparecerá algo assim</p>
<img src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/User-Access-Token-dark.webp" alt="User-Access-Token-dark">
<p>Damos a <code>New token</code> e será exibida uma janela para criar um novo token</p>
<img src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/new-token-dark.webp" alt="new-token-dark">
<p>Damos um nome ao token e o criamos com o papel <code>write</code>, ou com o papel <code>Fine-grained</code>, que nos permite selecionar exatamente quais permissões o token terá.</p>
<p>Uma vez criado, copiamos e colamos a seguir.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">huggingface_hub</span><span class="w"> </span><span class="kn">import</span> <span class="n">notebook_login</span>
<span class="n">notebook_login</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Conjunto de Dados">Conjunto de Dados<a class="anchor-link" href="#Conjunto de Dados">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Agora vamos baixar um dataset, neste caso vamos baixar um de avaliações do <a href="https://huggingface.co/datasets/mteb/amazon_reviews_multi">Amazon</a></p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="w"> </span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;mteb/amazon_reviews_multi&quot;</span><span class="p">,</span> <span class="s2">&quot;en&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vamos vê-lo um pouco</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">dataset</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>DatasetDict(&#x7B;
&#x20;&#x20;&#x20;&#x20;train: Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;id&#x27;, &#x27;text&#x27;, &#x27;label&#x27;, &#x27;label_text&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 200000
&#x20;&#x20;&#x20;&#x20;&#x7D;)
&#x20;&#x20;&#x20;&#x20;validation: Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;id&#x27;, &#x27;text&#x27;, &#x27;label&#x27;, &#x27;label_text&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 5000
&#x20;&#x20;&#x20;&#x20;&#x7D;)
&#x20;&#x20;&#x20;&#x20;test: Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;id&#x27;, &#x27;text&#x27;, &#x27;label&#x27;, &#x27;label_text&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 5000
&#x20;&#x20;&#x20;&#x20;&#x7D;)
&#x7D;)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vemos que tem um conjunto de treinamento com 200.000 amostras, um de validação com 5.000 amostras e um de teste com 5.000 amostras.</p>
</section>
<section class="section-block-markdown-cell">
<p>Vamos a ver um exemplo do conjunto de treinamento</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">random</span><span class="w"> </span><span class="kn">import</span> <span class="n">randint</span>
<span class="w"> </span>
<span class="n">idx</span> <span class="o">=</span> <span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&#x7B;&#x27;id&#x27;: &#x27;en_0907914&#x27;,
 &#x27;text&#x27;: &#x27;Mixed with fir it’s passable\n\nNot the scent I had hoped for . Love the scent of cedar, but this one missed&#x27;,
 &#x27;label&#x27;: 3,
 &#x27;label_text&#x27;: &#x27;3&#x27;&#x7D;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vemos que tem a avaliação no campo <code>text</code> e a pontuação que o usuário deu no campo <code>label</code></p>
</section>
<section class="section-block-markdown-cell">
<p>Como vamos a fazer um modelo de classificação de textos, precisamos saber quantas classes vamos ter.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="s1">&#39;label&#39;</span><span class="p">))</span>
<span class="n">num_classes</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>5
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vamos a ter 5 classes, agora vamos a ver o valor mínimo dessas classes para saber se a pontuação começa em 0 ou em 1. Para isso, usamos o método <code>unique</code></p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">dataset</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="s1">&#39;label&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&#x7B;&#x27;train&#x27;: [0, 1, 2, 3, 4],
 &#x27;validation&#x27;: [0, 1, 2, 3, 4],
 &#x27;test&#x27;: [0, 1, 2, 3, 4]&#x7D;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>O valor mínimo será 0</p>
</section>
<section class="section-block-markdown-cell">
<p>Para treinar, as etiquetas precisam estar em um campo chamado <code>labels</code>, enquanto no nosso conjunto de dados está em um campo chamado <code>label</code>, então criamos o novo campo <code>labels</code> com o mesmo valor que <code>label</code></p>
</section>
<section class="section-block-markdown-cell">
<p>Criamos uma função que faça o que quisermos</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">set_labels</span><span class="p">(</span><span class="n">example</span><span class="p">):</span>
<span class="w">    </span><span class="n">example</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">example</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span>
<span class="w">    </span><span class="k">return</span> <span class="n">example</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Aplicamos a função ao conjunto de dados</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">set_labels</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vamos ver como fica o dataset</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&#x7B;&#x27;id&#x27;: &#x27;en_0907914&#x27;,
 &#x27;text&#x27;: &#x27;Mixed with fir it’s passable\n\nNot the scent I had hoped for . Love the scent of cedar, but this one missed&#x27;,
 &#x27;label&#x27;: 3,
 &#x27;label_text&#x27;: &#x27;3&#x27;,
 &#x27;labels&#x27;: 3&#x7D;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Tokenizador">Tokenizador<a class="anchor-link" href="#Tokenizador">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Como temos as avaliações em texto no conjunto de dados, precisamos tokenizá-las para poder inserir os tokens no modelo.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>
<span class="w"> </span>
<span class="n">checkpoint</span> <span class="o">=</span> <span class="s2">&quot;openai-community/gpt2&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Agora criamos uma função para tokenizar o texto. Vamos fazer isso de maneira que todas as frases tenham o mesmo comprimento, de modo que o tokenizador truncará quando necessário e adicionará tokens de padding quando necessário. Além disso, indicamos que retorne tensores do pytorch.</p>
</section>
<section class="section-block-markdown-cell">
<p>Fazemos com que o comprimento de cada sentença seja de 768 tokens porque estamos usando o modelo pequeno do GPT2, que como vimos no post de <a href="https://maximofn.com/gpt2/#Arquitectura">GPT2</a> tem uma dimensão de embedding de 768 tokens</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vamos a provar a tokenizar um texto</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">][</span><span class="n">idx</span><span class="p">])</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>---------------------------------------------------------------------------ValueError                                Traceback (most recent call last)Cell In[11], line 1
----&amp;gt; 1 tokens = tokenize_function(dataset[&#x27;train&#x27;][idx])
Cell In[10], line 2, in tokenize_function(examples)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;1 def tokenize_function(examples):
----&amp;gt; 2     return tokenizer(examples[&quot;text&quot;], padding=&quot;max_length&quot;, truncation=True, max_length=768, return_tensors=&quot;pt&quot;)
File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2883, in PreTrainedTokenizerBase.__call__(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)
&#x20;&#x20;&#x20;2881     if not self._in_target_context_manager:
&#x20;&#x20;&#x20;2882         self._switch_to_input_mode()
-&amp;gt; 2883     encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
&#x20;&#x20;&#x20;2884 if text_target is not None:
&#x20;&#x20;&#x20;2885     self._switch_to_target_mode()
File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2989, in PreTrainedTokenizerBase._call_one(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)
&#x20;&#x20;&#x20;2969     return self.batch_encode_plus(
&#x20;&#x20;&#x20;2970         batch_text_or_text_pairs=batch_text_or_text_pairs,
&#x20;&#x20;&#x20;2971         add_special_tokens=add_special_tokens,
&#x20;&#x20;&#x20;(...)
&#x20;&#x20;&#x20;2986         **kwargs,
&#x20;&#x20;&#x20;2987     )
&#x20;&#x20;&#x20;2988 else:
-&amp;gt; 2989     return self.encode_plus(
&#x20;&#x20;&#x20;2990         text=text,
&#x20;&#x20;&#x20;2991         text_pair=text_pair,
&#x20;&#x20;&#x20;2992         add_special_tokens=add_special_tokens,
&#x20;&#x20;&#x20;2993         padding=padding,
&#x20;&#x20;&#x20;2994         truncation=truncation,
&#x20;&#x20;&#x20;2995         max_length=max_length,
&#x20;&#x20;&#x20;2996         stride=stride,
&#x20;&#x20;&#x20;2997         is_split_into_words=is_split_into_words,
&#x20;&#x20;&#x20;2998         pad_to_multiple_of=pad_to_multiple_of,
&#x20;&#x20;&#x20;2999         return_tensors=return_tensors,
&#x20;&#x20;&#x20;3000         return_token_type_ids=return_token_type_ids,
&#x20;&#x20;&#x20;3001         return_attention_mask=return_attention_mask,
&#x20;&#x20;&#x20;3002         return_overflowing_tokens=return_overflowing_tokens,
&#x20;&#x20;&#x20;3003         return_special_tokens_mask=return_special_tokens_mask,
&#x20;&#x20;&#x20;3004         return_offsets_mapping=return_offsets_mapping,
&#x20;&#x20;&#x20;3005         return_length=return_length,
&#x20;&#x20;&#x20;3006         verbose=verbose,
&#x20;&#x20;&#x20;3007         **kwargs,
&#x20;&#x20;&#x20;3008     )
File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3053, in PreTrainedTokenizerBase.encode_plus(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)
&#x20;&#x20;&#x20;3032 &quot;&quot;&quot;
&#x20;&#x20;&#x20;3033 Tokenize and prepare for the model a sequence or a pair of sequences.
&#x20;&#x20;&#x20;3034 
&#x20;&#x20;&#x20;(...)
&#x20;&#x20;&#x20;3049         method).
&#x20;&#x20;&#x20;3050 &quot;&quot;&quot;
&#x20;&#x20;&#x20;3052 # Backward compatibility for &#x27;truncation_strategy&#x27;, &#x27;pad_to_max_length&#x27;
-&amp;gt; 3053 padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
&#x20;&#x20;&#x20;3054     padding=padding,
&#x20;&#x20;&#x20;3055     truncation=truncation,
&#x20;&#x20;&#x20;3056     max_length=max_length,
&#x20;&#x20;&#x20;3057     pad_to_multiple_of=pad_to_multiple_of,
&#x20;&#x20;&#x20;3058     verbose=verbose,
&#x20;&#x20;&#x20;3059     **kwargs,
&#x20;&#x20;&#x20;3060 )
&#x20;&#x20;&#x20;3062 return self._encode_plus(
&#x20;&#x20;&#x20;3063     text=text,
&#x20;&#x20;&#x20;3064     text_pair=text_pair,
&#x20;&#x20;&#x20;(...)
&#x20;&#x20;&#x20;3080     **kwargs,
&#x20;&#x20;&#x20;3081 )
File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2788, in PreTrainedTokenizerBase._get_padding_truncation_strategies(self, padding, truncation, max_length, pad_to_multiple_of, verbose, **kwargs)
&#x20;&#x20;&#x20;2786 # Test if we have a padding token
&#x20;&#x20;&#x20;2787 if padding_strategy != PaddingStrategy.DO_NOT_PAD and (self.pad_token is None or self.pad_token_id &amp;lt; 0):
-&amp;gt; 2788     raise ValueError(
&#x20;&#x20;&#x20;2789         &quot;Asking to pad but the tokenizer does not have a padding token. &quot;
&#x20;&#x20;&#x20;2790         &quot;Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` &quot;
&#x20;&#x20;&#x20;2791         &quot;or add a new pad token via `tokenizer.add_special_tokens(&#x7B;&#x27;pad_token&#x27;: &#x27;[PAD]&#x27;&#x7D;)`.&quot;
&#x20;&#x20;&#x20;2792     )
&#x20;&#x20;&#x20;2794 # Check that we will truncate to a multiple of pad_to_multiple_of if both are provided
&#x20;&#x20;&#x20;2795 if (
&#x20;&#x20;&#x20;2796     truncation_strategy != TruncationStrategy.DO_NOT_TRUNCATE
&#x20;&#x20;&#x20;2797     and padding_strategy != PaddingStrategy.DO_NOT_PAD
&#x20;&#x20;&#x20;(...)
&#x20;&#x20;&#x20;2800     and (max_length % pad_to_multiple_of != 0)
&#x20;&#x20;&#x20;2801 ):
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens(&#x7B;&#x27;pad_token&#x27;: &#x27;[PAD]&#x27;&#x7D;)`.
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Dá-nos um erro porque o tokenizador do GPT2 não tem um token para preenchimento e pede que atribuamos um, além de sugerir fazer <code>tokenizer.pad_token = tokenizer.eos_token</code>, então fazemos isso.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Voltamos a testar a função de tokenização</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenize_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">][</span><span class="n">idx</span><span class="p">])</span>
<span class="n">tokens</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">tokens</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>(torch.Size([1, 768]), torch.Size([1, 768]))
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Agora que verificamos que a função tokeniza corretamente, aplicamos essa função ao conjunto de dados, mas também a aplicamos em lotes para que seja executada mais rapidamente.</p>
<p>Além disso, aproveitamos e eliminamos as colunas que não vamos precisar.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="s1">&#39;label_text&#39;</span><span class="p">])</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vamos ver agora como fica o dataset</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">dataset</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>DatasetDict(&#x7B;
&#x20;&#x20;&#x20;&#x20;train: Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;id&#x27;, &#x27;text&#x27;, &#x27;label&#x27;, &#x27;label_text&#x27;, &#x27;labels&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 200000
&#x20;&#x20;&#x20;&#x20;&#x7D;)
&#x20;&#x20;&#x20;&#x20;validation: Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;id&#x27;, &#x27;text&#x27;, &#x27;label&#x27;, &#x27;label_text&#x27;, &#x27;labels&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 5000
&#x20;&#x20;&#x20;&#x20;&#x7D;)
&#x20;&#x20;&#x20;&#x20;test: Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;id&#x27;, &#x27;text&#x27;, &#x27;label&#x27;, &#x27;label_text&#x27;, &#x27;labels&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 5000
&#x20;&#x20;&#x20;&#x20;&#x7D;)
&#x7D;)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vemos que temos os campos 'labels', 'input_ids' e 'attention_mask', que é o que nos interessa para treinar.</p>
</section>
<section class="section-block-markdown-cell">
<h3 id="Modelo">Modelo<a class="anchor-link" href="#Modelo">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Instanciamos um modelo para classificação de sequências e indicamos o número de classes que temos</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="n">num_classes</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: [&#x27;score.weight&#x27;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Diz que os pesos da camada <code>score</code> foram inicializados de maneira aleatória e que temos que reentreiná-los, vamos ver por que isso acontece.</p>
</section>
<section class="section-block-markdown-cell">
<p>O modelo GPT2 seria este</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span>
<span class="w"> </span>
<span class="n">casual_model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Enquanto o modelo do GPT2 para gerar texto é este</p>
</section>
<section class="section-block-markdown-cell">
<p>Vamos a ver sua arquitetura</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">casual_model</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>GPT2LMHeadModel(
&#x20;&#x20;(transformer): GPT2Model(
&#x20;&#x20;&#x20;&#x20;(wte): Embedding(50257, 768)
&#x20;&#x20;&#x20;&#x20;(wpe): Embedding(1024, 768)
&#x20;&#x20;&#x20;&#x20;(drop): Dropout(p=0.1, inplace=False)
&#x20;&#x20;&#x20;&#x20;(h): ModuleList(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(0-11): 12 x GPT2Block(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(attn): GPT2Attention(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(c_attn): Conv1D()
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(c_proj): Conv1D()
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(attn_dropout): Dropout(p=0.1, inplace=False)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(resid_dropout): Dropout(p=0.1, inplace=False)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(mlp): GPT2MLP(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(c_fc): Conv1D()
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(c_proj): Conv1D()
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(act): NewGELUActivation()
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(dropout): Dropout(p=0.1, inplace=False)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)
&#x20;&#x20;&#x20;&#x20;)
&#x20;&#x20;&#x20;&#x20;(ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
&#x20;&#x20;)
&#x20;&#x20;(lm_head): Linear(in_features=768, out_features=50257, bias=False)
)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>E agora a arquitetura do modelo que vamos usar para classificar as reviews</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">model</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>GPT2ForSequenceClassification(
&#x20;&#x20;(transformer): GPT2Model(
&#x20;&#x20;&#x20;&#x20;(wte): Embedding(50257, 768)
&#x20;&#x20;&#x20;&#x20;(wpe): Embedding(1024, 768)
&#x20;&#x20;&#x20;&#x20;(drop): Dropout(p=0.1, inplace=False)
&#x20;&#x20;&#x20;&#x20;(h): ModuleList(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(0-11): 12 x GPT2Block(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(attn): GPT2Attention(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(c_attn): Conv1D()
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(c_proj): Conv1D()
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(attn_dropout): Dropout(p=0.1, inplace=False)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(resid_dropout): Dropout(p=0.1, inplace=False)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(mlp): GPT2MLP(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(c_fc): Conv1D()
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(c_proj): Conv1D()
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(act): NewGELUActivation()
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(dropout): Dropout(p=0.1, inplace=False)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)
&#x20;&#x20;&#x20;&#x20;)
&#x20;&#x20;&#x20;&#x20;(ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
&#x20;&#x20;)
&#x20;&#x20;(score): Linear(in_features=768, out_features=5, bias=False)
)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Aqui há duas coisas para mencionar</p>
<ul>
  <li>A primeira é que em ambos, a primeira camada tem dimensões de 50257x768, o que corresponde a 50257 possíveis tokens do vocabulário do GPT2 e a 768 dimensões do embedding, por isso fizemos bem em tokenizar as avaliações com um tamanho de 768 tokens</li>
  <li>A segunda é que o modelo <code>casual</code> (o de geração de texto) tem no final uma camada <code>Linear</code> que gera 50257 valores, ou seja, é responsável por prever o próximo token e dar um valor a um possível token. Enquanto isso, o modelo de classificação tem uma camada <code>Linear</code> que gera apenas 5 valores, um para cada classe, o que nos fornecerá a probabilidade de a review pertencer a cada classe.</li>
</ul>
<p>Por isso recebíamos a mensagem de que os pesos da camada <code>score</code> haviam sido inicializados de forma aleatória, porque a biblioteca transformers removeu a camada <code>Linear</code> de 768x50257 e adicionou uma camada <code>Linear</code> de 768x5, inicializou-a com valores aleatórios e nós temos que treiná-la para o nosso problema específico.</p>
</section>
<section class="section-block-markdown-cell">
<p>Apagamos o modelo casual, pois não vamos usá-lo.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">del</span> <span class="n">casual_model</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Treinador">Treinador<a class="anchor-link" href="#Treinador">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Vamos agora a configurar os argumentos do treinamento</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">TrainingArguments</span>
<span class="w"> </span>
<span class="n">metric_name</span> <span class="o">=</span> <span class="s2">&quot;accuracy&quot;</span>
<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;GPT2-small-finetuned-amazon-reviews-en-classification&quot;</span>
<span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>
<span class="n">BS_TRAIN</span> <span class="o">=</span> <span class="mi">28</span>
<span class="n">BS_EVAL</span> <span class="o">=</span> <span class="mi">40</span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">WEIGHT_DECAY</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="w"> </span>
<span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
<span class="w">    </span><span class="n">model_name</span><span class="p">,</span>
<span class="w">    </span><span class="n">eval_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="n">save_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>
<span class="w">    </span><span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>
<span class="w">    </span><span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>
<span class="w">    </span><span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>
<span class="w">    </span><span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>
<span class="w">    </span><span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">&quot;cosine&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
<span class="w">    </span><span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="w">    </span><span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="w">    </span><span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span>
<span class="w">    </span><span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Definimos uma métrica para o dataloader de validação</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">evaluate</span><span class="w"> </span><span class="kn">import</span> <span class="n">load</span>
<span class="w"> </span>
<span class="n">metric</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">def</span><span class="w"> </span><span class="nf">compute_metrics</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">):</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">)</span>
<span class="w">    </span><span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">eval_pred</span>
<span class="w">    </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="w">    </span><span class="k">return</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Definimos agora o treinador</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Trainer</span>
<span class="w"> </span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
<span class="w">    </span><span class="n">model</span><span class="p">,</span>
<span class="w">    </span><span class="n">training_args</span><span class="p">,</span>
<span class="w">    </span><span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">],</span>
<span class="w">    </span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;validation&#39;</span><span class="p">],</span>
<span class="w">    </span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
<span class="w">    </span><span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Treinamos</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&#x20;&#x20;0%|          | 0/600000 [00:00&amp;lt;?, ?it/s]
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>---------------------------------------------------------------------------ValueError                                Traceback (most recent call last)Cell In[21], line 1
----&amp;gt; 1 trainer.train()
File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/trainer.py:1876, in Trainer.train(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)
&#x20;&#x20;&#x20;1873 try:
&#x20;&#x20;&#x20;1874     # Disable progress bars when uploading models during checkpoints to avoid polluting stdout
&#x20;&#x20;&#x20;1875     hf_hub_utils.disable_progress_bars()
-&amp;gt; 1876     return inner_training_loop(
&#x20;&#x20;&#x20;1877         args=args,
&#x20;&#x20;&#x20;1878         resume_from_checkpoint=resume_from_checkpoint,
&#x20;&#x20;&#x20;1879         trial=trial,
&#x20;&#x20;&#x20;1880         ignore_keys_for_eval=ignore_keys_for_eval,
&#x20;&#x20;&#x20;1881     )
&#x20;&#x20;&#x20;1882 finally:
&#x20;&#x20;&#x20;1883     hf_hub_utils.enable_progress_bars()
File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/trainer.py:2178, in Trainer._inner_training_loop(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)
&#x20;&#x20;&#x20;2175     rng_to_sync = True
&#x20;&#x20;&#x20;2177 step = -1
-&amp;gt; 2178 for step, inputs in enumerate(epoch_iterator):
&#x20;&#x20;&#x20;2179     total_batched_samples += 1
&#x20;&#x20;&#x20;2181     if self.args.include_num_input_tokens_seen:
File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/accelerate/data_loader.py:454, in DataLoaderShard.__iter__(self)
&#x20;&#x20;&#x20;&#x20;452 # We iterate one batch ahead to check when we are at the end
&#x20;&#x20;&#x20;&#x20;453 try:
--&amp;gt; 454     current_batch = next(dataloader_iter)
&#x20;&#x20;&#x20;&#x20;455 except StopIteration:
&#x20;&#x20;&#x20;&#x20;456     yield
File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631, in _BaseDataLoaderIter.__next__(self)
&#x20;&#x20;&#x20;&#x20;628 if self._sampler_iter is None:
&#x20;&#x20;&#x20;&#x20;629     # TODO(https://github.com/pytorch/pytorch/issues/76750)
&#x20;&#x20;&#x20;&#x20;630     self._reset()  # type: ignore[call-arg]
--&amp;gt; 631 data = self._next_data()
&#x20;&#x20;&#x20;&#x20;632 self._num_yielded += 1
&#x20;&#x20;&#x20;&#x20;633 if self._dataset_kind == _DatasetKind.Iterable and \
&#x20;&#x20;&#x20;&#x20;634         self._IterableDataset_len_called is not None and \
&#x20;&#x20;&#x20;&#x20;635         self._num_yielded &amp;gt; self._IterableDataset_len_called:
File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675, in _SingleProcessDataLoaderIter._next_data(self)
&#x20;&#x20;&#x20;&#x20;673 def _next_data(self):
&#x20;&#x20;&#x20;&#x20;674     index = self._next_index()  # may raise StopIteration
--&amp;gt; 675     data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
&#x20;&#x20;&#x20;&#x20;676     if self._pin_memory:
&#x20;&#x20;&#x20;&#x20;677         data = _utils.pin_memory.pin_memory(data, self._pin_memory_device)
File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:54, in _MapDatasetFetcher.fetch(self, possibly_batched_index)
&#x20;&#x20;&#x20;&#x20;&#x20;52 else:
&#x20;&#x20;&#x20;&#x20;&#x20;53     data = self.dataset[possibly_batched_index]
---&amp;gt; 54 return self.collate_fn(data)
File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/data/data_collator.py:271, in DataCollatorWithPadding.__call__(self, features)
&#x20;&#x20;&#x20;&#x20;270 def __call__(self, features: List[Dict[str, Any]]) -&amp;gt; Dict[str, Any]:
--&amp;gt; 271     batch = pad_without_fast_tokenizer_warning(
&#x20;&#x20;&#x20;&#x20;272         self.tokenizer,
&#x20;&#x20;&#x20;&#x20;273         features,
&#x20;&#x20;&#x20;&#x20;274         padding=self.padding,
&#x20;&#x20;&#x20;&#x20;275         max_length=self.max_length,
&#x20;&#x20;&#x20;&#x20;276         pad_to_multiple_of=self.pad_to_multiple_of,
&#x20;&#x20;&#x20;&#x20;277         return_tensors=self.return_tensors,
&#x20;&#x20;&#x20;&#x20;278     )
&#x20;&#x20;&#x20;&#x20;279     if &quot;label&quot; in batch:
&#x20;&#x20;&#x20;&#x20;280         batch[&quot;labels&quot;] = batch[&quot;label&quot;]
File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/data/data_collator.py:66, in pad_without_fast_tokenizer_warning(tokenizer, *pad_args, **pad_kwargs)
&#x20;&#x20;&#x20;&#x20;&#x20;63 tokenizer.deprecation_warnings[&quot;Asking-to-pad-a-fast-tokenizer&quot;] = True
&#x20;&#x20;&#x20;&#x20;&#x20;65 try:
---&amp;gt; 66     padded = tokenizer.pad(*pad_args, **pad_kwargs)
&#x20;&#x20;&#x20;&#x20;&#x20;67 finally:
&#x20;&#x20;&#x20;&#x20;&#x20;68     # Restore the state of the warning.
&#x20;&#x20;&#x20;&#x20;&#x20;69     tokenizer.deprecation_warnings[&quot;Asking-to-pad-a-fast-tokenizer&quot;] = warning_state
File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3299, in PreTrainedTokenizerBase.pad(self, encoded_inputs, padding, max_length, pad_to_multiple_of, return_attention_mask, return_tensors, verbose)
&#x20;&#x20;&#x20;3297 # The model&#x27;s main input name, usually `input_ids`, has be passed for padding
&#x20;&#x20;&#x20;3298 if self.model_input_names[0] not in encoded_inputs:
-&amp;gt; 3299     raise ValueError(
&#x20;&#x20;&#x20;3300         &quot;You should supply an encoding or a list of encodings to this method &quot;
&#x20;&#x20;&#x20;3301         f&quot;that includes &#x7B;self.model_input_names[0]&#x7D;, but you provided &#x7B;list(encoded_inputs.keys())&#x7D;&quot;
&#x20;&#x20;&#x20;3302     )
&#x20;&#x20;&#x20;3304 required_input = encoded_inputs[self.model_input_names[0]]
&#x20;&#x20;&#x20;3306 if required_input is None or (isinstance(required_input, Sized) and len(required_input) == 0):
ValueError: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided [&#x27;label&#x27;, &#x27;labels&#x27;]
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Nós recebemos novamente um erro porque o modelo não tem um token de padding atribuído, então, assim como com o tokenizador, nós o atribuímos.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Recriamos os argumentos do treinador com o novo modelo, que agora tem um token de padding, o treinador e voltamos a treinar.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
<span class="w">    </span><span class="n">model_name</span><span class="p">,</span>
<span class="w">    </span><span class="n">eval_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="n">save_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>
<span class="w">    </span><span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>
<span class="w">    </span><span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>
<span class="w">    </span><span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>
<span class="w">    </span><span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>
<span class="w">    </span><span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">&quot;cosine&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
<span class="w">    </span><span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="w">    </span><span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="w">    </span><span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span>
<span class="w">    </span><span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="w">    </span><span class="n">logging_dir</span><span class="o">=</span><span class="s2">&quot;./runs&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="w"> </span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
<span class="w">    </span><span class="n">model</span><span class="p">,</span>
<span class="w">    </span><span class="n">training_args</span><span class="p">,</span>
<span class="w">    </span><span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">],</span>
<span class="w">    </span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;validation&#39;</span><span class="p">],</span>
<span class="w">    </span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
<span class="w">    </span><span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Agora que vimos que tudo está bem, podemos treinar</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&amp;lt;IPython.core.display.HTML object&amp;gt;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&amp;lt;IPython.core.display.HTML object&amp;gt;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&amp;lt;transformers.trainer_utils.EvalPrediction object at 0x782767ea1450&amp;gt;
&amp;lt;transformers.trainer_utils.EvalPrediction object at 0x782767eeefe0&amp;gt;
&amp;lt;transformers.trainer_utils.EvalPrediction object at 0x782767eecfd0&amp;gt;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>TrainOutput(global_step=21429, training_loss=0.7846888848762739, metrics=&#x7B;&#x27;train_runtime&#x27;: 26367.7801, &#x27;train_samples_per_second&#x27;: 22.755, &#x27;train_steps_per_second&#x27;: 0.813, &#x27;total_flos&#x27;: 2.35173445632e+17, &#x27;train_loss&#x27;: 0.7846888848762739, &#x27;epoch&#x27;: 3.0&#x7D;)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Avaliacao">Avaliação<a class="anchor-link" href="#Avaliacao">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Uma vez treinado, avaliamos sobre o dataset de teste</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">])</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&amp;lt;IPython.core.display.HTML object&amp;gt;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&amp;lt;transformers.trainer_utils.EvalPrediction object at 0x7826ddfded40&amp;gt;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&#x7B;&#x27;eval_loss&#x27;: 0.7973636984825134,
 &#x27;eval_accuracy&#x27;: 0.6626,
 &#x27;eval_runtime&#x27;: 76.3016,
 &#x27;eval_samples_per_second&#x27;: 65.529,
 &#x27;eval_steps_per_second&#x27;: 1.638,
 &#x27;epoch&#x27;: 3.0&#x7D;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Publicar o modelo">Publicar o modelo<a class="anchor-link" href="#Publicar o modelo">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Já temos nosso modelo treinado, agora podemos compartilhá-lo com o mundo, então primeiro criamos uma **ficha do modelo**</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">create_model_card</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>E já podemos publicá-lo. Como a primeira coisa que fizemos foi fazer login no hub do huggingface, podemos enviá-lo para o nosso hub sem nenhum problema.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">push_to_hub</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Uso do modelo">Uso do modelo<a class="anchor-link" href="#Uso do modelo">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Limpamos tudo o que for possível</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">gc</span>
<span class="w"> </span>

<span class="k">def</span><span class="w"> </span><span class="nf">clear_hardwares</span><span class="p">():</span>
<span class="w">    </span><span class="n">torch</span><span class="o">.</span><span class="n">clear_autocast_cache</span><span class="p">()</span>
<span class="w">    </span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">ipc_collect</span><span class="p">()</span>
<span class="w">    </span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
<span class="w">    </span><span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
<span class="w"> </span>

<span class="n">clear_hardwares</span><span class="p">()</span>
<span class="n">clear_hardwares</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Como subimos o modelo ao nosso hub, podemos baixá-lo e usá-lo</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">pipeline</span>
<span class="w"> </span>
<span class="n">user</span> <span class="o">=</span> <span class="s2">&quot;maximofn&quot;</span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">user</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="n">task</span> <span class="o">=</span> <span class="s2">&quot;text-classification&quot;</span>
<span class="n">classifier</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">checkpoints</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">checkpoints</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Agora, se quisermos que nos retorne a probabilidade de todas as classes, simplesmente usamos o classificador que acabamos de instanciar, com o parâmetro <code>top_k=None</code></p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">labels</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="s2">&quot;I love this product&quot;</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">labels</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>[&#x7B;&#x27;label&#x27;: &#x27;LABEL_4&#x27;, &#x27;score&#x27;: 0.8253807425498962&#x7D;,
 &#x7B;&#x27;label&#x27;: &#x27;LABEL_3&#x27;, &#x27;score&#x27;: 0.15411493182182312&#x7D;,
 &#x7B;&#x27;label&#x27;: &#x27;LABEL_2&#x27;, &#x27;score&#x27;: 0.013907806016504765&#x7D;,
 &#x7B;&#x27;label&#x27;: &#x27;LABEL_0&#x27;, &#x27;score&#x27;: 0.003939222544431686&#x7D;,
 &#x7B;&#x27;label&#x27;: &#x27;LABEL_1&#x27;, &#x27;score&#x27;: 0.0026572425849735737&#x7D;]
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Se quisermos apenas a classe com a maior probabilidade, fazemos o mesmo mas com o parâmetro <code>top_k=1</code></p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">label</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="s2">&quot;I love this product&quot;</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">label</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>[&#x7B;&#x27;label&#x27;: &#x27;LABEL_4&#x27;, &#x27;score&#x27;: 0.8253807425498962&#x7D;]
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>E se quisermos n classes, fazemos o mesmo mas com o parâmetro <code>top_k=n</code></p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">two_labels</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="s2">&quot;I love this product&quot;</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">two_labels</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>[&#x7B;&#x27;label&#x27;: &#x27;LABEL_4&#x27;, &#x27;score&#x27;: 0.8253807425498962&#x7D;,
 &#x7B;&#x27;label&#x27;: &#x27;LABEL_3&#x27;, &#x27;score&#x27;: 0.15411493182182312&#x7D;]
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Também podemos testar o modelo com Automodel e AutoTokenizer</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="w"> </span>
<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;GPT2-small-finetuned-amazon-reviews-en-classification&quot;</span>
<span class="n">user</span> <span class="o">=</span> <span class="s2">&quot;maximofn&quot;</span>
<span class="n">checkpoint</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">user</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">5</span>
<span class="w"> </span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="n">num_classes</span><span class="p">)</span><span class="o">.</span><span class="n">half</span><span class="p">()</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">&quot;I love this product&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="w">    </span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
<span class="n">logits</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">logits</span>
<span class="n">lables</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">lables</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>[0.003963470458984375,
 0.0026721954345703125,
 0.01397705078125,
 0.154541015625,
 0.82470703125]
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Se você quiser testar mais o modelo, você pode vê-lo em <a href="https://huggingface.co/Maximofn/GPT2-small-finetuned-amazon-reviews-en-classification">Maximofn/GPT2-small-finetuned-amazon-reviews-en-classification</a></p>
</section>
<section class="section-block-markdown-cell">
<h2 id="Ajuste fino para geracao de texto com Hugging Face">Ajuste fino para geração de texto com Hugging Face<a class="anchor-link" href="#Ajuste fino para geracao de texto com Hugging Face">¶</a></h2>
</section>
<section class="section-block-markdown-cell">
<p>Para garantizar que não tenho problemas de memória VRAM, reinicio o notebook</p>
</section>
<section class="section-block-markdown-cell">
<h3 id="Login">Login<a class="anchor-link" href="#Login">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Para poder fazer o upload do resultado do treinamento para o hub, devemos nos autenticar primeiro, para isso precisamos de um token</p>
<p>Para criar um token é necessário ir à página de <a href="https://huggingface.co/settings/tokens">settings/tokens</a> da nossa conta, aparecerá algo assim</p>
<img src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/User-Access-Token-dark.webp" alt="User-Access-Token-dark">
<p>Damos a <code>New token</code> e uma janela aparecerá para criar um novo token</p>
<img src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/new-token-dark.webp" alt="new-token-dark">
<p>Damos um nome ao token e o criamos com o papel <code>write</code>, ou com o papel <code>Fine-grained</code>, que nos permite selecionar exatamente quais permissões terá o token.</p>
<p>Uma vez criado, copiamos e colamos a seguir.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">huggingface_hub</span><span class="w"> </span><span class="kn">import</span> <span class="n">notebook_login</span>
<span class="n">notebook_login</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Conjunto de Dados">Conjunto de Dados<a class="anchor-link" href="#Conjunto de Dados">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Vamos a usar um dataset de <a href="https://huggingface.co/datasets/Maximofn/short-jokes-dataset">chistes em inglês</a></p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="w"> </span>
<span class="n">jokes</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;Maximofn/short-jokes-dataset&quot;</span><span class="p">)</span>
<span class="n">jokes</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>DatasetDict(&#x7B;
&#x20;&#x20;&#x20;&#x20;train: Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;ID&#x27;, &#x27;Joke&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 231657
&#x20;&#x20;&#x20;&#x20;&#x7D;)
&#x7D;)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vamos vê-lo um pouco</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">jokes</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>DatasetDict(&#x7B;
&#x20;&#x20;&#x20;&#x20;train: Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;ID&#x27;, &#x27;Joke&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 231657
&#x20;&#x20;&#x20;&#x20;&#x7D;)
&#x7D;)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vemos que é um conjunto de treinamento único com mais de 200 mil piadas. Então, mais tarde teremos que dividi-lo em treinamento e avaliação.</p>
</section>
<section class="section-block-markdown-cell">
<p>Vamos a ver um exemplo</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">random</span><span class="w"> </span><span class="kn">import</span> <span class="n">randint</span>
<span class="w"> </span>
<span class="n">idx</span> <span class="o">=</span> <span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">jokes</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">jokes</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&#x7B;&#x27;ID&#x27;: 198387,
 &#x27;Joke&#x27;: &#x27;My hot dislexic co-worker said she had an important massage to give me in her office... When I got there, she told me it can wait until I put on some clothes.&#x27;&#x7D;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vemos que tem um ID de piada que não nos interessa em absoluto e a própria piada</p>
</section>
<section class="section-block-markdown-cell">
<p>Caso você tenha pouca memória na GPU, vou fazer um subconjunto do conjunto de dados, escolha o percentual de piadas que deseja usar</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">percent_of_train_dataset</span> <span class="o">=</span> <span class="mi">1</span>    <span class="c1"># If you want 50% of the dataset, set this to 0.5</span>
<span class="w"> </span>
<span class="n">subset_dataset</span> <span class="o">=</span> <span class="n">jokes</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">jokes</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">])</span> <span class="o">*</span> <span class="n">percent_of_train_dataset</span><span class="p">)))</span>
<span class="n">subset_dataset</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;features: [&#x27;ID&#x27;, &#x27;Joke&#x27;],
&#x20;&#x20;&#x20;&#x20;num_rows: 231657
&#x7D;)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Agora dividimos o subconjunto em um conjunto de treinamento e outro de validação.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">percent_of_train_dataset</span> <span class="o">=</span> <span class="mf">0.90</span>
<span class="w"> </span>
<span class="n">split_dataset</span> <span class="o">=</span> <span class="n">subset_dataset</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">train_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">subset_dataset</span><span class="o">.</span><span class="n">num_rows</span> <span class="o">*</span> <span class="n">percent_of_train_dataset</span><span class="p">),</span> <span class="n">seed</span><span class="o">=</span><span class="mi">19</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span>
<span class="n">validation_test_dataset</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span>
<span class="w"> </span>
<span class="n">split_dataset</span> <span class="o">=</span> <span class="n">validation_test_dataset</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">train_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">validation_test_dataset</span><span class="o">.</span><span class="n">num_rows</span> <span class="o">*</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">seed</span><span class="o">=</span><span class="mi">19</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">validation_dataset</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span>
<span class="w"> </span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Size of the train set: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">. Size of the validation set: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">validation_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">. Size of the test set: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Size of the train set: 208491. Size of the validation set: 11583. Size of the test set: 11583
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Tokenizador">Tokenizador<a class="anchor-link" href="#Tokenizador">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Instanciamos o tokenizador. Instanciamos o token de padding do tokenizador para que não nos dê erro como antes.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;openai-community/gpt2&quot;</span>
<span class="w"> </span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>
<span class="n">tokenizer</span><span class="o">.</span><span class="n">padding_side</span> <span class="o">=</span> <span class="s2">&quot;right&quot;</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vamos adicionar dois novos tokens de início de piada e fim de piada para ter mais controle</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">new_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;&amp;lt;SJ&amp;gt;&#39;</span><span class="p">,</span> <span class="s1">&#39;&amp;lt;EJ&amp;gt;&#39;</span><span class="p">]</span>   <span class="c1"># Start and end of joke tokens</span>
<span class="w"> </span>
<span class="n">num_added_tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">add_tokens</span><span class="p">(</span><span class="n">new_tokens</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Added </span><span class="si">{</span><span class="n">num_added_tokens</span><span class="si">}</span><span class="s2"> tokens&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Added 2 tokens
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Criamos uma função para adicionar os novos tokens às frases.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">joke_column</span> <span class="o">=</span> <span class="s2">&quot;Joke&quot;</span>
<span class="w"> </span>
<span class="k">def</span><span class="w"> </span><span class="nf">format_joke</span><span class="p">(</span><span class="n">example</span><span class="p">):</span>
<span class="w">    </span><span class="n">example</span><span class="p">[</span><span class="n">joke_column</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;&amp;lt;SJ&amp;gt; &#39;</span> <span class="o">+</span> <span class="n">example</span><span class="p">[</span><span class="s1">&#39;Joke&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39; &amp;lt;EJ&amp;gt;&#39;</span>
<span class="w">    </span><span class="k">return</span> <span class="n">example</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Selecionamos as colunas que não precisamos</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">remove_columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">column</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">column_names</span> <span class="k">if</span> <span class="n">column</span> <span class="o">!=</span> <span class="n">joke_column</span><span class="p">]</span>
<span class="n">remove_columns</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>[&#x27;ID&#x27;]
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Formatamos o conjunto de dados e eliminamos as colunas que não precisamos</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">format_joke</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="n">remove_columns</span><span class="p">)</span>
<span class="n">validation_dataset</span> <span class="o">=</span> <span class="n">validation_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">format_joke</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="n">remove_columns</span><span class="p">)</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">format_joke</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="n">remove_columns</span><span class="p">)</span>
<span class="n">train_dataset</span><span class="p">,</span> <span class="n">validation_dataset</span><span class="p">,</span> <span class="n">test_dataset</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>(Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;Joke&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 208491
 &#x7D;),
 Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;Joke&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 11583
 &#x7D;),
 Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;Joke&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 11583
 &#x7D;))
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Agora criamos uma função para tokenizar os piadas</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="n">joke_column</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Tokenizamos o conjunto de dados e removemos a coluna com o texto</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="n">joke_column</span><span class="p">])</span>
<span class="n">validation_dataset</span> <span class="o">=</span> <span class="n">validation_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="n">joke_column</span><span class="p">])</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="n">joke_column</span><span class="p">])</span>
<span class="n">train_dataset</span><span class="p">,</span> <span class="n">validation_dataset</span><span class="p">,</span> <span class="n">test_dataset</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>(Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;input_ids&#x27;, &#x27;attention_mask&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 208491
 &#x7D;),
 Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;input_ids&#x27;, &#x27;attention_mask&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 11583
 &#x7D;),
 Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;input_ids&#x27;, &#x27;attention_mask&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 11583
 &#x7D;))
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Modelo">Modelo<a class="anchor-link" href="#Modelo">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Agora instanciamos o modelo para geração de texto e atribuímos ao token de padding o token de end of string</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vemos o tamanho do vocabulário do modelo</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span>
<span class="n">vocab_size</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>50257
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Tem 50257 tokens, que é o tamanho do vocabulário do GPT2. Mas como dissemos que iríamos criar dois novos tokens com o início da piada e o fim da piada, os adicionamos ao modelo.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">resize_token_embeddings</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">))</span>
<span class="w"> </span>
<span class="n">new_vocab_size</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Old vocab size: </span><span class="si">{</span><span class="n">vocab_size</span><span class="si">}</span><span class="s2">. New vocab size: </span><span class="si">{</span><span class="n">new_vocab_size</span><span class="si">}</span><span class="s2">. Added </span><span class="si">{</span><span class="n">new_vocab_size</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">vocab_size</span><span class="si">}</span><span class="s2"> tokens&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Old vocab size: 50257. New vocab size: 50259. Added 2 tokens
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Foram adicionados os dois novos tokens</p>
</section>
<section class="section-block-markdown-cell">
<h3 id="Treinamento">Treinamento<a class="anchor-link" href="#Treinamento">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Configuramos os parâmetros de treinamento</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">TrainingArguments</span>
<span class="w"> </span>
<span class="n">metric_name</span> <span class="o">=</span> <span class="s2">&quot;accuracy&quot;</span>
<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;GPT2-small-finetuned-Maximofn-short-jokes-dataset-casualLM&quot;</span>
<span class="n">output_dir</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;./training_results&quot;</span>
<span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>
<span class="n">BS_TRAIN</span> <span class="o">=</span> <span class="mi">28</span>
<span class="n">BS_EVAL</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">WEIGHT_DECAY</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">WARMUP_STEPS</span> <span class="o">=</span> <span class="mi">100</span>
<span class="w"> </span>
<span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
<span class="w">    </span><span class="n">model_name</span><span class="p">,</span>
<span class="w">    </span><span class="n">eval_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="n">save_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>
<span class="w">    </span><span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>
<span class="w">    </span><span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>
<span class="w">    </span><span class="n">warmup_steps</span><span class="o">=</span><span class="n">WARMUP_STEPS</span><span class="p">,</span>
<span class="w">    </span><span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>
<span class="w">    </span><span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>
<span class="w">    </span><span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">&quot;cosine&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
<span class="w">    </span><span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="w">    </span><span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="w">    </span><span class="c1"># metric_for_best_model=metric_name,</span>
<span class="w">    </span><span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Agora não usamos <code>metric_for_best_model</code>, depois de definir o treinador explicamos por que</p>
</section>
<section class="section-block-markdown-cell">
<p>Definimos o treinador</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Trainer</span>
<span class="w"> </span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
<span class="w">    </span><span class="n">model</span><span class="p">,</span>
<span class="w">    </span><span class="n">training_args</span><span class="p">,</span>
<span class="w">    </span><span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>
<span class="w">    </span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">validation_dataset</span><span class="p">,</span>
<span class="w">    </span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
<span class="w">    </span><span class="c1"># compute_metrics=compute_metrics,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Neste caso, não passamos uma função <code>compute_metrics</code>, mas sim, durante a avaliação, será usada a <code>loss</code> para avaliar o modelo. Por isso, ao definir os argumentos, não definimos <code>metric_for_best_model</code>, pois não vamos usar uma métrica para avaliar o modelo, mas sim a <code>loss</code>.</p>
</section>
<section class="section-block-markdown-cell">
<p>Treinamos</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&#x20;&#x20;0%|          | 0/625473 [00:00&amp;lt;?, ?it/s]
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>---------------------------------------------------------------------------ValueError                                Traceback (most recent call last)Cell In[19], line 1
----&amp;gt; 1 trainer.train()
File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/trainer.py:1885, in Trainer.train(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)
&#x20;&#x20;&#x20;1883         hf_hub_utils.enable_progress_bars()
&#x20;&#x20;&#x20;1884 else:
-&amp;gt; 1885     return inner_training_loop(
&#x20;&#x20;&#x20;1886         args=args,
&#x20;&#x20;&#x20;1887         resume_from_checkpoint=resume_from_checkpoint,
&#x20;&#x20;&#x20;1888         trial=trial,
&#x20;&#x20;&#x20;1889         ignore_keys_for_eval=ignore_keys_for_eval,
&#x20;&#x20;&#x20;1890     )
File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/trainer.py:2216, in Trainer._inner_training_loop(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)
&#x20;&#x20;&#x20;2213     self.control = self.callback_handler.on_step_begin(args, self.state, self.control)
&#x20;&#x20;&#x20;2215 with self.accelerator.accumulate(model):
-&amp;gt; 2216     tr_loss_step = self.training_step(model, inputs)
&#x20;&#x20;&#x20;2218 if (
&#x20;&#x20;&#x20;2219     args.logging_nan_inf_filter
&#x20;&#x20;&#x20;2220     and not is_torch_xla_available()
&#x20;&#x20;&#x20;2221     and (torch.isnan(tr_loss_step) or torch.isinf(tr_loss_step))
&#x20;&#x20;&#x20;2222 ):
&#x20;&#x20;&#x20;2223     # if loss is nan or inf simply add the average of previous logged losses
&#x20;&#x20;&#x20;2224     tr_loss += tr_loss / (1 + self.state.global_step - self._globalstep_last_logged)
File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/trainer.py:3238, in Trainer.training_step(self, model, inputs)
&#x20;&#x20;&#x20;3235     return loss_mb.reduce_mean().detach().to(self.args.device)
&#x20;&#x20;&#x20;3237 with self.compute_loss_context_manager():
-&amp;gt; 3238     loss = self.compute_loss(model, inputs)
&#x20;&#x20;&#x20;3240 del inputs
&#x20;&#x20;&#x20;3241 torch.cuda.empty_cache()
File ~/miniconda3/envs/nlp_/lib/python3.11/site-packages/transformers/trainer.py:3282, in Trainer.compute_loss(self, model, inputs, return_outputs)
&#x20;&#x20;&#x20;3280 else:
&#x20;&#x20;&#x20;3281     if isinstance(outputs, dict) and &quot;loss&quot; not in outputs:
-&amp;gt; 3282         raise ValueError(
&#x20;&#x20;&#x20;3283             &quot;The model did not return a loss from the inputs, only the following keys: &quot;
&#x20;&#x20;&#x20;3284             f&quot;&#x7B;&#x27;,&#x27;.join(outputs.keys())&#x7D;. For reference, the inputs it received are &#x7B;&#x27;,&#x27;.join(inputs.keys())&#x7D;.&quot;
&#x20;&#x20;&#x20;3285         )
&#x20;&#x20;&#x20;3286     # We don&#x27;t use .loss here since the model may return tuples instead of ModelOutput.
&#x20;&#x20;&#x20;3287     loss = outputs[&quot;loss&quot;] if isinstance(outputs, dict) else outputs[0]
ValueError: The model did not return a loss from the inputs, only the following keys: logits,past_key_values. For reference, the inputs it received are input_ids,attention_mask.
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Como vemos, nos dá um erro, dizendo que o modelo não retorna o valor do loss, que é fundamental para poder treinar, vamos ver por quê.</p>
</section>
<section class="section-block-markdown-cell">
<p>Vamos ver como é um exemplo do dataset</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">idx</span> <span class="o">=</span> <span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">sample</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
<span class="n">sample</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&#x7B;&#x27;input_ids&#x27;: [50257,
&#x20;&#x20;4162,
&#x20;&#x20;750,
&#x20;&#x20;262,
&#x20;&#x20;18757,
&#x20;&#x20;6451,
&#x20;&#x20;2245,
&#x20;&#x20;2491,
&#x20;&#x20;30,
&#x20;&#x20;4362,
&#x20;&#x20;340,
&#x20;&#x20;373,
&#x20;&#x20;734,
&#x20;&#x20;10032,
&#x20;&#x20;13,
&#x20;&#x20;220,
&#x20;&#x20;50258,
&#x20;&#x20;50256,
&#x20;&#x20;50256,
&#x20;&#x20;...,
&#x20;&#x20;50256,
&#x20;&#x20;50256,
&#x20;&#x20;50256],
 &#x27;attention_mask&#x27;: [1,
&#x20;&#x20;1,
&#x20;&#x20;1,
&#x20;&#x20;1,
&#x20;&#x20;1,
&#x20;&#x20;1,
&#x20;&#x20;1,
&#x20;&#x20;1,
&#x20;&#x20;1,
&#x20;&#x20;1,
&#x20;&#x20;1,
&#x20;&#x20;1,
&#x20;&#x20;1,
&#x20;&#x20;1,
&#x20;&#x20;1,
&#x20;&#x20;1,
&#x20;&#x20;1,
&#x20;&#x20;0,
&#x20;&#x20;0,
&#x20;&#x20;0,
&#x20;&#x20;...,
&#x20;&#x20;0,
&#x20;&#x20;0,
&#x20;&#x20;0]&#x7D;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Como podemos ver, temos um dicionário com os <code>input_ids</code> e as <code>attention_mask</code>. Se o passarmos para o modelo, obtemos isso</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="w"> </span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span>
<span class="w">    </span><span class="n">input_ids</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>
<span class="w">    </span><span class="n">attention_mask</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">loss</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>None
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Como vemos, não retorna o valor da loss porque está esperando um valor para <code>labels</code>, que não foi fornecido. No exemplo anterior, em que fazíamos fine tuning para classificação de texto, dissemos que as etiquetas devem ser passadas para um campo do dataset chamado <code>labels</code>, mas neste caso não temos esse campo no dataset.</p>
<p>Se agora atribuirmos as <code>labels</code> aos <code>input_ids</code> e voltarmos a ver a loss</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="w"> </span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span>
<span class="w">    </span><span class="n">input_ids</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>
<span class="w">    </span><span class="n">attention_mask</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>
<span class="w">    </span><span class="n">labels</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">loss</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>tensor(102.1873, device=&#x27;cuda:0&#x27;, grad_fn=&amp;lt;NllLossBackward0&amp;gt;)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Agora sim obtemos uma <code>loss</code></p>
<p>Portanto, temos duas opções: adicionar um campo <code>labels</code> ao dataset, com os valores de <code>input_ids</code>, ou utilizar uma função da biblioteca <code>transformers</code> chamada <code>data_collator</code>. Neste caso, usaremos <code>DataCollatorForLanguageModeling</code>. Vamos ver isso.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataCollatorForLanguageModeling</span>
<span class="w"> </span>
<span class="n">my_data_collator</span><span class="o">=</span><span class="n">DataCollatorForLanguageModeling</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">mlm</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Passamos a amostra <code>sample</code> por este <code>data_collator</code></p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">collated_sample</span> <span class="o">=</span> <span class="n">my_data_collator</span><span class="p">([</span><span class="n">sample</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vemos como é a saída</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">collated_sample</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">): </span><span class="si">{</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>input_ids (torch.Size([1, 768])): tensor([[50257,  4162,   750,   262, 18757,  6451,  2245,  2491,    30,  4362,
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;340,   373,   734, 10032,    13,   220, 50258, 50256, ..., 50256, 50256]],
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;device=&#x27;cuda:0&#x27;)
attention_mask (torch.Size([1, 768])): tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, ..., 0, 0]],
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;device=&#x27;cuda:0&#x27;)
labels (torch.Size([1, 768])): tensor([[50257,  4162,   750,   262, 18757,  6451,  2245,  2491,    30,  4362,
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;340,   373,   734, 10032,    13,   220, 50258,  -100,  ...,  -100,  -100]],
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;device=&#x27;cuda:0&#x27;)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Como se pode ver, o <code>data_collator</code> criou um campo <code>labels</code> e lhe atribuiu os valores de <code>input_ids</code>. Os tokens que estão mascarados receberam o valor -100. Isso ocorre porque quando definimos o <code>data_collator</code>, passamos o parâmetro <code>mlm=False</code>, o que significa que não estamos fazendo <code>Masked Language Modeling</code>, mas sim <code>Language Modeling</code>, por isso nenhum token original é mascarado.</p>
</section>
<section class="section-block-markdown-cell">
<p>Vamos ver se agora obtemos uma <code>loss</code> com esse <code>data_collator</code></p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">collated_sample</span><span class="p">)</span>
<span class="n">output</span><span class="o">.</span><span class="n">loss</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>tensor(102.7181, device=&#x27;cuda:0&#x27;, grad_fn=&amp;lt;NllLossBackward0&amp;gt;)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Então, redefinimos o <code>trainer</code> com o <code>data_collator</code> e treinamos novamente.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataCollatorForLanguageModeling</span>
<span class="w"> </span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
<span class="w">    </span><span class="n">model</span><span class="p">,</span>
<span class="w">    </span><span class="n">training_args</span><span class="p">,</span>
<span class="w">    </span><span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>
<span class="w">    </span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">validation_dataset</span><span class="p">,</span>
<span class="w">    </span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
<span class="w">    </span><span class="n">data_collator</span><span class="o">=</span><span class="n">DataCollatorForLanguageModeling</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">mlm</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&amp;lt;IPython.core.display.HTML object&amp;gt;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>There were missing keys in the checkpoint model loaded: [&#x27;lm_head.weight&#x27;].
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>TrainOutput(global_step=22341, training_loss=3.505178199598342, metrics=&#x7B;&#x27;train_runtime&#x27;: 9209.5353, &#x27;train_samples_per_second&#x27;: 67.916, &#x27;train_steps_per_second&#x27;: 2.426, &#x27;total_flos&#x27;: 2.45146666696704e+17, &#x27;train_loss&#x27;: 3.505178199598342, &#x27;epoch&#x27;: 3.0&#x7D;)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Avaliacao">Avaliação<a class="anchor-link" href="#Avaliacao">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Uma vez treinado, avaliamos o modelo sobre o dataset de teste.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&amp;lt;IPython.core.display.HTML object&amp;gt;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&#x7B;&#x27;eval_loss&#x27;: 3.201305866241455,
 &#x27;eval_runtime&#x27;: 65.0033,
 &#x27;eval_samples_per_second&#x27;: 178.191,
 &#x27;eval_steps_per_second&#x27;: 5.569,
 &#x27;epoch&#x27;: 3.0&#x7D;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Publicar o modelo">Publicar o modelo<a class="anchor-link" href="#Publicar o modelo">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Criamos o cartão do modelo</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">create_model_card</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Publicamos</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">push_to_hub</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>events.out.tfevents.1720875425.8de3af1b431d.6946.1:   0%|          | 0.00/364 [00:00&amp;lt;?, ?B/s]
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>CommitInfo(commit_url=&#x27;https://huggingface.co/Maximofn/GPT2-small-finetuned-Maximofn-short-jokes-dataset-casualLM/commit/d107b3bb0e02076483238f9975697761015ec390&#x27;, commit_message=&#x27;End of training&#x27;, commit_description=&#x27;&#x27;, oid=&#x27;d107b3bb0e02076483238f9975697761015ec390&#x27;, pr_url=None, pr_revision=None, pr_num=None)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Uso do modelo">Uso do modelo<a class="anchor-link" href="#Uso do modelo">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Limpez tudo o possível</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">gc</span>
<span class="w"> </span>

<span class="k">def</span><span class="w"> </span><span class="nf">clear_hardwares</span><span class="p">():</span>
<span class="w">    </span><span class="n">torch</span><span class="o">.</span><span class="n">clear_autocast_cache</span><span class="p">()</span>
<span class="w">    </span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">ipc_collect</span><span class="p">()</span>
<span class="w">    </span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
<span class="w">    </span><span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
<span class="w"> </span>

<span class="n">clear_hardwares</span><span class="p">()</span>
<span class="n">clear_hardwares</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Baixamos o modelo e o tokenizador</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForCausalLM</span>
<span class="w"> </span>
<span class="n">user</span> <span class="o">=</span> <span class="s2">&quot;maximofn&quot;</span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">user</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="w"> </span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>
<span class="n">tokenizer</span><span class="o">.</span><span class="n">padding_side</span> <span class="o">=</span> <span class="s2">&quot;right&quot;</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Verificamos que o tokenizador e o modelo tenham os 2 tokens extras que adicionamos.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">tokenizer_vocab</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">get_vocab</span><span class="p">()</span>
<span class="n">model_vocab</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;tokenizer_vocab: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">tokenizer_vocab</span><span class="p">)</span><span class="si">}</span><span class="s2">. model_vocab: </span><span class="si">{</span><span class="n">model_vocab</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>tokenizer_vocab: 50259. model_vocab: 50259
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vemos que têm 50259 tokens, ou seja, os 50257 tokens do GPT2 mais os 2 que adicionamos.</p>
</section>
<section class="section-block-markdown-cell">
<p>Criamos uma função para gerar piadas</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">generate_joke</span><span class="p">(</span><span class="n">prompt_text</span><span class="p">):</span>
<span class="w">    </span><span class="n">text</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&amp;lt;SJ&amp;gt; </span><span class="si">{</span><span class="n">prompt_text</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="w">    </span><span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span class="w">    </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="w">        </span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="o">**</span><span class="n">tokens</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">eos_token_id</span><span class="o">=</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">&quot;&amp;lt;EJ&amp;gt;&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Geramos uma piada</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">generate_joke</span><span class="p">(</span><span class="s2">&quot;Why didn&#39;t the frog cross the road?&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Setting `pad_token_id` to `eos_token_id`:50258 for open-end generation.
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt-output-prompt">Out[]:</div>
<div class="output-text-output-subareaoutput_execute_result">
<pre>&quot;&amp;lt;SJ&amp;gt; Why didn&#x27;t the frog cross the road? Because he was frog-in-the-face. &amp;lt;EJ&amp;gt;&quot;</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Se quiser testar mais o modelo, você pode vê-lo em <a href="https://huggingface.co/Maximofn/GPT2-small-finetuned-Maximofn-short-jokes-dataset-casualLM">Maximofn/GPT2-small-finetuned-Maximofn-short-jokes-dataset-casualLM</a></p>
</section>
<section class="section-block-markdown-cell">
<h2 id="Ajuste fino para classificacao de texto com Pytorch">Ajuste fino para classificação de texto com Pytorch<a class="anchor-link" href="#Ajuste fino para classificacao de texto com Pytorch">¶</a></h2>
</section>
<section class="section-block-markdown-cell">
<p>Repetimos o treinamento com Pytorch</p>
</section>
<section class="section-block-markdown-cell">
<p>Reiniciamos o notebook para nos assegurar</p>
</section>
<section class="section-block-markdown-cell">
<h3 id="Conjunto de Dados">Conjunto de Dados<a class="anchor-link" href="#Conjunto de Dados">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Baixamos o mesmo conjunto de dados que quando fizemos o treinamento com as bibliotecas do Hugging Face</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="w"> </span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;mteb/amazon_reviews_multi&quot;</span><span class="p">,</span> <span class="s2">&quot;en&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Criamos uma variável com o número de classes</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="s1">&#39;label&#39;</span><span class="p">))</span>
<span class="n">num_classes</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>5
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Antes processávamos todo o conjunto de dados para criar um campo chamado <code>labels</code>, mas agora não é necessário porque, como vamos programar tudo nós mesmos, nos adaptamos a como é o conjunto de dados.</p>
</section>
<section class="section-block-markdown-cell">
<h3 id="Tokenizador">Tokenizador<a class="anchor-link" href="#Tokenizador">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Criamos o tokenizador. Atribuímos o token de padding para que não nos dê erro como antes.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>
<span class="w"> </span>
<span class="n">checkpoint</span> <span class="o">=</span> <span class="s2">&quot;openai-community/gpt2&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>
<span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Criamos uma função para tokenizar o dataset</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Tokenizamos. Removemos colunas que não sejam necessárias, mas agora mantemos a de texto.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="s1">&#39;label_text&#39;</span><span class="p">])</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">dataset</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>DatasetDict(&#x7B;
&#x20;&#x20;&#x20;&#x20;train: Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;text&#x27;, &#x27;label&#x27;, &#x27;input_ids&#x27;, &#x27;attention_mask&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 200000
&#x20;&#x20;&#x20;&#x20;&#x7D;)
&#x20;&#x20;&#x20;&#x20;validation: Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;text&#x27;, &#x27;label&#x27;, &#x27;input_ids&#x27;, &#x27;attention_mask&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 5000
&#x20;&#x20;&#x20;&#x20;&#x7D;)
&#x20;&#x20;&#x20;&#x20;test: Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;text&#x27;, &#x27;label&#x27;, &#x27;input_ids&#x27;, &#x27;attention_mask&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 5000
&#x20;&#x20;&#x20;&#x20;&#x7D;)
&#x7D;)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">percentage</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">subset_train</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">])</span> <span class="o">*</span> <span class="n">percentage</span><span class="p">)))</span>
<span class="n">percentage</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">subset_validation</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;validation&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;validation&#39;</span><span class="p">])</span> <span class="o">*</span> <span class="n">percentage</span><span class="p">)))</span>
<span class="n">subset_test</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">])</span> <span class="o">*</span> <span class="n">percentage</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;len subset_train: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">subset_train</span><span class="p">)</span><span class="si">}</span><span class="s2">, len subset_validation: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">subset_validation</span><span class="p">)</span><span class="si">}</span><span class="s2">, len subset_test: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">subset_test</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>len subset_train: 200000, len subset_validation: 5000, len subset_test: 5000
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Modelo">Modelo<a class="anchor-link" href="#Modelo">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Importamos os pesos e atribuímos o token de padding</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="n">num_classes</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: [&#x27;score.weight&#x27;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Dispositivo">Dispositivo<a class="anchor-link" href="#Dispositivo">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Criamos o dispositivo onde tudo será executado</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="w"> </span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>De passagem, transferimos o modelo para o dispositivo e, de passagem, o convertemos para FP16 para ocupar menos memória</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">half</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Conjunto de Dados do Pytorch">Conjunto de Dados do Pytorch<a class="anchor-link" href="#Conjunto de Dados do Pytorch">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Criamos um dataset de pytorch</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dataset</span>
<span class="w"> </span>
<span class="k">class</span><span class="w"> </span><span class="nc">ReviewsDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
<span class="w">    </span><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">huggingface_dataset</span><span class="p">):</span>
<span class="w">        </span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">huggingface_dataset</span>
<span class="w"> </span>
<span class="w">    </span><span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
<span class="w">        </span><span class="n">label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">&#39;label&#39;</span><span class="p">]</span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">&#39;input_ids&#39;</span><span class="p">])</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="w">        </span><span class="k">return</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">label</span>
<span class="w"> </span>
<span class="w">    </span><span class="k">def</span><span class="w"> </span><span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Instanciamos os datasets</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">ReviewsDataset</span><span class="p">(</span><span class="n">subset_train</span><span class="p">)</span>
<span class="n">validatation_dataset</span> <span class="o">=</span> <span class="n">ReviewsDataset</span><span class="p">(</span><span class="n">subset_validation</span><span class="p">)</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">ReviewsDataset</span><span class="p">(</span><span class="n">subset_test</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vamos dar uma olhada em um exemplo</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">input_ids</span><span class="p">,</span> <span class="n">at_mask</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">at_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">label</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>(torch.Size([768]), torch.Size([768]), 0)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Pytorch Dataloader">Pytorch Dataloader<a class="anchor-link" href="#Pytorch Dataloader">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Criamos agora um DataLoader do PyTorch</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="w"> </span>
<span class="n">BS</span> <span class="o">=</span> <span class="mi">12</span>
<span class="w"> </span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">validation_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">validatation_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vamos dar uma olhada em um exemplo</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">input_ids</span><span class="p">,</span> <span class="n">at_mask</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_loader</span><span class="p">))</span>
<span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">at_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">labels</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>(torch.Size([12, 768]),
 torch.Size([12, 768]),
 tensor([2, 1, 2, 0, 3, 3, 0, 4, 3, 3, 4, 2]))
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Para verificar se tudo está bem, passamos a amostra ao modelo para ver se tudo sai bem. Primeiro passamos os tokens para o dispositivo.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">at_mask</span> <span class="o">=</span> <span class="n">at_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Agora passamos isso para o modelo</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">at_mask</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="n">output</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>odict_keys([&#x27;loss&#x27;, &#x27;logits&#x27;, &#x27;past_key_values&#x27;])
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Como vemos, nos dá a loss e os logits</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>tensor(5.9414, device=&#x27;cuda:0&#x27;, dtype=torch.float16,
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;grad_fn=&amp;lt;NllLossBackward0&amp;gt;)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">]</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>tensor([[ 6.1953e+00, -1.2275e+00, -2.4824e+00,  5.8867e+00, -1.4734e+01],
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;[ 5.4062e+00, -8.4570e-01, -2.3203e+00,  5.1055e+00, -1.1555e+01],
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;[ 6.1641e+00, -9.3066e-01, -2.5664e+00,  6.0039e+00, -1.4570e+01],
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;[ 5.2266e+00, -4.2358e-01, -2.0801e+00,  4.7461e+00, -1.1570e+01],
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;[ 3.8184e+00, -2.3460e-03, -1.7666e+00,  3.4160e+00, -7.7969e+00],
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;[ 4.1641e+00, -4.8169e-01, -1.6914e+00,  3.9941e+00, -8.7734e+00],
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;[ 4.6758e+00, -3.0298e-01, -2.1641e+00,  4.1055e+00, -9.3359e+00],
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;[ 4.1953e+00, -3.2471e-01, -2.1875e+00,  3.9375e+00, -8.3438e+00],
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;[-1.1650e+00,  1.3564e+00, -6.2158e-01, -6.8115e-01,  4.8672e+00],
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;[ 4.4961e+00, -8.7891e-02, -2.2793e+00,  4.2812e+00, -9.3359e+00],
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;[ 4.9336e+00, -2.6627e-03, -2.1543e+00,  4.3711e+00, -1.0742e+01],
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;[ 5.9727e+00, -4.3152e-02, -1.4551e+00,  4.3438e+00, -1.2117e+01]],
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;device=&#x27;cuda:0&#x27;, dtype=torch.float16, grad_fn=&amp;lt;IndexBackward0&amp;gt;)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Metrica">Métrica<a class="anchor-link" href="#Metrica">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Vamos a criar uma função para obter a métrica, que neste caso vai ser a acurácia.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">predicted_labels</span><span class="p">(</span><span class="n">logits</span><span class="p">):</span>
<span class="w">    </span><span class="n">percent</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="w">    </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">percent</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="w">    </span><span class="k">return</span> <span class="n">predictions</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">compute_accuracy</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
<span class="w">    </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">predicted_labels</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
<span class="w">    </span><span class="n">correct</span> <span class="o">=</span> <span class="p">(</span><span class="n">predictions</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="w">    </span><span class="k">return</span> <span class="n">correct</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vamos a ver se ele calcula bem.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">compute_accuracy</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>0.1666666716337204
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Otimizador">Otimizador<a class="anchor-link" href="#Otimizador">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Como vamos a precisar um otimizador, criamos um</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AdamW</span>
<span class="w"> </span>
<span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">LR</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
&#x20;&#x20;warnings.warn(
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Treinamento">Treinamento<a class="anchor-link" href="#Treinamento">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Criamos o loop de treinamento</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>
<span class="w"> </span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>
<span class="w"> </span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="mi">0</span>
<span class="w"> </span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="w">    </span><span class="n">train_loss</span> <span class="o">=</span> <span class="mi">0</span>
<span class="w">    </span><span class="n">progresbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">at_mask</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">progresbar</span><span class="p">:</span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="w">        </span><span class="n">at_mask</span> <span class="o">=</span> <span class="n">at_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="w">        </span><span class="n">label</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">at_mask</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
<span class="w">        </span><span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="w">        </span><span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="w">        </span><span class="n">progresbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">({</span><span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()})</span>
<span class="w">    </span><span class="n">train_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
<span class="w">    </span><span class="n">progresbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">({</span><span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="n">train_loss</span><span class="p">})</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="w">    </span><span class="n">valid_loss</span> <span class="o">=</span> <span class="mi">0</span>
<span class="w">    </span><span class="n">progresbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">validation_loader</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">validation_loader</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">at_mask</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">progresbar</span><span class="p">:</span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="w">        </span><span class="n">at_mask</span> <span class="o">=</span> <span class="n">at_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="w">        </span><span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">at_mask</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
<span class="w">        </span><span class="n">valid_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">step_accuracy</span> <span class="o">=</span> <span class="n">compute_accuracy</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
<span class="w">        </span><span class="n">accuracy</span> <span class="o">+=</span> <span class="n">step_accuracy</span>
<span class="w">        </span><span class="n">progresbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">({</span><span class="s1">&#39;valid_loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="s1">&#39;accuracy&#39;</span><span class="p">:</span> <span class="n">step_accuracy</span><span class="o">.</span><span class="n">item</span><span class="p">()})</span>
<span class="w"> </span>
<span class="w">    </span><span class="n">valid_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">validation_loader</span><span class="p">)</span>
<span class="w">    </span><span class="n">accuracy</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">validation_loader</span><span class="p">)</span>
<span class="w">    </span><span class="n">progresbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">({</span><span class="s1">&#39;valid_loss&#39;</span><span class="p">:</span> <span class="n">valid_loss</span><span class="p">,</span> <span class="s1">&#39;accuracy&#39;</span><span class="p">:</span> <span class="n">accuracy</span><span class="p">})</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Epoch 1: 100%|██████████| 16667/16667 [44:13&amp;lt;00:00,  6.28it/s, train_loss=nan]
Epoch 1: 100%|██████████| 417/417 [00:32&amp;lt;00:00, 12.72it/s, valid_loss=nan, accuracy=0]
Epoch 2: 100%|██████████| 16667/16667 [44:06&amp;lt;00:00,  6.30it/s, train_loss=nan]
Epoch 2: 100%|██████████| 417/417 [00:32&amp;lt;00:00, 12.77it/s, valid_loss=nan, accuracy=0]
Epoch 3: 100%|██████████| 16667/16667 [44:03&amp;lt;00:00,  6.30it/s, train_loss=nan]
Epoch 3: 100%|██████████| 417/417 [00:32&amp;lt;00:00, 12.86it/s, valid_loss=nan, accuracy=0]
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Uso do modelo">Uso do modelo<a class="anchor-link" href="#Uso do modelo">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Vamos a testar o modelo que treinamos</p>
</section>
<section class="section-block-markdown-cell">
<p>Primeiro tokenizamos um texto</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">input_tokens</span> <span class="o">=</span> <span class="n">tokenize_function</span><span class="p">({</span><span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="s2">&quot;I love this product. It is amazing.&quot;</span><span class="p">})</span>
<span class="n">input_tokens</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">input_tokens</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>(torch.Size([1, 768]), torch.Size([1, 768]))
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Agora passamos isso para o modelo.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_tokens</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">input_tokens</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
<span class="n">output</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">]</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>tensor([[nan, nan, nan, nan, nan]], device=&#x27;cuda:0&#x27;, dtype=torch.float16,
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;grad_fn=&amp;lt;IndexBackward0&amp;gt;)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vemos as previsões desses logits</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">predicted</span> <span class="o">=</span> <span class="n">predicted_labels</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">])</span>
<span class="n">predicted</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>tensor([0], device=&#x27;cuda:0&#x27;)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h2 id="Ajuste fino para geracao de texto com Pytorch">Ajuste fino para geração de texto com Pytorch<a class="anchor-link" href="#Ajuste fino para geracao de texto com Pytorch">¶</a></h2>
</section>
<section class="section-block-markdown-cell">
<p>Repetimos o treinamento com Pytorch</p>
</section>
<section class="section-block-markdown-cell">
<p>Reiniciamos o notebook para nos assegurar</p>
</section>
<section class="section-block-markdown-cell">
<h3 id="Conjunto de Dados">Conjunto de Dados<a class="anchor-link" href="#Conjunto de Dados">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Voltamos a baixar o conjunto de dados de piadas</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="w"> </span>
<span class="n">jokes</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;Maximofn/short-jokes-dataset&quot;</span><span class="p">)</span>
<span class="n">jokes</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>DatasetDict(&#x7B;
&#x20;&#x20;&#x20;&#x20;train: Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;ID&#x27;, &#x27;Joke&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 231657
&#x20;&#x20;&#x20;&#x20;&#x7D;)
&#x7D;)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Criamos um subconjunto caso haja pouca memória</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">percent_of_train_dataset</span> <span class="o">=</span> <span class="mi">1</span>    <span class="c1"># If you want 50% of the dataset, set this to 0.5</span>
<span class="w"> </span>
<span class="n">subset_dataset</span> <span class="o">=</span> <span class="n">jokes</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">jokes</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">])</span> <span class="o">*</span> <span class="n">percent_of_train_dataset</span><span class="p">)))</span>
<span class="n">subset_dataset</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;features: [&#x27;ID&#x27;, &#x27;Joke&#x27;],
&#x20;&#x20;&#x20;&#x20;num_rows: 231657
&#x7D;)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Dividimos o conjunto de dados em subconjuntos de treinamento, validação e teste.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">percent_of_train_dataset</span> <span class="o">=</span> <span class="mf">0.90</span>
<span class="w"> </span>
<span class="n">split_dataset</span> <span class="o">=</span> <span class="n">subset_dataset</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">train_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">subset_dataset</span><span class="o">.</span><span class="n">num_rows</span> <span class="o">*</span> <span class="n">percent_of_train_dataset</span><span class="p">),</span> <span class="n">seed</span><span class="o">=</span><span class="mi">19</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span>
<span class="n">validation_test_dataset</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span>
<span class="w"> </span>
<span class="n">split_dataset</span> <span class="o">=</span> <span class="n">validation_test_dataset</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">train_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">validation_test_dataset</span><span class="o">.</span><span class="n">num_rows</span> <span class="o">*</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">seed</span><span class="o">=</span><span class="mi">19</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">validation_dataset</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span>
<span class="w"> </span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Size of the train set: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">. Size of the validation set: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">validation_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">. Size of the test set: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Size of the train set: 208491. Size of the validation set: 11583. Size of the test set: 11583
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Tokenizador">Tokenizador<a class="anchor-link" href="#Tokenizador">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Iniciamos o tokenizador e atribuímos ao token de padding o de end of string</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>
<span class="w"> </span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="s2">&quot;openai-community/gpt2&quot;</span>
<span class="w"> </span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>
<span class="n">tokenizer</span><span class="o">.</span><span class="n">padding_side</span> <span class="o">=</span> <span class="s2">&quot;right&quot;</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Adicionamos os tokens especiais de início e fim de piada</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">new_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;&amp;lt;SJ&amp;gt;&#39;</span><span class="p">,</span> <span class="s1">&#39;&amp;lt;EJ&amp;gt;&#39;</span><span class="p">]</span>   <span class="c1"># Start and end of joke tokens</span>
<span class="w"> </span>
<span class="n">num_added_tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">add_tokens</span><span class="p">(</span><span class="n">new_tokens</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Added </span><span class="si">{</span><span class="n">num_added_tokens</span><span class="si">}</span><span class="s2"> tokens&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Added 2 tokens
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Os adicionamos ao dataset</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">joke_column</span> <span class="o">=</span> <span class="s2">&quot;Joke&quot;</span>
<span class="w"> </span>
<span class="k">def</span><span class="w"> </span><span class="nf">format_joke</span><span class="p">(</span><span class="n">example</span><span class="p">):</span>
<span class="w">    </span><span class="n">example</span><span class="p">[</span><span class="n">joke_column</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;&amp;lt;SJ&amp;gt; &#39;</span> <span class="o">+</span> <span class="n">example</span><span class="p">[</span><span class="s1">&#39;Joke&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39; &amp;lt;EJ&amp;gt;&#39;</span>
<span class="w">    </span><span class="k">return</span> <span class="n">example</span>
<span class="w"> </span>
<span class="n">remove_columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">column</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">column_names</span> <span class="k">if</span> <span class="n">column</span> <span class="o">!=</span> <span class="n">joke_column</span><span class="p">]</span>
<span class="w"> </span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">format_joke</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="n">remove_columns</span><span class="p">)</span>
<span class="n">validation_dataset</span> <span class="o">=</span> <span class="n">validation_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">format_joke</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="n">remove_columns</span><span class="p">)</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">format_joke</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="n">remove_columns</span><span class="p">)</span>
<span class="n">train_dataset</span><span class="p">,</span> <span class="n">validation_dataset</span><span class="p">,</span> <span class="n">test_dataset</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>(Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;Joke&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 208491
 &#x7D;),
 Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;Joke&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 11583
 &#x7D;),
 Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;Joke&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 11583
 &#x7D;))
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Tokenizamos o conjunto de dados</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="n">joke_column</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="n">joke_column</span><span class="p">])</span>
<span class="n">validation_dataset</span> <span class="o">=</span> <span class="n">validation_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="n">joke_column</span><span class="p">])</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="n">joke_column</span><span class="p">])</span>
<span class="n">train_dataset</span><span class="p">,</span> <span class="n">validation_dataset</span><span class="p">,</span> <span class="n">test_dataset</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>(Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;input_ids&#x27;, &#x27;attention_mask&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 208491
 &#x7D;),
 Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;input_ids&#x27;, &#x27;attention_mask&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 11583
 &#x7D;),
 Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;input_ids&#x27;, &#x27;attention_mask&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 11583
 &#x7D;))
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Modelo">Modelo<a class="anchor-link" href="#Modelo">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Instanciamos o modelo, atribuímos o token de padding e adicionamos os novos tokens de início de piada e fim de piada</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>
<span class="n">model</span><span class="o">.</span><span class="n">resize_token_embeddings</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">))</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Embedding(50259, 768)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Dispositivo">Dispositivo<a class="anchor-link" href="#Dispositivo">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Criamos o dispositivo e passamos o modelo para o dispositivo</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="w"> </span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">half</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Conjunto de Dados do Pytorch">Conjunto de Dados do Pytorch<a class="anchor-link" href="#Conjunto de Dados do Pytorch">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Criamos um conjunto de dados do PyTorch</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dataset</span>
<span class="w"> </span>
<span class="k">class</span><span class="w"> </span><span class="nc">JokesDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
<span class="w">    </span><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">huggingface_dataset</span><span class="p">):</span>
<span class="w">        </span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">huggingface_dataset</span>
<span class="w"> </span>
<span class="w">    </span><span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">&#39;input_ids&#39;</span><span class="p">])</span>
<span class="w">        </span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
<span class="w">        </span><span class="k">return</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span>
<span class="w"> </span>
<span class="w">    </span><span class="k">def</span><span class="w"> </span><span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Instanciamos os conjuntos de dados de treinamento, validação e teste</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">train_pytorch_dataset</span> <span class="o">=</span> <span class="n">JokesDataset</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span>
<span class="n">validation_pytorch_dataset</span> <span class="o">=</span> <span class="n">JokesDataset</span><span class="p">(</span><span class="n">validation_dataset</span><span class="p">)</span>
<span class="n">test_pytorch_dataset</span> <span class="o">=</span> <span class="n">JokesDataset</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vamos ver um exemplo.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">train_pytorch_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>(torch.Size([768]), torch.Size([768]))
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Pytorch Dataloader">Pytorch Dataloader<a class="anchor-link" href="#Pytorch Dataloader">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Criamos os dataloaders</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="w"> </span>
<span class="n">BS</span> <span class="o">=</span> <span class="mi">28</span>
<span class="w"> </span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_pytorch_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">validation_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">validation_pytorch_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_pytorch_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vemos uma amostra</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_loader</span><span class="p">))</span>
<span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>(torch.Size([28, 768]), torch.Size([28, 768]))
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Passamos isso para o modelo.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
<span class="n">output</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>odict_keys([&#x27;logits&#x27;, &#x27;past_key_values&#x27;])
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Como podemos ver, não temos um valor de <code>loss</code>. Como já vimos, precisamos passar o <code>input_ids</code> e o <code>labels</code>.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">=</span><span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
<span class="n">output</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>odict_keys([&#x27;loss&#x27;, &#x27;logits&#x27;, &#x27;past_key_values&#x27;])
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Agora sim temos <code>loss</code></p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>80.5625
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Otimizador">Otimizador<a class="anchor-link" href="#Otimizador">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Criamos um otimizador</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AdamW</span>
<span class="w"> </span>
<span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-5</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
&#x20;&#x20;warnings.warn(
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Treinamento">Treinamento<a class="anchor-link" href="#Treinamento">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Criamos o loop de treinamento</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>
<span class="w"> </span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>
<span class="w"> </span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
<span class="w">    </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="w">    </span><span class="n">train_loss</span> <span class="o">=</span> <span class="mi">0</span>
<span class="w">    </span><span class="n">progresbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">at_mask</span> <span class="ow">in</span> <span class="n">progresbar</span><span class="p">:</span>
<span class="w">        </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="w">        </span><span class="n">at_mask</span> <span class="o">=</span> <span class="n">at_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">at_mask</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">input_ids</span><span class="p">)</span>
<span class="w"> </span>
<span class="w">        </span><span class="n">loss</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
<span class="w">        </span><span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="w">        </span><span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="w">        </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="w">        </span><span class="n">progresbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">({</span><span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()})</span>
<span class="w">    </span><span class="n">train_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
<span class="w">    </span><span class="n">progresbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">({</span><span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="n">train_loss</span><span class="p">})</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Epoch 1: 100%|██████████| 7447/7447 [51:07&amp;lt;00:00,  2.43it/s, train_loss=nan]
Epoch 2: 100%|██████████| 7447/7447 [51:06&amp;lt;00:00,  2.43it/s, train_loss=nan]
Epoch 3: 100%|██████████| 7447/7447 [51:07&amp;lt;00:00,  2.43it/s, train_loss=nan]
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Uso do modelo">Uso do modelo<a class="anchor-link" href="#Uso do modelo">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Testamos o modelo</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">generate_text</span><span class="p">(</span><span class="n">decoded_joke</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">stop_token</span><span class="o">=</span><span class="s1">&#39;&amp;lt;EJ&amp;gt;&#39;</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">    </span><span class="n">input_tokens</span> <span class="o">=</span> <span class="n">tokenize_function</span><span class="p">({</span><span class="s1">&#39;Joke&#39;</span><span class="p">:</span> <span class="n">decoded_joke</span><span class="p">})</span>
<span class="w">    </span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_tokens</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">input_tokens</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
<span class="w">    </span><span class="n">nex_token</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">][:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="w">    </span><span class="n">nex_token_decoded</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">nex_token</span><span class="p">)</span>
<span class="w">    </span><span class="n">decoded_joke</span> <span class="o">=</span> <span class="n">decoded_joke</span> <span class="o">+</span> <span class="n">nex_token_decoded</span>
<span class="w">    </span><span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_new_tokens</span><span class="p">):</span>
<span class="w">        </span><span class="n">nex_token</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">][:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="w">        </span><span class="n">nex_token_decoded</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">nex_token</span><span class="p">)</span>
<span class="w">        </span><span class="k">if</span> <span class="n">nex_token_decoded</span> <span class="o">==</span> <span class="n">stop_token</span><span class="p">:</span>
<span class="w">            </span><span class="k">break</span>
<span class="w">        </span><span class="n">decoded_joke</span> <span class="o">=</span> <span class="n">decoded_joke</span> <span class="o">+</span> <span class="n">nex_token_decoded</span>
<span class="w">        </span><span class="n">input_tokens</span> <span class="o">=</span> <span class="n">tokenize_function</span><span class="p">({</span><span class="s1">&#39;Joke&#39;</span><span class="p">:</span> <span class="n">decoded_joke</span><span class="p">})</span>
<span class="w">        </span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_tokens</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">input_tokens</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
<span class="w">    </span><span class="k">return</span> <span class="n">decoded_joke</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">generated_text</span> <span class="o">=</span> <span class="n">generate_text</span><span class="p">(</span><span class="s2">&quot;&amp;lt;SJ&amp;gt; Why didn&#39;t the frog cross the road&quot;</span><span class="p">)</span>
<span class="n">generated_text</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt-output-prompt">Out[]:</div>
<div class="output-text-output-subareaoutput_execute_result">
<pre>&quot;&amp;lt;SJ&amp;gt; Why didn&#x27;t the frog cross the road!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!&quot;</pre>
</div>
</div>
</div>
</section>