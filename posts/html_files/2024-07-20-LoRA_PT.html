<section class="section-block-markdown-cell">
<h1 id="LoRA - adaptacao de baixa classificacao de grandes modelos linguisticos">LoRA - adaptação de baixa classificação de grandes modelos linguísticos<a class="anchor-link" href="#LoRA - adaptacao de baixa classificacao de grandes modelos linguisticos">¶</a></h1>
</section>
<section class="section-block-markdown-cell">
<blockquote>
<p>Aviso: Este post foi traduzido para o português usando um modelo de tradução automática. Por favor, me avise se encontrar algum erro.</p>
</blockquote>
</section>
<section class="section-block-markdown-cell">
<p>O aumento do tamanho dos modelos de linguagem faz com que sejam cada vez mais caros de treinar, pois é necessário cada vez mais VRAM para armazenar todos os seus parâmetros e os gradientes derivados do treinamento.</p>
<p>No artigo <a href="https://arxiv.org/abs/2106.09685">LoRA - Low rank adaption of large language models</a> propõem congelar os pesos do modelo e treinar duas matrizes chamadas A e B, reduzindo significativamente o número de parâmetros que precisam ser treinados.</p>
<img src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/LoRA_adapat.webp" alt="LoRA">
<p>Vamos a ver como se faz isso</p>
</section>
<section class="section-block-markdown-cell">
<h2 id="Explicacao de LoRA">Explicação de LoRA<a class="anchor-link" href="#Explicacao de LoRA">¶</a></h2>
</section>
<section class="section-block-markdown-cell">
<h3 id="Atualizacao de pesos em uma rede neural">Atualização de pesos em uma rede neural<a class="anchor-link" href="#Atualizacao de pesos em uma rede neural">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Para entender como funciona LoRA, primeiro temos que lembrar o que ocorre quando treinamos um modelo. Voltemos à parte mais básica do deep learning, temos uma camada densa de uma rede neural que é definida como:</p>
<p><span class="math-display">y = Wx + b</span></p>
<p>Onde <span class="math-inline">W</span> é a matriz de pesos e <span class="math-inline">b</span> é o vetor de vieses.</p>
<p>Para simplificar, vamos a supor que não há viés, portanto ficaria assim</p>
<p><span class="math-display">y = Wx</span></p>
<p>Suponhamos que para uma entrada <span class="math-inline">x</span> queremos que tenha uma saída <span class="math-inline">ŷ</span></p>
<ul>
  <li>Primeiro, o que fazemos é calcular a saída que obtemos com nosso valor atual de pesos <span class="math-inline">W</span>, ou seja, obtemos o valor <span class="math-inline">y</span></li>
  <li>Em seguida, calculamos o erro que existe entre o valor de <span class="math-inline">y</span> que obtivemos e o valor que queríamos obter <span class="math-inline">ŷ</span>. A esse erro chamamos de <span class="math-inline">loss</span>, e o calculamos com alguma função matemática, agora não importa qual.</li>
  <li>Calculamos o gradiente (a derivada) do erro <span class="math-inline">loss</span> em relação à matriz de pesos <span class="math-inline">W</span>, ou seja, <span class="math-inline">\Delta W = \frac&#123;dloss&#125;&#123;dW&#125;</span></li>
  <li>Atualizamos os pesos <span class="math-inline">W</span> subtraindo de cada um dos seus valores o valor do gradiente multiplicado por um fator de aprendizado <span class="math-inline">\alpha</span>, ou seja, <span class="math-inline">W = W - \alpha \Delta W</span></li>
</ul>
</section>
<section class="section-block-markdown-cell">
<h3 id="LoRA">LoRA<a class="anchor-link" href="#LoRA">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Os autores de LoRA propõem que a matriz de pesos <span class="math-inline">W</span> pode ser decomposta em</p>
<p><span class="math-display">W \sim W + \Delta W</span></p>
<p>Assim, ao congelar a matriz <span class="math-inline">W</span> e treinar apenas a matriz <span class="math-inline">\Delta W</span>, pode-se obter um modelo que se adeque a novos dados sem ter que retreinar todo o modelo.</p>
<p>Mas você pode pensar que <span class="math-inline">\Delta W</span> é uma matriz do mesmo tamanho de <span class="math-inline">W</span>, portanto nada foi ganho, mas aqui os autores se baseiam em <code>Aghajanyan et al. (2020)</code>, um artigo no qual eles demonstraram que, embora os modelos de linguagem sejam grandes e seus parâmetros sejam matrizes com dimensões muito grandes, para adaptá-los a novas tarefas não é necessário alterar todos os valores das matrizes, mas sim alterar alguns poucos valores, o que tecnicamente é chamado de adaptação de baixa classificação. Daí o nome LoRA (Low Rank Adaptation).</p>
</section>
<section class="section-block-markdown-cell">
<p>Congelamos o modelo e agora queremos treinar a matriz <span class="math-inline">\Delta W</span>. Suponhamos que tanto <span class="math-inline">W</span> quanto <span class="math-inline">\Delta W</span> são matrizes de tamanho <span class="math-inline">20 &times; 10</span>, portanto temos 200 parâmetros treináveis.</p>
<p>Agora suponhamos que a matriz <span class="math-inline">\Delta W</span> pode ser decomposta no produto de duas matrizes <span class="math-inline">A</span> e <span class="math-inline">B</span>, ou seja</p>
<p><span class="math-display">\Delta W = A · B</span></p>
<p>Para que esta multiplicação ocorra, os tamanhos das matrizes <span class="math-inline">A</span> e <span class="math-inline">B</span> têm que ser <span class="math-inline">20 &times; n</span> e <span class="math-inline">n &times; 10</span>, respectivamente. Suponhamos que <span class="math-inline">n = 5</span>, portanto <span class="math-inline">A</span> seria de tamanho <span class="math-inline">20 &times; 5</span>, ou seja, 100 parâmetros, e <span class="math-inline">B</span> de tamanho <span class="math-inline">5 &times; 10</span>, ou seja, 50 parâmetros, por isso teríamos 100+50=150 parâmetros treináveis. Já temos menos parâmetros treináveis do que antes.</p>
<p>Agora suponhamos que <span class="math-inline">W</span> na verdade é uma matriz de tamanho <span class="math-inline">10.000 &times; 10.000</span>, portanto teríamos 100.000.000 parâmetros treináveis, mas se decompor <span class="math-inline">\Delta W</span> em <span class="math-inline">A</span> e <span class="math-inline">B</span> com <span class="math-inline">n = 5</span>, teríamos uma matriz de tamanho <span class="math-inline">10.000 &times; 5</span> e outra de tamanho <span class="math-inline">5 &times; 10.000</span>, portanto teríamos 50.000 parâmetros de uma e outros 50.000 parâmetros de outra, no total 100.000 parâmetros treináveis, ou seja, reduzimos o número de parâmetros 1000 vezes</p>
<p>Já pode ver o poder da LoRA, quando se têm modelos muito grandes, o número de parâmetros treináveis pode ser reduzido drasticamente.</p>
<p>Se voltarmos a ver a imagem da arquitetura de LoRA, a entenderemos melhor.</p>
<img src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/LoRA_adapat.webp" alt="LoRA adapt">
<p>Mas parece ainda melhor, a economia no número de parâmetros treináveis com esta imagem</p>
<img src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/Lora_matmul.webp" alt="LoRA matmul">
</section>
<section class="section-block-markdown-cell">
<h3 id="Implementacao de LoRA em transformers">Implementação de LoRA em transformers<a class="anchor-link" href="#Implementacao de LoRA em transformers">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Como os modelos de linguagem são implementações de transformers, vamos ver como se implementa LoRA em transformers. Na arquitetura transformer há camadas lineares nas matrizes de atenção <span class="math-inline">Q</span>, <span class="math-inline">K</span> e <span class="math-inline">V</span>, e nas camadas feedforward, por isso pode-se aplicar LoRA a todas essas camadas lineares. No paper, eles falam que, por simplicidade, o aplicam apenas às camadas lineares das matrizes de atenção <span class="math-inline">Q</span>, <span class="math-inline">K</span> e <span class="math-inline">V</span>.</p>
<p>Estas camadas têm um tamanho <span class="math-inline">d<sub>model</sub> &times; d<sub>model</sub></span>, onde <span class="math-inline">d<sub>model</sub></span> é a dimensão de embedding do modelo</p>
</section>
<section class="section-block-markdown-cell">
<h3 id="Tamanho do intervalo r">Tamanho do intervalo r<a class="anchor-link" href="#Tamanho do intervalo r">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Para poder ter esses benefícios, o tamanho do intervalo <span class="math-inline">r</span> deve ser menor que o tamanho das camadas lineares. Como dissemos que só o implementavam nas camadas lineares de atenção, que têm um tamanho <span class="math-inline">d<sub>model</sub> &times; d<sub>model</sub></span>, o tamanho do intervalo <span class="math-inline">r</span> deve ser menor que <span class="math-inline">d<sub>model</sub></span>.</p>
</section>
<section class="section-block-markdown-cell">
<h3 id="Inicializacao das matrizes A e B">Inicialização das matrizes A e B<a class="anchor-link" href="#Inicializacao das matrizes A e B">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>As matrizes <span class="math-inline">A</span> e <span class="math-inline">B</span> são inicializadas com uma distribuição gaussiana aleatória para <span class="math-inline">A</span> e zero para <span class="math-inline">B</span>, assim o produto de ambas as matrizes será zero no início, ou seja</p>
<p><span class="math-display">\Delta W = A · B = 0</span></p>
</section>
<section class="section-block-markdown-cell">
<h3 id="Influencia de LoRA por meio do parametro $\alpha$">Influência de LoRA por meio do parâmetro $\alpha$<a class="anchor-link" href="#Influencia de LoRA por meio do parametro $\alpha$">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Por último, na implementação de LoRA, adiciona-se um parâmetro <span class="math-inline">&alpha;</span> para estabelecer o grau de influência de LoRA no treinamento. É similar à taxa de aprendizado (learning rate) no fine tuning normal, mas neste caso é usado para estabelecer a influência de LoRA no treinamento. Dessa forma, a fórmula de LoRA ficaria assim</p>
<p><span class="math-display">W = W + &alpha; \Delta W = W + &alpha; A · B</span></p>
</section>
<section class="section-block-markdown-cell">
<h2 id="Vantagens do LoRA">Vantagens do LoRA<a class="anchor-link" href="#Vantagens do LoRA">¶</a></h2>
<p>Agora que entendemos como isso funciona, vamos ver as vantagens desse método.</p>
<ul>
  <li>Redução do número de parâmetros treináveis. Como vimos, o número de parâmetros treináveis é reduzido drasticamente, o que torna o treinamento muito mais rápido e requer menos VRAM, economizando muitos custos.* Adaptadores em produção. Podemos ter em produção um único modelo de linguagem e vários adaptadores, cada um para uma tarefa diferente, em vez de ter vários modelos treinados para cada tarefa, o que economiza custos de armazenamento e computação. Além disso, este método não precisa adicionar latência na inferência porque a matriz de pesos original pode ser fusionada com o adaptador, já que vimos que <span class="math-inline">W \sim W + \Delta W = W + A \cdot B</span>, portanto, o tempo de inferência seria o mesmo que usar o modelo de linguagem original.</li>
  <li>Compartilhar adaptadores. Se treinarmos um adaptador, podemos compartilhar apenas o adaptador. Isso significa que, em produção, todos podem ter o modelo original e cada vez que treinamos um adaptador, compartilhamos apenas o adaptador, portanto, como seriam compartilhadas matrizes muito menores, o tamanho dos arquivos compartilhados seria muito menor</li>
</ul>
</section>
<section class="section-block-markdown-cell">
<h2 id="Implementacao de LoRA em um LLM">Implementação de LoRA em um LLM<a class="anchor-link" href="#Implementacao de LoRA em um LLM">¶</a></h2>
</section>
<section class="section-block-markdown-cell">
<p>Vamos a repetir o código de treinamento do post <a href="https://maximofn.com/fine-tuning-sml/">Fine tuning SLMs</a>, em específico o treinamento para classificação de texto com as bibliotecas da Hugging Face, mas desta vez vamos fazer isso com LoRA. No post anterior, usamos um batch size de 28 para o loop de treinamento e de 40 para o de avaliação, no entanto, como agora não vamos treinar todos os pesos do modelo, mas apenas as matrizes de LoRA, poderemos usar um batch size maior.</p>
</section>
<section class="section-block-markdown-cell">
<h3 id="Login no Hub">Login no Hub<a class="anchor-link" href="#Login no Hub">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Nós nos logamos para fazer o upload do modelo para o Hub</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">huggingface_hub</span><span class="w"> </span><span class="kn">import</span> <span class="n">notebook_login</span>
<span class="n">notebook_login</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Conjunto de Dados">Conjunto de Dados<a class="anchor-link" href="#Conjunto de Dados">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Baixamos o conjunto de dados que vamos utilizar, que é um conjunto de dados de avaliações do <a href="https://huggingface.co/datasets/mteb/amazon_reviews_multi">Amazon</a></p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="w"> </span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;mteb/amazon_reviews_multi&quot;</span><span class="p">,</span> <span class="s2">&quot;en&quot;</span><span class="p">)</span>
<span class="n">dataset</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>DatasetDict(&#x7B;
&#x20;&#x20;&#x20;&#x20;train: Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;id&#x27;, &#x27;text&#x27;, &#x27;label&#x27;, &#x27;label_text&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 200000
&#x20;&#x20;&#x20;&#x20;&#x7D;)
&#x20;&#x20;&#x20;&#x20;validation: Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;id&#x27;, &#x27;text&#x27;, &#x27;label&#x27;, &#x27;label_text&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 5000
&#x20;&#x20;&#x20;&#x20;&#x7D;)
&#x20;&#x20;&#x20;&#x20;test: Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;id&#x27;, &#x27;text&#x27;, &#x27;label&#x27;, &#x27;label_text&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 5000
&#x20;&#x20;&#x20;&#x20;&#x7D;)
&#x7D;)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Criamos um subconjunto se você quiser testar o código com um conjunto de dados menor. No meu caso, usarei 100% do conjunto de dados.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">percentage</span> <span class="o">=</span> <span class="mi">1</span>
<span class="w"> </span>
<span class="n">subset_dataset_train</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">])</span> <span class="o">*</span> <span class="n">percentage</span><span class="p">)))</span>
<span class="n">subset_dataset_validation</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;validation&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;validation&#39;</span><span class="p">])</span> <span class="o">*</span> <span class="n">percentage</span><span class="p">)))</span>
<span class="n">subset_dataset_test</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">])</span> <span class="o">*</span> <span class="n">percentage</span><span class="p">)))</span>
<span class="w"> </span>
<span class="n">subset_dataset_train</span><span class="p">,</span> <span class="n">subset_dataset_validation</span><span class="p">,</span> <span class="n">subset_dataset_test</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>(Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;id&#x27;, &#x27;text&#x27;, &#x27;label&#x27;, &#x27;label_text&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 200000
 &#x7D;),
 Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;id&#x27;, &#x27;text&#x27;, &#x27;label&#x27;, &#x27;label_text&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 5000
 &#x7D;),
 Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;id&#x27;, &#x27;text&#x27;, &#x27;label&#x27;, &#x27;label_text&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 5000
 &#x7D;))
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vemos uma amostra</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">random</span><span class="w"> </span><span class="kn">import</span> <span class="n">randint</span>
<span class="w"> </span>
<span class="n">idx</span> <span class="o">=</span> <span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">subset_dataset_train</span><span class="p">))</span>
<span class="n">subset_dataset_train</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&#x7B;&#x27;id&#x27;: &#x27;en_0388304&#x27;,
 &#x27;text&#x27;: &#x27;The N was missing from on\n\nThe N was missing from on&#x27;,
 &#x27;label&#x27;: 0,
 &#x27;label_text&#x27;: &#x27;0&#x27;&#x7D;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Obtemos o número de classes, para obter o número de classes usamos <code>dataset[&#x27;train&#x27;]</code> e não <code>subset_dataset_train</code> porque se o subconjunto for muito pequeno é possível que não haja exemplos com todas as possíveis classes do conjunto de dados original</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="s1">&#39;label&#39;</span><span class="p">))</span>
<span class="n">num_classes</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>5
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Criamos uma função para criar o campo <code>label</code> no dataset. O dataset baixado tem o campo <code>labels</code>, mas a biblioteca <code>transformers</code> precisa que o campo seja chamado de <code>label</code> e não <code>labels</code>.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">set_labels</span><span class="p">(</span><span class="n">example</span><span class="p">):</span>
<span class="w">    </span><span class="n">example</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">example</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span>
<span class="w">    </span><span class="k">return</span> <span class="n">example</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Aplicamos a função ao conjunto de dados</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">subset_dataset_train</span> <span class="o">=</span> <span class="n">subset_dataset_train</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">set_labels</span><span class="p">)</span>
<span class="n">subset_dataset_validation</span> <span class="o">=</span> <span class="n">subset_dataset_validation</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">set_labels</span><span class="p">)</span>
<span class="n">subset_dataset_test</span> <span class="o">=</span> <span class="n">subset_dataset_test</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">set_labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">subset_dataset_train</span><span class="p">,</span> <span class="n">subset_dataset_validation</span><span class="p">,</span> <span class="n">subset_dataset_test</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>(Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;id&#x27;, &#x27;text&#x27;, &#x27;label&#x27;, &#x27;label_text&#x27;, &#x27;labels&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 200000
 &#x7D;),
 Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;id&#x27;, &#x27;text&#x27;, &#x27;label&#x27;, &#x27;label_text&#x27;, &#x27;labels&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 5000
 &#x7D;),
 Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;id&#x27;, &#x27;text&#x27;, &#x27;label&#x27;, &#x27;label_text&#x27;, &#x27;labels&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 5000
 &#x7D;))
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Voltamos a ver um exemplo</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">subset_dataset_train</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&#x7B;&#x27;id&#x27;: &#x27;en_0388304&#x27;,
 &#x27;text&#x27;: &#x27;The N was missing from on\n\nThe N was missing from on&#x27;,
 &#x27;label&#x27;: 0,
 &#x27;label_text&#x27;: &#x27;0&#x27;,
 &#x27;labels&#x27;: 0&#x7D;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Tokenizador">Tokenizador<a class="anchor-link" href="#Tokenizador">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Implementamos o tokenizador. Para que não dê erro, atribuímos o token de end of string ao token de padding</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>
<span class="w"> </span>
<span class="n">checkpoint</span> <span class="o">=</span> <span class="s2">&quot;openai-community/gpt2&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>
<span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Criamos uma função para tokenizar o dataset</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Aplicamos a função ao conjunto de dados e, de passagem, eliminamos as colunas que não precisamos</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">subset_dataset_train</span> <span class="o">=</span> <span class="n">subset_dataset_train</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="s1">&#39;label_text&#39;</span><span class="p">])</span>
<span class="n">subset_dataset_validation</span> <span class="o">=</span> <span class="n">subset_dataset_validation</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="s1">&#39;label_text&#39;</span><span class="p">])</span>
<span class="n">subset_dataset_test</span> <span class="o">=</span> <span class="n">subset_dataset_test</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="s1">&#39;label_text&#39;</span><span class="p">])</span>
<span class="w"> </span>
<span class="n">subset_dataset_train</span><span class="p">,</span> <span class="n">subset_dataset_validation</span><span class="p">,</span> <span class="n">subset_dataset_test</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>(Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;labels&#x27;, &#x27;input_ids&#x27;, &#x27;attention_mask&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 200000
 &#x7D;),
 Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;labels&#x27;, &#x27;input_ids&#x27;, &#x27;attention_mask&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 5000
 &#x7D;),
 Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;labels&#x27;, &#x27;input_ids&#x27;, &#x27;attention_mask&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 5000
 &#x7D;))
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Voltamos a ver uma amostra, mas neste caso só vemos as <code>keys</code></p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">subset_dataset_train</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>dict_keys([&#x27;labels&#x27;, &#x27;input_ids&#x27;, &#x27;attention_mask&#x27;])
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Modelo">Modelo<a class="anchor-link" href="#Modelo">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Instanciamos o modelo. Também, para que não nos dê erro, atribuímos o token de end of string ao token de padding</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="n">num_classes</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: [&#x27;score.weight&#x27;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Como já vimos no post <a href="https://maximofn.com/fine-tuning-sml/">Fine tuning SLMs</a> obtemos um warning que diz que algumas camadas não foram inicializadas. Isso acontece porque, neste caso, como é um problema de classificação e quando instanciamos o modelo dissemos que queremos que seja um modelo de classificação com 5 classes, a biblioteca removeu a última camada e a substituiu por uma com 5 neurônios na saída. Se não entende bem isso, veja o post que cito, que está melhor explicado.</p>
</section>
<section class="section-block-markdown-cell">
<h3 id="LoRA">LoRA<a class="anchor-link" href="#LoRA">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Antes de implementar LoRA, vemos o número de parâmetros treináveis que tem o modelo</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">total_params</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total trainable parameters before: </span><span class="si">{</span><span class="n">total_params</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Total trainable parameters before: 124,443,648
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vemos que tem 124M de parâmetros treináveis. Agora vamos congelá-los.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
<span class="w">    </span><span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
<span class="w"> </span>
<span class="n">total_params</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total trainable parameters after: </span><span class="si">{</span><span class="n">total_params</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Total trainable parameters after: 0
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Após o congelamento, não há mais parâmetros treináveis.</p>
</section>
<section class="section-block-markdown-cell">
<p>Vamos ver como é o modelo antes de aplicar LoRA</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">model</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>GPT2ForSequenceClassification(
&#x20;&#x20;(transformer): GPT2Model(
&#x20;&#x20;&#x20;&#x20;(wte): Embedding(50257, 768)
&#x20;&#x20;&#x20;&#x20;(wpe): Embedding(1024, 768)
&#x20;&#x20;&#x20;&#x20;(drop): Dropout(p=0.1, inplace=False)
&#x20;&#x20;&#x20;&#x20;(h): ModuleList(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(0-11): 12 x GPT2Block(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(attn): GPT2Attention(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(c_attn): Conv1D()
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(c_proj): Conv1D()
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(attn_dropout): Dropout(p=0.1, inplace=False)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(resid_dropout): Dropout(p=0.1, inplace=False)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(mlp): GPT2MLP(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(c_fc): Conv1D()
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(c_proj): Conv1D()
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(act): NewGELUActivation()
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(dropout): Dropout(p=0.1, inplace=False)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)
&#x20;&#x20;&#x20;&#x20;)
&#x20;&#x20;&#x20;&#x20;(ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
&#x20;&#x20;)
&#x20;&#x20;(score): Linear(in_features=768, out_features=5, bias=False)
)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Primeiro criamos a camada LoRA layer.</p>
<p>Tem que herdar de <code>torch.nn.Module</code> para poder atuar como uma camada de uma rede neural</p>
<p>No método <code>_init_</code> criamos as matrizes <code>A</code> e <code>B</code> inicializadas como explicado anteriormente, a matriz <code>A</code> com uma distribuição gaussiana aleatória e a matriz <code>B</code> com zeros. Também criamos os parâmetros <code>rank</code> e <code>alpha</code>.</p>
<p>No método <code>forward</code> calculamos LoRA conforme explicado.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="w"> </span>
<span class="k">class</span><span class="w"> </span><span class="nc">LoRALayer</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
<span class="w">        </span><span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="w">        </span><span class="bp">self</span><span class="o">.</span><span class="n">A</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">rank</span><span class="p">))</span>
<span class="w">        </span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">5.</span><span class="p">))</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>  <span class="c1"># similar to standard weight initialization</span>
<span class="w">        </span><span class="bp">self</span><span class="o">.</span><span class="n">B</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">))</span>
<span class="w">        </span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
<span class="w"> </span>
<span class="w">    </span><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">A</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">B</span><span class="p">)</span>
<span class="w">        </span><span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Agora criamos uma classe linear com LoRA.</p>
<p>Assim como antes, herde de <code>torch.nn.Module</code> para que possa atuar como uma camada de uma rede neural.</p>
<p>No método <code>init</code> criamos uma variável com a camada linear original da rede e criamos outra variável com a nova camada LoRA que havíamos implementado anteriormente.</p>
<p>No método <code>forward</code> somamos as saídas da camada linear original e da camada LoRA.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">LoRALinear</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">linear</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
<span class="w">        </span><span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="w">        </span><span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">linear</span>
<span class="w">        </span><span class="bp">self</span><span class="o">.</span><span class="n">lora</span> <span class="o">=</span> <span class="n">LoRALayer</span><span class="p">(</span>
<span class="w">            </span><span class="n">linear</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">linear</span><span class="o">.</span><span class="n">out_features</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">alpha</span>
<span class="w">        </span><span class="p">)</span>
<span class="w"> </span>
<span class="w">    </span><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">lora</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Por último, criamos uma função que substitua as camadas lineares pela nova camada linear com LoRA que criamos. O que ela faz é que se encontrar uma camada linear no modelo, a substitui pela camada linear com LoRA; caso contrário, aplica a função dentro das subcamadas da camada.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">replace_linear_with_lora</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
<span class="w">    </span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_children</span><span class="p">():</span>
<span class="w">        </span><span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">):</span>
<span class="w">            </span><span class="c1"># Replace the Linear layer with LinearWithLoRA</span>
<span class="w">            </span><span class="nb">setattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">LoRALinear</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">alpha</span><span class="p">))</span>
<span class="w">        </span><span class="k">else</span><span class="p">:</span>
<span class="w">            </span><span class="c1"># Recursively apply the same function to child modules</span>
<span class="w">            </span><span class="n">replace_linear_with_lora</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Aplicamos a função ao modelo para substituir as camadas lineares do modelo pela nova camada linear com LoRA</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">rank</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mi">16</span>
<span class="w"> </span>
<span class="n">replace_linear_with_lora</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vemos agora o número de parâmetros treináveis</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">total_params</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total trainable LoRA parameters: </span><span class="si">{</span><span class="n">total_params</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Total trainable LoRA parameters: 12,368
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Passamos de 124M de parâmetros treináveis para 12k parâmetros treináveis, ou seja, reduzimos o número de parâmetros treináveis 10.000 vezes!</p>
</section>
<section class="section-block-markdown-cell">
<p>Voltamos a ver o modelo</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">model</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>GPT2ForSequenceClassification(
&#x20;&#x20;(transformer): GPT2Model(
&#x20;&#x20;&#x20;&#x20;(wte): Embedding(50257, 768)
&#x20;&#x20;&#x20;&#x20;(wpe): Embedding(1024, 768)
&#x20;&#x20;&#x20;&#x20;(drop): Dropout(p=0.1, inplace=False)
&#x20;&#x20;&#x20;&#x20;(h): ModuleList(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(0-11): 12 x GPT2Block(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(attn): GPT2Attention(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(c_attn): Conv1D()
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(c_proj): Conv1D()
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(attn_dropout): Dropout(p=0.1, inplace=False)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(resid_dropout): Dropout(p=0.1, inplace=False)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(mlp): GPT2MLP(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(c_fc): Conv1D()
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(c_proj): Conv1D()
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(act): NewGELUActivation()
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(dropout): Dropout(p=0.1, inplace=False)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)
&#x20;&#x20;&#x20;&#x20;)
&#x20;&#x20;&#x20;&#x20;(ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
&#x20;&#x20;)
&#x20;&#x20;(score): LoRALinear(
&#x20;&#x20;&#x20;&#x20;(linear): Linear(in_features=768, out_features=5, bias=False)
&#x20;&#x20;&#x20;&#x20;(lora): LoRALayer()
&#x20;&#x20;)
)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vamos a compará-los camada por camada</p>
<table>
  <thead>
    <tr>
      <th>Modelo original</th>
      <th>Modelo com LoRA</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>GPT2ForSequenceClassification(</td>
      <td>GPT2ForSequenceClassification(</td>
    </tr>
    <tr>
      <td>(transformer): GPT2Model(</td>
      <td>(transformer): GPT2Model(</td>
    </tr>
    <tr>
      <td>(wte): Embedding(50257, 768)</td>
      <td>(wte): Embedding(50257, 768)</td>
    </tr>
    <tr>
      <td>(wpe): Embedding(1024, 768)</td>
      <td>(wpe): Embedding(1024, 768)</td>
    </tr>
    <tr>
      <td>(drop): Dropout(p=0.1, inplace=False)</td>
      <td>(drop): Dropout(p=0.1, inplace=False)</td>
    </tr>
    <tr>
      <td>(h): ModuleList(</td>
      <td>(h): ModuleList(</td>
    </tr>
    <tr>
      <td>(0-11): 12 x GPT2Block(</td>
      <td>(0-11): 12 x GPT2Block(</td>
    </tr>
    <tr>
      <td>(ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)</td>
      <td>(ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)</td>
    </tr>
    <tr>
      <td>(attn): GPT2Attention(</td>
      <td>(attn): GPT2Attention(</td>
    </tr>
    <tr>
      <td>(c_attn): Conv1D()</td>
      <td>(c_attn): Conv1D()</td>
    </tr>
    <tr>
      <td>(c_proj): Conv1D()</td>
      <td>(c_proj): Conv1D()</td>
    </tr>
    <tr>
      <td>(attn_dropout): Dropout(p=0.1, inplace=False)</td>
      <td>(attn_dropout): Dropout(p=0.1, inplace=False)</td>
    </tr>
    <tr>
      <td>(resid_dropout): Dropout(p=0.1, inplace=False)</td>
      <td>(resid_dropout): Dropout(p=0.1, inplace=False)</td>
    </tr>
    <tr>
      <td>)</td>
      <td>)</td>
    </tr>
    <tr>
      <td>(ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)</td>
      <td>(ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)</td>
    </tr>
    <tr>
      <td>(c_fc): Conv1D()</td>
      <td>(c_fc): Conv1D()</td>
    </tr>
    <tr>
      <td>(c_proj): Conv1D()</td>
      <td>(c_proj): Conv1D()</td>
    </tr>
    <tr>
      <td>(act): NewGELUActivation()</td>
      <td>(act): NewGELUActivation()</td>
    </tr>
    <tr>
      <td>(dropout): Dropout(p=0.1, inplace=False)</td>
      <td>(dropout): Dropout(p=0.1, inplace=False)</td>
    </tr>
    <tr>
      <td>)</td>
      <td>)</td>
    </tr>
    <tr>
      <td>)</td>
      <td>)</td>
    </tr>
    <tr>
      <td>)</td>
      <td>)</td>
    </tr>
    <tr>
      <td>(ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)</td>
      <td>(ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)</td>
    </tr>
    <tr>
      <td>)</td>
      <td>)</td>
    </tr>
    <tr>
      <td></td>
      <td>(pontuação): LoRALinear()</td>
    </tr>
    <tr>
      <td>(score): Linear(in_features=768, out_features=5, bias=False)</td>
      <td>(linear): Linear(in_features=768, out_features=5, bias=False)</td>
    </tr>
    <tr>
      <td></td>
      <td>(lora): LoRAL层()</td>
    </tr>
  </tbody>
</table>
<p>Nota: Parece que hubo un error en la traducción del término "LoRALayer" al portugués. La traducción correcta sería:</p>
<table>
  <thead>
    <tr>
      <th></th>
      <th>(lora): LoRALayer()</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>)</td>
      <td>)</td>
    </tr>
  </tbody>
</table>
<p>Vemos que são iguais, exceto no final, onde no modelo original havia uma camada linear normal e no modelo com LoRA há uma camada <code>LoRALinear</code> que dentro possui a camada linear do modelo original e uma camada <code>LoRALayer</code></p>
</section>
<section class="section-block-markdown-cell">
<h3 id="Treinamento">Treinamento<a class="anchor-link" href="#Treinamento">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Uma vez instanciado o modelo com LoRA, vamos treiná-lo como sempre</p>
</section>
<section class="section-block-markdown-cell">
<p>Como dissem, no post <a href="https://maximofn.com/fine-tuning-sml/">Fine tuning SLMs</a> usamos um batch size de 28 para o loop de treinamento e de 40 para o de avaliação, enquanto agora que há menos parâmetros treináveis podemos usar um batch size maior.</p>
<p>Por que isso acontece? Quando se treina um modelo, é necessário armazenar na memória da GPU o modelo e os gradientes desse modelo, então tanto com LoRA quanto sem LoRA, o modelo precisa ser armazenado igualmente, mas no caso do LoRA, apenas os gradientes de 12k parâmetros são armazenados, enquanto que sem LoRA, os gradientes de 128M de parâmetros são armazenados, por isso com LoRA é necessário menos memória da GPU, permitindo o uso de um batch size maior.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">TrainingArguments</span>
<span class="w"> </span>
<span class="n">metric_name</span> <span class="o">=</span> <span class="s2">&quot;accuracy&quot;</span>
<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;GPT2-small-LoRA-finetuned-amazon-reviews-en-classification&quot;</span>
<span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>
<span class="n">BS_TRAIN</span> <span class="o">=</span> <span class="mi">400</span>
<span class="n">BS_EVAL</span> <span class="o">=</span> <span class="mi">400</span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">WEIGHT_DECAY</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="w"> </span>
<span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
<span class="w">    </span><span class="n">model_name</span><span class="p">,</span>
<span class="w">    </span><span class="n">eval_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="n">save_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>
<span class="w">    </span><span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>
<span class="w">    </span><span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>
<span class="w">    </span><span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>
<span class="w">    </span><span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>
<span class="w">    </span><span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">&quot;cosine&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
<span class="w">    </span><span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="w">    </span><span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="w">    </span><span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span>
<span class="w">    </span><span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="w">    </span><span class="n">logging_dir</span><span class="o">=</span><span class="s2">&quot;./runs&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">evaluate</span><span class="w"> </span><span class="kn">import</span> <span class="n">load</span>
<span class="w"> </span>
<span class="n">metric</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">def</span><span class="w"> </span><span class="nf">compute_metrics</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">):</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">)</span>
<span class="w">    </span><span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">eval_pred</span>
<span class="w">    </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="w">    </span><span class="k">return</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Trainer</span>
<span class="w"> </span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
<span class="w">    </span><span class="n">model</span><span class="p">,</span>
<span class="w">    </span><span class="n">training_args</span><span class="p">,</span>
<span class="w">    </span><span class="n">train_dataset</span><span class="o">=</span><span class="n">subset_dataset_train</span><span class="p">,</span>
<span class="w">    </span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">subset_dataset_validation</span><span class="p">,</span>
<span class="w">    </span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
<span class="w">    </span><span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&amp;lt;IPython.core.display.HTML object&amp;gt;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&amp;lt;transformers.trainer_utils.EvalPrediction object at 0x7cd07be46440&amp;gt;
&amp;lt;transformers.trainer_utils.EvalPrediction object at 0x7cd07be45c30&amp;gt;
&amp;lt;transformers.trainer_utils.EvalPrediction object at 0x7cd07be8b970&amp;gt;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>TrainOutput(global_step=1500, training_loss=1.8345018310546874, metrics=&#x7B;&#x27;train_runtime&#x27;: 2565.4667, &#x27;train_samples_per_second&#x27;: 233.876, &#x27;train_steps_per_second&#x27;: 0.585, &#x27;total_flos&#x27;: 2.352076406784e+17, &#x27;train_loss&#x27;: 1.8345018310546874, &#x27;epoch&#x27;: 3.0&#x7D;)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Avaliacao">Avaliação<a class="anchor-link" href="#Avaliacao">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Uma vez treinado, avaliamos sobre o dataset de teste</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">subset_dataset_test</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&amp;lt;IPython.core.display.HTML object&amp;gt;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&amp;lt;transformers.trainer_utils.EvalPrediction object at 0x7cd07be8bbe0&amp;gt;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&#x7B;&#x27;eval_loss&#x27;: 1.5203168392181396,
 &#x27;eval_accuracy&#x27;: 0.3374,
 &#x27;eval_runtime&#x27;: 19.3843,
 &#x27;eval_samples_per_second&#x27;: 257.94,
 &#x27;eval_steps_per_second&#x27;: 0.671,
 &#x27;epoch&#x27;: 3.0&#x7D;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Publicar o modelo">Publicar o modelo<a class="anchor-link" href="#Publicar o modelo">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Já temos nosso modelo treinado, já podemos compartilhá-lo com o mundo, então primeiro criamos uma **model card**</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">create_model_card</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>E já podemos publicá-lo. Como a primeira coisa que fizemos foi fazer login no hub do Hugging Face, podemos enviá-lo para o nosso hub sem nenhum problema.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">push_to_hub</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<h2 id="Teste do modelo">Teste do modelo<a class="anchor-link" href="#Teste do modelo">¶</a></h2>
</section>
<section class="section-block-markdown-cell">
<p>Limpez tudo o possível</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">gc</span>
<span class="w"> </span>

<span class="k">def</span><span class="w"> </span><span class="nf">clear_hardwares</span><span class="p">():</span>
<span class="w">    </span><span class="n">torch</span><span class="o">.</span><span class="n">clear_autocast_cache</span><span class="p">()</span>
<span class="w">    </span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">ipc_collect</span><span class="p">()</span>
<span class="w">    </span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
<span class="w">    </span><span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
<span class="w"> </span>

<span class="n">clear_hardwares</span><span class="p">()</span>
<span class="n">clear_hardwares</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Como subimos o modelo ao nosso hub, podemos baixá-lo e usá-lo</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">pipeline</span>
<span class="w"> </span>
<span class="n">user</span> <span class="o">=</span> <span class="s2">&quot;maximofn&quot;</span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">user</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="n">task</span> <span class="o">=</span> <span class="s2">&quot;text-classification&quot;</span>
<span class="n">classifier</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">checkpoints</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">checkpoints</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Agora, se quisermos que nos retorne a probabilidade de todas as classes, simplesmente usamos o classificador que acabamos de instanciar, com o parâmetro <code>top_k=None</code></p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">labels</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="s2">&quot;I love this product&quot;</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">labels</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>[&#x7B;&#x27;label&#x27;: &#x27;LABEL_0&#x27;, &#x27;score&#x27;: 0.8419149518013&#x7D;,
 &#x7B;&#x27;label&#x27;: &#x27;LABEL_1&#x27;, &#x27;score&#x27;: 0.09386005252599716&#x7D;,
 &#x7B;&#x27;label&#x27;: &#x27;LABEL_3&#x27;, &#x27;score&#x27;: 0.03624210134148598&#x7D;,
 &#x7B;&#x27;label&#x27;: &#x27;LABEL_2&#x27;, &#x27;score&#x27;: 0.02049318142235279&#x7D;,
 &#x7B;&#x27;label&#x27;: &#x27;LABEL_4&#x27;, &#x27;score&#x27;: 0.0074898069724440575&#x7D;]
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Se quisermos apenas a classe com a maior probabilidade, fazemos o mesmo mas com o parâmetro <code>top_k=1</code></p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">label</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="s2">&quot;I love this product&quot;</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">label</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>[&#x7B;&#x27;label&#x27;: &#x27;LABEL_0&#x27;, &#x27;score&#x27;: 0.8419149518013&#x7D;]
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>E se quisermos n classes, fazemos o mesmo mas com o parâmetro <code>top_k=n</code></p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">two_labels</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="s2">&quot;I love this product&quot;</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">two_labels</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>[&#x7B;&#x27;label&#x27;: &#x27;LABEL_0&#x27;, &#x27;score&#x27;: 0.8419149518013&#x7D;,
 &#x7B;&#x27;label&#x27;: &#x27;LABEL_1&#x27;, &#x27;score&#x27;: 0.09386005252599716&#x7D;]
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Também podemos testar o modelo com Automodel e AutoTokenizer</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="w"> </span>
<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;GPT2-small-finetuned-amazon-reviews-en-classification&quot;</span>
<span class="n">user</span> <span class="o">=</span> <span class="s2">&quot;maximofn&quot;</span>
<span class="n">checkpoint</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">user</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="n">num_classes</span>
<span class="w"> </span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="n">num_classes</span><span class="p">)</span><span class="o">.</span><span class="n">half</span><span class="p">()</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">&quot;I love this product&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="w">    </span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
<span class="n">logits</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">logits</span>
<span class="n">lables</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">lables</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>[0.003940582275390625,
 0.00266265869140625,
 0.013946533203125,
 0.1544189453125,
 0.8251953125]
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Se você quiser testar mais o modelo, você pode vê-lo em <a href="https://huggingface.co/Maximofn/GPT2-small-LoRA-finetuned-amazon-reviews-en-classification">Maximofn/GPT2-small-LoRA-finetuned-amazon-reviews-en-classification</a></p>
</section>
<section class="section-block-markdown-cell">
<h2 id="Implementacao de LoRA em um LLM com PEFT da Hugging Face">Implementação de LoRA em um LLM com PEFT da Hugging Face<a class="anchor-link" href="#Implementacao de LoRA em um LLM com PEFT da Hugging Face">¶</a></h2>
</section>
<section class="section-block-markdown-cell">
<p>Podemos fazer o mesmo com a biblioteca <code>PEFT</code> do Hugging Face. Vamos vê-lo.</p>
</section>
<section class="section-block-markdown-cell">
<h3 id="Login no Hub">Login no Hub<a class="anchor-link" href="#Login no Hub">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Nós fazemos login para fazer o upload do modelo para o Hub</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">huggingface_hub</span><span class="w"> </span><span class="kn">import</span> <span class="n">notebook_login</span>
<span class="n">notebook_login</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Conjunto de Dados">Conjunto de Dados<a class="anchor-link" href="#Conjunto de Dados">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Voltamos a baixar o dataset</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="w"> </span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;mteb/amazon_reviews_multi&quot;</span><span class="p">,</span> <span class="s2">&quot;en&quot;</span><span class="p">)</span>
<span class="n">dataset</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>DatasetDict(&#x7B;
&#x20;&#x20;&#x20;&#x20;train: Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;id&#x27;, &#x27;text&#x27;, &#x27;label&#x27;, &#x27;label_text&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 200000
&#x20;&#x20;&#x20;&#x20;&#x7D;)
&#x20;&#x20;&#x20;&#x20;validation: Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;id&#x27;, &#x27;text&#x27;, &#x27;label&#x27;, &#x27;label_text&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 5000
&#x20;&#x20;&#x20;&#x20;&#x7D;)
&#x20;&#x20;&#x20;&#x20;test: Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;id&#x27;, &#x27;text&#x27;, &#x27;label&#x27;, &#x27;label_text&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 5000
&#x20;&#x20;&#x20;&#x20;&#x7D;)
&#x7D;)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Criamos um subconjunto caso você queira testar o código com um conjunto de dados menor. No meu caso, usarei 100% do conjunto de dados.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">percentage</span> <span class="o">=</span> <span class="mi">1</span>
<span class="w"> </span>
<span class="n">subset_dataset_train</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">])</span> <span class="o">*</span> <span class="n">percentage</span><span class="p">)))</span>
<span class="n">subset_dataset_validation</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;validation&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;validation&#39;</span><span class="p">])</span> <span class="o">*</span> <span class="n">percentage</span><span class="p">)))</span>
<span class="n">subset_dataset_test</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">])</span> <span class="o">*</span> <span class="n">percentage</span><span class="p">)))</span>
<span class="w"> </span>
<span class="n">subset_dataset_train</span><span class="p">,</span> <span class="n">subset_dataset_validation</span><span class="p">,</span> <span class="n">subset_dataset_test</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>(Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;id&#x27;, &#x27;text&#x27;, &#x27;label&#x27;, &#x27;label_text&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 200000
 &#x7D;),
 Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;id&#x27;, &#x27;text&#x27;, &#x27;label&#x27;, &#x27;label_text&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 5000
 &#x7D;),
 Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;id&#x27;, &#x27;text&#x27;, &#x27;label&#x27;, &#x27;label_text&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 5000
 &#x7D;))
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Obtemos o número de classes, para obter o número de classes usamos <code>dataset[&#x27;train&#x27;]</code> e não <code>subset_dataset_train</code> porque se o subconjunto for muito pequeno é possível que não haja exemplos com todas as possíveis classes do conjunto de dados original</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="s1">&#39;label&#39;</span><span class="p">))</span>
<span class="n">num_classes</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>5
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Criamos uma função para criar o campo <code>label</code> no dataset. O dataset baixado tem o campo <code>labels</code>, mas a biblioteca <code>transformers</code> precisa que o campo seja chamado de <code>label</code> e não <code>labels</code>.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">set_labels</span><span class="p">(</span><span class="n">example</span><span class="p">):</span>
<span class="w">    </span><span class="n">example</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">example</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span>
<span class="w">    </span><span class="k">return</span> <span class="n">example</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Aplicamos a função ao conjunto de dados</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">subset_dataset_train</span> <span class="o">=</span> <span class="n">subset_dataset_train</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">set_labels</span><span class="p">)</span>
<span class="n">subset_dataset_validation</span> <span class="o">=</span> <span class="n">subset_dataset_validation</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">set_labels</span><span class="p">)</span>
<span class="n">subset_dataset_test</span> <span class="o">=</span> <span class="n">subset_dataset_test</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">set_labels</span><span class="p">)</span>
<span class="w"> </span>
<span class="n">subset_dataset_train</span><span class="p">,</span> <span class="n">subset_dataset_validation</span><span class="p">,</span> <span class="n">subset_dataset_test</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>(Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;id&#x27;, &#x27;text&#x27;, &#x27;label&#x27;, &#x27;label_text&#x27;, &#x27;labels&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 200000
 &#x7D;),
 Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;id&#x27;, &#x27;text&#x27;, &#x27;label&#x27;, &#x27;label_text&#x27;, &#x27;labels&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 5000
 &#x7D;),
 Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;id&#x27;, &#x27;text&#x27;, &#x27;label&#x27;, &#x27;label_text&#x27;, &#x27;labels&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 5000
 &#x7D;))
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Tokenizador">Tokenizador<a class="anchor-link" href="#Tokenizador">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Instanciamos o tokenizador. Para que não nos dê erro, atribuímos o token de end of string ao token de padding</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>
<span class="w"> </span>
<span class="n">checkpoint</span> <span class="o">=</span> <span class="s2">&quot;openai-community/gpt2&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>
<span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Criamos uma função para tokenizar o dataset</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
<span class="w">    </span><span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Aplicamos a função ao conjunto de dados e, de passagem, eliminamos as colunas que não precisamos.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">subset_dataset_train</span> <span class="o">=</span> <span class="n">subset_dataset_train</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="s1">&#39;label_text&#39;</span><span class="p">])</span>
<span class="n">subset_dataset_validation</span> <span class="o">=</span> <span class="n">subset_dataset_validation</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="s1">&#39;label_text&#39;</span><span class="p">])</span>
<span class="n">subset_dataset_test</span> <span class="o">=</span> <span class="n">subset_dataset_test</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="s1">&#39;label_text&#39;</span><span class="p">])</span>
<span class="w"> </span>
<span class="n">subset_dataset_train</span><span class="p">,</span> <span class="n">subset_dataset_validation</span><span class="p">,</span> <span class="n">subset_dataset_test</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>(Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;labels&#x27;, &#x27;input_ids&#x27;, &#x27;attention_mask&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 200000
 &#x7D;),
 Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;labels&#x27;, &#x27;input_ids&#x27;, &#x27;attention_mask&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 5000
 &#x7D;),
 Dataset(&#x7B;
&#x20;&#x20;&#x20;&#x20;&#x20;features: [&#x27;labels&#x27;, &#x27;input_ids&#x27;, &#x27;attention_mask&#x27;],
&#x20;&#x20;&#x20;&#x20;&#x20;num_rows: 5000
 &#x7D;))
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Modelo">Modelo<a class="anchor-link" href="#Modelo">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Instanciamos o modelo. Também, para que não dê erro, atribuímos o token de end of string ao token de padding</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="n">num_classes</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: [&#x27;score.weight&#x27;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="LoRA com PEFT">LoRA com PEFT<a class="anchor-link" href="#LoRA com PEFT">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Antes de criar o modelo com LoRA, vamos a ver suas camadas</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">model</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>GPT2ForSequenceClassification(
&#x20;&#x20;(transformer): GPT2Model(
&#x20;&#x20;&#x20;&#x20;(wte): Embedding(50257, 768)
&#x20;&#x20;&#x20;&#x20;(wpe): Embedding(1024, 768)
&#x20;&#x20;&#x20;&#x20;(drop): Dropout(p=0.1, inplace=False)
&#x20;&#x20;&#x20;&#x20;(h): ModuleList(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(0-11): 12 x GPT2Block(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(attn): GPT2Attention(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(c_attn): Conv1D()
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(c_proj): Conv1D()
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(attn_dropout): Dropout(p=0.1, inplace=False)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(resid_dropout): Dropout(p=0.1, inplace=False)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(mlp): GPT2MLP(
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(c_fc): Conv1D()
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(c_proj): Conv1D()
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(act): NewGELUActivation()
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;(dropout): Dropout(p=0.1, inplace=False)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)
&#x20;&#x20;&#x20;&#x20;&#x20;&#x20;)
&#x20;&#x20;&#x20;&#x20;)
&#x20;&#x20;&#x20;&#x20;(ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
&#x20;&#x20;)
&#x20;&#x20;(score): Linear(in_features=768, out_features=5, bias=False)
)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Como podemos ver, há apenas uma camada <code>Linear</code>, que é <code>score</code> e que é a que vamos substituir.</p>
</section>
<section class="section-block-markdown-cell">
<p>Podemos criar uma configuração de LoRA com a biblioteca PEFT e depois aplicar LoRA ao mo</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">peft</span><span class="w"> </span><span class="kn">import</span> <span class="n">LoraConfig</span><span class="p">,</span> <span class="n">TaskType</span>
<span class="w"> </span>
<span class="n">peft_config</span> <span class="o">=</span> <span class="n">LoraConfig</span><span class="p">(</span>
<span class="w">    </span><span class="n">r</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
<span class="w">    </span><span class="n">lora_alpha</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
<span class="w">    </span><span class="n">lora_dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
<span class="w">    </span><span class="n">task_type</span><span class="o">=</span><span class="n">TaskType</span><span class="o">.</span><span class="n">SEQ_CLS</span><span class="p">,</span>
<span class="w">    </span><span class="n">target_modules</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;score&quot;</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Com esta configuração, definimos um rank de 16 e um alpha de 32. Além disso, adicionamos um dropout às camadas de LoRA de 0.1. Precisamos indicar a tarefa para a configuração de LoRA, neste caso é uma tarefa de sequence classification. Por fim, indicamos quais camadas queremos substituir, neste caso a camada <code>score</code>.</p>
</section>
<section class="section-block-markdown-cell">
<p>Agora aplicamos LoRA ao modelo</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">peft</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_peft_model</span>
<span class="w"> </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">get_peft_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">peft_config</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vamos ver quantos parâmetros treináveis o modelo tem agora.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">print_trainable_parameters</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>trainable params: 12,368 || all params: 124,456,016 || trainable%: 0.0099
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Obtemos os mesmos parâmetros treináveis que antes</p>
</section>
<section class="section-block-markdown-cell">
<h3 id="Treinamento">Treinamento<a class="anchor-link" href="#Treinamento">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Uma vez instanciado o modelo com LoRA, vamos treiná-lo como sempre</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">TrainingArguments</span>
<span class="w"> </span>
<span class="n">metric_name</span> <span class="o">=</span> <span class="s2">&quot;accuracy&quot;</span>
<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;GPT2-small-PEFT-LoRA-finetuned-amazon-reviews-en-classification&quot;</span>
<span class="n">LR</span> <span class="o">=</span> <span class="mf">2e-5</span>
<span class="n">BS_TRAIN</span> <span class="o">=</span> <span class="mi">400</span>
<span class="n">BS_EVAL</span> <span class="o">=</span> <span class="mi">400</span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">WEIGHT_DECAY</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="w"> </span>
<span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
<span class="w">    </span><span class="n">model_name</span><span class="p">,</span>
<span class="w">    </span><span class="n">eval_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="n">save_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span>
<span class="w">    </span><span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BS_TRAIN</span><span class="p">,</span>
<span class="w">    </span><span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BS_EVAL</span><span class="p">,</span>
<span class="w">    </span><span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>
<span class="w">    </span><span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span>
<span class="w">    </span><span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">&quot;cosine&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
<span class="w">    </span><span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="w">    </span><span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="w">    </span><span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span>
<span class="w">    </span><span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="w">    </span><span class="n">logging_dir</span><span class="o">=</span><span class="s2">&quot;./runs&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">evaluate</span><span class="w"> </span><span class="kn">import</span> <span class="n">load</span>
<span class="w"> </span>
<span class="n">metric</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="w"> </span>
<span class="k">def</span><span class="w"> </span><span class="nf">compute_metrics</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">):</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">)</span>
<span class="w">    </span><span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">eval_pred</span>
<span class="w">    </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="w">    </span><span class="k">return</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Trainer</span>
<span class="w"> </span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
<span class="w">    </span><span class="n">model</span><span class="p">,</span>
<span class="w">    </span><span class="n">training_args</span><span class="p">,</span>
<span class="w">    </span><span class="n">train_dataset</span><span class="o">=</span><span class="n">subset_dataset_train</span><span class="p">,</span>
<span class="w">    </span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">subset_dataset_validation</span><span class="p">,</span>
<span class="w">    </span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
<span class="w">    </span><span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&amp;lt;IPython.core.display.HTML object&amp;gt;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&amp;lt;transformers.trainer_utils.EvalPrediction object at 0x7f774a50bbe0&amp;gt;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&amp;lt;IPython.core.display.HTML object&amp;gt;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&amp;lt;transformers.trainer_utils.EvalPrediction object at 0x7f77486a7c40&amp;gt;
&amp;lt;transformers.trainer_utils.EvalPrediction object at 0x7f7749eb5690&amp;gt;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>TrainOutput(global_step=1500, training_loss=1.751504597981771, metrics=&#x7B;&#x27;train_runtime&#x27;: 2551.7753, &#x27;train_samples_per_second&#x27;: 235.13, &#x27;train_steps_per_second&#x27;: 0.588, &#x27;total_flos&#x27;: 2.352524525568e+17, &#x27;train_loss&#x27;: 1.751504597981771, &#x27;epoch&#x27;: 3.0&#x7D;)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Avaliacao">Avaliação<a class="anchor-link" href="#Avaliacao">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Uma vez treinado, avaliamos sobre o dataset de teste</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">subset_dataset_test</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&amp;lt;IPython.core.display.HTML object&amp;gt;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&amp;lt;transformers.trainer_utils.EvalPrediction object at 0x7f77a1d1f7c0&amp;gt;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>&#x7B;&#x27;eval_loss&#x27;: 1.4127237796783447,
 &#x27;eval_accuracy&#x27;: 0.3862,
 &#x27;eval_runtime&#x27;: 19.3275,
 &#x27;eval_samples_per_second&#x27;: 258.699,
 &#x27;eval_steps_per_second&#x27;: 0.673,
 &#x27;epoch&#x27;: 3.0&#x7D;
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Publicar o modelo">Publicar o modelo<a class="anchor-link" href="#Publicar o modelo">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Criamos uma model card</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">create_model_card</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>O publicamos</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">push_to_hub</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>CommitInfo(commit_url=&#x27;https://huggingface.co/Maximofn/GPT2-small-PEFT-LoRA-finetuned-amazon-reviews-en-classification/commit/839066c2bde02689a6b3f5624ac25f89c4de217d&#x27;, commit_message=&#x27;End of training&#x27;, commit_description=&#x27;&#x27;, oid=&#x27;839066c2bde02689a6b3f5624ac25f89c4de217d&#x27;, pr_url=None, pr_revision=None, pr_num=None)
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h2 id="Teste do modelo treinado com PEFT">Teste do modelo treinado com PEFT<a class="anchor-link" href="#Teste do modelo treinado com PEFT">¶</a></h2>
</section>
<section class="section-block-markdown-cell">
<p>Limpamos tudo o possível</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">gc</span>
<span class="w"> </span>

<span class="k">def</span><span class="w"> </span><span class="nf">clear_hardwares</span><span class="p">():</span>
<span class="w">    </span><span class="n">torch</span><span class="o">.</span><span class="n">clear_autocast_cache</span><span class="p">()</span>
<span class="w">    </span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">ipc_collect</span><span class="p">()</span>
<span class="w">    </span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
<span class="w">    </span><span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
<span class="w"> </span>

<span class="n">clear_hardwares</span><span class="p">()</span>
<span class="n">clear_hardwares</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Como subimos o modelo ao nosso hub, podemos baixá-lo e usá-lo</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">pipeline</span>
<span class="w"> </span>
<span class="n">user</span> <span class="o">=</span> <span class="s2">&quot;maximofn&quot;</span>
<span class="n">checkpoints</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">user</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="n">task</span> <span class="o">=</span> <span class="s2">&quot;text-classification&quot;</span>
<span class="n">classifier</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">checkpoints</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">checkpoints</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: [&#x27;score.weight&#x27;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Agora, se quisermos que nos retorne a probabilidade de todas as classes, simplesmente usamos o classificador que acabamos de instanciar, com o parâmetro <code>top_k=None</code></p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">labels</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="s2">&quot;I love this product&quot;</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">labels</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>[&#x7B;&#x27;label&#x27;: &#x27;LABEL_1&#x27;, &#x27;score&#x27;: 0.9979197382926941&#x7D;,
 &#x7B;&#x27;label&#x27;: &#x27;LABEL_0&#x27;, &#x27;score&#x27;: 0.002080311067402363&#x7D;]
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Se quisermos apenas a classe com a maior probabilidade fazemos o mesmo mas com o parâmetro <code>top_k=1</code></p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">label</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="s2">&quot;I love this product&quot;</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">label</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>[&#x7B;&#x27;label&#x27;: &#x27;LABEL_1&#x27;, &#x27;score&#x27;: 0.9979197382926941&#x7D;]
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>E se quisermos n classes, fazemos o mesmo mas com o parâmetro <code>top_k=n</code></p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">two_labels</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="s2">&quot;I love this product&quot;</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">two_labels</span>
</pre></div>
</div>
</section>
<section class="section-block-code-cell-">
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>[&#x7B;&#x27;label&#x27;: &#x27;LABEL_1&#x27;, &#x27;score&#x27;: 0.9979197382926941&#x7D;,
 &#x7B;&#x27;label&#x27;: &#x27;LABEL_0&#x27;, &#x27;score&#x27;: 0.002080311067402363&#x7D;]
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Se você quiser testar mais o modelo, pode vê-lo em <a href="https://huggingface.co/Maximofn/GPT2-small-PEFT-LoRA-finetuned-amazon-reviews-en-classification">Maximofn/GPT2-small-PEFT-LoRA-finetuned-amazon-reviews-en-classification</a></p>
</section>