<p>
	<!-- Custom stylesheet, it must be in the same directory as the html file -->
	<!-- Loading mathjax macro --><!-- Load mathjax --><!-- MathJax configuration -->
<p>
<style>
	/* Media query para pantallas grandes */
	@media screen and (min-width: 1000px) {
		.container {
			flex-wrap: nowrap;
			display: flex;
			justify-content: space-between;
			height: 100vh; /* altura del viewport */
		}
		
		.indice {
			width: 25%; /* Ancho del índice en pantallas grandes */
			border-right: 1px solid #ccc;
			max-height: calc(100vh - 40px); /* Ajustar según tus necesidades. Aquí estamos restando el doble del padding para mantener todo visible */
			padding: 20px;
			box-sizing: border-box;
			overflow-y: auto; /* desplazamiento vertical cuando sea necesario */
		}
		
		.contenido {
			width: 70%; /* Ancho del contenido en pantallas grandes */
			max-height: calc(100vh - 40px); /* Ajustar según tus necesidades. Aquí estamos restando el doble del padding para mantener todo visible */
			padding: 20px;
			box-sizing: border-box;
			overflow-y: auto; /* desplazamiento vertical cuando sea necesario */
		}
	}
</style>
<!-- Open div notebook -->
<div id="notebook" class="border-box-sizing" tabindex="-1">
	<!-- Open div notebook container -->
	<div id="notebook-container" class="container">
		<!-- Open div indice -->
		<div class="indice">
			<!-- Open div index header -->
			<div class="cell border-box-sizing text_cell rendered">
				<h2 class="prompt input_prompt">
					<span style="
					color: var(--darkreader-text--heading-color, var(--darkreader-text--heading-2-color,
					var(--darkreader-text--headings-color)));
					font-family: var(--fontFamily); font-size: var(--fontSize);
					font-style: var(--fontStyle, inherit);
					font-weight: var(--fontWeight);
					letter-spacing: var(--letterSpacing);
					text-transform: var(--textTransform);
					background-color: transparent;
					--darkreader-inline-color: var(--darkreader-text--darkreader-text--heading-color,
					var(--darkreader-text--darkreader-text--heading-2-color, var(--darkreader-text--darkreader-text--headings-color)));
					--darkreader-inline-bgcolor: transparent;"
					data-darkreader-inline-color="" data-darkreader-inline-bgcolor="">
						Índice
					</span>
					<a class="anchor-link" style="
					font-family: var(--fontFamily);
					font-size: var(--fontSize);
					font-style: var(--fontStyle, inherit);
					font-weight: var(--fontWeight);
					letter-spacing: var(--letterSpacing);
					text-transform: var(--textTransform);
					background-color: transparent;
					--darkreader-inline-bgcolor: transparent;"
					href="#Índice" data-darkreader-inline-bgcolor="">
					</a>
				</h2>
			<!-- Close div index header -->
			</div>
			<!-- Index body -->
			<div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Vector-quantization-index">
									<a class="anchor-link" href="#Vector-quantization">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Vector quantization</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Threshold-value-α-index">
									<a class="anchor-link" href="#Threshold-value-α">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Threshold value α</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Use-of-llm.int8()-index">
									<a class="anchor-link" href="#Use-of-llm.int8()">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Use of llm.int8()</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
			</div>
		<!-- Close div indice -->
		</div>
 
		<!-- Content -->
		<div class="contenido">
		<div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><a href="https://colab.research.google.com/github/maximofn/portafolio/blob/main/posts/notebooks_translated/2024-07-23-llm.int8()_EN.ipynb" target="_blank"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h1 id="llm.int8()---8-bit-Matrix-Multiplication-for-Transformers-at-Scale">
								<a class="anchor-link" href="#llm.int8()---8-bit-Matrix-Multiplication-for-Transformers-at-Scale">
									<p style="margin-left: 0px">llm.int8() - 8-bit Matrix Multiplication for Transformers at Scale</p>
								</a>
							</h1>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">This notebook has been automatically translated to make it accessible to more people, please let me know if you see any typos.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">In the post <a href="https://maximofn.com/llms-quantization/" target="_blank">LLMs quantization</a> we explained the importance of quantization of LLMs to save memory. We also explained that there is a way of quantization which is <a href="https://maximofn.com/llms-quantization/#Cuantizaci%C3%B3n-de-punto-cero" target="_blank">zero-point quantization</a> that consists in transforming the parameter values of the weights linearly, but this has the problem of the degradation of the language models from the moment they exceed 2.7B parameters.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="https://maximofn.com/wp-content/uploads/2024/07/llm.int8-degradation.webp" alt="llm.int8()-degradation"></p></p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Vector-quantization">
								<a class="anchor-link" href="#Vector-quantization">
									<p style="margin-left: 10px">Vector quantization</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Since the quantization of all the parameters of the models produces errors in the large language models, what they propose in the paper <a href="https://arxiv.org/abs/2208.07339" target="_blank">llm.int8()</a> is to perform vector quantization, that is, to separate the matrices of the weights into vectors, so that some of these vectors can be quantized in 8 bits, while others cannot. So those that can be quantized in 8 bits are quantized and matrix multiplications are performed in INT8 format, while those vectors that cannot be quantized are kept in FP16 format and multiplications are performed in FP16 format.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Let's see it with an example</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Suppose we have the matrix</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="https://maximofn.com/wp-content/uploads/2024/07/llm.int8-A.webp" alt="llm.int8()-A"></p></p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">and we want to multiply it by the matrix</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="https://maximofn.com/wp-content/uploads/2024/07/llm.int8-B.webp" alt="llm.int8()-B"></p></p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">We set a threshold value and all the columns of the first matrix that have a value greater than that threshold are left in FP16 format, the rows equivalent to the rows of the first matrix, in the second matrix are also left in FP16 format.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Let me explain it more clearly, as the second and fourth columns of the first matrix (yellow columns) have values greater than a certain threshold, then the second and fourth rows of the second matrix (yellow rows) are left in FP16 format.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">In case of having threshold values in the second matrix the same would be done, for example, if in the second matrix a row had a value greater than a threshold, it would be left in FP16 format, and that column in the first matrix would be left in FP16 format.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">The remaining rows and columns that are not left in FP16 format are quantized in 8 bits and multiplications are performed in INT8 format.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">So we separate the first matrix into the two matrices</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="https://maximofn.com/wp-content/uploads/2024/07/llm.int8-A_separated_.webp" alt="llm.int8()-A_separated"></p></p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">And the second matrix in the two matrices</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="https://maximofn.com/wp-content/uploads/2024/07/llm.int8-B_separated_.webp" alt="llm.int8()-B_separated"></p></p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">We multiply the matrices in INT8 on one side</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="https://maximofn.com/wp-content/uploads/2024/07/llm.int8-AxB-int8_.webp" alt="llm.int8()-AxB-int8"></p></p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">and those in FP16 format on the other hand</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="https://maximofn.com/wp-content/uploads/2024/07/llm.int8-AxB-fp16_.webp" alt="llm.int8()-AxB-fp16"></p></p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">As you can see, multiplying the matrices in INT8 format gives us a matrix of size 3x2, and multiplying the matrices in FP16 format gives us another matrix of size 3x2, so if we add them together</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="https://maximofn.com/wp-content/uploads/2024/07/llm.int8-fp16int8_.webp" alt="llm.int8()-fp16+int8"></p></p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Interestingly, it gives us the same result as if we had multiplied the original matrices</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="https://maximofn.com/wp-content/uploads/2024/07/llm.int8-AxB_.webp" alt="llm.int8()-AxB"></p></p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">In order to see why this happens, if we develop the vector product of the two original matrices</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="https://maximofn.com/wp-content/uploads/2024/07/llm.int8-AxB-explained.webp" alt="llm.int8()-AxB-explained"></p></p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">We see that the separation we have made does not cause problems.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Therefore, we can conclude that we can separate rows and columns of matrices to perform matrix multiplications. This separation will be done when any element of the row or column is greater than a threshold value, so that the rows or columns that do not have a value greater than that threshold will be coded in INT8 occupying only one byte and the rows or columns that have an element greater than that threshold will be passed to FP16 occupying 2 bytes. In this way we will not have rounding problems, since the calculations we do in INT8 will be done with values that do not exceed the range of 8 bits.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Threshold-value-α">
								<a class="anchor-link" href="#Threshold-value-α">
									<p style="margin-left: 10px">Threshold value α</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">As we have said we are going to separate into rows and columns that have some element greater than a threshold value, but what threshold value should we choose? The authors of the paper did experiments with several values and determined that this threshold value should be α=6. Above that value they started to get degradations in the language models.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Use-of-llm.int8()">
								<a class="anchor-link" href="#Use-of-llm.int8()">
									<p style="margin-left: 10px">Use of llm.int8()</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Let's see how to quantize a model with llm.int8() with the transformers library. To do this you must have <code><b>bitsandbytes</b></code> installed.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 80px;"><code>pip install bitsandbytes<br></code></p>
						</div>
					</div>
				</div>
			</div>
	
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">We load a 1B parameter model twice, once normally and the second time quantizing it with llm.int8().</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoTokenizer</span></p>
<p><span style="color: #833aa0;">import</span> <span style="color: #4fcd7d;">torch</span></p>
<p></p>
<p><span style="color: #6b97e8;">device</span> <span>=</span> <span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">device</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span> <span style="color: #a04cc1;">if</span> <span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">cuda</span><span>.</span><span style="color: #6b97e8;">is_available</span><span style="color: #e3e11d;">()</span> <span style="color: #a04cc1;">else</span> <span style="color: #7e7a34;">&quot;cpu&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">checkpoint</span> <span>=</span> <span style="color: #7e7a34;">&quot;TinyLlama/TinyLlama-1.1B-Chat-v1.0&quot;</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">device</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">model_8bit</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a34;">&quot;auto&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">load_in_8bit</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Let's see how much memory each model takes up</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">get_memory_footprint</span><span style="color: #e3e11d;">()</span><span>/</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a38;">1024</span><span>**</span><span style="color: #7e7a38;">3</span><span style="color: #e3e11d;">),</span> <span style="color: #6b97e8;">model_8bit</span><span>.</span><span style="color: #6b97e8;">get_memory_footprint</span><span style="color: #e3e11d;">()</span><span>/</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a38;">1024</span><span>**</span><span style="color: #7e7a38;">3</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>(4.098002195358276, 1.1466586589813232)</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">As can be seen, the quantized model occupies much less memory.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Let's now do a text generation test with the two models</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">input_tokens</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;Hello my name is Maximo and I am a Machine Learning Engineer&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">device</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">input_tokens</span><span>.</span><span style="color: #6b97e8;">input_ids</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>tensor([[    1, 15043,   590,  1024,   338,  5918,  4200,   322,   306,   626,</p><p>           263,  6189, 29257, 10863,   261]], device='cuda:0')</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">We see the output with the normal model</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">import</span> <span style="color: #4fcd7d;">time</span></p>
<p></p>
<p><span style="color: #6b97e8;">t0</span> <span>=</span> <span style="color: #6b97e8;">time</span><span>.</span><span style="color: #6b97e8;">time</span><span style="color: #e3e11d;">()</span></p>
<p><span style="color: #6b97e8;">max_new_tokens</span> <span>=</span> <span style="color: #7e7a38;">50</span></p>
<p><span style="color: #6b97e8;">outputs</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span></p>
<p>    <span style="color: #6b97e8;">input_ids</span><span>=</span><span style="color: #6b97e8;">input_tokens</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">attention_mask</span><span>=</span><span style="color: #6b97e8;">input_tokens</span><span>.</span><span style="color: #6b97e8;">attention_mask</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">max_length</span><span>=</span><span style="color: #6b97e8;">input_tokens</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span>.</span><span style="color: #6b97e8;">shape</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">]</span> <span>+</span> <span style="color: #6b97e8;">max_new_tokens</span><span style="color: #e3e11d;">,</span></p>
<p><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">outputs</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">))</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">time</span><span>.</span><span style="color: #6b97e8;">time</span><span style="color: #e3e11d;">()</span> <span>-</span> <span style="color: #6b97e8;">t0</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>Hello my name is Maximo and I am a Machine Learning Engineer. I am currently working at [Company Name] as a Machine Learning Engineer. I have a Bachelor's degree in Computer Science from [University Name] and a Master's degree in Computer Science from [University Name]. I</p><p>1.7616662979125977</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">And now with the quantized model</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">t0</span> <span>=</span> <span style="color: #6b97e8;">time</span><span>.</span><span style="color: #6b97e8;">time</span><span style="color: #e3e11d;">()</span></p>
<p><span style="color: #6b97e8;">max_new_tokens</span> <span>=</span> <span style="color: #7e7a38;">50</span></p>
<p><span style="color: #6b97e8;">outputs</span> <span>=</span> <span style="color: #6b97e8;">model_8bit</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span></p>
<p>    <span style="color: #6b97e8;">input_ids</span><span>=</span><span style="color: #6b97e8;">input_tokens</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">attention_mask</span><span>=</span><span style="color: #6b97e8;">input_tokens</span><span>.</span><span style="color: #6b97e8;">attention_mask</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">max_length</span><span>=</span><span style="color: #6b97e8;">input_tokens</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span>.</span><span style="color: #6b97e8;">shape</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">]</span> <span>+</span> <span style="color: #6b97e8;">max_new_tokens</span><span style="color: #e3e11d;">,</span></p>
<p><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">outputs</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">))</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">time</span><span>.</span><span style="color: #6b97e8;">time</span><span style="color: #e3e11d;">()</span> <span>-</span> <span style="color: #6b97e8;">t0</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>Hello my name is Maximo and I am a Machine Learning Engineer. I am currently working at [Company Name] as a Machine Learning Engineer. I have a Bachelor's degree in Computer Science from [University Name] and a Master's degree in Computer Science from [University Name]. I</p><p>9.100712776184082</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">We see two things, on the one hand we get the same text at the output, so with a much smaller model we can get the same output, however the quantized model takes much longer to run, so if you need to use this model in real time it would not be advisable.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">This is contradictory, because we might think that a smaller model would have to run faster, but we have to think that in reality the two models, the normal and the quantized, perform the same operations, only that one performs all the operations in FP32 and the other does them in INT8 and FP16, however the quantized model has to search for rows and columns with values greater than the threshold value, separate them, perform the operations in INT8 and FP16 and then put the results back together, so the quantized model takes longer to run.</p>
						</div>
					</div>
				</div>
			</div>
		</div>
	<!-- Close class contenido -->
	</div>
<!-- Close div notebook container -->
</div>
<!-- Close div notebook -->
</div>
