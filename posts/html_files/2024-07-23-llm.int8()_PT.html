<p>
	<!-- Custom stylesheet, it must be in the same directory as the html file -->
	<!-- Loading mathjax macro --><!-- Load mathjax --><!-- MathJax configuration -->
<p>
<style>
	/* Media query para pantallas grandes */
	@media screen and (min-width: 1000px) {
		.container {
			flex-wrap: nowrap;
			display: flex;
			justify-content: space-between;
			height: 100vh; /* altura del viewport */
		}
		
		.indice {
			width: 25%; /* Ancho del índice en pantallas grandes */
			border-right: 1px solid #ccc;
			max-height: calc(100vh - 40px); /* Ajustar según tus necesidades. Aquí estamos restando el doble del padding para mantener todo visible */
			padding: 20px;
			box-sizing: border-box;
			overflow-y: auto; /* desplazamiento vertical cuando sea necesario */
		}
		
		.contenido {
			width: 70%; /* Ancho del contenido en pantallas grandes */
			max-height: calc(100vh - 40px); /* Ajustar según tus necesidades. Aquí estamos restando el doble del padding para mantener todo visible */
			padding: 20px;
			box-sizing: border-box;
			overflow-y: auto; /* desplazamiento vertical cuando sea necesario */
		}
	}
</style>
<!-- Open div notebook -->
<div id="notebook" class="border-box-sizing" tabindex="-1">
	<!-- Open div notebook container -->
	<div id="notebook-container" class="container">
		<!-- Open div indice -->
		<div class="indice">
			<!-- Open div index header -->
			<div class="cell border-box-sizing text_cell rendered">
				<h2 class="prompt input_prompt">
					<span style="
					color: var(--darkreader-text--heading-color, var(--darkreader-text--heading-2-color,
					var(--darkreader-text--headings-color)));
					font-family: var(--fontFamily); font-size: var(--fontSize);
					font-style: var(--fontStyle, inherit);
					font-weight: var(--fontWeight);
					letter-spacing: var(--letterSpacing);
					text-transform: var(--textTransform);
					background-color: transparent;
					--darkreader-inline-color: var(--darkreader-text--darkreader-text--heading-color,
					var(--darkreader-text--darkreader-text--heading-2-color, var(--darkreader-text--darkreader-text--headings-color)));
					--darkreader-inline-bgcolor: transparent;"
					data-darkreader-inline-color="" data-darkreader-inline-bgcolor="">
						Índice
					</span>
					<a class="anchor-link" style="
					font-family: var(--fontFamily);
					font-size: var(--fontSize);
					font-style: var(--fontStyle, inherit);
					font-weight: var(--fontWeight);
					letter-spacing: var(--letterSpacing);
					text-transform: var(--textTransform);
					background-color: transparent;
					--darkreader-inline-bgcolor: transparent;"
					href="#Índice" data-darkreader-inline-bgcolor="">
					</a>
				</h2>
			<!-- Close div index header -->
			</div>
			<!-- Index body -->
			<div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Quantização-de-vetores-index">
									<a class="anchor-link" href="#Quantização-de-vetores">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Quantização de vetores</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Valor-limiar-α-index">
									<a class="anchor-link" href="#Valor-limiar-α">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Valor limiar α</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Uso-de-llm.int8()-index">
									<a class="anchor-link" href="#Uso-de-llm.int8()">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Uso de llm.int8()</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
			</div>
		<!-- Close div indice -->
		</div>
 
		<!-- Content -->
		<div class="contenido">
		<div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><a href="https://colab.research.google.com/github/maximofn/portafolio/blob/main/posts/notebooks_translated/2024-07-23-llm.int8()_PT.ipynb" target="_blank"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h1 id="llm.int8()---8-bit-Matrix-Multiplication-for-Transformers-at-Scale">
								<a class="anchor-link" href="#llm.int8()---8-bit-Matrix-Multiplication-for-Transformers-at-Scale">
									<p style="margin-left: 0px">llm.int8() - 8-bit Matrix Multiplication for Transformers at Scale</p>
								</a>
							</h1>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Este caderno foi traduzido automaticamente para torná-lo acessível a mais pessoas, por favor me avise se você vir algum erro de digitação..</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Na postagem <a href="https://maximofn.com/llms-quantization/" target="_blank">LLMs quantization</a>, explicamos a importância da quantização dos LLMs para economizar memória. Também explicamos que há uma forma de quantização que é a <a href="https://maximofn.com/llms-quantization/#Cuantizaci%C3%B3n-de-punto-cero" target="_blank">quantização de ponto zero</a>, que consiste em transformar os valores dos parâmetros dos pesos linearmente, mas isso tem o problema da degradação dos modelos de linguagem a partir do momento em que eles ultrapassam 2,7 bilhões de parâmetros.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/llm.int8-degradation.webp" alt="llm.int8()-degradação"></p></p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Quantização-de-vetores">
								<a class="anchor-link" href="#Quantização-de-vetores">
									<p style="margin-left: 10px">Quantização de vetores</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Como a quantização de todos os parâmetros dos modelos produz erros nos modelos de idiomas grandes, o que eles propõem no artigo <a href="https://arxiv.org/abs/2208.07339" target="_blank">llm.int8()</a> é realizar a quantização de vetores, ou seja, separar as matrizes dos pesos em vetores, de modo que alguns desses vetores possam ser quantizados em 8 bits, enquanto outros não. Assim, aqueles que podem ser quantizados em 8 bits são quantizados e as multiplicações de matriz são realizadas no formato INT8, enquanto os vetores que não podem ser quantizados são mantidos no formato FP16 e as multiplicações são realizadas no formato FP16.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vamos dar uma olhada em um exemplo</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Suponha que tenhamos a matriz</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/llm.int8-A.webp" alt="llm.int8()-A"></p></p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">e queremos multiplicá-lo pela matriz</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/llm.int8-B.webp" alt="llm.int8()-B"></p></p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Definimos um valor limite e todas as colunas da primeira matriz que têm um valor maior do que esse limite são deixadas no formato FP16; as linhas equivalentes às linhas da primeira matriz na segunda matriz também são deixadas no formato FP16.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Explicando melhor, como a segunda e a quarta colunas da primeira matriz (colunas amarelas) têm valores maiores que um determinado limite, a segunda e a quarta linhas da segunda matriz (linhas amarelas) são deixadas no formato FP16.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">No caso de haver valores limiares na segunda matriz, o mesmo seria feito, por exemplo, se na segunda matriz uma linha tivesse um valor maior que um limiar, ela seria deixada no formato FP16, e essa coluna na primeira matriz seria deixada no formato FP16.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">As linhas e colunas restantes que não são deixadas no formato FP16 são quantizadas em 8 bits e as multiplicações são realizadas no formato INT8.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Portanto, dividimos a primeira matriz em duas matrizes</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/llm.int8-A_separated_.webp" alt="llm.int8()-A_separated"></p></p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">E a segunda matriz nas duas matrizes</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/llm.int8-B_separated_.webp" alt="llm.int8()-B_separated"></p></p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Multiplicamos as matrizes em INT8 em um lado</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/llm.int8-AxB-int8_.webp" alt="llm.int8()-AxB-int8"></p></p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">e aqueles no formato FP16, por outro lado</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/llm.int8-AxB-fp16_.webp" alt="llm.int8()-AxB-fp16"></p></p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Como pode ser visto, a multiplicação das matrizes no formato INT8 nos dá uma matriz de tamanho 3x2, e a multiplicação das matrizes no formato FP16 nos dá outra matriz de tamanho 3x2, de modo que, se as somarmos</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/llm.int8-fp16int8_.webp" alt="llm.int8()-fp16+int8"></p></p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">É interessante notar que ele apresenta o mesmo resultado como se tivéssemos multiplicado as matrizes originais.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/llm.int8-AxB_.webp" alt="llm.int8()-AxB"></p></p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Para ver por que isso acontece, se desenvolvermos o produto vetorial das duas matrizes originais</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/llm.int8-AxB-explained.webp" alt="llm.int8()-AxB-explained"></p></p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vemos que a separação que fizemos não traz problemas.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Portanto, podemos concluir que é possível separar linhas e colunas de matrizes para realizar multiplicações de matrizes. Essa separação será feita quando qualquer elemento da linha ou coluna for maior que um valor limite, de modo que as linhas ou colunas que não tiverem um valor maior que esse limite serão codificadas em INT8, ocupando apenas um byte, e as linhas ou colunas que tiverem um elemento maior que esse limite serão passadas para FP16, ocupando 2 bytes. Dessa forma, não teremos problemas de arredondamento, pois os cálculos que fizermos em INT8 serão feitos com valores que não ultrapassem o intervalo de 8 bits.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Valor-limiar-α">
								<a class="anchor-link" href="#Valor-limiar-α">
									<p style="margin-left: 10px">Valor limiar α</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Como dissemos, vamos separar em linhas e colunas que tenham algum elemento maior que um valor limite, mas qual valor limite devemos escolher? Os autores do artigo fizeram experimentos com vários valores e determinaram que o valor limite deveria ser α=6. Acima desse valor, eles começaram a obter degradações nos modelos de linguagem.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Uso-de-llm.int8()">
								<a class="anchor-link" href="#Uso-de-llm.int8()">
									<p style="margin-left: 10px">Uso de llm.int8()</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vamos ver como quantificar um modelo com llm.int8() com a biblioteca de transformadores. Para fazer isso, você precisa ter o <code><b>bitsandbytes</b></code> instalado.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 80px;"><code>pip install bitsandbytes<br></code></p>
						</div>
					</div>
				</div>
			</div>
	
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Carregamos um modelo de parâmetro 1B duas vezes, uma vez da maneira normal e a segunda vez quantificando-o com llm.int8().</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoTokenizer</span></p>
<p><span style="color: #833aa0;">import</span> <span style="color: #4fcd7d;">torch</span></p>
<p></p>
<p><span style="color: #6b97e8;">device</span> <span>=</span> <span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">device</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span> <span style="color: #a04cc1;">if</span> <span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">cuda</span><span>.</span><span style="color: #6b97e8;">is_available</span><span style="color: #e3e11d;">()</span> <span style="color: #a04cc1;">else</span> <span style="color: #7e7a34;">&quot;cpu&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">checkpoint</span> <span>=</span> <span style="color: #7e7a34;">&quot;TinyLlama/TinyLlama-1.1B-Chat-v1.0&quot;</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">device</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">model_8bit</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a34;">&quot;auto&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">load_in_8bit</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vemos a quantidade de memória que cada um dos modelos ocupa</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">get_memory_footprint</span><span style="color: #e3e11d;">()</span><span>/</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a38;">1024</span><span>**</span><span style="color: #7e7a38;">3</span><span style="color: #e3e11d;">),</span> <span style="color: #6b97e8;">model_8bit</span><span>.</span><span style="color: #6b97e8;">get_memory_footprint</span><span style="color: #e3e11d;">()</span><span>/</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a38;">1024</span><span>**</span><span style="color: #7e7a38;">3</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>(4.098002195358276, 1.1466586589813232)</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Como pode ser visto, o modelo quantizado ocupa muito menos memória.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vamos agora fazer um teste de geração de texto com os dois modelos.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">input_tokens</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;Hello my name is Maximo and I am a Machine Learning Engineer&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">device</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">input_tokens</span><span>.</span><span style="color: #6b97e8;">input_ids</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>tensor([[    1, 15043,   590,  1024,   338,  5918,  4200,   322,   306,   626,</p><p>           263,  6189, 29257, 10863,   261]], device='cuda:0')</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vemos o resultado com o modelo normal</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">import</span> <span style="color: #4fcd7d;">time</span></p>
<p></p>
<p><span style="color: #6b97e8;">t0</span> <span>=</span> <span style="color: #6b97e8;">time</span><span>.</span><span style="color: #6b97e8;">time</span><span style="color: #e3e11d;">()</span></p>
<p><span style="color: #6b97e8;">max_new_tokens</span> <span>=</span> <span style="color: #7e7a38;">50</span></p>
<p><span style="color: #6b97e8;">outputs</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span></p>
<p>    <span style="color: #6b97e8;">input_ids</span><span>=</span><span style="color: #6b97e8;">input_tokens</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">attention_mask</span><span>=</span><span style="color: #6b97e8;">input_tokens</span><span>.</span><span style="color: #6b97e8;">attention_mask</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">max_length</span><span>=</span><span style="color: #6b97e8;">input_tokens</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span>.</span><span style="color: #6b97e8;">shape</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">]</span> <span>+</span> <span style="color: #6b97e8;">max_new_tokens</span><span style="color: #e3e11d;">,</span></p>
<p><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">outputs</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">))</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">time</span><span>.</span><span style="color: #6b97e8;">time</span><span style="color: #e3e11d;">()</span> <span>-</span> <span style="color: #6b97e8;">t0</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>Hello my name is Maximo and I am a Machine Learning Engineer. I am currently working at [Company Name] as a Machine Learning Engineer. I have a Bachelor's degree in Computer Science from [University Name] and a Master's degree in Computer Science from [University Name]. I</p><p>1.7616662979125977</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">E agora com o modelo quantizado</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">t0</span> <span>=</span> <span style="color: #6b97e8;">time</span><span>.</span><span style="color: #6b97e8;">time</span><span style="color: #e3e11d;">()</span></p>
<p><span style="color: #6b97e8;">max_new_tokens</span> <span>=</span> <span style="color: #7e7a38;">50</span></p>
<p><span style="color: #6b97e8;">outputs</span> <span>=</span> <span style="color: #6b97e8;">model_8bit</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span></p>
<p>    <span style="color: #6b97e8;">input_ids</span><span>=</span><span style="color: #6b97e8;">input_tokens</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">attention_mask</span><span>=</span><span style="color: #6b97e8;">input_tokens</span><span>.</span><span style="color: #6b97e8;">attention_mask</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">max_length</span><span>=</span><span style="color: #6b97e8;">input_tokens</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span>.</span><span style="color: #6b97e8;">shape</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">]</span> <span>+</span> <span style="color: #6b97e8;">max_new_tokens</span><span style="color: #e3e11d;">,</span></p>
<p><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">outputs</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">))</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">time</span><span>.</span><span style="color: #6b97e8;">time</span><span style="color: #e3e11d;">()</span> <span>-</span> <span style="color: #6b97e8;">t0</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>Hello my name is Maximo and I am a Machine Learning Engineer. I am currently working at [Company Name] as a Machine Learning Engineer. I have a Bachelor's degree in Computer Science from [University Name] and a Master's degree in Computer Science from [University Name]. I</p><p>9.100712776184082</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vemos duas coisas: por um lado, obtemos o mesmo texto na saída, portanto, com um modelo muito menor, podemos obter a mesma saída; no entanto, o modelo quantizado leva muito mais tempo para ser executado, portanto, se você precisar usar esse modelo em tempo real, isso não seria aconselhável.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Isso é contraditório, porque poderíamos pensar que um modelo menor teria que ser executado mais rapidamente, mas temos que pensar que, na realidade, os dois modelos, o normal e o quantizado, executam as mesmas operações, apenas um executa todas as operações em FP32 e o outro as executa em INT8 e FP16, mas o modelo quantizado tem que procurar linhas e colunas com valores maiores que o valor limite, separá-las, executar as operações em INT8 e FP16 e, em seguida, juntar os resultados novamente, de modo que o modelo quantizado leva mais tempo para ser executado.</p>
						</div>
					</div>
				</div>
			</div>
		</div>
	<!-- Close class contenido -->
	</div>
<!-- Close div notebook container -->
</div>
<!-- Close div notebook -->
</div>
