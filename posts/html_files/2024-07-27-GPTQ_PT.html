<p>
	<!-- Custom stylesheet, it must be in the same directory as the html file -->
	<!-- Loading mathjax macro --><!-- Load mathjax --><!-- MathJax configuration -->
<p>
<style>
	/* Media query para pantallas grandes */
	@media screen and (min-width: 1000px) {
		.container {
			flex-wrap: nowrap;
			display: flex;
			justify-content: space-between;
			height: 100vh; /* altura del viewport */
		}
		
		.indice {
			width: 25%; /* Ancho del índice en pantallas grandes */
			border-right: 1px solid #ccc;
			max-height: calc(100vh - 40px); /* Ajustar según tus necesidades. Aquí estamos restando el doble del padding para mantener todo visible */
			padding: 20px;
			box-sizing: border-box;
			overflow-y: auto; /* desplazamiento vertical cuando sea necesario */
		}
		
		.contenido {
			width: 70%; /* Ancho del contenido en pantallas grandes */
			max-height: calc(100vh - 40px); /* Ajustar según tus necesidades. Aquí estamos restando el doble del padding para mantener todo visible */
			padding: 20px;
			box-sizing: border-box;
			overflow-y: auto; /* desplazamiento vertical cuando sea necesario */
		}
	}
</style>
<!-- Open div notebook -->
<div id="notebook" class="border-box-sizing" tabindex="-1">
	<!-- Open div notebook container -->
	<div id="notebook-container" class="container">
		<!-- Open div indice -->
		<div class="indice">
			<!-- Open div index header -->
			<div class="cell border-box-sizing text_cell rendered">
				<h2 class="prompt input_prompt">
					<span style="
					color: var(--darkreader-text--heading-color, var(--darkreader-text--heading-2-color,
					var(--darkreader-text--headings-color)));
					font-family: var(--fontFamily); font-size: var(--fontSize);
					font-style: var(--fontStyle, inherit);
					font-weight: var(--fontWeight);
					letter-spacing: var(--letterSpacing);
					text-transform: var(--textTransform);
					background-color: transparent;
					--darkreader-inline-color: var(--darkreader-text--darkreader-text--heading-color,
					var(--darkreader-text--darkreader-text--heading-2-color, var(--darkreader-text--darkreader-text--headings-color)));
					--darkreader-inline-bgcolor: transparent;"
					data-darkreader-inline-color="" data-darkreader-inline-bgcolor="">
						Índice
					</span>
					<a class="anchor-link" style="
					font-family: var(--fontFamily);
					font-size: var(--fontSize);
					font-style: var(--fontStyle, inherit);
					font-weight: var(--fontWeight);
					letter-spacing: var(--letterSpacing);
					text-transform: var(--textTransform);
					background-color: transparent;
					--darkreader-inline-bgcolor: transparent;"
					href="#Índice" data-darkreader-inline-bgcolor="">
					</a>
				</h2>
			<!-- Close div index header -->
			</div>
			<!-- Index body -->
			<div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Quantificação-em-camadas-index">
									<a class="anchor-link" href="#Quantificação-em-camadas">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Quantificação em camadas</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Quantização-ideal-do-cérebro-(OBQ)-index">
									<a class="anchor-link" href="#Quantização-ideal-do-cérebro-(OBQ)">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Quantização ideal do cérebro (OBQ)</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Algoritmo-GPTQ-index">
									<a class="anchor-link" href="#Algoritmo-GPTQ">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Algoritmo GPTQ</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Etapa-1:-informações-arbitrárias-do-pedido-index">
									<a class="anchor-link" href="#Etapa-1:-informações-arbitrárias-do-pedido">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Etapa 1: informações arbitrárias do pedido</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Etapa-2:-atualizações-em-lote-preguiçosas-index">
									<a class="anchor-link" href="#Etapa-2:-atualizações-em-lote-preguiçosas">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Etapa 2: atualizações em lote preguiçosas</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Etapa-3:-Reformulação-de-Cholesky-index">
									<a class="anchor-link" href="#Etapa-3:-Reformulação-de-Cholesky">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Etapa 3: Reformulação de Cholesky</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Resultados-do-GPTQ-index">
									<a class="anchor-link" href="#Resultados-do-GPTQ">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Resultados do GPTQ</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Quantificação-extrema-index">
									<a class="anchor-link" href="#Quantificação-extrema">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Quantificação extrema</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Desconto-dinâmico-na-inferência-index">
									<a class="anchor-link" href="#Desconto-dinâmico-na-inferência">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Desconto dinâmico na inferência</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Velocidade-de-inferência-index">
									<a class="anchor-link" href="#Velocidade-de-inferência">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Velocidade de inferência</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Livrarias-index">
									<a class="anchor-link" href="#Livrarias">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Livrarias</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Quantização-de-um-modelo-index">
									<a class="anchor-link" href="#Quantização-de-um-modelo">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Quantização de um modelo</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Inferência-de-modelo-não-quantificada-index">
									<a class="anchor-link" href="#Inferência-de-modelo-não-quantificada">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Inferência de modelo não quantificada</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Quantização-do-modelo-para-4-bits-index">
									<a class="anchor-link" href="#Quantização-do-modelo-para-4-bits">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Quantização do modelo para 4 bits</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Quantização-do-modelo-para-3-bits-index">
									<a class="anchor-link" href="#Quantização-do-modelo-para-3-bits">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Quantização do modelo para 3 bits</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Quantização-do-modelo-para-2-bits-index">
									<a class="anchor-link" href="#Quantização-do-modelo-para-2-bits">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Quantização do modelo para 2 bits</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h3 id="Quantização-do-modelo-para-1-bit-index">
									<a class="anchor-link" href="#Quantização-do-modelo-para-1-bit">
										<p style="margin-left: 40px; font-size: 12px; line-height: 1.5;">Quantização do modelo para 1 bit</p>
									</a>
								</h3>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Resumo-da-quantificação-index">
									<a class="anchor-link" href="#Resumo-da-quantificação">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Resumo da quantificação</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Carregamento-do-modelo-salvo-index">
									<a class="anchor-link" href="#Carregamento-do-modelo-salvo">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Carregamento do modelo salvo</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Carregando-o-modelo-carregado-para-o-hub-index">
									<a class="anchor-link" href="#Carregando-o-modelo-carregado-para-o-hub">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Carregando o modelo carregado para o hub</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
			</div>
		<!-- Close div indice -->
		</div>
 
		<!-- Content -->
		<div class="contenido">
		<div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><a href="https://colab.research.google.com/github/maximofn/portafolio/blob/main/posts/notebooks_translated/2024-07-27-GPTQ_PT.ipynb" target="_blank"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h1 id="GPTQ:-Quantização-pós-treinamento-precisa-para-transformadores-pré-treinados-generativos">
								<a class="anchor-link" href="#GPTQ:-Quantização-pós-treinamento-precisa-para-transformadores-pré-treinados-generativos">
									<p style="margin-left: 0px">GPTQ: Quantização pós-treinamento precisa para transformadores pré-treinados generativos</p>
								</a>
							</h1>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">No artigo <a href="https://arxiv.org/abs/2210.17323" target="_blank">GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers</a>, é exposta a necessidade de criar um método de quantização pós-treinamento que não prejudique a qualidade do modelo. Nesta postagem, vimos o método <a href="https://maximofn.com/llm-int8/" target="_blank">llm.int8()</a> que quantiza para INT8 alguns vetores das matrizes de peso, desde que nenhum de seus valores exceda um valor limite, o que é bom, mas eles não quantizam todos os pesos do modelo. Neste artigo, eles propõem um método que quantiza todos os pesos do modelo para 4 e 3 bits, sem degradar a qualidade do modelo. Isso economiza bastante memória, não só porque todos os pesos são quantizados, mas também porque isso é feito em 4, 3 bits (e até mesmo 1 e 2 bits sob certas condições), em vez de 8 bits.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Este caderno foi traduzido automaticamente para torná-lo acessível a mais pessoas, por favor me avise se você vir algum erro de digitação..</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">## Trabalhos nos quais se baseia</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h3 id="Quantificação-em-camadas">
								<a class="anchor-link" href="#Quantificação-em-camadas">
									<p style="margin-left: 20px">Quantificação em camadas</p>
								</a>
							</h3>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Por um lado, eles se baseiam nos trabalhos <code><b>Nagel et al., 2020</b></code>; <code><b>Wang et al., 2020</b></code>; <code><b>Hubara et al., 2021</b></code> e <code><b>Frantar et al., 2022</b></code>, que propõem quantizar os pesos das camadas de uma rede neural para 4 e 3 bits, sem degradar a qualidade do modelo.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Dado um conjunto de dados <code><b>m</b></code> de um conjunto de dados, cada camada <code><b>l</b></code> é alimentada com os dados e a saída dos pesos <code><b>W</b></code> dessa camada é obtida. Portanto, o que você faz é procurar novos pesos quantizados <code><b>Ŵ</b></code> que minimizem o erro quadrático em relação à saída da camada de precisão total.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><code><b>argmin_Ŵ||WX- ŴX||^2</b></code>.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Os valores de <code><b>Ŵ</b></code> são definidos antes da execução do processo de quantização e, durante o processo, cada parâmetro de <code><b>Ŵ</b></code> pode mudar de valor independentemente, sem depender do valor dos outros parâmetros de <code><b>Ŵ</b></code>.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h3 id="Quantização-ideal-do-cérebro-(OBQ)">
								<a class="anchor-link" href="#Quantização-ideal-do-cérebro-(OBQ)">
									<p style="margin-left: 20px">Quantização ideal do cérebro (OBQ)</p>
								</a>
							</h3>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">No trabalho <code><b>OBQ</b></code> de <code><b>Frantar et al., 2022</b></code>, eles otimizam o processo de quantização em camadas acima, tornando-o até três vezes mais rápido. Isso ajuda com modelos grandes, pois a quantização de um modelo grande pode levar muito tempo.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">O método <code><b>OBQ</b></code> é uma abordagem para resolver o problema de quantização em camadas em modelos de linguagem. O <code><b>OBQ</b></code> parte da ideia de que o erro quadrático pode ser decomposto na soma de erros individuais para cada linha da matriz de peso. O método quantifica cada peso de forma independente, sempre atualizando os pesos não quantificados para compensar o erro incorrido pela quantização.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">O método é capaz de quantificar modelos de tamanho médio em tempos razoáveis, mas, como é um algoritmo de complexidade cúbica, é extremamente caro para ser aplicado a modelos com bilhões de parâmetros.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Algoritmo-GPTQ">
								<a class="anchor-link" href="#Algoritmo-GPTQ">
									<p style="margin-left: 10px">Algoritmo GPTQ</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h3 id="Etapa-1:-informações-arbitrárias-do-pedido">
								<a class="anchor-link" href="#Etapa-1:-informações-arbitrárias-do-pedido">
									<p style="margin-left: 20px">Etapa 1: informações arbitrárias do pedido</p>
								</a>
							</h3>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">No <code><b>OBQ</b></code>, eles procuraram a linha de pesos que criava o menor erro quadrático médio para quantificar, mas perceberam que fazer isso aleatoriamente não aumentava muito o erro quadrático médio final. Assim, em vez de procurar a linha que minimizasse o erro quadrático médio, o que criava uma complexidade cúbica no algoritmo, isso é feito sempre na mesma ordem. Isso reduz bastante o tempo de execução do algoritmo de quantização.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h3 id="Etapa-2:-atualizações-em-lote-preguiçosas">
								<a class="anchor-link" href="#Etapa-2:-atualizações-em-lote-preguiçosas">
									<p style="margin-left: 20px">Etapa 2: atualizações em lote preguiçosas</p>
								</a>
							</h3>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Como a atualização dos pesos é feita linha por linha, isso torna o processo lento e não utiliza totalmente o hardware. Portanto, eles propõem executar as atualizações em lotes de <code><b>B=128</b></code> linhas. Isso faz melhor uso do hardware e reduz o tempo de execução do algoritmo.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h3 id="Etapa-3:-Reformulação-de-Cholesky">
								<a class="anchor-link" href="#Etapa-3:-Reformulação-de-Cholesky">
									<p style="margin-left: 20px">Etapa 3: Reformulação de Cholesky</p>
								</a>
							</h3>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">O problema com as atualizações em lote é que, devido à grande escala dos modelos, podem ocorrer erros numéricos que afetam a precisão do algoritmo. Em particular, matrizes indefinidas podem ser obtidas, fazendo com que o algoritmo atualize os pesos restantes nas direções erradas, resultando em uma quantização muito ruim.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Para resolver isso, os autores do artigo propõem o uso de uma reformulação Cholesky, que é um método numericamente mais estável.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Resultados-do-GPTQ">
								<a class="anchor-link" href="#Resultados-do-GPTQ">
									<p style="margin-left: 10px">Resultados do GPTQ</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Abaixo estão dois gráficos com a medida de perplexidade no conjunto de dados <code><b>WikiText2</b></code> para todos os tamanhos dos modelos OPT e BLOOM. É possível observar que, com a técnica de quantização RTN, a perplexidade em alguns tamanhos aumenta muito, enquanto com o GPTQ ela permanece semelhante à obtida com o modelo FP16.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="https://maximofn.com/wp-content/uploads/2024/07/GPTQ-figure1.webp" alt="GPTQ-figure1"></p></p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Outros gráficos são mostrados abaixo, mas com a medida de precisão no conjunto de dados <code><b>LAMBADA</b></code>. É a mesma coisa, enquanto o GPTQ permanece semelhante ao obtido com o FP16, outros métodos de quantização degradam muito a qualidade do modelo.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="https://maximofn.com/wp-content/uploads/2024/07/GPTQ-figure3.webp" alt="GPTQ-figure3"></p></p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Quantificação-extrema">
								<a class="anchor-link" href="#Quantificação-extrema">
									<p style="margin-left: 10px">Quantificação extrema</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Os gráficos anteriores mostraram os resultados da quantização do modelo em 3 e 4 bits, mas podemos quantizá-los em 2 bits ou até mesmo em 1 bit.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Modificando o tamanho dos lotes ao usar o algoritmo, podemos obter bons resultados quantificando tanto o modelo quanto os lotes.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<table>
								<tr>
									<th>Modelo </th>
									<th> FP16 </th>
									<th> g128 </th>
									<th> g64 </th>
									<th> g32 </th>
									<th> 3 bits</th>
								</tr>
								<tr>
									<td>OPT-175B </td>
									<td> 8,34 </td>
									<td> 9,58 </td>
									<td> 9,18 </td>
									<td> 8,94 </td>
									<td> 8,68</td>
								</tr>
								<tr>
									<td>BLOOM </td>
									<td> 8,11 </td>
									<td> 9,55 </td>
									<td> 9,17 </td>
									<td> 8,83 </td>
									<td> 8,64</td>
								</tr>
							</table>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Na tabela acima, você pode ver o resultado da perplexidade no conjunto de dados <code><b>WikiText2</b></code> para os modelos <code><b>OPT-175B</b></code> e <code><b>BLOOM</b></code> quantizados em 3 bits. É possível observar que, à medida que lotes menores são usados, a perplexidade diminui, o que significa que a qualidade do modelo quantizado é melhor. Mas o problema é que o algoritmo leva mais tempo para ser executado.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Desconto-dinâmico-na-inferência">
								<a class="anchor-link" href="#Desconto-dinâmico-na-inferência">
									<p style="margin-left: 10px">Desconto dinâmico na inferência</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Durante a inferência, algo chamado "dequantização dinâmica" é executado para realizar a inferência. Cada camada é dequantificada à medida que passa por ela.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Para fazer isso, eles desenvolveram um kernel que desquantifica as matrizes e executa produtos de matrizes. Embora a descompactação seja mais intensiva em termos de computação, o kernel precisa acessar muito menos memória, o que resulta em um aumento significativo da velocidade.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">A inferência é realizada no FP16, descontando os pesos à medida que você passa pelas camadas, e a função de ativação de cada camada também é realizada no FP16. Embora isso signifique que mais cálculos tenham de ser feitos, porque os pesos têm de ser descontados, esses cálculos tornam o processo geral mais rápido, porque menos dados têm de ser buscados na memória. Os pesos precisam ser obtidos da memória em menos bits, portanto, no final, em matrizes com muitos parâmetros, isso economiza muitos dados. O gargalo geralmente está na obtenção dos dados da memória, portanto, mesmo que você tenha que fazer mais cálculos, no final a inferência é mais rápida.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Velocidade-de-inferência">
								<a class="anchor-link" href="#Velocidade-de-inferência">
									<p style="margin-left: 10px">Velocidade de inferência</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Os autores do artigo testaram a quantização do modelo BLOOM-175B para 3 bits, o que ocupou cerca de 63 GB de memória VRAM, incluindo embeddings e a camada de saída que são mantidos em FP16. Além disso, a manutenção da janela de contexto de 2048 tokens consome cerca de 9 GB de memória, em um total de cerca de 72 GB de memória VRAM. Eles quantizaram em 3 bits e não em 4 bits para poder realizar esse experimento e ajustar o modelo em uma única GPU Nvidia A100 com 80 GB de memória VRAM.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Para fins de comparação, a inferência FP16 normal requer cerca de 350 GB de VRAM, o que equivale a 5 GPUs Nvidia A100 com 80 GB de VRAM. E a inferência quantizada de 8 bits usando <a href="https://maximofn.com/llm-int8/" target="_blank">llm.int8()</a> requer 3 dessas GPUs.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Abaixo está uma tabela com inferência de modelo em FP16 e 3 bits quantizados em GPUs Nvidia A100 com 80 GB de VRAM e GPUs Nvidia A6000 com 48 GB de VRAM.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<table>
								<tr>
									<th>GPU (VRAM)</th>
									<th>Tempo médio por token em FP16 (ms) </th>
									<th> Tempo médio por token em 3 bits (ms) </th>
									<th> Aceleração </th>
									<th> Redução das GPUs necessárias </th>
								</tr>
								<tr>
									<td>A6000 (48GB) </td>
									<td> 589 </td>
									<td> 130 </td>
									<td> ×4.53 </td>
									<td> 8→ 2</td>
								</tr>
								<tr>
									<td>A100 (80GB) </td>
									<td> 230 </td>
									<td> 71 </td>
									<td> ×3.24 </td>
									<td> 5→ 1</td>
								</tr>
							</table>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Por exemplo, usando os kernels, o modelo OPT-175B de 3 bits é executado em um único A100 (em vez de 5) e é aproximadamente 3,25 vezes mais rápido do que a versão FP16 em termos de tempo médio por token.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">A GPU NVIDIA A6000 tem uma largura de banda de memória muito menor, o que torna essa estratégia ainda mais eficaz: a execução do modelo OPT-175B de 3 bits em 2 GPUs A6000 (em vez de 8) é aproximadamente 4,53 vezes mais rápida do que a versão FP16.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Livrarias">
								<a class="anchor-link" href="#Livrarias">
									<p style="margin-left: 10px">Livrarias</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Os autores do artigo implementaram a biblioteca <a href="https://github.com/IST-DASLab/gptq" target="_blank">GPTQ</a>. Outras bibliotecas foram criadas, como <a href="https://github.com/qwopqwop200/GPTQ-for-LLaMa" target="_blank">GPTQ-for-LLaMa</a>, <a href="https://github.com/turboderp/exllama" target="_blank">exllama</a> e <a href="https://github.com/ggerganov/llama.cpp/" target="_blank">llama.cpp</a>. No entanto, essas bibliotecas se concentram apenas na arquitetura llama, de modo que a biblioteca <a href="https://github.com/AutoGPTQ/AutoGPTQ" target="_blank">AutoGPTQ</a> ganhou mais popularidade porque tem uma cobertura mais ampla de arquiteturas.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Por esse motivo, essa biblioteca <a href="https://github.com/AutoGPTQ/AutoGPTQ" target="_blank">AutoGPTQ</a> foi integrada por meio de uma API na biblioteca <a href="https://maximofn.com/hugging-face-transformers/" target="_blank">transformers</a>. Para usá-la, é necessário instalá-la conforme indicado na seção <a href="https://github.com/AutoGPTQ/AutoGPTQ#installation" target="_blank">Installation</a> de seu repositório e ter a biblioteca <a href="https://maximofn.com/hugging-face-optimun/" target="_blank">optimun</a> instalada.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Além da seção <a href="https://github.com/AutoGPTQ/AutoGPTQ#installation" target="_blank">Installation</a> do seu repositório, você também deve fazer o seguinte:</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 80px;"><code>git clone https://github.com/PanQiWei/AutoGPTQ<br>cd AutoGPTQ<br>pip install .<br></code></p>
						</div>
					</div>
				</div>
			</div>
	
	
	
	
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Para que os kernels de quantização da GPU desenvolvidos pelos autores do artigo sejam instalados.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Quantização-de-um-modelo">
								<a class="anchor-link" href="#Quantização-de-um-modelo">
									<p style="margin-left: 10px">Quantização de um modelo</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vamos ver como quantificar um modelo com a biblioteca <a href="https://maximofn.com/hugging-face-optimun/" target="_blank">optimun</a> e a API <a href="https://github.com/AutoGPTQ/AutoGPTQ" target="_blank">AutoGPTQ</a>.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h3 id="Inferência-de-modelo-não-quantificada">
								<a class="anchor-link" href="#Inferência-de-modelo-não-quantificada">
									<p style="margin-left: 20px">Inferência de modelo não quantificada</p>
								</a>
							</h3>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vamos quantificar o modelo <a href="https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct" target="_blank">meta-call/Meta-Call-3-8B-Instruct</a> que, como o nome indica, é um modelo de 8B parâmetros, portanto, no FP16, precisaríamos de 16 GB de memória VRAM. Primeiro, executamos o modelo para ver quanta memória ele ocupa e a saída que ele gera</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Como para usar esse modelo temos que pedir permissão ao Meta, entramos no HuggingFace para baixar o tokenizador e o modelo.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">huggingface_hub</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">notebook_login</span></p>
<p></p>
<p><span style="color: #6b97e8;">notebook_login</span><span style="color: #e3e11d;">()</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Instanciamos o tokenizador e o modelo</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoTokenizer</span></p>
<p><span style="color: #833aa0;">import</span> <span style="color: #4fcd7d;">torch</span></p>
<p></p>
<p><span style="color: #6b97e8;">device</span> <span>=</span> <span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">device</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;cuda&quot;</span> <span style="color: #a04cc1;">if</span> <span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">cuda</span><span>.</span><span style="color: #6b97e8;">is_available</span><span style="color: #e3e11d;">()</span> <span style="color: #a04cc1;">else</span> <span style="color: #7e7a34;">&quot;cpu&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">checkpoint</span> <span>=</span> <span style="color: #7e7a34;">&quot;meta-llama/Meta-Llama-3-8B-Instruct&quot;</span></p>
<p></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">half</span><span style="color: #e3e11d;">()</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">device</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vamos ver a quantidade de memória que o FP16 ocupa.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">model_memory</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">get_memory_footprint</span><span style="color: #e3e11d;">()</span><span>/</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a38;">1024</span><span>**</span><span style="color: #7e7a38;">3</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;Model memory: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">model_memory</span><span style="color: #3b75c2;">:</span><span style="color: #7e7a34;">.2f</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;"> GB&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>Model memory: 14.96 GB</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vemos que ele ocupa quase 15 GB, mais ou menos os 16 GB que dissemos que deveria ocupar, mas por que essa diferença? Certamente esse modelo não tem exatamente 8B de parâmetros, mas tem um pouco menos, mas ao indicar o número de parâmetros, ele é arredondado para 8B.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Fazemos uma inferência para ver como ele faz isso e quanto tempo leva.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">import</span> <span style="color: #4fcd7d;">time</span></p>
<p></p>
<p><span style="color: #6b97e8;">input_tokens</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;Hello my name is Maximo and I am a Machine Learning Engineer&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">device</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">t0</span> <span>=</span> <span style="color: #6b97e8;">time</span><span>.</span><span style="color: #6b97e8;">time</span><span style="color: #e3e11d;">()</span></p>
<p><span style="color: #6b97e8;">max_new_tokens</span> <span>=</span> <span style="color: #7e7a38;">50</span></p>
<p><span style="color: #6b97e8;">outputs</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span></p>
<p>    <span style="color: #6b97e8;">input_ids</span><span>=</span><span style="color: #6b97e8;">input_tokens</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">attention_mask</span><span>=</span><span style="color: #6b97e8;">input_tokens</span><span>.</span><span style="color: #6b97e8;">attention_mask</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">max_length</span><span>=</span><span style="color: #6b97e8;">input_tokens</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span>.</span><span style="color: #6b97e8;">shape</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">]</span> <span>+</span> <span style="color: #6b97e8;">max_new_tokens</span><span style="color: #e3e11d;">,</span></p>
<p><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">outputs</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">))</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;Inference time: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">time</span><span>.</span><span style="color: #6b97e8;">time</span><span style="color: #e3e11d;">()</span><span style="color: #7f6e38;"> </span><span>-</span><span style="color: #7f6e38;"> </span><span style="color: #6b97e8;">t0</span><span style="color: #3b75c2;">:</span><span style="color: #7e7a34;">.2f</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;"> s&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>Hello my name is Maximo and I am a Machine Learning Engineer at a startup in the Bay Area. I am passionate about building AI systems that can help humans make better decisions and improve their lives.</p><p>I have a background in computer science and mathematics, and I have been working with machine learning for several years. I</p><p>Inference time: 4.14 s</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h3 id="Quantização-do-modelo-para-4-bits">
								<a class="anchor-link" href="#Quantização-do-modelo-para-4-bits">
									<p style="margin-left: 20px">Quantização do modelo para 4 bits</p>
								</a>
							</h3>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vamos quantificar isso em 4 bits. Reinicio o notebook para evitar problemas de memória, então entramos no Hugging Face novamente.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">huggingface_hub</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">notebook_login</span></p>
<p></p>
<p><span style="color: #6b97e8;">notebook_login</span><span style="color: #e3e11d;">()</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Primeiro, crio o tokenizador</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span></p>
<p></p>
<p><span style="color: #6b97e8;">checkpoint</span> <span>=</span> <span style="color: #7e7a34;">&quot;meta-llama/Meta-Llama-3-8B-Instruct&quot;</span></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Agora criamos a configuração de quantização. Como já dissemos, esse algoritmo calcula o erro dos pesos quantizados em relação aos pesos originais com base nas entradas de um conjunto de dados, portanto, na configuração, temos de informá-lo com qual conjunto de dados queremos quantificar o modelo.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Os padrões disponíveis são <code><b>wikitext2</b></code>, <code><b>c4</b></code>, <code><b>c4-new</b></code>, <code><b>ptb</b></code> e <code><b>ptb-new</b></code>.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Também podemos criar um conjunto de dados a partir de uma lista de cadeias de caracteres.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 80px;"><code>dataset = ["auto-gptq é uma biblioteca de quantização de modelos fácil de usar com apis amigáveis, baseada no algoritmo GPTQ."].<br></code></p>
						</div>
					</div>
				</div>
			</div>
	
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Além disso, precisamos informar a ele o número de bits que o modelo quantizado tem por meio do parâmetro <code><b>bits</b></code>.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">GPTQConfig</span></p>
<p></p>
<p><span style="color: #6b97e8;">quantization_config</span> <span>=</span> <span style="color: #6b97e8;">GPTQConfig</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">bits</span><span>=</span><span style="color: #7e7a38;">4</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">dataset</span> <span>=</span> <span style="color: #7e7a34;">&quot;c4&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">tokenizer</span><span>=</span><span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Quantificamos o modelo</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p><span style="color: #833aa0;">import</span> <span style="color: #4fcd7d;">time</span></p>
<p></p>
<p><span style="color: #6b97e8;">t0</span> <span>=</span> <span style="color: #6b97e8;">time</span><span>.</span><span style="color: #6b97e8;">time</span><span style="color: #e3e11d;">()</span></p>
<p><span style="color: #6b97e8;">model_4bits</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a34;">&quot;auto&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">quantization_config</span><span>=</span><span style="color: #6b97e8;">quantization_config</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">t_quantization</span> <span>=</span> <span style="color: #6b97e8;">time</span><span>.</span><span style="color: #6b97e8;">time</span><span style="color: #e3e11d;">()</span> <span>-</span> <span style="color: #6b97e8;">t0</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;Quantization time: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">t_quantization</span><span style="color: #3b75c2;">:</span><span style="color: #7e7a34;">.2f</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;"> s = </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">t_quantization</span><span>/</span><span style="color: #7e7a38;">60</span><span style="color: #3b75c2;">:</span><span style="color: #7e7a34;">.2f</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;"> min&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>Quantization time: 1932.09 s = 32.20 min</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Como o processo de quantização calcula o menor erro entre os pesos quantizados e os pesos originais ao passar as entradas por cada camada, o processo de quantização leva tempo. Nesse caso, levou cerca de meia hora</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vamos dar uma olhada na memória que ele ocupa agora</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">model_4bits_memory</span> <span>=</span> <span style="color: #6b97e8;">model_4bits</span><span>.</span><span style="color: #6b97e8;">get_memory_footprint</span><span style="color: #e3e11d;">()</span><span>/</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a38;">1024</span><span>**</span><span style="color: #7e7a38;">3</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;Model memory: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">model_4bits_memory</span><span style="color: #3b75c2;">:</span><span style="color: #7e7a34;">.2f</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;"> GB&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>Model memory: 5.34 GB</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Aqui podemos ver um benefício da quantização. Enquanto o modelo original ocupava cerca de 15 GB de VRAM, agora o modelo quantizado ocupa cerca de 5 GB, quase um terço do tamanho original.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Fazemos a inferência e observamos o tempo que leva</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">import</span> <span style="color: #4fcd7d;">time</span></p>
<p></p>
<p><span style="color: #6b97e8;">input_tokens</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;Hello my name is Maximo and I am a Machine Learning Engineer&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">model_4bits</span><span>.</span><span style="color: #6b97e8;">device</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">t0</span> <span>=</span> <span style="color: #6b97e8;">time</span><span>.</span><span style="color: #6b97e8;">time</span><span style="color: #e3e11d;">()</span></p>
<p><span style="color: #6b97e8;">max_new_tokens</span> <span>=</span> <span style="color: #7e7a38;">50</span></p>
<p><span style="color: #6b97e8;">outputs</span> <span>=</span> <span style="color: #6b97e8;">model_4bits</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span></p>
<p>    <span style="color: #6b97e8;">input_ids</span><span>=</span><span style="color: #6b97e8;">input_tokens</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">attention_mask</span><span>=</span><span style="color: #6b97e8;">input_tokens</span><span>.</span><span style="color: #6b97e8;">attention_mask</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">max_length</span><span>=</span><span style="color: #6b97e8;">input_tokens</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span>.</span><span style="color: #6b97e8;">shape</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">]</span> <span>+</span> <span style="color: #6b97e8;">max_new_tokens</span><span style="color: #e3e11d;">,</span></p>
<p><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">outputs</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">))</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;Inference time: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">time</span><span>.</span><span style="color: #6b97e8;">time</span><span style="color: #e3e11d;">()</span><span style="color: #7f6e38;"> </span><span>-</span><span style="color: #7f6e38;"> </span><span style="color: #6b97e8;">t0</span><span style="color: #3b75c2;">:</span><span style="color: #7e7a34;">.2f</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;"> s&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>Hello my name is Maximo and I am a Machine Learning Engineer. I have a strong background in computer science and mathematics, and I am passionate about developing innovative solutions that can positively impact society. I am excited to be a part of this community and to learn from and contribute to the discussions here. I am particularly</p><p>Inference time: 2.34 s</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">O modelo não quantizado levou 4,14 segundos, enquanto agora quantizado para 4 bits levou 2,34 segundos e também gerou bem o texto. Conseguimos reduzir a inferência em quase metade.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Como o tamanho do modelo quantizado é quase um terço do modelo FP16, poderíamos pensar que a velocidade de inferência deveria ser cerca de três vezes mais rápida com o modelo quantizado. Mas lembre-se de que, em cada camada, os pesos são quantificados e os cálculos são realizados em FP16, portanto, só conseguimos reduzir o tempo de inferência pela metade e não em um terço.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Agora vamos salvar o modelo</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">save_folder</span> <span>=</span> <span style="color: #7e7a34;">&quot;./model_4bits/&quot;</span></p>
<p><span style="color: #6b97e8;">model_4bits</span><span>.</span><span style="color: #6b97e8;">save_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">save_folder</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">save_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">save_folder</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>('./model_4bits/tokenizer_config.json',</p><p> './model_4bits/special_tokens_map.json',</p><p> './model_4bits/tokenizer.json')</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">E fazemos o upload para o hub</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">repo_id</span> <span>=</span> <span style="color: #7e7a34;">&quot;Llama-3-8B-Instruct-GPTQ-4bits&quot;</span></p>
<p><span style="color: #6b97e8;">commit_message</span> <span>=</span> <span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;AutoGPTQ model for </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">quantization_config</span><span>.</span><span style="color: #6b97e8;">bits</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">bits, gr</span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">quantization_config</span><span>.</span><span style="color: #6b97e8;">group_size</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">, desc_act=</span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">quantization_config</span><span>.</span><span style="color: #6b97e8;">desc_act</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span></p>
<p><span style="color: #6b97e8;">model_4bits</span><span>.</span><span style="color: #6b97e8;">push_to_hub</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">repo_id</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">commit_message</span><span>=</span><span style="color: #6b97e8;">commit_message</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>CommitInfo(commit_url='https://huggingface.co/Maximofn/Llama-3-8B-Instruct-GPTQ-4bits/commit/44cfdcad78db260122943d3f57858c1b840bda17', commit_message='AutoGPTQ model for meta-llama/Meta-Llama-3-8B-Instruct: 4bits, gr128, desc_act=False', commit_description='', oid='44cfdcad78db260122943d3f57858c1b840bda17', pr_url=None, pr_revision=None, pr_num=None)</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Também fizemos o upload do tokenizador. Embora não tenhamos alterado o tokenizador, nós o carregamos porque, se alguém fizer download do nosso modelo a partir do hub, não precisará saber qual tokenizador usamos, portanto, provavelmente desejará fazer o download do modelo e do tokenizador juntos. Podemos indicar no cartão do modelo qual tokenizador usamos para fazer o download, mas é muito provável que a pessoa não leia o cartão do modelo, tente fazer o download do tokenizador, receba um erro e não saiba o que fazer. Por isso, fizemos o upload para evitar esse problema.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">repo_id</span> <span>=</span> <span style="color: #7e7a34;">&quot;Llama-3-8B-Instruct-GPTQ-4bits&quot;</span></p>
<p><span style="color: #6b97e8;">commit_message</span> <span>=</span> <span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;Tokenizers for </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">quantization_config</span><span>.</span><span style="color: #6b97e8;">bits</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">bits, gr</span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">quantization_config</span><span>.</span><span style="color: #6b97e8;">group_size</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">, desc_act=</span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">quantization_config</span><span>.</span><span style="color: #6b97e8;">desc_act</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">push_to_hub</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">repo_id</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">commit_message</span><span>=</span><span style="color: #6b97e8;">commit_message</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>CommitInfo(commit_url='https://huggingface.co/Maximofn/Llama-3-8B-Instruct-GPTQ-4bits/commit/75600041ca6e38b5f1fb912ad1803b66656faae4', commit_message='Tokenizers for meta-llama/Meta-Llama-3-8B-Instruct: 4bits, gr128, desc_act=False', commit_description='', oid='75600041ca6e38b5f1fb912ad1803b66656faae4', pr_url=None, pr_revision=None, pr_num=None)</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h3 id="Quantização-do-modelo-para-3-bits">
								<a class="anchor-link" href="#Quantização-do-modelo-para-3-bits">
									<p style="margin-left: 20px">Quantização do modelo para 3 bits</p>
								</a>
							</h3>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vamos quantificar isso em 3 bits. Reinicio o notebook para evitar problemas de memória e faço login novamente no Hugging Face.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">huggingface_hub</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">notebook_login</span></p>
<p></p>
<p><span style="color: #6b97e8;">notebook_login</span><span style="color: #e3e11d;">()</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Primeiro, crio o tokenizador</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span></p>
<p></p>
<p><span style="color: #6b97e8;">checkpoint</span> <span>=</span> <span style="color: #7e7a34;">&quot;meta-llama/Meta-Llama-3-8B-Instruct&quot;</span></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Criamos a configuração de quantização e agora indicamos que queremos quantizar para 3 bits.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">GPTQConfig</span></p>
<p></p>
<p><span style="color: #6b97e8;">quantization_config</span> <span>=</span> <span style="color: #6b97e8;">GPTQConfig</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">bits</span><span>=</span><span style="color: #7e7a38;">3</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">dataset</span> <span>=</span> <span style="color: #7e7a34;">&quot;c4&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">tokenizer</span><span>=</span><span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Quantificamos o modelo</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p><span style="color: #833aa0;">import</span> <span style="color: #4fcd7d;">time</span></p>
<p></p>
<p><span style="color: #6b97e8;">t0</span> <span>=</span> <span style="color: #6b97e8;">time</span><span>.</span><span style="color: #6b97e8;">time</span><span style="color: #e3e11d;">()</span></p>
<p><span style="color: #6b97e8;">model_3bits</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a34;">&quot;auto&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">quantization_config</span><span>=</span><span style="color: #6b97e8;">quantization_config</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">t_quantization</span> <span>=</span> <span style="color: #6b97e8;">time</span><span>.</span><span style="color: #6b97e8;">time</span><span style="color: #e3e11d;">()</span> <span>-</span> <span style="color: #6b97e8;">t0</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;Quantization time: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">t_quantization</span><span style="color: #3b75c2;">:</span><span style="color: #7e7a34;">.2f</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;"> s = </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">t_quantization</span><span>/</span><span style="color: #7e7a38;">60</span><span style="color: #3b75c2;">:</span><span style="color: #7e7a34;">.2f</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;"> min&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>Quantization time: 1912.69 s = 31.88 min</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Como antes, demorou cerca de meia hora.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vamos dar uma olhada na memória que ele ocupa agora</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">model_3bits_memory</span> <span>=</span> <span style="color: #6b97e8;">model_3bits</span><span>.</span><span style="color: #6b97e8;">get_memory_footprint</span><span style="color: #e3e11d;">()</span><span>/</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a38;">1024</span><span>**</span><span style="color: #7e7a38;">3</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;Model memory: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">model_3bits_memory</span><span style="color: #3b75c2;">:</span><span style="color: #7e7a34;">.2f</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;"> GB&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>Model memory: 4.52 GB</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">O espaço ocupado pela memória do modelo de 3 bits também é de quase 5 GB. O modelo de 4 bits ocupava 5,34 GB, enquanto o modelo de 3 bits agora ocupa 4,52 GB, portanto, conseguimos reduzir um pouco mais o tamanho do modelo.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Fazemos a inferência e observamos o tempo que leva</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">import</span> <span style="color: #4fcd7d;">time</span></p>
<p></p>
<p><span style="color: #6b97e8;">input_tokens</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;Hello my name is Maximo and I am a Machine Learning Engineer&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">model_3bits</span><span>.</span><span style="color: #6b97e8;">device</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">t0</span> <span>=</span> <span style="color: #6b97e8;">time</span><span>.</span><span style="color: #6b97e8;">time</span><span style="color: #e3e11d;">()</span></p>
<p><span style="color: #6b97e8;">max_new_tokens</span> <span>=</span> <span style="color: #7e7a38;">50</span></p>
<p><span style="color: #6b97e8;">outputs</span> <span>=</span> <span style="color: #6b97e8;">model_3bits</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span></p>
<p>    <span style="color: #6b97e8;">input_ids</span><span>=</span><span style="color: #6b97e8;">input_tokens</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">attention_mask</span><span>=</span><span style="color: #6b97e8;">input_tokens</span><span>.</span><span style="color: #6b97e8;">attention_mask</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">max_length</span><span>=</span><span style="color: #6b97e8;">input_tokens</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span>.</span><span style="color: #6b97e8;">shape</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">]</span> <span>+</span> <span style="color: #6b97e8;">max_new_tokens</span><span style="color: #e3e11d;">,</span></p>
<p><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">outputs</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">))</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;Inference time: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">time</span><span>.</span><span style="color: #6b97e8;">time</span><span style="color: #e3e11d;">()</span><span style="color: #7f6e38;"> </span><span>-</span><span style="color: #7f6e38;"> </span><span style="color: #6b97e8;">t0</span><span style="color: #3b75c2;">:</span><span style="color: #7e7a34;">.2f</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;"> s&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>Hello my name is Maximo and I am a Machine Learning Engineer at Google. I am excited to be here today to talk about my work in the field of Machine Learning and to share some of the insights I have gained through my experiences.</p><p>I am a Machine Learning Engineer at Google, and I am excited to be</p><p>Inference time: 2.89 s</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Embora a saída de 3 bits seja boa, o tempo de inferência passou a ser de 2,89 segundos, enquanto a saída de 4 bits foi de 2,34 segundos. Mais testes devem ser feitos para verificar se sempre leva menos tempo em 4 bits ou se a diferença é tão pequena que às vezes a inferência de 3 bits é mais rápida e às vezes a inferência de 4 bits é mais rápida.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Além disso, embora o resultado faça sentido, ele começa a se tornar repetitivo.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Salvamos o modelo</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">save_folder</span> <span>=</span> <span style="color: #7e7a34;">&quot;./model_3bits/&quot;</span></p>
<p><span style="color: #6b97e8;">model_3bits</span><span>.</span><span style="color: #6b97e8;">save_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">save_folder</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">save_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">save_folder</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>('./model_3bits/tokenizer_config.json',</p><p> './model_3bits/special_tokens_map.json',</p><p> './model_3bits/tokenizer.json')</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">E fazemos o upload para o hub</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">repo_id</span> <span>=</span> <span style="color: #7e7a34;">&quot;Llama-3-8B-Instruct-GPTQ-3bits&quot;</span></p>
<p><span style="color: #6b97e8;">commit_message</span> <span>=</span> <span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;AutoGPTQ model for </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">quantization_config</span><span>.</span><span style="color: #6b97e8;">bits</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">bits, gr</span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">quantization_config</span><span>.</span><span style="color: #6b97e8;">group_size</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">, desc_act=</span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">quantization_config</span><span>.</span><span style="color: #6b97e8;">desc_act</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span></p>
<p><span style="color: #6b97e8;">model_3bits</span><span>.</span><span style="color: #6b97e8;">push_to_hub</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">repo_id</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">commit_message</span><span>=</span><span style="color: #6b97e8;">commit_message</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>CommitInfo(commit_url='https://huggingface.co/Maximofn/Llama-3-8B-Instruct-GPTQ-3bits/commit/422fd94a031234c10224ddbe09c0e029a5e9c01f', commit_message='AutoGPTQ model for meta-llama/Meta-Llama-3-8B-Instruct: 3bits, gr128, desc_act=False', commit_description='', oid='422fd94a031234c10224ddbe09c0e029a5e9c01f', pr_url=None, pr_revision=None, pr_num=None)</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Também carregamos o tokenizador</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">repo_id</span> <span>=</span> <span style="color: #7e7a34;">&quot;Llama-3-8B-Instruct-GPTQ-3bits&quot;</span></p>
<p><span style="color: #6b97e8;">commit_message</span> <span>=</span> <span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;Tokenizers for </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">quantization_config</span><span>.</span><span style="color: #6b97e8;">bits</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">bits, gr</span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">quantization_config</span><span>.</span><span style="color: #6b97e8;">group_size</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">, desc_act=</span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">quantization_config</span><span>.</span><span style="color: #6b97e8;">desc_act</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">push_to_hub</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">repo_id</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">commit_message</span><span>=</span><span style="color: #6b97e8;">commit_message</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>CommitInfo(commit_url='https://huggingface.co/Maximofn/Llama-3-8B-Instruct-GPTQ-4bits/commit/75600041ca6e38b5f1fb912ad1803b66656faae4', commit_message='Tokenizers for meta-llama/Meta-Llama-3-8B-Instruct: 4bits, gr128, desc_act=False', commit_description='', oid='75600041ca6e38b5f1fb912ad1803b66656faae4', pr_url=None, pr_revision=None, pr_num=None)</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h3 id="Quantização-do-modelo-para-2-bits">
								<a class="anchor-link" href="#Quantização-do-modelo-para-2-bits">
									<p style="margin-left: 20px">Quantização do modelo para 2 bits</p>
								</a>
							</h3>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vamos quantificar isso em 2 bits. Reinicio o notebook para evitar problemas de memória e faço login novamente no Hugging Face.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">huggingface_hub</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">notebook_login</span></p>
<p></p>
<p><span style="color: #6b97e8;">notebook_login</span><span style="color: #e3e11d;">()</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Primeiro, crio o tokenizador</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span></p>
<p></p>
<p><span style="color: #6b97e8;">checkpoint</span> <span>=</span> <span style="color: #7e7a34;">&quot;meta-llama/Meta-Llama-3-8B-Instruct&quot;</span></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Criamos a configuração de quantização. Agora dizemos a ele para quantizar em 2 bits. Além disso, temos que indicar quantos vetores da matriz de peso ele quantiza ao mesmo tempo por meio do parâmetro <code><b>group_size</b></code>, antes, por padrão, ele tinha o valor 128 e não mexemos nele, mas agora, ao quantizar para 2 bits, para ter menos erro, colocamos um valor menor. Se o deixarmos em 128, o modelo quantizado funcionará muito mal. Nesse caso, colocarei um valor de 16.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">GPTQConfig</span></p>
<p></p>
<p><span style="color: #6b97e8;">quantization_config</span> <span>=</span> <span style="color: #6b97e8;">GPTQConfig</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">bits</span><span>=</span><span style="color: #7e7a38;">2</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">dataset</span> <span>=</span> <span style="color: #7e7a34;">&quot;c4&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">tokenizer</span><span>=</span><span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">group_size</span><span>=</span><span style="color: #7e7a38;">16</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p><span style="color: #833aa0;">import</span> <span style="color: #4fcd7d;">time</span></p>
<p></p>
<p><span style="color: #6b97e8;">t0</span> <span>=</span> <span style="color: #6b97e8;">time</span><span>.</span><span style="color: #6b97e8;">time</span><span style="color: #e3e11d;">()</span></p>
<p><span style="color: #6b97e8;">model_2bits</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a34;">&quot;auto&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">quantization_config</span><span>=</span><span style="color: #6b97e8;">quantization_config</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">t_quantization</span> <span>=</span> <span style="color: #6b97e8;">time</span><span>.</span><span style="color: #6b97e8;">time</span><span style="color: #e3e11d;">()</span> <span>-</span> <span style="color: #6b97e8;">t0</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;Quantization time: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">t_quantization</span><span style="color: #3b75c2;">:</span><span style="color: #7e7a34;">.2f</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;"> s = </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">t_quantization</span><span>/</span><span style="color: #7e7a38;">60</span><span style="color: #3b75c2;">:</span><span style="color: #7e7a34;">.2f</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;"> min&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>Quantization time: 1973.12 s = 32.89 min</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vemos que isso também levou cerca de meia hora.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vamos dar uma olhada na memória que ele ocupa agora</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">model_2bits_memory</span> <span>=</span> <span style="color: #6b97e8;">model_2bits</span><span>.</span><span style="color: #6b97e8;">get_memory_footprint</span><span style="color: #e3e11d;">()</span><span>/</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a38;">1024</span><span>**</span><span style="color: #7e7a38;">3</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;Model memory: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">model_2bits_memory</span><span style="color: #3b75c2;">:</span><span style="color: #7e7a34;">.2f</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;"> GB&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>Model memory: 4.50 GB</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Enquanto a quantização de 4 bits era de 5,34 GB e a de 3 bits era de 4,52 GB, agora a quantização de 2 bits é de 4,50 GB, portanto, conseguimos reduzir um pouco mais o tamanho do modelo.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Fazemos a inferência e observamos o tempo que leva</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">import</span> <span style="color: #4fcd7d;">time</span></p>
<p></p>
<p><span style="color: #6b97e8;">input_tokens</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;Hello my name is Maximo and I am a Machine Learning Engineer&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">model_2bits</span><span>.</span><span style="color: #6b97e8;">device</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">t0</span> <span>=</span> <span style="color: #6b97e8;">time</span><span>.</span><span style="color: #6b97e8;">time</span><span style="color: #e3e11d;">()</span></p>
<p><span style="color: #6b97e8;">max_new_tokens</span> <span>=</span> <span style="color: #7e7a38;">50</span></p>
<p><span style="color: #6b97e8;">outputs</span> <span>=</span> <span style="color: #6b97e8;">model_2bits</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span></p>
<p>    <span style="color: #6b97e8;">input_ids</span><span>=</span><span style="color: #6b97e8;">input_tokens</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">attention_mask</span><span>=</span><span style="color: #6b97e8;">input_tokens</span><span>.</span><span style="color: #6b97e8;">attention_mask</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">max_length</span><span>=</span><span style="color: #6b97e8;">input_tokens</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span>.</span><span style="color: #6b97e8;">shape</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">]</span> <span>+</span> <span style="color: #6b97e8;">max_new_tokens</span><span style="color: #e3e11d;">,</span></p>
<p><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">outputs</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">))</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;Inference time: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">time</span><span>.</span><span style="color: #6b97e8;">time</span><span style="color: #e3e11d;">()</span><span style="color: #7f6e38;"> </span><span>-</span><span style="color: #7f6e38;"> </span><span style="color: #6b97e8;">t0</span><span style="color: #3b75c2;">:</span><span style="color: #7e7a34;">.2f</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;"> s&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>Hello my name is Maximo and I am a Machine Learning Engineer.  # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #</p><p>Inference time: 2.92 s</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vemos que o resultado já não é bom, além disso, o tempo de inferência é de 2,92 segundos, praticamente o mesmo que com 3 e 4 bits.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Salvamos o modelo</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">save_folder</span> <span>=</span> <span style="color: #7e7a34;">&quot;./model_2bits/&quot;</span></p>
<p><span style="color: #6b97e8;">model_2bits</span><span>.</span><span style="color: #6b97e8;">save_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">save_folder</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">save_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">save_folder</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>('./model_2bits/tokenizer_config.json',</p><p> './model_2bits/special_tokens_map.json',</p><p> './model_2bits/tokenizer.json')</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Nós o carregamos no hub</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">repo_id</span> <span>=</span> <span style="color: #7e7a34;">&quot;Llama-3-8B-Instruct-GPTQ-2bits&quot;</span></p>
<p><span style="color: #6b97e8;">commit_message</span> <span>=</span> <span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;AutoGPTQ model for </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">quantization_config</span><span>.</span><span style="color: #6b97e8;">bits</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">bits, gr</span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">quantization_config</span><span>.</span><span style="color: #6b97e8;">group_size</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">, desc_act=</span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">quantization_config</span><span>.</span><span style="color: #6b97e8;">desc_act</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span></p>
<p><span style="color: #6b97e8;">model_2bits</span><span>.</span><span style="color: #6b97e8;">push_to_hub</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">repo_id</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">commit_message</span><span>=</span><span style="color: #6b97e8;">commit_message</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>CommitInfo(commit_url='https://huggingface.co/Maximofn/Llama-3-8B-Instruct-GPTQ-2bits/commit/13ede006ce0dbbd8aca54212e960eff98ea5ec63', commit_message='AutoGPTQ model for meta-llama/Meta-Llama-3-8B-Instruct: 2bits, gr16, desc_act=False', commit_description='', oid='13ede006ce0dbbd8aca54212e960eff98ea5ec63', pr_url=None, pr_revision=None, pr_num=None)</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h3 id="Quantização-do-modelo-para-1-bit">
								<a class="anchor-link" href="#Quantização-do-modelo-para-1-bit">
									<p style="margin-left: 20px">Quantização do modelo para 1 bit</p>
								</a>
							</h3>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vamos quantificar isso em 1 bit. Reinicio o notebook para evitar problemas de memória e faço login novamente no Hugging Face.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">huggingface_hub</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">notebook_login</span></p>
<p></p>
<p><span style="color: #6b97e8;">notebook_login</span><span style="color: #e3e11d;">()</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Primeiro, crio o tokenizador</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span></p>
<p></p>
<p><span style="color: #6b97e8;">checkpoint</span> <span>=</span> <span style="color: #7e7a34;">&quot;meta-llama/Meta-Llama-3-8B-Instruct&quot;</span></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Criamos a configuração de quantização, agora dizemos a ela para quantizar em apenas 1 bit e também para usar um <code><b>group_size</b></code> de 8.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">GPTQConfig</span></p>
<p></p>
<p><span style="color: #6b97e8;">quantization_config</span> <span>=</span> <span style="color: #6b97e8;">GPTQConfig</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">bits</span><span>=</span><span style="color: #7e7a38;">2</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">dataset</span> <span>=</span> <span style="color: #7e7a34;">&quot;c4&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">tokenizer</span><span>=</span><span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">group_size</span><span>=</span><span style="color: #7e7a38;">8</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p><span style="color: #833aa0;">import</span> <span style="color: #4fcd7d;">time</span></p>
<p></p>
<p><span style="color: #6b97e8;">t0</span> <span>=</span> <span style="color: #6b97e8;">time</span><span>.</span><span style="color: #6b97e8;">time</span><span style="color: #e3e11d;">()</span></p>
<p><span style="color: #6b97e8;">model_1bits</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a34;">&quot;auto&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">quantization_config</span><span>=</span><span style="color: #6b97e8;">quantization_config</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">t_quantization</span> <span>=</span> <span style="color: #6b97e8;">time</span><span>.</span><span style="color: #6b97e8;">time</span><span style="color: #e3e11d;">()</span> <span>-</span> <span style="color: #6b97e8;">t0</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;Quantization time: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">t_quantization</span><span style="color: #3b75c2;">:</span><span style="color: #7e7a34;">.2f</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;"> s = </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">t_quantization</span><span>/</span><span style="color: #7e7a38;">60</span><span style="color: #3b75c2;">:</span><span style="color: #7e7a34;">.2f</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;"> min&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>Quantization time: 2030.38 s = 33.84 min</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vemos que também leva cerca de meia hora para quantificar.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vamos dar uma olhada na memória que ele ocupa agora</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">model_1bits_memory</span> <span>=</span> <span style="color: #6b97e8;">model_1bits</span><span>.</span><span style="color: #6b97e8;">get_memory_footprint</span><span style="color: #e3e11d;">()</span><span>/</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a38;">1024</span><span>**</span><span style="color: #7e7a38;">3</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;Model memory: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">model_1bits_memory</span><span style="color: #3b75c2;">:</span><span style="color: #7e7a34;">.2f</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;"> GB&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>Model memory: 5.42 GB</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vemos que, nesse caso, ele ocupa ainda mais do que quantificado em 2 bits, 4,52 GB.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Fazemos a inferência e observamos o tempo que leva</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">import</span> <span style="color: #4fcd7d;">time</span></p>
<p></p>
<p><span style="color: #6b97e8;">input_tokens</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;Hello my name is Maximo and I am a Machine Learning Engineer&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">model_1bits</span><span>.</span><span style="color: #6b97e8;">device</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">t0</span> <span>=</span> <span style="color: #6b97e8;">time</span><span>.</span><span style="color: #6b97e8;">time</span><span style="color: #e3e11d;">()</span></p>
<p><span style="color: #6b97e8;">max_new_tokens</span> <span>=</span> <span style="color: #7e7a38;">50</span></p>
<p><span style="color: #6b97e8;">outputs</span> <span>=</span> <span style="color: #6b97e8;">model_1bits</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span></p>
<p>    <span style="color: #6b97e8;">input_ids</span><span>=</span><span style="color: #6b97e8;">input_tokens</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">attention_mask</span><span>=</span><span style="color: #6b97e8;">input_tokens</span><span>.</span><span style="color: #6b97e8;">attention_mask</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">max_length</span><span>=</span><span style="color: #6b97e8;">input_tokens</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span>.</span><span style="color: #6b97e8;">shape</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">]</span> <span>+</span> <span style="color: #6b97e8;">max_new_tokens</span><span style="color: #e3e11d;">,</span></p>
<p><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">outputs</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">))</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;Inference time: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">time</span><span>.</span><span style="color: #6b97e8;">time</span><span style="color: #e3e11d;">()</span><span style="color: #7f6e38;"> </span><span>-</span><span style="color: #7f6e38;"> </span><span style="color: #6b97e8;">t0</span><span style="color: #3b75c2;">:</span><span style="color: #7e7a34;">.2f</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;"> s&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>Hello my name is Maximo and I am a Machine Learning Engineerimerszuimersimerspinsimersimersingoingoimersurosimersimersimersoleningoimersingopinsimersbirpinsimersimersimersorgeingoimersiringimersimersimersimersimersimersimersンディorge_REFERER ingest羊imersorgeimersimersendetingoШАhandsingo</p><p>Inference time: 3.12 s</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vemos que a saída é muito ruim e também demora mais do que quando quantizamos para 2 bits.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Salvamos o modelo</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">save_folder</span> <span>=</span> <span style="color: #7e7a34;">&quot;./model_1bits/&quot;</span></p>
<p><span style="color: #6b97e8;">model_1bits</span><span>.</span><span style="color: #6b97e8;">save_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">save_folder</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">save_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">save_folder</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>('./model_1bits/tokenizer_config.json',</p><p> './model_1bits/special_tokens_map.json',</p><p> './model_1bits/tokenizer.json')</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Nós o carregamos no hub</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">repo_id</span> <span>=</span> <span style="color: #7e7a34;">&quot;Llama-3-8B-Instruct-GPTQ-1bits&quot;</span></p>
<p><span style="color: #6b97e8;">commit_message</span> <span>=</span> <span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;AutoGPTQ model for </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">quantization_config</span><span>.</span><span style="color: #6b97e8;">bits</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">bits, gr</span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">quantization_config</span><span>.</span><span style="color: #6b97e8;">group_size</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">, desc_act=</span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">quantization_config</span><span>.</span><span style="color: #6b97e8;">desc_act</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;">&quot;</span></p>
<p><span style="color: #6b97e8;">model_1bits</span><span>.</span><span style="color: #6b97e8;">push_to_hub</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">repo_id</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">commit_message</span><span>=</span><span style="color: #6b97e8;">commit_message</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>CommitInfo(commit_url='https://huggingface.co/Maximofn/Llama-3-8B-Instruct-GPTQ-2bits/commit/e59ccffc03247e7dcc418f98b482cc02dc7a168d', commit_message='AutoGPTQ model for meta-llama/Meta-Llama-3-8B-Instruct: 2bits, gr8, desc_act=False', commit_description='', oid='e59ccffc03247e7dcc418f98b482cc02dc7a168d', pr_url=None, pr_revision=None, pr_num=None)</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Resumo-da-quantificação">
								<a class="anchor-link" href="#Resumo-da-quantificação">
									<p style="margin-left: 10px">Resumo da quantificação</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vamos comprar quantização de 4, 3, 2 e 1 bits.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<table>
								<tr>
									<th>Bits </th>
									<th>Tempo de quantização (min) </th>
									<th>Memória (GB) </th>
									<th>Tempo de inferência (s) </th>
									<th>Qualidade da saída </th>
								</tr>
								<tr>
									<td>FP16 </td>
									<td> 0 </td>
									<td> 14.96 </td>
									<td> 4.14 </td>
									<td> Bom </td>
								</tr>
								<tr>
									<td>4 </td>
									<td> 32.20 </td>
									<td> 5.34 </td>
									<td> 2.34 </td>
									<td> Bom </td>
								</tr>
								<tr>
									<td>3 </td>
									<td> 31.88 </td>
									<td> 4.52 </td>
									<td> 2.89 </td>
									<td> Bom </td>
								</tr>
								<tr>
									<td>2 </td>
									<td> 32.89 </td>
									<td> 4.50 </td>
									<td> 2.92 </td>
									<td> Ruim </td>
								</tr>
								<tr>
									<td>1 </td>
									<td> 33.84 </td>
									<td> 5.42 </td>
									<td> 3.12 </td>
									<td> Ruim </td>
								</tr>
							</table>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Observando essa tabela, vemos que não faz sentido, neste exemplo, quantificar com menos de 4 bits.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">A quantificação em 1 e 2 bits claramente não faz sentido porque a qualidade da saída é ruim.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Mas, embora a saída quando quantizamos para 3 bits seja boa, ela começou a se tornar repetitiva, portanto, a longo prazo, provavelmente não seria uma boa ideia usar esse modelo. Além disso, nem a economia no tempo de quantização, nem a economia de VRAM, nem a economia no tempo de inferência são significativas em comparação com a quantização para 4 bits.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Carregamento-do-modelo-salvo">
								<a class="anchor-link" href="#Carregamento-do-modelo-salvo">
									<p style="margin-left: 10px">Carregamento do modelo salvo</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Agora que comparamos a quantização dos modelos, vamos ver como seria feito para carregar o modelo de 4 bits que salvamos, já que, como vimos, essa é a melhor opção.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Primeiro, carregamos o tokenizador que usamos.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span></p>
<p></p>
<p><span style="color: #6b97e8;">path</span> <span>=</span> <span style="color: #7e7a34;">&quot;./model_4bits&quot;</span></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">path</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Agora, carregamos o modelo que salvamos</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p></p>
<p><span style="color: #6b97e8;">load_model_4bits</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">path</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a34;">&quot;auto&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>Loading checkpoint shards: 100%|██████████| 2/2 [00:00&lt;?, ?it/s]</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vemos a memória que ele ocupa</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">load_model_4bits_memory</span> <span>=</span> <span style="color: #6b97e8;">load_model_4bits</span><span>.</span><span style="color: #6b97e8;">get_memory_footprint</span><span style="color: #e3e11d;">()</span><span>/</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a38;">1024</span><span>**</span><span style="color: #7e7a38;">3</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;Model memory: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">load_model_4bits_memory</span><span style="color: #3b75c2;">:</span><span style="color: #7e7a34;">.2f</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;"> GB&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>Model memory: 5.34 GB</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vemos que ele ocupa a mesma memória de quando o quantificamos, o que é lógico.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Fazemos a inferência e observamos o tempo que leva</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">import</span> <span style="color: #4fcd7d;">time</span></p>
<p></p>
<p><span style="color: #6b97e8;">input_tokens</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;Hello my name is Maximo and I am a Machine Learning Engineer&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">load_model_4bits</span><span>.</span><span style="color: #6b97e8;">device</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">t0</span> <span>=</span> <span style="color: #6b97e8;">time</span><span>.</span><span style="color: #6b97e8;">time</span><span style="color: #e3e11d;">()</span></p>
<p><span style="color: #6b97e8;">max_new_tokens</span> <span>=</span> <span style="color: #7e7a38;">50</span></p>
<p><span style="color: #6b97e8;">outputs</span> <span>=</span> <span style="color: #6b97e8;">load_model_4bits</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span></p>
<p>    <span style="color: #6b97e8;">input_ids</span><span>=</span><span style="color: #6b97e8;">input_tokens</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">attention_mask</span><span>=</span><span style="color: #6b97e8;">input_tokens</span><span>.</span><span style="color: #6b97e8;">attention_mask</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">max_length</span><span>=</span><span style="color: #6b97e8;">input_tokens</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span>.</span><span style="color: #6b97e8;">shape</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">]</span> <span>+</span> <span style="color: #6b97e8;">max_new_tokens</span><span style="color: #e3e11d;">,</span></p>
<p><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">outputs</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">))</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;Inference time: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">time</span><span>.</span><span style="color: #6b97e8;">time</span><span style="color: #e3e11d;">()</span><span style="color: #7f6e38;"> </span><span>-</span><span style="color: #7f6e38;"> </span><span style="color: #6b97e8;">t0</span><span style="color: #3b75c2;">:</span><span style="color: #7e7a34;">.2f</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;"> s&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>Hello my name is Maximo and I am a Machine Learning Engineer. I have a strong background in computer science and mathematics, and I have been working with machine learning models for several years. I am excited to be a part of this community and to share my knowledge and experience with others. I am particularly interested in</p><p>Inference time: 3.82 s</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vemos que a inferência é boa e levou 3,82 segundos, um pouco mais do que quando a quantificamos. Mas, como eu disse antes, teríamos que fazer esse teste várias vezes e tirar uma média.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Carregando-o-modelo-carregado-para-o-hub">
								<a class="anchor-link" href="#Carregando-o-modelo-carregado-para-o-hub">
									<p style="margin-left: 10px">Carregando o modelo carregado para o hub</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Agora veremos como carregar o modelo de 4 bits que carregamos no hub.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Primeiro, carregamos o tokenizador que carregamos.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span></p>
<p></p>
<p><span style="color: #6b97e8;">checkpoint</span> <span>=</span> <span style="color: #7e7a34;">&quot;Maximofn/Llama-3-8B-Instruct-GPTQ-4bits&quot;</span></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Agora, carregamos o modelo que salvamos</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span></p>
<p></p>
<p><span style="color: #6b97e8;">load_model_4bits</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoint</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a34;">&quot;auto&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vemos a memória que ele ocupa</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">load_model_4bits_memory</span> <span>=</span> <span style="color: #6b97e8;">load_model_4bits</span><span>.</span><span style="color: #6b97e8;">get_memory_footprint</span><span style="color: #e3e11d;">()</span><span>/</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a38;">1024</span><span>**</span><span style="color: #7e7a38;">3</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;Model memory: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">load_model_4bits_memory</span><span style="color: #3b75c2;">:</span><span style="color: #7e7a34;">.2f</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;"> GB&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>Model memory: 5.34 GB</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Ele também ocupa a mesma memória</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Fazemos a inferência e observamos o tempo que leva</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">import</span> <span style="color: #4fcd7d;">time</span></p>
<p></p>
<p><span style="color: #6b97e8;">input_tokens</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a34;">&quot;Hello my name is Maximo and I am a Machine Learning Engineer&quot;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">load_model_4bits</span><span>.</span><span style="color: #6b97e8;">device</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #6b97e8;">t0</span> <span>=</span> <span style="color: #6b97e8;">time</span><span>.</span><span style="color: #6b97e8;">time</span><span style="color: #e3e11d;">()</span></p>
<p><span style="color: #6b97e8;">max_new_tokens</span> <span>=</span> <span style="color: #7e7a38;">50</span></p>
<p><span style="color: #6b97e8;">outputs</span> <span>=</span> <span style="color: #6b97e8;">load_model_4bits</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span></p>
<p>    <span style="color: #6b97e8;">input_ids</span><span>=</span><span style="color: #6b97e8;">input_tokens</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">attention_mask</span><span>=</span><span style="color: #6b97e8;">input_tokens</span><span>.</span><span style="color: #6b97e8;">attention_mask</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #6b97e8;">max_length</span><span>=</span><span style="color: #6b97e8;">input_tokens</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span>.</span><span style="color: #6b97e8;">shape</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">]</span> <span>+</span> <span style="color: #6b97e8;">max_new_tokens</span><span style="color: #e3e11d;">,</span></p>
<p><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">outputs</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">))</span></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;Inference time: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">time</span><span>.</span><span style="color: #6b97e8;">time</span><span style="color: #e3e11d;">()</span><span style="color: #7f6e38;"> </span><span>-</span><span style="color: #7f6e38;"> </span><span style="color: #6b97e8;">t0</span><span style="color: #3b75c2;">:</span><span style="color: #7e7a34;">.2f</span><span style="color: #3b75c2;">}</span><span style="color: #7e7a34;"> s&quot;</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>Hello my name is Maximo and I am a Machine Learning Engineer with a passion for building innovative AI solutions. I have been working in the field of AI for over 5 years, and have gained extensive experience in developing and implementing machine learning models for various industries.</p><p>In my free time, I enjoy reading books on</p><p>Inference time: 3.81 s</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vemos que a inferência também é boa e levou 3,81 segundos.</p>
						</div>
					</div>
				</div>
			</div>
		</div>
	<!-- Close class contenido -->
	</div>
<!-- Close div notebook container -->
</div>
<!-- Close div notebook -->
</div>

