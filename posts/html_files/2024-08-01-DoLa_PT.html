<p>
	<!-- Custom stylesheet, it must be in the same directory as the html file -->
	<!-- Loading mathjax macro --><!-- Load mathjax --><!-- MathJax configuration -->
<p>
<style>
	/* Media query para pantallas grandes */
	@media screen and (min-width: 1000px) {
		.container {
			flex-wrap: nowrap;
			display: flex;
			justify-content: space-between;
			height: 100vh; /* altura del viewport */
		}
		
		.indice {
			width: 25%; /* Ancho del índice en pantallas grandes */
			border-right: 1px solid #ccc;
			max-height: calc(100vh - 40px); /* Ajustar según tus necesidades. Aquí estamos restando el doble del padding para mantener todo visible */
			padding: 20px;
			box-sizing: border-box;
			overflow-y: auto; /* desplazamiento vertical cuando sea necesario */
		}
		
		.contenido {
			width: 70%; /* Ancho del contenido en pantallas grandes */
			max-height: calc(100vh - 40px); /* Ajustar según tus necesidades. Aquí estamos restando el doble del padding para mantener todo visible */
			padding: 20px;
			box-sizing: border-box;
			overflow-y: auto; /* desplazamiento vertical cuando sea necesario */
		}
	}
</style>
<!-- Open div notebook -->
<div id="notebook" class="border-box-sizing" tabindex="-1">
	<!-- Open div notebook container -->
	<div id="notebook-container" class="container">
		<!-- Open div indice -->
		<div class="indice">
			<!-- Open div index header -->
			<div class="cell border-box-sizing text_cell rendered">
				<h2 class="prompt input_prompt">
					<span style="
					color: var(--darkreader-text--heading-color, var(--darkreader-text--heading-2-color,
					var(--darkreader-text--headings-color)));
					font-family: var(--fontFamily); font-size: var(--fontSize);
					font-style: var(--fontStyle, inherit);
					font-weight: var(--fontWeight);
					letter-spacing: var(--letterSpacing);
					text-transform: var(--textTransform);
					background-color: transparent;
					--darkreader-inline-color: var(--darkreader-text--darkreader-text--heading-color,
					var(--darkreader-text--darkreader-text--heading-2-color, var(--darkreader-text--darkreader-text--headings-color)));
					--darkreader-inline-bgcolor: transparent;"
					data-darkreader-inline-color="" data-darkreader-inline-bgcolor="">
						Índice
					</span>
					<a class="anchor-link" style="
					font-family: var(--fontFamily);
					font-size: var(--fontSize);
					font-style: var(--fontStyle, inherit);
					font-weight: var(--fontWeight);
					letter-spacing: var(--letterSpacing);
					text-transform: var(--textTransform);
					background-color: transparent;
					--darkreader-inline-bgcolor: transparent;"
					href="#Índice" data-darkreader-inline-bgcolor="">
					</a>
				</h2>
			<!-- Close div index header -->
			</div>
			<!-- Index body -->
			<div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Método-index">
									<a class="anchor-link" href="#Método">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Método</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Seleção-dinâmica-da-camada-prematura-index">
									<a class="anchor-link" href="#Seleção-dinâmica-da-camada-prematura">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Seleção dinâmica da camada prematura</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Contraste-de-previsões-index">
									<a class="anchor-link" href="#Contraste-de-previsões">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Contraste de previsões</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Penalidade-de-repetição-index">
									<a class="anchor-link" href="#Penalidade-de-repetição">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Penalidade de repetição</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
				<!-- Open div header -->
				<div class="cell border-box-sizing text_cell rendered">
					<div class="prompt input_prompt">
						<div class="inner_cell">
							<div class="text_cell_render border-box-sizing rendered_html">
								<h2 id="Implementação-com-transformadores-index">
									<a class="anchor-link" href="#Implementação-com-transformadores">
										<p style="margin-left: 0px; font-size: 12px; line-height: 1.5;">Implementação com transformadores</p>
									</a>
								</h2>
							</div>
						</div>
					</div>
				</div>
			</div>
		<!-- Close div indice -->
		</div>
 
		<!-- Content -->
		<div class="contenido">
		<div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><a href="https://colab.research.google.com/github/maximofn/portafolio/blob/main/posts/notebooks_translated/2024-08-01-DoLa_PT.ipynb" target="_blank"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h1 id="DoLa:-a-decodificação-por-camadas-contrastantes-melhora-a-factualidade-em-grandes-modelos-de-linguagem">
								<a class="anchor-link" href="#DoLa:-a-decodificação-por-camadas-contrastantes-melhora-a-factualidade-em-grandes-modelos-de-linguagem">
									<p style="margin-left: 0px">DoLa: a decodificação por camadas contrastantes melhora a factualidade em grandes modelos de linguagem</p>
								</a>
							</h1>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Entretanto, à medida que os LLMs aumentam de tamanho e surgem novos recursos, temos um problema, que é o aliasing. Os autores do artigo [DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models] (https://arxiv.org/abs/2309.03883) propõem um método para evitar esse problema.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Este caderno foi traduzido automaticamente para torná-lo acessível a mais pessoas, por favor me avise se você vir algum erro de digitação..</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Eles propõem uma abordagem de decodificação contrastiva, em que a probabilidade de saída da próxima palavra é obtida a partir da diferença de logits entre uma camada superior e uma inferior. Ao enfatizar o conhecimento nas camadas superiores e reduzir a ênfase no conhecimento das camadas inferiores, podemos tornar as LMs mais factuais e, assim, reduzir as alucinações.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">A figura abaixo mostra essa ideia. Embora <code><b>Seattle</b></code> mantenha uma alta probabilidade em todas as camadas, a probabilidade da resposta correta <code><b>Olympia</b></code> aumenta depois que as camadas superiores injetam mais conhecimento factual. O contraste das diferenças entre as diferentes camadas pode revelar a resposta correta nesse caso.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"><p align="center"><img src="https://maximofn.com/wp-content/uploads/2024/07/DoLa-figure1.webp" alt="DoLa-figure1"></p></p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Método">
								<a class="anchor-link" href="#Método">
									<p style="margin-left: 10px">Método</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Um LLM consiste em uma camada de incorporação, vários transformadores sequenciais e, em seguida, uma camada de saída. O que eles propõem é medir a saída de cada transformador usando a divergência de Jensen-Shannon (JSD).</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">A figura a seguir mostra essa medida na saída de cada transformador para uma frase de entrada do LLM. Cada coluna corresponde a um token da frase</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">DoLa-figure2](https://maximofn.com/wp-content/uploads/2024/07/DoLa-figure2.webp)</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Dois padrões podem ser observados</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">
								<ul>
									<li>O primeiro ocorre ao prever entidades nomeadas ou datas importantes, como <code><b>Wole Soyinka</b></code> e <code><b>1986</b></code>, que exigem conhecimento factual. É possível observar que o JSD calculado permanece extremamente alto nas camadas superiores. Esse padrão indica que o modelo continua alterando suas previsões nas camadas posteriores e, possivelmente, injetando mais conhecimento factual nas previsões.</li>
									<li>A segunda ocorre ao prever palavras funcionais, como <code><b>was</b></code>, <code><b>the</b></code>, <code><b>to</b></code>, <code><b>in</b></code>, e tokens copiados da pergunta de entrada, como <code><b>first Nigerian</b></code>, <code><b>Nobel Prize</b></code>. Quando esses tokens "fáceis" são previstos, podemos observar que o JSD se torna muito pequeno a partir das camadas intermediárias. Essa constatação indica que o modelo já decidiu qual token gerar nas camadas intermediárias e mantém as distribuições de saída praticamente inalteradas nas camadas superiores. Essa descoberta também é consistente com as suposições nos LLMs de saída inicial <code><b>Schuster et al., 2022</b></code>.</li>
								</ul>
							</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;"> </p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">

						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Quando a previsão da próxima palavra requer conhecimento factual, o LLM parece alterar as previsões nas camadas superiores. O contraste das camadas antes e depois de uma mudança repentina pode, portanto, ampliar o conhecimento que emerge das camadas superiores e fazer com que o modelo confie mais em seu conhecimento factual interno. Além disso, essa evolução das informações parece variar de token para token.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Seu método requer a seleção precisa da camada prematura que contém informações plausíveis, mas menos factuais, que nem sempre podem estar na mesma camada inicial. Portanto, eles propõem encontrar essa camada prematura selecionando dinamicamente a camada prematura, conforme visto na imagem a seguir.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">DoLa-figure3](https://maximofn.com/wp-content/uploads/2024/07/DoLa-figure3.webp)</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Seleção-dinâmica-da-camada-prematura">
								<a class="anchor-link" href="#Seleção-dinâmica-da-camada-prematura">
									<p style="margin-left: 10px">Seleção dinâmica da camada prematura</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Para selecionar a camada prematura, eles calculam a divergência de Jensen-Shannon (JSD) entre as camadas intermediárias e a camada final. A camada prematura é selecionada como a camada com a maior JSD.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Entretanto, como esse processo pode ser um pouco lento, o que eles fazem é agrupar várias camadas para fazer menos cálculos.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Contraste-de-previsões">
								<a class="anchor-link" href="#Contraste-de-previsões">
									<p style="margin-left: 10px">Contraste de previsões</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Agora que temos a última camada (camada madura) e a camada prematura, podemos contrastar as previsões de ambas as camadas. Para isso, eles calculam a probabilidade de log do próximo token na camada madura e na camada prematura. Em seguida, eles subtraem a probabilidade de log da camada prematura daquela da camada madura, dando assim mais peso ao conhecimento da camada madura.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Penalidade-de-repetição">
								<a class="anchor-link" href="#Penalidade-de-repetição">
									<p style="margin-left: 10px">Penalidade de repetição</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">A motivação da DoLa é reduzir a ênfase no conhecimento linguístico das camadas inferiores e ampliar o conhecimento factual do mundo real. Entretanto, isso pode fazer com que o modelo gere parágrafos gramaticalmente incorretos.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Empiricamente, eles não observaram esse problema, mas descobriram que a distribuição DoLa resultante às vezes tem uma tendência maior de repetir frases geradas anteriormente, especialmente durante a geração de longas sequências de raciocínio na cadeia de pensamento.</p>
						</div>
					</div>
				</div>
			</div>
	
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Portanto, eles incluem uma penalidade de repetição introduzida em <code><b>Keskar et al. (2019)</b></code> com <code><b>θ = 1,2</b></code> durante a decodificação.</p>
						</div>
					</div>
				</div>
			</div>
			<!-- Open div header -->
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<h2 id="Implementação-com-transformadores">
								<a class="anchor-link" href="#Implementação-com-transformadores">
									<p style="margin-left: 10px">Implementação com transformadores</p>
								</a>
							</h2>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vamos ver como implementar a DoLa com a biblioteca <code><b>transformers</b></code> da Hugging Face. Para obter mais informações sobre como implementar a DoLa com a biblioteca <code><b>transformers</b></code>, você pode consultar o seguinte [link] (https://huggingface.co/docs/transformers/main/en/generation_strategies#dola-decoding)</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Primeiro, fazemos o login no Hub, porque vamos usar o Llama 3 8B e, para usá-lo, precisamos pedir permissão ao Meta, portanto, para fazer o download, precisamos estar conectados para que ele saiba quem está fazendo o download.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">huggingface_hub</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">notebook_login</span></p>
<p><span style="color: #6b97e8;">notebook_login</span><span style="color: #e3e11d;">()</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Agora, instanciamos o tokenizador e o modelo</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">set_seed</span></p>
<p><span style="color: #833aa0;">import</span> <span style="color: #4fcd7d;">torch</span></p>
<p></p>
<p><span style="color: #6b97e8;">compute_dtype</span> <span>=</span> <span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">bfloat16</span> <span style="color: #a04cc1;">if</span> <span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">cuda</span><span>.</span><span style="color: #6b97e8;">is_bf16_supported</span><span style="color: #e3e11d;">()</span> <span style="color: #a04cc1;">else</span> <span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">float16</span></p>
<p></p>
<p><span style="color: #6b97e8;">device</span> <span>=</span> <span style="color: #8d783e;">&#39;cuda&#39;</span> <span style="color: #a04cc1;">if</span> <span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">cuda</span><span>.</span><span style="color: #6b97e8;">is_available</span><span style="color: #e3e11d;">()</span> <span style="color: #a04cc1;">else</span> <span style="color: #8d783e;">&#39;cpu&#39;</span></p>
<p><span style="color: #6b97e8;">checkpoints</span> <span>=</span> <span style="color: #7e7a34;">&quot;meta-llama/Meta-Llama-3-8B-Instruct&quot;</span></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoints</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoints</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">torch_dtype</span><span>=</span><span style="color: #6b97e8;">compute_dtype</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a34;">&quot;auto&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">config</span><span>.</span><span style="color: #6b97e8;">pad_token_id</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">config</span><span>.</span><span style="color: #6b97e8;">eos_token_id</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Atribuímos um valor de semente fixo para a reprodutibilidade do exemplo.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">set_seed</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a38;">42</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Geramos os tokens de entrada do LLM.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">question</span> <span>=</span> <span style="color: #8d783e;">&#39;What does Darth Vader say to Luke in &quot;The Empire Strikes Back&quot;?&#39;</span></p>
<p><span style="color: #6b97e8;">text</span> <span>=</span> <span style="color: #1b1477;">f</span><span style="color: #7e7a34;">&quot;Answer with a short answer.</span><span style="color: #a6a831;">\n\n</span><span style="color: #7e7a34;">Question: </span><span style="color: #3b75c2;">{</span><span style="color: #6b97e8;">question</span><span style="color: #3b75c2;">}</span><span style="color: #a6a831;">\n\n</span><span style="color: #7e7a34;">Answer: &quot;</span></p>
<p><span style="color: #6b97e8;">inputs</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">text</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">device</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Agora, geramos a entrada vanilla, ou seja, sem aplicar o DoLa</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">generate_kwargs</span><span>=</span><span style="color: #e3e11d;">{</span></p>
<p>    <span style="color: #7e7a34;">&quot;do_sample&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7f6e38;">False</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #7e7a34;">&quot;max_new_tokens&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a38;">50</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #7e7a34;">&quot;top_p&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7f6e38;">None</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #7e7a34;">&quot;temperature&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7f6e38;">None</span></p>
<p><span style="color: #e3e11d;">}</span></p>
<p></p>
<p><span style="color: #6b97e8;">vanilla_output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">inputs</span><span style="color: #e3e11d;">,</span> <span>**</span><span style="color: #6b97e8;">generate_kwargs</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">batch_decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">vanilla_output</span><span style="color: #e3e11d;">[:,</span> <span style="color: #6b97e8;">inputs</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span>.</span><span style="color: #6b97e8;">shape</span><span style="color: #e3e11d;">[</span><span>-</span><span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">]:],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">])</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p> "No, I am your father." (Note: This is a famous misquote. The actual quote is "No, I am your father" is not in the movie. The correct quote is "No, I am your father." is not</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vemos que ele sabe que há um erro famoso, mas não diz a frase verdadeira</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Agora aplicando o DoLa</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">dola_high_output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">inputs</span><span style="color: #e3e11d;">,</span> <span>**</span><span style="color: #6b97e8;">generate_kwargs</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">dola_layers</span><span>=</span><span style="color: #8d783e;">&#39;high&#39;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">repetition_penalty</span><span>=</span><span style="color: #a09e19;">1.2</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">batch_decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">dola_high_output</span><span style="color: #e3e11d;">[:,</span> <span style="color: #6b97e8;">inputs</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span>.</span><span style="color: #6b97e8;">shape</span><span style="color: #e3e11d;">[</span><span>-</span><span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">]:],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">])</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p> "No, I am your father." (Note: This is one of the most famous lines in movie history, and it's often misquoted as "Luke, I am your father.")</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Agora ele consegue dar a frase correta e o [famoso erro] (https://www.bbc.co.uk/bitesize/articles/zc38kty)</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vamos fazer outro teste com outro exemplo, reiniciar o notebook e usar outro modelo.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #833aa0;">from</span> <span style="color: #4fcd7d;">transformers</span> <span style="color: #833aa0;">import</span> <span style="color: #6b97e8;">AutoTokenizer</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">set_seed</span></p>
<p><span style="color: #833aa0;">import</span> <span style="color: #4fcd7d;">torch</span></p>
<p></p>
<p><span style="color: #6b97e8;">compute_dtype</span> <span>=</span> <span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">bfloat16</span> <span style="color: #a04cc1;">if</span> <span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">cuda</span><span>.</span><span style="color: #6b97e8;">is_bf16_supported</span><span style="color: #e3e11d;">()</span> <span style="color: #a04cc1;">else</span> <span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">float16</span></p>
<p></p>
<p><span style="color: #6b97e8;">device</span> <span>=</span> <span style="color: #8d783e;">&#39;cuda&#39;</span> <span style="color: #a04cc1;">if</span> <span style="color: #6b97e8;">torch</span><span>.</span><span style="color: #6b97e8;">cuda</span><span>.</span><span style="color: #6b97e8;">is_available</span><span style="color: #e3e11d;">()</span> <span style="color: #a04cc1;">else</span> <span style="color: #8d783e;">&#39;cpu&#39;</span></p>
<p><span style="color: #6b97e8;">checkpoints</span> <span>=</span> <span style="color: #7e7a34;">&quot;huggyllama/llama-7b&quot;</span></p>
<p><span style="color: #6b97e8;">tokenizer</span> <span>=</span> <span style="color: #6b97e8;">AutoTokenizer</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoints</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">pad_token</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">eos_token</span></p>
<p><span style="color: #6b97e8;">model</span> <span>=</span> <span style="color: #6b97e8;">AutoModelForCausalLM</span><span>.</span><span style="color: #6b97e8;">from_pretrained</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">checkpoints</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">torch_dtype</span><span>=</span><span style="color: #6b97e8;">compute_dtype</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">device_map</span><span>=</span><span style="color: #7e7a34;">&quot;auto&quot;</span><span style="color: #e3e11d;">)</span></p>
<p><span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">config</span><span>.</span><span style="color: #6b97e8;">pad_token_id</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">config</span><span>.</span><span style="color: #6b97e8;">eos_token_id</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Atribuímos um valor de semente fixo para a reprodutibilidade do exemplo.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">set_seed</span><span style="color: #e3e11d;">(</span><span style="color: #7e7a38;">42</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Estou escrevendo uma nova pergunta</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">text</span> <span>=</span> <span style="color: #7e7a34;">&quot;On what date was the Declaration of Independence officially signed?&quot;</span></p>
<p><span style="color: #6b97e8;">inputs</span> <span>=</span> <span style="color: #6b97e8;">tokenizer</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">text</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">return_tensors</span><span>=</span><span style="color: #7e7a34;">&quot;pt&quot;</span><span style="color: #e3e11d;">)</span><span>.</span><span style="color: #6b97e8;">to</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">device</span><span style="color: #e3e11d;">)</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Geramos a saída vanilla</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">generate_kwargs</span><span>=</span><span style="color: #e3e11d;">{</span></p>
<p>    <span style="color: #7e7a34;">&quot;do_sample&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7f6e38;">False</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #7e7a34;">&quot;max_new_tokens&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7e7a38;">50</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #7e7a34;">&quot;top_p&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7f6e38;">None</span><span style="color: #e3e11d;">,</span></p>
<p>    <span style="color: #7e7a34;">&quot;temperature&quot;</span><span style="color: #e3e11d;">:</span> <span style="color: #7f6e38;">None</span></p>
<p><span style="color: #e3e11d;">}</span></p>
<p></p>
<p><span style="color: #6b97e8;">vanilla_output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">inputs</span><span style="color: #e3e11d;">,</span> <span>**</span><span style="color: #6b97e8;">generate_kwargs</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">batch_decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">vanilla_output</span><span style="color: #e3e11d;">[:,</span> <span style="color: #6b97e8;">inputs</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span>.</span><span style="color: #6b97e8;">shape</span><span style="color: #e3e11d;">[</span><span>-</span><span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">]:],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">])</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>The Declaration of Independence was signed on July 4, 1776.</p><p>What was the date of the signing of the Declaration of Independence?</p><p>The Declaration of Independence was signed on July 4,</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Como podemos ver, ela gera a partida errada, pois, embora seja comemorada em 4 de julho, na verdade foi assinada em [2 de julho] (https://education.nationalgeographic.org/resource/signing-declaration-independence/).</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Vamos experimentar o DoLa agora</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">dola_high_output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">inputs</span><span style="color: #e3e11d;">,</span> <span>**</span><span style="color: #6b97e8;">generate_kwargs</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">dola_layers</span><span>=</span><span style="color: #8d783e;">&#39;high&#39;</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">repetition_penalty</span><span>=</span><span style="color: #a09e19;">1.2</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">batch_decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">dola_high_output</span><span style="color: #e3e11d;">[:,</span> <span style="color: #6b97e8;">inputs</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span>.</span><span style="color: #6b97e8;">shape</span><span style="color: #e3e11d;">[</span><span>-</span><span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">]:],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">])</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>July 4, 1776. This is the most well-known date in U.S. history. The day has been celebrated with parades, barbeques, fireworks and festivals for hundreds of years.</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Ele ainda não gera a saída correta, portanto, vamos instruí-lo a contrastar apenas a camada final com as camadas 28 e 30.</p>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing code_cell rendered">
				<div class="input">
					<div class="prompt input_prompt" style="margin-left: 20px;">Code:</div>
					<div class="inner_cell">
						<div class="input_area">
							<div class=" highlight hl-python3">
								<pre class="python" style="margin-left: 40px; line-height: 0%;font-family:monospace;">
<p><span style="color: #6b97e8;">dola_high_output</span> <span>=</span> <span style="color: #6b97e8;">model</span><span>.</span><span style="color: #6b97e8;">generate</span><span style="color: #e3e11d;">(</span><span>**</span><span style="color: #6b97e8;">inputs</span><span style="color: #e3e11d;">,</span> <span>**</span><span style="color: #6b97e8;">generate_kwargs</span><span style="color: #e3e11d;">,</span> <span style="color: #6b97e8;">dola_layers</span><span>=</span><span style="color: #e3e11d;">[</span><span style="color: #7e7a38;">28</span><span style="color: #e3e11d;">,</span><span style="color: #7e7a38;">30</span><span style="color: #e3e11d;">],</span> <span style="color: #6b97e8;">repetition_penalty</span><span>=</span><span style="color: #a09e19;">1.2</span><span style="color: #e3e11d;">)</span></p>
<p></p>
<p><span style="color: #dfd84a;">print</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">tokenizer</span><span>.</span><span style="color: #6b97e8;">batch_decode</span><span style="color: #e3e11d;">(</span><span style="color: #6b97e8;">dola_high_output</span><span style="color: #e3e11d;">[:,</span> <span style="color: #6b97e8;">inputs</span><span>.</span><span style="color: #6b97e8;">input_ids</span><span>.</span><span style="color: #6b97e8;">shape</span><span style="color: #e3e11d;">[</span><span>-</span><span style="color: #7e7a38;">1</span><span style="color: #e3e11d;">]:],</span> <span style="color: #6b97e8;">skip_special_tokens</span><span>=</span><span style="color: #7f6e38;">True</span><span style="color: #e3e11d;">)[</span><span style="color: #7e7a38;">0</span><span style="color: #e3e11d;">])</span></p>
								</pre>
							</div>
						</div>
					</div>
				</div>
				<div class="output_wrapper">
					<div class="output">
						<div class="output_area">
							<div class="prompt" style="margin-left: 20px;">Output:</div>
							<div class="output_subarea output_stream output_stdout output_text">
								<pre style="margin-left: 60px; line-height: 0%;"><p>It was officially signed on 2 August 1776, when 56 members of the Second Continental Congress put their John Hancocks to the Declaration. The 2-page document had been written in 17</p></pre>
							</div>
						</div>
					</div>
				</div>
			</div>
			<div class="cell border-box-sizing text_cell rendered">
				<div class="prompt input_prompt">
					<div class="inner_cell">
						<div class="text_cell_render border-box-sizing rendered_html">
							<p style="margin-left: 0px;">Agora, ele consegue gerar a resposta correta</p>
						</div>
					</div>
				</div>
			</div>
		</div>
	<!-- Close class contenido -->
	</div>
<!-- Close div notebook container -->
</div>
<!-- Close div notebook -->
</div>

