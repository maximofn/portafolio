<section class="section-block-markdown-cell">
<h1 id="Hugging-Face-Inference-Providers">Hugging Face Inference Providers<a class="anchor-link" href="#Hugging-Face-Inference-Providers">¶</a></h1>
</section>
<section class="section-block-markdown-cell">
<p>Está claro que el mayor hub de modelos de inteligencia artificial es Hugging Face. Y ahora están dando la posibilidad de hacer inferencia de alguno de sus modelos en proveedores de GPUs serverless</p>
</section>
<section class="section-block-markdown-cell">
<p>Uno de esos modelos es <a href="https://huggingface.co/Wan-AI/Wan2.1-T2V-14B">Wan-AI/Wan2.1-T2V-14B</a> que a día de escribir este post es el mejor modelo de generación de vídeo open source, como se puede ver en la <a href="https://artificialanalysis.ai/text-to-video/arena?tab=Leaderboard">Artificial Analysis Video Generation Arena Leaderboard</a></p>
<p><img alt="video generation arena leaderboard" src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/Video-arena-leaderboard-wan21.webp"/></p>
</section>
<section class="section-block-markdown-cell">
<p>Si nos fijamos en su <a href="https://huggingface.co/Wan-AI/Wan2.1-T2V-14B">modelcard</a> podemos ver a la derecha un botón que pone <code>Replicate</code>.</p>
<p><img alt="Wan2.1-T2V-14B modelcard" src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/Wan2.1-T2V-14B.webp"/></p>
</section>
<section class="section-block-markdown-cell">
<h2 id="Inference-providers">Inference providers<a class="anchor-link" href="#Inference-providers">¶</a></h2>
</section>
<section class="section-block-markdown-cell">
<p>Si vamos a la página de configuración de los <a href="https://huggingface.co/settings/inference-providers">Inference providers</a> veremos algo como esto</p>
<p><img alt="Inference Providers" src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/Inference%20Providers.webp"/></p>
<p>Dónde podemos darle al botón con una llave para introducir la API KEY del proveedor que queramos usar, o dejar seleccionado el camino con dos puntos. Si hacemos la primera opción será el proveedor el que nos cobre por la inferencia, mientras que en el segundo será Hugging Face quien nos cobre la inferencia. Así que haz lo que mejor te convenga</p>
</section>
<section class="section-block-markdown-cell">
<h2 id="Inferencia-con-Replicate">Inferencia con Replicate<a class="anchor-link" href="#Inferencia-con-Replicate">¶</a></h2>
</section>
<section class="section-block-markdown-cell">
<p>En mi caso he obtenido una API KEY de Replicate y la he introducido en un archivo llamado <code>.env</code> que es donde guardaré las API KEYS y que no debes subir a GitHub, GitLab o el repositorio de tu proyecto.</p>
<p>El <code>.env</code> tiene que tener este formato</p>
<div class="highlight"><pre><span></span><span class="n">HUGGINGFACE_TOKEN_INFERENCE_PROVIDERS</span><span class="o">=</span><span class="s2">"hf_aL...AY"</span>
<span class="n">REPLICATE_API_KEY</span><span class="o">=</span><span class="s2">"r8_Sh...UD"</span>
</pre></div>
<p>Donde <code>HUGGINGFACE_TOKEN_INFERENCE_PROVIDERS</code> es un token que tienes que obtener desde <a href="https://huggingface.co/settings/tokens">Hugging Face</a> y <code>REPLICATE_API_KEY</code> es la API KEY de Replicate que puedes obtener desde <a href="https://replicate.com/account/api-tokens">Replicate</a>.</p>
</section>
<section class="section-block-markdown-cell">
<h3 id="Lectura-de-las-API-Keys">Lectura de las API Keys<a class="anchor-link" href="#Lectura-de-las-API-Keys">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Lo primero que tenemos que hacer es leer las API KEYS desde el archivo <code>.env</code></p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">dotenv</span>
<span class="n">dotenv</span><span class="o">.</span><span class="n">load_dotenv</span><span class="p">()</span>

<span class="n">REPLICATE_API_KEY</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">"REPLICATE_API_KEY"</span><span class="p">)</span>
<span class="n">HUGGINGFACE_TOKEN_INFERENCE_PROVIDERS</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">"HUGGINGFACE_TOKEN_INFERENCE_PROVIDERS"</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Logging-en-el-hub-de-Hugging-Face">Logging en el hub de Hugging Face<a class="anchor-link" href="#Logging-en-el-hub-de-Hugging-Face">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Para poder usar el modelo de Wan-AI/Wan2.1-T2V-14B, como está en el hub de Hugging Face, necesitamos loguearnos.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">huggingface_hub</span> <span class="kn">import</span> <span class="n">login</span>
<span class="n">login</span><span class="p">(</span><span class="n">HUGGINGFACE_TOKEN_INFERENCE_PROVIDERS</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Cliente-de-Inferencia">Cliente de Inferencia<a class="anchor-link" href="#Cliente-de-Inferencia">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Ahora creamos un cliente de inferencia, tenemos que especificar el proveedor, la API KEY y en este caso, además, vamos a establecer un tiempo de <code>timeout</code> de 1000 segundos, porque por defecto es de 60 segundos y el modelo tarda bastante en generar el vídeo.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">huggingface_hub</span> <span class="kn">import</span> <span class="n">InferenceClient</span>

<span class="n">client</span> <span class="o">=</span> <span class="n">InferenceClient</span><span class="p">(</span>
	<span class="n">provider</span><span class="o">=</span><span class="s2">"replicate"</span><span class="p">,</span>
	<span class="n">api_key</span><span class="o">=</span><span class="n">REPLICATE_API_KEY</span><span class="p">,</span>
	<span class="n">timeout</span><span class="o">=</span><span class="mi">1000</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Generaci%C3%B3n-del-v%C3%ADdeo">Generación del vídeo<a class="anchor-link" href="#Generaci%C3%B3n-del-v%C3%ADdeo">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Ya tenemos todo para generar nuestro video. Usamos el método <code>text_to_video</code> del cliente, le pasamos el prompt y le decimos cuál modelo del hub queremos usar, si no usará el que está por defecto.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">video</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">text_to_video</span><span class="p">(</span>
	<span class="s2">"Funky dancer, dancing in a rehearsal room. She wears long hair that moves to the rhythm of her dance."</span><span class="p">,</span>
	<span class="n">model</span><span class="o">=</span><span class="s2">"Wan-AI/Wan2.1-T2V-14B"</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<h3 id="Guardando-el-v%C3%ADdeo">Guardando el vídeo<a class="anchor-link" href="#Guardando-el-v%C3%ADdeo">¶</a></h3>
</section>
<section class="section-block-markdown-cell">
<p>Por último guardamos el video, que es de tipo <code>bytes</code>, en un fichero en nuestro disco</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">output_path</span> <span class="o">=</span> <span class="s2">"output_video.mp4"</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="s2">"wb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">video</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Video saved to: </span><span class="si">{</span><span class="n">output_path</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Video saved to: output_video.mp4
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<h2 id="Video-generado">Video generado<a class="anchor-link" href="#Video-generado">¶</a></h2>
</section>
<section class="section-block-markdown-cell">
<p>Este es el video generado por el modelo</p>
<p><video controls="" src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/wan2_1_video.webm"></video></p>
</section>
