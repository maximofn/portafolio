<section class="section-block-markdown-cell">
<h1 id="FastRTC:-La-Biblioteca-de-Comunicaci%C3%B3n-en-Tiempo-Real-para-Python">FastRTC: La Biblioteca de Comunicaci√≥n en Tiempo Real para Python<a class="anchor-link" href="#FastRTC:-La-Biblioteca-de-Comunicaci%C3%B3n-en-Tiempo-Real-para-Python">¬∂</a></h1>
</section>
<section class="section-block-markdown-cell">
<p>En los √∫ltimos meses, hemos visto un gran avance en modelos de voz en tiempo real, con empresas enteras fundadas alrededor de modelos tanto de c√≥digo abierto como cerrado. Algunos hitos importantes incluyen:</p>
<ul>
<li><code>OpenAI</code> y <code>Google</code> lanzaron sus APIs multimodales en vivo para ChatGPT y Gemini. ¬°OpenAI incluso lanz√≥ un n√∫mero de tel√©fono <code>1-800-ChatGPT</code>!</li>
<li><code>Kyutai</code> lanz√≥ <a href="https://huggingface.co/kyutai">Moshi</a>, un LLM de audio a audio completamente de c√≥digo abierto.</li>
<li><code>Alibaba</code> lanz√≥ <a href="https://huggingface.co/Qwen/Qwen2-Audio-7B-Instruct">Qwen2-Audio</a>, un LLM de c√≥digo abierto que entiende audio de forma nativa.</li>
<li><code>Fixie.ai</code> lanz√≥ <a href="https://huggingface.co/fixie-ai/ultravox-v0_5-llama-3_3-70b">Ultravox</a>, otro LLM de c√≥digo abierto que tambi√©n entiende audio de forma nativa.</li>
<li><code>ElevenLabs</code> recaud√≥ 180 millones de d√≥lares en su Serie C.</li>
</ul>
</section>
<section class="section-block-markdown-cell">
<p>A pesar de esta explosi√≥n en modelos y financiaci√≥n, sigue siendo dif√≠cil construir aplicaciones de IA en tiempo real que transmitan audio y video, especialmente en Python.</p>
<ul>
<li>Los ingenieros de ML pueden no tener experiencia con las tecnolog√≠as necesarias para construir aplicaciones en tiempo real, como <code>WebRTC</code>.</li>
<li>Incluso herramientas de asistencia de c√≥digo como <code>Cursor</code> y <code>Copilot</code> tienen dificultades para escribir c√≥digo Python que soporte aplicaciones de audio/video en tiempo real.</li>
</ul>
<p>Por eso es emocionante el anuncio de <code>FastRTC</code>, la biblioteca de comunicaci√≥n en tiempo real para Python. ¬°La biblioteca est√° dise√±ada para facilitar la construcci√≥n de aplicaciones de IA de audio y video en tiempo real completamente en Python!</p>
</section>
<section class="section-block-markdown-cell">
<h2 id="Caracter%C3%ADsticas-principales-de-FastRTC">Caracter√≠sticas principales de FastRTC<a class="anchor-link" href="#Caracter%C3%ADsticas-principales-de-FastRTC">¬∂</a></h2>
</section>
<section class="section-block-markdown-cell">
<ul>
<li>üó£Ô∏è Detecci√≥n de voz autom√°tica y toma de turnos incorporada, para que solo tengas que preocuparte por la l√≥gica de respuesta al usuario.</li>
<li>üíª UI autom√°tica - UI de Gradio habilitada para WebRTC incorporada para pruebas (¬°o despliegue a producci√≥n!).</li>
<li>üìû Llamada por tel√©fono - Usa <code>fastphone()</code> para obtener un n√∫mero de tel√©fono <strong>gratuito</strong> para llamar a tu stream de audio (se requiere un token HF).</li>
<li>‚ö°Ô∏è Soporte para <code>WebRTC</code> y <code>Websocket</code>.</li>
<li>üí™ Personalizable - Puedes montar el stream en cualquier aplicaci√≥n <code>FastAPI</code> para servir una UI personalizada y desplegar m√°s all√° de <code>Gradio</code>.</li>
<li>üß∞ Muchas utilidades para <code>text-to-speech</code>, <code>speech-to-text</code>, <code>detecci√≥n de parada</code> para ayudarte a comenzar.</li>
</ul>
</section>
<section class="section-block-markdown-cell">
<h2 id="Instalaci%C3%B3n">Instalaci√≥n<a class="anchor-link" href="#Instalaci%C3%B3n">¬∂</a></h2>
</section>
<section class="section-block-markdown-cell">
<p>Para poder usar <code>FastRTC</code>, primero necesitas instalar la biblioteca:</p>
<div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>fastrtc
</pre></div>
<p>Pero si queremos instalar las funcionalidades de detecci√≥n de pausa, speech-to-text y text-to-speech, necesitamos instalar algunas dependencias adicionales:</p>
<div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span><span class="s2">"fastrtc[vad, stt, tts]"</span>
</pre></div>
</section>
<section class="section-block-markdown-cell">
<h2 id="Primeros-pasos">Primeros pasos<a class="anchor-link" href="#Primeros-pasos">¬∂</a></h2>
</section>
<section class="section-block-markdown-cell">
<p>Empezaremos construyendo el <code>hola mundo</code> del audio en tiempo real: hacer eco de lo que dice el usuario. En <code>FastRTC</code>, esto es tan simple como:</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">fastrtc</span> <span class="kn">import</span> <span class="n">Stream</span><span class="p">,</span> <span class="n">ReplyOnPause</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">echo</span><span class="p">(</span><span class="n">audio</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
    <span class="k">yield</span> <span class="n">audio</span>

<span class="n">stream</span> <span class="o">=</span> <span class="n">Stream</span><span class="p">(</span><span class="n">ReplyOnPause</span><span class="p">(</span><span class="n">echo</span><span class="p">),</span> <span class="n">modality</span><span class="o">=</span><span class="s2">"audio"</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">"send-receive"</span><span class="p">)</span>
<span class="n">stream</span><span class="o">.</span><span class="n">ui</span><span class="o">.</span><span class="n">launch</span><span class="p">()</span>
</pre></div>
</div>
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>* Running on local URL:  http://127.0.0.1:7872

To create a public link, set `share=True` in `launch()`.
</pre>
</div>
</div>
<div class="output-area">
<div class="prompt"></div>
<div class="output-html-rendered-html-output-subarea"><div><iframe allow="autoplay; camera; microphone; clipboard-read; clipboard-write;" allowfullscreen="" frameborder="0" height="500" src="http://127.0.0.1:7872/" width="100%"></iframe></div></div>
</div>
<div class="output-area">
<div class="prompt-output-prompt">Out[15]:</div>
<div class="output-text-output-subareaoutput_execute_result">
<pre></pre>
</div>
</div>
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>INFO:     127.0.0.1:58223 - "GET / HTTP/1.1" 200 OK
INFO:     127.0.0.1:58223 - "GET /assets/index-C7PS0jJm.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58225 - "GET /assets/index-Bo0Yq5bb.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58223 - "GET /assets/svelte/svelte.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58225 - "GET /assets/Embed-FUIL71FR.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58223 - "GET /assets/Index-wMEhc4G9.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58228 - "GET /assets/StreamingBar-DOagx4HU.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58227 - "GET /assets/index-B1gfMDT9.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58230 - "GET /assets/IconButtonWrapper-EOzMzU45.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58229 - "GET /assets/StreamingBar.svelte_svelte_type_style_lang-CDNxkBIr.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58225 - "GET /assets/MarkdownCode-DPiWQnAx.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58223 - "GET /assets/DownloadLink-CqD3Uu0l.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58227 - "GET /assets/IconButtonWrapper.svelte_svelte_type_style_lang-BOpxTcdu.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58229 - "GET /assets/prism-python-qapVsvY8.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58228 - "GET /assets/Index-BJ_RfjVB.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58230 - "GET /assets/MarkdownCode.svelte_svelte_type_style_lang-3tofWDHK.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58225 - "GET /assets/IconButton-B-aAVSzy.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58229 - "GET /assets/Clear-By3xiIwg.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58228 - "GET /assets/context-TgWPFwN2.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58230 - "GET /theme.css?v=63194d3741d384f9f85db890247b6c0ef9e7abac0f297f40a15c59fe4baba916 HTTP/1.1" 200 OK
INFO:     127.0.0.1:58228 - "GET /assets/Button-BWSOH8Qq.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58225 - "GET /assets/Image-CsmDAdIf.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58229 - "GET /assets/Blocks-E57YC_S0.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58227 - "GET /assets/Button-DTh9AgeE.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58223 - "GET /assets/Image-B8dFOee4.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58230 - "GET /assets/ImagePreview-DJhr8Mfv.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58223 - "GET /assets/file-url-DgijyRSD.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58225 - "GET /assets/Dropdown-CWxB-qJp.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58228 - "GET /assets/Example-D7K5RtQ2.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58227 - "GET /assets/Blocks-B5wxaDIo.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58229 - "GET /assets/Dropdown-DjrBHETv.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58230 - "GET /assets/Block-DZqtZLFP.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58228 - "GET /assets/BlockTitle-BIcnzvtg.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58225 - "GET /assets/index-CvpmwOJi.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58223 - "GET /assets/MarkdownCode-DJM7o_VY.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58230 - "GET /assets/Info-DcCn6tHi.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58227 - "GET /assets/DropdownArrow-dYuMZY9s.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58229 - "GET /assets/Toast-DdWZrg4w.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58230 - "GET /assets/utils-BsGrhMNe.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58223 - "GET /gradio_api/custom_component/91a0d0cc3e6164063c775a057aff53510cb8fc04c8b99d010e09ce4ba9beb99d/client/component/style.css HTTP/1.1" 304 Not Modified
INFO:     127.0.0.1:58230 - "GET /assets/Index-ChJkSByh.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58227 - "GET /assets/Index-CfowPFmo.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58228 - "GET /assets/Index-CptIZeFZ.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58229 - "GET /assets/Index-Csm0OGa9.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58225 - "GET /assets/Index-Cgj6KPvj.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58223 - "GET /assets/Code-DGNrTu_I.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58225 - "GET /gradio_api/custom_component/91a0d0cc3e6164063c775a057aff53510cb8fc04c8b99d010e09ce4ba9beb99d/client/component/index.js HTTP/1.1" 304 Not Modified
INFO:     127.0.0.1:58228 - "GET /assets/Index-HXWviefR.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58229 - "GET /assets/Index-WEzAIkMk.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58230 - "GET /assets/BlockLabel-DqHge3FF.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58227 - "GET /assets/Index-CRGGsrTx.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58241 - "GET / HTTP/1.1" 200 OK
INFO:     127.0.0.1:58241 - "GET /theme.css?v=63194d3741d384f9f85db890247b6c0ef9e7abac0f297f40a15c59fe4baba916 HTTP/1.1" 200 OK
INFO:     127.0.0.1:58241 - "GET /gradio_api/custom_component/91a0d0cc3e6164063c775a057aff53510cb8fc04c8b99d010e09ce4ba9beb99d/client/component/style.css HTTP/1.1" 304 Not Modified
INFO:     127.0.0.1:58244 - "GET /gradio_api/custom_component/91a0d0cc3e6164063c775a057aff53510cb8fc04c8b99d010e09ce4ba9beb99d/client/component/index.js HTTP/1.1" 304 Not Modified
INFO:     127.0.0.1:58260 - "GET /static/fonts/ui-sans-serif/ui-sans-serif-Bold.woff2 HTTP/1.1" 404 Not Found
INFO:     127.0.0.1:58260 - "GET /static/fonts/system-ui/system-ui-Bold.woff2 HTTP/1.1" 404 Not Found
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Cuando vamos al enlace que nos sugiere Gradio, primero tenemos que dar permisos al navegador para acceder al micr√≥fono. A continuaci√≥n nos aparecer√° esto</p>
<p><img alt="fastrct - hello world - init" src="https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/fastRTC%20-%20hello%20world%20-%20init.webp"/></p>
</section>
<section class="section-block-markdown-cell">
<p>Si pinchamos en la pesta√±a de la derecha de la palabra <code>Record</code> podemos seleccionar el micr√≥fono que queremos usar.</p>
</section>
<section class="section-block-markdown-cell">
<p>A continuaci√≥n si pulsamos en el bot√≥n de <code>Record</code>, todo lo que digamos, la aplicaci√≥n lo repetir√°. Es decir captura el audio, detecta cuando hemos dejado de hablar y lo repite.</p>
</section>
<section class="section-block-markdown-cell">
<p>Vamos a desglosarlo:</p>
<ul>
<li><code>ReplyOnPause</code> manejar√° la detecci√≥n de voz y la toma de turnos por ti. Solo tienes que preocuparte por la l√≥gica para responder al usuario. Hay que pasarle la funci√≥n que se encargar√° de gestionar el audio de entrada. En nuestro caso es la funci√≥n <code>echo</code>, que captura el audio de entrada y lo devuelve en stream mediante el uso de <code>yield</code>, que mucha gente no conoce, pero es un generador, es decir, es un m√©todo de python para crear iteradores. Si quieres saber m√°s sobre <code>yield</code> puedes leer mi post de <a href="https://www.maximofn.com/python#6.5.-Generadores">Python</a>. Cualquier generador que devuelva una tupla de audio (representada como <code>(sample_rate, audio_data)</code>) funcionar√°.</li>
<li>La clase <code>Stream</code> construir√° una UI de Gradio para que puedas probar r√°pidamente tu stream. Una vez que hayas terminado de prototipar, puedes desplegar tu Stream como una aplicaci√≥n FastAPI lista para producci√≥n en una sola l√≠nea de c√≥digo</li>
</ul>
</section>
<section class="section-block-markdown-cell">
<p>Aqu√≠ podemos ver un ejemplo de los creadores de <code>FastRTC</code></p>
<p><video controls="" src="https://github.com/user-attachments/assets/fcf2d30e-3e98-47c9-8dc3-23340784c441"></video></p>
</section>
<section class="section-block-markdown-cell">
<h2 id="Subiendo-de-nivel:-Chat-de-voz-con-LLM">Subiendo de nivel: Chat de voz con LLM<a class="anchor-link" href="#Subiendo-de-nivel:-Chat-de-voz-con-LLM">¬∂</a></h2>
</section>
<section class="section-block-markdown-cell">
<p>El siguiente nivel es usar un LLM para responder al usuario. <code>FastRTC</code> viene con capacidades de <code>speech-to-text</code> y <code>text-to-speech</code> incorporadas, por lo que trabajar con LLMs es realmente f√°cil. Vamos a cambiar nuestra funci√≥n <code>echo</code> en consecuencia:</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">fastrtc</span> <span class="kn">import</span> <span class="n">ReplyOnPause</span><span class="p">,</span> <span class="n">Stream</span><span class="p">,</span> <span class="n">get_stt_model</span><span class="p">,</span> <span class="n">get_tts_model</span>
<span class="kn">from</span> <span class="nn">gradio_client</span> <span class="kn">import</span> <span class="n">Client</span>

<span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="s2">"Maximofn/SmolLM2_localModel"</span><span class="p">)</span>
<span class="n">stt_model</span> <span class="o">=</span> <span class="n">get_stt_model</span><span class="p">()</span>
<span class="n">tts_model</span> <span class="o">=</span> <span class="n">get_tts_model</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">echo</span><span class="p">(</span><span class="n">audio</span><span class="p">):</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="n">stt_model</span><span class="o">.</span><span class="n">stt</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
            <span class="n">message</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
            <span class="n">system_message</span><span class="o">=</span><span class="s2">"You are a friendly Chatbot. Always reply in the language in which the user is writing to you."</span><span class="p">,</span>
            <span class="n">max_tokens</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
            <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
            <span class="n">top_p</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span>
            <span class="n">api_name</span><span class="o">=</span><span class="s2">"/chat"</span>
    <span class="p">)</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="n">response</span>
    <span class="k">for</span> <span class="n">audio_chunk</span> <span class="ow">in</span> <span class="n">tts_model</span><span class="o">.</span><span class="n">stream_tts_sync</span><span class="p">(</span><span class="n">prompt</span><span class="p">):</span>
        <span class="k">yield</span> <span class="n">audio_chunk</span>

<span class="n">stream</span> <span class="o">=</span> <span class="n">Stream</span><span class="p">(</span><span class="n">ReplyOnPause</span><span class="p">(</span><span class="n">echo</span><span class="p">),</span> <span class="n">modality</span><span class="o">=</span><span class="s2">"audio"</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">"send-receive"</span><span class="p">)</span>
<span class="n">stream</span><span class="o">.</span><span class="n">ui</span><span class="o">.</span><span class="n">launch</span><span class="p">()</span>
</pre></div>
</div>
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Loaded as API: https://maximofn-smollm2-localmodel.hf.space ‚úî
* Running on local URL:  http://127.0.0.1:7871

To create a public link, set `share=True` in `launch()`.
</pre>
</div>
</div>
<div class="output-area">
<div class="prompt"></div>
<div class="output-html-rendered-html-output-subarea"><div><iframe allow="autoplay; camera; microphone; clipboard-read; clipboard-write;" allowfullscreen="" frameborder="0" height="500" src="http://127.0.0.1:7871/" width="100%"></iframe></div></div>
</div>
<div class="output-area">
<div class="prompt-output-prompt">Out[14]:</div>
<div class="output-text-output-subareaoutput_execute_result">
<pre></pre>
</div>
</div>
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>INFO:     127.0.0.1:58224 - "GET / HTTP/1.1" 200 OK
INFO:     127.0.0.1:58224 - "GET /assets/index-Bo0Yq5bb.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58226 - "GET /assets/index-C7PS0jJm.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58226 - "GET /assets/svelte/svelte.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58226 - "GET /assets/Index-wMEhc4G9.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58232 - "GET /assets/StreamingBar-DOagx4HU.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58234 - "GET /assets/IconButtonWrapper-EOzMzU45.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58224 - "GET /assets/Embed-FUIL71FR.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58233 - "GET /assets/StreamingBar.svelte_svelte_type_style_lang-CDNxkBIr.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58231 - "GET /assets/index-B1gfMDT9.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58231 - "GET /assets/MarkdownCode-DPiWQnAx.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58224 - "GET /assets/MarkdownCode.svelte_svelte_type_style_lang-3tofWDHK.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58233 - "GET /assets/Index-BJ_RfjVB.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58232 - "GET /assets/DownloadLink-CqD3Uu0l.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58234 - "GET /assets/IconButtonWrapper.svelte_svelte_type_style_lang-BOpxTcdu.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58226 - "GET /assets/prism-python-qapVsvY8.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58231 - "GET /assets/IconButton-B-aAVSzy.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58233 - "GET /assets/Clear-By3xiIwg.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58234 - "GET /assets/context-TgWPFwN2.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58224 - "GET /theme.css?v=63194d3741d384f9f85db890247b6c0ef9e7abac0f297f40a15c59fe4baba916 HTTP/1.1" 200 OK
INFO:     127.0.0.1:58234 - "GET /assets/Blocks-E57YC_S0.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58231 - "GET /assets/Image-B8dFOee4.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58226 - "GET /assets/ImagePreview-DJhr8Mfv.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58233 - "GET /assets/Button-BWSOH8Qq.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58232 - "GET /assets/Button-DTh9AgeE.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58224 - "GET /assets/Dropdown-CWxB-qJp.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58232 - "GET /assets/Image-CsmDAdIf.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58226 - "GET /assets/Blocks-B5wxaDIo.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58233 - "GET /assets/Example-D7K5RtQ2.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58234 - "GET /assets/Block-DZqtZLFP.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58231 - "GET /assets/file-url-DgijyRSD.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58224 - "GET /assets/Info-DcCn6tHi.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58232 - "GET /assets/MarkdownCode-DJM7o_VY.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58234 - "GET /assets/Dropdown-DjrBHETv.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58233 - "GET /assets/index-CvpmwOJi.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58226 - "GET /assets/BlockTitle-BIcnzvtg.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58231 - "GET /assets/DropdownArrow-dYuMZY9s.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58224 - "GET /assets/Toast-DdWZrg4w.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58234 - "GET /assets/utils-BsGrhMNe.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58232 - "GET /assets/Index-CfowPFmo.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58234 - "GET /assets/Index-ChJkSByh.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58224 - "GET /assets/Code-DGNrTu_I.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58226 - "GET /assets/Index-Csm0OGa9.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58233 - "GET /assets/Index-HXWviefR.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58231 - "GET /assets/BlockLabel-DqHge3FF.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58224 - "GET /gradio_api/custom_component/91a0d0cc3e6164063c775a057aff53510cb8fc04c8b99d010e09ce4ba9beb99d/client/component/style.css HTTP/1.1" 304 Not Modified
INFO:     127.0.0.1:58231 - "GET /assets/Index-Cgj6KPvj.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58233 - "GET /gradio_api/custom_component/91a0d0cc3e6164063c775a057aff53510cb8fc04c8b99d010e09ce4ba9beb99d/client/component/index.js HTTP/1.1" 304 Not Modified
INFO:     127.0.0.1:58226 - "GET /assets/Index-CptIZeFZ.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58232 - "GET /assets/Index-CRGGsrTx.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58234 - "GET /assets/Index-WEzAIkMk.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58242 - "GET / HTTP/1.1" 200 OK
INFO:     127.0.0.1:58242 - "GET /theme.css?v=63194d3741d384f9f85db890247b6c0ef9e7abac0f297f40a15c59fe4baba916 HTTP/1.1" 200 OK
INFO:     127.0.0.1:58242 - "GET /gradio_api/custom_component/91a0d0cc3e6164063c775a057aff53510cb8fc04c8b99d010e09ce4ba9beb99d/client/component/style.css HTTP/1.1" 304 Not Modified
INFO:     127.0.0.1:58243 - "GET /gradio_api/custom_component/91a0d0cc3e6164063c775a057aff53510cb8fc04c8b99d010e09ce4ba9beb99d/client/component/index.js HTTP/1.1" 304 Not Modified
INFO:     127.0.0.1:58250 - "GET /static/fonts/ui-sans-serif/ui-sans-serif-Bold.woff2 HTTP/1.1" 404 Not Found
INFO:     127.0.0.1:58250 - "GET /static/fonts/system-ui/system-ui-Bold.woff2 HTTP/1.1" 404 Not Found
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Como modelo de <code>speech-to-text</code> usa <code>Moonshine</code> que supuestamente solo soporta ingl√©s, pero lo he probado en espa√±ol y me entiende bien.</p>
</section>
<section class="section-block-markdown-cell">
<p>Como modelo de lenguaje vamos a usar el modelo que desplegu√© en un backend en Hugging Face y que escrib√≠ en el post <a href="https://www.maximofn.com/deploy-backend-with-llm-in-huggingface">Desplegar backend con LLM en HuggingFace</a>. Utiliza el LLM <code>HuggingFaceTB/SmolLM2-1.7B-Instruct</code> que es un modelo peque√±o, ya que est√° corriendo en un backend con CPU, pero que funciona bastante bien.</p>
</section>
<section class="section-block-markdown-cell">
<p>Como modelo de <code>text-to-speech</code> usa <code>Kokoro</code> que s√≠ tiene opciones de hablar en otros idiomas, pero que de momento en la librer√≠a de <code>FastRTC</code> de momento no est√° implementado.</p>
</section>
<section class="section-block-markdown-cell">
<p>Si nos interesa mucho usar modelos de <code>speech-to-speech</code> y <code>text-to-speech</code> en otros idiomas, podr√≠amos implementarlos nosotros mismos, porque el mayor potencial de <code>FastRTC</code> est√° en la capa de comunicaci√≥n en tiempo real, pero no me voy a meter en eso ahora.</p>
</section>
<section class="section-block-markdown-cell">
<p>Ahora s√≠ probamos el c√≥digo que acabamos de escribir podemos tener un chatbot, por voz en tiempo real.</p>
</section>
<section class="section-block-markdown-cell">
<h2 id="Llamada-por-tel%C3%A9fono">Llamada por tel√©fono<a class="anchor-link" href="#Llamada-por-tel%C3%A9fono">¬∂</a></h2><p>Si en lugar de <code>stream.ui.launch()</code>, llamas a <code>stream.fastphone()</code>, obtendr√°s un n√∫mero de tel√©fono gratuito para llamar a tu stream. Ten en cuenta que se requiere un token de Hugging Face.</p>
<p>Generamos un script, porque en un Jupyter Notebook no siempre funciona</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%writefile</span> fastrtc_phone_demo.py

<span class="kn">from</span> <span class="nn">fastrtc</span> <span class="kn">import</span> <span class="n">ReplyOnPause</span><span class="p">,</span> <span class="n">Stream</span><span class="p">,</span> <span class="n">get_stt_model</span><span class="p">,</span> <span class="n">get_tts_model</span>
<span class="kn">import</span> <span class="nn">gradio</span>
<span class="kn">from</span> <span class="nn">gradio_client</span> <span class="kn">import</span> <span class="n">Client</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">gradio.networking</span> <span class="kn">import</span> <span class="n">setup_tunnel</span> <span class="k">as</span> <span class="n">original_setup_tunnel</span>
<span class="kn">import</span> <span class="nn">socket</span>

<span class="c1"># Monkey patch setup_tunnel para que acepte el par√°metro adicional</span>
<span class="k">def</span> <span class="nf">patched_setup_tunnel</span><span class="p">(</span><span class="n">host</span><span class="p">,</span> <span class="n">port</span><span class="p">,</span> <span class="n">share_token</span><span class="p">,</span> <span class="n">share_server_address</span><span class="p">,</span> <span class="n">share_server_tls_certificate</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">original_setup_tunnel</span><span class="p">(</span><span class="n">host</span><span class="p">,</span> <span class="n">port</span><span class="p">,</span> <span class="n">share_token</span><span class="p">,</span> <span class="n">share_server_address</span><span class="p">,</span> <span class="n">share_server_tls_certificate</span><span class="p">)</span>

<span class="c1"># Replace the original function with our patched version</span>
<span class="n">gradio</span><span class="o">.</span><span class="n">networking</span><span class="o">.</span><span class="n">setup_tunnel</span> <span class="o">=</span> <span class="n">patched_setup_tunnel</span>

<span class="c1"># Get the token from the environment variable</span>
<span class="n">HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">"HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN"</span><span class="p">)</span>

<span class="c1"># Initialize the LLM client</span>
<span class="n">llm_client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="s2">"Maximofn/SmolLM2_localModel"</span><span class="p">)</span>

<span class="c1"># Initialize the STT and TTS models</span>
<span class="n">stt_model</span> <span class="o">=</span> <span class="n">get_stt_model</span><span class="p">()</span>
<span class="n">tts_model</span> <span class="o">=</span> <span class="n">get_tts_model</span><span class="p">()</span>

<span class="c1"># Define the echo function</span>
<span class="k">def</span> <span class="nf">echo</span><span class="p">(</span><span class="n">audio</span><span class="p">):</span>
    <span class="c1"># Convert the audio to text</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="n">stt_model</span><span class="o">.</span><span class="n">stt</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>

    <span class="c1"># Generate the response</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">llm_client</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
            <span class="n">message</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
            <span class="n">system_message</span><span class="o">=</span><span class="s2">"You are a friendly Chatbot. Always reply in the language in which the user is writing to you."</span><span class="p">,</span>
            <span class="n">max_tokens</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
            <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
            <span class="n">top_p</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span>
            <span class="n">api_name</span><span class="o">=</span><span class="s2">"/chat"</span>
    <span class="p">)</span>
    
    <span class="c1"># Convert the response to audio</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="n">response</span>

    <span class="c1"># Stream the audio</span>
    <span class="k">for</span> <span class="n">audio_chunk</span> <span class="ow">in</span> <span class="n">tts_model</span><span class="o">.</span><span class="n">stream_tts_sync</span><span class="p">(</span><span class="n">prompt</span><span class="p">):</span>
        <span class="k">yield</span> <span class="n">audio_chunk</span>

<span class="k">def</span> <span class="nf">find_free_port</span><span class="p">(</span><span class="n">start_port</span><span class="o">=</span><span class="mi">8000</span><span class="p">,</span> <span class="n">max_port</span><span class="o">=</span><span class="mi">9000</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Find the first free port starting from start_port."""</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Searching for a free port starting from </span><span class="si">{</span><span class="n">start_port</span><span class="si">}</span><span class="s2">..."</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">port</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_port</span><span class="p">,</span> <span class="n">max_port</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">socket</span><span class="o">.</span><span class="n">socket</span><span class="p">(</span><span class="n">socket</span><span class="o">.</span><span class="n">AF_INET</span><span class="p">,</span> <span class="n">socket</span><span class="o">.</span><span class="n">SOCK_STREAM</span><span class="p">)</span> <span class="k">as</span> <span class="n">sock</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">sock</span><span class="o">.</span><span class="n">connect_ex</span><span class="p">((</span><span class="s1">'127.0.0.1'</span><span class="p">,</span> <span class="n">port</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">result</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># If result != 0, the port is free</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Free port found: </span><span class="si">{</span><span class="n">port</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">port</span>
    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"No free port found between </span><span class="si">{</span><span class="n">start_port</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="n">max_port</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    
<span class="n">free_port</span> <span class="o">=</span> <span class="n">find_free_port</span><span class="p">()</span>    <span class="c1"># Search for a free port</span>

<span class="n">stream</span> <span class="o">=</span> <span class="n">Stream</span><span class="p">(</span><span class="n">ReplyOnPause</span><span class="p">(</span><span class="n">echo</span><span class="p">),</span> <span class="n">modality</span><span class="o">=</span><span class="s2">"audio"</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">"send-receive"</span><span class="p">)</span>
<span class="n">stream</span><span class="o">.</span><span class="n">fastphone</span><span class="p">(</span><span class="n">token</span><span class="o">=</span><span class="n">HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN</span><span class="p">,</span> <span class="n">port</span><span class="o">=</span><span class="n">free_port</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Explicamos el c√≥digo</p>
</section>
<section class="section-block-markdown-cell">
<p>La parte</p>
<pre><code class="language-pyhon">pyhon
# Monkey patch setup_tunnel para que acepte el par√°metro adicional
def patched_setup_tunnel(host, port, share_token, share_server_address, share_server_tls_certificate=None):
    return original_setup_tunnel(host, port, share_token, share_server_address, share_server_tls_certificate)

# Replace the original function with our patched version
gradio.networking.setup_tunnel = patched_setup_tunnel
</code></pre>
<p>Es necesario porque <code>FastRTC</code> est√° escrito para una versi√≥n antigua de <code>gradio</code> que no soporta el par√°metro <code>share_server_address</code> en el m√©todo <code>setup_tunnel</code>. As√≠ que lo parcheamos para que acepte el par√°metro adicional.</p>
</section>
<section class="section-block-markdown-cell">
<p>Como es necesario un token de Hugging Face, lo obtenemos de la variable de entorno <code>HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN</code>.</p>
<div class="highlight"><pre><span></span><span class="c1"># Get the token from the environment variable</span>
<span class="n">HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">"HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN"</span><span class="p">)</span>
</pre></div>
</section>
<section class="section-block-markdown-cell">
<p>A continuaci√≥n se crean los modelos de lenguaje, de <code>speech-to-text</code> y de <code>text-to-speech</code>, y creamos la funci√≥n <code>echo</code> que se encargar√° de gestionar el audio de entrada y salida.</p>
<div class="highlight"><pre><span></span><span class="c1"># Initialize the LLM client</span>
<span class="n">llm_client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="s2">"Maximofn/SmolLM2_localModel"</span><span class="p">)</span>

<span class="c1"># Initialize the STT and TTS models</span>
<span class="n">stt_model</span> <span class="o">=</span> <span class="n">get_stt_model</span><span class="p">()</span>
<span class="n">tts_model</span> <span class="o">=</span> <span class="n">get_tts_model</span><span class="p">()</span>

<span class="c1"># Define the echo function</span>
<span class="k">def</span> <span class="nf">echo</span><span class="p">(</span><span class="n">audio</span><span class="p">):</span>
    <span class="c1"># Convert the audio to text</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="n">stt_model</span><span class="o">.</span><span class="n">stt</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>

    <span class="c1"># Generate the response</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">llm_client</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
            <span class="n">message</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
            <span class="n">system_message</span><span class="o">=</span><span class="s2">"You are a friendly Chatbot. Always reply in the language in which the user is writing to you."</span><span class="p">,</span>
            <span class="n">max_tokens</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
            <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
            <span class="n">top_p</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span>
            <span class="n">api_name</span><span class="o">=</span><span class="s2">"/chat"</span>
    <span class="p">)</span>

    <span class="c1"># Convert the response to audio</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="n">response</span>

    <span class="c1"># Stream the audio</span>
    <span class="k">for</span> <span class="n">audio_chunk</span> <span class="ow">in</span> <span class="n">tts_model</span><span class="o">.</span><span class="n">stream_tts_sync</span><span class="p">(</span><span class="n">prompt</span><span class="p">):</span>
        <span class="k">yield</span> <span class="n">audio_chunk</span>
</pre></div>
</section>
<section class="section-block-markdown-cell">
<p>Como antes hemos usado el puerto <code>8000</code>, por si os dice que est√° ocupado, creamos una funci√≥n para encontrar un puerto libre y encontramos uno</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">find_free_port</span><span class="p">(</span><span class="n">start_port</span><span class="o">=</span><span class="mi">8000</span><span class="p">,</span> <span class="n">max_port</span><span class="o">=</span><span class="mi">9000</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Find the first free port starting from start_port."""</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Searching for a free port starting from </span><span class="si">{</span><span class="n">start_port</span><span class="si">}</span><span class="s2">..."</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">port</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_port</span><span class="p">,</span> <span class="n">max_port</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">socket</span><span class="o">.</span><span class="n">socket</span><span class="p">(</span><span class="n">socket</span><span class="o">.</span><span class="n">AF_INET</span><span class="p">,</span> <span class="n">socket</span><span class="o">.</span><span class="n">SOCK_STREAM</span><span class="p">)</span> <span class="k">as</span> <span class="n">sock</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">sock</span><span class="o">.</span><span class="n">connect_ex</span><span class="p">((</span><span class="s1">'127.0.0.1'</span><span class="p">,</span> <span class="n">port</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">result</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># If result != 0, the port is free</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Free port found: </span><span class="si">{</span><span class="n">port</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">port</span>
    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"No free port found between </span><span class="si">{</span><span class="n">start_port</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="n">max_port</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="n">free_port</span> <span class="o">=</span> <span class="n">find_free_port</span><span class="p">()</span>    <span class="c1"># Search for a free port</span>
</pre></div>
</section>
<section class="section-block-markdown-cell">
<p>Se crea el stream y ahora se usa <code>stream.fastphone()</code> para obtener un n√∫mero de tel√©fono gratuito para llamar a tu stream, en vez de <code>stream.ui.launch()</code> que usamos antes para crear la interfaz gr√°fica.</p>
<div class="highlight"><pre><span></span><span class="n">stream</span> <span class="o">=</span> <span class="n">Stream</span><span class="p">(</span><span class="n">ReplyOnPause</span><span class="p">(</span><span class="n">echo</span><span class="p">),</span> <span class="n">modality</span><span class="o">=</span><span class="s2">"audio"</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">"send-receive"</span><span class="p">)</span>
<span class="n">stream</span><span class="o">.</span><span class="n">fastphone</span><span class="p">(</span><span class="n">token</span><span class="o">=</span><span class="n">HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN</span><span class="p">,</span> <span class="n">port</span><span class="o">=</span><span class="n">free_port</span><span class="p">)</span>
</pre></div>
</section>
<section class="section-block-markdown-cell">
<p>Si lo ejecutamos, veremos algo como esto:</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">!</span>python<span class="w"> </span>fastrtc_phone_demo.py
</pre></div>
</div>
<div class="output-wrapper">
<div class="output-area">
<div class="prompt"></div>
<div class="output-subarea-output-stream-output-stdout-output-text">
<pre>Loaded as API: https://maximofn-smollm2-localmodel.hf.space ‚úî
<span class="ansi-green-fg">INFO</span>:	  Warming up STT model.
<span class="ansi-green-fg">INFO</span>:	  STT model warmed up.
<span class="ansi-green-fg">INFO</span>:	  Warming up VAD model.
<span class="ansi-green-fg">INFO</span>:	  VAD model warmed up.
Searching for a free port starting from 8000...
Free port found: 8004
<span class="ansi-green-fg">INFO</span>:     Started server process [<span class="ansi-cyan-fg">24029</span>]
<span class="ansi-green-fg">INFO</span>:     Waiting for application startup.
<span class="ansi-green-fg">INFO</span>:	  Visit <span class="ansi-cyan-fg">https://fastrtc.org/userguide/api/</span> for WebRTC or Websocket API docs.
<span class="ansi-green-fg">INFO</span>:     Application startup complete.
<span class="ansi-green-fg">INFO</span>:     Uvicorn running on <span class="ansi-bold">http://127.0.0.1:8004</span> (Press CTRL+C to quit)
<span class="ansi-green-fg">INFO</span>:	  Your FastPhone is now live! Call <span class="ansi-cyan-fg">+1 877-713-4471</span> and use code <span class="ansi-cyan-fg">994514</span> to connect to your stream.
<span class="ansi-green-fg">INFO</span>:	  You have <span class="ansi-cyan-fg">30:00</span> minutes remaining in your quota (Resetting on <span class="ansi-cyan-fg">2025-04-07</span>)
<span class="ansi-green-fg">INFO</span>:	  Visit <span class="ansi-cyan-fg">https://fastrtc.org/userguide/audio/#telephone-integration</span> for information on making your handler compatible with phone usage.
</pre>
</div>
</div>
</div>
</section>
<section class="section-block-markdown-cell">
<p>Vemos que aparece</p>
<div class="highlight"><pre><span></span>INFO:<span class="w">	  </span>Your<span class="w"> </span>FastPhone<span class="w"> </span>is<span class="w"> </span>now<span class="w"> </span>live!<span class="w"> </span>Call<span class="w"> </span>+1<span class="w"> </span><span class="m">877</span>-713-4471<span class="w"> </span>and<span class="w"> </span>use<span class="w"> </span>code<span class="w"> </span><span class="m">994514</span><span class="w"> </span>to<span class="w"> </span>connect<span class="w"> </span>to<span class="w"> </span>your<span class="w"> </span>stream.
INFO:<span class="w">	  </span>You<span class="w"> </span>have<span class="w"> </span><span class="m">30</span>:00<span class="w"> </span>minutes<span class="w"> </span>remaining<span class="w"> </span><span class="k">in</span><span class="w"> </span>your<span class="w"> </span>quota<span class="w"> </span><span class="o">(</span>Resetting<span class="w"> </span>on<span class="w"> </span><span class="m">2025</span>-04-07<span class="o">)</span>
</pre></div>
<p>Es decir, si llamamos al n√∫mero <code>+1 877-713-4471</code> y usamos el c√≥digo <code>994514</code> nos conectar√° a nuestro stream.</p>
</section>
<section class="section-block-markdown-cell">
<p>Si nos vamos a <a href="https://fastrtc.org/userguide/audio/#telephone-integration">Telephone Integration</a> de la documentaci√≥n de <code>FastRTC</code> veremos que usa <a href="https://www.twilio.com/">twilio</a> para hacer la llamada. Tiene opci√≥n para configurar un n√∫mero local desde estados unidos, Dublin, Frankfurt, Tokio, Singapur, Sidney y Sao Paulo.</p>
</section>
<section class="section-block-markdown-cell">
<p>He probado a hacer la llamada desde Espa√±a (que me va a costar bastante) y funciona, pero es lento. He llamado, he metido el c√≥digo y he estado esperando a que conectara con el agente, pero como estaba tardando mucho, he colgado.</p>
</section>
