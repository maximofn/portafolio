{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Docker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " > Disclaimer: This post has been translated to English using a machine translation model. Please, let me know if you find any mistakes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Containers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hello world"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the first Hello World container with the command `docker run hello-world`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unable to find image 'hello-world:latest' locally\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "latest: Pulling from library/hello-world\n",
            "\n",
            "\u001b[1B85e32844: Pull complete 457kB/2.457kBB\u001b[1A\u001b[2KDigest: sha256:dcba6daec718f547568c562956fa47e1b03673dd010fe6ee58ca806767031d1c\n",
            "Status: Downloaded newer image for hello-world:latest\n",
            "\n",
            "Hello from Docker!\n",
            "This message shows that your installation appears to be working correctly.\n",
            "\n",
            "To generate this message, Docker took the following steps:\n",
            " 1. The Docker client contacted the Docker daemon.\n",
            " 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\n",
            "    (amd64)\n",
            " 3. The Docker daemon created a new container from that image which runs the\n",
            "    executable that produces the output you are currently reading.\n",
            " 4. The Docker daemon streamed that output to the Docker client, which sent it\n",
            "    to your terminal.\n",
            "\n",
            "To try something more ambitious, you can run an Ubuntu container with:\n",
            " $ docker run -it ubuntu bash\n",
            "\n",
            "Share images, automate workflows, and more with a free Docker ID:\n",
            " https://hub.docker.com/\n",
            "\n",
            "For more examples and ideas, visit:\n",
            " https://docs.docker.com/get-started/\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!docker run hello-world"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since we don't have the container saved locally, Docker downloads it from Docker Hub. If we now run the container again, the initial message indicating that it is being downloaded will not appear."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Hello from Docker!\n",
            "This message shows that your installation appears to be working correctly.\n",
            "\n",
            "To generate this message, Docker took the following steps:\n",
            " 1. The Docker client contacted the Docker daemon.\n",
            " 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\n",
            "    (amd64)\n",
            " 3. The Docker daemon created a new container from that image which runs the\n",
            "    executable that produces the output you are currently reading.\n",
            " 4. The Docker daemon streamed that output to the Docker client, which sent it\n",
            "    to your terminal.\n",
            "\n",
            "To try something more ambitious, you can run an Ubuntu container with:\n",
            " $ docker run -it ubuntu bash\n",
            "\n",
            "Share images, automate workflows, and more with a free Docker ID:\n",
            " https://hub.docker.com/\n",
            "\n",
            "For more examples and ideas, visit:\n",
            " https://docs.docker.com/get-started/\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!docker run hello-world"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To see the containers that are running, execute `docker ps`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
          ]
        }
      ],
      "source": [
        "!docker ps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see, there are no open containers. However, if we run `docker ps -a` (`all`), we see that they do appear."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE         COMMAND    CREATED          STATUS                      PORTS     NAMES\n",
            "1efb51bbbf38   hello-world   \"/hello\"   10 seconds ago   Exited (0) 9 seconds ago              strange_thompson\n",
            "5f5705e7603e   hello-world   \"/hello\"   15 seconds ago   Exited (0) 14 seconds ago             laughing_jang\n"
          ]
        }
      ],
      "source": [
        "!docker ps -a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that two containers called `hello-world` appear, which are the two we executed before. Therefore, each time we run the `run` command, Docker creates a new container, it does not execute one that already exists."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we want to get more information about one of the two containers, we can run `docker inspect <id>`, where `<id>` corresponds to the ID of the container that was displayed in the previous list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "    {\n",
            "        \"Id\": \"1efb51bbbf38917affd1b5871db8e658ebfe0b2efa5ead17545680b7866f682e\",\n",
            "        \"Created\": \"2023-09-04T03:59:17.795499354Z\",\n",
            "        \"Path\": \"/hello\",\n",
            "        \"Args\": [],\n",
            "        \"State\": {\n",
            "            \"Status\": \"exited\",\n",
            "            \"Running\": false,\n",
            "            \"Paused\": false,\n",
            "            \"Restarting\": false,\n",
            "            \"OOMKilled\": false,\n",
            "            \"Dead\": false,\n",
            "            \"Pid\": 0,\n",
            "            \"ExitCode\": 0,\n",
            "            \"Error\": \"\",\n",
            "            \"StartedAt\": \"2023-09-04T03:59:18.406663026Z\",\n",
            "            \"FinishedAt\": \"2023-09-04T03:59:18.406181184Z\"\n",
            "        },\n",
            "        \"Image\": \"sha256:9c7a54a9a43cca047013b82af109fe963fde787f63f9e016fdc3384500c2823d\",\n",
            "        \"ResolvConfPath\": \"/var/lib/docker/containers/1efb51bbbf38917affd1b5871db8e658ebfe0b2efa5ead17545680b7866f682e/resolv.conf\",\n",
            "        \"HostnamePath\": \"/var/lib/docker/containers/1efb51bbbf38917affd1b5871db8e658ebfe0b2efa5ead17545680b7866f682e/hostname\",\n",
            "        \"HostsPath\": \"/var/lib/docker/containers/1efb51bbbf38917affd1b5871db8e658ebfe0b2efa5ead17545680b7866f682e/hosts\",\n",
            "        \"LogPath\": \"/var/lib/docker/containers/1efb51bbbf38917affd1b5871db8e658ebfe0b2efa5ead17545680b7866f682e/1efb51bbbf38917affd1b5871db8e658ebfe0b2efa5ead17545680b7866f682e-json.log\",\n",
            "        \"Name\": \"/strange_thompson\",\n",
            "        ...\n",
            "            }\n",
            "        }\n",
            "    }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "!docker inspect 1efb51bbbf38"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since remembering IDs is complicated for us, Docker assigns names to containers to make our life easier. So in the previous list, the last column corresponds to the name that Docker has assigned to each container, so if we now run `docker inspect <name>` we will get the same information as with the ID."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I run `docker ps -a` again to see the list once more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE         COMMAND    CREATED         STATUS                     PORTS     NAMES\n",
            "1efb51bbbf38   hello-world   \"/hello\"   2 minutes ago   Exited (0) 2 minutes ago             strange_thompson\n",
            "5f5705e7603e   hello-world   \"/hello\"   2 minutes ago   Exited (0) 2 minutes ago             laughing_jang\n"
          ]
        }
      ],
      "source": [
        "!docker ps -a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And now I run `docker inspect <name>` to view the container information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "    {\n",
            "        \"Id\": \"1efb51bbbf38917affd1b5871db8e658ebfe0b2efa5ead17545680b7866f682e\",\n",
            "        \"Created\": \"2023-09-04T03:59:17.795499354Z\",\n",
            "        \"Path\": \"/hello\",\n",
            "        \"Args\": [],\n",
            "        \"State\": {\n",
            "            \"Status\": \"exited\",\n",
            "            \"Running\": false,\n",
            "            \"Paused\": false,\n",
            "            \"Restarting\": false,\n",
            "            \"OOMKilled\": false,\n",
            "            \"Dead\": false,\n",
            "            \"Pid\": 0,\n",
            "            \"ExitCode\": 0,\n",
            "            \"Error\": \"\",\n",
            "            \"StartedAt\": \"2023-09-04T03:59:18.406663026Z\",\n",
            "            \"FinishedAt\": \"2023-09-04T03:59:18.406181184Z\"\n",
            "        },\n",
            "        \"Image\": \"sha256:9c7a54a9a43cca047013b82af109fe963fde787f63f9e016fdc3384500c2823d\",\n",
            "        \"ResolvConfPath\": \"/var/lib/docker/containers/1efb51bbbf38917affd1b5871db8e658ebfe0b2efa5ead17545680b7866f682e/resolv.conf\",\n",
            "        \"HostnamePath\": \"/var/lib/docker/containers/1efb51bbbf38917affd1b5871db8e658ebfe0b2efa5ead17545680b7866f682e/hostname\",\n",
            "        \"HostsPath\": \"/var/lib/docker/containers/1efb51bbbf38917affd1b5871db8e658ebfe0b2efa5ead17545680b7866f682e/hosts\",\n",
            "        \"LogPath\": \"/var/lib/docker/containers/1efb51bbbf38917affd1b5871db8e658ebfe0b2efa5ead17545680b7866f682e/1efb51bbbf38917affd1b5871db8e658ebfe0b2efa5ead17545680b7866f682e-json.log\",\n",
            "        \"Name\": \"/strange_thompson\",\n",
            "        ...\n",
            "            }\n",
            "        }\n",
            "    }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "!docker inspect strange_thompson"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "But why don't we see any containers with `docker ps` and do see them with `docker ps -a`? This is because `docker ps` only shows the containers that are running, while `docker ps -a` shows all containers, both those that are running and those that are stopped."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can create a container by assigning it a name using the command `docker run --name <name> hello-world`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Hello from Docker!\n",
            "This message shows that your installation appears to be working correctly.\n",
            "\n",
            "To generate this message, Docker took the following steps:\n",
            " 1. The Docker client contacted the Docker daemon.\n",
            " 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\n",
            "    (amd64)\n",
            " 3. The Docker daemon created a new container from that image which runs the\n",
            "    executable that produces the output you are currently reading.\n",
            " 4. The Docker daemon streamed that output to the Docker client, which sent it\n",
            "    to your terminal.\n",
            "\n",
            "To try something more ambitious, you can run an Ubuntu container with:\n",
            " $ docker run -it ubuntu bash\n",
            "\n",
            "Share images, automate workflows, and more with a free Docker ID:\n",
            " https://hub.docker.com/\n",
            "\n",
            "For more examples and ideas, visit:\n",
            " https://docs.docker.com/get-started/\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!docker run --name hello_world hello-world"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This will be more convenient for us, as we will be able to control the names of the containers ourselves."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we now want to create another container with the same name, we won't be able to, because Docker does not allow container names to be duplicated. So, if we want to rename the container, we can use the command `docker rename <old name> <new name>`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "!docker rename hello_world hello_world2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now have a bunch of identical containers. So if we want to delete one, we have to use the command `docker rm <id>` or `docker rm <name>`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE         COMMAND    CREATED         STATUS                     PORTS     NAMES\n",
            "f432c9c2ca21   hello-world   \"/hello\"   9 seconds ago   Exited (0) 8 seconds ago             hello_world2\n",
            "1efb51bbbf38   hello-world   \"/hello\"   4 minutes ago   Exited (0) 4 minutes ago             strange_thompson\n",
            "5f5705e7603e   hello-world   \"/hello\"   4 minutes ago   Exited (0) 4 minutes ago             laughing_jang\n"
          ]
        }
      ],
      "source": [
        "!docker ps -a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hello_world2\n"
          ]
        }
      ],
      "source": [
        "!docker rm hello_world2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we look at the list of containers again, the `hello_world2` container will no longer be there."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE         COMMAND    CREATED         STATUS                     PORTS     NAMES\n",
            "1efb51bbbf38   hello-world   \"/hello\"   5 minutes ago   Exited (0) 5 minutes ago             strange_thompson\n",
            "5f5705e7603e   hello-world   \"/hello\"   5 minutes ago   Exited (0) 5 minutes ago             laughing_jang\n"
          ]
        }
      ],
      "source": [
        "!docker ps -a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we want to delete all containers, we can do it one by one, but since that is very tedious, we can delete all of them using the command `docker container prune`. This command removes only stopped containers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING! This will remove all stopped containers.\n",
            "Are you sure you want to continue? [y/N] y"
          ]
        }
      ],
      "source": [
        "!docker container prune"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Docker asks if you're sure, and if you say yes, it deletes all of them. If I now list all containers, none appear."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
          ]
        }
      ],
      "source": [
        "!docker ps -a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The interactive mode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are going to run an Ubuntu using the command `docker run ubuntu`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unable to find image 'ubuntu:latest' locally\n",
            "latest: Pulling from library/ubuntu\n",
            "\n",
            "\u001b[1BDigest: sha256:20fa2d7bb4de7723f542be5923b06c4d704370f0390e4ae9e1c833c8785644c1[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\n",
            "Status: Downloaded newer image for ubuntu:latest\n"
          ]
        }
      ],
      "source": [
        "!docker run ubuntu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see, it has now taken longer to download. If we list the containers using the command `docker ps`, we see that the container we just created does not appear, meaning it is not running."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
          ]
        }
      ],
      "source": [
        "!docker ps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now list all the containers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE     COMMAND   CREATED         STATUS                     PORTS     NAMES\n",
            "da16b3a85178   ubuntu    \"bash\"    4 seconds ago   Exited (0) 3 seconds ago             hardcore_kare\n"
          ]
        }
      ],
      "source": [
        "!docker ps -a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that the container status is `Exited (0)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we look at the container command, it shows `bash` and alongside the status `Exited (0)`, indicating that Ubuntu has started, executed its *bash*, completed execution, and returned a 0. This happens because the Ubuntu bash was not given anything to do. To solve this, we will now run the container using the command `docker run -it ubuntu`, where `it` indicates that we want to run it in interactive mode."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root@5b633e9d838f:/#"
          ]
        }
      ],
      "source": [
        "!docker run -it ubuntu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we see that we are inside the Ubuntu bash. If we run the command `cat /etc/lsb-release` we can see the Ubuntu distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DISTRIB_ID=Ubuntu\n",
            "DISTRIB_RELEASE=22.04\n",
            "DISTRIB_CODENAME=jammy\n",
            "DISTRIB_DESCRIPTION=\"Ubuntu 22.04.1 LTS\""
          ]
        }
      ],
      "source": [
        "!root@5b633e9d838f:/# cat /etc/lsb-release"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we open another terminal and check the list of containers, the Ubuntu container will now appear as running."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE     COMMAND   CREATED         STATUS         PORTS     NAMES\n",
            "5b633e9d838f   ubuntu    \"bash\"    3 minutes ago   Up 3 minutes             funny_mirzakhani\n"
          ]
        }
      ],
      "source": [
        "!docker ps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see the container with Ubuntu and in its status we can see `UP`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we now look at the list of all containers, we will see that both Ubuntu containers appear, the first one stopped and the second one running."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE     COMMAND   CREATED         STATUS                     PORTS     NAMES\n",
            "5b633e9d838f   ubuntu    \"bash\"    3 minutes ago   Up 3 minutes                         funny_mirzakhani\n",
            "da16b3a85178   ubuntu    \"bash\"    3 minutes ago   Exited (0) 3 minutes ago             hardcore_kare\n"
          ]
        }
      ],
      "source": [
        "!docker ps -a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we go back to the terminal where we had Ubuntu running inside a Docker container, if we type `exit` we will exit Ubuntu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "exit"
          ]
        }
      ],
      "source": [
        "!root@5b633e9d838f:/# exit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we run `docker ps` the container no longer appears"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
          ]
        }
      ],
      "source": [
        "!docker ps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "But if I run ``docker ps -a`` it does appear. This means that the container has stopped."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE     COMMAND   CREATED         STATUS                      PORTS     NAMES\n",
            "5b633e9d838f   ubuntu    \"bash\"    4 minutes ago   Exited (0) 27 seconds ago             funny_mirzakhani\n",
            "da16b3a85178   ubuntu    \"bash\"    4 minutes ago   Exited (0) 4 minutes ago              hardcore_kare\n"
          ]
        }
      ],
      "source": [
        "!docker ps -a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This happens because when we type ``exit``, we are actually typing it in the Ubuntu bash console, which means we are ending the Ubuntu bash process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Container Lifecycle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In Docker, when the main process of a container ends, the container shuts down. Multiple processes can run inside a container, but the container only stops when the main process terminates.",
        "\n",
        "Therefore, if we want to run a container that does not stop when a process finishes, we must ensure that its main process does not terminate. In this case, that bash does not exit.",
        "\n",
        "If we want to run a container with Ubuntu, but prevent it from exiting when the Bash process finishes, we can do it as follows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ce4d60427dcd4b326d15aa832b816c209761d6b4e067a016bb75bf9366c37054\n"
          ]
        }
      ],
      "source": [
        "!docker run --name alwaysup -d ubuntu tail -f /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What we do is first give it the name `alwaysup`, secondly pass it the `-d` (`detach`) option so that the container runs in the background, and finally tell it the main process we want to run in the container, which in this case is `tail -f /dev/null` which is equivalent to a `nop` command.",
        "\n",
        "This will return the container's ID, but we won't be inside Ubuntu as before."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we now look at the list of running containers, the container we just created will appear."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE     COMMAND               CREATED          STATUS          PORTS     NAMES\n",
            "ce4d60427dcd   ubuntu    \"tail -f /dev/null\"   18 seconds ago   Up 17 seconds             alwaysup\n"
          ]
        }
      ],
      "source": [
        "!docker ps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since we already have a container running all the time, we can connect to it using the `exec` command. We tell it the name or ID of the container and pass the process we want to run. Additionally, we pass the `-it` option to make it interactive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root@ce4d60427dcd:/#"
          ]
        }
      ],
      "source": [
        "!docker exec -it alwaysup bash"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we are back inside Ubuntu. If we run the command ``ps -aux`` we can see a list of the processes that are running inside Ubuntu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n",
            "root           1  0.0  0.0   2820  1048 ?        Ss   13:04   0:00 tail -f /dev/null\n",
            "root           7  0.0  0.0   4628  3796 pts/0    Ss   13:04   0:00 bash\n",
            "root          15  0.0  0.0   7060  1556 pts/0    R+   13:05   0:00 ps -aux"
          ]
        }
      ],
      "source": [
        "!ps -aux"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We only see three processes, the ``ps -aux``, the ``bash``, and the ``tail -f /dev/null``",
        "\n",
        "This container will remain running as long as the process ``tail -f /dev/null`` continues to run."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we exit the container with the command ``exit`` and run the command ``docker ps``, we see that the container is still running."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "exit"
          ]
        }
      ],
      "source": [
        "!exit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE     COMMAND               CREATED         STATUS         PORTS     NAMES\n",
            "ce4d60427dcd   ubuntu    \"tail -f /dev/null\"   2 minutes ago   Up 2 minutes             alwaysup\n"
          ]
        }
      ],
      "source": [
        "!docker ps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To be able to complete the process and shut down the container, we must use the command ``docker stop <name>``"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "alwaysup\n"
          ]
        }
      ],
      "source": [
        "!docker stop alwaysup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we now list the running containers again, the container with Ubuntu will no longer appear."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
          ]
        }
      ],
      "source": [
        "!docker ps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And if we list all the containers, the container with Ubuntu appears, and its status is ``Exited``"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE     COMMAND               CREATED          STATUS                            PORTS     NAMES\n",
            "ce4d60427dcd   ubuntu    \"tail -f /dev/null\"   14 minutes ago   Exited (137) About a minute ago             alwaysup\n",
            "5b633e9d838f   ubuntu    \"bash\"                19 minutes ago   Exited (0) 15 minutes ago                   funny_mirzakhani\n",
            "da16b3a85178   ubuntu    \"bash\"                20 minutes ago   Exited (0) 20 minutes ago                   hardcore_kare\n"
          ]
        }
      ],
      "source": [
        "!docker ps -a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also pause a container using the command `docker pause <name>`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8282eaf9dc3604fa94df206b2062287409cc92cbcd203f1a018742b5c171c9e4\n"
          ]
        }
      ],
      "source": [
        "!docker run --name alwaysup -d ubuntu tail -f /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we pause it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "alwaysup\n"
          ]
        }
      ],
      "source": [
        "!docker pause alwaysup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we look at all the containers again, we see that the container with Ubuntu is paused"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE     COMMAND               CREATED          STATUS                       PORTS     NAMES\n",
            "8282eaf9dc36   ubuntu    \"tail -f /dev/null\"   41 seconds ago   Up 41 seconds (Paused)                 alwaysup\n",
            "5b633e9d838f   ubuntu    \"bash\"                19 minutes ago   Exited (0) 15 minutes ago              funny_mirzakhani\n",
            "da16b3a85178   ubuntu    \"bash\"                20 minutes ago   Exited (0) 20 minutes ago              hardcore_kare\n"
          ]
        }
      ],
      "source": [
        "!docker ps -a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Single-use containers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If at the time of running a container, we put the option `--rm`, that container will be deleted when it finishes executing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "!docker run --rm --name autoremove ubuntu:latest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we now see which containers we have"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
          ]
        }
      ],
      "source": [
        "!docker ps -a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that the container we just created is not there."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exposing containers to the outside world"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's create a new container with a server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unable to find image 'nginx:latest' locally\n",
            "latest: Pulling from library/nginx\n",
            "\n",
            "\u001b[1Bf1ad4ce1: Pulling fs layer \n",
            "\u001b[1Bb079d0f8: Pulling fs layer \n",
            "\u001b[1B5fbbebc6: Pulling fs layer \n",
            "\u001b[1Bffdd25f4: Pulling fs layer \n",
            "\u001b[1B32c8fba2: Pulling fs layer \n",
            "\u001b[1B24b8ba39: Pull complete 393kB/1.393kBB[5A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[3A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[2A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[4A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KDigest: sha256:2888a97f7c7d498bbcc47ede1ad0f6ced07d72dfd181071dde051863f1f79d7b\n",
            "Status: Downloaded newer image for nginx:latest\n",
            "1a530e04f14be082811b72ea8b6ea5a95dad3037301ee8a1351a0108ff8d3b30\n"
          ]
        }
      ],
      "source": [
        "!docker run -d --name proxy nginx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This creates a server, let's list the containers that are running"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE     COMMAND                  CREATED        STATUS                  PORTS     NAMES\n",
            "1a530e04f14b   nginx     \"/docker-entrypoint.\u2026\"   1 second ago   Up Less than a second   80/tcp    proxy\n"
          ]
        }
      ],
      "source": [
        "!docker ps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now a new column appears with the port, and it tells us that the server we just created is on port `80` under the `tcp` protocol.",
        "\n",
        "If we open a browser and try to connect to the server using `http://localhost:80`, we won't be able to connect. This is because each container has its own network interface. In other words, the server is listening on port `80` of the container, but we are trying to connect to port `80` of the host."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We stop the container to relaunch it in a different way"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "proxy\n"
          ]
        }
      ],
      "source": [
        "!docker stop proxy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we list the containers, it is not running"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
          ]
        }
      ],
      "source": [
        "!docker ps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We delete it to recreate it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "proxy\n"
          ]
        }
      ],
      "source": [
        "!docker rm proxy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we list all the containers, it is no longer there."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE     COMMAND               CREATED          STATUS                       PORTS     NAMES\n",
            "ce4d60427dcd   ubuntu    \"tail -f /dev/null\"   19 minutes ago   Exited (137) 5 minutes ago             alwaysup\n",
            "5b633e9d838f   ubuntu    \"bash\"                24 minutes ago   Exited (0) 20 minutes ago              funny_mirzakhani\n",
            "da16b3a85178   ubuntu    \"bash\"                24 minutes ago   Exited (0) 24 minutes ago              hardcore_kare\n"
          ]
        }
      ],
      "source": [
        "!docker ps -a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To recreate the container with the server and be able to see it from the host, we need to use the ``-p`` (``publish``) option, specifying first the port where we want to see it on the host and then the container's port, i.e., ``-p <host ip>:<container ip>``"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c199235e42f76a30266f6e1af972e0a59811806eb3d3a9afdd873f6fa1785eae\n"
          ]
        }
      ],
      "source": [
        "!docker run -d --name proxy -p 8080:80 nginx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We list the containers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE     COMMAND                  CREATED          STATUS          PORTS                                   NAMES\n",
            "c199235e42f7   nginx     \"/docker-entrypoint.\u2026\"   22 seconds ago   Up 21 seconds   0.0.0.0:8080->80/tcp, :::8080->80/tcp   proxy\n"
          ]
        }
      ],
      "source": [
        "!docker ps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that the container port is `0.0.0.0:8080->80/tcp`. If we now go to a browser and enter `0.0.0.0:8080`, we will be able to access the container's server."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When listing the containers, in the ``PORTS`` column it shows ``0.0.0.0:8080->80/tcp``, which helps us see the port mapping relationship."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To view the container logs, using the command `docker logs <name>` I can see the container logs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration\n",
            "/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/\n",
            "/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh\n",
            "10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf\n",
            "10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf\n",
            "/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh\n",
            "/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh\n",
            "/docker-entrypoint.sh: Configuration complete; ready for start up\n",
            "2022/09/13 13:24:06 [notice] 1#1: using the \"epoll\" event method\n",
            "2022/09/13 13:24:06 [notice] 1#1: nginx/1.23.1\n",
            "2022/09/13 13:24:06 [notice] 1#1: built by gcc 10.2.1 20210110 (Debian 10.2.1-6) \n",
            "2022/09/13 13:24:06 [notice] 1#1: OS: Linux 5.15.0-46-generic\n",
            "2022/09/13 13:24:06 [notice] 1#1: getrlimit(RLIMIT_NOFILE): 1048576:1048576\n",
            "2022/09/13 13:24:06 [notice] 1#1: start worker processes\n",
            "2022/09/13 13:24:06 [notice] 1#1: start worker process 31\n",
            "2022/09/13 13:24:06 [notice] 1#1: start worker process 32\n",
            "2022/09/13 13:24:06 [notice] 1#1: start worker process 33\n",
            "2022/09/13 13:24:06 [notice] 1#1: start worker process 34\n",
            "2022/09/13 13:24:06 [notice] 1#1: start worker process 35\n",
            "2022/09/13 13:24:06 [notice] 1#1: start worker process 36\n",
            "2022/09/13 13:24:06 [notice] 1#1: start worker process 37\n",
            "2022/09/13 13:24:06 [notice] 1#1: start worker process 38\n",
            "2022/09/13 13:24:06 [notice] 1#1: start worker process 39\n",
            "2022/09/13 13:24:06 [notice] 1#1: start worker process 40\n",
            "2022/09/13 13:24:06 [notice] 1#1: start worker process 41\n",
            "...\n",
            "172.17.0.1 - - [13/Sep/2022:13:24:40 +0000] \"GET /favicon.ico HTTP/1.1\" 404 555 \"http://0.0.0.0:8080/\" \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\" \"-\"\n",
            "172.17.0.1 - - [13/Sep/2022:13:25:00 +0000] \"\\x16\\x03\\x01\\x02\\x00\\x01\\x00\\x01\\xFC\\x03\\x03\\xE2\\x19V$Zqi'\\xD7\\xFC[\\x80\\xEF\\xBA\\xE5\\xC7\\xE8\\xF7&3nS\\xEB\\xC9\\xEC\\x91\\xC2\\xD8\\xD1\\x89\\x9E\\xBE \\xC7?\\xE1\\xFA\\x04a\\x1C\\xCE\\x90\\x0F\\x8F\\x98u\\xE3/\\xD8RfOH\\xEC\\x92+\\x93\\x5C\\xBB\\xB1\\xBF\\xD2m\\xB09\\x00 \\xFA\\xFA\\x13\\x01\\x13\\x02\\x13\\x03\\xC0+\\xC0/\\xC0,\\xC00\\xCC\\xA9\\xCC\\xA8\\xC0\\x13\\xC0\\x14\\x00\\x9C\\x00\\x9D\\x00/\\x005\\x01\\x00\\x01\\x93\\x9A\\x9A\\x00\\x00\\x00\\x00\\x00\\x0E\\x00\\x0C\\x00\\x00\\x09localhost\\x00\\x17\\x00\\x00\\xFF\\x01\\x00\\x01\\x00\\x00\" 400 157 \"-\" \"-\" \"-\"\n",
            "172.17.0.1 - - [13/Sep/2022:13:25:00 +0000] \"\\x16\\x03\\x01\\x02\\x00\\x01\\x00\\x01\\xFC\\x03\\x03)\\x9A\\x8FbC\\xD9m\\xF1\\x86\\xEBd\\x22\\xCF\\xC4E\\x87#~L\\xC1\\x84\\x7F\\xB5\\x91k\\x98\\xABl\\xEE\\x1E[0 \\xD0\\xD2`\\x85\\xC6\\x8B\\x85R\\x8B\\x87\\xEAq{P\\xF2\\xFB\\xE2\\xA8\\x9DI\\xF4tH\\x99\\x13\\x10~\\xCA1-|\\x8E\\x00 \\xEA\\xEA\\x13\\x01\\x13\\x02\\x13\\x03\\xC0+\\xC0/\\xC0,\\xC00\\xCC\\xA9\\xCC\\xA8\\xC0\\x13\\xC0\\x14\\x00\\x9C\\x00\\x9D\\x00/\\x005\\x01\\x00\\x01\\x93\" 400 157 \"-\" \"-\" \"-\"\n",
            "172.17.0.1 - - [13/Sep/2022:13:26:28 +0000] \"GET / HTTP/1.1\" 304 0 \"-\" \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\" \"-\"\n"
          ]
        }
      ],
      "source": [
        "!docker logs proxy"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now I can see all the requests that have been made to the server. But if I want to view the logs in real time, I can do so with ``docker logs -f <name>``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": []
        }
      ],
      "source": [
        "!docker logs -f proxy"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now I can see the logs in real time. To exit, press ``CTRL+C``"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As there can come a time when there are many logs, if you only want the latest logs, with the option ``--tail <num>`` you can view the last ``<num>`` logs. If I add the option ``-f``, we will always be seeing the last ``<num>`` logs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022/09/13 13:24:06 [notice] 1#1: start worker process 41\n",
            "2022/09/13 13:24:06 [notice] 1#1: start worker process 42\n",
            "172.17.0.1 - - [13/Sep/2022:13:24:16 +0000] \"\\x16\\x03\\x01\\x02\\x00\\x01\\x00\\x01\\xFC\\x03\\x03\\x01E\\x14\\x8E\\xB6\\x0BEg\\xF3\\xC9\\x9A\\x19\\x9C\\xCA\\xEC\\xA7y#3\\x92\\x05\\x95\\xDCQ\\x07\\x19\\x1D\\xEF\\xEA$\\xBF# \\x0B\\x83\\xF7-,s\\x1B!r\\xEA|\\xAE\\xDF\\xA1\\x9DLZ\\xAA4y\\xB3t\\xAB\\xC0\\xCE_\\xB8\\xE7\\xFF'\\xCF\\x86\\x00 \\xEA\\xEA\\x13\\x01\\x13\\x02\\x13\\x03\\xC0+\\xC0/\\xC0,\\xC00\\xCC\\xA9\\xCC\\xA8\\xC0\\x13\\xC0\\x14\\x00\\x9C\\x00\\x9D\\x00/\\x005\\x01\\x00\\x01\\x93\\x8A\\x8A\\x00\\x00\\x00\\x00\\x00\\x0E\\x00\\x0C\\x00\\x00\\x09localhost\\x00\\x17\\x00\\x00\\xFF\\x01\\x00\\x01\\x00\\x00\" 400 157 \"-\" \"-\" \"-\"\n",
            "172.17.0.1 - - [13/Sep/2022:13:24:16 +0000] \"\\x16\\x03\\x01\\x02\\x00\\x01\\x00\\x01\\xFC\\x03\\x03}\\xA9Dr{\\x8C;\\x90z\\x82\\xAD\\xBC\\x8Az\\xC2x\\xDF\\x1E\\x9A\\xE6l?\\xA7\\xE0DoK\\x91'g\\xBB\\xB5 %\\xBB\\xFD\\xD9\\x82?\\xDB\\x80\\xB3T\\xF6cJ\\xF7\\xE5\\xC2\\xD2\\x11\\xBC\\xA2\\x1F\\x90\\x14\\xA3\\xEB\\xBD=R\\xBC\\x83\\x89\\x85\\x00 \\xCA\\xCA\\x13\\x01\\x13\\x02\\x13\\x03\\xC0+\\xC0/\\xC0,\\xC00\\xCC\\xA9\\xCC\\xA8\\xC0\\x13\\xC0\\x14\\x00\\x9C\\x00\\x9D\\x00/\\x005\\x01\\x00\\x01\\x93\\x9A\\x9A\\x00\\x00\\x00\\x00\\x00\\x0E\\x00\\x0C\\x00\\x00\\x09localhost\\x00\\x17\\x00\\x00\\xFF\\x01\\x00\\x01\\x00\\x00\" 400 157 \"-\" \"-\" \"-\"\n",
            "172.17.0.1 - - [13/Sep/2022:13:24:39 +0000] \"GET / HTTP/1.1\" 200 615 \"-\" \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\" \"-\"\n",
            "2022/09/13 13:24:40 [error] 34#34: *3 open() \"/usr/share/nginx/html/favicon.ico\" failed (2: No such file or directory), client: 172.17.0.1, server: localhost, request: \"GET /favicon.ico HTTP/1.1\", host: \"0.0.0.0:8080\", referrer: \"http://0.0.0.0:8080/\"\n",
            "172.17.0.1 - - [13/Sep/2022:13:24:40 +0000] \"GET /favicon.ico HTTP/1.1\" 404 555 \"http://0.0.0.0:8080/\" \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\" \"-\"\n",
            "172.17.0.1 - - [13/Sep/2022:13:25:00 +0000] \"\\x16\\x03\\x01\\x02\\x00\\x01\\x00\\x01\\xFC\\x03\\x03\\xE2\\x19V$Zqi'\\xD7\\xFC[\\x80\\xEF\\xBA\\xE5\\xC7\\xE8\\xF7&3nS\\xEB\\xC9\\xEC\\x91\\xC2\\xD8\\xD1\\x89\\x9E\\xBE \\xC7?\\xE1\\xFA\\x04a\\x1C\\xCE\\x90\\x0F\\x8F\\x98u\\xE3/\\xD8RfOH\\xEC\\x92+\\x93\\x5C\\xBB\\xB1\\xBF\\xD2m\\xB09\\x00 \\xFA\\xFA\\x13\\x01\\x13\\x02\\x13\\x03\\xC0+\\xC0/\\xC0,\\xC00\\xCC\\xA9\\xCC\\xA8\\xC0\\x13\\xC0\\x14\\x00\\x9C\\x00\\x9D\\x00/\\x005\\x01\\x00\\x01\\x93\\x9A\\x9A\\x00\\x00\\x00\\x00\\x00\\x0E\\x00\\x0C\\x00\\x00\\x09localhost\\x00\\x17\\x00\\x00\\xFF\\x01\\x00\\x01\\x00\\x00\" 400 157 \"-\" \"-\" \"-\"\n",
            "172.17.0.1 - - [13/Sep/2022:13:25:00 +0000] \"\\x16\\x03\\x01\\x02\\x00\\x01\\x00\\x01\\xFC\\x03\\x03)\\x9A\\x8FbC\\xD9m\\xF1\\x86\\xEBd\\x22\\xCF\\xC4E\\x87#~L\\xC1\\x84\\x7F\\xB5\\x91k\\x98\\xABl\\xEE\\x1E[0 \\xD0\\xD2`\\x85\\xC6\\x8B\\x85R\\x8B\\x87\\xEAq{P\\xF2\\xFB\\xE2\\xA8\\x9DI\\xF4tH\\x99\\x13\\x10~\\xCA1-|\\x8E\\x00 \\xEA\\xEA\\x13\\x01\\x13\\x02\\x13\\x03\\xC0+\\xC0/\\xC0,\\xC00\\xCC\\xA9\\xCC\\xA8\\xC0\\x13\\xC0\\x14\\x00\\x9C\\x00\\x9D\\x00/\\x005\\x01\\x00\\x01\\x93\" 400 157 \"-\" \"-\" \"-\"\n",
            "172.17.0.1 - - [13/Sep/2022:13:26:28 +0000] \"GET / HTTP/1.1\" 304 0 \"-\" \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\" \"-\"\n"
          ]
        }
      ],
      "source": [
        "!docker logs --tail 10 proxy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we add the `-t` option, we can see the date and time of each log, so if we have had a problem, we can know when it occurred."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-13T13:24:06.573362728Z 2022/09/13 13:24:06 [notice] 1#1: start worker process 41\n",
            "2022-09-13T13:24:06.651127107Z 2022/09/13 13:24:06 [notice] 1#1: start worker process 42\n",
            "2022-09-13T13:24:16.651160189Z 172.17.0.1 - - [13/Sep/2022:13:24:16 +0000] \"\\x16\\x03\\x01\\x02\\x00\\x01\\x00\\x01\\xFC\\x03\\x03\\x01E\\x14\\x8E\\xB6\\x0BEg\\xF3\\xC9\\x9A\\x19\\x9C\\xCA\\xEC\\xA7y#3\\x92\\x05\\x95\\xDCQ\\x07\\x19\\x1D\\xEF\\xEA$\\xBF# \\x0B\\x83\\xF7-,s\\x1B!r\\xEA|\\xAE\\xDF\\xA1\\x9DLZ\\xAA4y\\xB3t\\xAB\\xC0\\xCE_\\xB8\\xE7\\xFF'\\xCF\\x86\\x00 \\xEA\\xEA\\x13\\x01\\x13\\x02\\x13\\x03\\xC0+\\xC0/\\xC0,\\xC00\\xCC\\xA9\\xCC\\xA8\\xC0\\x13\\xC0\\x14\\x00\\x9C\\x00\\x9D\\x00/\\x005\\x01\\x00\\x01\\x93\\x8A\\x8A\\x00\\x00\\x00\\x00\\x00\\x0E\\x00\\x0C\\x00\\x00\\x09localhost\\x00\\x17\\x00\\x00\\xFF\\x01\\x00\\x01\\x00\\x00\" 400 157 \"-\" \"-\" \"-\"\n",
            "2022-09-13T13:24:16.116817914Z 172.17.0.1 - - [13/Sep/2022:13:24:16 +0000] \"\\x16\\x03\\x01\\x02\\x00\\x01\\x00\\x01\\xFC\\x03\\x03}\\xA9Dr{\\x8C;\\x90z\\x82\\xAD\\xBC\\x8Az\\xC2x\\xDF\\x1E\\x9A\\xE6l?\\xA7\\xE0DoK\\x91'g\\xBB\\xB5 %\\xBB\\xFD\\xD9\\x82?\\xDB\\x80\\xB3T\\xF6cJ\\xF7\\xE5\\xC2\\xD2\\x11\\xBC\\xA2\\x1F\\x90\\x14\\xA3\\xEB\\xBD=R\\xBC\\x83\\x89\\x85\\x00 \\xCA\\xCA\\x13\\x01\\x13\\x02\\x13\\x03\\xC0+\\xC0/\\xC0,\\xC00\\xCC\\xA9\\xCC\\xA8\\xC0\\x13\\xC0\\x14\\x00\\x9C\\x00\\x9D\\x00/\\x005\\x01\\x00\\x01\\x93\\x9A\\x9A\\x00\\x00\\x00\\x00\\x00\\x0E\\x00\\x0C\\x00\\x00\\x09localhost\\x00\\x17\\x00\\x00\\xFF\\x01\\x00\\x01\\x00\\x00\" 400 157 \"-\" \"-\" \"-\"\n",
            "2022-09-13T13:24:39.117398081Z 172.17.0.1 - - [13/Sep/2022:13:24:39 +0000] \"GET / HTTP/1.1\" 200 615 \"-\" \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\" \"-\"\n",
            "2022-09-13T13:24:39.117412408Z 2022/09/13 13:24:40 [error] 34#34: *3 open() \"/usr/share/nginx/html/favicon.ico\" failed (2: No such file or directory), client: 172.17.0.1, server: localhost, request: \"GET /favicon.ico HTTP/1.1\", host: \"0.0.0.0:8080\", referrer: \"http://0.0.0.0:8080/\"\n",
            "2022-09-13T13:24:40.117419389Z 172.17.0.1 - - [13/Sep/2022:13:24:40 +0000] \"GET /favicon.ico HTTP/1.1\" 404 555 \"http://0.0.0.0:8080/\" \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\" \"-\"\n",
            "2022-09-13T13:25:00.117434249Z 172.17.0.1 - - [13/Sep/2022:13:25:00 +0000] \"\\x16\\x03\\x01\\x02\\x00\\x01\\x00\\x01\\xFC\\x03\\x03\\xE2\\x19V$Zqi'\\xD7\\xFC[\\x80\\xEF\\xBA\\xE5\\xC7\\xE8\\xF7&3nS\\xEB\\xC9\\xEC\\x91\\xC2\\xD8\\xD1\\x89\\x9E\\xBE \\xC7?\\xE1\\xFA\\x04a\\x1C\\xCE\\x90\\x0F\\x8F\\x98u\\xE3/\\xD8RfOH\\xEC\\x92+\\x93\\x5C\\xBB\\xB1\\xBF\\xD2m\\xB09\\x00 \\xFA\\xFA\\x13\\x01\\x13\\x02\\x13\\x03\\xC0+\\xC0/\\xC0,\\xC00\\xCC\\xA9\\xCC\\xA8\\xC0\\x13\\xC0\\x14\\x00\\x9C\\x00\\x9D\\x00/\\x005\\x01\\x00\\x01\\x93\\x9A\\x9A\\x00\\x00\\x00\\x00\\x00\\x0E\\x00\\x0C\\x00\\x00\\x09localhost\\x00\\x17\\x00\\x00\\xFF\\x01\\x00\\x01\\x00\\x00\" 400 157 \"-\" \"-\" \"-\"\n",
            "2022-09-13T13:25:00.223560881Z 172.17.0.1 - - [13/Sep/2022:13:25:00 +0000] \"\\x16\\x03\\x01\\x02\\x00\\x01\\x00\\x01\\xFC\\x03\\x03)\\x9A\\x8FbC\\xD9m\\xF1\\x86\\xEBd\\x22\\xCF\\xC4E\\x87#~L\\xC1\\x84\\x7F\\xB5\\x91k\\x98\\xABl\\xEE\\x1E[0 \\xD0\\xD2`\\x85\\xC6\\x8B\\x85R\\x8B\\x87\\xEAq{P\\xF2\\xFB\\xE2\\xA8\\x9DI\\xF4tH\\x99\\x13\\x10~\\xCA1-|\\x8E\\x00 \\xEA\\xEA\\x13\\x01\\x13\\x02\\x13\\x03\\xC0+\\xC0/\\xC0,\\xC00\\xCC\\xA9\\xCC\\xA8\\xC0\\x13\\xC0\\x14\\x00\\x9C\\x00\\x9D\\x00/\\x005\\x01\\x00\\x01\\x93\" 400 157 \"-\" \"-\" \"-\"\n",
            "2022-09-13T13:26:25.223596738Z 172.17.0.1 - - [13/Sep/2022:13:26:28 +0000] \"GET / HTTP/1.1\" 304 0 \"-\" \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\" \"-\"\n"
          ]
        }
      ],
      "source": [
        "!docker logs --tail -t 10 proxy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We stop and delete the container"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "proxy\n"
          ]
        }
      ],
      "source": [
        "!docker rm -f proxy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE     COMMAND               CREATED          STATUS                        PORTS     NAMES\n",
            "ce4d60427dcd   ubuntu    \"tail -f /dev/null\"   26 minutes ago   Exited (137) 13 minutes ago             alwaysup\n",
            "5b633e9d838f   ubuntu    \"bash\"                31 minutes ago   Exited (0) 27 minutes ago               funny_mirzakhani\n",
            "da16b3a85178   ubuntu    \"bash\"                32 minutes ago   Exited (0) 32 minutes ago               hardcore_kare\n"
          ]
        }
      ],
      "source": [
        "!docker ps -a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data in Docker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bind mounts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check the stopped containers we have."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE     COMMAND               CREATED          STATUS                        PORTS     NAMES\n",
            "ce4d60427dcd   ubuntu    \"tail -f /dev/null\"   26 minutes ago   Exited (137) 13 minutes ago             alwaysup\n",
            "5b633e9d838f   ubuntu    \"bash\"                31 minutes ago   Exited (0) 28 minutes ago               funny_mirzakhani\n",
            "da16b3a85178   ubuntu    \"bash\"                32 minutes ago   Exited (0) 32 minutes ago               hardcore_kare\n"
          ]
        }
      ],
      "source": [
        "!docker ps -a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's delete the two from Ubuntu where their main command is Bash and keep the one we left as no operation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "funny_mirzakhani\n"
          ]
        }
      ],
      "source": [
        "!docker rm funny_mirzakhani"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hardcore_kare\n"
          ]
        }
      ],
      "source": [
        "!docker rm hardcore_kare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE     COMMAND               CREATED          STATUS                        PORTS     NAMES\n",
            "ce4d60427dcd   ubuntu    \"tail -f /dev/null\"   27 minutes ago   Exited (137) 14 minutes ago             alwaysup\n"
          ]
        }
      ],
      "source": [
        "!docker ps -a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are going to restart the Ubuntu container that we left running, this is done using the `start` command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "alwaysup\n"
          ]
        }
      ],
      "source": [
        "!docker start alwaysup"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We dive into it again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root@ce4d60427dcd:/#\n"
          ]
        }
      ],
      "source": [
        "!docker exec -it alwaysup bash"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the container, I can create a new folder called `dockerfolder`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": []
        }
      ],
      "source": [
        "!mkdir dockerfolder"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we list the files, the new folder will appear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bin  boot  dev  dockerfolder  etc  home  lib  lib32  lib64  libx32  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we exit the container"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "exit"
          ]
        }
      ],
      "source": [
        "!exit"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And we delete it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "alwaysup\n"
          ]
        }
      ],
      "source": [
        "!docker rm -f alwaysup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we list all the containers, the last one we created no longer appears."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
          ]
        }
      ],
      "source": [
        "!docker ps -a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's do everything again, but first we will create a folder on the host where we will share the data with the container"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "!mkdir dockerHostFolder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that the folder is empty."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "!ls dockerHostFolder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we get our absolute path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/wallabot/Documentos/web/portafolio/posts\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We recreate the container but add the ``-v`` option (``bind mount``). Next, we add the absolute path of the folder on the host and the absolute path of the folder in the container, ``-v <host path>:<container path>``"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4ede4512c293bdcc155e9c8e874dfb4a28e5163f4d5c7ddda24ad2863f28921b\n"
          ]
        }
      ],
      "source": [
        "!docker run -d --name alwaysup -v ~/Documentos/web/portafolio/posts/dockerHostFolder:/dockerContainerFolder ubuntu tail -f /dev/null"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We enter the container, list the files, and the folder we created already appears."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root@4ede4512c293:/#"
          ]
        }
      ],
      "source": [
        "!docker exec -it alwaysup bash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bin   dev                    etc   lib    lib64   media  opt   root  sbin  sys  usr\n",
            "boot  dockerContainerFolder  home  lib32  libx32  mnt    proc  run   srv   tmp  var\n"
          ]
        }
      ],
      "source": [
        "root@4ede4512c293:/# ls"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's go to the container directory that we have shared, create a file, and exit the container."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": []
        }
      ],
      "source": [
        "root@4ede4512c293:/# cd dockerContainerFolder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": []
        }
      ],
      "source": [
        "root@4ede4512c293:/dockerContainerFolder# touch bindFile.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "exit"
          ]
        }
      ],
      "source": [
        "root@4ede4512c293:/dockerContainerFolder# exit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's see what's inside the shared folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bindFile.txt\n"
          ]
        }
      ],
      "source": [
        "!ls dockerHostFolder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "But more than that, if we delete the container, the file is still there."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "alwaysup\n"
          ]
        }
      ],
      "source": [
        "!docker rm -f alwaysup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bindFile.txt\n"
          ]
        }
      ],
      "source": [
        "!ls dockerHostFolder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If I recreate the container sharing the folders, all files will be in the container."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6c021d37ea29d8b23fe5cd4968baa446085ae1756682f65340288b4c851c362d\n"
          ]
        }
      ],
      "source": [
        "!docker run -d --name alwaysup -v ~/Documentos/web/portafolio/posts/dockerHostFolder:/dockerContainerFolder ubuntu tail -f /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root@6c021d37ea29:/#"
          ]
        }
      ],
      "source": [
        "!docker exec -it alwaysup bash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bindFile.txt:/#"
          ]
        }
      ],
      "source": [
        "!root@6c021d37ea29:/# ls dockerContainerFolder/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We remove the container"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "alwaysup\n"
          ]
        }
      ],
      "source": [
        "!docker rm -f alwaysup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
          ]
        }
      ],
      "source": [
        "!docker ps -a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Volumes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Volumes were created as an evolution of ``bind mounts`` to provide more security. We can list all Docker volumes using ``docker volume ls``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DRIVER    VOLUME NAME\n"
          ]
        }
      ],
      "source": [
        "!docker volume ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's create a new volume for the Ubuntu container, for this we use the command ``docker volume create <volume name>``"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ubuntuVolume\n"
          ]
        }
      ],
      "source": [
        "!docker volume create ubuntuVolume"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we list the volumes again, the one we just created will appear."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DRIVER    VOLUME NAME\n",
            "local     ubuntuVolume\n"
          ]
        }
      ],
      "source": [
        "!docker volume ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "However, it does not appear as a folder in the host's file system. With `ls -d */` we list all the folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dockerHostFolder/  __pycache__/\n"
          ]
        }
      ],
      "source": [
        "!ls -d */"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's recreate a container, but this time we create it with the volume we just created using the ``--mount`` option, specifying the source volume with ``src=<volume name>`` (if the volume did not exist, Docker would create it), followed by the destination separated by a `,`, ``dst=<container path>``, i.e., ``--mount src=<volume name>,dst=<container path>``"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "42cdcddf4e46dc298a87b0570115e0b2fc900cb4c6db5eea22a61409b8cb271d\n"
          ]
        }
      ],
      "source": [
        "!docker run -d --name alwaysup --mount src=ubuntuVolume,dst=/dockerVolumeFolder ubuntu tail -f /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once created, we can view the container's volumes using the `inspect` command and filtering by `'{{.Mounts}}'`",
        "\n",
        "```bash\n",
        "$ docker inspect --format '{{.Mounts}}' alwaysup",
        "[",
        "{",
        "volume ubuntuVolume /var/lib/docker/volumes/ubuntuVolume/_data /dockerVolumeFolder local z true",
        "It seems like you've provided an incomplete or incorrect Markdown structure. Please provide the full Markdown text for translation.",
        "]",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that the volume is called `ubuntuVolume` and we can also see the path where it is stored, in this case at `/var/lib/docker/volumes/ubuntuVolume/_data`. We do the same as before, enter the container, create a file in the volume's path, exit, and check on the host if it has been created.",
        "\n",
        "```bash\n",
        "$ docker exec -it alwaysup bash",
        "root@42cdcddf4e46:/# touch dockerVolumeFolder/volumeFile.txt",
        "root@42cdcddf4e46:/# exit",
        "```\n",
        "\n",
        "\n",
        "```bash\n",
        "$ sudo ls /var/lib/docker/volumes/ubuntuVolume/_data",
        "volumeFile.txt",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The file is created"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Insert and extract files from a container"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, let's create a file that we want to copy into a container"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "!touch dockerHostFolder/text.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We enter the container",
        "\n",
        "```bash\n",
        "$ docker exec -it alwaysup bash",
        "root@42cdcddf4e46:/#",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create a new folder where we are going to copy the file and exit",
        "\n",
        "```bash\n",
        "root@42cdcddf4e46:/# mkdir folderToCopy",
        "root@42cdcddf4e46:/# ls",
        "bin  boot  dev  dockerVolumeFolder  etc  folderToCopy  home  lib  lib32  lib64  libx32  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var",
        "root@42cdcddf4e46:/# exit",
        "exit",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We copy the file into the container using the ``cp`` command, specifying the file I **want** to copy, the container where we want to copy it, and the path inside the container, ``docker cp <file> <container>:<container path>``"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "!docker cp dockerHostFolder/text.txt alwaysup:/folderToCopy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We go back into the container and check that the file is there.",
        "\n",
        "```bash\n",
        "$ docker exec -it alwaysup bash",
        "root@42cdcddf4e46:/# ls folderToCopy/",
        "It seems like you're referring to a file named `text.txt`. However, the content of the file is not provided here. Could you please share the content of the file so I can translate it for you?",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We exit the container",
        "\n",
        "```bash\n",
        "/# exit",
        "exit",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we are going to extract the file from the container and save it on the host with a different name. For this, we use the `cp` command again, but now specifying the container, the file path in the container, and the path and name we want the file to have on the host, `docker cp <container>:<docker file path> <host file path>`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "!docker cp alwaysup:/folderToCopy/text.txt dockerHostFolder/fileExtract.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that it is on the host"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bindFile.txt  fileExtract.txt  text.txt\n"
          ]
        }
      ],
      "source": [
        "!ls dockerHostFolder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Although the container is stopped, files can still be copied."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we delete the container"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "alwaysup\n"
          ]
        }
      ],
      "source": [
        "!docker rm -f alwaysup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fundamental Concepts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Images are the files (\"templates\") with all the configuration to create a container. Every time we create a container, it is created from an image. When we created new containers for the first time, a message appeared saying that we did not have the image and that it was going to download it. On Docker Hub, there are numerous images of all kinds of machines, but for a very specific development environment, we can create our own template to pass it on to someone so they can work in a container with the same configuration as ours."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see all the images we have saved on our computer using the command ``docker image ls``"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REPOSITORY    TAG       IMAGE ID       CREATED         SIZE\n",
            "nginx         latest    2d389e545974   8 hours ago     142MB\n",
            "ubuntu        latest    2dc39ba059dc   11 days ago     77.8MB\n",
            "hello-world   latest    feb5d9fea6a5   11 months ago   13.3kB\n"
          ]
        }
      ],
      "source": [
        "!docker image ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see the sizes, and we can see how the `nginx` one takes up a lot of space, which is why it took longer to download than the others."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Another column we can see is the ``TAG`` one, which indicates the version of the image. In all cases, it says ``latest``, meaning it is the latest version. That is, when we download it, we have downloaded the latest version available on Docker Hub. This is not optimal in a development environment because we might download an Ubuntu image without specifying a version, for example, 20.04. But after some time, someone else may want to develop with you and download that image, but since they don't specify the version, they will download the latest one again, which could be 22.04 in their case. This can lead to issues where things work for one person but not for another."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see all the images available on Docker Hub by going to `https://hub.docker.com/`. There you can search for the image that best fits the project you want to work on. If we navigate to the Ubuntu image, for example, we can see the versions (`tags`) of the images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are going to download, **but not execute** an image. For this, we use the command ``docker pull <hub> <image name>:<tag>``. If we do not specify the hub, it will download from docker hub by default, but we can specify another one, for example a private one from our organization. Also, if we do not specify the tag, it will download the latest version by default."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20.04: Pulling from library/ubuntu\n",
            "\n",
            "\u001b[1BDigest: sha256:35ab2bf57814e9ff49e365efd5a5935b6915eede5c7f8581e9e1b85e0eecbe16[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\n",
            "Status: Downloaded newer image for ubuntu:20.04\n",
            "docker.io/library/ubuntu:20.04\n"
          ]
        }
      ],
      "source": [
        "!docker pull ubuntu:20.04"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we list the images again, we see that we now have two Ubuntu images, one with the tag `20.04` and another with the tag `latest`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REPOSITORY    TAG       IMAGE ID       CREATED         SIZE\n",
            "nginx         latest    2d389e545974   8 hours ago     142MB\n",
            "ubuntu        latest    2dc39ba059dc   11 days ago     77.8MB\n",
            "ubuntu        20.04     a0ce5a295b63   11 days ago     72.8MB\n",
            "hello-world   latest    feb5d9fea6a5   11 months ago   13.3kB\n"
          ]
        }
      ],
      "source": [
        "!docker image ls"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating images using `Dockerfile`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create a directory on the host called `dockerImages` to work in it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "!mkdir dockerImages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create a `Dockerfile` with which we will create an image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "!touch dockerImages/Dockerfile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We open the created file with our preferred editor and write the following:",
        "\n",
        "```Dockerfile\n",
        "FROM ubuntu:latest",
        "```\n",
        "\n",
        "This tells Docker to create the image based on the `latest` image of Ubuntu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below, we write a command that will be executed at compile time",
        "\n",
        "```Dockerfile\n",
        "RUN touch /test.txt",
        "```\n",
        "\n",
        "This means that when the `Dockerfile` is built, that command will be executed, but not when the container of the image is run."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "At the end, the `Dockerfile` looks like this:",
        "```dockerfile\n",
        "FROM ubuntu:latest",
        "RUN touch /test.txt",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We compile the `Dockerfile` using the `build` command, with the `-t` option we can give it a `tag`. Finally, we need to specify the path of the `build` context, which we will explain later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sending build context to Docker daemon  2.048kB\n",
            "Step 1/2 : FROM ubuntu:latest\n",
            " ---> 2dc39ba059dc\n",
            "Step 2/2 : RUN touch /test.txt\n",
            " ---> Using cache\n",
            " ---> a78cf3ea16d8\n",
            "Successfully built a78cf3ea16d8\n",
            "Successfully tagged ubuntu:test\n",
            "\n",
            "Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\n"
          ]
        }
      ],
      "source": [
        "!docker build -t ubuntu:test ./dockerImages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see, it compiles in 2 steps, each one has an `id`, each of these `id`s are layers of the image, we will also see this later.",
        "\n",
        "We go back to see the images we have saved on our computer and the one we just created appears."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REPOSITORY    TAG       IMAGE ID       CREATED         SIZE\n",
            "ubuntu        test      a78cf3ea16d8   8 minutes ago   77.8MB\n",
            "nginx         latest    2d389e545974   8 hours ago     142MB\n",
            "ubuntu        latest    2dc39ba059dc   11 days ago     77.8MB\n",
            "ubuntu        20.04     a0ce5a295b63   11 days ago     72.8MB\n",
            "hello-world   latest    feb5d9fea6a5   11 months ago   13.3kB\n"
          ]
        }
      ],
      "source": [
        "!docker image ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We run the container from the image we just created",
        "\n",
        "```bash\n",
        "$ docker run -it ubuntu:test",
        "root@b57b9d4eedeb:/#",
        "```\n",
        "\n",
        "We enter the bash of the container. As we said, the RUN command is executed at image build time, so the file that we have asked to be created should be in our container.",
        "\n",
        "```bash\n",
        "root@b57b9d4eedeb:/# ls",
        "bin  boot  dev  etc  home  lib  lib32  lib64  libx32  media  mnt  opt  proc  root  run  sbin  srv  sys  test.txt  tmp  usr  var",
        "```\n",
        "\n",
        "It is important to understand that this file was created when the image was built, that is, the container image already has this file. It is not created when the container is launched.",
        "\n",
        "We exit the container",
        "\n",
        "```bash\n",
        "root@b57b9d4eedeb:/# exit",
        "exit",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since we already have an image, we could upload it to the Docker hub, but let's list the images again before doing that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REPOSITORY    TAG       IMAGE ID       CREATED          SIZE\n",
            "ubuntu        test      a78cf3ea16d8   20 minutes ago   77.8MB\n",
            "nginx         latest    2d389e545974   8 hours ago      142MB\n",
            "ubuntu        latest    2dc39ba059dc   11 days ago      77.8MB\n",
            "ubuntu        20.04     a0ce5a295b63   11 days ago      72.8MB\n",
            "hello-world   latest    feb5d9fea6a5   11 months ago    13.3kB\n"
          ]
        }
      ],
      "source": [
        "!docker image ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we look, it is telling us that the image we just created belongs to the ubuntu repository, but we do not have access to the ubuntu repository, so we need to create an account on Docker Hub to be able to upload the image to our own repository. In my case, my repository is called `maximofn`, so I change the repository of the image using the `tag` command, specifying the image we want to change and the new repository. The new repository usually indicates the name of the repository followed by the type of image and the tag, in my case `maximofn/ubuntu:test`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "!docker tag ubuntu:test maximofn/ubuntu:test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we now list the images again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REPOSITORY        TAG       IMAGE ID       CREATED          SIZE\n",
            "ubuntu            test      a78cf3ea16d8   24 minutes ago   77.8MB\n",
            "maximofn/ubuntu   test      a78cf3ea16d8   24 minutes ago   77.8MB\n",
            "nginx             latest    2d389e545974   8 hours ago      142MB\n",
            "ubuntu            latest    2dc39ba059dc   11 days ago      77.8MB\n",
            "ubuntu            20.04     a0ce5a295b63   11 days ago      72.8MB\n",
            "hello-world       latest    feb5d9fea6a5   11 months ago    13.3kB\n"
          ]
        }
      ],
      "source": [
        "!docker image ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we need to log in to Docker Hub to be able to upload the image, for this we use the `login` command.",
        "\n",
        "```bash\n",
        "$ docker login",
        "Login with your Docker ID to push and pull images from Docker Hub. If you do not have a Docker ID, head over to https://hub.docker.com to create one.",
        "Username: maximofn",
        "Password:",
        "\n",
        "Login succeeded",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can upload the image using the `push` command"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The push refers to repository [docker.io/maximofn/ubuntu]\n",
            "\n",
            "\u001b[1B06994357: Preparing \n",
            "\u001b[2B06994357: Pushed  from library/ubuntu \u001b[2A\u001b[2Ktest: digest: sha256:318d83fc3c35ff930d695b0dc1c5ad1b0ea54e1ec6e3478b8ca85c05fd793c4e size: 735\n"
          ]
        }
      ],
      "source": [
        "!docker push maximofn/ubuntu:test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "He uploaded only the first layer, the second one, since I used it based on the Ubuntu image, what it does is place a pointer to that image so that layers are not uploaded more than once."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It's important to keep in mind that this repository is public, so you should not upload images with sensitive data. Additionally, if an image is not used within 6 months, it will be deleted."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The layer system"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using the `history` command we can see the layers of an image. If we look at the layers of the image we just created, we use `docker history ubuntu:test`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IMAGE          CREATED        CREATED BY                                      SIZE      COMMENT\n",
            "a78cf3ea16d8   3 minutes ago  /bin/sh -c touch /test.txt                      0B        \n",
            "2dc39ba059dc   12 days ago    /bin/sh -c #(nop)  CMD [\"bash\"]                 0B        \n",
            "<missing>      12 days ago    /bin/sh -c #(nop) ADD file:a7268f82a86219801\u2026   77.8MB    \n"
          ]
        }
      ],
      "source": [
        "!docker history ubuntu:test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that the first layer has the command we introduced in the `Dockerfile`, and it says it was created 3 minutes ago. However, the rest of the layers were created 12 days ago, and they are the layers of the Ubuntu image we based ourselves on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To the `Dockerfile` we created earlier, we add the line",
        "\n",
        "```docker\n",
        "RUN rm /test.txt",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "At the end, the `Dockerfile` looks like this:",
        "```dockerfile\n",
        "FROM ubuntu:latest",
        "RUN touch /test.txt",
        "RUN rm /test.txt",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we compile again, let's see what happens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sending build context to Docker daemon  2.048kB\n",
            "Step 1/3 : FROM ubuntu:latest\n",
            " ---> 2dc39ba059dc\n",
            "Step 2/3 : RUN touch /test.txt\n",
            " ---> Using cache\n",
            " ---> a78cf3ea16d8\n",
            "Step 3/3 : RUN rm /test.txt\n",
            " ---> Running in c2e6887f2025\n",
            "Removing intermediate container c2e6887f2025\n",
            " ---> 313243a9b573\n",
            "Successfully built 313243a9b573\n",
            "Successfully tagged ubuntu:test\n",
            "\n",
            "Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\n"
          ]
        }
      ],
      "source": [
        "!docker build -t ubuntu:test ./dockerImages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see, there is an additional layer with the new line we have added. If we look at the image layers again with `history`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IMAGE          CREATED              CREATED BY                                      SIZE      COMMENT\n",
            "313243a9b573   About a minute ago   /bin/sh -c rm /test.txt                         0B        \n",
            "a78cf3ea16d8   3 minutes ago        /bin/sh -c touch /test.txt                      0B        \n",
            "2dc39ba059dc   12 days ago          /bin/sh -c #(nop)  CMD [\"bash\"]                 0B        \n",
            "<missing>      12 days ago          /bin/sh -c #(nop) ADD file:a7268f82a86219801\u2026   77.8MB    \n"
          ]
        }
      ],
      "source": [
        "!docker history ubuntu:test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that the first layers are the same as before and it has added a new layer with the new command"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Search on Docker Hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There's no need to go to the Docker Hub page to search for images; you can do it from the terminal. For this, we use the command `docker search <image name>`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NAME                             DESCRIPTION                                     STARS     OFFICIAL   AUTOMATED\n",
            "ubuntu                           Ubuntu is a Debian-based Linux operating sys\u2026   16425     [OK]       \n",
            "websphere-liberty                WebSphere Liberty multi-architecture images \u2026   297       [OK]       \n",
            "open-liberty                     Open Liberty multi-architecture images based\u2026   62        [OK]       \n",
            "neurodebian                      NeuroDebian provides neuroscience research s\u2026   104       [OK]       \n",
            "ubuntu-debootstrap               DEPRECATED; use \"ubuntu\" instead                52        [OK]       \n",
            "ubuntu-upstart                   DEPRECATED, as is Upstart (find other proces\u2026   115       [OK]       \n",
            "ubuntu/nginx                     Nginx, a high-performance reverse proxy & we\u2026   98                   \n",
            "ubuntu/squid                     Squid is a caching proxy for the Web. Long-t\u2026   66                   \n",
            "ubuntu/cortex                    Cortex provides storage for Prometheus. Long\u2026   4                    \n",
            "ubuntu/apache2                   Apache, a secure & extensible open-source HT\u2026   60                   \n",
            "ubuntu/kafka                     Apache Kafka, a distributed event streaming \u2026   35                   \n",
            "ubuntu/mysql                     MySQL open source fast, stable, multi-thread\u2026   53                   \n",
            "ubuntu/bind9                     BIND 9 is a very flexible, full-featured DNS\u2026   62                   \n",
            "ubuntu/prometheus                Prometheus is a systems and service monitori\u2026   51                   \n",
            "ubuntu/zookeeper                 ZooKeeper maintains configuration informatio\u2026   12                   \n",
            "ubuntu/postgres                  PostgreSQL is an open source object-relation\u2026   31                   \n",
            "ubuntu/redis                     Redis, an open source key-value store. Long-\u2026   19                   \n",
            "ubuntu/grafana                   Grafana, a feature rich metrics dashboard & \u2026   9                    \n",
            "ubuntu/memcached                 Memcached, in-memory keyvalue store for smal\u2026   5                    \n",
            "ubuntu/dotnet-aspnet             Chiselled Ubuntu runtime image for ASP.NET a\u2026   11                   \n",
            "ubuntu/dotnet-deps               Chiselled Ubuntu for self-contained .NET & A\u2026   11                   \n",
            "ubuntu/prometheus-alertmanager   Alertmanager handles client alerts from Prom\u2026   9                    \n",
            "ubuntu/dotnet-runtime            Chiselled Ubuntu runtime image for .NET apps\u2026   10                   \n",
            "ubuntu/cassandra                 Cassandra, an open source NoSQL distributed \u2026   2                    \n",
            "ubuntu/telegraf                  Telegraf collects, processes, aggregates & w\u2026   4                    \n"
          ]
        }
      ],
      "source": [
        "!docker search ubuntu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using Docker to Create Applications"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Port Exposure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We previously saw how we could link a container port to a computer port (`-p 8080:80`). But for that to be possible, when creating the image, the port must be exposed. This is done by adding the line `EXPOSE <port>` to the Dockerfile, as in the previous case.",
        "\n",
        "```docker\n",
        "EXPOSE 80",
        "```\n",
        "\n",
        "Or use images as a base that already have exposed ports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Layer Cache Reuse When Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When we compile an image, if any of the layers we have defined have already been compiled before, Docker detects this and uses them, without recompiling them. If we recompile the image we have defined in the `Dockerfile` now, it will take very little time because all the layers are already compiled and Docker does not recompile them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sending build context to Docker daemon  2.048kB\n",
            "Step 1/3 : FROM ubuntu:latest\n",
            " ---> 2dc39ba059dc\n",
            "Step 2/3 : RUN touch /test.txt\n",
            " ---> Using cache\n",
            " ---> a78cf3ea16d8\n",
            "Step 3/3 : RUN rm /test.txt\n",
            " ---> Using cache\n",
            " ---> 313243a9b573\n",
            "Successfully built 313243a9b573\n",
            "Successfully tagged ubuntu:test\n",
            "\n",
            "Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\n"
          ]
        }
      ],
      "source": [
        "!docker build -t ubuntu:test ./dockerImages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the second and third layer, the text `Using cache` appears.",
        "\n",
        "Since this is a Jupyter notebook, when you run the cells it gives you information about how long they take to execute. The last time I compiled the image, it took 1.4 seconds, while now it has taken 0.5 seconds."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "But if I now change the Dockerfile, and in the first line, where it said we were based on the latest version of Ubuntu, we change to version 20.04",
        "\n",
        "```docker\n",
        "FROM ubuntu:20.04",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "At the end, the `Dockerfile` looks like this:",
        "```dockerfile\n",
        "FROM ubuntu:20.04",
        "RUN touch /test.txt",
        "RUN rm /test.txt",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we compile again, it will take much longer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sending build context to Docker daemon  2.048kB\n",
            "Step 1/3 : FROM ubuntu:20.04\n",
            " ---> a0ce5a295b63\n",
            "Step 2/3 : RUN touch /test.txt\n",
            " ---> Running in a40fe8df2c0d\n",
            "Removing intermediate container a40fe8df2c0d\n",
            " ---> 0bb9b452c11f\n",
            "Step 3/3 : RUN rm /test.txt\n",
            " ---> Running in 2e14919f3685\n",
            "Removing intermediate container 2e14919f3685\n",
            " ---> fdc248fa833b\n",
            "Successfully built fdc248fa833b\n",
            "Successfully tagged ubuntu:test\n",
            "\n",
            "Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\n"
          ]
        }
      ],
      "source": [
        "!docker build -t ubuntu:test ./dockerImages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It took 1.9 seconds and the text `Using cache` no longer appears."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When changing the first layer, Docker recompiles all layers. This can be a problem because when developing code, the following case may occur:",
        "* We developed the code on our computer",
        "* When building the image, we copy all the code from our computer to the container",
        "* Then we ask the image to install the necessary libraries",
        "\n",
        "This can cause that when changing any part of the code, having to recompile the image, the layer where the libraries are installed will have to be recompiled, since a previous layer has changed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To solve this, the idea would be that when creating the image, we first request that the libraries be installed and then copy the code from our computer to the container. This way, every time we change the code and recompile the image, only the layer where the code is copied will be recompiled, making the compilation faster."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You might think it's better to share a folder between the host and the container (`bind mount`) where we will have the code, so there's no need to rebuild the image every time the code changes. And the answer is that you're right; I only used this example because it's very easy to understand, but it's meant to illustrate that when creating images, you should think carefully so that if you do need to rebuild it, it recompiles the minimum number of layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Writing a Correct Dockerfile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we have seen, Docker does not recompile layers of a Dockerfile if it has already compiled them before, so it loads them from cache. Let's see how the correct way to write a Dockerfile should be to take advantage of this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's start from this Dockerfile to comment on possible corrections",
        "\n",
        "``` Dockerfile\n",
        "FROM ubuntu",
        "COPY ./sourceCode /sourceCode",
        "RUN apt-get update",
        "RUN apt-get install -y python3 ssh",
        "CMD [\"python3\", \"/sourceCode/sourceApp/app.py\"]",
        "```\n",
        "\n",
        "As can be seen, it starts with an Ubuntu image, the folder with the code is copied, the repositories are updated, Python is installed, SSH is also installed, and the application is run."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Copy the code before execution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we said before, if we first copy the code and then install Python, every time we make a change to the code and build the image, it will build the entire image. But if we copy the code after installing Python, every time we change the code and build the image, it will only build from the code copy and will not reinstall Python, so the Dockerfile should be changed to this:",
        "\n",
        "``` Dockerfile\n",
        "FROM ubuntu",
        "RUN apt-get update",
        "RUN apt-get install -y python3 ssh",
        "COPY ./sourceCode /sourceCode",
        "CMD [\"python3\", \"/sourceCode/sourceApp/app.py\"]",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Copy only the necessary code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are copying the folder with all the code, but perhaps inside we have code that we don't need, so we need to copy only the code that we really need for the application, this way the image will take up less memory. So the Dockerfile would look like this",
        "\n",
        "``` Dockerfile\n",
        "FROM ubuntu",
        "RUN apt-get update",
        "RUN apt-get install -y python3 ssh",
        "COPY ./sourceCode/sourceApp /sourceCode/sourceApp",
        "CMD [\"python3\", \"/sourceCode/sourceApp/app.py\"]",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Update repositories and install Python in the same line"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are updating the repositories in one line and installing python3 in another.",
        "\n",
        "``` Dockerfile\n",
        "FROM ubuntu",
        "RUN apt-get update && apt-get install -y python3 ssh",
        "COPY ./sourceCode/sourceApp /sourceCode/sourceApp",
        "CMD [\"python3\", \"/sourceCode/sourceApp/app.py\"]",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Do not install ssh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We had installed ssh in the image to be able to debug if needed, but that makes the image take up more memory. If we need to debug, we should enter the container, install ssh, and then debug. Therefore, we remove the installation of ssh.",
        "\n",
        "``` Dockerfile\n",
        "FROM ubuntu",
        "RUN apt-get update && apt-get install -y python3",
        "COPY ./sourceCode/sourceApp /sourceCode/sourceApp",
        "CMD [\"python3\", \"/sourceCode/sourceApp/app.py\"]",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Use `--no-install-recommends`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When we install something in Ubuntu, it installs recommended packages that we don't need, so the image takes up more space. Therefore, to avoid this, we add `--no-install-recommends` to the installation.",
        "\n",
        "``` Dockerfile\n",
        "FROM ubuntu",
        "RUN apt-get update && apt-get install -y python3 --no-install-recommends",
        "COPY ./sourceCode/sourceApp /sourceCode/sourceApp",
        "CMD [\"python3\", \"/sourceCode/sourceApp/app.py\"]",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Delete list of updated repositories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have updated the list of repositories and installed python, but once that's done we no longer need the updated repository list, as it will only make the image larger, so we remove them after installing python and in the same line.",
        "\n",
        "``` Dockerfile\n",
        "FROM ubuntu",
        "RUN apt-get update && apt-get install -y python3 --no-install-recommends && rm -rf /var/lib/apt/lists/*",
        "COPY ./sourceCode/sourceApp /sourceCode/sourceApp",
        "CMD [\"python3\", \"/sourceCode/sourceApp/app.py\"]",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Use a Python image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Everything we have done to update the package list and install Python is not necessary, as there are already Python images based on Ubuntu that have likely followed good practices, possibly even better than what we would do ourselves, and have been scanned for vulnerabilities by Docker Hub. Therefore, we remove all of that and start from a Python image.",
        "\n",
        "``` Dockerfile\n",
        "FROM python",
        "COPY ./sourceCode/sourceApp /sourceCode/sourceApp",
        "CMD [\"python3\", \"/sourceCode/sourceApp/app.py\"]",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Specify the Python image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If the Python image is not specified, the latest one is being downloaded, but depending on when you build the container, a different version might be downloaded. Therefore, you should add the tag with the desired Python version.",
        "\n",
        "``` Dockerfile\n",
        "FROM python:3.9.18",
        "COPY ./sourceCode/sourceApp /sourceCode/sourceApp",
        "CMD [\"python3\", \"/sourceCode/sourceApp/app.py\"]",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Choose a small tag"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have chosen the tag `3.9.18`, but that version of Python has a lot of libraries that we might not need, so we can use the `3.9.18-slim` versions which have many fewer installed libraries, or the `3.9.18-alpine` version which is a Python version on Alpine and not on Ubuntu. Alpine is a very lightweight Linux distribution with very few packages installed and is often used in Docker containers to take up very little space.",
        "\n",
        "The `3.9.18` Python image takes up 997 MB, the `3.9.18-slim` takes up 126 MB, and the `3.9.18-alpine` takes up 47.8 MB.",
        "\n",
        "``` Dockerfile\n",
        "FROM python:3.9.18-alpine",
        "COPY ./sourceCode/sourceApp /sourceCode/sourceApp",
        "CMD [\"python3\", \"/sourceCode/sourceApp/app.py\"]",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Specify the workspace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Instead of specifying the image path as `/sourceCode/sourceApp`, we set this path to be the image's workspace. This way, when we copy the code or run the application, there is no need to specify the path.",
        "\n",
        "``` Dockerfile\n",
        "FROM python:3.9.18-alpine",
        "WORKDIR /sourceCode/sourceApp",
        "COPY ./sourceCode/sourceApp .",
        "CMD [\"python3\", \"app.py\"]",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Specify the workspace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Instead of specifying the image path as `/sourceCode/sourceApp`, we set this path to be the image's workspace. This way, when we copy the code or run the application, there is no need to specify the path.",
        "\n",
        "``` Dockerfile\n",
        "FROM python:3.9.18-alpine",
        "WORKDIR /sourceCode/sourceApp",
        "COPY ./sourceCode/sourceApp .",
        "CMD [\"python3\", \"app.py\"]",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Code shared in a `bind mount` folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We had created a folder called `dockerHostFolder` in which we had shared files between the host and a container. Inside, there should also be three files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bindFile.txt  fileExtract.txt  text.txt\n"
          ]
        }
      ],
      "source": [
        "!ls dockerHostFolder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's use the `text.txt` file to check that out. Let's see what's inside `text.txt`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "!cat dockerHostFolder/text.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There is no output, the file is empty. Let's create an Ubuntu container again, sharing the folder `dockerHostFolder`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24adbded61f507cdf7f192eb5e246e43ee3ffafc9944b7c57918eb2d547dff19\n"
          ]
        }
      ],
      "source": [
        "!docker run --name alwaysup -d -v ~/Documentos/web/portafolio/posts/dockerHostFolder:/dockerContainerFolder ubuntu tail -f /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that the container is running"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE     COMMAND               CREATED          STATUS          PORTS     NAMES\n",
            "24adbded61f5   ubuntu    \"tail -f /dev/null\"   16 seconds ago   Up 15 seconds             alwaysup\n"
          ]
        }
      ],
      "source": [
        "!docker ps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We enter the container, we see that `text.txt` is there and it is empty",
        "\n",
        "```bash\n",
        "$ docker exec -it alwaysup bash",
        "root@24adbded61f5:/# ls dockerContainerFolder/",
        "bindFile.txt  fileExtract.txt  text.txt",
        "root@24adbded61f5:/# cat dockerContainerFolder/text.txt",
        "root@24adbded61f5:/#",
        "```\n",
        "\n",
        "Now we open the `text.txt` file on the host with the text editor of our choice, write `Hello world` and save it. If we now check what's inside the file in the container, we will see the same text.",
        "\n",
        "```bash\n",
        "root@24adbded61f5:/# cat dockerContainerFolder/text.txt",
        "Hello world",
        "```\n",
        "\n",
        "Now we edit the file in the container and exit the container",
        "\n",
        "```bash\n",
        "root@24adbded61f5:/# echo hello container > dockerContainerFolder/text.txt",
        "root@24adbded61f5:/# cat dockerContainerFolder/text.txt",
        "hello container",
        "root@24adbded61f5:/# exit",
        "exit",
        "```\n",
        "\n",
        "If we look at the file in the host, we will see the text we wrote in the container"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hola contenedor\n"
          ]
        }
      ],
      "source": [
        "!cat dockerHostFolder/text.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We delete the container"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "alwaysup\n"
          ]
        }
      ],
      "source": [
        "!docker rm -f alwaysup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Connecting containers via network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we want to have several containers running and want them to communicate, we can make them communicate through a network. Docker gives us the possibility to do this through its virtual networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's see what networks Docker has with the command `docker network ls`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NETWORK ID     NAME      DRIVER    SCOPE\n",
            "de6e8b7b737e   bridge    bridge    local\n",
            "da1f5f6fccc0   host      host      local\n",
            "d3b0d93993c0   none      null      local\n"
          ]
        }
      ],
      "source": [
        "!docker network ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that by default Docker has three networks",
        "* bridge: It's for backward compatibility with previous versions, but we shouldn't use it anymore",
        "* host: It is the host's network",
        "* none: This is the option we should use if we want a container to have no internet access"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can create new networks to which other containers can connect, for this we use the command `docker network create <name>`, in addition, for other containers to be able to connect, we must add the option `--attachable`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2f6f3ddbfa8642e9f6819aa0965c16339e9e910be7bcf56ebb718fcac324cc27\n"
          ]
        }
      ],
      "source": [
        "!docker network create --attachable myNetwork"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can inspect it using the command `docker network inspect <name>`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "    {\n",
            "        \"Name\": \"myNetwork\",\n",
            "        \"Id\": \"2f6f3ddbfa8642e9f6819aa0965c16339e9e910be7bcf56ebb718fcac324cc27\",\n",
            "        \"Created\": \"2022-09-14T15:20:08.539830161+02:00\",\n",
            "        \"Scope\": \"local\",\n",
            "        \"Driver\": \"bridge\",\n",
            "        \"EnableIPv6\": false,\n",
            "        \"IPAM\": {\n",
            "            \"Driver\": \"default\",\n",
            "            \"Options\": {},\n",
            "            \"Config\": [\n",
            "                {\n",
            "                    \"Subnet\": \"172.18.0.0/16\",\n",
            "                    \"Gateway\": \"172.18.0.1\"\n",
            "                }\n",
            "            ]\n",
            "        },\n",
            "        \"Internal\": false,\n",
            "        \"Attachable\": true,\n",
            "        \"Ingress\": false,\n",
            "        \"ConfigFrom\": {\n",
            "            \"Network\": \"\"\n",
            "        },\n",
            "        \"ConfigOnly\": false,\n",
            "        \"Containers\": {},\n",
            "        \"Options\": {},\n",
            "        \"Labels\": {}\n",
            "    }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "!docker network inspect myNetwork"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we need to create two containers so they can communicate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's create a new container, which we will call `container1`, with a shared folder that will be called `folder1` inside it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a5fca8ba1e4ff0a67002f8f1b8cc3cd43185373c2a7e295546f774059ad8dd1a\n"
          ]
        }
      ],
      "source": [
        "!docker run --name container1 -d -v ~/Documentos/web/portafolio/posts/dockerHostFolder:/folder1 ubuntu tail -f /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we create another container, called `container2`, with another shared folder, but it should be named `folder2`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6c8dc18315488ef686f7548516c19b3d716728dd8a173cdb889ec0dd082232f9\n"
          ]
        }
      ],
      "source": [
        "!docker run --name container2 -d -v ~/Documentos/web/portafolio/posts/dockerHostFolder:/folder2 ubuntu tail -f /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see the containers running and we see that both are there."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE     COMMAND               CREATED         STATUS         PORTS     NAMES\n",
            "6c8dc1831548   ubuntu    \"tail -f /dev/null\"   3 seconds ago   Up 2 seconds             container2\n",
            "a5fca8ba1e4f   ubuntu    \"tail -f /dev/null\"   4 seconds ago   Up 3 seconds             container1\n"
          ]
        }
      ],
      "source": [
        "!docker ps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we need to connect the containers to the network, for this we use the command `docker network connect <network name> <container name>`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "!docker network connect myNetwork container1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "!docker network connect myNetwork container2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To check that they have connected correctly, we can inspect the network, but filtering by the connected containers.",
        "\n",
        "```bash\n",
        "$ docker network inspect --format '{{.Containers}}' myNetwork",
        "map",
        "[",
        "6c8dc18315488ef686f7548516c19b3d716728dd8a173cdb889ec0dd082232f9:",
        "{",
        "container2",
        "This appears to be a SHA-256 hash, which is not translatable. If you intended to provide markdown text for translation, please provide the actual text content instead of a hash value.",
        "02:42:ac:12:00:03",
        "172.18.0.3/16",
        "}",
        "a5fca8ba1e4ff0a67002f8f1b8cc3cd43185373c2a7e295546f774059ad8dd1a:",
        "{",
        "container1",
        "This does not appear to be Markdown text, but rather a hash or unique identifier. If you intended to provide Markdown content for translation, please share the appropriate text.",
        "02:42:ac:12:00:02",
        "172.18.0.2/16",
        "It seems like there was an issue with the input you provided. Could you please provide the Markdown text you would like to be translated?",
        "]",
        "```\n",
        "\n",
        "As we can see, the container `container1` has the IP `172.18.0.2` and the container `container2` has the IP `172.18.0.3`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We get inside the container `container1` and install `ping`",
        "\n",
        "``` bash\n",
        "$ docker exec -it container1 bash",
        "root@a5fca8ba1e4f:/# apt update",
        "...",
        "root@a5fca8ba1e4f:/# apt install iputils-ping",
        "...",
        "root@a5fca8ba1e4f:/#",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We get inside the container `container2` and install `ping`",
        "\n",
        "```bash\n",
        "$ docker exec -it container2 bash",
        "root@a5fca8ba1e4f:/# apt update",
        "...",
        "root@a5fca8ba1e4f:/# apt install iputils-ping",
        "...",
        "root@a5fca8ba1e4f:/#",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now from the container `container1` we ping the IP `172.18.0.3`, which belongs to the container `container2`",
        "\n",
        "```bash\n",
        "root@a5fca8ba1e4f:/# ping 172.18.0.3",
        "PING 172.18.0.3 (172.18.0.3) 56(84) bytes of data.",
        "64 bytes from 172.18.0.3: icmp_seq=1 ttl=64 time=0.115 ms",
        "64 bytes from 172.18.0.3: icmp_seq=2 ttl=64 time=0.049 ms",
        "64 bytes from 172.18.0.3: icmp_seq=3 ttl=64 time=0.056 ms",
        "64 bytes from 172.18.0.3: icmp_seq=4 ttl=64 time=0.060 ms",
        "^C",
        "--- 172.18.0.3 ping statistics ---",
        "4 packets transmitted, 4 received, 0% packet loss, time 3068ms",
        "rtt min/avg/max/mdev = 0.049/0.070/0.115/0.026 ms",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And from the container `container2` we make a ping to the IP `172.18.0.2`, which belongs to the container `container1`",
        "\n",
        "```bash\n",
        "root@6c8dc1831548:/# ping 172.18.0.2",
        "PING 172.18.0.2 (172.18.0.2) 56(84) bytes of data.",
        "64 bytes from 172.18.0.2: icmp_seq=1 ttl=64 time=0.076 ms",
        "64 bytes from 172.18.0.2: icmp_seq=2 ttl=64 time=0.045 ms",
        "64 bytes from 172.18.0.2: icmp_seq=3 ttl=64 time=0.049 ms",
        "64 bytes from 172.18.0.2: icmp_seq=4 ttl=64 time=0.051 ms",
        "^C",
        "--- 172.18.0.2 ping statistics ---",
        "4 packets transmitted, 4 received, 0% packet loss, time 3074ms",
        "rtt min/avg/max/mdev = 0.045/0.055/0.076/0.012 ms",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "But there is something better that Docker allows us to do: if I don't know the IP of the container I want to connect to, instead of writing its IP, I can write its name."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now from the container `container1` we ping the IP of `container2`",
        "\n",
        "```bash\n",
        "root@a5fca8ba1e4f:/# ping container2",
        "PING container2 (172.18.0.3) 56(84) bytes of data.",
        "64 bytes from container2.myNetwork (172.18.0.3): icmp_seq=1 ttl=64 time=0.048 ms",
        "64 bytes from container2.myNetwork (172.18.0.3): icmp_seq=2 ttl=64 time=0.050 ms",
        "64 bytes from container2.myNetwork (172.18.0.3): icmp_seq=3 ttl=64 time=0.052 ms",
        "64 bytes from container2.myNetwork (172.18.0.3): icmp_seq=4 ttl=64 time=0.053 ms",
        "^C",
        "--- container2 ping statistics ---",
        "4 packets transmitted, 4 received, 0% packet loss, time 3071ms",
        "rtt min/avg/max/mdev = 0.048/0.050/0.053/0.002 ms",
        "```\n",
        "\n",
        "As we can see, Docker knows that the IP of the container `container2` is `172.18.0.3`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And from the container `container2` we make a ping to the IP of `container1`",
        "\n",
        "```bash\n",
        "root@6c8dc1831548:/# ping container1",
        "PING container1 (172.18.0.2) 56(84) bytes of data.",
        "64 bytes from container1.myNetwork (172.18.0.2): icmp_seq=1 ttl=64 time=0.051 ms",
        "64 bytes from container1.myNetwork (172.18.0.2): icmp_seq=2 ttl=64 time=0.058 ms",
        "64 bytes from container1.myNetwork (172.18.0.2): icmp_seq=3 ttl=64 time=0.052 ms",
        "64 bytes from container1.myNetwork (172.18.0.2): icmp_seq=4 ttl=64 time=0.056 ms",
        "^C",
        "--- container1 ping statistics ---",
        "4 packets transmitted, 4 received, 0% packet loss, time 3057ms",
        "rtt min/avg/max/mdev = 0.051/0.054/0.058/0.003 ms",
        "```\n",
        "\n",
        "As we can see, Docker knows that the IP of the container `container1` is `172.18.0.2`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We exit the containers and delete them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "container1\n",
            "container2\n"
          ]
        }
      ],
      "source": [
        "!docker rm -f container1 container2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We also delete the network we have created"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "myNetwork\n"
          ]
        }
      ],
      "source": [
        "!docker network rm myNetwork"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Use of GPUs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To be able to use the host's GPUs within Docker containers, it is necessary to follow the steps described in the installation page of the [Nvidia container toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set up the repository and the GPG key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We need to configure the `nvidia container toolkit` repository and the GPG key, for this we run the following command in the console",
        "\n",
        "``` bash\n",
        "distribution=$(. /etc/os-release;echo $ID$VERSION_ID) \\",
        "&& curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\",
        "&& curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | \\",
        "sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \\",
        "sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Installation of `nvidia container toolkit`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once we have updated the repository and the key, we update the repositories using the command",
        "``` bash\n",
        "sudo apt update",
        "```\n",
        "\n",
        "And we install `nvidia container toolkit`",
        "``` bash\n",
        "sudo apt install -y nvidia-docker2",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Docker Reset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once we have finished, we need to restart the Docker daemon by",
        "``` bash\n",
        "sudo systemctl restart docker",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Use of GPUs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have configured Docker to use the host's GPUs within containers, we can test it using the `--gpus all` option. If you have more than one GPU and only want to use one, you would need to specify it, but for now, here we only explain how to use all of them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create a container that will not run in the background, but instead it will execute the command `nvidia-smi` so we can see if it has access to the GPUs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unable to find image 'ubuntu:latest' locally\n",
            "latest: Pulling from library/ubuntu\n",
            "\n",
            "\u001b[1B6a12be2b: Pull complete .54MB/29.54MBB\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KDigest: sha256:aabed3296a3d45cede1dc866a24476c4d7e093aa806263c27ddaadbdce3c1054\n",
            "Status: Downloaded newer image for ubuntu:latest\n",
            "Mon Sep  4 07:10:36 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.39.01    Driver Version: 510.39.01    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Quadro T1000        On   | 00000000:01:00.0 Off |                  N/A |\n",
            "| N/A   44C    P0    15W /  N/A |      9MiB /  4096MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A      2545      G                                       4MiB |\n",
            "|    0   N/A  N/A      3421      G                                       4MiB |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!docker run --name container_gpus --gpus all ubuntu nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We delete the container"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "!doker rm container_gpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Docker compose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Docker compose vs docker-compose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`docker-compose` was a tool created to help with the maintenance of images and containers, and it had to be installed separately from Docker. However, Docker incorporated it into its latest versions, so it is no longer necessary to install it separately. Nevertheless, to use it, instead of using the `docker-compose` command, you need to use the `docker compose` command. You will find information with `docker-compose` in many places, but when you install Docker, `docker compose` will be installed by default, so everything that could be done with `docker-compose` is compatible with `docker compose`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Docker compose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Docker Compose is a Docker tool that does everything we've seen so far, but saves us time and effort. By editing a `.yml` file, we can tell Docker Compose to create all the containers we want.",
        "\n",
        "There won't be much difference in writing all the commands we saw before or writing the `.yml` file for a one-time use, but when you want to have the same container configuration running again, just by calling the `.yml` file, it will recreate the entire setup."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's create a folder where we will store the Docker Compose files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "!mkdir dockerComposeFiles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create the .yml file inside"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "!touch dockerComposeFiles/docker-compose.yml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A Docker Compose file must start with the version",
        "\n",
        "```json\n",
        "version: \"<v.v>\"",
        "```\n",
        "\n",
        "At the time of writing this, the latest version is `3.8`, so we write that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*docker-compose.yml*:",
        "\n",
        "```json\n",
        "version: \"3.8\"",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following are the services, which are the containers. In each service, you must specify the image, and additionally, you can add other parameters such as ports, environment variables, etc.",
        "\n",
        "```json\n",
        "services:",
        "container1:",
        "image: ubuntu",
        "    \n",
        "container2:",
        "image: ubuntu",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `docker-compose.yml` would look like this:",
        "\n",
        "```json\n",
        "version: \"3.8\"",
        "\n",
        "services:",
        "container1:",
        "image: ubuntu",
        "    \n",
        "container2:",
        "image: ubuntu",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once we have created the file, in its path, we can run everything using the command `docker compose up`, but by adding the option `-d` we will make it run in the background."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Running 1/0\n",
            "\u001b[34m \u283f Network dockercomposefiles_default         Created                      0.1s\n",
            "\u001b[0m\u001b[37m \u280b Container dockercomposefiles-container2-1  Creating                     0.0s\n",
            "\u001b[0m\u001b[37m \u280b Container dockercomposefiles-container1-1  Creating                     0.0s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/3\n",
            "\u001b[34m \u283f Network dockercomposefiles_default         Created                      0.1s\n",
            "\u001b[0m\u001b[37m \u2819 Container dockercomposefiles-container2-1  Creating                     0.1s\n",
            "\u001b[0m\u001b[37m \u2819 Container dockercomposefiles-container1-1  Creating                     0.1s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/3\n",
            "\u001b[34m \u283f Network dockercomposefiles_default         Created                      0.1s\n",
            "\u001b[0m\u001b[37m \u283f Container dockercomposefiles-container2-1  Starting                     0.2s\n",
            "\u001b[0m\u001b[37m \u283f Container dockercomposefiles-container1-1  Starting                     0.2s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/3\n",
            "\u001b[34m \u283f Network dockercomposefiles_default         Created                      0.1s\n",
            "\u001b[0m\u001b[37m \u283f Container dockercomposefiles-container2-1  Starting                     0.3s\n",
            "\u001b[0m\u001b[37m \u283f Container dockercomposefiles-container1-1  Starting                     0.3s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/3\n",
            "\u001b[34m \u283f Network dockercomposefiles_default         Created                      0.1s\n",
            "\u001b[0m\u001b[37m \u283f Container dockercomposefiles-container2-1  Starting                     0.4s\n",
            "\u001b[0m\u001b[37m \u283f Container dockercomposefiles-container1-1  Starting                     0.4s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/3\n",
            "\u001b[34m \u283f Network dockercomposefiles_default         Created                      0.1s\n",
            "\u001b[0m\u001b[37m \u283f Container dockercomposefiles-container2-1  Starting                     0.5s\n",
            "\u001b[0m\u001b[37m \u283f Container dockercomposefiles-container1-1  Starting                     0.5s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 2/3\n",
            "\u001b[34m \u283f Network dockercomposefiles_default         Created                      0.1s\n",
            "\u001b[0m\u001b[34m \u283f Container dockercomposefiles-container2-1  Started                      0.5s\n",
            "\u001b[0m\u001b[37m \u283f Container dockercomposefiles-container1-1  Starting                     0.6s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l\u001b[34m[+] Running 3/3\u001b[0m\n",
            "\u001b[34m \u283f Network dockercomposefiles_default         Created                      0.1s\n",
            "\u001b[0m\u001b[34m \u283f Container dockercomposefiles-container2-1  Started                      0.5s\n",
            "\u001b[0m\u001b[34m \u283f Container dockercomposefiles-container1-1  Started                      0.7s\n",
            "\u001b[0m\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!cd dockerComposeFiles && docker compose up -d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we look, it has created two containers `dockercomposefiles-container1-1` and `dockercomposefiles-container2-1` and the network that connects them `dockercomposefiles_default`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's delete the two containers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dockercomposefiles-container1-1\n",
            "dockercomposefiles-container2-1\n"
          ]
        }
      ],
      "source": [
        "!docker rm -f dockercomposefiles-container1-1 dockercomposefiles-container2-1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And we delete the network that has been created"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dockercomposefiles_default\n"
          ]
        }
      ],
      "source": [
        "!docker network rm dockercomposefiles_default"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's try to do what we did before with what we know so far. We'll create a new image that comes with `ping` installed.",
        "\n",
        "*Dockerfile*:",
        "```docker\n",
        "FROM ubuntu:20.04",
        "RUN apt update",
        "RUN apt install iputils-ping -y",
        "```\n",
        "\n",
        "And we compile it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sending build context to Docker daemon  2.048kB\n",
            "Step 1/3 : FROM ubuntu:20.04\n",
            " ---> a0ce5a295b63\n",
            "Step 2/3 : RUN apt update\n",
            " ---> Running in 3bd5278d39b4\n",
            "\u001b[91m\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "\u001b[0mGet:1 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal InRelease [265 kB]\n",
            "Get:3 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [898 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu focal/universe amd64 Packages [11.3 MB]\n",
            "Get:7 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2133 kB]\n",
            "Get:8 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [27.5 kB]\n",
            "Get:9 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [1501 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu focal/main amd64 Packages [1275 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu focal/restricted amd64 Packages [33.4 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu focal/multiverse amd64 Packages [177 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [2594 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [1613 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [30.2 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1200 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu focal-backports/universe amd64 Packages [27.4 kB]\n",
            "...\n",
            "Successfully built c3d32aa9de02\n",
            "Successfully tagged ubuntu:ping\n",
            "\n",
            "Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\n"
          ]
        }
      ],
      "source": [
        "!docker build -t ubuntu:ping ./dockerImages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We check that it has been created"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REPOSITORY        TAG       IMAGE ID       CREATED              SIZE\n",
            "ubuntu            ping      c3d32aa9de02   About a minute ago   112MB\n",
            "maximofn/ubuntu   test      a78cf3ea16d8   25 hours ago         77.8MB\n",
            "nginx             latest    2d389e545974   33 hours ago         142MB\n",
            "ubuntu            latest    2dc39ba059dc   12 days ago          77.8MB\n",
            "ubuntu            20.04     a0ce5a295b63   12 days ago          72.8MB\n",
            "hello-world       latest    feb5d9fea6a5   11 months ago        13.3kB\n"
          ]
        }
      ],
      "source": [
        "!docker image ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We changed the tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "!docker tag ubuntu:ping maximofn/ubuntu:ping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REPOSITORY        TAG       IMAGE ID       CREATED              SIZE\n",
            "ubuntu            ping      c3d32aa9de02   About a minute ago   112MB\n",
            "maximofn/ubuntu   ping      c3d32aa9de02   About a minute ago   112MB\n",
            "maximofn/ubuntu   test      c3d32aa9de02   About a minute ago   112MB\n",
            "nginx             latest    2d389e545974   33 hours ago         142MB\n",
            "ubuntu            latest    2dc39ba059dc   12 days ago          77.8MB\n",
            "ubuntu            20.04     a0ce5a295b63   12 days ago          72.8MB\n",
            "hello-world       latest    feb5d9fea6a5   11 months ago        13.3kB\n"
          ]
        }
      ],
      "source": [
        "!docker image ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We edit the Docker Compose file to use the images we just created",
        "\n",
        "*docker-compose.yml*:",
        "```json\n",
        "version: \"3.8\"",
        "\n",
        "services:",
        "container1:",
        "image: maximofn/ubuntu:ping",
        "\n",
        "container2:",
        "image: maximofn/ubuntu:ping",
        "```\n",
        "\n",
        "And we also tell it to execute a no-operation",
        "\n",
        "The `docker-compose.yml` would look like this:",
        "```json\n",
        "version: \"3.8\"",
        "\n",
        "services:",
        "container1:",
        "image: ubuntu",
        "command: tail -f /dev/null",
        "\n",
        "container2:",
        "image: ubuntu",
        "command: tail -f /dev/null",
        "```\n",
        "\n",
        "We lift it up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Running 0/0\n",
            "\u001b[37m \u280b Container dockercomposefiles-container1-1  Recreate                     0.1s\n",
            "\u001b[0m\u001b[37m \u280b Container dockercomposefiles-container2-1  Recreate                     0.1s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
            "\u001b[34m \u283f Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
            "\u001b[0m\u001b[37m \u2819 Container dockercomposefiles-container2-1  Recreate                     0.2s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
            "\u001b[34m \u283f Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
            "\u001b[0m\u001b[37m \u2839 Container dockercomposefiles-container2-1  Recreate                     0.3s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
            "\u001b[34m \u283f Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
            "\u001b[0m\u001b[37m \u2838 Container dockercomposefiles-container2-1  Recreate                     0.4s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
            "\u001b[34m \u283f Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
            "\u001b[0m\u001b[37m \u283c Container dockercomposefiles-container2-1  Recreate                     0.5s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
            "\u001b[34m \u283f Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
            "\u001b[0m\u001b[37m \u2834 Container dockercomposefiles-container2-1  Recreate                     0.6s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
            "\u001b[34m \u283f Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
            "\u001b[0m\u001b[37m \u2826 Container dockercomposefiles-container2-1  Recreate                     0.7s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
            "\u001b[34m \u283f Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
            "\u001b[0m\u001b[37m \u2827 Container dockercomposefiles-container2-1  Recreate                     0.8s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
            "\u001b[34m \u283f Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
            "\u001b[0m\u001b[37m \u2807 Container dockercomposefiles-container2-1  Recreate                     0.9s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
            "\u001b[34m \u283f Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
            "\u001b[0m\u001b[37m \u280f Container dockercomposefiles-container2-1  Recreate                     1.0s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
            "\u001b[34m \u283f Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
            "\u001b[0m\u001b[37m \u280b Container dockercomposefiles-container2-1  Recreate                     1.1s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
            "\u001b[34m \u283f Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
            "\u001b[0m\u001b[37m \u2819 Container dockercomposefiles-container2-1  Recreate                     1.2s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
            "\u001b[34m \u283f Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
            "\u001b[0m\u001b[37m \u2839 Container dockercomposefiles-container2-1  Recreate                     1.3s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
            "\u001b[34m \u283f Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
            "\u001b[0m\u001b[37m \u2838 Container dockercomposefiles-container2-1  Recreate                     1.4s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
            "\u001b[34m \u283f Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
            "...\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l\u001b[34m[+] Running 2/2\u001b[0m\n",
            "\u001b[34m \u283f Container dockercomposefiles-container1-1  Started                     10.8s\n",
            "\u001b[0m\u001b[34m \u283f Container dockercomposefiles-container2-1  Started                     10.9s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l\u001b[34m[+] Running 2/2\u001b[0m\n",
            "\u001b[34m \u283f Container dockercomposefiles-container1-1  Started                     10.8s\n",
            "\u001b[0m\u001b[34m \u283f Container dockercomposefiles-container2-1  Started                     10.9s\n",
            "\u001b[0m\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!cd dockerComposeFiles && docker compose up -d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see the containers that are running"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE                  COMMAND               CREATED          STATUS          PORTS     NAMES\n",
            "935939e5a75d   maximofn/ubuntu:ping   \"tail -f /dev/null\"   15 seconds ago   Up 13 seconds             dockercomposefiles-container2-1\n",
            "f9138d7064dd   maximofn/ubuntu:ping   \"tail -f /dev/null\"   25 seconds ago   Up 13 seconds             dockercomposefiles-container1-1\n"
          ]
        }
      ],
      "source": [
        "!docker ps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Both containers are running, now let's get into one and try to do a `ping` to the other.",
        "\n",
        "```bash\n",
        "$ docker exec -it dockercomposefiles-container1-1 bash",
        "root@f9138d7064dd:/# ping dockercomposefiles-container2-1",
        "PING dockercomposefiles-container2-1 (172.21.0.3) 56(84) bytes of data.",
        "64 bytes from dockercomposefiles-container2-1.dockercomposefiles_default (172.21.0.3): icmp_seq=1 ttl=64 time=0.110 ms",
        "64 bytes from dockercomposefiles-container2-1.dockercomposefiles_default (172.21.0.3): icmp_seq=2 ttl=64 time=0.049 ms",
        "64 bytes from dockercomposefiles-container2-1.dockercomposefiles_default (172.21.0.3): icmp_seq=3 ttl=64 time=0.049 ms",
        "64 bytes from dockercomposefiles-container2-1.dockercomposefiles_default (172.21.0.3): icmp_seq=4 ttl=64 time=0.075 ms",
        "^C",
        "--- dockercomposefiles-container2-1 ping statistics ---",
        "4 packets transmitted, 4 received, 0% packet loss, time 3068ms",
        "rtt min/avg/max/mdev = 0.049/0.070/0.110/0.025 ms",
        "```\n",
        "\n",
        "As we can see, we can perform `ping`, we have successfully created the image with `ping` installed. Additionally, in the docker-compose, we have set it to execute a no-operation so that the containers keep running."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We delete the two containers and the network we have created"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dockercomposefiles-container1-1\n",
            "dockercomposefiles-container2-1\n"
          ]
        }
      ],
      "source": [
        "!docker rm -f dockercomposefiles-container1-1 dockercomposefiles-container2-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dockercomposefiles_default\n"
          ]
        }
      ],
      "source": [
        "!docker network rm dockercomposefiles_default"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### How Docker Compose Names Containers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we look closely, the containers created by Docker are called `dockercomposefiles-container1-1` and `dockercomposefiles-container2-1`. This is because the folder containing the Docker Compose file is named `dockerComposeFiles`, hence the first part of the container names is `dockercomposefiles`. Following that, it shows the service name we provided in the Docker Compose file (`container1` and `container2`), and finally a number to allow for more to be created if necessary.",
        "\n",
        "The same applies to the network name that has been created `dockercomposefiles_default`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Logs in docker compose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's change the Docker Compose file, in the lines where we had `command: tail -f /dev/null`, we will put `command: ping 0.0.0.0`",
        "\n",
        "And we also tell it to execute a no-operation",
        "\n",
        "The `docker-compose.yml` would look like this:",
        "```json\n",
        "version: \"3.8\"",
        "\n",
        "services:",
        "container1:",
        "image: ubuntu",
        "command: ping 0.0.0.0",
        "\n",
        "container2:",
        "image: ubuntu",
        "command: ping 0.0.0.0",
        "```\n",
        "\n",
        "We do this so that each container is constantly spitting out the ping, thus simulating some logs.",
        "\n",
        "If we run the docker-compose again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Running 0/0\n",
            "\u001b[37m \u280b Container dockercomposefiles-container1-1  Recreate                     0.1s\n",
            "\u001b[0m\u001b[37m \u280b Container dockercomposefiles-container2-1  Recreate                     0.1s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
            "\u001b[37m \u2819 Container dockercomposefiles-container1-1  Recreate                     0.2s\n",
            "\u001b[0m\u001b[37m \u2819 Container dockercomposefiles-container2-1  Recreate                     0.2s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
            "\u001b[37m \u2839 Container dockercomposefiles-container1-1  Recreate                     0.3s\n",
            "\u001b[0m\u001b[37m \u2839 Container dockercomposefiles-container2-1  Recreate                     0.3s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
            "\u001b[37m \u2838 Container dockercomposefiles-container1-1  Recreate                     0.4s\n",
            "\u001b[0m\u001b[37m \u2838 Container dockercomposefiles-container2-1  Recreate                     0.4s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
            "\u001b[37m \u283c Container dockercomposefiles-container1-1  Recreate                     0.5s\n",
            "\u001b[0m\u001b[37m \u283c Container dockercomposefiles-container2-1  Recreate                     0.5s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
            "\u001b[37m \u2834 Container dockercomposefiles-container1-1  Recreate                     0.6s\n",
            "\u001b[0m\u001b[37m \u2834 Container dockercomposefiles-container2-1  Recreate                     0.6s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
            "\u001b[37m \u2826 Container dockercomposefiles-container1-1  Recreate                     0.7s\n",
            "\u001b[0m\u001b[37m \u2826 Container dockercomposefiles-container2-1  Recreate                     0.7s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
            "\u001b[37m \u2827 Container dockercomposefiles-container1-1  Recreate                     0.8s\n",
            "\u001b[0m\u001b[37m \u2827 Container dockercomposefiles-container2-1  Recreate                     0.8s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
            "...\n",
            "\u001b[37m \u283f Container dockercomposefiles-container1-1  Starting                    11.0s\n",
            "\u001b[0m\u001b[34m \u283f Container dockercomposefiles-container2-1  Started                     11.0s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l\u001b[34m[+] Running 2/2\u001b[0m\n",
            "\u001b[34m \u283f Container dockercomposefiles-container1-1  Started                     11.1s\n",
            "\u001b[0m\u001b[34m \u283f Container dockercomposefiles-container2-1  Started                     11.0s\n",
            "\u001b[0m\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!cd dockerComposeFiles && docker compose up -d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can see the logs of the two containers using the command `docker compose logs`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0mPING 0.0.0.0 (127.0.0.1) 56(84) bytes of data.\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=1 ttl=64 time=0.042 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=2 ttl=64 time=0.025 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=3 ttl=64 time=0.022 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=4 ttl=64 time=0.030 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=5 ttl=64 time=0.021 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=6 ttl=64 time=0.021 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=7 ttl=64 time=0.030 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=8 ttl=64 time=0.028 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=9 ttl=64 time=0.028 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=10 ttl=64 time=0.026 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=11 ttl=64 time=0.028 ms\n",
            "\u001b[33mdockercomposefiles-container1-1  | \u001b[0mPING 0.0.0.0 (127.0.0.1) 56(84) bytes of data.\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=12 ttl=64 time=0.027 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=13 ttl=64 time=0.039 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=14 ttl=64 time=0.035 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=15 ttl=64 time=0.034 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=16 ttl=64 time=0.036 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=17 ttl=64 time=0.034 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=18 ttl=64 time=0.036 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=19 ttl=64 time=0.032 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=20 ttl=64 time=0.032 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=21 ttl=64 time=0.033 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=22 ttl=64 time=0.034 ms\n",
            "\u001b[33mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=1 ttl=64 time=0.037 ms\n",
            "...\n",
            "\u001b[33mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=214 ttl=64 time=0.015 ms\n",
            "\u001b[33mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=215 ttl=64 time=0.021 ms\n",
            "\u001b[33mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=216 ttl=64 time=0.020 ms\n",
            "\u001b[33mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=217 ttl=64 time=0.049 ms\n"
          ]
        }
      ],
      "source": [
        "!cd dockerComposeFiles && docker compose logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see, we can view the logs of both containers, but if we want to view only those of one, we can specify the **service name**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36mdockercomposefiles-container1-1  | \u001b[0mPING 0.0.0.0 (127.0.0.1) 56(84) bytes of data.\n",
            "\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=1 ttl=64 time=0.037 ms\n",
            "\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=2 ttl=64 time=0.025 ms\n",
            "\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=3 ttl=64 time=0.023 ms\n",
            "\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=4 ttl=64 time=0.031 ms\n",
            "\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=5 ttl=64 time=0.034 ms\n",
            "\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=6 ttl=64 time=0.033 ms\n",
            "\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=7 ttl=64 time=0.034 ms\n",
            "\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=8 ttl=64 time=0.022 ms\n",
            "\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=9 ttl=64 time=0.032 ms\n",
            "\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=10 ttl=64 time=0.029 ms\n",
            "\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=11 ttl=64 time=0.031 ms\n",
            "\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=12 ttl=64 time=0.024 ms\n",
            "\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=13 ttl=64 time=0.029 ms\n",
            "\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=14 ttl=64 time=0.032 ms\n",
            "\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=15 ttl=64 time=0.033 ms\n",
            "\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=16 ttl=64 time=0.034 ms\n",
            "\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=17 ttl=64 time=0.028 ms\n",
            "\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=18 ttl=64 time=0.034 ms\n",
            "...\n",
            "\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=332 ttl=64 time=0.027 ms\n",
            "\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=333 ttl=64 time=0.030 ms\n",
            "\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=334 ttl=64 time=0.033 ms\n",
            "\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=335 ttl=64 time=0.036 ms\n"
          ]
        }
      ],
      "source": [
        "!cd dockerComposeFiles && docker compose logs container1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0mPING 0.0.0.0 (127.0.0.1) 56(84) bytes of data.\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=1 ttl=64 time=0.042 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=2 ttl=64 time=0.025 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=3 ttl=64 time=0.022 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=4 ttl=64 time=0.030 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=5 ttl=64 time=0.021 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=6 ttl=64 time=0.021 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=7 ttl=64 time=0.030 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=8 ttl=64 time=0.028 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=9 ttl=64 time=0.028 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=10 ttl=64 time=0.026 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=11 ttl=64 time=0.028 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=12 ttl=64 time=0.027 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=13 ttl=64 time=0.039 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=14 ttl=64 time=0.035 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=15 ttl=64 time=0.034 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=16 ttl=64 time=0.036 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=17 ttl=64 time=0.034 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=18 ttl=64 time=0.036 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=19 ttl=64 time=0.032 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=20 ttl=64 time=0.032 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=21 ttl=64 time=0.033 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=22 ttl=64 time=0.034 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=23 ttl=64 time=0.035 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=24 ttl=64 time=0.037 ms\n",
            "...\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=340 ttl=64 time=0.034 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=341 ttl=64 time=0.033 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=342 ttl=64 time=0.034 ms\n",
            "\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=343 ttl=64 time=0.036 ms\n"
          ]
        }
      ],
      "source": [
        "!cd dockerComposeFiles && docker compose logs container2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we want to view the logs continuously, we can add the `-f` option: `docker compose logs -f <service name>`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If I have created a docker compose with more than two services, when you want to view the logs of several services, you just need to add more names to the command, `docker compose logs <name service 1> <name service 2> ...`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exec services"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we have seen, using the `exec` command we can enter a container by specifying the container name, the command to be executed, and the `-it` option. With Docker Compose, this is simpler, as only the service name and the command are required, without the need for the `-it` option since Docker Compose assumes it.",
        "\n",
        "```bash\n",
        "$ docker compose exec container1 bash",
        "root@a7cf282fe66c:/#",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Stopping docker compose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When we have finished working, with a single command (`stop`), Docker Compose stops everything, there's no need to stop each container one by one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Running 0/0\n",
            "\u001b[37m \u280b Container dockercomposefiles-container2-1  Stopping                     0.1s\n",
            "\u001b[0m\u001b[37m \u280b Container dockercomposefiles-container1-1  Stopping                     0.1s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
            "\u001b[37m \u2819 Container dockercomposefiles-container2-1  Stopping                     0.2s\n",
            "\u001b[0m\u001b[37m \u2819 Container dockercomposefiles-container1-1  Stopping                     0.2s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
            "\u001b[37m \u2839 Container dockercomposefiles-container2-1  Stopping                     0.3s\n",
            "\u001b[0m\u001b[37m \u2839 Container dockercomposefiles-container1-1  Stopping                     0.3s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
            "\u001b[37m \u2838 Container dockercomposefiles-container2-1  Stopping                     0.4s\n",
            "\u001b[0m\u001b[37m \u2838 Container dockercomposefiles-container1-1  Stopping                     0.4s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
            "\u001b[37m \u283c Container dockercomposefiles-container2-1  Stopping                     0.5s\n",
            "\u001b[0m\u001b[37m \u283c Container dockercomposefiles-container1-1  Stopping                     0.5s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
            "\u001b[37m \u2834 Container dockercomposefiles-container2-1  Stopping                     0.6s\n",
            "\u001b[0m\u001b[37m \u2834 Container dockercomposefiles-container1-1  Stopping                     0.6s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
            "\u001b[37m \u2826 Container dockercomposefiles-container2-1  Stopping                     0.7s\n",
            "\u001b[0m\u001b[37m \u2826 Container dockercomposefiles-container1-1  Stopping                     0.7s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
            "\u001b[37m \u2827 Container dockercomposefiles-container2-1  Stopping                     0.8s\n",
            "\u001b[0m\u001b[37m \u2827 Container dockercomposefiles-container1-1  Stopping                     0.8s\n",
            "...\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
            "\u001b[34m \u283f Container dockercomposefiles-container2-1  Stopped                     10.4s\n",
            "\u001b[0m\u001b[37m \u2838 Container dockercomposefiles-container1-1  Stopping                    10.4s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l\u001b[34m[+] Running 2/2\u001b[0m\n",
            "\u001b[34m \u283f Container dockercomposefiles-container2-1  Stopped                     10.4s\n",
            "\u001b[0m\u001b[34m \u283f Container dockercomposefiles-container1-1  Stopped                     10.4s\n",
            "\u001b[0m\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!cd dockerComposeFiles && docker compose stop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As can be seen, Docker Compose has stopped the two containers, but it has not deleted them, nor has it deleted the network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
          ]
        }
      ],
      "source": [
        "!docker ps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE                  COMMAND          CREATED          STATUS                        PORTS     NAMES\n",
            "1e6c1dd9adb2   maximofn/ubuntu:ping   \"ping 0.0.0.0\"   16 minutes ago   Exited (137) 25 seconds ago             dockercomposefiles-container2-1\n",
            "a7cf282fe66c   maximofn/ubuntu:ping   \"ping 0.0.0.0\"   16 minutes ago   Exited (137) 25 seconds ago             dockercomposefiles-container1-1\n"
          ]
        }
      ],
      "source": [
        "!docker ps -a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NETWORK ID     NAME                         DRIVER    SCOPE\n",
            "13cc632147f3   bridge                       bridge    local\n",
            "d4a2f718cd83   dockercomposefiles_default   bridge    local\n",
            "da1f5f6fccc0   host                         host      local\n",
            "d3b0d93993c0   none                         null      local\n"
          ]
        }
      ],
      "source": [
        "!docker network ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Docker Compose as a Development Tool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Just like we saw before, to be able to develop, it would be ideal to share the folder that contains the code with the service. This is done in Docker Compose by adding the `volumes` label to the docker-compose file. First, we need to add the path of the folder where the code is located on the host and then the path inside the container.",
        "\n",
        "*docker-compose.yml*:",
        "```json\n",
        "version: \"3.8\"",
        "\n",
        "services:",
        "container1:",
        "image: ubuntu",
        "command: ping 0.0.0.0",
        "volumes:",
        "- ../dockerHostFolder/:/dockerContainerFolder",
        "\n",
        "container2:",
        "image: ubuntu",
        "command: ping 0.0.0.0",
        "```\n",
        "\n",
        "As can be seen, the host folder path has been set as relative.",
        "\n",
        "If we bring up the Docker Compose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Running 1/0\n",
            "\u001b[37m \u280b Container dockercomposefiles-container1-1  Recreate                     0.1s\n",
            "\u001b[0m\u001b[34m \u283f Container dockercomposefiles-container2-1  Created                      0.0s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
            "\u001b[37m \u283f Container dockercomposefiles-container1-1  Starting                     0.2s\n",
            "\u001b[0m\u001b[37m \u283f Container dockercomposefiles-container2-1  Starting                     0.2s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
            "\u001b[37m \u283f Container dockercomposefiles-container1-1  Starting                     0.3s\n",
            "\u001b[0m\u001b[37m \u283f Container dockercomposefiles-container2-1  Starting                     0.3s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
            "\u001b[37m \u283f Container dockercomposefiles-container1-1  Starting                     0.4s\n",
            "\u001b[0m\u001b[37m \u283f Container dockercomposefiles-container2-1  Starting                     0.4s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
            "\u001b[34m \u283f Container dockercomposefiles-container1-1  Started                      0.5s\n",
            "\u001b[0m\u001b[37m \u283f Container dockercomposefiles-container2-1  Starting                     0.5s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l\u001b[34m[+] Running 2/2\u001b[0m\n",
            "\u001b[34m \u283f Container dockercomposefiles-container1-1  Started                      0.5s\n",
            "\u001b[0m\u001b[34m \u283f Container dockercomposefiles-container2-1  Started                      0.6s\n",
            "\u001b[0m\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!cd dockerComposeFiles && docker compose up -d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we enter the container, we can see what is inside the file text.txt",
        "\n",
        "```bash\n",
        "$ docker compose exec container1 bash",
        "root@c8aae9d619d3:/# ls dockerContainerFolder/",
        "bindFile.txt  fileExtract.txt  text.txt",
        "root@c8aae9d619d3:/# cat dockerContainerFolder/text.txt",
        "hello container",
        "```\n",
        "\n",
        "If we now open it on the host, write `hola host` and go back to see in the container",
        "\n",
        "```bash\n",
        "root@c8aae9d619d3:/# cat dockerContainerFolder/text.txt",
        "hello host",
        "```\n",
        "\n",
        "And now the other way around, if we modify it in the container",
        "\n",
        "```bash\n",
        "root@c8aae9d619d3:/# echo hello compose > dockerContainerFolder/text.txt",
        "root@c8aae9d619d3:/# exit",
        "exit",
        "```\n",
        "\n",
        "If we see it from the host, we should get `hello compose`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hola compose\n"
          ]
        }
      ],
      "source": [
        "!cat dockerHostFolder/text.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Port Exposure in Docker Compose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also configure the ports in the Docker Compose file using the `ports` label, indicating the host port followed by the service IP.",
        "\n",
        "```json\n",
        "ports:",
        "- <host port>:<service port>",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Docker compose in team - docker override"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we are a group of people developing with Docker using Docker Compose, it's likely that many people will be changing the Docker Compose file, which can lead to poor synchronization and conflicts.",
        "\n",
        "To solve this, Docker offers a tool called Docker Override. This way, there can be a base Docker Compose file and each user can modify it through Docker Override.",
        "\n",
        "To do this, we now need to create a file called `docker-compose.override.yml` which will be the one we can edit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "!touch dockerComposeFiles/docker-compose.override.yml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we now try to start the Docker Compose, we will receive an error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-level object must be a mapping\n"
          ]
        }
      ],
      "source": [
        "!cd dockerComposeFiles && docker compose up -d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And this is because Docker Compose has detected that there is a file called `docker-compose.override.yml` and it is empty, so we are going to edit it. The `docker-compose.override.yml` file is used to override the `docker-compose.yml` file, so if for example we want to make a change in the `container2` service to add a volume, we would write the `docker-compose.override.yml` file like this:",
        "\n",
        "*docker-compose.override.yml*:",
        "```json\n",
        "version: \"3.8\"",
        "\n",
        "services:",
        "container2:",
        "volumes:",
        "- ../dockerHostFolder/:/dockerOverrideFolder",
        "```\n",
        "\n",
        "Notice that I have named the shared folder in the service `dockerOverrideFolder`, so we are going to start the docker-compose and see if we can see that folder in the container `container2`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Running 1/0\n",
            "\u001b[37m \u280b Container dockercomposefiles-container2-1  Recreate                     0.1s\n",
            "\u001b[0m\u001b[34m \u283f Container dockercomposefiles-container1-1  Running                      0.0s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
            "\u001b[37m \u2819 Container dockercomposefiles-container2-1  Recreate                     0.2s\n",
            "\u001b[0m\u001b[34m \u283f Container dockercomposefiles-container1-1  Running                      0.0s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
            "\u001b[37m \u2839 Container dockercomposefiles-container2-1  Recreate                     0.3s\n",
            "\u001b[0m\u001b[34m \u283f Container dockercomposefiles-container1-1  Running                      0.0s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
            "\u001b[37m \u2838 Container dockercomposefiles-container2-1  Recreate                     0.4s\n",
            "\u001b[0m\u001b[34m \u283f Container dockercomposefiles-container1-1  Running                      0.0s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
            "\u001b[37m \u283c Container dockercomposefiles-container2-1  Recreate                     0.5s\n",
            "\u001b[0m\u001b[34m \u283f Container dockercomposefiles-container1-1  Running                      0.0s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
            "\u001b[37m \u2834 Container dockercomposefiles-container2-1  Recreate                     0.6s\n",
            "\u001b[0m\u001b[34m \u283f Container dockercomposefiles-container1-1  Running                      0.0s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
            "\u001b[37m \u2826 Container dockercomposefiles-container2-1  Recreate                     0.7s\n",
            "\u001b[0m\u001b[34m \u283f Container dockercomposefiles-container1-1  Running                      0.0s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
            "\u001b[37m \u2827 Container dockercomposefiles-container2-1  Recreate                     0.8s\n",
            "\u001b[0m\u001b[34m \u283f Container dockercomposefiles-container1-1  Running                      0.0s\n",
            "...\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
            "\u001b[37m \u283f Container dockercomposefiles-container2-1  Starting                    10.8s\n",
            "\u001b[0m\u001b[34m \u283f Container dockercomposefiles-container1-1  Running                      0.0s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l\u001b[34m[+] Running 2/2\u001b[0m\n",
            "\u001b[34m \u283f Container dockercomposefiles-container2-1  Started                     10.8s\n",
            "\u001b[0m\u001b[34m \u283f Container dockercomposefiles-container1-1  Running                      0.0s\n",
            "\u001b[0m\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!cd dockerComposeFiles && docker compose up -d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that it took 10 seconds to mount the `container2` service, this is because it was applying the changes.",
        "\n",
        "```bash\n",
        "$ docker compose exec container2 bash",
        "root@d8777a4e611a:/# ls dockerOverrideFolder/",
        "bindFile.txt  fileExtract.txt  text.txt",
        "root@d8777a4e611a:/# cat dockerOverrideFolder/text.txt",
        "hello compose",
        "root@d8777a4e611a:/# exit",
        "exit",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We bring down the Compose and delete the containers and the network created"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Running 0/0\n",
            "\u001b[37m \u280b Container dockercomposefiles-container2-1  Stopping                     0.1s\n",
            "\u001b[0m\u001b[37m \u280b Container dockercomposefiles-container1-1  Stopping                     0.1s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
            "\u001b[37m \u2819 Container dockercomposefiles-container2-1  Stopping                     0.2s\n",
            "\u001b[0m\u001b[37m \u2819 Container dockercomposefiles-container1-1  Stopping                     0.2s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
            "\u001b[37m \u2839 Container dockercomposefiles-container2-1  Stopping                     0.3s\n",
            "\u001b[0m\u001b[37m \u2839 Container dockercomposefiles-container1-1  Stopping                     0.3s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
            "\u001b[37m \u2838 Container dockercomposefiles-container2-1  Stopping                     0.4s\n",
            "\u001b[0m\u001b[37m \u2838 Container dockercomposefiles-container1-1  Stopping                     0.4s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
            "\u001b[37m \u283c Container dockercomposefiles-container2-1  Stopping                     0.5s\n",
            "\u001b[0m\u001b[37m \u283c Container dockercomposefiles-container1-1  Stopping                     0.5s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
            "\u001b[37m \u2834 Container dockercomposefiles-container2-1  Stopping                     0.6s\n",
            "\u001b[0m\u001b[37m \u2834 Container dockercomposefiles-container1-1  Stopping                     0.6s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
            "\u001b[37m \u2826 Container dockercomposefiles-container2-1  Stopping                     0.7s\n",
            "\u001b[0m\u001b[37m \u2826 Container dockercomposefiles-container1-1  Stopping                     0.7s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
            "\u001b[37m \u2827 Container dockercomposefiles-container2-1  Stopping                     0.8s\n",
            "\u001b[0m\u001b[37m \u2827 Container dockercomposefiles-container1-1  Stopping                     0.8s\n",
            "...\n",
            "\u001b[37m \u2838 Container dockercomposefiles-container2-1  Stopping                    10.4s\n",
            "\u001b[0m\u001b[37m \u2838 Container dockercomposefiles-container1-1  Stopping                    10.4s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
            "\u001b[34m \u283f Container dockercomposefiles-container2-1  Removed                     10.4s\n",
            "\u001b[0m\u001b[37m \u283f Container dockercomposefiles-container1-1  Removing                    10.5s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l\u001b[34m[+] Running 2/2\u001b[0m\n",
            "\u001b[34m \u283f Container dockercomposefiles-container2-1  Removed                     10.4s\n",
            "\u001b[0m\u001b[34m \u283f Container dockercomposefiles-container1-1  Removed                     10.5s\n",
            "\u001b[0m\u001b[37m \u280b Network dockercomposefiles_default         Removing                     0.1s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l\u001b[34m[+] Running 3/3\u001b[0m\n",
            "\u001b[34m \u283f Container dockercomposefiles-container2-1  Removed                     10.4s\n",
            "\u001b[0m\u001b[34m \u283f Container dockercomposefiles-container1-1  Removed                     10.5s\n",
            "\u001b[0m\u001b[34m \u283f Network dockercomposefiles_default         Removed                      0.2s\n",
            "\u001b[0m\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!cd dockerComposeFiles && docker compose down"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this case, with just `down`, Docker Compose has stopped and removed everything, as we can see in the containers and network it says `Removed`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Docker compose restart"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When writing a Docker Compose file, we can add the `restart` label so that if the container goes down, it will automatically restart.",
        "\n",
        "```json\n",
        "restart: always",
        "```\n",
        "\n",
        "In this way, if the container goes down, it will automatically restart. If we want it to restart only a certain number of times, we can add the `on-failure` option.",
        "\n",
        "```json\n",
        "restart: on-failure:<number>",
        "```\n",
        "\n",
        "Now the container will restart a number of times, but if it fails more times, it won't restart. If we want it to always restart, we can add the `unless-stopped` option.",
        "\n",
        "```json\n",
        "restart: unless-stopped",
        "```\n",
        "\n",
        "Now the container will always restart, unless it is manually stopped."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Advanced Docker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Manage work environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Deletion of stopped containers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After developing for a while, we can end up with several stopped containers still stored on the computer. This eventually takes up memory, so with `docker container prune` we can remove all of those that are stopped."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "!docker run ubuntu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
          ]
        }
      ],
      "source": [
        "!docker ps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE     COMMAND   CREATED          STATUS                      PORTS     NAMES\n",
            "effcee24f54a   ubuntu    \"bash\"    37 seconds ago   Exited (0) 36 seconds ago             musing_rosalind\n"
          ]
        }
      ],
      "source": [
        "!docker ps -a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``` bash\n",
        "$ docker container prune",
        "WARNING! This will remove all stopped containers.",
        "\u00bfEst\u00e1s seguro de que quieres continuar? [s/N] s",
        "Deleted Containers:",
        "This appears to be a hash value, not markdown text. As such, it doesn't require translation. If you have a specific piece of markdown text to translate, please provide it and I'll be happy to assist!",
        "\n",
        "Total reclaimed space: 0B",
        "```\n",
        "\n",
        "In this case we have saved 0 bytes, but in the case of leaving containers turned off after extensive development, the memory savings will certainly be greater."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Deletion of all containers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In case of having running containers, we can delete all containers through another command",
        "\n",
        "The command `docker ps -q` returns the ID of all containers, so with the command `docker rm -f $(docker ps -aq)` we will stop and remove all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c22516186ef7e3561fb1ad0d508a914857dbc61274a218f297c4d80b1fc33863\n"
          ]
        }
      ],
      "source": [
        "!docker run -d ubuntu tail -f /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE     COMMAND               CREATED              STATUS              PORTS     NAMES\n",
            "c22516186ef7   ubuntu    \"tail -f /dev/null\"   About a minute ago   Up About a minute             agitated_knuth\n"
          ]
        }
      ],
      "source": [
        "!docker ps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c22516186ef7\n"
          ]
        }
      ],
      "source": [
        "!docker rm -f $(docker ps -aq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
          ]
        }
      ],
      "source": [
        "!docker ps -a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Deletion of everything"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we have seen, Docker also creates networks, images, volumes, etc., so with the command `docker system prune` we can delete all stopped containers, all unused networks that are not used by at least one container, duplicate images, and what is duplicated in the build cache.",
        "\n",
        "``` bash\n",
        "$ docker system prune",
        "WARNING! This will remove:",
        "- all stopped containers",
        "- all networks not used by at least one container",
        "- all dangling images",
        "- all dangling build cache",
        "\n",
        "\u00bfEst\u00e1s seguro de que quieres continuar? [s/N] s",
        "Total reclaimed space: 0B",
        "```\n",
        "\n",
        "Just like before, not much space has been saved, but after a long time of development, the savings will be significant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Use of Host Resources by Containers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For example, when creating a container, we can limit the RAM that the host can use by using the `--memory` option."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "d84888eafe531831ef8915d2270422365adec02678122bf59580e2da782e6972\n"
          ]
        }
      ],
      "source": [
        "!docker run -d --memory 1g ubuntu tail -f /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "But with `docker ps` we don't have access to the resources that the container is consuming."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE     COMMAND               CREATED          STATUS          PORTS     NAMES\n",
            "d84888eafe53   ubuntu    \"tail -f /dev/null\"   35 seconds ago   Up 34 seconds             musing_ritchie\n"
          ]
        }
      ],
      "source": [
        "!docker ps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For this, we have the command `docker stats`",
        "\n",
        "```bash\n",
        "$ docker stats",
        "CONTAINER ID   NAME             CPU %     MEM USAGE / LIMIT   MEM %     NET I/O       BLOCK I/O   PIDS",
        "d84888eafe53   musing_ritchie   0.00%     540KiB / 1GiB       0.05%     5.62kB / 0B   0B / 0B     1",
        "```\n",
        "\n",
        "This is very useful if we want to simulate an environment with a RAM limit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Stopping containers properly: SHELL vs EXEC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we have explained, when we assign a process to a container, when that process ends, the container stops, but sometimes we may encounter problems with this. Let's create a new folder called Dockerfile_loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "!mkdir Dockerfile_loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we are going to create a file called `loop.sh` inside `Dockerfile_loop`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "!touch Dockerfile_loop/loop.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And we are going to write the following inside `loop.sh`",
        "\n",
        "``` shell\n",
        "#!/usr/bin/env bash",
        "trap \"exit 0\" SIGTERM",
        "while true; do :; done",
        "```\n",
        "\n",
        "If I run this script on the host, it runs until I enter `CTRL+C`",
        "\n",
        "\n",
        "``` bash\n",
        "./loop",
        "^C",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we are going to create a `Dockerfile` inside `Dockerfile_loop`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "!touch Dockerfile_loop/Dockerfile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Dockerfile*:",
        "``` docker\n",
        "FROM ubuntu:trusty",
        "COPY [\"loop.sh\", \"/\"]",
        "CMD /loop.sh",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's create an image based on Ubuntu that copies the script inside and runs it, and the script runs until it receives the `SIGTERM` signal from the operating system. We compile the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sending build context to Docker daemon  3.072kB\n",
            "Step 1/3 : FROM ubuntu:trusty\n",
            " ---> 13b66b487594\n",
            "Step 2/3 : COPY [\"loop.sh\", \"/\"]\n",
            " ---> 89f2bbd25a88\n",
            "Step 3/3 : CMD /loop.sh\n",
            " ---> Running in ff52569c35fd\n",
            "Removing intermediate container ff52569c35fd\n",
            " ---> feb091e4efa3\n",
            "Successfully built feb091e4efa3\n",
            "Successfully tagged ubuntu:loop\n",
            "\n",
            "Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\n"
          ]
        }
      ],
      "source": [
        "!docker build -t ubuntu:loop ./Dockerfile_loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We run the container",
        "\n",
        "``` bash\n",
        "docker run -d --name looper ubuntu:loop bash",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8a28f8cc9892213c4e0603dfdde320edf52c091b82c60510083549a391cd6645\n"
          ]
        }
      ],
      "source": [
        "!docker run -d --name looper ubuntu:loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We check and see that the container is running"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE         COMMAND                 CREATED         STATUS         PORTS     NAMES\n",
            "8a28f8cc9892   ubuntu:loop   \"/bin/sh -c /loop.sh\"   4 seconds ago   Up 3 seconds             looper\n"
          ]
        }
      ],
      "source": [
        "!docker ps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We tried to stop the container with `docker stop looper`. Docker stop attempts to stop the container by sending it the `SIGTERM` signal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "looper\n",
            "CPU times: user 89.2 ms, sys: 21.7 ms, total: 111 ms\n",
            "Wall time: 10.6 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "!docker stop looper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This took about 10 seconds to stop, when it should be immediate. This is because `stop` sent the `SIGTERM` signal to stop the container, but since it didn't stop, after a while it sent a `SIGKILL` to force it to stop. Let's see what happens if we list the containers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE         COMMAND                 CREATED          STATUS                       PORTS     NAMES\n",
            "8a28f8cc9892   ubuntu:loop   \"/bin/sh -c /loop.sh\"   23 seconds ago   Exited (137) 2 seconds ago             looper\n"
          ]
        }
      ],
      "source": [
        "!docker ps -a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that the `Exited` signal is `137`, which corresponds to SIGKILL, meaning Docker had to force the shutdown."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's delete the container and run it again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "looper\n"
          ]
        }
      ],
      "source": [
        "!docker rm looper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "84bc37f944d270be5f84a952968db2b8cf5372c61146d29383468198ceed18fd\n"
          ]
        }
      ],
      "source": [
        "!docker run -d --name looper ubuntu:loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we now try to stop the container with `docker kill looper`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "looper\n",
            "CPU times: user 9.1 ms, sys: 857 \u00b5s, total: 9.96 ms\n",
            "Wall time: 545 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "!docker kill looper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that the time is around 500 ms, meaning Docker stopped it at a certain point by sending the `SIGKILL` command. This is because `kill` does not send `SIGTERM`, and if the container has not stopped after a certain time, it sends `SIGKILL`. In this case, it sends `SIGKILL` from the start.",
        "\n",
        "If we look at the containers, we see that the exit signal is the same, `137`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE         COMMAND                 CREATED         STATUS                       PORTS     NAMES\n",
            "84bc37f944d2   ubuntu:loop   \"/bin/sh -c /loop.sh\"   6 seconds ago   Exited (137) 2 seconds ago             looper\n"
          ]
        }
      ],
      "source": [
        "!docker ps -a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is not the correct way to stop a container, because when we want to stop the container, it should be done through the `SIGTERM` signal, so that it can finish processing what it was doing and then shut down."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we delete the container and run it again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "looper\n"
          ]
        }
      ],
      "source": [
        "!docker rm looper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b9d9f370cc0de7569eb09d0a85cd67e8ea6babc0754a517ccba5c5057f5cc50e\n"
          ]
        }
      ],
      "source": [
        "!docker run -d --name looper ubuntu:loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we now look at the processes running inside the container"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UID          PID    PPID  C STIME TTY          TIME CMD\n",
            "root           1       0  0 14:05 ?        00:00:00 /bin/sh -c /loop.sh\n",
            "root           7       1 93 14:05 ?        00:00:02 bash /loop.sh\n",
            "root           8       0  0 14:05 ?        00:00:00 ps -ef\n"
          ]
        }
      ],
      "source": [
        "!docker exec looper ps -ef"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In fact, the main process, number 1, is not `/loop.sh` but rather `/bin/sh -c /loop.sh`, meaning it is a child process of the `shell`. So when the `SIGTERM` signal arrived, it reached the `shell`, but the shell does not forward it to its child processes, which is why `loop.sh` did not receive it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To prevent this, you need to change the `Dockerfile` to the following",
        "\n",
        "*Dockerfile*:",
        "``` docker\n",
        "FROM ubuntu:trusty",
        "COPY [\"loop.sh\", \"/\"]",
        "CMD [\"/loop.sh\"]    # it was previously CMD /loop.sh",
        "```\n",
        "\n",
        "This form is called `exec form`, while the previous one is called `shell form`. In the previous form, the process runs as a child of the `shell`, whereas in the `exec form` it executes the specified process. So we delete the container, recompile, and run the container with the image again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "looper\n"
          ]
        }
      ],
      "source": [
        "!docker rm -f looper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sending build context to Docker daemon  3.072kB\n",
            "Step 1/3 : FROM ubuntu:trusty\n",
            " ---> 13b66b487594\n",
            "Step 2/3 : COPY [\"loop.sh\", \"/\"]\n",
            " ---> Using cache\n",
            " ---> 89f2bbd25a88\n",
            "Step 3/3 : CMD [\"/loop.sh\"]\n",
            " ---> Running in 6b8d92fcd57c\n",
            "Removing intermediate container 6b8d92fcd57c\n",
            " ---> 35a7bb2b1892\n",
            "Successfully built 35a7bb2b1892\n",
            "Successfully tagged ubuntu:loop\n",
            "\n",
            "Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\n"
          ]
        }
      ],
      "source": [
        "!docker build -t ubuntu:loop ./Dockerfile_loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "850ae70c071426850b28428ac60dcbf875c6d35d9b7cc66c17cf391a23392965\n"
          ]
        }
      ],
      "source": [
        "!docker run -d --name looper ubuntu:loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Yes, now I see the processes inside the container"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UID          PID    PPID  C STIME TTY          TIME CMD\n",
            "root           1       0 88 14:14 ?        00:00:02 bash /loop.sh\n",
            "root           7       0  0 14:14 ?        00:00:00 ps -ef\n"
          ]
        }
      ],
      "source": [
        "!docker exec looper ps -ef"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now I see that the main process, number 1, is `/loop.sh`",
        "\n",
        "If I now try to stop the container"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "looper\n",
            "CPU times: user 989 \u00b5s, sys: 7.55 ms, total: 8.54 ms\n",
            "Wall time: 529 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "!docker stop looper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that it takes longer. Let's look at the code where it stopped."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE         COMMAND      CREATED              STATUS                      PORTS     NAMES\n",
            "850ae70c0714   ubuntu:loop   \"/loop.sh\"   About a minute ago   Exited (0) 33 seconds ago             looper\n"
          ]
        }
      ],
      "source": [
        "!docker ps -a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Executable Containers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we want a binary that runs as an executable, in the `dockerfile` we need to specify the command in `ENTRYPOINT` and the command parameters in `CMD`, let's see it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's create a new folder where we will store the `Dockerfile`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "!mkdir dockerfile_ping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we create a Dockerfile inside"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "!touch dockerfile_ping/Dockerfile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We write the following inside the Dockerfile",
        "\n",
        "``` docker\n",
        "FROM ubuntu:trusty",
        "ENTRYPOINT [ \"/bin/ping\", \"-c\", \"3\" ]",
        "CMD [ \"localhost\" ]",
        "```\n",
        "\n",
        "We compile the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sending build context to Docker daemon  3.072kB\n",
            "Step 1/3 : FROM ubuntu:trusty\n",
            " ---> 13b66b487594\n",
            "Step 2/3 : ENTRYPOINT [ \"/bin/ping\", \"-c\", \"3\" ]\n",
            " ---> Using cache\n",
            " ---> 1cebcfb542b1\n",
            "Step 3/3 : CMD [ \"localhost\" ]\n",
            " ---> Using cache\n",
            " ---> 04ddc3de52a2\n",
            "Successfully built 04ddc3de52a2\n",
            "Successfully tagged ubuntu:ping\n",
            "\n",
            "Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\n"
          ]
        }
      ],
      "source": [
        "!docker build -t ubuntu:ping ./dockerfile_ping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we now run the image without passing it a parameter, the container will ping itself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PING localhost (127.0.0.1) 56(84) bytes of data.\n",
            "64 bytes from localhost (127.0.0.1): icmp_seq=1 ttl=64 time=0.041 ms\n",
            "64 bytes from localhost (127.0.0.1): icmp_seq=2 ttl=64 time=0.058 ms\n",
            "64 bytes from localhost (127.0.0.1): icmp_seq=3 ttl=64 time=0.054 ms\n",
            "\n",
            "--- localhost ping statistics ---\n",
            "3 packets transmitted, 3 received, 0% packet loss, time 2027ms\n",
            "rtt min/avg/max/mdev = 0.041/0.051/0.058/0.007 ms\n"
          ]
        }
      ],
      "source": [
        "!docker run --name ping_localhost ubuntu:ping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "But if we pass it a parameter, it will ping the address we tell it to."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PING google.com (216.58.209.78) 56(84) bytes of data.\n",
            "64 bytes from waw02s06-in-f14.1e100.net (216.58.209.78): icmp_seq=1 ttl=111 time=3.93 ms\n",
            "64 bytes from waw02s06-in-f14.1e100.net (216.58.209.78): icmp_seq=2 ttl=111 time=6.80 ms\n",
            "64 bytes from waw02s06-in-f14.1e100.net (216.58.209.78): icmp_seq=3 ttl=111 time=6.92 ms\n",
            "\n",
            "--- google.com ping statistics ---\n",
            "3 packets transmitted, 3 received, 0% packet loss, time 2002ms\n",
            "rtt min/avg/max/mdev = 3.930/5.886/6.920/1.383 ms\n"
          ]
        }
      ],
      "source": [
        "!docker run --name ping_google ubuntu:ping google.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We delete the containers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ping_localhost\n",
            "ping_google\n"
          ]
        }
      ],
      "source": [
        "!docker rm ping_localhost ping_google"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The context of `build`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's create a folder called `dockerfile_contexto`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "!mkdir dokerfile_contexto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we create two files in it: a `test.txt` and the `Dockerfile`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "!touch dokerfile_contexto/Dockerfile dokerfile_contexto/text.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We modify the Dockerfile and put the following",
        "\n",
        "``` docker\n",
        "FROM ubuntu:trusty",
        "COPY [\".\", \"/\"]",
        "```\n",
        "\n",
        "This will copy into the image everything that is in the folder where the `Dockerfile` is located. We compile the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sending build context to Docker daemon   2.56kB\n",
            "Step 1/2 : FROM ubuntu:trusty\n",
            " ---> 13b66b487594\n",
            "Step 2/2 : COPY [\".\", \"/\"]\n",
            " ---> 3ab79fdce389\n",
            "Successfully built 3ab79fdce389\n",
            "Successfully tagged ubuntu:contexto\n",
            "\n",
            "Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\n"
          ]
        }
      ],
      "source": [
        "!docker build -t ubuntu:contexto ./dokerfile_contexto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's see what's inside the container"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dockerfile\n",
            "bin\n",
            "boot\n",
            "dev\n",
            "etc\n",
            "home\n",
            "lib\n",
            "lib64\n",
            "media\n",
            "mnt\n",
            "opt\n",
            "proc\n",
            "root\n",
            "run\n",
            "sbin\n",
            "srv\n",
            "sys\n",
            "text.txt\n",
            "tmp\n",
            "usr\n",
            "var\n"
          ]
        }
      ],
      "source": [
        "!docker run --name ls ubuntu:contexto ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see, there is the file `text.txt`. However, it's possible that within the folder in the same directory as the `Dockerfile` there are files or folders that we don't want to be copied into the image for whatever reason. Just like with git we have the `.gitignore`, in docker we have the `.dockerignore`, where we put the files or folders that we don't want to be taken into account when building the image.",
        "\n",
        "So we create a `.dockerignore` file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "!touch dokerfile_contexto/.dockerignore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And inside we add the `text.txt`, and while we're at it, the `Dockerfile` which we don't need inside the image.",
        "\n",
        "*.dockerignore*:",
        "```\n",
        "Dockerfile",
        "It seems like you're referring to a file named `text.txt`. However, I need the actual content of the Markdown file to translate it. Please provide the text from the file.",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We delete the container we had created, compile again, and see what's inside the container."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ls\n"
          ]
        }
      ],
      "source": [
        "!docker rm ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sending build context to Docker daemon  3.072kB\n",
            "Step 1/2 : FROM ubuntu:trusty\n",
            " ---> 13b66b487594\n",
            "Step 2/2 : COPY [\".\", \"/\"]\n",
            " ---> 7a6689546da4\n",
            "Successfully built 7a6689546da4\n",
            "Successfully tagged ubuntu:contexto\n",
            "\n",
            "Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\n"
          ]
        }
      ],
      "source": [
        "!docker build -t ubuntu:contexto ./dokerfile_contexto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bin\n",
            "boot\n",
            "dev\n",
            "etc\n",
            "home\n",
            "lib\n",
            "lib64\n",
            "media\n",
            "mnt\n",
            "opt\n",
            "proc\n",
            "root\n",
            "run\n",
            "sbin\n",
            "srv\n",
            "sys\n",
            "tmp\n",
            "usr\n",
            "var\n"
          ]
        }
      ],
      "source": [
        "!docker run --name ls ubuntu:contexto ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that now neither `Dockerfile` nor `text.txt` are present. Let's delete the container."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ls\n"
          ]
        }
      ],
      "source": [
        "!docker rm ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Multi-stage build"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "At the end of a development, we don't want all the code to be in the image that is going to be sent to production.",
        "\n",
        "We can split the `dockerfile` into two, for example, `developer.Dockerfile` and `production.Dockerfile`, where in development there will be more things than in production. When compiling them, using the `-f` option we choose the `dockerfile` we want to use.",
        "\n",
        "``` bash\n",
        "docker build -t <tag> -f developer.Dockerfile",
        "docker build -t <tag> -f production.Dockerfile",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "But to avoid having to create two `Dockerfile`s, Docker created the `multi stage builds`. With a single `Dockerfile` we will solve the problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create the folder where we are going to save the `Dockerfile`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "!mkdir docker_multi_stage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And inside we create the file `Dockerfile`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "!cd docker_multi_stage && touch Dockerfile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We edit the file, adding the following",
        "\n",
        "``` dockerfile\n",
        "# Stage 1: Generate the executable with Python based on Alpine",
        "FROM python:3.9-alpine as build-stage",
        "WORKDIR /app",
        "# Install dependencies for PyInstaller",
        "RUN apk add --no-cache gcc musl-dev libc-dev",
        "# Generate hello.py",
        "RUN echo 'print(\"Hello from Alpine!\")' > hello.py",
        "# Install PyInstaller",
        "RUN pip install pyinstaller",
        "# Using PyInstaller to Create a Standalone Executable",
        "RUN pyinstaller --onefile hello.py",
        "\n",
        "# Stage 2: Run the executable in an Alpine image",
        "FROM alpine:latest",
        "WORKDIR /app",
        "# Copy the executable from the build stage",
        "COPY --from=build-stage /app/dist/hello .",
        "# Default command to run the executable",
        "CMD [\"./hello\"]",
        "```\n",
        "\n",
        "As can be seen, the `Dockerfile` is divided into two parts. On one hand, we work on the image `python:3.9-alpine`, which is called `build-stage`. On the other hand, we work on the image `alpine:latest`, which is a very lightweight Linux image and is widely used in production.",
        "\n",
        "We compile it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/2)                                          docker:default\n",
            "\u001b[?25h"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.2s (4/6)                                          docker:default\n",
            "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
            "\u001b[0m\u001b[34m => => transferring dockerfile: 722B                                       0.0s\n",
            "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
            "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
            "\u001b[0m => [internal] load metadata for docker.io/library/alpine:latest           0.1s\n",
            " => [internal] load metadata for docker.io/library/python:3.9-alpine       0.1s\n",
            "...\n",
            "\u001b[0m\u001b[34m => CACHED [stage-1 3/3] COPY --from=build-stage /app/dist/hello .         0.0s\n",
            "\u001b[0m\u001b[34m => exporting to image                                                     0.0s\n",
            "\u001b[0m\u001b[34m => => exporting layers                                                    0.0s\n",
            "\u001b[0m\u001b[34m => => writing image sha256:7fb090d1495d00e892118b6bc3c03400b63a435fd4703  0.0s\n",
            "\u001b[0m\u001b[34m => => naming to docker.io/maximofn/multistagebuild:latest                 0.0s\n",
            "\u001b[0m\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!docker build -t maximofn/multistagebuild:latest ./docker_multi_stage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we now look at the images we have"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REPOSITORY                 TAG       IMAGE ID       CREATED         SIZE\n",
            "maximofn/multistagebuild   latest    7fb090d1495d   8 minutes ago   13.6MB\n"
          ]
        }
      ],
      "source": [
        "!docker image ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's download the Python image to see how much it weighs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.9-alpine: Pulling from library/python\n",
            "\n",
            "\u001b[1Ba8db6415: Already exists \n",
            "\u001b[1Bd5e70e42: Already exists \n",
            "\u001b[1B3fe96417: Already exists \n",
            "\u001b[1Baa4dddbb: Already exists \n",
            "\u001b[1B518be9f7: Already exists Digest: sha256:6e508b43604ff9a81907ec17405c9ad5c13664e45a5affa2206af128818c7486\n",
            "Status: Downloaded newer image for python:3.9-alpine\n",
            "docker.io/library/python:3.9-alpine\n"
          ]
        }
      ],
      "source": [
        "!docker pull python:3.9-alpine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REPOSITORY                 TAG          IMAGE ID       CREATED         SIZE\n",
            "maximofn/multistagebuild   latest       7fb090d1495d   9 minutes ago   13.6MB\n",
            "python                     3.9-alpine   6946662f018b   9 days ago      47.8MB\n"
          ]
        }
      ],
      "source": [
        "!docker image ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that while our image weighs only 13.6 MB, the Python image with which the application was built weighs 47.8 MB. Therefore, we can draw two conclusions: with the first image, the Python one, the application was built, the executable was generated, and it is this executable that we use in the second image, the Alpine one. Additionally, we can see that although the first image used is the Python one, it does not get downloaded to our system, as we had to download it ourselves."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Well, it only remains to test it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello from Alpine!\n"
          ]
        }
      ],
      "source": [
        "!docker run --rm --name multi_stage_build maximofn/multistagebuild"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It works!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Multi arch builds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Suppose we want to create an image that can run on a computer and a Raspberry Pi. The computer likely has a microprocessor with AMD64 architecture, while the Raspberry Pi has a microprocessor with ARM architecture. Therefore, we cannot create the same image for both. That is, when we create an image, we do so with a `Dockerfile` that usually starts like this",
        "\n",
        "``` Dockerfile\n",
        "FROM ...",
        "```\n",
        "\n",
        "Therefore, the `Dockerfile` for the computer image could start like this",
        "\n",
        "``` Dockerfile\n",
        "FROM ubuntu:latest",
        "```\n",
        "\n",
        "While the one for the Raspberry could start like this",
        "\n",
        "``` Dockerfile\n",
        "FROM arm64v8/ubuntu:latest",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We should create two `Dockerfile` files, build them, and use one image on the computer and another on the Raspberry Pi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To avoid having to look at the computer architecture and see what image we need to use, Docker creates the `manifest`, which, as its name suggests, is a manifest that indicates, based on the microarchitecture we have, which image to use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So let's see how to do this"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we create a folder where we are going to create our `Dockerfile`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "!mkdir docker_multi_arch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we create the two Dockerfiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "!cd docker_multi_arch && touch Dockerfile_arm64 Dockerfile_amd64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We write the `Dockerfile` for AMD64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "!cd docker_multi_arch && echo \"FROM ubuntu:20.04\" >> Dockerfile_amd64 && echo \"CMD echo 'Hello from amd64'\" >> Dockerfile_amd64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "!cd docker_multi_arch && echo \"FROM arm64v8/ubuntu:latest\" >> Dockerfile_arm && echo \"CMD echo 'Hello from ARM'\" >> Dockerfile_arm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we combine the two images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/1)                                          docker:default\n",
            "\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.2s (2/3)                                          docker:default\n",
            "\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
            "\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
            "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
            "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
            "\u001b[0m => [internal] load metadata for docker.io/library/ubuntu:20.04            0.1s\n",
            "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.3s (2/3)                                          docker:default\n",
            "\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
            "\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
            "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
            "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
            "\u001b[0m => [internal] load metadata for docker.io/library/ubuntu:20.04            0.2s\n",
            "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.5s (2/3)                                          docker:default\n",
            "\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
            "\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
            "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
            "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
            "\u001b[0m => [internal] load metadata for docker.io/library/ubuntu:20.04            0.4s\n",
            "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.6s (2/3)                                          docker:default\n",
            "\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
            "\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
            "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
            "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
            "\u001b[0m => [internal] load metadata for docker.io/library/ubuntu:20.04            0.5s\n",
            "...\n",
            "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
            "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile_arm                   0.0s\n",
            "\u001b[0m\u001b[34m => => transferring dockerfile: 94B                                        0.0s\n",
            "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/arm64v8/ubuntu:latest           1.8s\n",
            "\u001b[0m\u001b[34m => [auth] arm64v8/ubuntu:pull token for registry-1.docker.io              0.0s\n",
            "\u001b[0m\u001b[34m => CACHED [1/1] FROM docker.io/arm64v8/ubuntu:latest@sha256:94d12db896d0  0.0s\n",
            "\u001b[0m\u001b[34m => exporting to image                                                     0.0s\n",
            "\u001b[0m\u001b[34m => => exporting layers                                                    0.0s\n",
            "\u001b[0m\u001b[34m => => writing image sha256:a9732c1988756dc8e836fd96e5c9512e349c97ea5af46  0.0s\n",
            "\u001b[0m\u001b[34m => => naming to docker.io/maximofn/multiarch:arm                          0.0s\n",
            "\u001b[0m\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!cd docker_multi_arch && docker build -t maximofn/multiarch:arm -f Dockerfile_arm ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's see if we have both images compiled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REPOSITORY           TAG       IMAGE ID       CREATED       SIZE\n",
            "maximofn/multiarch   arm       a9732c198875   4 weeks ago   69.2MB\n",
            "maximofn/multiarch   amd64     5b612c83025f   6 weeks ago   72.8MB\n"
          ]
        }
      ],
      "source": [
        "!docker image ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that we have compiled the two images. To be able to create a manifest, we first have to upload the images to Docker Hub, so we upload them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The push refers to repository [docker.io/maximofn/multiarch]\n",
            "\n",
            "\u001b[1B82bdeb5f: Mounted from library/ubuntu amd64: digest: sha256:30e820f2a11a24ad4d8fb624ae485f7c1bcc299e8cfc72c88adce1acd0447e1d size: 529\n"
          ]
        }
      ],
      "source": [
        "!docker push maximofn/multiarch:amd64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The push refers to repository [docker.io/maximofn/multiarch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1Beda53374: Layer already exists arm: digest: sha256:6ec5a0752d49d3805061314147761bf25b5ff7430ce143adf34b70d4eda15fb8 size: 529\n"
          ]
        }
      ],
      "source": [
        "!docker push maximofn/multiarch:arm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If I go to my Docker Hub I can see that my image `maximofn/multiarch` has the tags `amd64` and `arm`",
        "\n",
        "![docker_multi_arch_tags](https://images.maximofn.com/docker_multi_arch_tags.webp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we are going to create the `manifest` based on these two images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created manifest list docker.io/maximofn/multiarch:latest\n"
          ]
        }
      ],
      "source": [
        "!docker manifest create maximofn/multiarch:latest maximofn/multiarch:amd64 maximofn/multiarch:arm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once created, we have to indicate the CPU architectures to which each one corresponds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "!docker manifest annotate maximofn/multiarch:latest maximofn/multiarch:amd64 --os linux --arch amd64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "manifest for image maximofn/multiarch:arm64 does not exist in maximofn/multiarch:latest\n"
          ]
        }
      ],
      "source": [
        "!docker manifest annotate maximofn/multiarch:latest maximofn/multiarch:arm64 --os linux --arch arm64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once created and annotated, we can upload the `manifest` to Docker Hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sha256:1ea28e9a04867fe0e0d8b0efa455ce8e4e29e7d9fd4531412b75dbd0325e9304\n"
          ]
        }
      ],
      "source": [
        "!docker manifest push maximofn/multiarch:latest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If I now look at the tags for my image `maximofn/multiarch`, I also see the `latest` tag.",
        "\n",
        "![docker_multi_arch_tags_manifest](https://images.maximofn.com/docker_multi_arch_tags_manifest.webp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, whether I want to use my image from a machine with an AMD64 or ARM CPU when doing `FROM maximofn/multiarch:latest`, Docker will check the CPU architecture and download the `amd64` tag or the `arm` tag. Let's see it in action; if I run the image on my computer, I get"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unable to find image 'maximofn/multiarch:latest' locally\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "latest: Pulling from maximofn/multiarch\n",
            "Digest: sha256:7cef0de10f7fa2b3b0dca0fbf398d1f48af17a0bbc5b9beca701d7c427c9fd84\n",
            "Status: Downloaded newer image for maximofn/multiarch:latest\n",
            "Hello from amd64\n"
          ]
        }
      ],
      "source": [
        "!docker run maximofn/multiarch:latest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since he doesn't have it, he downloads it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If I now connect via SSH to a Raspberry Pi and try the same thing, I get",
        "\n",
        "```bash\n",
        "raspberrry@raspberrypi:~ $ docker run maximofn/multiarch:latest",
        "Unable to find image 'maximofn/multiarch:latest' locally",
        "latest: Pulling from maximofn/multiarch",
        "Digest: sha256:1ea28e9a04867fe0e0d8b0efa455ce8e4e29e7d9fd4531412b75dbd0325e9304",
        "Status: Downloaded newer image for maximofn/multiarch:latest",
        "Hello from ARM",
        "```\n",
        "\n",
        "`Hello from ARM` appears because the Raspberry Pi has a microcontroller with an ARM architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As can be seen, each machine has downloaded the image it needed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Advanced Correct Writing of Dockerfiles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have already seen how to write Dockerfiles correctly, but there is one more thing we can do now that we know about multi-stage builds: create a container to build the executable and another smaller one to run it.",
        "\n",
        "We came to the conclusion that a good Dockerfile could be this",
        "\n",
        "``` Dockerfile\n",
        "FROM python:3.9.18-alpine",
        "WORKDIR /sourceCode/sourceApp",
        "COPY ./sourceCode/sourceApp .",
        "CMD [\"python3\", \"app.py\"]",
        "```\n",
        "\n",
        "Let's now create an executable in a builder container and run it in another smaller one.",
        "\n",
        "``` dockerfile\n",
        "FROM python:3.9.18-alpine as builder",
        "WORKDIR /sourceCode/sourceApp",
        "RUN apk add --no-cache gcc musl-dev libc-dev && pip install pyinstaller",
        "COPY ./sourceCode/sourceApp .",
        "RUN pyinstaller --onefile app.py",
        "\n",
        "FROM alpine:3.18.3",
        "WORKDIR /sourceCode/sourceApp",
        "COPY --from=builder /sourceCode/sourceApp/dist/app .",
        "CMD [\"./app\"]",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create the Python code in the necessary path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "!mkdir multistagebuild/sourceCode\n",
        "!mkdir multistagebuild/sourceCode/sourceApp\n",
        "!touch multistagebuild/sourceCode/sourceApp/app.py\n",
        "!echo 'print(\"Hello from Alpine!\")' > multistagebuild/sourceCode/sourceApp/app.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now compiling the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/0)                                          docker:default\n",
            "\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.0s (0/1)                                          docker:default\n",
            "\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.2s (3/5)                                          docker:default\n",
            "\u001b[34m => [internal] load build definition from Dockerfile                       0.1s\n",
            "\u001b[0m\u001b[34m => => transferring dockerfile: 357B                                       0.0s\n",
            "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
            "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
            "\u001b[0m => [internal] load metadata for docker.io/library/alpine:3.18.3           0.1s\n",
            " => [internal] load metadata for docker.io/library/python:3.9.18-alpine    0.1s\n",
            "\u001b[34m => [auth] library/alpine:pull token for registry-1.docker.io              0.0s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.3s (3/5)                                          docker:default\n",
            "\u001b[34m => [internal] load build definition from Dockerfile                       0.1s\n",
            "\u001b[0m\u001b[34m => => transferring dockerfile: 357B                                       0.0s\n",
            "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
            "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
            "\u001b[0m => [internal] load metadata for docker.io/library/alpine:3.18.3           0.2s\n",
            " => [internal] load metadata for docker.io/library/python:3.9.18-alpine    0.2s\n",
            "\u001b[34m => [auth] library/alpine:pull token for registry-1.docker.io              0.0s\n",
            "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.5s (4/6)                                          docker:default\n",
            "\u001b[34m => [internal] load build definition from Dockerfile                       0.1s\n",
            "\u001b[0m\u001b[34m => => transferring dockerfile: 357B                                       0.0s\n",
            "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
            "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
            "\u001b[0m => [internal] load metadata for docker.io/library/alpine:3.18.3           0.4s\n",
            "...\n",
            "\u001b[0m\u001b[34m => exporting to image                                                     0.1s\n",
            "\u001b[0m\u001b[34m => => exporting layers                                                    0.1s\n",
            "\u001b[0m\u001b[34m => => writing image sha256:8a22819145c6fee17e138e818610ccf46d7e13c786825  0.0s\n",
            "\u001b[0m\u001b[34m => => naming to docker.io/maximofn/multistagebuild:alpine-3.18.3          0.0s\n",
            "\u001b[0m\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!docker build -t maximofn/multistagebuild:alpine-3.18.3 ./multistagebuild"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We run it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello from Alpine!\n"
          ]
        }
      ],
      "source": [
        "!docker run --rm --name multi_stage_build maximofn/multistagebuild:alpine-3.18.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The image `maximofn/multistagebuild:alpine-3.18.3` only weighs 13.6 MB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Difference between RUN, CMD and ENTRYPOINT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### RUN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `RUN` command is the simplest; it just executes a command during the image build process. For example, if we want to install a package in the image, we do it using `RUN`.",
        "\n",
        "Therefore, it is important, `RUN` is executed at the time of image compilation, not when the container is run."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### CMD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `CMD` command is the command that runs when the container starts. For example, if we want the container to run a command when it starts, we do this through `CMD`. For instance, if we have a Python application in a container, with `CMD` we can tell it to run the Python application when the container starts.",
        "\n",
        "In this way, when the container is started, the Python application will be executed. That is, if we do `docker run <image>`, the Python application will be executed. However, `CMD` allows us to override the command that runs when the container starts, for example, if we do `docker run <image> bash`, `bash` will run instead of the Python application."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ENTRYPOINT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `ENTRYPOINT` command is similar to the `CMD` command, but with a difference: `ENTRYPOINT` is not intended to be overwritten. This means that if we have a Python application in a container, with `ENTRYPOINT` we can specify that when the container runs, it should execute the Python application. However, if we run `docker run <image> bash`, the Python application will still run, not `bash`.",
        "\n",
        "A very common use of `ENTRYPOINT` is when we want the container to be an executable, for example, if we want the container to be an executable version of Python that we don't have on our host, because we want to test the new version of Python that has been released, we can do",
        "\n",
        "``` Dockerfile\n",
        "FROM python:3.9.18-alpine",
        "ENTRYPOINT [\"python3\"]",
        "```\n",
        "\n",
        "In this way, when the container is started, Python will be executed. That is, if we do `docker run <image>`, Python will be executed. But `ENTRYPOINT` allows us to override the command that runs when the container starts, for example, if we do `docker run <image> myapp.py`, it will execute `python3 myapp.py` inside the container. This way we can test our Python application in the new version of Python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Changes in a Container"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With `docker diff` we can see the differences between the container and the image, which is the same as the difference in the container from when it was created until now.",
        "\n",
        "Let's run a container and inside we create a file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root@895a19aef124:/# touch file.txt\n"
          ]
        }
      ],
      "source": [
        "!docker run --rm -it --name ubuntu-20.04 ubuntu:20.04 bash"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can see the difference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C /root\n",
            "A /root/.bash_history\n",
            "A /file.txt\n"
          ]
        }
      ],
      "source": [
        "!docker diff ubuntu-20.04"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`A` means that it has been added, `C` means that it has been changed and `D` means that it has been deleted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Docker in Docker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Suppose we have containers that need to start or stop other containers. This is achieved in the following way",
        "\n",
        "Since in Linux everything is a file and the host communicates with Docker through a socket, for Linux that socket is a file. So if we mount that socket as a file to the container, it will be able to communicate with Docker."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, let's set up a container with Ubuntu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "144091e4a3325c9068064ff438f8865b40f944af5ce649c7156ca55a3453e423\n"
          ]
        }
      ],
      "source": [
        "!docker run -d --name ubuntu ubuntu:latest tail -f /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's set up the container that will be able to communicate with Docker by mounting the `/var/run/docker.sock` folder.",
        "\n",
        "``` bash\n",
        "$ docker run -it --rm --name main -v /var/run/docker.sock:/var/run/docker.sock docker:19.03.12",
        "#",
        "```\n",
        "\n",
        "We have entered a container, and if we run `docker ps` inside it",
        "\n",
        "``` bash\n",
        "# docker ps",
        "CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES",
        "9afb778d6c20        docker:19.03.12     \"docker-entrypoint.s\u2026\"   3 seconds ago       Up 2 seconds                            main",
        "144091e4a332        ubuntu:latest       \"tail -f /dev/null\"      19 seconds ago      Up 18 seconds                           ubuntu",
        "```\n",
        "\n",
        "As we can see, inside Docker we can see the containers of the host"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can run a new container",
        "\n",
        "``` bash\n",
        "# docker run -d --name ubuntu_from_main ubuntu:latest tail -f /dev/null",
        "This appears to be a hash value, not markdown text. As such, it doesn't require translation. If you have actual markdown text to translate, please provide it and I'll happily translate it for you.",
        "/ #",
        "```\n",
        "\n",
        "And if we look at the containers again",
        "\n",
        "``` bash\n",
        "# docker ps",
        "CONTAINER ID        IMAGE               COMMAND                  CREATED              STATUS              PORTS               NAMES",
        "362654a72bb0        ubuntu:latest       \"tail -f /dev/null\"      3 seconds ago        Up 3 seconds                            ubuntu_from_main",
        "9afb778d6c20        docker:19.03.12     \"docker-entrypoint.s\u2026\"   About a minute ago   Up About a minute                       main",
        "144091e4a332        ubuntu:latest       \"tail -f /dev/null\"      2 minutes ago        Up About a minute                       ubuntu",
        "```\n",
        "\n",
        "But if we now run a new terminal from the host, we will see the container created from inside the container."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE             COMMAND                  CREATED              STATUS              PORTS     NAMES\n",
            "362654a72bb0   ubuntu:latest     \"tail -f /dev/null\"      About a minute ago   Up About a minute             ubuntu_from_main\n",
            "9afb778d6c20   docker:19.03.12   \"docker-entrypoint.s\u2026\"   3 minutes ago        Up 3 minutes                  main\n",
            "144091e4a332   ubuntu:latest     \"tail -f /dev/null\"      3 minutes ago        Up 3 minutes                  ubuntu\n"
          ]
        }
      ],
      "source": [
        "!docker ps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Everything we do from the `main` container will be reflected on the host."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This has the advantage that we can install programs in a container that has access to the host without having to install them on the host. For example [dive](https://github.com/wagoodman/dive) is a tool for exploring containers, but if you don't want to install it on the host, you can install it in a container with access to the host, so from that `main` container you can explore the rest of the containers without having to install it on the host."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.7.6 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "maximofn": {
      "date": "2023-01-22",
      "description_en": "\ud83d\udc33 Create as many development environments as you want with Docker. No more On my machine it works",
      "description_es": "\ud83d\udc33 Crea todos los entornos de desarrollo que quieras con Docker. Ya no m\u00e1s En mi m\u00e1quina funciona",
      "description_pt": "\ud83d\udc33 Crie quantos ambientes de desenvolvimento voc\u00ea quiser com o Docker. Chega de Funciona na minha m\u00e1quina",
      "end_url": "docker",
      "image": "https://images.maximofn.com/docker.webp",
      "image_hover_path": "https://images.maximofn.com/docker.webp",
      "keywords_en": "docker, tutorial, development, environments",
      "keywords_es": "docker, tutorial, desarrollo, entornos",
      "keywords_pt": "docker, tutorial, desenvolvimento, ambientes",
      "title_en": "Docker",
      "title_es": "Docker",
      "title_pt": "Docker"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "d5745ab6aba164e1152437c779991855725055592b9f2bdb41a4825db7168d26"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}