{
  "cells": [
  {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "# Docker"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "## Containers"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "This notebook has been automatically translated to make it accessible to more people, please let me know if you see any typos.\n",
"\n",
"### Hello world"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Run the first Hello world container with the command `docker run hello-world`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Unable to find image 'hello-world:latest' locally\n"
          ]
        },
{
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "latest: Pulling from library/hello-world\n",
"\n",
"\u001b[1B85e32844: Pull complete 457kB/2.457kBB\u001b[1A\u001b[2KDigest: sha256:dcba6daec718f547568c562956fa47e1b03673dd010fe6ee58ca806767031d1c\n",
"Status: Downloaded newer image for hello-world:latest\n",
"\n",
"Hello from Docker!\n",
"This message shows that your installation appears to be working correctly.\n",
"\n",
"To generate this message, Docker took the following steps:\n",
" 1. The Docker client contacted the Docker daemon.\n",
" 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\n",
"    (amd64)\n",
" 3. The Docker daemon created a new container from that image which runs the\n",
"    executable that produces the output you are currently reading.\n",
" 4. The Docker daemon streamed that output to the Docker client, which sent it\n",
"    to your terminal.\n",
"\n",
"To try something more ambitious, you can run an Ubuntu container with:\n",
" $ docker run -it ubuntu bash\n",
"\n",
"Share images, automate workflows, and more with a free Docker ID:\n",
" https://hub.docker.com/\n",
"\n",
"For more examples and ideas, visit:\n",
" https://docs.docker.com/get-started/\n",
"\n"
          ]
        }
      ],
      "source": [
      "!docker run hello-world"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "As we do not have the container saved locally, docker downloads it from docker hub. If we now run the container again, the first message, indicating that it is being downloaded, will no longer appear."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "\n",
"Hello from Docker!\n",
"This message shows that your installation appears to be working correctly.\n",
"\n",
"To generate this message, Docker took the following steps:\n",
" 1. The Docker client contacted the Docker daemon.\n",
" 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\n",
"    (amd64)\n",
" 3. The Docker daemon created a new container from that image which runs the\n",
"    executable that produces the output you are currently reading.\n",
" 4. The Docker daemon streamed that output to the Docker client, which sent it\n",
"    to your terminal.\n",
"\n",
"To try something more ambitious, you can run an Ubuntu container with:\n",
" $ docker run -it ubuntu bash\n",
"\n",
"Share images, automate workflows, and more with a free Docker ID:\n",
" https://hub.docker.com/\n",
"\n",
"For more examples and ideas, visit:\n",
" https://docs.docker.com/get-started/\n",
"\n"
          ]
        }
      ],
      "source": [
      "!docker run hello-world"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "To see which containers are running run `docker ps`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
          ]
        }
      ],
      "source": [
      "!docker ps"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "As we can see there is no open container. However, if we run `docker ps -a` (`all`) we see that if we run `docker ps -a` (`all`) we see that there are"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE         COMMAND    CREATED          STATUS                      PORTS     NAMES\n",
"1efb51bbbf38   hello-world   \"/hello\"   10 seconds ago   Exited (0) 9 seconds ago              strange_thompson\n",
"5f5705e7603e   hello-world   \"/hello\"   15 seconds ago   Exited (0) 14 seconds ago             laughing_jang\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We see that two containers named `hello-world` appear, which are the two that we have executed before. So every time we run the `run` command, docker creates a new container, not runs one that already exists."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If we want to have more information about one of the two containers we can run `docker inspect <id>`, where `<id>` corresponds to the ID of the docker shown in the previous list."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "[\n",
"    {\n",
"        \"Id\": \"1efb51bbbf38917affd1b5871db8e658ebfe0b2efa5ead17545680b7866f682e\",\n",
"        \"Created\": \"2023-09-04T03:59:17.795499354Z\",\n",
"        \"Path\": \"/hello\",\n",
"        \"Args\": [],\n",
"        \"State\": {\n",
"            \"Status\": \"exited\",\n",
"            \"Running\": false,\n",
"            \"Paused\": false,\n",
"            \"Restarting\": false,\n",
"            \"OOMKilled\": false,\n",
"            \"Dead\": false,\n",
"            \"Pid\": 0,\n",
"            \"ExitCode\": 0,\n",
"            \"Error\": \"\",\n",
"            \"StartedAt\": \"2023-09-04T03:59:18.406663026Z\",\n",
"            \"FinishedAt\": \"2023-09-04T03:59:18.406181184Z\"\n",
"        },\n",
"        \"Image\": \"sha256:9c7a54a9a43cca047013b82af109fe963fde787f63f9e016fdc3384500c2823d\",\n",
"        \"ResolvConfPath\": \"/var/lib/docker/containers/1efb51bbbf38917affd1b5871db8e658ebfe0b2efa5ead17545680b7866f682e/resolv.conf\",\n",
"        \"HostnamePath\": \"/var/lib/docker/containers/1efb51bbbf38917affd1b5871db8e658ebfe0b2efa5ead17545680b7866f682e/hostname\",\n",
"        \"HostsPath\": \"/var/lib/docker/containers/1efb51bbbf38917affd1b5871db8e658ebfe0b2efa5ead17545680b7866f682e/hosts\",\n",
"        \"LogPath\": \"/var/lib/docker/containers/1efb51bbbf38917affd1b5871db8e658ebfe0b2efa5ead17545680b7866f682e/1efb51bbbf38917affd1b5871db8e658ebfe0b2efa5ead17545680b7866f682e-json.log\",\n",
"        \"Name\": \"/strange_thompson\",\n",
"        ...\n",
"            }\n",
"        }\n",
"    }\n",
"]\n"
          ]
        }
      ],
      "source": [
      "!docker inspect 1efb51bbbf38"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "As remembering IDs is complicated for us, docker assigns names to the containers to make our life easier. So in the list above, the last column corresponds to the name that docker has assigned to each container, so if we now run `docker inspect <name>` we will get the same information as with the ID"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "I run `docker ps -a` again to see the list again"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE         COMMAND    CREATED         STATUS                     PORTS     NAMES\n",
"1efb51bbbf38   hello-world   \"/hello\"   2 minutes ago   Exited (0) 2 minutes ago             strange_thompson\n",
"5f5705e7603e   hello-world   \"/hello\"   2 minutes ago   Exited (0) 2 minutes ago             laughing_jang\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "And now I run `docker inspect <name>` to see the information of the container"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "[\n",
"    {\n",
"        \"Id\": \"1efb51bbbf38917affd1b5871db8e658ebfe0b2efa5ead17545680b7866f682e\",\n",
"        \"Created\": \"2023-09-04T03:59:17.795499354Z\",\n",
"        \"Path\": \"/hello\",\n",
"        \"Args\": [],\n",
"        \"State\": {\n",
"            \"Status\": \"exited\",\n",
"            \"Running\": false,\n",
"            \"Paused\": false,\n",
"            \"Restarting\": false,\n",
"            \"OOMKilled\": false,\n",
"            \"Dead\": false,\n",
"            \"Pid\": 0,\n",
"            \"ExitCode\": 0,\n",
"            \"Error\": \"\",\n",
"            \"StartedAt\": \"2023-09-04T03:59:18.406663026Z\",\n",
"            \"FinishedAt\": \"2023-09-04T03:59:18.406181184Z\"\n",
"        },\n",
"        \"Image\": \"sha256:9c7a54a9a43cca047013b82af109fe963fde787f63f9e016fdc3384500c2823d\",\n",
"        \"ResolvConfPath\": \"/var/lib/docker/containers/1efb51bbbf38917affd1b5871db8e658ebfe0b2efa5ead17545680b7866f682e/resolv.conf\",\n",
"        \"HostnamePath\": \"/var/lib/docker/containers/1efb51bbbf38917affd1b5871db8e658ebfe0b2efa5ead17545680b7866f682e/hostname\",\n",
"        \"HostsPath\": \"/var/lib/docker/containers/1efb51bbbf38917affd1b5871db8e658ebfe0b2efa5ead17545680b7866f682e/hosts\",\n",
"        \"LogPath\": \"/var/lib/docker/containers/1efb51bbbf38917affd1b5871db8e658ebfe0b2efa5ead17545680b7866f682e/1efb51bbbf38917affd1b5871db8e658ebfe0b2efa5ead17545680b7866f682e-json.log\",\n",
"        \"Name\": \"/strange_thompson\",\n",
"        ...\n",
"            }\n",
"        }\n",
"    }\n",
"]\n"
          ]
        }
      ],
      "source": [
      "!docker inspect strange_thompson"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "But why with `docker ps` we don't see any containers and with `docker ps -a` we do. This is because `docker ps` only shows the containers that are running, while `docker ps -a` shows all containers, those that are running and those that are off."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We can create a container by assigning it a name ourselves using the command `docker run --name <name> hello-world`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "\n",
"Hello from Docker!\n",
"This message shows that your installation appears to be working correctly.\n",
"\n",
"To generate this message, Docker took the following steps:\n",
" 1. The Docker client contacted the Docker daemon.\n",
" 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\n",
"    (amd64)\n",
" 3. The Docker daemon created a new container from that image which runs the\n",
"    executable that produces the output you are currently reading.\n",
" 4. The Docker daemon streamed that output to the Docker client, which sent it\n",
"    to your terminal.\n",
"\n",
"To try something more ambitious, you can run an Ubuntu container with:\n",
" $ docker run -it ubuntu bash\n",
"\n",
"Share images, automate workflows, and more with a free Docker ID:\n",
" https://hub.docker.com/\n",
"\n",
"For more examples and ideas, visit:\n",
" https://docs.docker.com/get-started/\n",
"\n"
          ]
        }
      ],
      "source": [
      "!docker run --name hello_world hello-world"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "This will be more convenient for us, since we will be able to control the names of the containers ourselves."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If we now want to create another container with the same name we will not be able to, because docker does not allow duplicate container names. So if we want to rename the container we can use the command `docker rename <old name> <new name>`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
      "!docker rename hello_world hello_world2"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We now have a bunch of the same containers. So if we want to delete any of them we have to use the command `docker rm <id>` or `docker rm <name>`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE         COMMAND    CREATED         STATUS                     PORTS     NAMES\n",
"f432c9c2ca21   hello-world   \"/hello\"   9 seconds ago   Exited (0) 8 seconds ago             hello_world2\n",
"1efb51bbbf38   hello-world   \"/hello\"   4 minutes ago   Exited (0) 4 minutes ago             strange_thompson\n",
"5f5705e7603e   hello-world   \"/hello\"   4 minutes ago   Exited (0) 4 minutes ago             laughing_jang\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "hello_world2\n"
          ]
        }
      ],
      "source": [
      "!docker rm hello_world2"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If we look at the list of containers again, the `hello_world2` container is no longer there."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE         COMMAND    CREATED         STATUS                     PORTS     NAMES\n",
"1efb51bbbf38   hello-world   \"/hello\"   5 minutes ago   Exited (0) 5 minutes ago             strange_thompson\n",
"5f5705e7603e   hello-world   \"/hello\"   5 minutes ago   Exited (0) 5 minutes ago             laughing_jang\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If we want to delete all the containers, we can do it one by one, but as it is very heavy, we can delete all of them using the `docker container prune` command. This command deletes only the containers that are stopped."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "WARNING! This will remove all stopped containers.\n",
"Are you sure you want to continue? [y/N] y"
          ]
        }
      ],
      "source": [
      "!docker container prune"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Docker asks if you are sure, and if you say yes, it deletes them all. If you now list all the containers, none of them appear"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Iterative mode"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We are going to run ubuntu using the command `docker run ubuntu`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Unable to find image 'ubuntu:latest' locally\n",
"latest: Pulling from library/ubuntu\n",
"\n",
"\u001b[1BDigest: sha256:20fa2d7bb4de7723f542be5923b06c4d704370f0390e4ae9e1c833c8785644c1[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\n",
"Status: Downloaded newer image for ubuntu:latest\n"
          ]
        }
      ],
      "source": [
      "!docker run ubuntu"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "As we can see now it has taken longer to download. If we list the containers using the `docker ps` command we see that the container we just created does not appear, that is, it is not running."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
          ]
        }
      ],
      "source": [
      "!docker ps"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We now list all the containers"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND   CREATED         STATUS                     PORTS     NAMES\n",
"da16b3a85178   ubuntu    \"bash\"    4 seconds ago   Exited (0) 3 seconds ago             hardcore_kare\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We see that the container status is `Exited (0)`."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If we look at the container command `bash` and next to the `Exited (0)` status it indicates that Ubuntu has started, has executed its *bash*, has finished the execution and has returned a 0. This happens because Ubuntu's bash has not been told anything to do. To solve this, we are now going to run the container using the command `docker run -it ubuntu`, with `it` what we are telling it is that we want to run it in iterative mode."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "root@5b633e9d838f:/#"
          ]
        }
      ],
      "source": [
      "!docker run -it ubuntu"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Now we see that we are inside the ubuntu bash. If we run the command `cat /etc/lsb-release` we can see the distribution of Ubuntu"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "DISTRIB_ID=Ubuntu\n",
"DISTRIB_RELEASE=22.04\n",
"DISTRIB_CODENAME=jammy\n",
"DISTRIB_DESCRIPTION=\"Ubuntu 22.04.1 LTS\""
          ]
        }
      ],
      "source": [
      "!root@5b633e9d838f:/# cat /etc/lsb-release"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If we open another terminal and see the list of containers, now the container running Ubuntu will appear."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND   CREATED         STATUS         PORTS     NAMES\n",
"5b633e9d838f   ubuntu    \"bash\"    3 minutes ago   Up 3 minutes             funny_mirzakhani\n"
          ]
        }
      ],
      "source": [
      "!docker ps"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We see the container with Ubuntu and in its status we can see `UP`."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If we see now the list of all the containers, we will see that the two containers with Ubuntu are shown, the first one off and the second one running"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND   CREATED         STATUS                     PORTS     NAMES\n",
"5b633e9d838f   ubuntu    \"bash\"    3 minutes ago   Up 3 minutes                         funny_mirzakhani\n",
"da16b3a85178   ubuntu    \"bash\"    3 minutes ago   Exited (0) 3 minutes ago             hardcore_kare\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If we go back to the terminal where we had Ubuntu running inside a docker, if we type ``exit`` we will exit Ubuntu."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "exit"
          ]
        }
      ],
      "source": [
      "!root@5b633e9d838f:/# exit"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If we run ``docker ps`` the container is no longer displayed"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
          ]
        }
      ],
      "source": [
      "!docker ps"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "But if I run ``docker ps -a`` it does appear. This means that the container is turned off"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND   CREATED         STATUS                      PORTS     NAMES\n",
"5b633e9d838f   ubuntu    \"bash\"    4 minutes ago   Exited (0) 27 seconds ago             funny_mirzakhani\n",
"da16b3a85178   ubuntu    \"bash\"    4 minutes ago   Exited (0) 4 minutes ago              hardcore_kare\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "This happens because when typing ``exit``, we are actually typing it in the Ubuntu bash console, which means that we are terminating the Ubuntu bash process."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Life cycle of a container"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "In docker, when the main process of a container terminates, the container is shut down. Several processes can run inside a container, but only when the main process is terminated, the container is shut down.\n",
"\n",
"Therefore, if we want to run a container that does not shut down when a process terminates, we must make its main process not terminate. In this case, do not terminate bash\n",
"\n",
"If we want to run a container with ubuntu, but not end when the bash process finishes, we can do it in the following way"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "ce4d60427dcd4b326d15aa832b816c209761d6b4e067a016bb75bf9366c37054\n"
          ]
        }
      ],
      "source": [
      "!docker run --name alwaysup -d ubuntu tail -f /dev/null"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "What we do is first give it the name ``alwaysup``, secondly we pass the ``-d`` (``detach``) option to make the container run in the background and finally we tell it the main process we want to run in the container, which in this case is ``tail -f /dev/null`` which is equivalent to a ``nop`` command.\n",
"\n",
"This will return the container ID, but we will not be inside ubuntu as it was before."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If we now look at the list of containers that are running, the container we have just created is displayed"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND               CREATED          STATUS          PORTS     NAMES\n",
"ce4d60427dcd   ubuntu    \"tail -f /dev/null\"   18 seconds ago   Up 17 seconds             alwaysup\n"
          ]
        }
      ],
      "source": [
      "!docker ps"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Since we already have a container always running, we can connect to it using the ``exec`` command. We tell it the name or ID of the container and pass it the process we want to run. We also pass the ``-it`` option to tell it to be iteractive."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "root@ce4d60427dcd:/#"
          ]
        }
      ],
      "source": [
      "!docker exec -it alwaysup bash"
      ]
    },
{
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Now we are back inside ubuntu. If we run the command ``ps -aux`` we can see a list of the processes running inside ubuntu."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n",
"root           1  0.0  0.0   2820  1048 ?        Ss   13:04   0:00 tail -f /dev/null\n",
"root           7  0.0  0.0   4628  3796 pts/0    Ss   13:04   0:00 bash\n",
"root          15  0.0  0.0   7060  1556 pts/0    R+   13:05   0:00 ps -aux"
          ]
        }
      ],
      "source": [
      "!ps -aux"
      ]
    },
{
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We see only three processes, the ``ps -aux``, the ``bash`` and the ``tail -f /dev/null``.\n",
"\n",
"This container will always be on as long as the ``tail -f /dev/null`` process is running."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If we exit the container with the ``exit`` command and execute the ``docker ps`` command we see that the container is still on."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "exit"
          ]
        }
      ],
      "source": [
      "!exit"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND               CREATED         STATUS         PORTS     NAMES\n",
"ce4d60427dcd   ubuntu    \"tail -f /dev/null\"   2 minutes ago   Up 2 minutes             alwaysup\n"
          ]
        }
      ],
      "source": [
      "!docker ps"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "In order to end the process and shut down the container we must use the command ``docker stop <name>``."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "alwaysup\n"
          ]
        }
      ],
      "source": [
      "!docker stop alwaysup"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If we now list again the containers that are on, the container with Ubuntu is no longer displayed."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
          ]
        }
      ],
      "source": [
      "!docker ps"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "And if we list all the containers, the container with Ubuntu appears, and its status ``Exited``."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND               CREATED          STATUS                            PORTS     NAMES\n",
"ce4d60427dcd   ubuntu    \"tail -f /dev/null\"   14 minutes ago   Exited (137) About a minute ago             alwaysup\n",
"5b633e9d838f   ubuntu    \"bash\"                19 minutes ago   Exited (0) 15 minutes ago                   funny_mirzakhani\n",
"da16b3a85178   ubuntu    \"bash\"                20 minutes ago   Exited (0) 20 minutes ago                   hardcore_kare\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Single-use containers"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If at the time of executing a container, we set the `--rm` option, that container will be deleted when it finishes executing."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
      "!docker run --rm --name autoremove ubuntu:latest"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If we now see which containers we have"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We see that the container we have just created is not present."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Exposing containers to the outside world"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Let's create a new container with a server"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Unable to find image 'nginx:latest' locally\n",
"latest: Pulling from library/nginx\n",
"\n",
"\u001b[1Bf1ad4ce1: Pulling fs layer \n",
"\u001b[1Bb079d0f8: Pulling fs layer \n",
"\u001b[1B5fbbebc6: Pulling fs layer \n",
"\u001b[1Bffdd25f4: Pulling fs layer \n",
"\u001b[1B32c8fba2: Pulling fs layer \n",
"\u001b[1B24b8ba39: Pull complete 393kB/1.393kBB[5A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[3A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[2A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[4A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KDigest: sha256:2888a97f7c7d498bbcc47ede1ad0f6ced07d72dfd181071dde051863f1f79d7b\n",
"Status: Downloaded newer image for nginx:latest\n",
"1a530e04f14be082811b72ea8b6ea5a95dad3037301ee8a1351a0108ff8d3b30\n"
          ]
        }
      ],
      "source": [
      "!docker run -d --name proxy nginx"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "This creates a server, we will re-list the containers that are running"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND                  CREATED        STATUS                  PORTS     NAMES\n",
"1a530e04f14b   nginx     \"/docker-entrypoint.…\"   1 second ago   Up Less than a second   80/tcp    proxy\n"
          ]
        }
      ],
      "source": [
      "!docker ps"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Now a new column appears with the port, and tells us that the server we have just created is on port ``80`` under the ``tcp`` protocol.\n",
"\n",
"If we open a browser and try to connect to the server via ``http://localhost:80`` we will not be able to connect. This is because each container has its own network interface. That is, the server is listening on port ``80`` of the container, but we are trying to connect to port ``80`` of the host."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We stop the container in order to relaunch it in another way"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "proxy\n"
          ]
        }
      ],
      "source": [
      "!docker stop proxy"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If we list the containers, it does not appear running"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
          ]
        }
      ],
      "source": [
      "!docker ps"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We delete it to recreate it"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "proxy\n"
          ]
        }
      ],
      "source": [
      "!docker rm proxy"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If we list all the containers, it is no longer"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND               CREATED          STATUS                       PORTS     NAMES\n",
"ce4d60427dcd   ubuntu    \"tail -f /dev/null\"   19 minutes ago   Exited (137) 5 minutes ago             alwaysup\n",
"5b633e9d838f   ubuntu    \"bash\"                24 minutes ago   Exited (0) 20 minutes ago              funny_mirzakhani\n",
"da16b3a85178   ubuntu    \"bash\"                24 minutes ago   Exited (0) 24 minutes ago              hardcore_kare\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "To recreate the container with the server and be able to see it from the host, we have to use the ``-p`` (``publish``) option, indicating first the port on which we want to see it on the host and then the port of the container, i.e. ``-p <ip host>:<ip conteiner>``."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "c199235e42f76a30266f6e1af972e0a59811806eb3d3a9afdd873f6fa1785eae\n"
          ]
        }
      ],
      "source": [
      "!docker run -d --name proxy -p 8080:80 nginx"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We list the containers"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND                  CREATED          STATUS          PORTS                                   NAMES\n",
"c199235e42f7   nginx     \"/docker-entrypoint.…\"   22 seconds ago   Up 21 seconds   0.0.0.0:8080->80/tcp, :::8080->80/tcp   proxy\n"
          ]
        }
      ],
      "source": [
      "!docker ps"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We see that the container port is `0.0.0.0.0:8080->80/tcp`. If we now go to a browser and enter `0.0.0.0.0:8080` we will be able to access the container's server"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "When listing the containers, in the ``PORTS`` column it indicates ``0.0.0.0:8080->80/tcp``, which helps us to see the port relationship"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "To view the container logs, using the command ``docker logs <name>`` I can view the logs of the container"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration\n",
"/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/\n",
"/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh\n",
"10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf\n",
"10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf\n",
"/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh\n",
"/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh\n",
"/docker-entrypoint.sh: Configuration complete; ready for start up\n",
"2022/09/13 13:24:06 [notice] 1#1: using the \"epoll\" event method\n",
"2022/09/13 13:24:06 [notice] 1#1: nginx/1.23.1\n",
"2022/09/13 13:24:06 [notice] 1#1: built by gcc 10.2.1 20210110 (Debian 10.2.1-6) \n",
"2022/09/13 13:24:06 [notice] 1#1: OS: Linux 5.15.0-46-generic\n",
"2022/09/13 13:24:06 [notice] 1#1: getrlimit(RLIMIT_NOFILE): 1048576:1048576\n",
"2022/09/13 13:24:06 [notice] 1#1: start worker processes\n",
"2022/09/13 13:24:06 [notice] 1#1: start worker process 31\n",
"2022/09/13 13:24:06 [notice] 1#1: start worker process 32\n",
"2022/09/13 13:24:06 [notice] 1#1: start worker process 33\n",
"2022/09/13 13:24:06 [notice] 1#1: start worker process 34\n",
"2022/09/13 13:24:06 [notice] 1#1: start worker process 35\n",
"2022/09/13 13:24:06 [notice] 1#1: start worker process 36\n",
"2022/09/13 13:24:06 [notice] 1#1: start worker process 37\n",
"2022/09/13 13:24:06 [notice] 1#1: start worker process 38\n",
"2022/09/13 13:24:06 [notice] 1#1: start worker process 39\n",
"2022/09/13 13:24:06 [notice] 1#1: start worker process 40\n",
"2022/09/13 13:24:06 [notice] 1#1: start worker process 41\n",
"...\n",
"172.17.0.1 - - [13/Sep/2022:13:24:40 +0000] \"GET /favicon.ico HTTP/1.1\" 404 555 \"http://0.0.0.0:8080/\" \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\" \"-\"\n",
"172.17.0.1 - - [13/Sep/2022:13:25:00 +0000] \"\\x16\\x03\\x01\\x02\\x00\\x01\\x00\\x01\\xFC\\x03\\x03\\xE2\\x19V$Zqi'\\xD7\\xFC[\\x80\\xEF\\xBA\\xE5\\xC7\\xE8\\xF7&3nS\\xEB\\xC9\\xEC\\x91\\xC2\\xD8\\xD1\\x89\\x9E\\xBE \\xC7?\\xE1\\xFA\\x04a\\x1C\\xCE\\x90\\x0F\\x8F\\x98u\\xE3/\\xD8RfOH\\xEC\\x92+\\x93\\x5C\\xBB\\xB1\\xBF\\xD2m\\xB09\\x00 \\xFA\\xFA\\x13\\x01\\x13\\x02\\x13\\x03\\xC0+\\xC0/\\xC0,\\xC00\\xCC\\xA9\\xCC\\xA8\\xC0\\x13\\xC0\\x14\\x00\\x9C\\x00\\x9D\\x00/\\x005\\x01\\x00\\x01\\x93\\x9A\\x9A\\x00\\x00\\x00\\x00\\x00\\x0E\\x00\\x0C\\x00\\x00\\x09localhost\\x00\\x17\\x00\\x00\\xFF\\x01\\x00\\x01\\x00\\x00\" 400 157 \"-\" \"-\" \"-\"\n",
"172.17.0.1 - - [13/Sep/2022:13:25:00 +0000] \"\\x16\\x03\\x01\\x02\\x00\\x01\\x00\\x01\\xFC\\x03\\x03)\\x9A\\x8FbC\\xD9m\\xF1\\x86\\xEBd\\x22\\xCF\\xC4E\\x87#~L\\xC1\\x84\\x7F\\xB5\\x91k\\x98\\xABl\\xEE\\x1E[0 \\xD0\\xD2`\\x85\\xC6\\x8B\\x85R\\x8B\\x87\\xEAq{P\\xF2\\xFB\\xE2\\xA8\\x9DI\\xF4tH\\x99\\x13\\x10~\\xCA1-|\\x8E\\x00 \\xEA\\xEA\\x13\\x01\\x13\\x02\\x13\\x03\\xC0+\\xC0/\\xC0,\\xC00\\xCC\\xA9\\xCC\\xA8\\xC0\\x13\\xC0\\x14\\x00\\x9C\\x00\\x9D\\x00/\\x005\\x01\\x00\\x01\\x93\" 400 157 \"-\" \"-\" \"-\"\n",
"172.17.0.1 - - [13/Sep/2022:13:26:28 +0000] \"GET / HTTP/1.1\" 304 0 \"-\" \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\" \"-\"\n"
          ]
        }
      ],
      "source": [
      "!docker logs proxy"
      ]
    },
{
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Now I can see all the requests that have been made to the server. But if I want to see the logs in real time, using ``docker logs -f <name>`` I can do it."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": []
        }
      ],
      "source": [
      "!docker logs -f proxy"
      ]
    },
{
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Now I can see the logs in real time. To exit enter ``CTRL+C``."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "As there may come a time when there are many logs, if you only want the latest logs, by using the ``--tail <num>`` option I can see the latest ``<num>`` logs. If I add the ``-f`` option, we will always see the last ``<num>`` logs."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "2022/09/13 13:24:06 [notice] 1#1: start worker process 41\n",
"2022/09/13 13:24:06 [notice] 1#1: start worker process 42\n",
"172.17.0.1 - - [13/Sep/2022:13:24:16 +0000] \"\\x16\\x03\\x01\\x02\\x00\\x01\\x00\\x01\\xFC\\x03\\x03\\x01E\\x14\\x8E\\xB6\\x0BEg\\xF3\\xC9\\x9A\\x19\\x9C\\xCA\\xEC\\xA7y#3\\x92\\x05\\x95\\xDCQ\\x07\\x19\\x1D\\xEF\\xEA$\\xBF# \\x0B\\x83\\xF7-,s\\x1B!r\\xEA|\\xAE\\xDF\\xA1\\x9DLZ\\xAA4y\\xB3t\\xAB\\xC0\\xCE_\\xB8\\xE7\\xFF'\\xCF\\x86\\x00 \\xEA\\xEA\\x13\\x01\\x13\\x02\\x13\\x03\\xC0+\\xC0/\\xC0,\\xC00\\xCC\\xA9\\xCC\\xA8\\xC0\\x13\\xC0\\x14\\x00\\x9C\\x00\\x9D\\x00/\\x005\\x01\\x00\\x01\\x93\\x8A\\x8A\\x00\\x00\\x00\\x00\\x00\\x0E\\x00\\x0C\\x00\\x00\\x09localhost\\x00\\x17\\x00\\x00\\xFF\\x01\\x00\\x01\\x00\\x00\" 400 157 \"-\" \"-\" \"-\"\n",
"172.17.0.1 - - [13/Sep/2022:13:24:16 +0000] \"\\x16\\x03\\x01\\x02\\x00\\x01\\x00\\x01\\xFC\\x03\\x03}\\xA9Dr{\\x8C;\\x90z\\x82\\xAD\\xBC\\x8Az\\xC2x\\xDF\\x1E\\x9A\\xE6l?\\xA7\\xE0DoK\\x91'g\\xBB\\xB5 %\\xBB\\xFD\\xD9\\x82?\\xDB\\x80\\xB3T\\xF6cJ\\xF7\\xE5\\xC2\\xD2\\x11\\xBC\\xA2\\x1F\\x90\\x14\\xA3\\xEB\\xBD=R\\xBC\\x83\\x89\\x85\\x00 \\xCA\\xCA\\x13\\x01\\x13\\x02\\x13\\x03\\xC0+\\xC0/\\xC0,\\xC00\\xCC\\xA9\\xCC\\xA8\\xC0\\x13\\xC0\\x14\\x00\\x9C\\x00\\x9D\\x00/\\x005\\x01\\x00\\x01\\x93\\x9A\\x9A\\x00\\x00\\x00\\x00\\x00\\x0E\\x00\\x0C\\x00\\x00\\x09localhost\\x00\\x17\\x00\\x00\\xFF\\x01\\x00\\x01\\x00\\x00\" 400 157 \"-\" \"-\" \"-\"\n",
"172.17.0.1 - - [13/Sep/2022:13:24:39 +0000] \"GET / HTTP/1.1\" 200 615 \"-\" \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\" \"-\"\n",
"2022/09/13 13:24:40 [error] 34#34: *3 open() \"/usr/share/nginx/html/favicon.ico\" failed (2: No such file or directory), client: 172.17.0.1, server: localhost, request: \"GET /favicon.ico HTTP/1.1\", host: \"0.0.0.0:8080\", referrer: \"http://0.0.0.0:8080/\"\n",
"172.17.0.1 - - [13/Sep/2022:13:24:40 +0000] \"GET /favicon.ico HTTP/1.1\" 404 555 \"http://0.0.0.0:8080/\" \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\" \"-\"\n",
"172.17.0.1 - - [13/Sep/2022:13:25:00 +0000] \"\\x16\\x03\\x01\\x02\\x00\\x01\\x00\\x01\\xFC\\x03\\x03\\xE2\\x19V$Zqi'\\xD7\\xFC[\\x80\\xEF\\xBA\\xE5\\xC7\\xE8\\xF7&3nS\\xEB\\xC9\\xEC\\x91\\xC2\\xD8\\xD1\\x89\\x9E\\xBE \\xC7?\\xE1\\xFA\\x04a\\x1C\\xCE\\x90\\x0F\\x8F\\x98u\\xE3/\\xD8RfOH\\xEC\\x92+\\x93\\x5C\\xBB\\xB1\\xBF\\xD2m\\xB09\\x00 \\xFA\\xFA\\x13\\x01\\x13\\x02\\x13\\x03\\xC0+\\xC0/\\xC0,\\xC00\\xCC\\xA9\\xCC\\xA8\\xC0\\x13\\xC0\\x14\\x00\\x9C\\x00\\x9D\\x00/\\x005\\x01\\x00\\x01\\x93\\x9A\\x9A\\x00\\x00\\x00\\x00\\x00\\x0E\\x00\\x0C\\x00\\x00\\x09localhost\\x00\\x17\\x00\\x00\\xFF\\x01\\x00\\x01\\x00\\x00\" 400 157 \"-\" \"-\" \"-\"\n",
"172.17.0.1 - - [13/Sep/2022:13:25:00 +0000] \"\\x16\\x03\\x01\\x02\\x00\\x01\\x00\\x01\\xFC\\x03\\x03)\\x9A\\x8FbC\\xD9m\\xF1\\x86\\xEBd\\x22\\xCF\\xC4E\\x87#~L\\xC1\\x84\\x7F\\xB5\\x91k\\x98\\xABl\\xEE\\x1E[0 \\xD0\\xD2`\\x85\\xC6\\x8B\\x85R\\x8B\\x87\\xEAq{P\\xF2\\xFB\\xE2\\xA8\\x9DI\\xF4tH\\x99\\x13\\x10~\\xCA1-|\\x8E\\x00 \\xEA\\xEA\\x13\\x01\\x13\\x02\\x13\\x03\\xC0+\\xC0/\\xC0,\\xC00\\xCC\\xA9\\xCC\\xA8\\xC0\\x13\\xC0\\x14\\x00\\x9C\\x00\\x9D\\x00/\\x005\\x01\\x00\\x01\\x93\" 400 157 \"-\" \"-\" \"-\"\n",
"172.17.0.1 - - [13/Sep/2022:13:26:28 +0000] \"GET / HTTP/1.1\" 304 0 \"-\" \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\" \"-\"\n"
          ]
        }
      ],
      "source": [
      "!docker logs --tail 10 proxy"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If we also add the `-t` option we can see the date and time of each log, so if we have had a problem, we can know at what time it happened"
      ]
    },
{
      "cell_type": "code",
      "execution_count": "None",
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "2022-09-13T13:24:06.573362728Z 2022/09/13 13:24:06 [notice] 1#1: start worker process 41\n",
"2022-09-13T13:24:06.651127107Z 2022/09/13 13:24:06 [notice] 1#1: start worker process 42\n",
"2022-09-13T13:24:16.651160189Z 172.17.0.1 - - [13/Sep/2022:13:24:16 +0000] \"\\x16\\x03\\x01\\x02\\x00\\x01\\x00\\x01\\xFC\\x03\\x03\\x01E\\x14\\x8E\\xB6\\x0BEg\\xF3\\xC9\\x9A\\x19\\x9C\\xCA\\xEC\\xA7y#3\\x92\\x05\\x95\\xDCQ\\x07\\x19\\x1D\\xEF\\xEA$\\xBF# \\x0B\\x83\\xF7-,s\\x1B!r\\xEA|\\xAE\\xDF\\xA1\\x9DLZ\\xAA4y\\xB3t\\xAB\\xC0\\xCE_\\xB8\\xE7\\xFF'\\xCF\\x86\\x00 \\xEA\\xEA\\x13\\x01\\x13\\x02\\x13\\x03\\xC0+\\xC0/\\xC0,\\xC00\\xCC\\xA9\\xCC\\xA8\\xC0\\x13\\xC0\\x14\\x00\\x9C\\x00\\x9D\\x00/\\x005\\x01\\x00\\x01\\x93\\x8A\\x8A\\x00\\x00\\x00\\x00\\x00\\x0E\\x00\\x0C\\x00\\x00\\x09localhost\\x00\\x17\\x00\\x00\\xFF\\x01\\x00\\x01\\x00\\x00\" 400 157 \"-\" \"-\" \"-\"\n",
"2022-09-13T13:24:16.116817914Z 172.17.0.1 - - [13/Sep/2022:13:24:16 +0000] \"\\x16\\x03\\x01\\x02\\x00\\x01\\x00\\x01\\xFC\\x03\\x03}\\xA9Dr{\\x8C;\\x90z\\x82\\xAD\\xBC\\x8Az\\xC2x\\xDF\\x1E\\x9A\\xE6l?\\xA7\\xE0DoK\\x91'g\\xBB\\xB5 %\\xBB\\xFD\\xD9\\x82?\\xDB\\x80\\xB3T\\xF6cJ\\xF7\\xE5\\xC2\\xD2\\x11\\xBC\\xA2\\x1F\\x90\\x14\\xA3\\xEB\\xBD=R\\xBC\\x83\\x89\\x85\\x00 \\xCA\\xCA\\x13\\x01\\x13\\x02\\x13\\x03\\xC0+\\xC0/\\xC0,\\xC00\\xCC\\xA9\\xCC\\xA8\\xC0\\x13\\xC0\\x14\\x00\\x9C\\x00\\x9D\\x00/\\x005\\x01\\x00\\x01\\x93\\x9A\\x9A\\x00\\x00\\x00\\x00\\x00\\x0E\\x00\\x0C\\x00\\x00\\x09localhost\\x00\\x17\\x00\\x00\\xFF\\x01\\x00\\x01\\x00\\x00\" 400 157 \"-\" \"-\" \"-\"\n",
"2022-09-13T13:24:39.117398081Z 172.17.0.1 - - [13/Sep/2022:13:24:39 +0000] \"GET / HTTP/1.1\" 200 615 \"-\" \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\" \"-\"\n",
"2022-09-13T13:24:39.117412408Z 2022/09/13 13:24:40 [error] 34#34: *3 open() \"/usr/share/nginx/html/favicon.ico\" failed (2: No such file or directory), client: 172.17.0.1, server: localhost, request: \"GET /favicon.ico HTTP/1.1\", host: \"0.0.0.0:8080\", referrer: \"http://0.0.0.0:8080/\"\n",
"2022-09-13T13:24:40.117419389Z 172.17.0.1 - - [13/Sep/2022:13:24:40 +0000] \"GET /favicon.ico HTTP/1.1\" 404 555 \"http://0.0.0.0:8080/\" \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\" \"-\"\n",
"2022-09-13T13:25:00.117434249Z 172.17.0.1 - - [13/Sep/2022:13:25:00 +0000] \"\\x16\\x03\\x01\\x02\\x00\\x01\\x00\\x01\\xFC\\x03\\x03\\xE2\\x19V$Zqi'\\xD7\\xFC[\\x80\\xEF\\xBA\\xE5\\xC7\\xE8\\xF7&3nS\\xEB\\xC9\\xEC\\x91\\xC2\\xD8\\xD1\\x89\\x9E\\xBE \\xC7?\\xE1\\xFA\\x04a\\x1C\\xCE\\x90\\x0F\\x8F\\x98u\\xE3/\\xD8RfOH\\xEC\\x92+\\x93\\x5C\\xBB\\xB1\\xBF\\xD2m\\xB09\\x00 \\xFA\\xFA\\x13\\x01\\x13\\x02\\x13\\x03\\xC0+\\xC0/\\xC0,\\xC00\\xCC\\xA9\\xCC\\xA8\\xC0\\x13\\xC0\\x14\\x00\\x9C\\x00\\x9D\\x00/\\x005\\x01\\x00\\x01\\x93\\x9A\\x9A\\x00\\x00\\x00\\x00\\x00\\x0E\\x00\\x0C\\x00\\x00\\x09localhost\\x00\\x17\\x00\\x00\\xFF\\x01\\x00\\x01\\x00\\x00\" 400 157 \"-\" \"-\" \"-\"\n",
"2022-09-13T13:25:00.223560881Z 172.17.0.1 - - [13/Sep/2022:13:25:00 +0000] \"\\x16\\x03\\x01\\x02\\x00\\x01\\x00\\x01\\xFC\\x03\\x03)\\x9A\\x8FbC\\xD9m\\xF1\\x86\\xEBd\\x22\\xCF\\xC4E\\x87#~L\\xC1\\x84\\x7F\\xB5\\x91k\\x98\\xABl\\xEE\\x1E[0 \\xD0\\xD2`\\x85\\xC6\\x8B\\x85R\\x8B\\x87\\xEAq{P\\xF2\\xFB\\xE2\\xA8\\x9DI\\xF4tH\\x99\\x13\\x10~\\xCA1-|\\x8E\\x00 \\xEA\\xEA\\x13\\x01\\x13\\x02\\x13\\x03\\xC0+\\xC0/\\xC0,\\xC00\\xCC\\xA9\\xCC\\xA8\\xC0\\x13\\xC0\\x14\\x00\\x9C\\x00\\x9D\\x00/\\x005\\x01\\x00\\x01\\x93\" 400 157 \"-\" \"-\" \"-\"\n",
"2022-09-13T13:26:25.223596738Z 172.17.0.1 - - [13/Sep/2022:13:26:28 +0000] \"GET / HTTP/1.1\" 304 0 \"-\" \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\" \"-\"\n"
          ]
        }
      ],
      "source": [
      "!docker logs --tail -t 10 proxy"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We stop and delete the container"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "proxy\n"
          ]
        }
      ],
      "source": [
      "!docker rm -f proxy"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND               CREATED          STATUS                        PORTS     NAMES\n",
"ce4d60427dcd   ubuntu    \"tail -f /dev/null\"   26 minutes ago   Exited (137) 13 minutes ago             alwaysup\n",
"5b633e9d838f   ubuntu    \"bash\"                31 minutes ago   Exited (0) 27 minutes ago               funny_mirzakhani\n",
"da16b3a85178   ubuntu    \"bash\"                32 minutes ago   Exited (0) 32 minutes ago               hardcore_kare\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "## Data in Docker"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Bind mounts"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Let's take a look at the containers we have standing"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND               CREATED          STATUS                        PORTS     NAMES\n",
"ce4d60427dcd   ubuntu    \"tail -f /dev/null\"   26 minutes ago   Exited (137) 13 minutes ago             alwaysup\n",
"5b633e9d838f   ubuntu    \"bash\"                31 minutes ago   Exited (0) 28 minutes ago               funny_mirzakhani\n",
"da16b3a85178   ubuntu    \"bash\"                32 minutes ago   Exited (0) 32 minutes ago               hardcore_kare\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Let's delete the two ubuntu ones in which your main command is the bash and let's leave the one we left a non-operation"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "funny_mirzakhani\n"
          ]
        }
      ],
      "source": [
      "!docker rm funny_mirzakhani"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "hardcore_kare\n"
          ]
        }
      ],
      "source": [
      "!docker rm hardcore_kare"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND               CREATED          STATUS                        PORTS     NAMES\n",
"ce4d60427dcd   ubuntu    \"tail -f /dev/null\"   27 minutes ago   Exited (137) 14 minutes ago             alwaysup\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We are going to restart the ubuntu container we have left, this is done by using the `start` command"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "alwaysup\n"
          ]
        }
      ],
      "source": [
      "!docker start alwaysup"
      ]
    },
{
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We get back into it"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "root@ce4d60427dcd:/#\n"
          ]
        }
      ],
      "source": [
      "!docker exec -it alwaysup bash"
      ]
    },
{
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "In the container, I can create a new folder called ``dockerfolder``."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": []
        }
      ],
      "source": [
      "!mkdir dockerfolder"
      ]
    },
{
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If we list the files the new folder will appear"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "bin  boot  dev  dockerfolder  etc  home  lib  lib32  lib64  libx32  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var"
          ]
        }
      ],
      "source": [
      "!ls"
      ]
    },
{
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If we get out of the container"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "exit"
          ]
        }
      ],
      "source": [
      "!exit"
      ]
    },
{
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "And we delete it"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "alwaysup\n"
          ]
        }
      ],
      "source": [
      "!docker rm -f alwaysup"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If we list all the containers, the last one we created is no longer displayed."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Let's redo everything, but first let's create a folder on the host where we will share the data with the container"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
      "!mkdir dockerHostFolder"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We can see that there is nothing inside the folder"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
      "!ls dockerHostFolder"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Now we obtain our absolute route"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "/home/wallabot/Documentos/web/portafolio/posts\n"
          ]
        }
      ],
      "source": [
      "!pwd"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We recreate the container but add the ``-v`` (``bind mount``) option. Then add the absolute path of the host folder and the absolute path of the folder in the container, ``-v <host path>:<container path>``."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "4ede4512c293bdcc155e9c8e874dfb4a28e5163f4d5c7ddda24ad2863f28921b\n"
          ]
        }
      ],
      "source": [
      "!docker run -d --name alwaysup -v ~/Documentos/web/portafolio/posts/dockerHostFolder:/dockerContainerFolder ubuntu tail -f /dev/null"
      ]
    },
{
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We enter the container, list the files and the folder we created is displayed"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "root@4ede4512c293:/#"
          ]
        }
      ],
      "source": [
      "!docker exec -it alwaysup bash"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "bin   dev                    etc   lib    lib64   media  opt   root  sbin  sys  usr\n",
"boot  dockerContainerFolder  home  lib32  libx32  mnt    proc  run   srv   tmp  var\n"
          ]
        }
      ],
      "source": [
      "root@4ede4512c293:/# ls"
      ]
    },
{
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We go to the directory of the container we have shared, create a file and leave the container"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": []
        }
      ],
      "source": [
      "root@4ede4512c293:/# cd dockerContainerFolder"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": []
        }
      ],
      "source": [
      "root@4ede4512c293:/dockerContainerFolder# touch bindFile.txt"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "exit"
          ]
        }
      ],
      "source": [
      "root@4ede4512c293:/dockerContainerFolder# exit"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Let's see what's inside the shared folder"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "bindFile.txt\n"
          ]
        }
      ],
      "source": [
      "!ls dockerHostFolder"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Moreover, if we delete the container, the file is still there."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "alwaysup\n"
          ]
        }
      ],
      "source": [
      "!docker rm -f alwaysup"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "bindFile.txt\n"
          ]
        }
      ],
      "source": [
      "!ls dockerHostFolder"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If I recreate a container by sharing the folders, all the files will be in the container."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "6c021d37ea29d8b23fe5cd4968baa446085ae1756682f65340288b4c851c362d\n"
          ]
        }
      ],
      "source": [
      "!docker run -d --name alwaysup -v ~/Documentos/web/portafolio/posts/dockerHostFolder:/dockerContainerFolder ubuntu tail -f /dev/null"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "root@6c021d37ea29:/#"
          ]
        }
      ],
      "source": [
      "!docker exec -it alwaysup bash"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "bindFile.txt:/#"
          ]
        }
      ],
      "source": [
      "!root@6c021d37ea29:/# ls dockerContainerFolder/"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We remove the container"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "alwaysup\n"
          ]
        }
      ],
      "source": [
      "!docker rm -f alwaysup"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Volumes"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Volumes were created as an evolution of ``bind mounts`` to provide more security. We can list all docker volumes using ``docker volume ls``."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "DRIVER    VOLUME NAME\n"
          ]
        }
      ],
      "source": [
      "!docker volume ls"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Let's create a new volume for the ubuntu container, for this we use the command ``docker volume create <volume name>``."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "ubuntuVolume\n"
          ]
        }
      ],
      "source": [
      "!docker volume create ubuntuVolume"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If we list the volumes again, the one we have just created will appear."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "DRIVER    VOLUME NAME\n",
"local     ubuntuVolume\n"
          ]
        }
      ],
      "source": [
      "!docker volume ls"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "However it does not appear as a folder in the host file system. With `ls -d */` we list all folders"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "dockerHostFolder/  __pycache__/\n"
          ]
        }
      ],
      "source": [
      "!ls -d */"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Let's create a container again, but now we create it with the volume we just created with the ``--mount`` option, indicating the source volume by ``src=<volume name>`` (if the volume did not exist, docker would create it), then the destination separated by a ``,``, ``dst=<container path>``, i.e. ``--mount src=<volume name>,dst=<container path>``."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "42cdcddf4e46dc298a87b0570115e0b2fc900cb4c6db5eea22a61409b8cb271d\n"
          ]
        }
      ],
      "source": [
      "!docker run -d --name alwaysup --mount src=ubuntuVolume,dst=/dockerVolumeFolder ubuntu tail -f /dev/null"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Once created we can view the container volumes by using the ``inspect`` command and filtering by `'{{.Mounts}}'`.\n",
"\n",
"````bash\n",
"$ docker inspect --format '{{.Mounts}}' alwaysup\n",
"[\n",
"    {\n",
"        volume ubuntuVolume /var/lib/docker/volumes/ubuntuVolume/_data /dockerVolumeFolder local z true\n",
"    }\n",
"\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We see that the volume is called `ubuntuVolume` and we can also see the path where it is stored, in this case in `/var/lib/docker/volumes/ubuntuVolume/_data`. We do the same as before, we get into the container, create a file in the path of the volume, exit and see on the host if it has been created.\n",
"\n",
"````bash\n",
"$ docker exec -it alwaysup bash\n",
"root@42cdcdcddf4e46:/# touch dockerVolumeFolder/volumeFile.txt\n",
"root@42cdcdcddf4e46:/# exit\n",
"```\n",
"\n",
"\n",
"````bash\n",
"$ sudo ls /var/lib/docker/volumes/ubuntuVolume/_data\n",
"volumeFile.txt\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "The file is created"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Inserting and extracting files from a container"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "First let's create a file that we want to copy inside a container"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
      "!touch dockerHostFolder/text.txt"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We enter the container\n",
"\n",
"````bash\n",
"$ docker exec -it alwaysup bash\n",
"root@42cdcdcddf4e46:/#\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We create a new folder where we are going to copy the file and we exit\n",
"\n",
"````bash\n",
"root@42cdcdcddf4e46:/# mkdir folderToCopy\n",
"root@42cdcdcddf4e46:/# ls\n",
"bin boot dev dockerVolumeFolder etc folderToCopy home lib lib32 lib64 libx32 libx32 media mnt opt proc root run sbin srv sys tmp usr var\n",
"root@42cdcdcddf4e46:/# exit\n",
"exit\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We copy inside the container the file using the ``cp`` command, indicating the file we want to copy, the container where we want to copy it and the path inside the container, ``docker cp <file> <container>:<container path>```."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
      "!docker cp dockerHostFolder/text.txt alwaysup:/folderToCopy"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We re-enter the container and check that the file is present.\n",
"\n",
"````bash\n",
"$ docker exec -it alwaysup bash\n",
"root@42cdcdcddf4e46:/# ls folderToCopy/\n",
"text.txt\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We are coming out of the container\n",
"\n",
"````bash\n",
"/# exit\n",
"exit\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Now we are going to extract the file from the container and save it on the host with another name, for this we use the command ``cp`` again, but indicating now the container, the path of the file in the container and the path and name of the one we want the file to have on the host, ``docker cp <container>:<docker file path> <host file path>```."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
      "!docker cp alwaysup:/folderToCopy/text.txt dockerHostFolder/fileExtract.txt"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We see that you are on the host"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "bindFile.txt  fileExtract.txt  text.txt\n"
          ]
        }
      ],
      "source": [
      "!ls dockerHostFolder"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Even if the container is stopped, files can also be copied."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Finally we delete the container"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "alwaysup\n"
          ]
        }
      ],
      "source": [
      "!docker rm -f alwaysup"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "## Images"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Fundamental concepts"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "The images are the files (\"templates\") with all the configuration to create a container. Every time we create a container it is created from an image. When we created new containers, the first time we got a message saying that we didn't have the image and that we were going to download it. In docker hub there are many images with all kinds of machines, but for a very specific development environment we can create our own template to pass it to someone and work in a container with the same configuration as ours."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We can see all the images that we have saved in our computer using the command ``docker image ls``."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "REPOSITORY    TAG       IMAGE ID       CREATED         SIZE\n",
"nginx         latest    2d389e545974   8 hours ago     142MB\n",
"ubuntu        latest    2dc39ba059dc   11 days ago     77.8MB\n",
"hello-world   latest    feb5d9fea6a5   11 months ago   13.3kB\n"
          ]
        }
      ],
      "source": [
      "!docker image ls"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We can see the sizes, and we can see how the `nginx` one occupies a lot and that is why it took longer to download than the rest."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Another column that we can see is the ``TAG``, this indicates the version of the image. In all of them it says ``latest``, this means that it is the last one. That is to say, at the moment of downloading it we have downloaded the last version that there is in docker hub. This in a development environment is not optimal, because we can download an image of ubuntu, and if we do not specify the latest version is downloaded, for example 20.04. But after a while someone may want to develop with you and download that image, but not specifying the version will download again the latest, which in your case may be the 22.04. This can lead to problems and things that one person works and the other does not."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "You can see all the images in docker hub by going to ``https://hub.docker.com/``. There you can search for the image that best suits the project you want to do. If we navigate to the Ubuntu image, for example, we can see the versions (``tags``) of the images."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We are going to download, **but not execute** an image. To do this we use the command ``docker pull <hub> <image name>:<tag>``. If we do not specify the hub, it will download it from docker hub by default, but we can specify another one, for example a private one from our organization. Also, if we do not specify the tag, it will download the latest version by default."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "20.04: Pulling from library/ubuntu\n",
"\n",
"\u001b[1BDigest: sha256:35ab2bf57814e9ff49e365efd5a5935b6915eede5c7f8581e9e1b85e0eecbe16[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\n",
"Status: Downloaded newer image for ubuntu:20.04\n",
"docker.io/library/ubuntu:20.04\n"
          ]
        }
      ],
      "source": [
      "!docker pull ubuntu:20.04"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If we list the images again, we see that we now have two ubuntu images, one with the ``20.04`` tag and one with the ``latest`` tag."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "REPOSITORY    TAG       IMAGE ID       CREATED         SIZE\n",
"nginx         latest    2d389e545974   8 hours ago     142MB\n",
"ubuntu        latest    2dc39ba059dc   11 days ago     77.8MB\n",
"ubuntu        20.04     a0ce5a295b63   11 days ago     72.8MB\n",
"hello-world   latest    feb5d9fea6a5   11 months ago   13.3kB\n"
          ]
        }
      ],
      "source": [
      "!docker image ls"
      ]
    },
{
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Create images using `Dockerfile`."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We create a directory on the host called ``dockerImages`` to work in the ``dockerImages`` directory."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
      "!mkdir dockerImages"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We create a ``Dockerfile`` file with which we will create an image"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
      "!touch dockerImages/Dockerfile"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Open the created file with your favorite editor and type the following:\n",
"\n",
"````Dockerfile\n",
"FROM ubuntu:latest\n",
"```\n",
"\n",
"This tells docker to create the image from the `latest` ubuntu image."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Next we write a command to be executed at compile time\n",
"\n",
"```DOckerfile\n",
"RUN touch /test.txt\n",
"```\n",
"\n",
"This means that when the `Dockefile` is compiled, this command will be executed, but not when the image container is run."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "At the end the `Dockerfile` looks like this:\n",
"```dockerfile\n",
"    FROM ubuntu:latest\n",
"    RUN touch /test.txt\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We compile the `Dockerfile` using the `build` command, with the `-t` option we can give it a `tag`. Finally we must indicate the path of the `build` context, we will explain this later."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Sending build context to Docker daemon  2.048kB\n",
"Step 1/2 : FROM ubuntu:latest\n",
" ---> 2dc39ba059dc\n",
"Step 2/2 : RUN touch /test.txt\n",
" ---> Using cache\n",
" ---> a78cf3ea16d8\n",
"Successfully built a78cf3ea16d8\n",
"Successfully tagged ubuntu:test\n",
"\n",
"Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\n"
          ]
        }
      ],
      "source": [
      "!docker build -t ubuntu:test ./dockerImages"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "As we can see it is compiled in 2 steps, each one has an `id`, each one of those `id`s are layers of the image, we will also see this later on.\n",
"\n",
"We go back to the images we have saved in our computer and the one we have just created appears."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "REPOSITORY    TAG       IMAGE ID       CREATED         SIZE\n",
"ubuntu        test      a78cf3ea16d8   8 minutes ago   77.8MB\n",
"nginx         latest    2d389e545974   8 hours ago     142MB\n",
"ubuntu        latest    2dc39ba059dc   11 days ago     77.8MB\n",
"ubuntu        20.04     a0ce5a295b63   11 days ago     72.8MB\n",
"hello-world   latest    feb5d9fea6a5   11 months ago   13.3kB\n"
          ]
        }
      ],
      "source": [
      "!docker image ls"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We run the container from the image that we have just created\n",
"\n",
"````bash\n",
"$ docker run -it ubuntu:test\n",
"root@b57b9d4eedeb:/#\n",
"```\n",
"\n",
"We enter the bash of the container. As we said, the RUN command was executed at compile time of the image, so the file we have asked to be created should be in our container\n",
"\n",
"````bash\n",
"root@b57b9d4eedeb:/# ls\n",
"bin boot dev etc home lib lib32 lib32 lib64 lib64 libx32 media mnt opt proc root run sbin srv sys test.txt test.txt usr var\n",
"```\n",
"\n",
"It is important to understand that this file was created when the image was built, i.e. the container image already has this file. It is not created when the container is launched\n",
"\n",
"We are coming out of the container\n",
"\n",
"````bash\n",
"root@b57b9d4eedeb:/# exit\n",
"exit\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "As we already have an image we could upload it to the docker hub, but let's re-list the images before that"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "REPOSITORY    TAG       IMAGE ID       CREATED          SIZE\n",
"ubuntu        test      a78cf3ea16d8   20 minutes ago   77.8MB\n",
"nginx         latest    2d389e545974   8 hours ago      142MB\n",
"ubuntu        latest    2dc39ba059dc   11 days ago      77.8MB\n",
"ubuntu        20.04     a0ce5a295b63   11 days ago      72.8MB\n",
"hello-world   latest    feb5d9fea6a5   11 months ago    13.3kB\n"
          ]
        }
      ],
      "source": [
      "!docker image ls"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If we see it is telling us that the image we just created belongs to the ubuntu repository, but we do not have access to the ubuntu repository, so in docker hub we have to make an account to upload the image to our repository. In my case, my repository is called `maximofn`, so I change the repository of the image using the `tag` command, indicating the image we want to change the repository and the new repository. In the new repository we usually indicate the name of the repository followed by the type of image and the tag, in my case `maximofn/ubuntu:test`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
      "!docker tag ubuntu:test maximofn/ubuntu:test"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If we now list the images again"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "REPOSITORY        TAG       IMAGE ID       CREATED          SIZE\n",
"ubuntu            test      a78cf3ea16d8   24 minutes ago   77.8MB\n",
"maximofn/ubuntu   test      a78cf3ea16d8   24 minutes ago   77.8MB\n",
"nginx             latest    2d389e545974   8 hours ago      142MB\n",
"ubuntu            latest    2dc39ba059dc   11 days ago      77.8MB\n",
"ubuntu            20.04     a0ce5a295b63   11 days ago      72.8MB\n",
"hello-world       latest    feb5d9fea6a5   11 months ago    13.3kB\n"
          ]
        }
      ],
      "source": [
      "!docker image ls"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Now we must log into the docker hub to upload the image, for this we use the command `login`.\n",
"\n",
"````bash\n",
"$ docker login\n",
"Login with your Docker ID to push and pull images from Docker Hub. If you do not have a Docker ID, head over to https://hub.docker.com to create one.\n",
"Username: maximofn\n",
"Password:\n",
"\n",
"Login Succeeded\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Now we can upload the image using the `push` command"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "The push refers to repository [docker.io/maximofn/ubuntu]\n",
"\n",
"\u001b[1B06994357: Preparing \n",
"\u001b[2B06994357: Pushed  from library/ubuntu \u001b[2A\u001b[2Ktest: digest: sha256:318d83fc3c35ff930d695b0dc1c5ad1b0ea54e1ec6e3478b8ca85c05fd793c4e size: 735\n"
          ]
        }
      ],
      "source": [
      "!docker push maximofn/ubuntu:test"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "You have uploaded only the first layer, the second one, as I used it after the ubuntu image, what it does is to place a pointer to that image to avoid having more than one layer uploaded at the same time."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Keep in mind that this repository is public, so you should not upload images with sensitive data. Also, if an image is not used within 6 months it will be deleted."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### The layer system"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Using the `history` command we can see the layers of an image. If we want to see the layers of the image we just created we use `docker history ubuntu:test`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "IMAGE          CREATED        CREATED BY                                      SIZE      COMMENT\n",
"a78cf3ea16d8   3 minutes ago  /bin/sh -c touch /test.txt                      0B        \n",
"2dc39ba059dc   12 days ago    /bin/sh -c #(nop)  CMD [\"bash\"]                 0B        \n",
"<missing>      12 days ago    /bin/sh -c #(nop) ADD file:a7268f82a86219801…   77.8MB    \n"
          ]
        }
      ],
      "source": [
      "!docker history ubuntu:test"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We see that the first layer has the command we entered in the `Dockerfile`, and it says that it was created 3 minutes ago. However, the rest of the layers were created 12 days ago, and they are the layers of the ubuntu image that we have been based on."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "To the `Dockerfile` we created earlier, we add the line\n",
"\n",
"```docker\n",
"RUN rm /test.txt\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "At the end the `Dockerfile` looks like this:\n",
"```dockerfile\n",
"    FROM ubuntu:latest\n",
"    RUN touch /test.txt\n",
"    RUN rm /test.txt\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If we compile again, we see what happens"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Sending build context to Docker daemon  2.048kB\n",
"Step 1/3 : FROM ubuntu:latest\n",
" ---> 2dc39ba059dc\n",
"Step 2/3 : RUN touch /test.txt\n",
" ---> Using cache\n",
" ---> a78cf3ea16d8\n",
"Step 3/3 : RUN rm /test.txt\n",
" ---> Running in c2e6887f2025\n",
"Removing intermediate container c2e6887f2025\n",
" ---> 313243a9b573\n",
"Successfully built 313243a9b573\n",
"Successfully tagged ubuntu:test\n",
"\n",
"Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\n"
          ]
        }
      ],
      "source": [
      "!docker build -t ubuntu:test ./dockerImages"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "As we can see there is one more layer with the new line we have added. If we look at the image layers with `history` again"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "IMAGE          CREATED              CREATED BY                                      SIZE      COMMENT\n",
"313243a9b573   About a minute ago   /bin/sh -c rm /test.txt                         0B        \n",
"a78cf3ea16d8   3 minutes ago        /bin/sh -c touch /test.txt                      0B        \n",
"2dc39ba059dc   12 days ago          /bin/sh -c #(nop)  CMD [\"bash\"]                 0B        \n",
"<missing>      12 days ago          /bin/sh -c #(nop) ADD file:a7268f82a86219801…   77.8MB    \n"
          ]
        }
      ],
      "source": [
      "!docker history ubuntu:test"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We can see that the first layers are the same as before and you have added a new layer with the new command"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "## Using docker to create applications"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Port exposure"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Earlier we saw how we could bind a container port to a computer port (`-p 8080:80`). But for that to be possible, at the time of creating the image we must expose the port, this is done by adding to the Dockerfile the line `EXPOSE <port>`, in the case of before\n",
"\n",
"```docker\n",
"EXPOSE 80\n",
"```\n",
"\n",
"Or use images as a base that already have exposed ports."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Reuse of layer cache when compiling"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "When we compile an image, if any of the layers we have defined have already been compiled before, docker detects it and uses them, it does not recompile them. If we recompile the image we have defined in the `Dockerfile` now it will take very little time, because all the layers are already compiled and docker does not recompile them."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Sending build context to Docker daemon  2.048kB\n",
"Step 1/3 : FROM ubuntu:latest\n",
" ---> 2dc39ba059dc\n",
"Step 2/3 : RUN touch /test.txt\n",
" ---> Using cache\n",
" ---> a78cf3ea16d8\n",
"Step 3/3 : RUN rm /test.txt\n",
" ---> Using cache\n",
" ---> 313243a9b573\n",
"Successfully built 313243a9b573\n",
"Successfully tagged ubuntu:test\n",
"\n",
"Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\n"
          ]
        }
      ],
      "source": [
      "!docker build -t ubuntu:test ./dockerImages"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "The text `Using cache` appears on the second and third layers.\n",
"\n",
"As this is a Jupyter notebook when executing the cells it gives you the information of the time it takes to execute, the previous time I compiled the image took 1.4 seconds, while now it has taken 0.5 seconds."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "But if now I change the Dockerfile, and in the first line, where it said that we were based on the latest version of ubuntu and we change to version 20.04\n",
"\n",
"```docker\n",
"FROM ubuntu:20.04\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "At the end the `Dockerfile` looks like this:\n",
"```dockerfile\n",
"    FROM ubuntu:20.04\n",
"    RUN touch /test.txt\n",
"    RUN rm /test.txt\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If we recompile it will take much longer"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Sending build context to Docker daemon  2.048kB\n",
"Step 1/3 : FROM ubuntu:20.04\n",
" ---> a0ce5a295b63\n",
"Step 2/3 : RUN touch /test.txt\n",
" ---> Running in a40fe8df2c0d\n",
"Removing intermediate container a40fe8df2c0d\n",
" ---> 0bb9b452c11f\n",
"Step 3/3 : RUN rm /test.txt\n",
" ---> Running in 2e14919f3685\n",
"Removing intermediate container 2e14919f3685\n",
" ---> fdc248fa833b\n",
"Successfully built fdc248fa833b\n",
"Successfully tagged ubuntu:test\n",
"\n",
"Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\n"
          ]
        }
      ],
      "source": [
      "!docker build -t ubuntu:test ./dockerImages"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "It took 1.9 seconds and the text `Using cache` is no longer displayed."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "When changing the first layer, docker recompiles all layers. This can be a problem because the following case can occur when developing code.\n",
" * We develop the code on our computer\n",
" * When building the image we copy all the code from our computer to the container.\n",
" * We then ask the image to install the necessary libraries.\n",
"\n",
"This may cause that when changing any part of the code, when having to recompile the image, the layer where the libraries are installed will have to be recompiled, because a previous layer has changed"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "To solve this, the idea would be that when creating the image, we first ask for the libraries to be installed and then copy the code from our computer to the container. This way every time we change the code and compile the image again, only the layer where the code is copied will be recompiled, so the compilation will be faster."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "You may think that it is better to share a folder between the host and the container (`bind mount`) where we will have the code and so we do not need to recompile the image every time we change the code. And the answer is that it is true, I have only put this example because it is very easy to understand, but it is to show that at the time of creating images it is necessary to think well so that if it is necessary to compile it again, it recompiles the minimum number of layers."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Correctly writing a Dockerfile"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "As we have seen Docker does not recompile layers of a Dockerfile if it has already compiled them before, so it loads them from cache. Let's see how the correct way to write a Dockerfile has to be to take advantage of this"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Let's start from this Dockerfile to discuss possible corrections\n",
"\n",
"``` Dockerfile\n",
"FROM ubuntu\n",
"COPY ./sourceCode /sourceCode\n",
"RUN apt-get update\n",
"RUN apt-get install -y python3 ssh\n",
"CMD [\"python3\", \"/sourceCode/sourceApp/app.py\"]\n",
"```\n",
"\n",
"As you can see, we start with an ubuntu image, copy the folder with the code, update the repositories, install python, install ssh and run the application."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "#### Copy the code before execution"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "As we said before, if we first copy the code and then install python, every time we make a change in the code and compile the image it will compile the whole image, but if we copy the code after installing python, every time we change the code and compile the image, it will only compile from the copy of the code and will not reinstall python, so the Dockerfile should look like this\n",
"\n",
"``` Dockerfile\n",
"FROM ubuntu\n",
"RUN apt-get update\n",
"RUN apt-get install -y python3 ssh\n",
"COPY ./sourceCode /sourceCode\n",
"CMD [\"python3\", \"/sourceCode/sourceApp/app.py\"]\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "#### Copy only the necessary code"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We are copying the folder with all the code, but maybe we have code inside that we don't need, so we must copy only the code that we really need for the application, this way the image will occupy less memory. So the Dockerfile would look like this\n",
"\n",
"``` Dockerfile\n",
"FROM ubuntu\n",
"RUN apt-get update\n",
"RUN apt-get install -y python3 ssh\n",
"COPY ./sourceCode/sourceApp /sourceCode/sourceApp\n",
"CMD [\"python3\", \"/sourceCode/sourceApp/app.py\"]\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "#### Update repositories and install python on the same line"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We are updating the repositories in one line and in another installing python3. But it can happen that in the line in which we install python3 we also add pip3, however, as the previous line, in which the repositories are updated, as it does not change, it will not be compiled again, as it is cached. So it can happen that in the repositories that we had updated there are not the necessary ones for pip3. For what it is necessary to put the two actions in one single line\n",
"\n",
"``` Dockerfile\n",
"FROM ubuntu\n",
"RUN apt-get update && apt-get install -y python3 ssh\n",
"COPY ./sourceCode/sourceApp /sourceCode/sourceApp\n",
"CMD [\"python3\", \"/sourceCode/sourceApp/app.py\"]\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "#### Do not install ssh"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We had installed ssh in the image so that we could debug if we needed to, but that makes the image take up more memory. In case we need to debug, we should go into the container, install ssh and then debug. So we remove the ssh installation.\n",
"\n",
"``` Dockerfile\n",
"FROM ubuntu\n",
"RUN apt-get update && apt-get install -yython3\n",
"COPY ./sourceCode/sourceApp /sourceCode/sourceApp\n",
"CMD [\"python3\", \"/sourceCode/sourceApp/app.py\"]\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "#### Use `--no-install-recommends`."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "When we install something in Ubuntu it installs recommended packages, but we don't need them, so the image takes more space. So to avoid this we add to the installation `--no-install-recommends`.\n",
"\n",
"``` Dockerfile\n",
"FROM ubuntu\n",
"RUN apt-get update && apt-get install -yython3 --no-install-recommends\n",
"COPY ./sourceCode/sourceApp /sourceCode/sourceApp\n",
"CMD [\"python3\", \"/sourceCode/sourceApp/app.py\"]\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "#### Clear list of updated repositories"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We have updated the repository list and installed python, but once we have done that we no longer need the updated repository list, because all they will do is make the image take up more space, so we remove them after installing python and on its own line\n",
"\n",
"``` Dockerfile\n",
"FROM ubuntu\n",
"RUN apt-get update && apt-get install -y python3 --no-install-recommends && rm -rf /var/lib/apt/lists/*\n",
"COPY ./sourceCode/sourceApp /sourceCode/sourceApp\n",
"CMD [\"python3\", \"/sourceCode/sourceApp/app.py\"]\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "#### Using a Python image"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Everything we have done of updating the package list and installing python is not necessary, as there are already python images on Ubuntu, which have probably also followed good practices, which have even done better than us and which has been scanned for vulnerabilities by Docker Hub. So we remove all that and we start from a Python image.\n",
"\n",
"``` Dockerfile\n",
"FROM python\n",
"COPY ./sourceCode/sourceApp /sourceCode/sourceApp\n",
"CMD [\"python3\", \"/sourceCode/sourceApp/app.py\"]\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "#### Specifying the Python image"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "By not specifying the python image you are downloading the latest, but depending on when you build the container you can download one or another, so you have to add the tag with the version of Python you want to download\n",
"\n",
"``` Dockerfile\n",
"FROM python:3.9.18\n",
"COPY ./sourceCode/sourceApp /sourceCode/sourceApp\n",
"CMD [\"python3\", \"/sourceCode/sourceApp/app.py\"]\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "#### Choose a small tag"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We have chosen the `3.9.18` tag, but that version of python has a lot of libraries that we may not need, so we can use the `3.9.18-slim` version which has much less libraries installed, or the `3.9.18-alphine` version which is a version of python on alpine and not on Ubuntu. Alpine is a very light Linux distribution that has very few packages installed and is often used in Docker containers so that they take up very little space.\n",
"\n",
"The `3.9.18` python image occupies 997 MB, `3.9.18-slim` occupies 126 MB and `3.9.18-alpine` occupies 47.8 MB.\n",
"\n",
"``` Dockerfile\n",
"FROM python:3.9.18-alpine\n",
"COPY ./sourceCode/sourceApp /sourceCode/sourceApp\n",
"CMD [\"python3\", \"/sourceCode/sourceApp/app.py\"]\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "#### Indicate the workspace"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Instead of indicating the path of the image `/sourceCode/sourceApp` we establish that this path is the workspace of the image. This way when we copy the code or run the application we do not need to indicate the path\n",
"\n",
"``` Dockerfile\n",
"FROM python:3.9.18-alpine\n",
"WORKDIR /sourceCode/sourceApp\n",
"COPY ./sourceCode/sourceApp .\n",
"CMD [\"python3\", \"app.py\"]\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "#### Indicate the workspace"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Instead of indicating the path of the image `/sourceCode/sourceApp` we establish that this path is the workspace of the image. This way when we copy the code or run the application we do not need to indicate the path\n",
"\n",
"``` Dockerfile\n",
"FROM python:3.9.18-alpine\n",
"WORKDIR /sourceCode/sourceApp\n",
"COPY ./sourceCode/sourceApp .\n",
"CMD [\"python3\", \"app.py\"]\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Shared code in a `bind mount` folder"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We had created a folder called `dockerHostFolder` in which we had shared files between the host and a container. Inside there should also be three files"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "bindFile.txt  fileExtract.txt  text.txt\n"
          ]
        }
      ],
      "source": [
      "!ls dockerHostFolder"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Let's take advantage of the `text.txt` file to see that. Let's see what's inside `text.txt`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
      "!cat dockerHostFolder/text.txt"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "No output, the file is empty. Let's create again an ubuntu container sharing the `dockerHostFolder` folder."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "24adbded61f507cdf7f192eb5e246e43ee3ffafc9944b7c57918eb2d547dff19\n"
          ]
        }
      ],
      "source": [
      "!docker run --name alwaysup -d -v ~/Documentos/web/portafolio/posts/dockerHostFolder:/dockerContainerFolder ubuntu tail -f /dev/null"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We see that the container is running"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND               CREATED          STATUS          PORTS     NAMES\n",
"24adbded61f5   ubuntu    \"tail -f /dev/null\"   16 seconds ago   Up 15 seconds             alwaysup\n"
          ]
        }
      ],
      "source": [
      "!docker ps"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We enter the container, we see that `text.txt` is there and that it is empty\n",
"\n",
"````bash\n",
"$ docker exec -it alwaysup bash\n",
"root@24adbded61f5:/# ls dockerContainerFolder/\n",
"bindFile.txt fileExtract.txt text.txt\n",
"root@24adbded61f5:/# cat dockerContainerFolder/text.txt\n",
"root@24adbded61f5:/#\n",
"```\n",
"\n",
"Now we open in the host the file `text.txt` with the text editor of our choice, write `Hello world` and save. If now we see what is inside the file in the container we will see the same text\n",
"\n",
"````bash\n",
"root@24adbded61f5:/# cat dockerContainerFolder/text.txt\n",
"Hello world\n",
"```\n",
"\n",
"Now we edit the file in the container and leave the container\n",
"\n",
"````bash\n",
"root@24adbded61f5:/# echo hello container > dockerContainerFolder/text.txt\n",
"root@24adbded61f5:/# cat dockerContainerFolder/text.txt\n",
"hello container\n",
"root@24adbded61f5:/# exit\n",
"exit\n",
"```\n",
"\n",
"If we look at the file on the host we will see the text we wrote in the container"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "hola contenedor\n"
          ]
        }
      ],
      "source": [
      "!cat dockerHostFolder/text.txt"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Delete the container"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "alwaysup\n"
          ]
        }
      ],
      "source": [
      "!docker rm -f alwaysup"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Connect containers by network"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "In case we want to have several containers running and we want them to communicate, we can make them communicate over a network. Docker gives us the possibility to do that through its virtual networks."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Let's see which networks docker has using the command `docker network ls`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "NETWORK ID     NAME      DRIVER    SCOPE\n",
"de6e8b7b737e   bridge    bridge    local\n",
"da1f5f6fccc0   host      host      local\n",
"d3b0d93993c0   none      null      local\n"
          ]
        }
      ],
      "source": [
      "!docker network ls"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We see that by default docker has three networks\n",
" * Bridge: It is backward compatible with previous versions but we should not use it anymore.\n",
" * host: The host network\n",
" * none: This is the one we should use if we want a container to have no internet access."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We can create new networks that other containers can connect to it, for this we use the command `docker network create <name>`, so that other containers can also connect to it we must add the option `--attachable`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "2f6f3ddbfa8642e9f6819aa0965c16339e9e910be7bcf56ebb718fcac324cc27\n"
          ]
        }
      ],
      "source": [
      "!docker network create --attachable myNetwork"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We can inspect it using the command `docker network inspect <name>`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "[\n",
"    {\n",
"        \"Name\": \"myNetwork\",\n",
"        \"Id\": \"2f6f3ddbfa8642e9f6819aa0965c16339e9e910be7bcf56ebb718fcac324cc27\",\n",
"        \"Created\": \"2022-09-14T15:20:08.539830161+02:00\",\n",
"        \"Scope\": \"local\",\n",
"        \"Driver\": \"bridge\",\n",
"        \"EnableIPv6\": false,\n",
"        \"IPAM\": {\n",
"            \"Driver\": \"default\",\n",
"            \"Options\": {},\n",
"            \"Config\": [\n",
"                {\n",
"                    \"Subnet\": \"172.18.0.0/16\",\n",
"                    \"Gateway\": \"172.18.0.1\"\n",
"                }\n",
"            ]\n",
"        },\n",
"        \"Internal\": false,\n",
"        \"Attachable\": true,\n",
"        \"Ingress\": false,\n",
"        \"ConfigFrom\": {\n",
"            \"Network\": \"\"\n",
"        },\n",
"        \"ConfigOnly\": false,\n",
"        \"Containers\": {},\n",
"        \"Options\": {},\n",
"        \"Labels\": {}\n",
"    }\n",
"]\n"
          ]
        }
      ],
      "source": [
      "!docker network inspect myNetwork"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Now we have to create two containers so that they can communicate."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We are going to create a new container, which we will call `container1`, with a shared folder and inside it will be called `folder1`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "a5fca8ba1e4ff0a67002f8f1b8cc3cd43185373c2a7e295546f774059ad8dd1a\n"
          ]
        }
      ],
      "source": [
      "!docker run --name container1 -d -v ~/Documentos/web/portafolio/posts/dockerHostFolder:/folder1 ubuntu tail -f /dev/null"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Now we create another container, called `container2`, with another shared folder, but named `folder2`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "6c8dc18315488ef686f7548516c19b3d716728dd8a173cdb889ec0dd082232f9\n"
          ]
        }
      ],
      "source": [
      "!docker run --name container2 -d -v ~/Documentos/web/portafolio/posts/dockerHostFolder:/folder2 ubuntu tail -f /dev/null"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We see the containers running and we see that they are both"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND               CREATED         STATUS         PORTS     NAMES\n",
"6c8dc1831548   ubuntu    \"tail -f /dev/null\"   3 seconds ago   Up 2 seconds             container2\n",
"a5fca8ba1e4f   ubuntu    \"tail -f /dev/null\"   4 seconds ago   Up 3 seconds             container1\n"
          ]
        }
      ],
      "source": [
      "!docker ps"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Now we have to connect the containers to the network, for this we use the command `docker network connect <network name> <container name>`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
      "!docker network connect myNetwork container1"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
      "!docker network connect myNetwork container2"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "To check that they are properly connected we can inspect the network, but filtering by the connected containers\n",
"\n",
"````bash\n",
"$ docker network inspect --format '{{.Containers}}' myNetwork\n",
"map\n",
"[\n",
"    6c8dc18315488ef686f7548516c19b3d716728dd8a173cdb889ec0dd082232f9:\n",
"    {\n",
"        container2\n",
"        f828d211e894f7a5a992ce41a2a0def8e2424e9737fb4e1485fc09cc2d607b69\n",
"        02:42:ac:12:00:03\n",
"        172.18.0.3/16\n",
"    }\n",
"    a5fca8ba1e4ff0a67002f8f1b8cc3cd43185373c2a7e295546f774059ad8dd1a:\n",
"    {\n",
"        container1\n",
"        cff762e6286ebc169804b2a675bbff904102de796751d367c18d4b490c994c45\n",
"        02:42:ac:12:12:00:02\n",
"        172.18.0.2/16\n",
"    }\n",
"\n",
"```\n",
"\n",
"As we can see the container `container1` has the IP `172.18.0.2` and the container `container2` has the IP `172.18.0.3`."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We go inside the `container1` container and install `ping`.\n",
"\n",
"``` bash\n",
"$ docker exec -it container1 bash\n",
"root@a5fca8ba1e4f:/# apt update\n",
"    ...\n",
"root@a5fca8ba1e4f:/# apt install iputils-ping\n",
"    ...\n",
"root@a5fca8ba1e4f:/#\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We go inside the `container2` container and install `ping`.\n",
"\n",
"````bash\n",
"$ docker exec -it container2 bash\n",
"root@a5fca8ba1e4f:/# apt update\n",
"    ...\n",
"root@a5fca8ba1e4f:/# apt install iputils-ping\n",
"    ...\n",
"root@a5fca8ba1e4f:/#\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Now from container `container1` we ping the IP `172.18.0.3`, which belongs to container `container2`.\n",
"\n",
"````bash\n",
"root@a5fca8ba1e4f:/# ping 172.18.0.3\n",
"PING 172.18.0.3 (172.18.0.3) 56(84) bytes of data.\n",
"64 bytes from 172.18.0.3: icmp_seq=1 ttl=64 time=0.115 ms\n",
"64 bytes from 172.18.0.3: icmp_seq=2 ttl=64 time=0.049 ms\n",
"64 bytes from 172.18.0.3: icmp_seq=3 ttl=64 time=0.056 ms\n",
"64 bytes from 172.18.0.3: icmp_seq=4 ttl=64 time=0.060 ms\n",
"^C\n",
"--- 172.18.0.3 ping statistics ---\n",
"4 packets transmitted, 4 received, 0% packet loss, time 3068ms\n",
"rtt min/avg/max/mdev = 0.049/0.070/0.115/0.026 ms\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "And from container `container2` we ping the IP `172.18.0.2`, which belongs to container `container1`.\n",
"\n",
"````bash\n",
"root@6c8dc1831548:/# ping 172.18.0.2\n",
"PING 172.18.0.2 (172.18.0.2) 56(84) bytes of data.\n",
"64 bytes from 172.18.0.2: icmp_seq=1 ttl=64 time=0.076 ms\n",
"64 bytes from 172.18.0.2: icmp_seq=2 ttl=64 time=0.045 ms\n",
"64 bytes from 172.18.0.2: icmp_seq=3 ttl=64 time=0.049 ms\n",
"64 bytes from 172.18.0.2: icmp_seq=4 ttl=64 time=0.051 ms\n",
"^C\n",
"--- 172.18.0.2 ping statistics ---\n",
"4 packets transmitted, 4 received, 0% packet loss, time 3074ms\n",
"rtt min/avg/max/mdev = 0.045/0.055/0.076/0.012 ms\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "But there is a better thing that docker allows us to do, if I don't know the IP of the container I want to connect to, instead of typing its IP I can type its name"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Now from the container `container1` we ping the IP `container2`.\n",
"\n",
"````bash\n",
"root@a5fca8ba1e4f:/# ping container2\n",
"PING container2 (172.18.0.3) 56(84) bytes of data.\n",
"64 bytes from container2.myNetwork (172.18.0.3): icmp_seq=1 ttl=64 time=0.048 ms\n",
"64 bytes from container2.myNetwork (172.18.0.3): icmp_seq=2 ttl=64 time=0.050 ms\n",
"64 bytes from container2.myNetwork (172.18.0.3): icmp_seq=3 ttl=64 time=0.052 ms\n",
"64 bytes from container2.myNetwork (172.18.0.3): icmp_seq=4 ttl=64 time=0.053 ms\n",
"^C\n",
"--- container2 ping statistics ---\n",
"4 packets transmitted, 4 received, 0% packet loss, time 3071ms\n",
"rtt min/avg/max/mdev = 0.048/0.050/0.053/0.002 ms\n",
"```\n",
"\n",
"As we can see docker knows that the IP of the container `conteiner2` is `172.18.0.3`."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "And from the container `container2` we ping the IP `container1`.\n",
"\n",
"````bash\n",
"root@6c8dc1831548:/# ping container1\n",
"PING container1 (172.18.0.2) 56(84) bytes of data.\n",
"64 bytes from container1.myNetwork (172.18.0.2): icmp_seq=1 ttl=64 time=0.051 ms\n",
"64 bytes from container1.myNetwork (172.18.0.2): icmp_seq=2 ttl=64 time=0.058 ms\n",
"64 bytes from container1.myNetwork (172.18.0.2): icmp_seq=3 ttl=64 time=0.052 ms\n",
"64 bytes from container1.myNetwork (172.18.0.2): icmp_seq=4 ttl=64 time=0.056 ms\n",
"^C\n",
"--- container1 ping statistics ---\n",
"4 packets transmitted, 4 received, 0% packet loss, time 3057ms\n",
"rtt min/avg/max/mdev = 0.051/0.054/0.058/0.003 ms\n",
"```\n",
"\n",
"As we can see docker knows that the IP of the container `conteiner1` is `172.18.0.2`."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We get out of the containers and erase them."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "container1\n",
"container2\n"
          ]
        }
      ],
      "source": [
      "!docker rm -f container1 container2"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We also delete the network we have created"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "myNetwork\n"
          ]
        }
      ],
      "source": [
      "!docker network rm myNetwork"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "## Use of GPUs"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "In order to use the host GPUs inside the docker containers, it is necessary to follow the steps described in the [Nvidia container toolkit] installation page (https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html)."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Configure the repository and the GPG key"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We have to configure the `nvidia container toolkit` repository and the GPG key, for that we execute the following command in the console\n",
"\n",
"``` bash\n",
"distribution=$((. /etc/os-release;echo $ID$VERSION_ID) \\(.\n",
"      && curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg\n",
"      && curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | |\n",
"            sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' |\n",
"            sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Installation of `nvidia container toolkit`."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Once we have updated the repository and the key, we update the repositories using the command\n",
"``` bash\n",
"sudo apt update\n",
"```\n",
"\n",
"And install `nvidia container toolkit`.\n",
"``` bash\n",
"sudo apt install -y nvidia-docker2\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Docker restart"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Once we have finished we have to restart the docker daemon using\n",
"``` bash\n",
"sudo systemctl restart docker\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Use of GPUs"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Now that we have configured docker to be able to use the host GPUs inside the containers we can test it using the `--gpus all` option. If you have more than one GPU and you only want to use 1 you would have to specify it, but for the moment here we only explain how to use all GPUs."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We create a container that will not run in the background, but what it will do is run the `nvidia-smi` command so we can see if it has access to GPUs"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Unable to find image 'ubuntu:latest' locally\n",
"latest: Pulling from library/ubuntu\n",
"\n",
"\u001b[1B6a12be2b: Pull complete .54MB/29.54MBB\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KDigest: sha256:aabed3296a3d45cede1dc866a24476c4d7e093aa806263c27ddaadbdce3c1054\n",
"Status: Downloaded newer image for ubuntu:latest\n",
"Mon Sep  4 07:10:36 2023       \n",
"+-----------------------------------------------------------------------------+\n",
"| NVIDIA-SMI 510.39.01    Driver Version: 510.39.01    CUDA Version: 11.6     |\n",
"|-------------------------------+----------------------+----------------------+\n",
"| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
"| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
"|                               |                      |               MIG M. |\n",
"|===============================+======================+======================|\n",
"|   0  Quadro T1000        On   | 00000000:01:00.0 Off |                  N/A |\n",
"| N/A   44C    P0    15W /  N/A |      9MiB /  4096MiB |      0%      Default |\n",
"|                               |                      |                  N/A |\n",
"+-------------------------------+----------------------+----------------------+\n",
"                                                                               \n",
"+-----------------------------------------------------------------------------+\n",
"| Processes:                                                                  |\n",
"|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
"|        ID   ID                                                   Usage      |\n",
"|=============================================================================|\n",
"|    0   N/A  N/A      2545      G                                       4MiB |\n",
"|    0   N/A  N/A      3421      G                                       4MiB |\n",
"+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
      "!docker run --name container_gpus --gpus all ubuntu nvidia-smi"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Delete the container"
      ]
    },
{
      "cell_type": "code",
      "execution_count": "None",
      "metadata": {},
      "outputs": [],
      "source": [
      "!doker rm container_gpus"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "## Docker compose"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Docker compose vs. docker-compose"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "`docker-compose` was a tool that was created to help the maintenance of images and containers and had to be installed separately from docker. However docker incorporated it in its latest versions and it is no longer necessary to install it, however, to use it, instead of using the `docker-compose` command you have to use the `docker-compose` command. In many sites you will find information with `docker-compose`, but when you install docker you will already have `docker compose` installed, so everything you could do with `docker-compose` is compatible with `docker compose`."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Docker compose"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Docker compose is a docker tool that does everything we have seen so far, but saving us time and effort. By editing a `.yml` file we can tell docker compose to create as many containers as we want.\n",
"\n",
"To use it once will not make much difference from typing all the commands we saw before or typing the `.yml` file but when you want to get the same container configuration working again, just calling the `.yml` file will recreate the whole configuration."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Let's create a folder where we will store the docker compose files"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
      "!mkdir dockerComposeFiles"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We create inside the `.yml` file"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
      "!touch dockerComposeFiles/docker-compose.yml"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "A docker compose file has to start with the version\n",
"\n",
"```json\n",
"version: \"<v.v>\"\n",
"```\n",
"\n",
"At the time of writing, the latest version is `3.8` so we write that one"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "*docker-compose.yml*:\n",
"\n",
"```json\n",
"    version: \"3.8\".\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "The following are the services, which are the containers. For each service, the image must be specified and other parameters such as ports, environment variables, etc. can be added.\n",
"\n",
"```json\n",
"services:\n",
"    container1:\n",
"        image: ubuntu\n",
"    \n",
"    container2:\n",
"        image: ubuntu\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "The `docker-compose.yml` would look like this:\n",
"\n",
"```json\n",
"    version: \"3.8\".\n",
"\n",
"    services:\n",
"    container1:\n",
"        image: ubuntu\n",
"    \n",
"    container2:\n",
"        image: ubuntu\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Once we have created the file, in its path, we can run everything through the `docker compose up` command, but also adding the `-d` option we will make it run in the background"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Running 1/0\n",
"\u001b[34m ⠿ Network dockercomposefiles_default         Created                      0.1s\n",
"\u001b[0m\u001b[37m ⠋ Container dockercomposefiles-container2-1  Creating                     0.0s\n",
"\u001b[0m\u001b[37m ⠋ Container dockercomposefiles-container1-1  Creating                     0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/3\n",
"\u001b[34m ⠿ Network dockercomposefiles_default         Created                      0.1s\n",
"\u001b[0m\u001b[37m ⠙ Container dockercomposefiles-container2-1  Creating                     0.1s\n",
"\u001b[0m\u001b[37m ⠙ Container dockercomposefiles-container1-1  Creating                     0.1s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/3\n",
"\u001b[34m ⠿ Network dockercomposefiles_default         Created                      0.1s\n",
"\u001b[0m\u001b[37m ⠿ Container dockercomposefiles-container2-1  Starting                     0.2s\n",
"\u001b[0m\u001b[37m ⠿ Container dockercomposefiles-container1-1  Starting                     0.2s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/3\n",
"\u001b[34m ⠿ Network dockercomposefiles_default         Created                      0.1s\n",
"\u001b[0m\u001b[37m ⠿ Container dockercomposefiles-container2-1  Starting                     0.3s\n",
"\u001b[0m\u001b[37m ⠿ Container dockercomposefiles-container1-1  Starting                     0.3s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/3\n",
"\u001b[34m ⠿ Network dockercomposefiles_default         Created                      0.1s\n",
"\u001b[0m\u001b[37m ⠿ Container dockercomposefiles-container2-1  Starting                     0.4s\n",
"\u001b[0m\u001b[37m ⠿ Container dockercomposefiles-container1-1  Starting                     0.4s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/3\n",
"\u001b[34m ⠿ Network dockercomposefiles_default         Created                      0.1s\n",
"\u001b[0m\u001b[37m ⠿ Container dockercomposefiles-container2-1  Starting                     0.5s\n",
"\u001b[0m\u001b[37m ⠿ Container dockercomposefiles-container1-1  Starting                     0.5s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 2/3\n",
"\u001b[34m ⠿ Network dockercomposefiles_default         Created                      0.1s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container2-1  Started                      0.5s\n",
"\u001b[0m\u001b[37m ⠿ Container dockercomposefiles-container1-1  Starting                     0.6s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l\u001b[34m[+] Running 3/3\u001b[0m\n",
"\u001b[34m ⠿ Network dockercomposefiles_default         Created                      0.1s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container2-1  Started                      0.5s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container1-1  Started                      0.7s\n",
"\u001b[0m\u001b[?25h"
          ]
        }
      ],
      "source": [
      "!cd dockerComposeFiles && docker compose up -d"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If you look at two containers `dockercomposefiles-container1-1` and `dockercomposefiles-container2-1` and the network linking them `dockercomposefiles_default`, you have created two containers `dockercomposefiles-container1-1` and `dockercomposefiles-container2-1`."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Let's delete the two containers"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "dockercomposefiles-container1-1\n",
"dockercomposefiles-container2-1\n"
          ]
        }
      ],
      "source": [
      "!docker rm -f dockercomposefiles-container1-1 dockercomposefiles-container2-1"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "And we delete the network it has created"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "dockercomposefiles_default\n"
          ]
        }
      ],
      "source": [
      "!docker network rm dockercomposefiles_default"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Let's try to do what we did before with what we know so far. We create a new image that comes with `ping` installed.\n",
"\n",
"*Dockerfile:\n",
"```docker\n",
"    FROM ubuntu:20.04\n",
"    RUN apt update\n",
"    RUN apt install iputils-ping -y\n",
"```\n",
"\n",
"And we compile it"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Sending build context to Docker daemon  2.048kB\n",
"Step 1/3 : FROM ubuntu:20.04\n",
" ---> a0ce5a295b63\n",
"Step 2/3 : RUN apt update\n",
" ---> Running in 3bd5278d39b4\n",
"\u001b[91m\n",
"WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
"\n",
"\u001b[0mGet:1 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
"Get:2 http://archive.ubuntu.com/ubuntu focal InRelease [265 kB]\n",
"Get:3 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [898 kB]\n",
"Get:4 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
"Get:5 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
"Get:6 http://archive.ubuntu.com/ubuntu focal/universe amd64 Packages [11.3 MB]\n",
"Get:7 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2133 kB]\n",
"Get:8 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [27.5 kB]\n",
"Get:9 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [1501 kB]\n",
"Get:10 http://archive.ubuntu.com/ubuntu focal/main amd64 Packages [1275 kB]\n",
"Get:11 http://archive.ubuntu.com/ubuntu focal/restricted amd64 Packages [33.4 kB]\n",
"Get:12 http://archive.ubuntu.com/ubuntu focal/multiverse amd64 Packages [177 kB]\n",
"Get:13 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [2594 kB]\n",
"Get:14 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [1613 kB]\n",
"Get:15 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [30.2 kB]\n",
"Get:16 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1200 kB]\n",
"Get:17 http://archive.ubuntu.com/ubuntu focal-backports/universe amd64 Packages [27.4 kB]\n",
"...\n",
"Successfully built c3d32aa9de02\n",
"Successfully tagged ubuntu:ping\n",
"\n",
"Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\n"
          ]
        }
      ],
      "source": [
      "!docker build -t ubuntu:ping ./dockerImages"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We check that"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "REPOSITORY        TAG       IMAGE ID       CREATED              SIZE\n",
"ubuntu            ping      c3d32aa9de02   About a minute ago   112MB\n",
"maximofn/ubuntu   test      a78cf3ea16d8   25 hours ago         77.8MB\n",
"nginx             latest    2d389e545974   33 hours ago         142MB\n",
"ubuntu            latest    2dc39ba059dc   12 days ago          77.8MB\n",
"ubuntu            20.04     a0ce5a295b63   12 days ago          72.8MB\n",
"hello-world       latest    feb5d9fea6a5   11 months ago        13.3kB\n"
          ]
        }
      ],
      "source": [
      "!docker image ls"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We change the tag"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
      "!docker tag ubuntu:ping maximofn/ubuntu:ping"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "REPOSITORY        TAG       IMAGE ID       CREATED              SIZE\n",
"ubuntu            ping      c3d32aa9de02   About a minute ago   112MB\n",
"maximofn/ubuntu   ping      c3d32aa9de02   About a minute ago   112MB\n",
"maximofn/ubuntu   test      c3d32aa9de02   About a minute ago   112MB\n",
"nginx             latest    2d389e545974   33 hours ago         142MB\n",
"ubuntu            latest    2dc39ba059dc   12 days ago          77.8MB\n",
"ubuntu            20.04     a0ce5a295b63   12 days ago          72.8MB\n",
"hello-world       latest    feb5d9fea6a5   11 months ago        13.3kB\n"
          ]
        }
      ],
      "source": [
      "!docker image ls"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We edit the docker compose file to take the images we just created\n",
"\n",
"*docker-compose.yml*:\n",
"```json\n",
"    version: \"3.8\".\n",
"\n",
"    services:\n",
"      container1:\n",
"        image: maximofn/ubuntu:ping\n",
"\n",
"    container2:\n",
"        image: maximofn/ubuntu:ping\n",
"```\n",
"\n",
"And we also tell it to execute a non-operation.\n",
"\n",
"The `docker-compose.yml` would look like this:\n",
"```json\n",
"    version: \"3.8\".\n",
"\n",
"    services:\n",
"      container1:\n",
"        image: ubuntu\n",
"        command: tail -f /dev/null\n",
"\n",
"    container2:\n",
"        image: ubuntu\n",
"        command: tail -f /dev/null\n",
"```\n",
"\n",
"We lift it"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Running 0/0\n",
"\u001b[37m ⠋ Container dockercomposefiles-container1-1  Recreate                     0.1s\n",
"\u001b[0m\u001b[37m ⠋ Container dockercomposefiles-container2-1  Recreate                     0.1s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[34m ⠿ Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
"\u001b[0m\u001b[37m ⠙ Container dockercomposefiles-container2-1  Recreate                     0.2s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[34m ⠿ Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
"\u001b[0m\u001b[37m ⠹ Container dockercomposefiles-container2-1  Recreate                     0.3s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[34m ⠿ Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
"\u001b[0m\u001b[37m ⠸ Container dockercomposefiles-container2-1  Recreate                     0.4s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[34m ⠿ Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
"\u001b[0m\u001b[37m ⠼ Container dockercomposefiles-container2-1  Recreate                     0.5s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[34m ⠿ Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
"\u001b[0m\u001b[37m ⠴ Container dockercomposefiles-container2-1  Recreate                     0.6s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[34m ⠿ Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
"\u001b[0m\u001b[37m ⠦ Container dockercomposefiles-container2-1  Recreate                     0.7s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[34m ⠿ Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
"\u001b[0m\u001b[37m ⠧ Container dockercomposefiles-container2-1  Recreate                     0.8s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[34m ⠿ Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
"\u001b[0m\u001b[37m ⠇ Container dockercomposefiles-container2-1  Recreate                     0.9s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[34m ⠿ Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
"\u001b[0m\u001b[37m ⠏ Container dockercomposefiles-container2-1  Recreate                     1.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[34m ⠿ Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
"\u001b[0m\u001b[37m ⠋ Container dockercomposefiles-container2-1  Recreate                     1.1s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[34m ⠿ Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
"\u001b[0m\u001b[37m ⠙ Container dockercomposefiles-container2-1  Recreate                     1.2s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[34m ⠿ Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
"\u001b[0m\u001b[37m ⠹ Container dockercomposefiles-container2-1  Recreate                     1.3s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[34m ⠿ Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
"\u001b[0m\u001b[37m ⠸ Container dockercomposefiles-container2-1  Recreate                     1.4s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[34m ⠿ Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
"...\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l\u001b[34m[+] Running 2/2\u001b[0m\n",
"\u001b[34m ⠿ Container dockercomposefiles-container1-1  Started                     10.8s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container2-1  Started                     10.9s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l\u001b[34m[+] Running 2/2\u001b[0m\n",
"\u001b[34m ⠿ Container dockercomposefiles-container1-1  Started                     10.8s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container2-1  Started                     10.9s\n",
"\u001b[0m\u001b[?25h"
          ]
        }
      ],
      "source": [
      "!cd dockerComposeFiles && docker compose up -d"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We see the containers that are running"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE                  COMMAND               CREATED          STATUS          PORTS     NAMES\n",
"935939e5a75d   maximofn/ubuntu:ping   \"tail -f /dev/null\"   15 seconds ago   Up 13 seconds             dockercomposefiles-container2-1\n",
"f9138d7064dd   maximofn/ubuntu:ping   \"tail -f /dev/null\"   25 seconds ago   Up 13 seconds             dockercomposefiles-container1-1\n"
          ]
        }
      ],
      "source": [
      "!docker ps"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "The two containers are running, now we get into one and try to 'ping' the other one.\n",
"\n",
"````bash\n",
"$ docker exec -it dockercomposefiles-container1-1 bash\n",
"root@f9138d7064dd:/# ping dockercomposefiles-container2-1\n",
"PING dockercomposefiles-container2-1 (172.21.0.3) 56(84) bytes of data.\n",
"64 bytes from dockercomposefiles-container2-1.dockercomposefiles_default (172.21.0.3): icmp_seq=1 ttl=64 time=0.110 ms\n",
"64 bytes from dockercomposefiles-container2-1.dockercomposefiles_default (172.21.0.3): icmp_seq=2 ttl=64 time=0.049 ms\n",
"64 bytes from dockercomposefiles-container2-1.dockercomposefiles_default (172.21.0.3): icmp_seq=3 ttl=64 time=0.049 ms\n",
"64 bytes from dockercomposefiles-container2-1.dockercomposefiles_default (172.21.0.3): icmp_seq=4 ttl=64 time=0.075 ms\n",
"^C\n",
"--- dockercomposefiles-container2-1 ping statistics ---\n",
"4 packets transmitted, 4 received, 0% packet loss, time 3068ms\n",
"rtt min/avg/max/mdev = 0.049/0.070/0.110/0.025 ms\n",
"```\n",
"\n",
"As we can see we can do `ping`, we have created well the image with `ping` installed. In addition in the docker compose we have made a non-operation to be executed so that the containers are running"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We delete the two containers and the network it has created"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "dockercomposefiles-container1-1\n",
"dockercomposefiles-container2-1\n"
          ]
        }
      ],
      "source": [
      "!docker rm -f dockercomposefiles-container1-1 dockercomposefiles-container2-1"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "dockercomposefiles_default\n"
          ]
        }
      ],
      "source": [
      "!docker network rm dockercomposefiles_default"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### How to name docker compose containers"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If you look at the containers that docker created they were named `dockercomposefiles-container1-1` and `dockercomposefiles-container1-1`. This is because the folder where the docker compose file is in a folder called `dockerComposeFiles`, so the first part of the name of the containers is `dockercomposefiles`, then appears the name of the service that we have given in the docker compose file (`container1` and `container2`) and finally a number to create more if necessary.\n",
"\n",
"Similar happens with the name of the network you have created `dockercomposefiles_default`."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Logs in docker compose"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We are now going to change the docker compose file, in the lines where we had ```command: tail -f /dev/null```, we are going to put ```command: ping 0.0.0.0.0```.\n",
"\n",
"And we also tell it to execute a non-operation.\n",
"\n",
"The `docker-compose.yml` would look like this:\n",
"```json\n",
"    version: \"3.8\".\n",
"\n",
"    services:\n",
"      container1:\n",
"        image: ubuntu\n",
"        command: ping 0.0.0.0.0\n",
"\n",
"    container2:\n",
"        image: ubuntu\n",
"        command: ping 0.0.0.0.0\n",
"```\n",
"\n",
"We do this so that each container is constantly spitting out the ping, so we simulate logs.\n",
"\n",
"If we run again docker compose"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Running 0/0\n",
"\u001b[37m ⠋ Container dockercomposefiles-container1-1  Recreate                     0.1s\n",
"\u001b[0m\u001b[37m ⠋ Container dockercomposefiles-container2-1  Recreate                     0.1s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠙ Container dockercomposefiles-container1-1  Recreate                     0.2s\n",
"\u001b[0m\u001b[37m ⠙ Container dockercomposefiles-container2-1  Recreate                     0.2s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠹ Container dockercomposefiles-container1-1  Recreate                     0.3s\n",
"\u001b[0m\u001b[37m ⠹ Container dockercomposefiles-container2-1  Recreate                     0.3s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠸ Container dockercomposefiles-container1-1  Recreate                     0.4s\n",
"\u001b[0m\u001b[37m ⠸ Container dockercomposefiles-container2-1  Recreate                     0.4s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠼ Container dockercomposefiles-container1-1  Recreate                     0.5s\n",
"\u001b[0m\u001b[37m ⠼ Container dockercomposefiles-container2-1  Recreate                     0.5s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠴ Container dockercomposefiles-container1-1  Recreate                     0.6s\n",
"\u001b[0m\u001b[37m ⠴ Container dockercomposefiles-container2-1  Recreate                     0.6s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠦ Container dockercomposefiles-container1-1  Recreate                     0.7s\n",
"\u001b[0m\u001b[37m ⠦ Container dockercomposefiles-container2-1  Recreate                     0.7s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠧ Container dockercomposefiles-container1-1  Recreate                     0.8s\n",
"\u001b[0m\u001b[37m ⠧ Container dockercomposefiles-container2-1  Recreate                     0.8s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"...\n",
"\u001b[37m ⠿ Container dockercomposefiles-container1-1  Starting                    11.0s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container2-1  Started                     11.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l\u001b[34m[+] Running 2/2\u001b[0m\n",
"\u001b[34m ⠿ Container dockercomposefiles-container1-1  Started                     11.1s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container2-1  Started                     11.0s\n",
"\u001b[0m\u001b[?25h"
          ]
        }
      ],
      "source": [
      "!cd dockerComposeFiles && docker compose up -d"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Now we can view the logs of the two containers using the command `docker compose logs`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "\u001b[36mdockercomposefiles-container2-1  | \u001b[0mPING 0.0.0.0 (127.0.0.1) 56(84) bytes of data.\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=1 ttl=64 time=0.042 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=2 ttl=64 time=0.025 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=3 ttl=64 time=0.022 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=4 ttl=64 time=0.030 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=5 ttl=64 time=0.021 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=6 ttl=64 time=0.021 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=7 ttl=64 time=0.030 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=8 ttl=64 time=0.028 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=9 ttl=64 time=0.028 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=10 ttl=64 time=0.026 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=11 ttl=64 time=0.028 ms\n",
"\u001b[33mdockercomposefiles-container1-1  | \u001b[0mPING 0.0.0.0 (127.0.0.1) 56(84) bytes of data.\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=12 ttl=64 time=0.027 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=13 ttl=64 time=0.039 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=14 ttl=64 time=0.035 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=15 ttl=64 time=0.034 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=16 ttl=64 time=0.036 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=17 ttl=64 time=0.034 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=18 ttl=64 time=0.036 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=19 ttl=64 time=0.032 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=20 ttl=64 time=0.032 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=21 ttl=64 time=0.033 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=22 ttl=64 time=0.034 ms\n",
"\u001b[33mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=1 ttl=64 time=0.037 ms\n",
"...\n",
"\u001b[33mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=214 ttl=64 time=0.015 ms\n",
"\u001b[33mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=215 ttl=64 time=0.021 ms\n",
"\u001b[33mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=216 ttl=64 time=0.020 ms\n",
"\u001b[33mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=217 ttl=64 time=0.049 ms\n"
          ]
        }
      ],
      "source": [
      "!cd dockerComposeFiles && docker compose logs"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "As we can see we can see the logs of both containers, but in case we want to see only the logs of one, we can specify the **service name**."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "\u001b[36mdockercomposefiles-container1-1  | \u001b[0mPING 0.0.0.0 (127.0.0.1) 56(84) bytes of data.\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=1 ttl=64 time=0.037 ms\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=2 ttl=64 time=0.025 ms\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=3 ttl=64 time=0.023 ms\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=4 ttl=64 time=0.031 ms\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=5 ttl=64 time=0.034 ms\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=6 ttl=64 time=0.033 ms\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=7 ttl=64 time=0.034 ms\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=8 ttl=64 time=0.022 ms\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=9 ttl=64 time=0.032 ms\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=10 ttl=64 time=0.029 ms\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=11 ttl=64 time=0.031 ms\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=12 ttl=64 time=0.024 ms\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=13 ttl=64 time=0.029 ms\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=14 ttl=64 time=0.032 ms\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=15 ttl=64 time=0.033 ms\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=16 ttl=64 time=0.034 ms\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=17 ttl=64 time=0.028 ms\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=18 ttl=64 time=0.034 ms\n",
"...\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=332 ttl=64 time=0.027 ms\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=333 ttl=64 time=0.030 ms\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=334 ttl=64 time=0.033 ms\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=335 ttl=64 time=0.036 ms\n"
          ]
        }
      ],
      "source": [
      "!cd dockerComposeFiles && docker compose logs container1"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "\u001b[36mdockercomposefiles-container2-1  | \u001b[0mPING 0.0.0.0 (127.0.0.1) 56(84) bytes of data.\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=1 ttl=64 time=0.042 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=2 ttl=64 time=0.025 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=3 ttl=64 time=0.022 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=4 ttl=64 time=0.030 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=5 ttl=64 time=0.021 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=6 ttl=64 time=0.021 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=7 ttl=64 time=0.030 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=8 ttl=64 time=0.028 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=9 ttl=64 time=0.028 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=10 ttl=64 time=0.026 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=11 ttl=64 time=0.028 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=12 ttl=64 time=0.027 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=13 ttl=64 time=0.039 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=14 ttl=64 time=0.035 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=15 ttl=64 time=0.034 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=16 ttl=64 time=0.036 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=17 ttl=64 time=0.034 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=18 ttl=64 time=0.036 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=19 ttl=64 time=0.032 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=20 ttl=64 time=0.032 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=21 ttl=64 time=0.033 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=22 ttl=64 time=0.034 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=23 ttl=64 time=0.035 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=24 ttl=64 time=0.037 ms\n",
"...\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=340 ttl=64 time=0.034 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=341 ttl=64 time=0.033 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=342 ttl=64 time=0.034 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=343 ttl=64 time=0.036 ms\n"
          ]
        }
      ],
      "source": [
      "!cd dockerComposeFiles && docker compose logs container2"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If we want to see the logs continuously we can add the `-f` option, `docker compose logs - <service name>`."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If I have made a docker compose with more than two services, when I want to see the logs of several services just add more names to the command, `docker compose logs <name service 1> <name service 2> ...`."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Exec services"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "As we have seen, using the `exec` command we can enter a container indicating the name of the container, the command to be executed and the `-it` option. With docker compose this is simpler, since only the name of the service and the command are required, but the `-it` option is not necessary since docker compose takes it for granted.\n",
"\n",
"````bash\n",
"$ docker compose exec container1 bash\n",
"root@a7cf282fe66c:/#\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Stopping docker compose"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "When we have finished working, with a single command (`stop`), docker compose for everything, there is no need to stop each container one by one."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Running 0/0\n",
"\u001b[37m ⠋ Container dockercomposefiles-container2-1  Stopping                     0.1s\n",
"\u001b[0m\u001b[37m ⠋ Container dockercomposefiles-container1-1  Stopping                     0.1s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠙ Container dockercomposefiles-container2-1  Stopping                     0.2s\n",
"\u001b[0m\u001b[37m ⠙ Container dockercomposefiles-container1-1  Stopping                     0.2s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠹ Container dockercomposefiles-container2-1  Stopping                     0.3s\n",
"\u001b[0m\u001b[37m ⠹ Container dockercomposefiles-container1-1  Stopping                     0.3s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠸ Container dockercomposefiles-container2-1  Stopping                     0.4s\n",
"\u001b[0m\u001b[37m ⠸ Container dockercomposefiles-container1-1  Stopping                     0.4s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠼ Container dockercomposefiles-container2-1  Stopping                     0.5s\n",
"\u001b[0m\u001b[37m ⠼ Container dockercomposefiles-container1-1  Stopping                     0.5s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠴ Container dockercomposefiles-container2-1  Stopping                     0.6s\n",
"\u001b[0m\u001b[37m ⠴ Container dockercomposefiles-container1-1  Stopping                     0.6s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠦ Container dockercomposefiles-container2-1  Stopping                     0.7s\n",
"\u001b[0m\u001b[37m ⠦ Container dockercomposefiles-container1-1  Stopping                     0.7s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠧ Container dockercomposefiles-container2-1  Stopping                     0.8s\n",
"\u001b[0m\u001b[37m ⠧ Container dockercomposefiles-container1-1  Stopping                     0.8s\n",
"...\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[34m ⠿ Container dockercomposefiles-container2-1  Stopped                     10.4s\n",
"\u001b[0m\u001b[37m ⠸ Container dockercomposefiles-container1-1  Stopping                    10.4s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l\u001b[34m[+] Running 2/2\u001b[0m\n",
"\u001b[34m ⠿ Container dockercomposefiles-container2-1  Stopped                     10.4s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container1-1  Stopped                     10.4s\n",
"\u001b[0m\u001b[?25h"
          ]
        }
      ],
      "source": [
      "!cd dockerComposeFiles && docker compose stop"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "As you can see docker compose has stopped the two containers, but has not deleted them, nor has it deleted the network."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
          ]
        }
      ],
      "source": [
      "!docker ps"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE                  COMMAND          CREATED          STATUS                        PORTS     NAMES\n",
"1e6c1dd9adb2   maximofn/ubuntu:ping   \"ping 0.0.0.0\"   16 minutes ago   Exited (137) 25 seconds ago             dockercomposefiles-container2-1\n",
"a7cf282fe66c   maximofn/ubuntu:ping   \"ping 0.0.0.0\"   16 minutes ago   Exited (137) 25 seconds ago             dockercomposefiles-container1-1\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "NETWORK ID     NAME                         DRIVER    SCOPE\n",
"13cc632147f3   bridge                       bridge    local\n",
"d4a2f718cd83   dockercomposefiles_default   bridge    local\n",
"da1f5f6fccc0   host                         host      local\n",
"d3b0d93993c0   none                         null      local\n"
          ]
        }
      ],
      "source": [
      "!docker network ls"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Docker compose as a development tool"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "As we saw before, in order to be able to develop, the ideal would be to share the folder that has the code with the service. This with docker compose is done by adding the `volumes` tag to the docker compose file. First we have to add the path to the folder where the code is on the host and then the path in the container.\n",
"\n",
"*docker-compose.yml*:\n",
"```json\n",
"    version: \"3.8\".\n",
"\n",
"    services:\n",
"      container1:\n",
"        image: ubuntu\n",
"        command: ping 0.0.0.0.0\n",
"        volumes:\n",
"            - ../dockerHostFolder/:/dockerContainerFolder\n",
"\n",
"    container2:\n",
"        image: ubuntu\n",
"        command: ping 0.0.0.0.0\n",
"```\n",
"\n",
"As you can see, the path to the host folder I have set relative\n",
"\n",
"If we lift the docker compose"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Running 1/0\n",
"\u001b[37m ⠋ Container dockercomposefiles-container1-1  Recreate                     0.1s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container2-1  Created                      0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠿ Container dockercomposefiles-container1-1  Starting                     0.2s\n",
"\u001b[0m\u001b[37m ⠿ Container dockercomposefiles-container2-1  Starting                     0.2s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠿ Container dockercomposefiles-container1-1  Starting                     0.3s\n",
"\u001b[0m\u001b[37m ⠿ Container dockercomposefiles-container2-1  Starting                     0.3s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠿ Container dockercomposefiles-container1-1  Starting                     0.4s\n",
"\u001b[0m\u001b[37m ⠿ Container dockercomposefiles-container2-1  Starting                     0.4s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[34m ⠿ Container dockercomposefiles-container1-1  Started                      0.5s\n",
"\u001b[0m\u001b[37m ⠿ Container dockercomposefiles-container2-1  Starting                     0.5s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l\u001b[34m[+] Running 2/2\u001b[0m\n",
"\u001b[34m ⠿ Container dockercomposefiles-container1-1  Started                      0.5s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container2-1  Started                      0.6s\n",
"\u001b[0m\u001b[?25h"
          ]
        }
      ],
      "source": [
      "!cd dockerComposeFiles && docker compose up -d"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If we go inside the container, we can see what is inside the text.txt file\n",
"\n",
"````bash\n",
"$ docker compose exec container1 bash\n",
"root@c8aae9d619d3:/# ls dockerContainerFolder/\n",
"bindFile.txt fileExtract.txt text.txt\n",
"root@c8aae9d619d3:/# cat dockerContainerFolder/text.txt\n",
"hello container\n",
"```\n",
"\n",
"If we now open it on the host, we type `hello host` and we see again in the container\n",
"\n",
"````bash\n",
"root@c8aae9d619d3:/# cat dockerContainerFolder/text.txt\n",
"hello host\n",
"```\n",
"\n",
"And now the other way around, if we modify it in the container\n",
"\n",
"````bash\n",
"root@c8aae9d619d3:/# echo hello compose > dockerContainerFolder/text.txt\n",
"root@c8aae9d619d3:/# exit\n",
"exit\n",
"```\n",
"\n",
"If we see it from the host we must get `hello compose`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "hola compose\n"
          ]
        }
      ],
      "source": [
      "!cat dockerHostFolder/text.txt"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Port exposure in docker compose"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We can also configure the ports in the docker compose file, using the `ports` tag, indicating the host port and then the ip of the service\n",
"\n",
"```json\n",
"ports:\n",
"    - <host port>:<service port>.\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Docker compose on team - docker override"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If we are a group of people developing on docker with docker compose, it is likely that many people are changing the docker compose file, which can make them not synchronize well and cause conflicts.\n",
"\n",
"To solve this docker offers a tool called docker override. This way there can be a base docker compose file and everyone can modify it using docker override.\n",
"\n",
"To do this, we now have to create a file called `docker-compose.override.yml` which will be the one we can edit"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
      "!touch dockerComposeFiles/docker-compose.override.yml"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If we now try to raise the docker compose we will receive an error"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Top-level object must be a mapping\n"
          ]
        }
      ],
      "source": [
      "!cd dockerComposeFiles && docker compose up -d"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "And this is because docker compose has detected that there is a file called `docker-compose.override.yml` and it is empty, so we are going to edit it. The `docker-compose.override.yml` file what it does is to edit the `docker-compose.yml` file, so if for example we want to make a change in the `container2` service to add a volume to it we would write the `docker-compose.override.yml` file like this\n",
"\n",
"*docker-compose.override.yml*:\n",
"```json\n",
"    version: \"3.8\".\n",
"\n",
"    services:\n",
"    container2:\n",
"        volumes:\n",
"        - .../dockerHostFolder/:/dockerOverrideFolder\n",
"```\n",
"\n",
"Note that the shared folder in the service I have named `dockerOverrideFolder`, so let's pull up the docker compose and see if we see that folder in the `container2` container."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Running 1/0\n",
"\u001b[37m ⠋ Container dockercomposefiles-container2-1  Recreate                     0.1s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container1-1  Running                      0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[37m ⠙ Container dockercomposefiles-container2-1  Recreate                     0.2s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container1-1  Running                      0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[37m ⠹ Container dockercomposefiles-container2-1  Recreate                     0.3s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container1-1  Running                      0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[37m ⠸ Container dockercomposefiles-container2-1  Recreate                     0.4s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container1-1  Running                      0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[37m ⠼ Container dockercomposefiles-container2-1  Recreate                     0.5s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container1-1  Running                      0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[37m ⠴ Container dockercomposefiles-container2-1  Recreate                     0.6s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container1-1  Running                      0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[37m ⠦ Container dockercomposefiles-container2-1  Recreate                     0.7s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container1-1  Running                      0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[37m ⠧ Container dockercomposefiles-container2-1  Recreate                     0.8s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container1-1  Running                      0.0s\n",
"...\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[37m ⠿ Container dockercomposefiles-container2-1  Starting                    10.8s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container1-1  Running                      0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l\u001b[34m[+] Running 2/2\u001b[0m\n",
"\u001b[34m ⠿ Container dockercomposefiles-container2-1  Started                     10.8s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container1-1  Running                      0.0s\n",
"\u001b[0m\u001b[?25h"
          ]
        }
      ],
      "source": [
      "!cd dockerComposeFiles && docker compose up -d"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We see that it has taken 10 seconds to mount the `container2` service, that's because it has been applying the changes\n",
"\n",
"````bash\n",
"$ docker compose exec container2 bash\n",
"root@d8777a4e611a:/# ls dockerOverrideFolder/\n",
"bindFile.txt fileExtract.txt text.txt\n",
"root@d8777a4e611a:/# cat dockerOverrideFolder/text.txt\n",
"hello compose\n",
"root@d8777a4e611a:/# exit\n",
"exit\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We download the compose and delete the containers and the created network."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Running 0/0\n",
"\u001b[37m ⠋ Container dockercomposefiles-container2-1  Stopping                     0.1s\n",
"\u001b[0m\u001b[37m ⠋ Container dockercomposefiles-container1-1  Stopping                     0.1s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠙ Container dockercomposefiles-container2-1  Stopping                     0.2s\n",
"\u001b[0m\u001b[37m ⠙ Container dockercomposefiles-container1-1  Stopping                     0.2s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠹ Container dockercomposefiles-container2-1  Stopping                     0.3s\n",
"\u001b[0m\u001b[37m ⠹ Container dockercomposefiles-container1-1  Stopping                     0.3s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠸ Container dockercomposefiles-container2-1  Stopping                     0.4s\n",
"\u001b[0m\u001b[37m ⠸ Container dockercomposefiles-container1-1  Stopping                     0.4s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠼ Container dockercomposefiles-container2-1  Stopping                     0.5s\n",
"\u001b[0m\u001b[37m ⠼ Container dockercomposefiles-container1-1  Stopping                     0.5s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠴ Container dockercomposefiles-container2-1  Stopping                     0.6s\n",
"\u001b[0m\u001b[37m ⠴ Container dockercomposefiles-container1-1  Stopping                     0.6s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠦ Container dockercomposefiles-container2-1  Stopping                     0.7s\n",
"\u001b[0m\u001b[37m ⠦ Container dockercomposefiles-container1-1  Stopping                     0.7s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠧ Container dockercomposefiles-container2-1  Stopping                     0.8s\n",
"\u001b[0m\u001b[37m ⠧ Container dockercomposefiles-container1-1  Stopping                     0.8s\n",
"...\n",
"\u001b[37m ⠸ Container dockercomposefiles-container2-1  Stopping                    10.4s\n",
"\u001b[0m\u001b[37m ⠸ Container dockercomposefiles-container1-1  Stopping                    10.4s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[34m ⠿ Container dockercomposefiles-container2-1  Removed                     10.4s\n",
"\u001b[0m\u001b[37m ⠿ Container dockercomposefiles-container1-1  Removing                    10.5s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l\u001b[34m[+] Running 2/2\u001b[0m\n",
"\u001b[34m ⠿ Container dockercomposefiles-container2-1  Removed                     10.4s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container1-1  Removed                     10.5s\n",
"\u001b[0m\u001b[37m ⠋ Network dockercomposefiles_default         Removing                     0.1s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l\u001b[34m[+] Running 3/3\u001b[0m\n",
"\u001b[34m ⠿ Container dockercomposefiles-container2-1  Removed                     10.4s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container1-1  Removed                     10.5s\n",
"\u001b[0m\u001b[34m ⠿ Network dockercomposefiles_default         Removed                      0.2s\n",
"\u001b[0m\u001b[?25h"
          ]
        }
      ],
      "source": [
      "!cd dockerComposeFiles && docker compose down"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "In this case, only with `down` docker compose has stopped and deleted everything, since, as we can see in the containers and in the network it says `Removed`."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Docker compose restart"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "When writing a docker compose, we can add the `restart` tag so that if the container crashes, it restarts automatically\n",
"\n",
"```json\n",
"restart: always\n",
"```\n",
"\n",
"This way, if the container crashes, it will restart automatically. If we want it to restart only a number of times, we can add the option `on-failure`.\n",
"\n",
"```json\n",
"restart: on-failure:<number>\n",
"```\n",
"\n",
"Now the container will restart a number of times, but if it crashes more times, it will not restart. If we want it to restart always, we can add the `unless-stopped` option to it.\n",
"\n",
"```json\n",
"restart: unless-stopped\n",
"```\n",
"\n",
"Now the container will always restart, unless it is manually stopped."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "## Advanced Docker"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Manage work environment"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "#### Deletion of containers that have been turned off"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "After a while of development, we can have several containers off, but saved on the computer. This eventually takes up memory, so with `docker contanier prune` we can delete all the ones that are stopped."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
      "!docker run ubuntu"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
          ]
        }
      ],
      "source": [
      "!docker ps"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND   CREATED          STATUS                      PORTS     NAMES\n",
"effcee24f54a   ubuntu    \"bash\"    37 seconds ago   Exited (0) 36 seconds ago             musing_rosalind\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "``` bash\n",
"$ docker container prune\n",
"WARNING! This will remove all stopped containers.\n",
"Are you sure you want to continue? [y/N] y\n",
"Deleted Containers:\n",
"effcee24f54aab22e34fdea2465b3b7af132d8c627e5432ba3e915a370876977\n",
"\n",
"Total reclaimed space: 0B\n",
"```\n",
"\n",
"In this case we have saved 0 bytes, but in the case of leaving containers off after a lot of development, the memory savings will certainly be greater."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "#### Deletion of all containers"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "In case we have containers running, we can kill all the containers by another command\n",
"\n",
"The command `docker ps -q` returns the id of all containers, so with the command `docker rm -f $(docker ps -aq)` we will stop and delete all containers."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "c22516186ef7e3561fb1ad0d508a914857dbc61274a218f297c4d80b1fc33863\n"
          ]
        }
      ],
      "source": [
      "!docker run -d ubuntu tail -f /dev/null"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND               CREATED              STATUS              PORTS     NAMES\n",
"c22516186ef7   ubuntu    \"tail -f /dev/null\"   About a minute ago   Up About a minute             agitated_knuth\n"
          ]
        }
      ],
      "source": [
      "!docker ps"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "c22516186ef7\n"
          ]
        }
      ],
      "source": [
      "!docker rm -f $(docker ps -aq)"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "#### Delete all"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "As we have seen docker also creates networks, images, volumes, etc, so with the command `docker system prune` we can delete all the stopped containers, all the networks that are not used by at least one container, the repeated images, and whatever is repeated in the compilation cache.\n",
"\n",
"``` bash\n",
"$ docker system prune\n",
"WARNING! This will remove:\n",
"  - all stopped containers\n",
"  - all networks not used by at least one container\n",
"  - all dangling images\n",
"  - all dangling build cache\n",
"\n",
"Are you sure you want to continue? [y/N] y\n",
"Total reclaimed space: 0B\n",
"```\n",
"\n",
"As before, not much space has been saved, but after a long time developing, the savings will be considerable."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Container use of host resources"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "For example when creating a container, we can limit the host RAM it can use by using the `--memory` option."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "d84888eafe531831ef8915d2270422365adec02678122bf59580e2da782e6972\n"
          ]
        }
      ],
      "source": [
      "!docker run -d --memory 1g ubuntu tail -f /dev/null"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "But with `docker ps` we do not have access to the resources being consumed by the container."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND               CREATED          STATUS          PORTS     NAMES\n",
"d84888eafe53   ubuntu    \"tail -f /dev/null\"   35 seconds ago   Up 34 seconds             musing_ritchie\n"
          ]
        }
      ],
      "source": [
      "!docker ps"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "For this we have the command `docker stats`.\n",
"\n",
"````bash\n",
"$ docker stats\n",
"CONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS\n",
"d84888eafe53 musing_ritchie 0.00% 540KiB / 1GiB 0.05% 5.62kB / 0B 0B / 0B 1\n",
"```\n",
"\n",
"This is very useful if we want to simulate an environment with a RAM limit."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Stopping containers correctly: SHELL vs EXEC"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "As we have explained, when we assign a process to a container, when that process ends, the container stops, but sometimes we can encounter problems with this. Let's create a new folder named Dockerfile_loop"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
      "!mkdir Dockerfile_loop"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Now let's create a file called `loop.sh` inside `Dockerfile_loop`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
      "!touch Dockerfile_loop/loop.sh"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "And we are going to write the following inside `loop.sh`\n",
"\n",
"``` shell\n",
"#!/usr/bin/env bash\n",
"trap \"exit 0\" SIGTERM\n",
"while true; do :; done\n",
"```\n",
"\n",
"If I run this script on the host it will run until I enter `CTRL+C`.\n",
"\n",
"\n",
"``` bash\n",
" ./loop\n",
" ^C\n",
" ```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Now let's create a `Dockerfile` file inside `Dockerfile_loop`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
      "!touch Dockerfile_loop/Dockerfile"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "*Dockerfile:\n",
"``` docker\n",
"FROM ubuntu:trusty\n",
"COPY [\"loop.sh\", \"/\"]\n",
"CMD /loop.sh\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We will create an ubuntu based image that copies the script inside and runs it, and the script runs until it receives the `SIGTERM` signal from the operating system. We compile the image"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Sending build context to Docker daemon  3.072kB\n",
"Step 1/3 : FROM ubuntu:trusty\n",
" ---> 13b66b487594\n",
"Step 2/3 : COPY [\"loop.sh\", \"/\"]\n",
" ---> 89f2bbd25a88\n",
"Step 3/3 : CMD /loop.sh\n",
" ---> Running in ff52569c35fd\n",
"Removing intermediate container ff52569c35fd\n",
" ---> feb091e4efa3\n",
"Successfully built feb091e4efa3\n",
"Successfully tagged ubuntu:loop\n",
"\n",
"Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\n"
          ]
        }
      ],
      "source": [
      "!docker build -t ubuntu:loop ./Dockerfile_loop"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We run the container\n",
"\n",
"``` bash\n",
"docker run -d --name looper ubuntu:loop bash\n",
"```"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "8a28f8cc9892213c4e0603dfdde320edf52c091b82c60510083549a391cd6645\n"
          ]
        }
      ],
      "source": [
      "!docker run -d --name looper ubuntu:loop"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We check and see that the container is running"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE         COMMAND                 CREATED         STATUS         PORTS     NAMES\n",
"8a28f8cc9892   ubuntu:loop   \"/bin/sh -c /loop.sh\"   4 seconds ago   Up 3 seconds             looper\n"
          ]
        }
      ],
      "source": [
      "!docker ps"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We try to stop the container with `docker stop looper`. Docker stop tries to stop the container by sending it the `SIGTERM` signal."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "looper\n",
"CPU times: user 89.2 ms, sys: 21.7 ms, total: 111 ms\n",
"Wall time: 10.6 s\n"
          ]
        }
      ],
      "source": [
      "%%time\n",
"!docker stop looper"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "This has taken about 10 seconds to stop, when it should be immediate. This is because `stop` has sent the `SIGTERM` command to stop the container, but as it did not stop, after a while it has sent a `SIGKILL` to force it to stop. Let's see what happens, if we list the containers"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE         COMMAND                 CREATED          STATUS                       PORTS     NAMES\n",
"8a28f8cc9892   ubuntu:loop   \"/bin/sh -c /loop.sh\"   23 seconds ago   Exited (137) 2 seconds ago             looper\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We can see that the `Exited` signal is `137`, that means SIGKILL, that is, docker had to force the shutdown."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Let's delete the container and run it again."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "looper\n"
          ]
        }
      ],
      "source": [
      "!docker rm looper"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "84bc37f944d270be5f84a952968db2b8cf5372c61146d29383468198ceed18fd\n"
          ]
        }
      ],
      "source": [
      "!docker run -d --name looper ubuntu:loop"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If we now try to stop the container with `docker kill looper`, we will try to stop the container with `docker kill looper`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "looper\n",
"CPU times: user 9.1 ms, sys: 857 µs, total: 9.96 ms\n",
"Wall time: 545 ms\n"
          ]
        }
      ],
      "source": [
      "%%time\n",
"!docker kill looper"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We see that the time is about 500 ms, that is to say, docker has stopped it in a moment by sending the `SIGKILL` command. Because `kill` does not send `SIGTERM` and if in a time the container has not stopped sending `SIGKILL`, what it does is to send `SIGKILL` from the beginning.\n",
"\n",
"If we look at the containers, we see that the output signal is the same, `137`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE         COMMAND                 CREATED         STATUS                       PORTS     NAMES\n",
"84bc37f944d2   ubuntu:loop   \"/bin/sh -c /loop.sh\"   6 seconds ago   Exited (137) 2 seconds ago             looper\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "This is not the correct way to shut down a container, because when we want to shut down the container we would have to do it through the `SIGTERM` signal, so that it finishes processing what it was doing and then it shuts down."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If we delete the container and run it again"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "looper\n"
          ]
        }
      ],
      "source": [
      "!docker rm looper"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "b9d9f370cc0de7569eb09d0a85cd67e8ea6babc0754a517ccba5c5057f5cc50e\n"
          ]
        }
      ],
      "source": [
      "!docker run -d --name looper ubuntu:loop"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If we now look at the processes that are running inside the container"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "UID          PID    PPID  C STIME TTY          TIME CMD\n",
"root           1       0  0 14:05 ?        00:00:00 /bin/sh -c /loop.sh\n",
"root           7       1 93 14:05 ?        00:00:02 bash /loop.sh\n",
"root           8       0  0 14:05 ?        00:00:00 ps -ef\n"
          ]
        }
      ],
      "source": [
      "!docker exec looper ps -ef"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Actually the main process, the 1, is not `/loop.sh` but it is `/bin/sh -c /loop.sh`, that is to say, it is a child process of `shell`. So when the `SIGTERM` signal arrived to `shell`, but this one does not send it to its child processes, that is why it did not arrive to `loop.sh`."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "To prevent this from happening, you must change the `Dockerfile` to the following\n",
"\n",
"*Dockerfile:\n",
"``` docker\n",
"FROM ubuntu:trusty\n",
"COPY [\"loop.sh\", \"/\"]\n",
"CMD [\"/loop.sh\"] # previously CMD /loop.sh\n",
"```\n",
"\n",
"This form is called `exec form`, while the previous form is called `shell form`, so the previous form runs the process as a child of the `shell`, while the `exec form` runs the process we tell it to. So we delete the container, compile again and run the container with the image again."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "looper\n"
          ]
        }
      ],
      "source": [
      "!docker rm -f looper"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Sending build context to Docker daemon  3.072kB\n",
"Step 1/3 : FROM ubuntu:trusty\n",
" ---> 13b66b487594\n",
"Step 2/3 : COPY [\"loop.sh\", \"/\"]\n",
" ---> Using cache\n",
" ---> 89f2bbd25a88\n",
"Step 3/3 : CMD [\"/loop.sh\"]\n",
" ---> Running in 6b8d92fcd57c\n",
"Removing intermediate container 6b8d92fcd57c\n",
" ---> 35a7bb2b1892\n",
"Successfully built 35a7bb2b1892\n",
"Successfully tagged ubuntu:loop\n",
"\n",
"Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\n"
          ]
        }
      ],
      "source": [
      "!docker build -t ubuntu:loop ./Dockerfile_loop"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "850ae70c071426850b28428ac60dcbf875c6d35d9b7cc66c17cf391a23392965\n"
          ]
        }
      ],
      "source": [
      "!docker run -d --name looper ubuntu:loop"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If I now see the processes inside the container"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "UID          PID    PPID  C STIME TTY          TIME CMD\n",
"root           1       0 88 14:14 ?        00:00:02 bash /loop.sh\n",
"root           7       0  0 14:14 ?        00:00:00 ps -ef\n"
          ]
        }
      ],
      "source": [
      "!docker exec looper ps -ef"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Now I see that the main process, the 1, is `/loop.sh`.\n",
"\n",
"If I now try to stop the container"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "looper\n",
"CPU times: user 989 µs, sys: 7.55 ms, total: 8.54 ms\n",
"Wall time: 529 ms\n"
          ]
        }
      ],
      "source": [
      "%%time\n",
"!docker stop looper"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We see that it takes ms. Let's see the code it stopped with"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE         COMMAND      CREATED              STATUS                      PORTS     NAMES\n",
"850ae70c0714   ubuntu:loop   \"/loop.sh\"   About a minute ago   Exited (0) 33 seconds ago             looper\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Executable containers"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If we want a binary to run as an executable, in the `dockerfile` we have to specify the command in `ENTRYPOINT` and the command parameters in `CMD`, let's see it"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Let's create a new folder where we will save the `Dockerfile`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
      "!mkdir dockerfile_ping"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Now we create a Dockerfile inside"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
      "!touch dockerfile_ping/Dockerfile"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We write the following inside the Dockerfile\n",
"\n",
"``` docker\n",
"FROM ubuntu:trusty\n",
"ENTRYPOINT [ \"/bin/ping\", \"-c\", \"3\" ]\n",
"CMD [ \"localhost\" ]\n",
"```\n",
"\n",
"We compile the image"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Sending build context to Docker daemon  3.072kB\n",
"Step 1/3 : FROM ubuntu:trusty\n",
" ---> 13b66b487594\n",
"Step 2/3 : ENTRYPOINT [ \"/bin/ping\", \"-c\", \"3\" ]\n",
" ---> Using cache\n",
" ---> 1cebcfb542b1\n",
"Step 3/3 : CMD [ \"localhost\" ]\n",
" ---> Using cache\n",
" ---> 04ddc3de52a2\n",
"Successfully built 04ddc3de52a2\n",
"Successfully tagged ubuntu:ping\n",
"\n",
"Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\n"
          ]
        }
      ],
      "source": [
      "!docker build -t ubuntu:ping ./dockerfile_ping"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If we now run the image without passing a parameter to it, the container will ping itself"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "PING localhost (127.0.0.1) 56(84) bytes of data.\n",
"64 bytes from localhost (127.0.0.1): icmp_seq=1 ttl=64 time=0.041 ms\n",
"64 bytes from localhost (127.0.0.1): icmp_seq=2 ttl=64 time=0.058 ms\n",
"64 bytes from localhost (127.0.0.1): icmp_seq=3 ttl=64 time=0.054 ms\n",
"\n",
"--- localhost ping statistics ---\n",
"3 packets transmitted, 3 received, 0% packet loss, time 2027ms\n",
"rtt min/avg/max/mdev = 0.041/0.051/0.058/0.007 ms\n"
          ]
        }
      ],
      "source": [
      "!docker run --name ping_localhost ubuntu:ping"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "But if we now pass it a parameter, it will ping the address we tell it to ping to"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "PING google.com (216.58.209.78) 56(84) bytes of data.\n",
"64 bytes from waw02s06-in-f14.1e100.net (216.58.209.78): icmp_seq=1 ttl=111 time=3.93 ms\n",
"64 bytes from waw02s06-in-f14.1e100.net (216.58.209.78): icmp_seq=2 ttl=111 time=6.80 ms\n",
"64 bytes from waw02s06-in-f14.1e100.net (216.58.209.78): icmp_seq=3 ttl=111 time=6.92 ms\n",
"\n",
"--- google.com ping statistics ---\n",
"3 packets transmitted, 3 received, 0% packet loss, time 2002ms\n",
"rtt min/avg/max/mdev = 3.930/5.886/6.920/1.383 ms\n"
          ]
        }
      ],
      "source": [
      "!docker run --name ping_google ubuntu:ping google.com"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We erase the containers"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "ping_localhost\n",
"ping_google\n"
          ]
        }
      ],
      "source": [
      "!docker rm ping_localhost ping_google"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### The `build` context"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Let's create a folder called `dockerfile_context`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
      "!mkdir dokerfile_contexto"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Now we create two files in it, a `test.txt` and the `Dockerfile`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
      "!touch dokerfile_contexto/Dockerfile dokerfile_contexto/text.txt"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Modify the Dockerfile and add the following\n",
"\n",
"``` docker\n",
"FROM ubuntu:trusty\n",
"COPY [\".\", \"/\"]\n",
"```\n",
"\n",
"What this is going to do is that it is going to copy inside the image, everything that it has in the folder where the `Dockerfile` is located. We compile the image"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Sending build context to Docker daemon   2.56kB\n",
"Step 1/2 : FROM ubuntu:trusty\n",
" ---> 13b66b487594\n",
"Step 2/2 : COPY [\".\", \"/\"]\n",
" ---> 3ab79fdce389\n",
"Successfully built 3ab79fdce389\n",
"Successfully tagged ubuntu:contexto\n",
"\n",
"Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\n"
          ]
        }
      ],
      "source": [
      "!docker build -t ubuntu:contexto ./dokerfile_contexto"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Let's see what's inside the container"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Dockerfile\n",
"bin\n",
"boot\n",
"dev\n",
"etc\n",
"home\n",
"lib\n",
"lib64\n",
"media\n",
"mnt\n",
"opt\n",
"proc\n",
"root\n",
"run\n",
"sbin\n",
"srv\n",
"sys\n",
"text.txt\n",
"tmp\n",
"usr\n",
"var\n"
          ]
        }
      ],
      "source": [
      "!docker run --name ls ubuntu:contexto ls"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "As we can see there is the `text.txt` file. But maybe inside the folder that is in the same directory as the `Dockerfile` there are files or folders that we do not want to be copied in the image, for whatever reason, so just as in git we have the `.gitignore`, in docker we have the `.dockerignore`, where we put the files or folders that we do not want to be taken into account when compiling.\n",
"\n",
"So we create a `.dockerignore` file"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
      "!touch dokerfile_contexto/.dockerignore"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "And inside we add the `text.txt`, and by the way the `Dockerfile` that we don`t need inside the image\n",
"\n",
"*.dockerignore*:\n",
"```\n",
"Dockerfile\n",
"text.txt\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We delete the container we created, compile again and see what is inside the container."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "ls\n"
          ]
        }
      ],
      "source": [
      "!docker rm ls"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Sending build context to Docker daemon  3.072kB\n",
"Step 1/2 : FROM ubuntu:trusty\n",
" ---> 13b66b487594\n",
"Step 2/2 : COPY [\".\", \"/\"]\n",
" ---> 7a6689546da4\n",
"Successfully built 7a6689546da4\n",
"Successfully tagged ubuntu:contexto\n",
"\n",
"Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\n"
          ]
        }
      ],
      "source": [
      "!docker build -t ubuntu:contexto ./dokerfile_contexto"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "bin\n",
"boot\n",
"dev\n",
"etc\n",
"home\n",
"lib\n",
"lib64\n",
"media\n",
"mnt\n",
"opt\n",
"proc\n",
"root\n",
"run\n",
"sbin\n",
"srv\n",
"sys\n",
"tmp\n",
"usr\n",
"var\n"
          ]
        }
      ],
      "source": [
      "!docker run --name ls ubuntu:contexto ls"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We see that now neither `Dockerfile`, nor `text.txt` are there. We delete the container"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "ls\n"
          ]
        }
      ],
      "source": [
      "!docker rm ls"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Multi-stage build"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "At the end of a development we do not want all the code to be in the image to be sent to production.\n",
"\n",
"We can divide the `dockerfile` in two, for example, the `developer.Dockerfile` and the `production.Dockerfile`, where in development there will be more things than in production. When compiling them, using the `-f` option we choose the `dockerfile` we want to use\n",
"\n",
"``` bash\n",
"docker build -t <tag> -f developer.Dockerfile\n",
"docker build -t <tag> -f production.Dockerfile\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "But to avoid having to create two `Dockerfile` files, docker created the `multi stage buils`. With a single `Dockerfile` we will solve the problem."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Create the folder where we are going to save the `Dockerfile`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
      "!mkdir docker_multi_stage"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "And inside we create the file `Dockerfile`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
      "!cd docker_multi_stage && touch Dockerfile"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Edit the file by inserting the following\n",
"\n",
"``` dockerfile\n",
"# Step 1: Generate the executable with Python based on Alpine\n",
"FROM python:3.9-alpine as build-stage\n",
"WORKDIR /app\n",
"# Install dependencies for PyInstaller\n",
"RUN apk apk add --no-cache gcc musl-dev libc-dev\n",
"# Generate hello.py\n",
"RUN echo 'print(\"Hello from Alpine!\")' > hello.py\n",
"# Install PyInstaller\n",
"RUN pip install pyinstaller\n",
"# Using PyInstaller to create a standalone executable\n",
"RUN pyinstaller --onefile hello.py\n",
"\n",
"# Step 2: Run the executable on an Alpine image\n",
"FROM alpine:latest\n",
"WORKDIR /app\n",
"# Copy the executable from the build stage\n",
"COPY --from=build-stage /app/dist/hello .\n",
"# Default command to run the executable\n",
"CMD [\"./hello\"]\n",
"```\n",
"\n",
"As you can see the `Dockerfile` is divided in two, on one side we work on the `python:3.9-alpine` image which is called as `build-stage`. And on the other hand we work on the `alpine:latest` image, which is a very light linux image and is widely used in production.\n",
"\n",
"We compile it"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/2)                                          docker:default\n",
"\u001b[?25h"
          ]
        },
{
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.2s (4/6)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 722B                                       0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/alpine:latest           0.1s\n",
" => [internal] load metadata for docker.io/library/python:3.9-alpine       0.1s\n",
"...\n",
"\u001b[0m\u001b[34m => CACHED [stage-1 3/3] COPY --from=build-stage /app/dist/hello .         0.0s\n",
"\u001b[0m\u001b[34m => exporting to image                                                     0.0s\n",
"\u001b[0m\u001b[34m => => exporting layers                                                    0.0s\n",
"\u001b[0m\u001b[34m => => writing image sha256:7fb090d1495d00e892118b6bc3c03400b63a435fd4703  0.0s\n",
"\u001b[0m\u001b[34m => => naming to docker.io/maximofn/multistagebuild:latest                 0.0s\n",
"\u001b[0m\u001b[?25h"
          ]
        }
      ],
      "source": [
      "!docker build -t maximofn/multistagebuild:latest ./docker_multi_stage"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If we now look at the images we have"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "REPOSITORY                 TAG       IMAGE ID       CREATED         SIZE\n",
"maximofn/multistagebuild   latest    7fb090d1495d   8 minutes ago   13.6MB\n"
          ]
        }
      ],
      "source": [
      "!docker image ls"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We can see the image we just created and it only weighs 13.6 MB. Let's download the image from Python to see how much it weighs"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "3.9-alpine: Pulling from library/python\n",
"\n",
"\u001b[1Ba8db6415: Already exists \n",
"\u001b[1Bd5e70e42: Already exists \n",
"\u001b[1B3fe96417: Already exists \n",
"\u001b[1Baa4dddbb: Already exists \n",
"\u001b[1B518be9f7: Already exists Digest: sha256:6e508b43604ff9a81907ec17405c9ad5c13664e45a5affa2206af128818c7486\n",
"Status: Downloaded newer image for python:3.9-alpine\n",
"docker.io/library/python:3.9-alpine\n"
          ]
        }
      ],
      "source": [
      "!docker pull python:3.9-alpine"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "REPOSITORY                 TAG          IMAGE ID       CREATED         SIZE\n",
"maximofn/multistagebuild   latest       7fb090d1495d   9 minutes ago   13.6MB\n",
"python                     3.9-alpine   6946662f018b   9 days ago      47.8MB\n"
          ]
        }
      ],
      "source": [
      "!docker image ls"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We can see that while our image weighs only 13.6 MB, the python image with which he has built the application weighs 47.8 MB. So we can draw two conclusions, with the first image, the python one, he has built the application, he has generated the executable and that executable is the one we use in the second image, the alpine one. In addition we can see that although the first image that uses is the one of python, it is not downloaded in our system, since we have had to download it ourselves."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "All that remains is to test it"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Hello from Alpine!\n"
          ]
        }
      ],
      "source": [
      "!docker run --rm --name multi_stage_build maximofn/multistagebuild"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "It works!"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Multi arch builds"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Suppose we want to make an image that we want to be able to run on a computer and on a raspberry, the computer probably has a micro with AMD64 architecture, while the raspberry has a micro with ARM architecture. So we cannot create the same image for both, that is, when we create an image we create it with a `Dockerfile` that usually starts like this\n",
"\n",
"``` Dockerfile\n",
"FROM ...\n",
"```\n",
"\n",
"So the `Dockerfile` of the computer image could start like this\n",
"\n",
"``` Dockerfile\n",
"FROM ubuntu:latest\n",
"```\n",
"\n",
"While the raspberry's could start like this.\n",
"\n",
"``` Dockerfile\n",
"FROM arm64v8/ubuntu:latest\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We would have to create two `Dockerfile` files compile them and on the computer use one image and on the raspebrry use another one."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "To avoid having to see the computer architecture and see what image we have to use Docker I create the `manifest`, which as its name suggests is a manifest that indicates depending on what micro architecture we have uses one image or another."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "So let's see how to do this"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "First we create a folder where we are going to create our `Dockerfile` files."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
      "!mkdir docker_multi_arch"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Now we create the two dockerfiles"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
      "!cd docker_multi_arch && touch Dockerfile_arm64 Dockerfile_amd64"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We write from the `Dockerfile` for AMD64"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
      "!cd docker_multi_arch && echo \"FROM ubuntu:20.04\" >> Dockerfile_amd64 && echo \"CMD echo 'Hello from amd64'\" >> Dockerfile_amd64"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
      "!cd docker_multi_arch && echo \"FROM arm64v8/ubuntu:latest\" >> Dockerfile_arm && echo \"CMD echo 'Hello from ARM'\" >> Dockerfile_arm"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We now compile the two images"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/1)                                          docker:default\n",
"\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.2s (2/3)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/ubuntu:20.04            0.1s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.3s (2/3)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/ubuntu:20.04            0.2s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.5s (2/3)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/ubuntu:20.04            0.4s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.6s (2/3)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/ubuntu:20.04            0.5s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.7s (2/4)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/ubuntu:20.04            0.6s\n",
" => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.9s (3/4)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/ubuntu:20.04            0.8s\n",
"\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.0s (3/4)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/ubuntu:20.04            0.9s\n",
"\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.2s (3/4)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/ubuntu:20.04            1.1s\n",
"\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.3s (3/4)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/ubuntu:20.04            1.2s\n",
"\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.5s (3/4)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/ubuntu:20.04            1.4s\n",
"\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.6s (3/4)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/ubuntu:20.04            1.5s\n",
"\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.8s (3/4)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/ubuntu:20.04            1.7s\n",
"\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.9s (3/4)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/ubuntu:20.04            1.8s\n",
"\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.1s (3/4)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.0s\n",
"\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.2s (3/4)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.1s\n",
"\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.4s (3/4)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.3s\n",
"\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.5s (3/4)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.4s\n",
"\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.7s (3/4)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.6s\n",
"\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.8s (4/4)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.9s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.1s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b11063bc4 0B / 27.51MB  0.1s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.0s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.2s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b11063bc4 0B / 27.51MB  0.2s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.1s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.3s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b11063bc4 0B / 27.51MB  0.3s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.3s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.5s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b11063bc4 0B / 27.51MB  0.4s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.4s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.6s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b11063bc4 0B / 27.51MB  0.6s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.5s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.7s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b11063bc4 0B / 27.51MB  0.7s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.7s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.9s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b11063bc4 0B / 27.51MB  0.8s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.8s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  1.0s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b1106 1.05MB / 27.51MB  1.0s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 4.0s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  1.2s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b1106 1.05MB / 27.51MB  1.1s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 4.1s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  1.3s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b1106 2.10MB / 27.51MB  1.3s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 4.2s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  1.4s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b1106 2.10MB / 27.51MB  1.4s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 4.4s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  1.6s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b1106 2.10MB / 27.51MB  1.5s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 4.5s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  1.7s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b1106 3.15MB / 27.51MB  1.7s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 4.6s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  1.8s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b1106 3.15MB / 27.51MB  1.8s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 4.8s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  2.0s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b1106 4.19MB / 27.51MB  1.9s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 4.9s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  2.1s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b1106 4.19MB / 27.51MB  2.1s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 5.0s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  2.2s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b1106 5.24MB / 27.51MB  2.2s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 5.2s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  2.4s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b1106 5.24MB / 27.51MB  2.3s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 5.3s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  2.5s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b1106 6.29MB / 27.51MB  2.5s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 5.4s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  2.6s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b1106 6.29MB / 27.51MB  2.6s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 5.6s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  2.8s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b1106 6.29MB / 27.51MB  2.7s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 5.7s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  2.9s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b1106 7.34MB / 27.51MB  2.9s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 5.8s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  3.0s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b1106 8.39MB / 27.51MB  3.0s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 6.0s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  3.2s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b1106 8.39MB / 27.51MB  3.1s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 6.1s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  3.3s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b1106 9.44MB / 27.51MB  3.3s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 6.3s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  3.5s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b1106 9.44MB / 27.51MB  3.4s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 6.4s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  3.6s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 10.49MB / 27.51MB  3.6s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 6.5s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  3.7s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 10.49MB / 27.51MB  3.7s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 6.6s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  3.8s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 11.53MB / 27.51MB  3.8s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 6.8s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  4.0s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 11.53MB / 27.51MB  3.9s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 6.9s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  4.1s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 12.58MB / 27.51MB  4.1s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 7.1s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  4.3s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 12.58MB / 27.51MB  4.2s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 7.2s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  4.4s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 13.63MB / 27.51MB  4.4s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 7.4s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  4.6s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 14.68MB / 27.51MB  4.5s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 7.5s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  4.7s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 15.73MB / 27.51MB  4.7s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 7.6s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  4.8s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 15.73MB / 27.51MB  4.8s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 7.8s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  5.0s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 16.78MB / 27.51MB  4.9s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 7.9s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  5.1s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 16.78MB / 27.51MB  5.1s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 8.1s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  5.3s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 17.83MB / 27.51MB  5.2s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 8.2s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  5.4s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 18.87MB / 27.51MB  5.4s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 8.4s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  5.6s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 19.92MB / 27.51MB  5.5s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 8.5s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  5.7s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 19.92MB / 27.51MB  5.7s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 8.7s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  5.9s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 20.97MB / 27.51MB  5.8s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 8.8s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  6.0s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 22.02MB / 27.51MB  6.0s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 8.9s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  6.1s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 23.07MB / 27.51MB  6.1s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 9.1s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  6.3s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 23.07MB / 27.51MB  6.2s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 9.2s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  6.4s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 24.12MB / 27.51MB  6.4s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 9.3s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  6.5s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 25.17MB / 27.51MB  6.5s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 9.5s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  6.7s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 25.17MB / 27.51MB  6.6s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 9.6s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  6.8s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 26.21MB / 27.51MB  6.8s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 9.7s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  6.9s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 27.26MB / 27.51MB  6.9s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 9.8s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  7.0s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 27.51MB / 27.51MB  7.0s\n",
"\u001b[0m => => extracting sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b11063bc445  0.0s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 9.9s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  7.1s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 27.51MB / 27.51MB  7.0s\n",
"\u001b[0m => => extracting sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b11063bc445  0.1s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 10.0s (4/5)                                         docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  7.2s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 27.51MB / 27.51MB  7.0s\n",
"\u001b[0m => => extracting sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b11063bc445  0.2s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 10.1s (4/5)                                         docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  7.4s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 27.51MB / 27.51MB  7.0s\n",
"\u001b[0m => => extracting sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b11063bc445  0.3s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 10.3s (4/5)                                         docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  7.5s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 27.51MB / 27.51MB  7.0s\n",
"\u001b[0m => => extracting sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b11063bc445  0.4s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 10.4s (4/5)                                         docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  7.6s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 27.51MB / 27.51MB  7.0s\n",
"\u001b[0m => => extracting sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b11063bc445  0.5s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 10.5s (4/5)                                         docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  7.7s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 27.51MB / 27.51MB  7.0s\n",
"\u001b[0m => => extracting sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b11063bc445  0.6s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 10.6s (4/5)                                         docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  7.8s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 27.51MB / 27.51MB  7.0s\n",
"\u001b[0m\u001b[34m => => extracting sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b11063bc445  0.7s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 10.7s (5/5)                                         docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[34m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  7.9s\n",
"\u001b[0m\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 27.51MB / 27.51MB  7.0s\n",
"\u001b[0m\u001b[34m => => extracting sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b11063bc445  0.7s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 10.8s (6/6) FINISHED                                docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[34m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  7.9s\n",
"\u001b[0m\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 27.51MB / 27.51MB  7.0s\n",
"\u001b[0m\u001b[34m => => extracting sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b11063bc445  0.7s\n",
"\u001b[0m\u001b[34m => exporting to image                                                     0.0s\n",
"\u001b[0m\u001b[34m => => exporting layers                                                    0.0s\n",
"\u001b[0m\u001b[34m => => writing image sha256:5b612c83025ff77a7237d662357a1b7f07ff1bfb4aadf  0.0s\n",
"\u001b[0m\u001b[34m => => naming to docker.io/maximofn/multiarch:amd64                        0.0s\n",
"\u001b[0m\u001b[?25h"
          ]
        }
      ],
      "source": [
      "!cd docker_multi_arch && docker build -t maximofn/multiarch:amd64 -f Dockerfile_amd64 ."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/1)                                          docker:default\n",
"\u001b[?25h"
          ]
        },
{
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.2s (2/3)                                          docker:default\n",
"\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile_arm                   0.0s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 94B                                        0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/arm64v8/ubuntu:latest           0.1s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.3s (2/3)                                          docker:default\n",
"\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile_arm                   0.0s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 94B                                        0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/arm64v8/ubuntu:latest           0.3s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.5s (2/3)                                          docker:default\n",
"\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile_arm                   0.0s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 94B                                        0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/arm64v8/ubuntu:latest           0.4s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.6s (2/3)                                          docker:default\n",
"\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile_arm                   0.0s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 94B                                        0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/arm64v8/ubuntu:latest           0.6s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.8s (2/3)                                          docker:default\n",
"\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile_arm                   0.0s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 94B                                        0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/arm64v8/ubuntu:latest           0.7s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.9s (2/4)                                          docker:default\n",
"\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile_arm                   0.0s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 94B                                        0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/arm64v8/ubuntu:latest           0.8s\n",
" => [auth] arm64v8/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.0s (3/4)                                          docker:default\n",
"\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile_arm                   0.0s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 94B                                        0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/arm64v8/ubuntu:latest           1.0s\n",
"\u001b[34m => [auth] arm64v8/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.2s (3/4)                                          docker:default\n",
"\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile_arm                   0.0s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 94B                                        0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/arm64v8/ubuntu:latest           1.1s\n",
"\u001b[34m => [auth] arm64v8/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.3s (3/4)                                          docker:default\n",
"\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile_arm                   0.0s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 94B                                        0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/arm64v8/ubuntu:latest           1.3s\n",
"\u001b[34m => [auth] arm64v8/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.5s (3/4)                                          docker:default\n",
"\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile_arm                   0.0s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 94B                                        0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/arm64v8/ubuntu:latest           1.4s\n",
"\u001b[34m => [auth] arm64v8/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.6s (3/4)                                          docker:default\n",
"\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile_arm                   0.0s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 94B                                        0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/arm64v8/ubuntu:latest           1.6s\n",
"\u001b[34m => [auth] arm64v8/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.8s (3/4)                                          docker:default\n",
"\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile_arm                   0.0s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 94B                                        0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/arm64v8/ubuntu:latest           1.7s\n",
"\u001b[34m => [auth] arm64v8/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.9s (6/6) FINISHED                                 docker:default\n",
"\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile_arm                   0.0s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 94B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/arm64v8/ubuntu:latest           1.8s\n",
"\u001b[0m\u001b[34m => [auth] arm64v8/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[34m => CACHED [1/1] FROM docker.io/arm64v8/ubuntu:latest@sha256:94d12db896d0  0.0s\n",
"\u001b[0m\u001b[34m => exporting to image                                                     0.0s\n",
"\u001b[0m\u001b[34m => => exporting layers                                                    0.0s\n",
"\u001b[0m\u001b[34m => => writing image sha256:a9732c1988756dc8e836fd96e5c9512e349c97ea5af46  0.0s\n",
"\u001b[0m\u001b[34m => => naming to docker.io/maximofn/multiarch:arm                          0.0s\n",
"\u001b[0m\u001b[?25h"
          ]
        }
      ],
      "source": [
      "!cd docker_multi_arch && docker build -t maximofn/multiarch:arm -f Dockerfile_arm ."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Let's see that we have the compiled ods images"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "REPOSITORY           TAG       IMAGE ID       CREATED       SIZE\n",
"maximofn/multiarch   arm       a9732c198875   4 weeks ago   69.2MB\n",
"maximofn/multiarch   amd64     5b612c83025f   6 weeks ago   72.8MB\n"
          ]
        }
      ],
      "source": [
      "!docker image ls"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We see that we have compiled the two images. In order to create a manifest, we first have to upload the images to docker hub, so we upload them"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "The push refers to repository [docker.io/maximofn/multiarch]\n",
"\n",
"\u001b[1B82bdeb5f: Mounted from library/ubuntu amd64: digest: sha256:30e820f2a11a24ad4d8fb624ae485f7c1bcc299e8cfc72c88adce1acd0447e1d size: 529\n"
          ]
        }
      ],
      "source": [
      "!docker push maximofn/multiarch:amd64"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "The push refers to repository [docker.io/maximofn/multiarch]\n"
          ]
        },
{
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "\n",
"\u001b[1Beda53374: Layer already exists arm: digest: sha256:6ec5a0752d49d3805061314147761bf25b5ff7430ce143adf34b70d4eda15fb8 size: 529\n"
          ]
        }
      ],
      "source": [
      "!docker push maximofn/multiarch:arm"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If I go to my docker hub I can see that my `maximofn/multiarch` image has the tags `amd64` and `arm`.\n",
"\n",
"![docker_multi_arch_tags](https://maximofn.com/wp-content/uploads/2023/09/docker_multi_arch_tags.png)"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Now we are going to create the `manifest` based on these two images"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Created manifest list docker.io/maximofn/multiarch:latest\n"
          ]
        }
      ],
      "source": [
      "!docker manifest create maximofn/multiarch:latest maximofn/multiarch:amd64 maximofn/multiarch:arm"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Once created, we have to indicate the architectures of the CPUs to which each one corresponds"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
      "!docker manifest annotate maximofn/multiarch:latest maximofn/multiarch:amd64 --os linux --arch amd64"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "manifest for image maximofn/multiarch:arm64 does not exist in maximofn/multiarch:latest\n"
          ]
        }
      ],
      "source": [
      "!docker manifest annotate maximofn/multiarch:latest maximofn/multiarch:arm64 --os linux --arch arm64"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Once created and annotated we can upload the `manifest` to docker hub"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "sha256:1ea28e9a04867fe0e0d8b0efa455ce8e4e29e7d9fd4531412b75dbd0325e9304\n"
          ]
        }
      ],
      "source": [
      "!docker manifest push maximofn/multiarch:latest"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If I now look at the tags that my `maximofn/multiarch` image has, I also see the `latest` tag.\n",
"\n",
"![docker_multi_arch_tags_manifest](https://maximofn.com/wp-content/uploads/2023/09/docker_multi_arch_tags_manifest.png)"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Now, whether I want to use my image from a machine with AMD64 CPU or ARM CPU by doing `FROM maximofn/multiarch:latest`, docker will check the CPU architecture and pull down the `amd64` tag or the `arm` tag. Let's see it, if from my computer I run the image I get"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Unable to find image 'maximofn/multiarch:latest' locally\n"
          ]
        },
{
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "latest: Pulling from maximofn/multiarch\n",
"Digest: sha256:7cef0de10f7fa2b3b0dca0fbf398d1f48af17a0bbc5b9beca701d7c427c9fd84\n",
"Status: Downloaded newer image for maximofn/multiarch:latest\n",
"Hello from amd64\n"
          ]
        }
      ],
      "source": [
      "!docker run maximofn/multiarch:latest"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "As it does not have it, it downloads it and then the text `Hello from amd64` appears, since the CPU of my computer has an AMD64 architecture."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "If I now connect via ssh to a raspberry pi and try the same thing I get\n",
"\n",
"````bash\n",
"raspiberry@raspberrypi:~ $ docker run maximofn/multiarch:latest\n",
"    Unable to find image 'maximofn/multiarch:latest' locally\n",
"    latest: Pulling from maximofn/multiarch\n",
"    Digest: sha256:1ea28e9a04867fe0e0d8b0efa455ce8e4e29e7d9fd4531412b75dbd0325e9304\n",
"    Status: Downloaded newer image for maximofn/multiarch:latest\n",
"    Hello from ARM\n",
"```\n",
"\n",
"The `Hello from ARM` appears as the raspberry has a micro with ARM architecture."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "As you can see, each machine has downloaded the image it needed."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Correct writing of advanced Dockerfiles"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We have already seen how to write dockerfiles correctly, but there is one more thing we can do now that we know the multi-stage build and that is to create a container to create the executable and a smaller one to run it in\n",
"\n",
"We came to the conclusion that a good dockerfile could be this one\n",
"\n",
"``` Dockerfile\n",
"FROM python:3.9.18-alpine\n",
"WORKDIR /sourceCode/sourceApp\n",
"COPY ./sourceCode/sourceApp .\n",
"CMD [\"python3\", \"app.py\"]\n",
"```\n",
"\n",
"Let's now create an executable in a builder container and run it in a smaller container\n",
"\n",
"``` dockerfile\n",
"FROM python:3.9.18-alpine as builder\n",
"WORKDIR /sourceCode/sourceApp\n",
"RUN apk add --no-cache gcc musl-dev libc-dev && pip install pyinstaller\n",
"COPY ./sourceCode/sourceApp .\n",
"RUN pyinstaller --onefile app.py\n",
"\n",
"FROM alpine:3.18.3\n",
"WORKDIR /sourceCode/sourceApp\n",
"COPY --from=builder /sourceCode/sourceApp/dist/app .\n",
"CMD [\"./app\"]\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We create the python code in the necessary path"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
      "!mkdir multistagebuild/sourceCode\n",
"!mkdir multistagebuild/sourceCode/sourceApp\n",
"!touch multistagebuild/sourceCode/sourceApp/app.py\n",
"!echo 'print(\"Hello from Alpine!\")' > multistagebuild/sourceCode/sourceApp/app.py"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Now we compile the image"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/0)                                          docker:default\n",
"\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.0s (0/1)                                          docker:default\n",
"\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.2s (3/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile                       0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 357B                                       0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/alpine:3.18.3           0.1s\n",
" => [internal] load metadata for docker.io/library/python:3.9.18-alpine    0.1s\n",
"\u001b[34m => [auth] library/alpine:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.3s (3/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile                       0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 357B                                       0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/alpine:3.18.3           0.2s\n",
" => [internal] load metadata for docker.io/library/python:3.9.18-alpine    0.2s\n",
"\u001b[34m => [auth] library/alpine:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.5s (4/6)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile                       0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 357B                                       0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/alpine:3.18.3           0.4s\n",
"...\n",
"\u001b[0m\u001b[34m => exporting to image                                                     0.1s\n",
"\u001b[0m\u001b[34m => => exporting layers                                                    0.1s\n",
"\u001b[0m\u001b[34m => => writing image sha256:8a22819145c6fee17e138e818610ccf46d7e13c786825  0.0s\n",
"\u001b[0m\u001b[34m => => naming to docker.io/maximofn/multistagebuild:alpine-3.18.3          0.0s\n",
"\u001b[0m\u001b[?25h"
          ]
        }
      ],
      "source": [
      "!docker build -t maximofn/multistagebuild:alpine-3.18.3 ./multistagebuild"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We run it"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Hello from Alpine!\n"
          ]
        }
      ],
      "source": [
      "!docker run --rm --name multi_stage_build maximofn/multistagebuild:alpine-3.18.3"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "The `maximofn/multistagebuild:alpine-3.18.3` image weighs only 13.6 MB"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Difference between RUN, CMD and ENTRYPOINT"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "#### RUN"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "The `RUN` command is the simplest command, it simply executes a command at image compilation time. For example, if we want to install a package in the image, we do it using `RUN`.\n",
"\n",
"Therefore, important, `RUN` is executed at image compilation time, not when the container is executed."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "#### CMD"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "The `CMD` command is the command that is executed when the container is executed. For example, if we want the container to execute a command when it is executed, we do it with `CMD`. For example, if we have a python application in a container, with `CMD` we can tell it to run the python application when the container runs.\n",
"\n",
"This way, when the container is lifted, the python application will be executed. That is, if we do `docker run <image>` the python application will be executed. But `CMD` allows us to overwrite the command that is executed when the container is lifted, for example, if we do `docker run <image> bash` it will execute `bash` instead of the python application."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "#### ENTRYPOINT"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "The `ENTRYPOINT` command is similar to the `CMD` command, but with one difference, and that is that `ENTRYPOINT` is not intended to be overwritten. That is, if we have a python application in a container, with `ENTRYPOINT` we can tell it to run the python application when the container runs. But if we do `docker run <image> bash` it will run the python application, not `bash`.\n",
"\n",
"A very common use of `ENTRYPOINT` is when we want the container to be an executable, for example, if we want the container to be an executable of a version of python that we do not have on our host, because for example we want to test the new version of python that has been released we can do\n",
"\n",
"``` Dockerfile\n",
"FROM python:3.9.18-alpine\n",
"ENTRYPOINT [\"python3\"]\n",
"```\n",
"\n",
"This way, when the container is lifted, python will be executed. That is if we do `docker run <image>` it will run python. But `ENTRYPOINT` allows us to overwrite the command that is executed when the container is lifted, for example, if we do `docker run <image> myapp.py` it will execute `python3 myapp.py` inside the container. So we can test our python application in the new python version."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Docker in docker"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Suppose we have containers that need to lift or turn off other containers. This is accomplished as follows\n",
"\n",
"Since linux everything is a file and the host communicates with docker through a socket. So for linux, that socket is a file. So a container we mount that socket as a file will be able to talk to docker."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "First we are going to mount a container with ubuntu"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "144091e4a3325c9068064ff438f8865b40f944af5ce649c7156ca55a3453e423\n"
          ]
        }
      ],
      "source": [
      "!docker run -d --name ubuntu ubuntu:latest tail -f /dev/null"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Let's mount the container that will be able to talk to docker by mounting the folder `/var/run/docker.sock`.\n",
"\n",
"``` bash\n",
"$ docker run -it --rm --name main -v /var/run/docker.sock:/var/run/docker.sock docker:19.03.12\n",
"/ #\n",
"```\n",
"\n",
"We have put ourselves inside a container, and if inside we execute `docker ps`\n",
"\n",
"``` bash\n",
"# docker ps\n",
"CONTAINER ID CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES\n",
"9afb778d6c20 docker:19.03.12 \"docker-entrypoint.s...\"   3 seconds ago Up 2 seconds main\n",
"144091e4a332 ubuntu:latest \"tail -f /dev/null\" 19 seconds ago Up 18 seconds ubuntu\n",
"```\n",
"\n",
"As we can see, inside the docker we can see the host containers"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "We can run a new container\n",
"\n",
"``` bash\n",
"# docker run -d --name ubuntu_from_main ubuntu:latest tail -f /dev/null\n",
"362654a72bb0fb047c13968707a6f16b87fed7ce051eb5c1a146b15828589a1a\n",
"/ #\n",
"```\n",
"\n",
"And if we see the containers again\n",
"\n",
"``` bash\n",
"# docker ps\n",
"CONTAINER ID CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES\n",
"362654a72bb0 ubuntu:latest \"tail -f /dev/null\" 3 seconds ago Up 3 seconds ubuntu_from_main\n",
"9afb778d6c20 docker:19.03.12 \"docker-entrypoint.s...\"   About a minute ago Up About a minute main\n",
"144091e4a332 ubuntu:latest \"tail -f /dev/null\" 2 minutes ago Up About a minute ubuntu\n",
"```\n",
"\n",
"But if we now run a new host terminal we will see the container created from within the container"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE             COMMAND                  CREATED              STATUS              PORTS     NAMES\n",
"362654a72bb0   ubuntu:latest     \"tail -f /dev/null\"      About a minute ago   Up About a minute             ubuntu_from_main\n",
"9afb778d6c20   docker:19.03.12   \"docker-entrypoint.s…\"   3 minutes ago        Up 3 minutes                  main\n",
"144091e4a332   ubuntu:latest     \"tail -f /dev/null\"      3 minutes ago        Up 3 minutes                  ubuntu\n"
          ]
        }
      ],
      "source": [
      "!docker ps"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Everything we do from the `main` container will be reflected in the host."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "This has the advantage that we can install programs in a container that has access to the host so we don't have to install them on the host. For example [dive](https://github.com/wagoodman/dive) is a tool to explore containers, but if you do not want to install it on the host you can install it in a container with access to the host, so from that `main` container you can explore the rest of containers without having to install it on the host."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.7.6 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "d5745ab6aba164e1152437c779991855725055592b9f2bdb41a4825db7168d26"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
