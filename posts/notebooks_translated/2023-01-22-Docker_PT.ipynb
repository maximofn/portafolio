{
  "cells": [
  {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "# Docker"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "## Contêineres"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Este caderno foi traduzido automaticamente para torná-lo acessível a mais pessoas, por favor me avise se você vir algum erro de digitação..\n",
"\n",
"### Olá mundo"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Execute o primeiro contêiner Hello world com o comando `docker run hello-world`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Unable to find image 'hello-world:latest' locally\n"
          ]
        },
{
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "latest: Pulling from library/hello-world\n",
"\n",
"\u001b[1B85e32844: Pull complete 457kB/2.457kBB\u001b[1A\u001b[2KDigest: sha256:dcba6daec718f547568c562956fa47e1b03673dd010fe6ee58ca806767031d1c\n",
"Status: Downloaded newer image for hello-world:latest\n",
"\n",
"Hello from Docker!\n",
"This message shows that your installation appears to be working correctly.\n",
"\n",
"To generate this message, Docker took the following steps:\n",
" 1. The Docker client contacted the Docker daemon.\n",
" 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\n",
"    (amd64)\n",
" 3. The Docker daemon created a new container from that image which runs the\n",
"    executable that produces the output you are currently reading.\n",
" 4. The Docker daemon streamed that output to the Docker client, which sent it\n",
"    to your terminal.\n",
"\n",
"To try something more ambitious, you can run an Ubuntu container with:\n",
" $ docker run -it ubuntu bash\n",
"\n",
"Share images, automate workflows, and more with a free Docker ID:\n",
" https://hub.docker.com/\n",
"\n",
"For more examples and ideas, visit:\n",
" https://docs.docker.com/get-started/\n",
"\n"
          ]
        }
      ],
      "source": [
      "!docker run hello-world"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Como não temos o contêiner salvo localmente, o docker faz o download a partir do docker hub. Se agora executarmos o contêiner novamente, a primeira mensagem, indicando que ele está sendo baixado, não será mais exibida."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "\n",
"Hello from Docker!\n",
"This message shows that your installation appears to be working correctly.\n",
"\n",
"To generate this message, Docker took the following steps:\n",
" 1. The Docker client contacted the Docker daemon.\n",
" 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\n",
"    (amd64)\n",
" 3. The Docker daemon created a new container from that image which runs the\n",
"    executable that produces the output you are currently reading.\n",
" 4. The Docker daemon streamed that output to the Docker client, which sent it\n",
"    to your terminal.\n",
"\n",
"To try something more ambitious, you can run an Ubuntu container with:\n",
" $ docker run -it ubuntu bash\n",
"\n",
"Share images, automate workflows, and more with a free Docker ID:\n",
" https://hub.docker.com/\n",
"\n",
"For more examples and ideas, visit:\n",
" https://docs.docker.com/get-started/\n",
"\n"
          ]
        }
      ],
      "source": [
      "!docker run hello-world"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Para ver quais contêineres estão em execução, execute `docker ps`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
          ]
        }
      ],
      "source": [
      "!docker ps"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Como podemos ver, não há contêineres abertos. No entanto, se executarmos `docker ps -a` (`all`), veremos que há"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE         COMMAND    CREATED          STATUS                      PORTS     NAMES\n",
"1efb51bbbf38   hello-world   \"/hello\"   10 seconds ago   Exited (0) 9 seconds ago              strange_thompson\n",
"5f5705e7603e   hello-world   \"/hello\"   15 seconds ago   Exited (0) 14 seconds ago             laughing_jang\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vemos que aparecem dois contêineres chamados `hello-world`, que são os dois que executamos anteriormente. Portanto, toda vez que executamos o comando `run`, o docker cria um novo contêiner, não executa um que já existe."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se quisermos obter mais informações sobre um dos dois contêineres, podemos executar `docker inspect <id>`, em que `<id>` corresponde ao ID do contêiner mostrado na lista acima."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "[\n",
"    {\n",
"        \"Id\": \"1efb51bbbf38917affd1b5871db8e658ebfe0b2efa5ead17545680b7866f682e\",\n",
"        \"Created\": \"2023-09-04T03:59:17.795499354Z\",\n",
"        \"Path\": \"/hello\",\n",
"        \"Args\": [],\n",
"        \"State\": {\n",
"            \"Status\": \"exited\",\n",
"            \"Running\": false,\n",
"            \"Paused\": false,\n",
"            \"Restarting\": false,\n",
"            \"OOMKilled\": false,\n",
"            \"Dead\": false,\n",
"            \"Pid\": 0,\n",
"            \"ExitCode\": 0,\n",
"            \"Error\": \"\",\n",
"            \"StartedAt\": \"2023-09-04T03:59:18.406663026Z\",\n",
"            \"FinishedAt\": \"2023-09-04T03:59:18.406181184Z\"\n",
"        },\n",
"        \"Image\": \"sha256:9c7a54a9a43cca047013b82af109fe963fde787f63f9e016fdc3384500c2823d\",\n",
"        \"ResolvConfPath\": \"/var/lib/docker/containers/1efb51bbbf38917affd1b5871db8e658ebfe0b2efa5ead17545680b7866f682e/resolv.conf\",\n",
"        \"HostnamePath\": \"/var/lib/docker/containers/1efb51bbbf38917affd1b5871db8e658ebfe0b2efa5ead17545680b7866f682e/hostname\",\n",
"        \"HostsPath\": \"/var/lib/docker/containers/1efb51bbbf38917affd1b5871db8e658ebfe0b2efa5ead17545680b7866f682e/hosts\",\n",
"        \"LogPath\": \"/var/lib/docker/containers/1efb51bbbf38917affd1b5871db8e658ebfe0b2efa5ead17545680b7866f682e/1efb51bbbf38917affd1b5871db8e658ebfe0b2efa5ead17545680b7866f682e-json.log\",\n",
"        \"Name\": \"/strange_thompson\",\n",
"        ...\n",
"            }\n",
"        }\n",
"    }\n",
"]\n"
          ]
        }
      ],
      "source": [
      "!docker inspect 1efb51bbbf38"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Como lembrar os IDs é complicado para nós, o docker atribui nomes aos contêineres para facilitar nossa vida. Assim, na lista acima, a última coluna corresponde ao nome que o docker atribuiu a cada contêiner, portanto, se agora executarmos `docker inspect <name>`, obteremos as mesmas informações que com o ID"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Executo novamente o `docker ps -a` para ver a lista novamente"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE         COMMAND    CREATED         STATUS                     PORTS     NAMES\n",
"1efb51bbbf38   hello-world   \"/hello\"   2 minutes ago   Exited (0) 2 minutes ago             strange_thompson\n",
"5f5705e7603e   hello-world   \"/hello\"   2 minutes ago   Exited (0) 2 minutes ago             laughing_jang\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "E agora executo `docker inspect <name>` para ver as informações do contêiner."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "[\n",
"    {\n",
"        \"Id\": \"1efb51bbbf38917affd1b5871db8e658ebfe0b2efa5ead17545680b7866f682e\",\n",
"        \"Created\": \"2023-09-04T03:59:17.795499354Z\",\n",
"        \"Path\": \"/hello\",\n",
"        \"Args\": [],\n",
"        \"State\": {\n",
"            \"Status\": \"exited\",\n",
"            \"Running\": false,\n",
"            \"Paused\": false,\n",
"            \"Restarting\": false,\n",
"            \"OOMKilled\": false,\n",
"            \"Dead\": false,\n",
"            \"Pid\": 0,\n",
"            \"ExitCode\": 0,\n",
"            \"Error\": \"\",\n",
"            \"StartedAt\": \"2023-09-04T03:59:18.406663026Z\",\n",
"            \"FinishedAt\": \"2023-09-04T03:59:18.406181184Z\"\n",
"        },\n",
"        \"Image\": \"sha256:9c7a54a9a43cca047013b82af109fe963fde787f63f9e016fdc3384500c2823d\",\n",
"        \"ResolvConfPath\": \"/var/lib/docker/containers/1efb51bbbf38917affd1b5871db8e658ebfe0b2efa5ead17545680b7866f682e/resolv.conf\",\n",
"        \"HostnamePath\": \"/var/lib/docker/containers/1efb51bbbf38917affd1b5871db8e658ebfe0b2efa5ead17545680b7866f682e/hostname\",\n",
"        \"HostsPath\": \"/var/lib/docker/containers/1efb51bbbf38917affd1b5871db8e658ebfe0b2efa5ead17545680b7866f682e/hosts\",\n",
"        \"LogPath\": \"/var/lib/docker/containers/1efb51bbbf38917affd1b5871db8e658ebfe0b2efa5ead17545680b7866f682e/1efb51bbbf38917affd1b5871db8e658ebfe0b2efa5ead17545680b7866f682e-json.log\",\n",
"        \"Name\": \"/strange_thompson\",\n",
"        ...\n",
"            }\n",
"        }\n",
"    }\n",
"]\n"
          ]
        }
      ],
      "source": [
      "!docker inspect strange_thompson"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Mas por que com o `docker ps` não vemos nenhum contêiner e com o `docker ps -a` vemos. Isso ocorre porque o `docker ps` mostra apenas os contêineres em execução, enquanto o `docker ps -a` mostra todos os contêineres, em execução e desligados."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Podemos criar um contêiner atribuindo um nome a ele usando o comando `docker run --name <name> hello-world`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "\n",
"Hello from Docker!\n",
"This message shows that your installation appears to be working correctly.\n",
"\n",
"To generate this message, Docker took the following steps:\n",
" 1. The Docker client contacted the Docker daemon.\n",
" 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\n",
"    (amd64)\n",
" 3. The Docker daemon created a new container from that image which runs the\n",
"    executable that produces the output you are currently reading.\n",
" 4. The Docker daemon streamed that output to the Docker client, which sent it\n",
"    to your terminal.\n",
"\n",
"To try something more ambitious, you can run an Ubuntu container with:\n",
" $ docker run -it ubuntu bash\n",
"\n",
"Share images, automate workflows, and more with a free Docker ID:\n",
" https://hub.docker.com/\n",
"\n",
"For more examples and ideas, visit:\n",
" https://docs.docker.com/get-started/\n",
"\n"
          ]
        }
      ],
      "source": [
      "!docker run --name hello_world hello-world"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Isso será mais conveniente para nós, pois poderemos controlar os nomes dos contêineres por conta própria."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se agora quisermos criar outro contêiner com o mesmo nome, não será possível, pois o docker não permite nomes de contêineres duplicados. Portanto, se quisermos renomear o contêiner, podemos usar o comando `docker rename <old name> <new name>`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
      "!docker rename hello_world hello_world2"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Agora temos vários contêineres iguais. Portanto, se quisermos excluir qualquer um deles, teremos que usar o comando `docker rm <id>` ou `docker rm <name>`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE         COMMAND    CREATED         STATUS                     PORTS     NAMES\n",
"f432c9c2ca21   hello-world   \"/hello\"   9 seconds ago   Exited (0) 8 seconds ago             hello_world2\n",
"1efb51bbbf38   hello-world   \"/hello\"   4 minutes ago   Exited (0) 4 minutes ago             strange_thompson\n",
"5f5705e7603e   hello-world   \"/hello\"   4 minutes ago   Exited (0) 4 minutes ago             laughing_jang\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "hello_world2\n"
          ]
        }
      ],
      "source": [
      "!docker rm hello_world2"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se olharmos a lista de contêineres novamente, o contêiner `hello_world2` não está mais lá."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE         COMMAND    CREATED         STATUS                     PORTS     NAMES\n",
"1efb51bbbf38   hello-world   \"/hello\"   5 minutes ago   Exited (0) 5 minutes ago             strange_thompson\n",
"5f5705e7603e   hello-world   \"/hello\"   5 minutes ago   Exited (0) 5 minutes ago             laughing_jang\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se quisermos excluir todos os contêineres, podemos fazer isso um a um, mas como é muito pesado, podemos excluir todos eles usando o comando `docker container prune`. Esse comando exclui apenas os contêineres que estão parados."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "WARNING! This will remove all stopped containers.\n",
"Are you sure you want to continue? [y/N] y"
          ]
        }
      ],
      "source": [
      "!docker container prune"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "O Docker pergunta se você tem certeza e, se você disser que sim, ele exclui todos eles. Se agora você listar todos os contêineres, nenhum deles aparecerá"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Modo iterativo"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vamos executar o ubuntu usando o comando `docker run ubuntu`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Unable to find image 'ubuntu:latest' locally\n",
"latest: Pulling from library/ubuntu\n",
"\n",
"\u001b[1BDigest: sha256:20fa2d7bb4de7723f542be5923b06c4d704370f0390e4ae9e1c833c8785644c1[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\n",
"Status: Downloaded newer image for ubuntu:latest\n"
          ]
        }
      ],
      "source": [
      "!docker run ubuntu"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Como podemos ver agora, o download demorou mais. Se listarmos os contêineres usando o comando `docker ps`, veremos que o contêiner que acabamos de criar não aparece, ou seja, não está em execução."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
          ]
        }
      ],
      "source": [
      "!docker ps"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Agora listamos todos os contêineres"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND   CREATED         STATUS                     PORTS     NAMES\n",
"da16b3a85178   ubuntu    \"bash\"    4 seconds ago   Exited (0) 3 seconds ago             hardcore_kare\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vemos que o estado do contêiner é `Exited (0)`."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se olharmos para o comando do contêiner, `bash` aparece e, ao lado do status `Exited (0)`, ele nos diz que o Ubuntu foi iniciado, executou seu *bash*, terminou a execução e retornou um 0. Isso acontece porque o bash do Ubuntu não foi informado sobre o que fazer. Para resolver isso, agora vamos executar o contêiner usando o comando `docker run -it ubuntu`, com `it` o que estamos dizendo é que queremos executá-lo no modo iterativo."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "root@5b633e9d838f:/#"
          ]
        }
      ],
      "source": [
      "!docker run -it ubuntu"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Agora vemos que estamos dentro do bash do Ubuntu. Se executarmos o comando `cat /etc/lsb-release`, poderemos ver a distribuição do Ubuntu"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "DISTRIB_ID=Ubuntu\n",
"DISTRIB_RELEASE=22.04\n",
"DISTRIB_CODENAME=jammy\n",
"DISTRIB_DESCRIPTION=\"Ubuntu 22.04.1 LTS\""
          ]
        }
      ],
      "source": [
      "!root@5b633e9d838f:/# cat /etc/lsb-release"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se abrirmos outro terminal e olharmos a lista de contêineres, agora aparecerá o contêiner que está executando o Ubuntu."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND   CREATED         STATUS         PORTS     NAMES\n",
"5b633e9d838f   ubuntu    \"bash\"    3 minutes ago   Up 3 minutes             funny_mirzakhani\n"
          ]
        }
      ],
      "source": [
      "!docker ps"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vemos o contêiner com o Ubuntu e, em seu status, podemos ver `UP`."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se olharmos agora para a lista de todos os contêineres, veremos que os dois contêineres com o Ubuntu aparecem, o primeiro desligado e o segundo em execução"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND   CREATED         STATUS                     PORTS     NAMES\n",
"5b633e9d838f   ubuntu    \"bash\"    3 minutes ago   Up 3 minutes                         funny_mirzakhani\n",
"da16b3a85178   ubuntu    \"bash\"    3 minutes ago   Exited (0) 3 minutes ago             hardcore_kare\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se voltarmos ao terminal onde tínhamos o Ubuntu em execução dentro de uma janela de encaixe, digitar ``exit`` encerrará o Ubuntu."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "exit"
          ]
        }
      ],
      "source": [
      "!root@5b633e9d838f:/# exit"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se executarmos o ``docker ps``, o contêiner não aparecerá mais."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
          ]
        }
      ],
      "source": [
      "!docker ps"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Mas se eu executar o ``docker ps -a``, ele aparecerá. Isso significa que o contêiner está desligado"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND   CREATED         STATUS                      PORTS     NAMES\n",
"5b633e9d838f   ubuntu    \"bash\"    4 minutes ago   Exited (0) 27 seconds ago             funny_mirzakhani\n",
"da16b3a85178   ubuntu    \"bash\"    4 minutes ago   Exited (0) 4 minutes ago              hardcore_kare\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Isso acontece porque quando digitamos ``exit``, na verdade estamos digitando no console do Ubuntu bash, o que significa que estamos encerrando o processo do Ubuntu bash."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Ciclo de vida de um contêiner"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "No docker, quando o processo principal de um contêiner termina, o contêiner é encerrado. Vários processos podem ser executados dentro de um contêiner, mas somente quando o processo principal termina é que o contêiner é encerrado.\n",
"\n",
"Portanto, se quisermos executar um contêiner que não seja encerrado quando um processo for encerrado, devemos fazer com que seu processo principal não seja encerrado. Nesse caso, não encerre o bash\n",
"\n",
"Se quisermos executar um contêiner com o ubuntu, mas não encerrá-lo quando o processo bash terminar, podemos fazer isso da seguinte maneira"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "ce4d60427dcd4b326d15aa832b816c209761d6b4e067a016bb75bf9366c37054\n"
          ]
        }
      ],
      "source": [
      "!docker run --name alwaysup -d ubuntu tail -f /dev/null"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Primeiro, damos a ele o nome ``alwaysup``, depois passamos a opção ``-d`` (``detach``) para fazer com que o contêiner seja executado em segundo plano e, por fim, informamos o processo principal que queremos executar no contêiner, que nesse caso é ``tail -f /dev/null``, o que equivale a um comando ``nop``.\n",
"\n",
"Isso retornará o ID do contêiner, mas não estaremos dentro do ubuntu como antes."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se olharmos agora para a lista de contêineres em execução, o contêiner que acabamos de criar será exibido"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND               CREATED          STATUS          PORTS     NAMES\n",
"ce4d60427dcd   ubuntu    \"tail -f /dev/null\"   18 seconds ago   Up 17 seconds             alwaysup\n"
          ]
        }
      ],
      "source": [
      "!docker ps"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Como já temos um contêiner em execução o tempo todo, podemos nos conectar a ele usando o comando ``exec``. Informamos a ele o nome ou ID do contêiner e passamos o processo que queremos executar. Também passamos a opção ``-it`` para dizer a ele que deve ser iterativo."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "root@ce4d60427dcd:/#"
          ]
        }
      ],
      "source": [
      "!docker exec -it alwaysup bash"
      ]
    },
{
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Agora estamos de volta ao Ubuntu. Se executarmos o comando ``ps -aux``, poderemos ver uma lista dos processos em execução no Ubuntu."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n",
"root           1  0.0  0.0   2820  1048 ?        Ss   13:04   0:00 tail -f /dev/null\n",
"root           7  0.0  0.0   4628  3796 pts/0    Ss   13:04   0:00 bash\n",
"root          15  0.0  0.0   7060  1556 pts/0    R+   13:05   0:00 ps -aux"
          ]
        }
      ],
      "source": [
      "!ps -aux"
      ]
    },
{
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vemos apenas três processos, o ``ps -aux``, o ``bash`` e o ``tail -f /dev/null``.\n",
"\n",
"Esse contêiner estará sempre ativo enquanto o processo ``tail -f /dev/null`` estiver em execução."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se sairmos do contêiner com o comando ``exit`` e executarmos o comando ``docker ps``, veremos que o contêiner ainda está ativo."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "exit"
          ]
        }
      ],
      "source": [
      "!exit"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND               CREATED         STATUS         PORTS     NAMES\n",
"ce4d60427dcd   ubuntu    \"tail -f /dev/null\"   2 minutes ago   Up 2 minutes             alwaysup\n"
          ]
        }
      ],
      "source": [
      "!docker ps"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Para encerrar o processo e fechar o contêiner, devemos usar o comando ``docker stop <name>``."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "alwaysup\n"
          ]
        }
      ],
      "source": [
      "!docker stop alwaysup"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se agora listarmos novamente os contêineres ativados, o contêiner com o Ubuntu não aparecerá mais."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
          ]
        }
      ],
      "source": [
      "!docker ps"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "E se listarmos todos os contêineres, veremos o contêiner com o Ubuntu e seu status ``Exited``."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND               CREATED          STATUS                            PORTS     NAMES\n",
"ce4d60427dcd   ubuntu    \"tail -f /dev/null\"   14 minutes ago   Exited (137) About a minute ago             alwaysup\n",
"5b633e9d838f   ubuntu    \"bash\"                19 minutes ago   Exited (0) 15 minutes ago                   funny_mirzakhani\n",
"da16b3a85178   ubuntu    \"bash\"                20 minutes ago   Exited (0) 20 minutes ago                   hardcore_kare\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Recipientes de uso único"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se definirmos a opção `--rm` ao executar um contêiner, esse contêiner será excluído quando terminar de ser executado."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
      "!docker run --rm --name autoremove ubuntu:latest"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se olharmos agora para os contêineres que temos"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vemos que o contêiner que acabamos de criar está faltando."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Expondo contêineres ao mundo externo"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vamos criar um novo contêiner com um servidor"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Unable to find image 'nginx:latest' locally\n",
"latest: Pulling from library/nginx\n",
"\n",
"\u001b[1Bf1ad4ce1: Pulling fs layer \n",
"\u001b[1Bb079d0f8: Pulling fs layer \n",
"\u001b[1B5fbbebc6: Pulling fs layer \n",
"\u001b[1Bffdd25f4: Pulling fs layer \n",
"\u001b[1B32c8fba2: Pulling fs layer \n",
"\u001b[1B24b8ba39: Pull complete 393kB/1.393kBB[5A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[3A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[2A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[4A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KDigest: sha256:2888a97f7c7d498bbcc47ede1ad0f6ced07d72dfd181071dde051863f1f79d7b\n",
"Status: Downloaded newer image for nginx:latest\n",
"1a530e04f14be082811b72ea8b6ea5a95dad3037301ee8a1351a0108ff8d3b30\n"
          ]
        }
      ],
      "source": [
      "!docker run -d --name proxy nginx"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Isso cria um servidor, vamos listar novamente os contêineres que estão em execução"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND                  CREATED        STATUS                  PORTS     NAMES\n",
"1a530e04f14b   nginx     \"/docker-entrypoint.…\"   1 second ago   Up Less than a second   80/tcp    proxy\n"
          ]
        }
      ],
      "source": [
      "!docker ps"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Agora, uma nova coluna aparece com a porta e nos informa que o servidor que acabamos de criar está na porta ``80`` sob o protocolo ``tcp``.\n",
"\n",
"Se abrirmos um navegador e tentarmos nos conectar ao servidor via ``http://localhost:80``, não conseguiremos nos conectar. Isso ocorre porque cada contêiner tem sua própria interface de rede. Ou seja, o servidor está escutando na porta ``80`` do contêiner, mas estamos tentando nos conectar à porta ``80`` do host."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Paramos o contêiner para relançá-lo de outra forma"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "proxy\n"
          ]
        }
      ],
      "source": [
      "!docker stop proxy"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se listarmos os contêineres, ele não aparecerá em execução"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
          ]
        }
      ],
      "source": [
      "!docker ps"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Nós o excluímos para recriá-lo"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "proxy\n"
          ]
        }
      ],
      "source": [
      "!docker rm proxy"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se listarmos todos os contêineres, não será mais"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND               CREATED          STATUS                       PORTS     NAMES\n",
"ce4d60427dcd   ubuntu    \"tail -f /dev/null\"   19 minutes ago   Exited (137) 5 minutes ago             alwaysup\n",
"5b633e9d838f   ubuntu    \"bash\"                24 minutes ago   Exited (0) 20 minutes ago              funny_mirzakhani\n",
"da16b3a85178   ubuntu    \"bash\"                24 minutes ago   Exited (0) 24 minutes ago              hardcore_kare\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Para recriar o contêiner com o servidor e poder vê-lo a partir do host, precisamos usar a opção ``-p`` (``publish``), indicando primeiro a porta na qual queremos vê-lo no host e, em seguida, a porta do contêiner, ou seja, ``-p <ip host>:<ip conteiner>``."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "c199235e42f76a30266f6e1af972e0a59811806eb3d3a9afdd873f6fa1785eae\n"
          ]
        }
      ],
      "source": [
      "!docker run -d --name proxy -p 8080:80 nginx"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Listamos os contêineres"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND                  CREATED          STATUS          PORTS                                   NAMES\n",
"c199235e42f7   nginx     \"/docker-entrypoint.…\"   22 seconds ago   Up 21 seconds   0.0.0.0:8080->80/tcp, :::8080->80/tcp   proxy\n"
          ]
        }
      ],
      "source": [
      "!docker ps"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vemos que a porta do contêiner é `0.0.0.0.0:8080->80/tcp`. Se agora formos a um navegador e digitarmos `0.0.0.0.0:8080`, poderemos acessar o servidor de contêineres."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Ao listar os contêineres, a coluna ``PORTS`` indica ``0.0.0.0.0:8080->80/tcp``, o que nos ajuda a ver a relação entre as portas."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Para visualizar os logs do contêiner, usando o comando ``docker logs <name>``, posso visualizar os logs do contêiner."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration\n",
"/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/\n",
"/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh\n",
"10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf\n",
"10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf\n",
"/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh\n",
"/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh\n",
"/docker-entrypoint.sh: Configuration complete; ready for start up\n",
"2022/09/13 13:24:06 [notice] 1#1: using the \"epoll\" event method\n",
"2022/09/13 13:24:06 [notice] 1#1: nginx/1.23.1\n",
"2022/09/13 13:24:06 [notice] 1#1: built by gcc 10.2.1 20210110 (Debian 10.2.1-6) \n",
"2022/09/13 13:24:06 [notice] 1#1: OS: Linux 5.15.0-46-generic\n",
"2022/09/13 13:24:06 [notice] 1#1: getrlimit(RLIMIT_NOFILE): 1048576:1048576\n",
"2022/09/13 13:24:06 [notice] 1#1: start worker processes\n",
"2022/09/13 13:24:06 [notice] 1#1: start worker process 31\n",
"2022/09/13 13:24:06 [notice] 1#1: start worker process 32\n",
"2022/09/13 13:24:06 [notice] 1#1: start worker process 33\n",
"2022/09/13 13:24:06 [notice] 1#1: start worker process 34\n",
"2022/09/13 13:24:06 [notice] 1#1: start worker process 35\n",
"2022/09/13 13:24:06 [notice] 1#1: start worker process 36\n",
"2022/09/13 13:24:06 [notice] 1#1: start worker process 37\n",
"2022/09/13 13:24:06 [notice] 1#1: start worker process 38\n",
"2022/09/13 13:24:06 [notice] 1#1: start worker process 39\n",
"2022/09/13 13:24:06 [notice] 1#1: start worker process 40\n",
"2022/09/13 13:24:06 [notice] 1#1: start worker process 41\n",
"...\n",
"172.17.0.1 - - [13/Sep/2022:13:24:40 +0000] \"GET /favicon.ico HTTP/1.1\" 404 555 \"http://0.0.0.0:8080/\" \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\" \"-\"\n",
"172.17.0.1 - - [13/Sep/2022:13:25:00 +0000] \"\\x16\\x03\\x01\\x02\\x00\\x01\\x00\\x01\\xFC\\x03\\x03\\xE2\\x19V$Zqi'\\xD7\\xFC[\\x80\\xEF\\xBA\\xE5\\xC7\\xE8\\xF7&3nS\\xEB\\xC9\\xEC\\x91\\xC2\\xD8\\xD1\\x89\\x9E\\xBE \\xC7?\\xE1\\xFA\\x04a\\x1C\\xCE\\x90\\x0F\\x8F\\x98u\\xE3/\\xD8RfOH\\xEC\\x92+\\x93\\x5C\\xBB\\xB1\\xBF\\xD2m\\xB09\\x00 \\xFA\\xFA\\x13\\x01\\x13\\x02\\x13\\x03\\xC0+\\xC0/\\xC0,\\xC00\\xCC\\xA9\\xCC\\xA8\\xC0\\x13\\xC0\\x14\\x00\\x9C\\x00\\x9D\\x00/\\x005\\x01\\x00\\x01\\x93\\x9A\\x9A\\x00\\x00\\x00\\x00\\x00\\x0E\\x00\\x0C\\x00\\x00\\x09localhost\\x00\\x17\\x00\\x00\\xFF\\x01\\x00\\x01\\x00\\x00\" 400 157 \"-\" \"-\" \"-\"\n",
"172.17.0.1 - - [13/Sep/2022:13:25:00 +0000] \"\\x16\\x03\\x01\\x02\\x00\\x01\\x00\\x01\\xFC\\x03\\x03)\\x9A\\x8FbC\\xD9m\\xF1\\x86\\xEBd\\x22\\xCF\\xC4E\\x87#~L\\xC1\\x84\\x7F\\xB5\\x91k\\x98\\xABl\\xEE\\x1E[0 \\xD0\\xD2`\\x85\\xC6\\x8B\\x85R\\x8B\\x87\\xEAq{P\\xF2\\xFB\\xE2\\xA8\\x9DI\\xF4tH\\x99\\x13\\x10~\\xCA1-|\\x8E\\x00 \\xEA\\xEA\\x13\\x01\\x13\\x02\\x13\\x03\\xC0+\\xC0/\\xC0,\\xC00\\xCC\\xA9\\xCC\\xA8\\xC0\\x13\\xC0\\x14\\x00\\x9C\\x00\\x9D\\x00/\\x005\\x01\\x00\\x01\\x93\" 400 157 \"-\" \"-\" \"-\"\n",
"172.17.0.1 - - [13/Sep/2022:13:26:28 +0000] \"GET / HTTP/1.1\" 304 0 \"-\" \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\" \"-\"\n"
          ]
        }
      ],
      "source": [
      "!docker logs proxy"
      ]
    },
{
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Agora posso ver todas as solicitações que foram feitas ao servidor. Mas se eu quiser ver os logs em tempo real, posso usar ``docker logs -f <name>``."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": []
        }
      ],
      "source": [
      "!docker logs -f proxy"
      ]
    },
{
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Agora posso visualizar os registros em tempo real. Para sair, digite ``CTRL+C``."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Como pode haver um momento em que há muitos logs, se você quiser apenas os logs mais recentes, usando a opção ``--tail <num>`` posso ver os logs mais recentes ``<num>``. Se eu adicionar a opção ``-f``, sempre veremos os últimos registros ``<num>``."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "2022/09/13 13:24:06 [notice] 1#1: start worker process 41\n",
"2022/09/13 13:24:06 [notice] 1#1: start worker process 42\n",
"172.17.0.1 - - [13/Sep/2022:13:24:16 +0000] \"\\x16\\x03\\x01\\x02\\x00\\x01\\x00\\x01\\xFC\\x03\\x03\\x01E\\x14\\x8E\\xB6\\x0BEg\\xF3\\xC9\\x9A\\x19\\x9C\\xCA\\xEC\\xA7y#3\\x92\\x05\\x95\\xDCQ\\x07\\x19\\x1D\\xEF\\xEA$\\xBF# \\x0B\\x83\\xF7-,s\\x1B!r\\xEA|\\xAE\\xDF\\xA1\\x9DLZ\\xAA4y\\xB3t\\xAB\\xC0\\xCE_\\xB8\\xE7\\xFF'\\xCF\\x86\\x00 \\xEA\\xEA\\x13\\x01\\x13\\x02\\x13\\x03\\xC0+\\xC0/\\xC0,\\xC00\\xCC\\xA9\\xCC\\xA8\\xC0\\x13\\xC0\\x14\\x00\\x9C\\x00\\x9D\\x00/\\x005\\x01\\x00\\x01\\x93\\x8A\\x8A\\x00\\x00\\x00\\x00\\x00\\x0E\\x00\\x0C\\x00\\x00\\x09localhost\\x00\\x17\\x00\\x00\\xFF\\x01\\x00\\x01\\x00\\x00\" 400 157 \"-\" \"-\" \"-\"\n",
"172.17.0.1 - - [13/Sep/2022:13:24:16 +0000] \"\\x16\\x03\\x01\\x02\\x00\\x01\\x00\\x01\\xFC\\x03\\x03}\\xA9Dr{\\x8C;\\x90z\\x82\\xAD\\xBC\\x8Az\\xC2x\\xDF\\x1E\\x9A\\xE6l?\\xA7\\xE0DoK\\x91'g\\xBB\\xB5 %\\xBB\\xFD\\xD9\\x82?\\xDB\\x80\\xB3T\\xF6cJ\\xF7\\xE5\\xC2\\xD2\\x11\\xBC\\xA2\\x1F\\x90\\x14\\xA3\\xEB\\xBD=R\\xBC\\x83\\x89\\x85\\x00 \\xCA\\xCA\\x13\\x01\\x13\\x02\\x13\\x03\\xC0+\\xC0/\\xC0,\\xC00\\xCC\\xA9\\xCC\\xA8\\xC0\\x13\\xC0\\x14\\x00\\x9C\\x00\\x9D\\x00/\\x005\\x01\\x00\\x01\\x93\\x9A\\x9A\\x00\\x00\\x00\\x00\\x00\\x0E\\x00\\x0C\\x00\\x00\\x09localhost\\x00\\x17\\x00\\x00\\xFF\\x01\\x00\\x01\\x00\\x00\" 400 157 \"-\" \"-\" \"-\"\n",
"172.17.0.1 - - [13/Sep/2022:13:24:39 +0000] \"GET / HTTP/1.1\" 200 615 \"-\" \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\" \"-\"\n",
"2022/09/13 13:24:40 [error] 34#34: *3 open() \"/usr/share/nginx/html/favicon.ico\" failed (2: No such file or directory), client: 172.17.0.1, server: localhost, request: \"GET /favicon.ico HTTP/1.1\", host: \"0.0.0.0:8080\", referrer: \"http://0.0.0.0:8080/\"\n",
"172.17.0.1 - - [13/Sep/2022:13:24:40 +0000] \"GET /favicon.ico HTTP/1.1\" 404 555 \"http://0.0.0.0:8080/\" \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\" \"-\"\n",
"172.17.0.1 - - [13/Sep/2022:13:25:00 +0000] \"\\x16\\x03\\x01\\x02\\x00\\x01\\x00\\x01\\xFC\\x03\\x03\\xE2\\x19V$Zqi'\\xD7\\xFC[\\x80\\xEF\\xBA\\xE5\\xC7\\xE8\\xF7&3nS\\xEB\\xC9\\xEC\\x91\\xC2\\xD8\\xD1\\x89\\x9E\\xBE \\xC7?\\xE1\\xFA\\x04a\\x1C\\xCE\\x90\\x0F\\x8F\\x98u\\xE3/\\xD8RfOH\\xEC\\x92+\\x93\\x5C\\xBB\\xB1\\xBF\\xD2m\\xB09\\x00 \\xFA\\xFA\\x13\\x01\\x13\\x02\\x13\\x03\\xC0+\\xC0/\\xC0,\\xC00\\xCC\\xA9\\xCC\\xA8\\xC0\\x13\\xC0\\x14\\x00\\x9C\\x00\\x9D\\x00/\\x005\\x01\\x00\\x01\\x93\\x9A\\x9A\\x00\\x00\\x00\\x00\\x00\\x0E\\x00\\x0C\\x00\\x00\\x09localhost\\x00\\x17\\x00\\x00\\xFF\\x01\\x00\\x01\\x00\\x00\" 400 157 \"-\" \"-\" \"-\"\n",
"172.17.0.1 - - [13/Sep/2022:13:25:00 +0000] \"\\x16\\x03\\x01\\x02\\x00\\x01\\x00\\x01\\xFC\\x03\\x03)\\x9A\\x8FbC\\xD9m\\xF1\\x86\\xEBd\\x22\\xCF\\xC4E\\x87#~L\\xC1\\x84\\x7F\\xB5\\x91k\\x98\\xABl\\xEE\\x1E[0 \\xD0\\xD2`\\x85\\xC6\\x8B\\x85R\\x8B\\x87\\xEAq{P\\xF2\\xFB\\xE2\\xA8\\x9DI\\xF4tH\\x99\\x13\\x10~\\xCA1-|\\x8E\\x00 \\xEA\\xEA\\x13\\x01\\x13\\x02\\x13\\x03\\xC0+\\xC0/\\xC0,\\xC00\\xCC\\xA9\\xCC\\xA8\\xC0\\x13\\xC0\\x14\\x00\\x9C\\x00\\x9D\\x00/\\x005\\x01\\x00\\x01\\x93\" 400 157 \"-\" \"-\" \"-\"\n",
"172.17.0.1 - - [13/Sep/2022:13:26:28 +0000] \"GET / HTTP/1.1\" 304 0 \"-\" \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\" \"-\"\n"
          ]
        }
      ],
      "source": [
      "!docker logs --tail 10 proxy"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se também adicionarmos a opção `-t`, poderemos ver a data e a hora de cada registro, portanto, se tivermos um problema, poderemos saber quando ele ocorreu."
      ]
    },
{
      "cell_type": "code",
      "execution_count": "None",
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "2022-09-13T13:24:06.573362728Z 2022/09/13 13:24:06 [notice] 1#1: start worker process 41\n",
"2022-09-13T13:24:06.651127107Z 2022/09/13 13:24:06 [notice] 1#1: start worker process 42\n",
"2022-09-13T13:24:16.651160189Z 172.17.0.1 - - [13/Sep/2022:13:24:16 +0000] \"\\x16\\x03\\x01\\x02\\x00\\x01\\x00\\x01\\xFC\\x03\\x03\\x01E\\x14\\x8E\\xB6\\x0BEg\\xF3\\xC9\\x9A\\x19\\x9C\\xCA\\xEC\\xA7y#3\\x92\\x05\\x95\\xDCQ\\x07\\x19\\x1D\\xEF\\xEA$\\xBF# \\x0B\\x83\\xF7-,s\\x1B!r\\xEA|\\xAE\\xDF\\xA1\\x9DLZ\\xAA4y\\xB3t\\xAB\\xC0\\xCE_\\xB8\\xE7\\xFF'\\xCF\\x86\\x00 \\xEA\\xEA\\x13\\x01\\x13\\x02\\x13\\x03\\xC0+\\xC0/\\xC0,\\xC00\\xCC\\xA9\\xCC\\xA8\\xC0\\x13\\xC0\\x14\\x00\\x9C\\x00\\x9D\\x00/\\x005\\x01\\x00\\x01\\x93\\x8A\\x8A\\x00\\x00\\x00\\x00\\x00\\x0E\\x00\\x0C\\x00\\x00\\x09localhost\\x00\\x17\\x00\\x00\\xFF\\x01\\x00\\x01\\x00\\x00\" 400 157 \"-\" \"-\" \"-\"\n",
"2022-09-13T13:24:16.116817914Z 172.17.0.1 - - [13/Sep/2022:13:24:16 +0000] \"\\x16\\x03\\x01\\x02\\x00\\x01\\x00\\x01\\xFC\\x03\\x03}\\xA9Dr{\\x8C;\\x90z\\x82\\xAD\\xBC\\x8Az\\xC2x\\xDF\\x1E\\x9A\\xE6l?\\xA7\\xE0DoK\\x91'g\\xBB\\xB5 %\\xBB\\xFD\\xD9\\x82?\\xDB\\x80\\xB3T\\xF6cJ\\xF7\\xE5\\xC2\\xD2\\x11\\xBC\\xA2\\x1F\\x90\\x14\\xA3\\xEB\\xBD=R\\xBC\\x83\\x89\\x85\\x00 \\xCA\\xCA\\x13\\x01\\x13\\x02\\x13\\x03\\xC0+\\xC0/\\xC0,\\xC00\\xCC\\xA9\\xCC\\xA8\\xC0\\x13\\xC0\\x14\\x00\\x9C\\x00\\x9D\\x00/\\x005\\x01\\x00\\x01\\x93\\x9A\\x9A\\x00\\x00\\x00\\x00\\x00\\x0E\\x00\\x0C\\x00\\x00\\x09localhost\\x00\\x17\\x00\\x00\\xFF\\x01\\x00\\x01\\x00\\x00\" 400 157 \"-\" \"-\" \"-\"\n",
"2022-09-13T13:24:39.117398081Z 172.17.0.1 - - [13/Sep/2022:13:24:39 +0000] \"GET / HTTP/1.1\" 200 615 \"-\" \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\" \"-\"\n",
"2022-09-13T13:24:39.117412408Z 2022/09/13 13:24:40 [error] 34#34: *3 open() \"/usr/share/nginx/html/favicon.ico\" failed (2: No such file or directory), client: 172.17.0.1, server: localhost, request: \"GET /favicon.ico HTTP/1.1\", host: \"0.0.0.0:8080\", referrer: \"http://0.0.0.0:8080/\"\n",
"2022-09-13T13:24:40.117419389Z 172.17.0.1 - - [13/Sep/2022:13:24:40 +0000] \"GET /favicon.ico HTTP/1.1\" 404 555 \"http://0.0.0.0:8080/\" \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\" \"-\"\n",
"2022-09-13T13:25:00.117434249Z 172.17.0.1 - - [13/Sep/2022:13:25:00 +0000] \"\\x16\\x03\\x01\\x02\\x00\\x01\\x00\\x01\\xFC\\x03\\x03\\xE2\\x19V$Zqi'\\xD7\\xFC[\\x80\\xEF\\xBA\\xE5\\xC7\\xE8\\xF7&3nS\\xEB\\xC9\\xEC\\x91\\xC2\\xD8\\xD1\\x89\\x9E\\xBE \\xC7?\\xE1\\xFA\\x04a\\x1C\\xCE\\x90\\x0F\\x8F\\x98u\\xE3/\\xD8RfOH\\xEC\\x92+\\x93\\x5C\\xBB\\xB1\\xBF\\xD2m\\xB09\\x00 \\xFA\\xFA\\x13\\x01\\x13\\x02\\x13\\x03\\xC0+\\xC0/\\xC0,\\xC00\\xCC\\xA9\\xCC\\xA8\\xC0\\x13\\xC0\\x14\\x00\\x9C\\x00\\x9D\\x00/\\x005\\x01\\x00\\x01\\x93\\x9A\\x9A\\x00\\x00\\x00\\x00\\x00\\x0E\\x00\\x0C\\x00\\x00\\x09localhost\\x00\\x17\\x00\\x00\\xFF\\x01\\x00\\x01\\x00\\x00\" 400 157 \"-\" \"-\" \"-\"\n",
"2022-09-13T13:25:00.223560881Z 172.17.0.1 - - [13/Sep/2022:13:25:00 +0000] \"\\x16\\x03\\x01\\x02\\x00\\x01\\x00\\x01\\xFC\\x03\\x03)\\x9A\\x8FbC\\xD9m\\xF1\\x86\\xEBd\\x22\\xCF\\xC4E\\x87#~L\\xC1\\x84\\x7F\\xB5\\x91k\\x98\\xABl\\xEE\\x1E[0 \\xD0\\xD2`\\x85\\xC6\\x8B\\x85R\\x8B\\x87\\xEAq{P\\xF2\\xFB\\xE2\\xA8\\x9DI\\xF4tH\\x99\\x13\\x10~\\xCA1-|\\x8E\\x00 \\xEA\\xEA\\x13\\x01\\x13\\x02\\x13\\x03\\xC0+\\xC0/\\xC0,\\xC00\\xCC\\xA9\\xCC\\xA8\\xC0\\x13\\xC0\\x14\\x00\\x9C\\x00\\x9D\\x00/\\x005\\x01\\x00\\x01\\x93\" 400 157 \"-\" \"-\" \"-\"\n",
"2022-09-13T13:26:25.223596738Z 172.17.0.1 - - [13/Sep/2022:13:26:28 +0000] \"GET / HTTP/1.1\" 304 0 \"-\" \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\" \"-\"\n"
          ]
        }
      ],
      "source": [
      "!docker logs --tail -t 10 proxy"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Paramos e excluímos o contêiner"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "proxy\n"
          ]
        }
      ],
      "source": [
      "!docker rm -f proxy"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND               CREATED          STATUS                        PORTS     NAMES\n",
"ce4d60427dcd   ubuntu    \"tail -f /dev/null\"   26 minutes ago   Exited (137) 13 minutes ago             alwaysup\n",
"5b633e9d838f   ubuntu    \"bash\"                31 minutes ago   Exited (0) 27 minutes ago               funny_mirzakhani\n",
"da16b3a85178   ubuntu    \"bash\"                32 minutes ago   Exited (0) 32 minutes ago               hardcore_kare\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "## Dados no Docker"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Montarias vinculadas"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vamos dar uma olhada nos contêineres que estão parados"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND               CREATED          STATUS                        PORTS     NAMES\n",
"ce4d60427dcd   ubuntu    \"tail -f /dev/null\"   26 minutes ago   Exited (137) 13 minutes ago             alwaysup\n",
"5b633e9d838f   ubuntu    \"bash\"                31 minutes ago   Exited (0) 28 minutes ago               funny_mirzakhani\n",
"da16b3a85178   ubuntu    \"bash\"                32 minutes ago   Exited (0) 32 minutes ago               hardcore_kare\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vamos excluir os dois do ubuntu em que seu comando principal é bash e vamos deixar o que deixamos sem operação"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "funny_mirzakhani\n"
          ]
        }
      ],
      "source": [
      "!docker rm funny_mirzakhani"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "hardcore_kare\n"
          ]
        }
      ],
      "source": [
      "!docker rm hardcore_kare"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND               CREATED          STATUS                        PORTS     NAMES\n",
"ce4d60427dcd   ubuntu    \"tail -f /dev/null\"   27 minutes ago   Exited (137) 14 minutes ago             alwaysup\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vamos reiniciar o contêiner do Ubuntu que nos resta, o que é feito usando o comando `start"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "alwaysup\n"
          ]
        }
      ],
      "source": [
      "!docker start alwaysup"
      ]
    },
{
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Voltamos ao assunto"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "root@ce4d60427dcd:/#\n"
          ]
        }
      ],
      "source": [
      "!docker exec -it alwaysup bash"
      ]
    },
{
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "No contêiner, posso criar uma nova pasta chamada ``dockerfolder``."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": []
        }
      ],
      "source": [
      "!mkdir dockerfolder"
      ]
    },
{
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se listarmos os arquivos, a nova pasta será exibida."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "bin  boot  dev  dockerfolder  etc  home  lib  lib32  lib64  libx32  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var"
          ]
        }
      ],
      "source": [
      "!ls"
      ]
    },
{
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se sairmos do contêiner"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "exit"
          ]
        }
      ],
      "source": [
      "!exit"
      ]
    },
{
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "E nós o excluímos"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "alwaysup\n"
          ]
        }
      ],
      "source": [
      "!docker rm -f alwaysup"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se listarmos todos os contêineres, o último que criamos não será mais exibido."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vamos refazer tudo, mas primeiro vamos criar uma pasta no host onde compartilharemos os dados com o contêiner."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
      "!mkdir dockerHostFolder"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vemos que não há nada dentro da pasta."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
      "!ls dockerHostFolder"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Agora temos nossa rota absoluta"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "/home/wallabot/Documentos/web/portafolio/posts\n"
          ]
        }
      ],
      "source": [
      "!pwd"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Recriamos o contêiner, mas adicionamos a opção ``-v`` (``bind mount``). Em seguida, adicione o caminho absoluto da pasta do host e o caminho absoluto da pasta no contêiner, ``-v <caminho do host>:<caminho do contêiner>``."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "4ede4512c293bdcc155e9c8e874dfb4a28e5163f4d5c7ddda24ad2863f28921b\n"
          ]
        }
      ],
      "source": [
      "!docker run -d --name alwaysup -v ~/Documentos/web/portafolio/posts/dockerHostFolder:/dockerContainerFolder ubuntu tail -f /dev/null"
      ]
    },
{
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Entramos no contêiner, listamos os arquivos e a pasta que criamos é exibida."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "root@4ede4512c293:/#"
          ]
        }
      ],
      "source": [
      "!docker exec -it alwaysup bash"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "bin   dev                    etc   lib    lib64   media  opt   root  sbin  sys  usr\n",
"boot  dockerContainerFolder  home  lib32  libx32  mnt    proc  run   srv   tmp  var\n"
          ]
        }
      ],
      "source": [
      "root@4ede4512c293:/# ls"
      ]
    },
{
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vamos para o diretório do contêiner que compartilhamos, criamos um arquivo e saímos do contêiner."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": []
        }
      ],
      "source": [
      "root@4ede4512c293:/# cd dockerContainerFolder"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": []
        }
      ],
      "source": [
      "root@4ede4512c293:/dockerContainerFolder# touch bindFile.txt"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "exit"
          ]
        }
      ],
      "source": [
      "root@4ede4512c293:/dockerContainerFolder# exit"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vemos o que está dentro da pasta compartilhada"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "bindFile.txt\n"
          ]
        }
      ],
      "source": [
      "!ls dockerHostFolder"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Além disso, se excluirmos o contêiner, o arquivo ainda estará lá."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "alwaysup\n"
          ]
        }
      ],
      "source": [
      "!docker rm -f alwaysup"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "bindFile.txt\n"
          ]
        }
      ],
      "source": [
      "!ls dockerHostFolder"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se eu recriar um contêiner compartilhando as pastas, todos os arquivos estarão no contêiner."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "6c021d37ea29d8b23fe5cd4968baa446085ae1756682f65340288b4c851c362d\n"
          ]
        }
      ],
      "source": [
      "!docker run -d --name alwaysup -v ~/Documentos/web/portafolio/posts/dockerHostFolder:/dockerContainerFolder ubuntu tail -f /dev/null"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "root@6c021d37ea29:/#"
          ]
        }
      ],
      "source": [
      "!docker exec -it alwaysup bash"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "bindFile.txt:/#"
          ]
        }
      ],
      "source": [
      "!root@6c021d37ea29:/# ls dockerContainerFolder/"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Removemos o contêiner"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "alwaysup\n"
          ]
        }
      ],
      "source": [
      "!docker rm -f alwaysup"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Volumes"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Os volumes foram criados como uma evolução do ``bind mounts`` para oferecer mais segurança. Podemos listar todos os volumes do docker usando ``docker volume ls``."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "DRIVER    VOLUME NAME\n"
          ]
        }
      ],
      "source": [
      "!docker volume ls"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vamos criar um novo volume para o contêiner do ubuntu, usando o comando ``docker volume create <volume name>``."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "ubuntuVolume\n"
          ]
        }
      ],
      "source": [
      "!docker volume create ubuntuVolume"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se listarmos os volumes novamente, aparecerá o que acabamos de criar."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "DRIVER    VOLUME NAME\n",
"local     ubuntuVolume\n"
          ]
        }
      ],
      "source": [
      "!docker volume ls"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "No entanto, ele não aparece como uma pasta no sistema de arquivos do host. Com `ls -d */`, listamos todas as pastas"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "dockerHostFolder/  __pycache__/\n"
          ]
        }
      ],
      "source": [
      "!ls -d */"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vamos criar um contêiner novamente, mas agora vamos criá-lo com o volume que acabamos de criar com a opção ``--mount``, indicando o volume de origem por ``src=<nome do volume>` (se o volume não existir, o docker o criará), depois o destino separado por ``,``, ``dst=<caminho do contêiner>`, ou seja, ``--mount src=<nome do volume>,dst=<caminho do contêiner>``."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "42cdcddf4e46dc298a87b0570115e0b2fc900cb4c6db5eea22a61409b8cb271d\n"
          ]
        }
      ],
      "source": [
      "!docker run -d --name alwaysup --mount src=ubuntuVolume,dst=/dockerVolumeFolder ubuntu tail -f /dev/null"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Após a criação, podemos visualizar os volumes do contêiner usando o comando ``inspect`` e filtrando por `'{{.Mounts}}'`.\n",
"\n",
"````bash\n",
"$ docker inspect --format '{{.Mounts}}' alwaysup\n",
"[\n",
"    {\n",
"        volume ubuntuVolume /var/lib/docker/volumes/ubuntuVolume/_data /dockerVolumeFolder local z true\n",
"    }\n",
"\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vemos que o volume se chama `ubuntuVolume` e também podemos ver o caminho onde ele está armazenado, nesse caso em `/var/lib/docker/volumes/ubuntuVolume/_data`. Fazemos o mesmo que antes, entramos no contêiner, criamos um arquivo no caminho do volume, saímos e vemos no host se ele foi criado.\n",
"\n",
"````bash\n",
"$ docker exec -it alwaysup bash\n",
"root@42cdcdcddf4e46:/# touch dockerVolumeFolder/volumeFile.txt\n",
"root@42cdcdcddf4e46:/# exit\n",
"```\n",
"\n",
"\n",
"````bash\n",
"$ sudo ls /var/lib/docker/volumes/ubuntuVolume/_data\n",
"volumeFile.txt\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "O arquivo é criado"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Inserção e extração de arquivos de um contêiner"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Primeiro, criaremos um arquivo que queremos copiar para um contêiner."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
      "!touch dockerHostFolder/text.txt"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Entramos no contêiner\n",
"\n",
"````bash\n",
"$ docker exec -it alwaysup bash\n",
"root@42cdcdcddf4e46:/#\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Criamos uma nova pasta na qual copiaremos o arquivo e saímos\n",
"\n",
"````bash\n",
"root@42cdcdcddf4e46:/# mkdir folderToCopy\n",
"root@42cdcdcddf4e46:/# ls\n",
"bin boot dev dockerVolumeFolder etc folderToCopy home lib lib32 lib64 libx32 libx32 media mnt opt proc root run sbin srv sys tmp usr var\n",
"root@42cdcdcddf4e46:/# exit\n",
"saída\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Copiamos o arquivo dentro do contêiner usando o comando ``cp``, indicando o arquivo que queremos copiar, o contêiner onde queremos copiá-lo e o caminho dentro do contêiner, ``docker cp <arquivo> <contêiner>:<caminho do contêiner>``."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
      "!docker cp dockerHostFolder/text.txt alwaysup:/folderToCopy"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Entramos novamente no contêiner e verificamos se o arquivo está lá.\n",
"\n",
"````bash\n",
"$ docker exec -it alwaysup bash\n",
"root@42cdcdcddf4e46:/# ls folderToCopy/\n",
"text.txt\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Saímos do contêiner\n",
"\n",
"````bash\n",
"/# saída\n",
"saída\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Agora vamos extrair o arquivo do contêiner e salvá-lo no host com outro nome, para isso usamos o comando ``cp`` novamente, mas indicando agora o contêiner, o caminho do arquivo no contêiner e o caminho e o nome do arquivo que queremos que tenha no host, ``docker cp <container>:<docker file path> <host file path>``."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
      "!docker cp alwaysup:/folderToCopy/text.txt dockerHostFolder/fileExtract.txt"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vimos que você está no host"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "bindFile.txt  fileExtract.txt  text.txt\n"
          ]
        }
      ],
      "source": [
      "!ls dockerHostFolder"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Mesmo que o contêiner esteja parado, os arquivos também podem ser copiados."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Por fim, excluímos o contêiner"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "alwaysup\n"
          ]
        }
      ],
      "source": [
      "!docker rm -f alwaysup"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "## Imagens"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Conceitos fundamentais"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "As imagens são os arquivos (\"modelos\") com toda a configuração para criar um contêiner. Toda vez que criamos um contêiner, ele é criado a partir de uma imagem. Quando criamos novos contêineres, na primeira vez recebemos uma mensagem dizendo que não tínhamos a imagem e que iríamos baixá-la. No docker hub, há muitas imagens com todos os tipos de máquinas, mas, para um ambiente de desenvolvimento muito específico, podemos criar nosso próprio modelo para passá-lo a outra pessoa e ela trabalhará em um contêiner com a mesma configuração que a nossa."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Podemos ver todas as imagens que salvamos em nosso computador usando o comando ``docker image ls``."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "REPOSITORY    TAG       IMAGE ID       CREATED         SIZE\n",
"nginx         latest    2d389e545974   8 hours ago     142MB\n",
"ubuntu        latest    2dc39ba059dc   11 days ago     77.8MB\n",
"hello-world   latest    feb5d9fea6a5   11 months ago   13.3kB\n"
          ]
        }
      ],
      "source": [
      "!docker image ls"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Podemos ver os tamanhos e podemos ver como o `nginx` ocupa muito espaço e é por isso que o download demorou mais do que os demais."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Outra coluna que podemos ver é a coluna ``TAG``, que indica a versão da imagem. Em todas elas está escrito ``latest``, o que significa que é a mais recente. Ou seja, no momento do download, baixamos a versão mais recente no docker hub. Isso não é o ideal em um ambiente de desenvolvimento, pois podemos baixar uma imagem do Ubuntu e, se não especificarmos uma versão, ela baixará a mais recente, por exemplo, 20.04. Mas, depois de algum tempo, alguém pode querer desenvolver com você e baixar essa imagem, mas, se não especificar a versão, ele baixará novamente a mais recente, que, no seu caso, pode ser a 22.04. Isso pode gerar problemas e coisas que uma pessoa trabalha e a outra não."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Você pode ver todas as imagens no hub do docker acessando ``https://hub.docker.com/``. Lá, você pode pesquisar a imagem que melhor se adapta ao projeto que deseja realizar. Se navegarmos até a imagem do Ubuntu, por exemplo, poderemos ver as versões (`tags`) das imagens."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vamos fazer o download, **mas não executar**, de uma imagem. Para fazer isso, usamos o comando ``docker pull <hub> <nome da imagem>:<tag>``. Se não especificarmos o hub, o download será feito a partir do hub padrão do docker, mas podemos especificar outro, por exemplo, um hub privado de nossa organização. Além disso, se não especificarmos a tag, ele fará o download da versão mais recente por padrão."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "20.04: Pulling from library/ubuntu\n",
"\n",
"\u001b[1BDigest: sha256:35ab2bf57814e9ff49e365efd5a5935b6915eede5c7f8581e9e1b85e0eecbe16[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\n",
"Status: Downloaded newer image for ubuntu:20.04\n",
"docker.io/library/ubuntu:20.04\n"
          ]
        }
      ],
      "source": [
      "!docker pull ubuntu:20.04"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se listarmos as imagens novamente, veremos que agora temos duas imagens do ubuntu, uma com a tag ``20.04`` e outra com a tag ``latest``."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "REPOSITORY    TAG       IMAGE ID       CREATED         SIZE\n",
"nginx         latest    2d389e545974   8 hours ago     142MB\n",
"ubuntu        latest    2dc39ba059dc   11 days ago     77.8MB\n",
"ubuntu        20.04     a0ce5a295b63   11 days ago     72.8MB\n",
"hello-world   latest    feb5d9fea6a5   11 months ago   13.3kB\n"
          ]
        }
      ],
      "source": [
      "!docker image ls"
      ]
    },
{
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Criar imagens usando o `Dockerfile`."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Criamos um diretório no host chamado ``dockerImages`` para trabalhar no"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
      "!mkdir dockerImages"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Criamos um ``Dockerfile`` com o qual criaremos uma imagem."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
      "!touch dockerImages/Dockerfile"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Abra o arquivo criado com seu editor preferido e digite o seguinte:\n",
"\n",
"````Dockerfile\n",
"DE ubuntu:latest\n",
"```\n",
"\n",
"Isso diz ao docker para criar a imagem a partir da imagem \"mais recente\" do Ubuntu."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Em seguida, escrevemos um comando a ser executado no momento da compilação\n",
"\n",
"```DOckerfile\n",
"RUN touch /test.txt\n",
"```\n",
"\n",
"Isso significa que, quando o `Dockefile` for compilado, esse comando será executado, mas não quando o contêiner de imagem for executado."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "No final, o `Dockerfile` tem a seguinte aparência:\n",
"````dockerfile\n",
"    DE ubuntu:latest\n",
"    RUN touch /test.txt\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Compilamos o `Dockerfile` usando o comando `build`, com a opção `-t` podemos dar a ele uma `tag`. Por fim, temos que fornecer o caminho para o contexto `build`, o que explicaremos mais tarde."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Sending build context to Docker daemon  2.048kB\n",
"Step 1/2 : FROM ubuntu:latest\n",
" ---> 2dc39ba059dc\n",
"Step 2/2 : RUN touch /test.txt\n",
" ---> Using cache\n",
" ---> a78cf3ea16d8\n",
"Successfully built a78cf3ea16d8\n",
"Successfully tagged ubuntu:test\n",
"\n",
"Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\n"
          ]
        }
      ],
      "source": [
      "!docker build -t ubuntu:test ./dockerImages"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Como podemos ver, ele é compilado em duas etapas, cada uma com um `id`, e cada um desses `id` são camadas da imagem, como veremos mais adiante.\n",
"\n",
"Voltamos às imagens que salvamos em nosso computador e a que acabamos de criar aparece."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "REPOSITORY    TAG       IMAGE ID       CREATED         SIZE\n",
"ubuntu        test      a78cf3ea16d8   8 minutes ago   77.8MB\n",
"nginx         latest    2d389e545974   8 hours ago     142MB\n",
"ubuntu        latest    2dc39ba059dc   11 days ago     77.8MB\n",
"ubuntu        20.04     a0ce5a295b63   11 days ago     72.8MB\n",
"hello-world   latest    feb5d9fea6a5   11 months ago   13.3kB\n"
          ]
        }
      ],
      "source": [
      "!docker image ls"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Executamos o contêiner a partir da imagem que acabamos de criar.\n",
"\n",
"````bash\n",
"$ docker run -it ubuntu:test\n",
"root@b57b9d4eedeb:/#\n",
"```\n",
"\n",
"Entramos no bash do contêiner. Como dissemos, o comando RUN foi executado no momento da compilação da imagem, portanto, o arquivo que pedimos para ser criado deve estar em nosso contêiner.\n",
"\n",
"````bash\n",
"root@b57b9d4eedeb:/# ls\n",
"bin boot dev etc home lib lib32 lib32 lib64 lib64 libx32 media mnt opt proc root run sbin srv sys test.txt tmp usr var\n",
"```\n",
"\n",
"É importante entender que esse arquivo foi criado quando a imagem foi construída, ou seja, a imagem do contêiner já tem esse arquivo. Ele não é criado quando o contêiner é iniciado\n",
"\n",
"Saímos do contêiner\n",
"\n",
"````bash\n",
"root@b57b9d4eedeb:/# exit\n",
"saída\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Como já temos uma imagem, podemos carregá-la no hub do docker, mas vamos listar novamente as imagens antes disso."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "REPOSITORY    TAG       IMAGE ID       CREATED          SIZE\n",
"ubuntu        test      a78cf3ea16d8   20 minutes ago   77.8MB\n",
"nginx         latest    2d389e545974   8 hours ago      142MB\n",
"ubuntu        latest    2dc39ba059dc   11 days ago      77.8MB\n",
"ubuntu        20.04     a0ce5a295b63   11 days ago      72.8MB\n",
"hello-world   latest    feb5d9fea6a5   11 months ago    13.3kB\n"
          ]
        }
      ],
      "source": [
      "!docker image ls"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se virmos que ele está nos dizendo que a imagem que acabamos de criar pertence ao repositório do ubuntu, mas não temos acesso ao repositório do ubuntu, então no docker hub temos que criar uma conta para fazer upload da imagem para o nosso repositório. No meu caso, meu repositório se chama `maximofn`, então altero o repositório da imagem usando o comando `tag`, indicando a imagem que queremos alterar o repositório e o novo repositório. No novo repositório, você geralmente especifica o nome do repositório seguido do tipo de imagem e da tag, no meu caso `maximofn/ubuntu:test`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
      "!docker tag ubuntu:test maximofn/ubuntu:test"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se agora listarmos as imagens novamente"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "REPOSITORY        TAG       IMAGE ID       CREATED          SIZE\n",
"ubuntu            test      a78cf3ea16d8   24 minutes ago   77.8MB\n",
"maximofn/ubuntu   test      a78cf3ea16d8   24 minutes ago   77.8MB\n",
"nginx             latest    2d389e545974   8 hours ago      142MB\n",
"ubuntu            latest    2dc39ba059dc   11 days ago      77.8MB\n",
"ubuntu            20.04     a0ce5a295b63   11 days ago      72.8MB\n",
"hello-world       latest    feb5d9fea6a5   11 months ago    13.3kB\n"
          ]
        }
      ],
      "source": [
      "!docker image ls"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Agora precisamos fazer login no hub do docker para fazer upload da imagem, usando o comando `login`.\n",
"\n",
"````bash\n",
"$ docker login\n",
"Faça login com seu Docker ID para enviar e extrair imagens do Docker Hub. Se você não tiver um ID do Docker, acesse https://hub.docker.com para criar um.\n",
"Nome de usuário: maximofn\n",
"Senha:\n",
"\n",
"Login bem-sucedido\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Agora podemos fazer upload da imagem usando o comando `push`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "The push refers to repository [docker.io/maximofn/ubuntu]\n",
"\n",
"\u001b[1B06994357: Preparing \n",
"\u001b[2B06994357: Pushed  from library/ubuntu \u001b[2A\u001b[2Ktest: digest: sha256:318d83fc3c35ff930d695b0dc1c5ad1b0ea54e1ec6e3478b8ca85c05fd793c4e size: 735\n"
          ]
        }
      ],
      "source": [
      "!docker push maximofn/ubuntu:test"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Ele carregou apenas a primeira camada, a segunda, como eu a usei depois da imagem do Ubuntu, o que ele faz é colocar um ponteiro para essa imagem para evitar que as camadas sejam carregadas mais de uma vez."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Observe que esse repositório é público, portanto, você não deve carregar imagens com dados confidenciais. Além disso, se uma imagem não for usada dentro de 6 meses, ela será excluída."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### O sistema de camadas"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Usando o comando `history`, podemos visualizar as camadas de uma imagem. Se quisermos ver as camadas da imagem que acabamos de criar, usaremos o comando `docker history ubuntu:test`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "IMAGE          CREATED        CREATED BY                                      SIZE      COMMENT\n",
"a78cf3ea16d8   3 minutes ago  /bin/sh -c touch /test.txt                      0B        \n",
"2dc39ba059dc   12 days ago    /bin/sh -c #(nop)  CMD [\"bash\"]                 0B        \n",
"<missing>      12 days ago    /bin/sh -c #(nop) ADD file:a7268f82a86219801…   77.8MB    \n"
          ]
        }
      ],
      "source": [
      "!docker history ubuntu:test"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vemos que a primeira camada tem o comando que inserimos no `Dockerfile` e diz que foi criada há 3 minutos. No entanto, o restante das camadas foi criado há 12 dias e são as camadas da imagem do Ubuntu na qual nos baseamos."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "No `Dockerfile` que criamos anteriormente, adicionamos a linha\n",
"\n",
"```docker\n",
"EXECUTAR rm /test.txt\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "No final, o `Dockerfile` tem a seguinte aparência:\n",
"````dockerfile\n",
"    DE ubuntu:latest\n",
"    RUN touch /test.txt\n",
"    EXECUTAR rm /test.txt\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se compilarmos novamente, veremos o que acontece"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Sending build context to Docker daemon  2.048kB\n",
"Step 1/3 : FROM ubuntu:latest\n",
" ---> 2dc39ba059dc\n",
"Step 2/3 : RUN touch /test.txt\n",
" ---> Using cache\n",
" ---> a78cf3ea16d8\n",
"Step 3/3 : RUN rm /test.txt\n",
" ---> Running in c2e6887f2025\n",
"Removing intermediate container c2e6887f2025\n",
" ---> 313243a9b573\n",
"Successfully built 313243a9b573\n",
"Successfully tagged ubuntu:test\n",
"\n",
"Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\n"
          ]
        }
      ],
      "source": [
      "!docker build -t ubuntu:test ./dockerImages"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Como podemos ver, há mais uma camada com a nova linha que adicionamos. Se olharmos novamente para as camadas da imagem com `history`, veremos que há mais uma camada com a nova linha."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "IMAGE          CREATED              CREATED BY                                      SIZE      COMMENT\n",
"313243a9b573   About a minute ago   /bin/sh -c rm /test.txt                         0B        \n",
"a78cf3ea16d8   3 minutes ago        /bin/sh -c touch /test.txt                      0B        \n",
"2dc39ba059dc   12 days ago          /bin/sh -c #(nop)  CMD [\"bash\"]                 0B        \n",
"<missing>      12 days ago          /bin/sh -c #(nop) ADD file:a7268f82a86219801…   77.8MB    \n"
          ]
        }
      ],
      "source": [
      "!docker history ubuntu:test"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Podemos ver que as primeiras camadas são as mesmas de antes e que você adicionou uma nova camada com o novo comando"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "## Usando o docker para criar aplicativos"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Exibição da porta"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Anteriormente, vimos como poderíamos vincular uma porta de contêiner a uma porta de computador (`-p 8080:80`). Mas, para que isso seja possível, ao criar a imagem, você precisa expor a porta, o que é feito adicionando ao Dockerfile a linha `EXPOSE <port>`, no caso de antes\n",
"\n",
"```docker\n",
"EXPOSE 80\n",
"```\n",
"\n",
"Ou use imagens como base que já tenham portas expostas."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Reutilização do cache de camada na compilação"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Quando compilamos uma imagem, se alguma das camadas que definimos já tiver sido compilada antes, o docker detecta isso e as utiliza, não as recompila. Se recompilarmos a imagem que definimos no `Dockerfile` agora, isso levará muito pouco tempo, pois todas as camadas já foram compiladas e o docker não as recompila."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Sending build context to Docker daemon  2.048kB\n",
"Step 1/3 : FROM ubuntu:latest\n",
" ---> 2dc39ba059dc\n",
"Step 2/3 : RUN touch /test.txt\n",
" ---> Using cache\n",
" ---> a78cf3ea16d8\n",
"Step 3/3 : RUN rm /test.txt\n",
" ---> Using cache\n",
" ---> 313243a9b573\n",
"Successfully built 313243a9b573\n",
"Successfully tagged ubuntu:test\n",
"\n",
"Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\n"
          ]
        }
      ],
      "source": [
      "!docker build -t ubuntu:test ./dockerImages"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Na segunda e terceira camadas, aparece o texto `Usando cache`.\n",
"\n",
"Como esse é um notebook Jupyter, ao executar as células, ele fornece as informações sobre o tempo de execução; na vez anterior em que compilei a imagem, levou 1,4 segundo, enquanto agora levou 0,5 segundo."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Mas se eu agora alterar o Dockerfile e, na primeira linha, onde dizia que estávamos nos baseando na versão mais recente do Ubuntu, e mudarmos para a versão 20.04, alterarei o Dockerfile para a versão 20.04.\n",
"\n",
"```docker\n",
"DO ubuntu:20.04\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "No final, o `Dockerfile` tem a seguinte aparência:\n",
"````dockerfile\n",
"    DO ubuntu:20.04\n",
"    RUN touch /test.txt\n",
"    EXECUTAR rm /test.txt\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "A recompilação levará muito mais tempo."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Sending build context to Docker daemon  2.048kB\n",
"Step 1/3 : FROM ubuntu:20.04\n",
" ---> a0ce5a295b63\n",
"Step 2/3 : RUN touch /test.txt\n",
" ---> Running in a40fe8df2c0d\n",
"Removing intermediate container a40fe8df2c0d\n",
" ---> 0bb9b452c11f\n",
"Step 3/3 : RUN rm /test.txt\n",
" ---> Running in 2e14919f3685\n",
"Removing intermediate container 2e14919f3685\n",
" ---> fdc248fa833b\n",
"Successfully built fdc248fa833b\n",
"Successfully tagged ubuntu:test\n",
"\n",
"Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\n"
          ]
        }
      ],
      "source": [
      "!docker build -t ubuntu:test ./dockerImages"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Levou 1,9 segundos e o texto `Usando cache` não é mais exibido."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Ao alterar a primeira camada, a janela de encaixe recompila todas as camadas. Isso pode ser um problema porque, ao desenvolver o código, pode ocorrer o seguinte caso\n",
" * Desenvolvemos o código em nosso computador\n",
" * Ao criar a imagem, copiamos todo o código do nosso computador para o contêiner.\n",
" * Em seguida, solicitamos que a imagem instale as bibliotecas necessárias.\n",
"\n",
"Isso pode significar que, ao alterar qualquer parte do código, a camada na qual as bibliotecas estão instaladas terá de ser recompilada, pois uma camada anterior foi alterada."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Para resolver isso, a ideia seria que, ao criar a imagem, primeiro solicitássemos a instalação das bibliotecas e, em seguida, copiássemos o código do nosso computador para o contêiner. Dessa forma, toda vez que alterarmos o código e compilarmos a imagem novamente, somente a camada em que o código foi copiado será recompilada, de modo que a compilação será mais rápida."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Você pode pensar que é melhor compartilhar uma pasta entre o host e o container (`bind mount`) onde teremos o código e assim não precisaremos recompilar a imagem toda vez que alterarmos o código. E a resposta é que isso é verdade, só coloquei esse exemplo porque é muito fácil de entender, mas é para mostrar que, ao criar imagens, você deve pensar bem para que, se precisar recompilar, recompile o número mínimo de camadas."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Como escrever corretamente um Dockerfile"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Como vimos, o Docker não recompila as camadas de um Dockerfile se já as tiver compilado antes, portanto, ele as carrega do cache. Vamos ver como deve ser a maneira correta de escrever um Dockerfile para tirar proveito disso"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vamos começar com esse Dockerfile para comentar sobre possíveis correções.\n",
"\n",
"``` Dockerfile\n",
"DO ubuntu\n",
"COPY ./sourceCode /sourceCode\n",
"Execute o apt-get update\n",
"Executar apt-get install -y python3 ssh\n",
"CMD [\"python3\", \"/sourceCode/sourceApp/app.py\"]\n",
"```\n",
"\n",
"Como você pode ver, você inicia a partir de uma imagem do Ubuntu, copia a pasta com o código, atualiza os repositórios, instala o python, instala o ssh e executa o aplicativo."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "#### Copiar código antes da execução"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Como dissemos antes, se primeiro copiarmos o código e depois instalarmos o python, toda vez que fizermos uma alteração no código e compilarmos a imagem, ela compilará toda a imagem, mas se copiarmos o código depois de instalar o python, toda vez que alterarmos o código e compilarmos a imagem, ela compilará somente a partir da cópia do código e não reinstalará o python, portanto, o Dockerfile deverá ter a seguinte aparência\n",
"\n",
"``` Dockerfile\n",
"DO ubuntu\n",
"Execute o apt-get update\n",
"Executar apt-get install -y python3 ssh\n",
"COPY ./sourceCode /sourceCode\n",
"CMD [\"python3\", \"/sourceCode/sourceApp/app.py\"]\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "#### Copie apenas o código necessário"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Estamos copiando a pasta com todo o código, mas talvez tenhamos um código dentro que não precisamos, portanto, temos que copiar apenas o código que realmente precisamos para o aplicativo, dessa forma a imagem ocupará menos memória. Portanto, o Dockerfile teria a seguinte aparência\n",
"\n",
"``` Dockerfile\n",
"DO ubuntu\n",
"Execute o apt-get update\n",
"Executar apt-get install -y python3 ssh\n",
"COPY ./sourceCode/sourceApp /sourceCode/sourceApp\n",
"CMD [\"python3\", \"/sourceCode/sourceApp/app.py\"]\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "#### Atualize os repositórios e instale o python na mesma linha"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Estamos atualizando os repositórios em uma linha e instalando o python3 em outra. Mas pode acontecer que, na linha em que instalamos o python3, também adicionemos o pip3; no entanto, como a linha anterior, em que os repositórios são atualizados, não é alterada, ela não será compilada novamente, pois está em cache. Portanto, pode acontecer que os repositórios que atualizamos não contenham os repositórios necessários para o pip3. Portanto, é preciso colocar as duas ações em uma única linha\n",
"\n",
"``` Dockerfile\n",
"DO ubuntu\n",
"Execute o apt-get update && apt-get install -y python3 ssh\n",
"COPY ./sourceCode/sourceApp /sourceCode/sourceApp\n",
"CMD [\"python3\", \"/sourceCode/sourceApp/app.py\"]\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "#### Não instale o ssh"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Instalamos o ssh na imagem para que pudéssemos depurar se fosse necessário, mas isso faz com que a imagem ocupe mais memória. Caso precisemos depurar, devemos entrar no contêiner, instalar o ssh e depois depurar. Portanto, removemos a instalação do ssh.\n",
"\n",
"``` Dockerfile\n",
"DO ubuntu\n",
"Execute o apt-get update && apt-get install -yython3\n",
"COPY ./sourceCode/sourceApp /sourceCode/sourceApp\n",
"CMD [\"python3\", \"/sourceCode/sourceApp/app.py\"]\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "#### Use `--no-install-recommends`."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Quando instalamos algo no Ubuntu, ele instala os pacotes recomendados, mas não precisamos deles, o que faz com que a imagem ocupe mais espaço. Portanto, para evitar isso, adicionamos \"no-install-recommends\" à instalação.\n",
"\n",
"``` Dockerfile\n",
"DO ubuntu\n",
"Execute o apt-get update && apt-get install -yython3 --no-install-recommends\n",
"COPY ./sourceCode/sourceApp /sourceCode/sourceApp\n",
"CMD [\"python3\", \"/sourceCode/sourceApp/app.py\"]\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "#### Limpar a lista de repositórios atualizados"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Atualizamos a lista de repositórios e instalamos o python, mas, depois de fazer isso, não precisamos mais da lista de repositórios atualizada, porque eles só aumentarão a imagem, então os removemos depois de instalar o python e na mesma linha\n",
"\n",
"``` Dockerfile\n",
"DO ubuntu\n",
"EXECUTAR apt-get update && apt-get install -yython3 --no-install-recommends && rm -rf /var/lib/apt/lists/*\n",
"COPY ./sourceCode/sourceApp /sourceCode/sourceApp\n",
"CMD [\"python3\", \"/sourceCode/sourceApp/app.py\"]\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "#### Usando uma imagem Python"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Tudo o que fizemos para atualizar a lista de pacotes e instalar o Python não é necessário, pois já existem imagens do Python no Ubuntu, que provavelmente também seguiram as boas práticas, que se saíram até melhor do que nós e que foram verificadas quanto a vulnerabilidades pelo Docker Hub. Então, tiramos tudo isso e começamos com uma imagem do Python\n",
"\n",
"``` Dockerfile\n",
"DE python\n",
"COPY ./sourceCode/sourceApp /sourceCode/sourceApp\n",
"CMD [\"python3\", \"/sourceCode/sourceApp/app.py\"]\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "#### Especificando a imagem do Python"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Ao não especificar a imagem do Python, você está baixando a mais recente, mas, dependendo de quando você constrói o contêiner, pode baixar uma ou outra, portanto, é necessário adicionar a tag com a versão do Python que você deseja\n",
"\n",
"``` Dockerfile\n",
"DE python:3.9.18\n",
"COPY ./sourceCode/sourceApp /sourceCode/sourceApp\n",
"CMD [\"python3\", \"/sourceCode/sourceApp/app.py\"]\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "#### Escolha uma etiqueta pequena"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Escolhemos a tag `3.9.18`, mas essa versão do python tem muitas bibliotecas de que talvez não precisemos, portanto, podemos usar a versão `3.9.18-slim`, que tem muito menos bibliotecas instaladas, ou a versão `3.9.18-alphine`, que é uma versão do python sobre o alpine e não sobre o Ubuntu. O Alpine é uma distribuição Linux muito leve que tem pouquíssimos pacotes instalados e é frequentemente usada em contêineres do Docker para que ocupem pouco espaço.\n",
"\n",
"A imagem python `3.9.18` tem 997 MB, a `3.9.18-slim` tem 126 MB e a `3.9.18-alpine` tem 47,8 MB.\n",
"\n",
"``` Dockerfile\n",
"DE python:3.9.18-alpine\n",
"COPY ./sourceCode/sourceApp /sourceCode/sourceApp\n",
"CMD [\"python3\", \"/sourceCode/sourceApp/app.py\"]\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "#### Indicar o espaço de trabalho"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Em vez de especificar o caminho para a imagem `/sourceCode/sourceApp`, definimos o caminho para o espaço de trabalho da imagem. Dessa forma, quando copiarmos o código ou executarmos o aplicativo, não precisaremos indicar o caminho\n",
"\n",
"``` Dockerfile\n",
"DE python:3.9.18-alpine\n",
"WORKDIR /sourceCode/sourceApp\n",
"COPY ./sourceCode/sourceApp .\n",
"CMD [\"python3\", \"app.py\"]\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "#### Indicar o espaço de trabalho"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Em vez de especificar o caminho para a imagem `/sourceCode/sourceApp`, definimos o caminho para o espaço de trabalho da imagem. Dessa forma, quando copiarmos o código ou executarmos o aplicativo, não precisaremos indicar o caminho\n",
"\n",
"``` Dockerfile\n",
"DE python:3.9.18-alpine\n",
"WORKDIR /sourceCode/sourceApp\n",
"COPY ./sourceCode/sourceApp .\n",
"CMD [\"python3\", \"app.py\"]\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Código compartilhado em uma pasta `bind mount`"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Criamos uma pasta chamada `dockerHostFolder` na qual compartilhamos arquivos entre o host e um contêiner. Dentro dela, também deve haver três arquivos"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "bindFile.txt  fileExtract.txt  text.txt\n"
          ]
        }
      ],
      "source": [
      "!ls dockerHostFolder"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vamos aproveitar o arquivo `text.txt` para dar uma olhada nisso. Vamos ver o que há dentro do arquivo `text.txt`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
      "!cat dockerHostFolder/text.txt"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Não há saída, o arquivo está vazio. Vamos criar novamente um contêiner do Ubuntu que compartilha a pasta `dockerHostFolder`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "24adbded61f507cdf7f192eb5e246e43ee3ffafc9944b7c57918eb2d547dff19\n"
          ]
        }
      ],
      "source": [
      "!docker run --name alwaysup -d -v ~/Documentos/web/portafolio/posts/dockerHostFolder:/dockerContainerFolder ubuntu tail -f /dev/null"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vemos que o contêiner está em execução"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND               CREATED          STATUS          PORTS     NAMES\n",
"24adbded61f5   ubuntu    \"tail -f /dev/null\"   16 seconds ago   Up 15 seconds             alwaysup\n"
          ]
        }
      ],
      "source": [
      "!docker ps"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Entramos no contêiner, vemos que `text.txt` está lá e que está vazio.\n",
"\n",
"````bash\n",
"$ docker exec -it alwaysup bash\n",
"root@24adbded61f5:/# ls dockerContainerFolder/\n",
"bindFile.txt fileExtract.txt fileExtract.txt text.txt\n",
"root@24adbded61f5:/# cat dockerContainerFolder/text.txt\n",
"root@24adbded61f5:/#\n",
"```\n",
"\n",
"Agora, abrimos o arquivo `text.txt` no host com o editor de texto de nossa escolha, digitamos `Hello world` e salvamos. Se agora virmos o que está dentro do arquivo no contêiner, veremos o mesmo texto\n",
"\n",
"````bash\n",
"root@24adbded61f5:/# cat dockerContainerFolder/text.txt\n",
"Olá mundo\n",
"```\n",
"\n",
"Agora, editamos o arquivo no contêiner e saímos dele.\n",
"\n",
"````bash\n",
"root@24adbded61f5:/# echo hello container > dockerContainerFolder/text.txt\n",
"root@24adbded61f5:/# cat dockerContainerFolder/text.txt\n",
"hello container\n",
"root@24adbded61f5:/# exit\n",
"saída\n",
"```\n",
"\n",
"Se olharmos o arquivo no host, veremos o texto que escrevemos no contêiner"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "hola contenedor\n"
          ]
        }
      ],
      "source": [
      "!cat dockerHostFolder/text.txt"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Excluímos o contêiner"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "alwaysup\n"
          ]
        }
      ],
      "source": [
      "!docker rm -f alwaysup"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Conectar contêineres via rede"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se quisermos ter vários contêineres em execução e quisermos que eles se comuniquem, podemos fazer com que eles se comuniquem por meio de uma rede. O Docker nos dá a possibilidade de fazer isso por meio de suas redes virtuais."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vamos ver quais redes o docker possui usando o comando `docker network ls`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "NETWORK ID     NAME      DRIVER    SCOPE\n",
"de6e8b7b737e   bridge    bridge    local\n",
"da1f5f6fccc0   host      host      local\n",
"d3b0d93993c0   none      null      local\n"
          ]
        }
      ],
      "source": [
      "!docker network ls"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vemos que, por padrão, o docker tem três redes\n",
" * Bridge: é compatível com versões anteriores, mas não devemos mais usá-la.\n",
" * Host: essa é a rede do host\n",
" * none: É a opção a ser usada se quisermos que um contêiner não tenha acesso à Internet."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Podemos criar novas redes às quais outros contêineres podem se conectar. Para isso, usamos o comando `docker network create <name>`, para que outros contêineres possam se conectar a ela, também devemos adicionar a opção `--attachable`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "2f6f3ddbfa8642e9f6819aa0965c16339e9e910be7bcf56ebb718fcac324cc27\n"
          ]
        }
      ],
      "source": [
      "!docker network create --attachable myNetwork"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Podemos inspecioná-lo usando o comando `docker network inspect <name>`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "[\n",
"    {\n",
"        \"Name\": \"myNetwork\",\n",
"        \"Id\": \"2f6f3ddbfa8642e9f6819aa0965c16339e9e910be7bcf56ebb718fcac324cc27\",\n",
"        \"Created\": \"2022-09-14T15:20:08.539830161+02:00\",\n",
"        \"Scope\": \"local\",\n",
"        \"Driver\": \"bridge\",\n",
"        \"EnableIPv6\": false,\n",
"        \"IPAM\": {\n",
"            \"Driver\": \"default\",\n",
"            \"Options\": {},\n",
"            \"Config\": [\n",
"                {\n",
"                    \"Subnet\": \"172.18.0.0/16\",\n",
"                    \"Gateway\": \"172.18.0.1\"\n",
"                }\n",
"            ]\n",
"        },\n",
"        \"Internal\": false,\n",
"        \"Attachable\": true,\n",
"        \"Ingress\": false,\n",
"        \"ConfigFrom\": {\n",
"            \"Network\": \"\"\n",
"        },\n",
"        \"ConfigOnly\": false,\n",
"        \"Containers\": {},\n",
"        \"Options\": {},\n",
"        \"Labels\": {}\n",
"    }\n",
"]\n"
          ]
        }
      ],
      "source": [
      "!docker network inspect myNetwork"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Agora precisamos criar dois contêineres para que eles possam se comunicar."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vamos criar um novo contêiner, que chamaremos de `contêiner1`, com uma pasta compartilhada e, dentro dela, será chamado de `pasta1`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "a5fca8ba1e4ff0a67002f8f1b8cc3cd43185373c2a7e295546f774059ad8dd1a\n"
          ]
        }
      ],
      "source": [
      "!docker run --name container1 -d -v ~/Documentos/web/portafolio/posts/dockerHostFolder:/folder1 ubuntu tail -f /dev/null"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Agora criamos outro contêiner, chamado `container2`, com outra pasta compartilhada, mas chamada `folder2`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "6c8dc18315488ef686f7548516c19b3d716728dd8a173cdb889ec0dd082232f9\n"
          ]
        }
      ],
      "source": [
      "!docker run --name container2 -d -v ~/Documentos/web/portafolio/posts/dockerHostFolder:/folder2 ubuntu tail -f /dev/null"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vemos os contêineres funcionando e vemos que ambos são"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND               CREATED         STATUS         PORTS     NAMES\n",
"6c8dc1831548   ubuntu    \"tail -f /dev/null\"   3 seconds ago   Up 2 seconds             container2\n",
"a5fca8ba1e4f   ubuntu    \"tail -f /dev/null\"   4 seconds ago   Up 3 seconds             container1\n"
          ]
        }
      ],
      "source": [
      "!docker ps"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Agora temos que conectar os contêineres à rede, para isso usamos o comando `docker network connect <nome da rede> <nome do contêiner>`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
      "!docker network connect myNetwork container1"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
      "!docker network connect myNetwork container2"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Para verificar se eles estão bem conectados, podemos inspecionar a rede, mas filtrando pelos contêineres conectados.\n",
"\n",
"````bash\n",
"$ docker network inspect --format '{{.Containers}}' myNetwork\n",
"mapa\n",
"[\n",
"    6c8dc18315488ef686f7548516c19b3d716728dd8a173cdb889ec0dd082232f9:\n",
"    {\n",
"        contêiner2\n",
"        f828d211e894f7a5a992ce41a2a0def8e2424e9737fb4e1485fc09cc2d607b69\n",
"        02:42:ac:12:00:03\n",
"        172.18.0.3/16\n",
"    }\n",
"    a5fca8ba1e4ff0a67002f8f1b8cc3cd43185373c2a7e295546f774059ad8dd1a:\n",
"    {\n",
"        contêiner1\n",
"        cff762e6286ebc169804b2a675bbff904102de796751d367c18d4b490c994c45\n",
"        02:42:ac:12:00:02\n",
"        172.18.0.2/16\n",
"    }\n",
"\n",
"```\n",
"\n",
"Como podemos ver, o contêiner `container1` tem o IP `172.18.0.2` e o contêiner `container2` tem o IP `172.18.0.3`."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Entramos no contêiner `container1` e instalamos o `ping`.\n",
"\n",
"``` bash\n",
"$ docker exec -it container1 bash\n",
"root@a5fca8ba1e4f:/# apt update\n",
"    ...\n",
"root@a5fca8ba1e4f:/# apt install iputils-ping\n",
"    ...\n",
"root@a5fca8ba1e4f:/#\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Entramos no contêiner `container2` e instalamos o `ping`.\n",
"\n",
"````bash\n",
"$ docker exec -it container2 bash\n",
"root@a5fca8ba1e4f:/# apt update\n",
"    ...\n",
"root@a5fca8ba1e4f:/# apt install iputils-ping\n",
"    ...\n",
"root@a5fca8ba1e4f:/#\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Agora, a partir do contêiner `container1`, fazemos ping no IP `172.18.0.3`, que pertence ao contêiner `container2`.\n",
"\n",
"````bash\n",
"root@a5fca8ba1e4f:/# ping 172.18.0.3\n",
"PING 172.18.0.3 (172.18.0.3) 56(84) bytes de dados.\n",
"64 bytes de 172.18.0.3: icmp_seq=1 ttl=64 time=0.115 ms\n",
"64 bytes de 172.18.0.3: icmp_seq=2 ttl=64 time=0.049 ms\n",
"64 bytes de 172.18.0.3: icmp_seq=3 ttl=64 time=0.056 ms\n",
"64 bytes de 172.18.0.3: icmp_seq=4 ttl=64 time=0.060 ms\n",
"^C\n",
"--- 172.18.0.3 estatísticas de ping ---\n",
"4 pacotes transmitidos, 4 recebidos, 0% de perda de pacotes, tempo 3068ms\n",
"rtt min/avg/max/mdev = 0,049/0,070/0,115/0,026 ms\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "E, a partir do contêiner `container2`, fazemos ping no IP `172.18.0.2`, que pertence ao contêiner `container1`.\n",
"\n",
"````bash\n",
"root@6c8dc1831548:/# ping 172.18.0.2\n",
"PING 172.18.0.2 (172.18.0.2) 56(84) bytes de dados.\n",
"64 bytes de 172.18.0.2: icmp_seq=1 ttl=64 time=0.076 ms\n",
"64 bytes de 172.18.0.2: icmp_seq=2 ttl=64 time=0.045 ms\n",
"64 bytes de 172.18.0.2: icmp_seq=3 ttl=64 time=0.049 ms\n",
"64 bytes de 172.18.0.2: icmp_seq=4 ttl=64 time=0.051 ms\n",
"^C\n",
"--- 172.18.0.2 estatísticas de ping ---\n",
"4 pacotes transmitidos, 4 recebidos, 0% de perda de pacotes, tempo 3074ms\n",
"rtt min/avg/max/mdev = 0,045/0,055/0,076/0,012 ms\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Mas há uma coisa melhor que o docker nos permite fazer: se eu não souber o IP do contêiner ao qual quero me conectar, em vez de digitar seu IP, posso digitar seu nome"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Agora, a partir do contêiner `contêiner1`, fazemos o ping do IP `contêiner2`.\n",
"\n",
"````bash\n",
"root@a5fca8ba1e4f:/# ping container2\n",
"PING contêiner2 (172.18.0.3) 56(84) bytes de dados.\n",
"64 bytes do container2.myNetwork (172.18.0.3): icmp_seq=1 ttl=64 time=0.048 ms\n",
"64 bytes do container2.myNetwork (172.18.0.3): icmp_seq=2 ttl=64 time=0.050 ms\n",
"64 bytes do container2.myNetwork (172.18.0.3): icmp_seq=3 ttl=64 time=0.052 ms\n",
"64 bytes do container2.myNetwork (172.18.0.3): icmp_seq=4 ttl=64 time=0.053 ms\n",
"^C\n",
"--- Estatísticas de ping do contêiner2 ---\n",
"4 pacotes transmitidos, 4 recebidos, 0% de perda de pacotes, tempo 3071ms\n",
"rtt min/avg/max/mdev = 0,048/0,050/0,053/0,002 ms\n",
"```\n",
"\n",
"Como podemos ver, o docker sabe que o IP do contêiner `conteiner2` é `172.18.0.3`."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "E, a partir do contêiner `contêiner2`, fazemos ping no IP `contêiner1`.\n",
"\n",
"````bash\n",
"root@6c8dc1831548:/# ping container1\n",
"PING container1 (172.18.0.2) 56(84) bytes de dados.\n",
"64 bytes do container1.myNetwork (172.18.0.2): icmp_seq=1 ttl=64 time=0.051 ms\n",
"64 bytes do container1.myNetwork (172.18.0.2): icmp_seq=2 ttl=64 time=0.058 ms\n",
"64 bytes do container1.myNetwork (172.18.0.2): icmp_seq=3 ttl=64 time=0.052 ms\n",
"64 bytes do container1.myNetwork (172.18.0.2): icmp_seq=4 ttl=64 time=0.056 ms\n",
"^C\n",
"--- Estatísticas de ping do contêiner1 ---\n",
"4 pacotes transmitidos, 4 recebidos, 0% de perda de pacotes, tempo 3057ms\n",
"rtt min/avg/max/mdev = 0,051/0,054/0,058/0,003 ms\n",
"```\n",
"\n",
"Como podemos ver, o docker sabe que o IP do contêiner `conteiner1` é `172.18.0.2`."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Saímos dos contêineres e os apagamos."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "container1\n",
"container2\n"
          ]
        }
      ],
      "source": [
      "!docker rm -f container1 container2"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Também excluímos a rede que criamos"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "myNetwork\n"
          ]
        }
      ],
      "source": [
      "!docker network rm myNetwork"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "## Uso de GPUs"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Para usar GPUs host em contêineres docker, é necessário seguir as etapas descritas na página de instalação do [Nvidia container toolkit] (https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html)."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Configurando o repositório e a chave GPG"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Temos que configurar o repositório `nvidia container toolkit` e a chave GPG. Para isso, executamos o seguinte comando no console\n",
"\n",
"``` bash\n",
"distribuição=$$((. /etc/os-release;echo $ID$VERSION_ID) \\\n",
"      && curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\\n",
"      && curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | | |\n",
"            sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g'\n",
"            sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Instalação do `nvidia container toolkit`."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Depois de atualizarmos o repositório e a chave, atualizamos os repositórios usando o comando\n",
"``` bash\n",
"sudo apt update\n",
"```\n",
"\n",
"E instale o `nvidia container toolkit`.\n",
"``` bash\n",
"sudo apt install -y nvidia-docker2\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Reiniciar o Docker"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Quando terminarmos, teremos que reiniciar o daemon do docker por meio de\n",
"``` bash\n",
"sudo systemctl restart docker\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Uso de GPUs"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Agora que configuramos o docker para poder usar as GPUs do host dentro dos contêineres, podemos testá-lo usando a opção `--gpus all`. Se você tiver mais de uma GPU e quiser usar apenas uma, especifique-a, mas, por enquanto, só explicaremos como usar todas elas."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Criamos um contêiner que não será executado em segundo plano, mas executará o comando `nvidia-smi` para que possamos ver se ele tem acesso às GPUs."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Unable to find image 'ubuntu:latest' locally\n",
"latest: Pulling from library/ubuntu\n",
"\n",
"\u001b[1B6a12be2b: Pull complete .54MB/29.54MBB\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KDigest: sha256:aabed3296a3d45cede1dc866a24476c4d7e093aa806263c27ddaadbdce3c1054\n",
"Status: Downloaded newer image for ubuntu:latest\n",
"Mon Sep  4 07:10:36 2023       \n",
"+-----------------------------------------------------------------------------+\n",
"| NVIDIA-SMI 510.39.01    Driver Version: 510.39.01    CUDA Version: 11.6     |\n",
"|-------------------------------+----------------------+----------------------+\n",
"| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
"| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
"|                               |                      |               MIG M. |\n",
"|===============================+======================+======================|\n",
"|   0  Quadro T1000        On   | 00000000:01:00.0 Off |                  N/A |\n",
"| N/A   44C    P0    15W /  N/A |      9MiB /  4096MiB |      0%      Default |\n",
"|                               |                      |                  N/A |\n",
"+-------------------------------+----------------------+----------------------+\n",
"                                                                               \n",
"+-----------------------------------------------------------------------------+\n",
"| Processes:                                                                  |\n",
"|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
"|        ID   ID                                                   Usage      |\n",
"|=============================================================================|\n",
"|    0   N/A  N/A      2545      G                                       4MiB |\n",
"|    0   N/A  N/A      3421      G                                       4MiB |\n",
"+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
      "!docker run --name container_gpus --gpus all ubuntu nvidia-smi"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Excluímos o contêiner"
      ]
    },
{
      "cell_type": "code",
      "execution_count": "None",
      "metadata": {},
      "outputs": [],
      "source": [
      "!doker rm container_gpus"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "## Docker compose"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Docker compose vs docker-compose"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "O Docker-compose era uma ferramenta criada para ajudar a manter imagens e contêineres e precisava ser instalada separadamente do docker. No entanto, o docker a incorporou em suas versões mais recentes e não é mais necessário instalá-la; porém, para usá-la, em vez de usar o comando `docker-compose`, é necessário usar o comando `docker-compose`. Em muitos lugares você encontrará informações sobre o `docker-compose`, mas ao instalar o docker você já terá o `docker compose` instalado, então tudo o que você poderia fazer com o `docker-compose` é compatível com o `docker compose`."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Docker compose"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "O Docker compose é uma ferramenta do Docker que faz tudo o que vimos até agora, mas nos poupa tempo e esforço. Ao editar um arquivo `.yml`, podemos dizer ao docker compose para criar quantos contêineres quisermos.\n",
"\n",
"Usá-lo uma vez não fará muita diferença em relação a digitar todos os comandos que vimos antes ou digitar o arquivo `.yml`, mas quando você quiser fazer com que a mesma configuração de contêiner funcione novamente, basta chamar o arquivo `.yml` para recriar toda a configuração."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vamos criar uma pasta onde armazenaremos os arquivos do docker compose"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
      "!mkdir dockerComposeFiles"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Criamos dentro do arquivo `.yml"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
      "!touch dockerComposeFiles/docker-compose.yml"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Um arquivo docker compose deve começar com a versão\n",
"\n",
"```json\n",
"versão: \"<v.v>\"\n",
"```\n",
"\n",
"No momento da redação deste texto, a versão mais recente é a `3.8`, portanto, escrevemos essa versão"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "*docker-compose.yml*:\n",
"\n",
"```json\n",
"    versão: \"3.8\".\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "A seguir estão os serviços, que são os contêineres. Em cada serviço, a imagem deve ser especificada e outros parâmetros, como portas, variáveis de ambiente etc., podem ser adicionados.\n",
"\n",
"```json\n",
"serviços:\n",
"    contêiner1:\n",
"        imagem: ubuntu\n",
"    \n",
"    contêiner2:\n",
"        imagem: ubuntu\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "O arquivo `docker-compose.yml` teria a seguinte aparência:\n",
"\n",
"```json\n",
"    versão: \"3.8\".\n",
"\n",
"    serviços:\n",
"    contêiner1:\n",
"        imagem: ubuntu\n",
"    \n",
"    contêiner2:\n",
"        imagem: ubuntu\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Depois de criar o arquivo, em seu caminho, podemos executar tudo por meio do comando `docker compose up`, mas também adicionar a opção `-d` fará com que ele seja executado em segundo plano."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Running 1/0\n",
"\u001b[34m ⠿ Network dockercomposefiles_default         Created                      0.1s\n",
"\u001b[0m\u001b[37m ⠋ Container dockercomposefiles-container2-1  Creating                     0.0s\n",
"\u001b[0m\u001b[37m ⠋ Container dockercomposefiles-container1-1  Creating                     0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/3\n",
"\u001b[34m ⠿ Network dockercomposefiles_default         Created                      0.1s\n",
"\u001b[0m\u001b[37m ⠙ Container dockercomposefiles-container2-1  Creating                     0.1s\n",
"\u001b[0m\u001b[37m ⠙ Container dockercomposefiles-container1-1  Creating                     0.1s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/3\n",
"\u001b[34m ⠿ Network dockercomposefiles_default         Created                      0.1s\n",
"\u001b[0m\u001b[37m ⠿ Container dockercomposefiles-container2-1  Starting                     0.2s\n",
"\u001b[0m\u001b[37m ⠿ Container dockercomposefiles-container1-1  Starting                     0.2s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/3\n",
"\u001b[34m ⠿ Network dockercomposefiles_default         Created                      0.1s\n",
"\u001b[0m\u001b[37m ⠿ Container dockercomposefiles-container2-1  Starting                     0.3s\n",
"\u001b[0m\u001b[37m ⠿ Container dockercomposefiles-container1-1  Starting                     0.3s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/3\n",
"\u001b[34m ⠿ Network dockercomposefiles_default         Created                      0.1s\n",
"\u001b[0m\u001b[37m ⠿ Container dockercomposefiles-container2-1  Starting                     0.4s\n",
"\u001b[0m\u001b[37m ⠿ Container dockercomposefiles-container1-1  Starting                     0.4s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/3\n",
"\u001b[34m ⠿ Network dockercomposefiles_default         Created                      0.1s\n",
"\u001b[0m\u001b[37m ⠿ Container dockercomposefiles-container2-1  Starting                     0.5s\n",
"\u001b[0m\u001b[37m ⠿ Container dockercomposefiles-container1-1  Starting                     0.5s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 2/3\n",
"\u001b[34m ⠿ Network dockercomposefiles_default         Created                      0.1s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container2-1  Started                      0.5s\n",
"\u001b[0m\u001b[37m ⠿ Container dockercomposefiles-container1-1  Starting                     0.6s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l\u001b[34m[+] Running 3/3\u001b[0m\n",
"\u001b[34m ⠿ Network dockercomposefiles_default         Created                      0.1s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container2-1  Started                      0.5s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container1-1  Started                      0.7s\n",
"\u001b[0m\u001b[?25h"
          ]
        }
      ],
      "source": [
      "!cd dockerComposeFiles && docker compose up -d"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se você observar os dois contêineres `dockercomposefiles-container1-1` e `dockercomposefiles-container2-1` e a rede que os vincula `dockercomposefiles_default`, terá criado dois contêineres `dockercomposefiles-container1-1` e `dockercomposefiles-container2-1`."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vamos excluir os dois contêineres"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "dockercomposefiles-container1-1\n",
"dockercomposefiles-container2-1\n"
          ]
        }
      ],
      "source": [
      "!docker rm -f dockercomposefiles-container1-1 dockercomposefiles-container2-1"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "E excluímos a rede que ele criou"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "dockercomposefiles_default\n"
          ]
        }
      ],
      "source": [
      "!docker network rm dockercomposefiles_default"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vamos tentar fazer o que fizemos antes com o que sabemos até agora. Criamos uma nova imagem que vem com o `ping` instalado.\n",
"\n",
"*Arquivo do Docker:\n",
"```docker\n",
"    DO ubuntu:20.04\n",
"    Executar apt update\n",
"    Execute o apt install iputils-ping -y\n",
"```\n",
"\n",
"E nós o compilamos"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Sending build context to Docker daemon  2.048kB\n",
"Step 1/3 : FROM ubuntu:20.04\n",
" ---> a0ce5a295b63\n",
"Step 2/3 : RUN apt update\n",
" ---> Running in 3bd5278d39b4\n",
"\u001b[91m\n",
"WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
"\n",
"\u001b[0mGet:1 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
"Get:2 http://archive.ubuntu.com/ubuntu focal InRelease [265 kB]\n",
"Get:3 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [898 kB]\n",
"Get:4 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
"Get:5 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
"Get:6 http://archive.ubuntu.com/ubuntu focal/universe amd64 Packages [11.3 MB]\n",
"Get:7 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2133 kB]\n",
"Get:8 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [27.5 kB]\n",
"Get:9 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [1501 kB]\n",
"Get:10 http://archive.ubuntu.com/ubuntu focal/main amd64 Packages [1275 kB]\n",
"Get:11 http://archive.ubuntu.com/ubuntu focal/restricted amd64 Packages [33.4 kB]\n",
"Get:12 http://archive.ubuntu.com/ubuntu focal/multiverse amd64 Packages [177 kB]\n",
"Get:13 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [2594 kB]\n",
"Get:14 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [1613 kB]\n",
"Get:15 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [30.2 kB]\n",
"Get:16 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1200 kB]\n",
"Get:17 http://archive.ubuntu.com/ubuntu focal-backports/universe amd64 Packages [27.4 kB]\n",
"...\n",
"Successfully built c3d32aa9de02\n",
"Successfully tagged ubuntu:ping\n",
"\n",
"Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\n"
          ]
        }
      ],
      "source": [
      "!docker build -t ubuntu:ping ./dockerImages"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Verificamos se ele foi criado"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "REPOSITORY        TAG       IMAGE ID       CREATED              SIZE\n",
"ubuntu            ping      c3d32aa9de02   About a minute ago   112MB\n",
"maximofn/ubuntu   test      a78cf3ea16d8   25 hours ago         77.8MB\n",
"nginx             latest    2d389e545974   33 hours ago         142MB\n",
"ubuntu            latest    2dc39ba059dc   12 days ago          77.8MB\n",
"ubuntu            20.04     a0ce5a295b63   12 days ago          72.8MB\n",
"hello-world       latest    feb5d9fea6a5   11 months ago        13.3kB\n"
          ]
        }
      ],
      "source": [
      "!docker image ls"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Alteramos a tag"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
      "!docker tag ubuntu:ping maximofn/ubuntu:ping"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "REPOSITORY        TAG       IMAGE ID       CREATED              SIZE\n",
"ubuntu            ping      c3d32aa9de02   About a minute ago   112MB\n",
"maximofn/ubuntu   ping      c3d32aa9de02   About a minute ago   112MB\n",
"maximofn/ubuntu   test      c3d32aa9de02   About a minute ago   112MB\n",
"nginx             latest    2d389e545974   33 hours ago         142MB\n",
"ubuntu            latest    2dc39ba059dc   12 days ago          77.8MB\n",
"ubuntu            20.04     a0ce5a295b63   12 days ago          72.8MB\n",
"hello-world       latest    feb5d9fea6a5   11 months ago        13.3kB\n"
          ]
        }
      ],
      "source": [
      "!docker image ls"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Edite o arquivo docker compose para obter as imagens que acabamos de criar.\n",
"\n",
"*docker-compose.yml*:\n",
"```json\n",
"    versão: \"3.8\".\n",
"\n",
"    serviços:\n",
"      contêiner1:\n",
"        imagem: maximofn/ubuntu:ping\n",
"\n",
"    contêiner2:\n",
"        imagem: maximofn/ubuntu:ping\n",
"```\n",
"\n",
"E também dizemos a ele para executar uma não operação.\n",
"\n",
"O arquivo `docker-compose.yml` teria a seguinte aparência:\n",
"```json\n",
"    versão: \"3.8\".\n",
"\n",
"    serviços:\n",
"      contêiner1:\n",
"        imagem: ubuntu\n",
"        comando: tail -f /dev/null\n",
"\n",
"    contêiner2:\n",
"        imagem: ubuntu\n",
"        comando: tail -f /dev/null\n",
"```\n",
"\n",
"Nós o levantamos"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Running 0/0\n",
"\u001b[37m ⠋ Container dockercomposefiles-container1-1  Recreate                     0.1s\n",
"\u001b[0m\u001b[37m ⠋ Container dockercomposefiles-container2-1  Recreate                     0.1s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[34m ⠿ Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
"\u001b[0m\u001b[37m ⠙ Container dockercomposefiles-container2-1  Recreate                     0.2s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[34m ⠿ Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
"\u001b[0m\u001b[37m ⠹ Container dockercomposefiles-container2-1  Recreate                     0.3s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[34m ⠿ Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
"\u001b[0m\u001b[37m ⠸ Container dockercomposefiles-container2-1  Recreate                     0.4s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[34m ⠿ Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
"\u001b[0m\u001b[37m ⠼ Container dockercomposefiles-container2-1  Recreate                     0.5s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[34m ⠿ Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
"\u001b[0m\u001b[37m ⠴ Container dockercomposefiles-container2-1  Recreate                     0.6s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[34m ⠿ Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
"\u001b[0m\u001b[37m ⠦ Container dockercomposefiles-container2-1  Recreate                     0.7s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[34m ⠿ Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
"\u001b[0m\u001b[37m ⠧ Container dockercomposefiles-container2-1  Recreate                     0.8s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[34m ⠿ Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
"\u001b[0m\u001b[37m ⠇ Container dockercomposefiles-container2-1  Recreate                     0.9s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[34m ⠿ Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
"\u001b[0m\u001b[37m ⠏ Container dockercomposefiles-container2-1  Recreate                     1.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[34m ⠿ Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
"\u001b[0m\u001b[37m ⠋ Container dockercomposefiles-container2-1  Recreate                     1.1s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[34m ⠿ Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
"\u001b[0m\u001b[37m ⠙ Container dockercomposefiles-container2-1  Recreate                     1.2s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[34m ⠿ Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
"\u001b[0m\u001b[37m ⠹ Container dockercomposefiles-container2-1  Recreate                     1.3s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[34m ⠿ Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
"\u001b[0m\u001b[37m ⠸ Container dockercomposefiles-container2-1  Recreate                     1.4s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[34m ⠿ Container dockercomposefiles-container1-1  Recreated                    0.1s\n",
"...\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l\u001b[34m[+] Running 2/2\u001b[0m\n",
"\u001b[34m ⠿ Container dockercomposefiles-container1-1  Started                     10.8s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container2-1  Started                     10.9s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l\u001b[34m[+] Running 2/2\u001b[0m\n",
"\u001b[34m ⠿ Container dockercomposefiles-container1-1  Started                     10.8s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container2-1  Started                     10.9s\n",
"\u001b[0m\u001b[?25h"
          ]
        }
      ],
      "source": [
      "!cd dockerComposeFiles && docker compose up -d"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vemos os contêineres que estão em execução"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE                  COMMAND               CREATED          STATUS          PORTS     NAMES\n",
"935939e5a75d   maximofn/ubuntu:ping   \"tail -f /dev/null\"   15 seconds ago   Up 13 seconds             dockercomposefiles-container2-1\n",
"f9138d7064dd   maximofn/ubuntu:ping   \"tail -f /dev/null\"   25 seconds ago   Up 13 seconds             dockercomposefiles-container1-1\n"
          ]
        }
      ],
      "source": [
      "!docker ps"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Os dois contêineres estão em execução. Agora, entramos em um deles e tentamos \"pingar\" o outro.\n",
"\n",
"````bash\n",
"$ docker exec -it dockercomposefiles-container1-1 bash\n",
"root@f9138d7064dd:/# ping dockercomposefiles-container2-1\n",
"PING dockercomposefiles-container2-1 (172.21.0.3) 56(84) bytes de dados.\n",
"64 bytes de dockercomposefiles-container2-1.dockercomposefiles_default (172.21.0.3): icmp_seq=1 ttl=64 time=0.110 ms\n",
"64 bytes de dockercomposefiles-container2-1.dockercomposefiles_default (172.21.0.3): icmp_seq=2 ttl=64 time=0.049 ms\n",
"64 bytes de dockercomposefiles-container2-1.dockercomposefiles_default (172.21.0.3): icmp_seq=3 ttl=64 time=0.049 ms\n",
"64 bytes de dockercomposefiles-container2-1.dockercomposefiles_default (172.21.0.3): icmp_seq=4 ttl=64 time=0.075 ms\n",
"^C\n",
"--- dockercomposefiles-container2-1 ping statistics ---\n",
"4 pacotes transmitidos, 4 recebidos, 0% de perda de pacotes, tempo 3068ms\n",
"rtt min/avg/max/mdev = 0,049/0,070/0,110/0,025 ms\n",
"```\n",
"\n",
"Como podemos ver, podemos fazer o `ping`, criamos a imagem bem com o `ping` instalado. Além disso, no docker compose, criamos uma não operação a ser executada para que os contêineres estejam em execução"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Exclua os dois contêineres e a rede que eles criaram."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "dockercomposefiles-container1-1\n",
"dockercomposefiles-container2-1\n"
          ]
        }
      ],
      "source": [
      "!docker rm -f dockercomposefiles-container1-1 dockercomposefiles-container2-1"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "dockercomposefiles_default\n"
          ]
        }
      ],
      "source": [
      "!docker network rm dockercomposefiles_default"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Como o nome do docker compõe contêineres?"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se você observar os contêineres que o docker criou, eles foram chamados de `dockercomposefiles-container1-1` e `dockercomposefiles-container1-1`. Isso ocorre porque a pasta em que o arquivo docker compose está localizado é uma pasta chamada `dockerComposeFiles`, portanto, a primeira parte do nome dos contêineres é `dockercomposefiles`, depois o nome do serviço que fornecemos no arquivo docker compose (`container1` e `container2`) e, por fim, um número para criar mais, se necessário.\n",
"\n",
"O mesmo acontece com o nome da rede que você criou `dockercomposefiles_default`."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Registros no docker compose"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Agora vamos alterar o arquivo docker compose, nas linhas onde tínhamos ```command: tail -f /dev/null```, vamos colocar ```command: ping 0.0.0.0.0.0```.\n",
"\n",
"E também dizemos a ele para executar uma não operação.\n",
"\n",
"O arquivo `docker-compose.yml` teria a seguinte aparência:\n",
"```json\n",
"    versão: \"3.8\".\n",
"\n",
"    serviços:\n",
"      contêiner1:\n",
"        imagem: ubuntu\n",
"        comando: ping 0.0.0.0.0.0\n",
"\n",
"    contêiner2:\n",
"        imagem: ubuntu\n",
"        comando: ping 0.0.0.0.0.0\n",
"```\n",
"\n",
"Fazemos isso de modo que cada contêiner esteja constantemente emitindo o ping, portanto, simulamos os registros.\n",
"\n",
"Se executarmos novamente o docker compose"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Running 0/0\n",
"\u001b[37m ⠋ Container dockercomposefiles-container1-1  Recreate                     0.1s\n",
"\u001b[0m\u001b[37m ⠋ Container dockercomposefiles-container2-1  Recreate                     0.1s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠙ Container dockercomposefiles-container1-1  Recreate                     0.2s\n",
"\u001b[0m\u001b[37m ⠙ Container dockercomposefiles-container2-1  Recreate                     0.2s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠹ Container dockercomposefiles-container1-1  Recreate                     0.3s\n",
"\u001b[0m\u001b[37m ⠹ Container dockercomposefiles-container2-1  Recreate                     0.3s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠸ Container dockercomposefiles-container1-1  Recreate                     0.4s\n",
"\u001b[0m\u001b[37m ⠸ Container dockercomposefiles-container2-1  Recreate                     0.4s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠼ Container dockercomposefiles-container1-1  Recreate                     0.5s\n",
"\u001b[0m\u001b[37m ⠼ Container dockercomposefiles-container2-1  Recreate                     0.5s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠴ Container dockercomposefiles-container1-1  Recreate                     0.6s\n",
"\u001b[0m\u001b[37m ⠴ Container dockercomposefiles-container2-1  Recreate                     0.6s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠦ Container dockercomposefiles-container1-1  Recreate                     0.7s\n",
"\u001b[0m\u001b[37m ⠦ Container dockercomposefiles-container2-1  Recreate                     0.7s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠧ Container dockercomposefiles-container1-1  Recreate                     0.8s\n",
"\u001b[0m\u001b[37m ⠧ Container dockercomposefiles-container2-1  Recreate                     0.8s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"...\n",
"\u001b[37m ⠿ Container dockercomposefiles-container1-1  Starting                    11.0s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container2-1  Started                     11.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l\u001b[34m[+] Running 2/2\u001b[0m\n",
"\u001b[34m ⠿ Container dockercomposefiles-container1-1  Started                     11.1s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container2-1  Started                     11.0s\n",
"\u001b[0m\u001b[?25h"
          ]
        }
      ],
      "source": [
      "!cd dockerComposeFiles && docker compose up -d"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Agora podemos visualizar os registros dos dois contêineres usando o comando `docker compose logs`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "\u001b[36mdockercomposefiles-container2-1  | \u001b[0mPING 0.0.0.0 (127.0.0.1) 56(84) bytes of data.\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=1 ttl=64 time=0.042 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=2 ttl=64 time=0.025 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=3 ttl=64 time=0.022 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=4 ttl=64 time=0.030 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=5 ttl=64 time=0.021 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=6 ttl=64 time=0.021 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=7 ttl=64 time=0.030 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=8 ttl=64 time=0.028 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=9 ttl=64 time=0.028 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=10 ttl=64 time=0.026 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=11 ttl=64 time=0.028 ms\n",
"\u001b[33mdockercomposefiles-container1-1  | \u001b[0mPING 0.0.0.0 (127.0.0.1) 56(84) bytes of data.\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=12 ttl=64 time=0.027 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=13 ttl=64 time=0.039 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=14 ttl=64 time=0.035 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=15 ttl=64 time=0.034 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=16 ttl=64 time=0.036 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=17 ttl=64 time=0.034 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=18 ttl=64 time=0.036 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=19 ttl=64 time=0.032 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=20 ttl=64 time=0.032 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=21 ttl=64 time=0.033 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=22 ttl=64 time=0.034 ms\n",
"\u001b[33mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=1 ttl=64 time=0.037 ms\n",
"...\n",
"\u001b[33mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=214 ttl=64 time=0.015 ms\n",
"\u001b[33mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=215 ttl=64 time=0.021 ms\n",
"\u001b[33mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=216 ttl=64 time=0.020 ms\n",
"\u001b[33mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=217 ttl=64 time=0.049 ms\n"
          ]
        }
      ],
      "source": [
      "!cd dockerComposeFiles && docker compose logs"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Como podemos ver, podemos ver os logs de ambos os contêineres, mas caso queiramos ver os logs de apenas um contêiner, podemos especificar o **nome do serviço**."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "\u001b[36mdockercomposefiles-container1-1  | \u001b[0mPING 0.0.0.0 (127.0.0.1) 56(84) bytes of data.\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=1 ttl=64 time=0.037 ms\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=2 ttl=64 time=0.025 ms\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=3 ttl=64 time=0.023 ms\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=4 ttl=64 time=0.031 ms\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=5 ttl=64 time=0.034 ms\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=6 ttl=64 time=0.033 ms\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=7 ttl=64 time=0.034 ms\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=8 ttl=64 time=0.022 ms\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=9 ttl=64 time=0.032 ms\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=10 ttl=64 time=0.029 ms\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=11 ttl=64 time=0.031 ms\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=12 ttl=64 time=0.024 ms\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=13 ttl=64 time=0.029 ms\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=14 ttl=64 time=0.032 ms\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=15 ttl=64 time=0.033 ms\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=16 ttl=64 time=0.034 ms\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=17 ttl=64 time=0.028 ms\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=18 ttl=64 time=0.034 ms\n",
"...\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=332 ttl=64 time=0.027 ms\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=333 ttl=64 time=0.030 ms\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=334 ttl=64 time=0.033 ms\n",
"\u001b[36mdockercomposefiles-container1-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=335 ttl=64 time=0.036 ms\n"
          ]
        }
      ],
      "source": [
      "!cd dockerComposeFiles && docker compose logs container1"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "\u001b[36mdockercomposefiles-container2-1  | \u001b[0mPING 0.0.0.0 (127.0.0.1) 56(84) bytes of data.\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=1 ttl=64 time=0.042 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=2 ttl=64 time=0.025 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=3 ttl=64 time=0.022 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=4 ttl=64 time=0.030 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=5 ttl=64 time=0.021 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=6 ttl=64 time=0.021 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=7 ttl=64 time=0.030 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=8 ttl=64 time=0.028 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=9 ttl=64 time=0.028 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=10 ttl=64 time=0.026 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=11 ttl=64 time=0.028 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=12 ttl=64 time=0.027 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=13 ttl=64 time=0.039 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=14 ttl=64 time=0.035 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=15 ttl=64 time=0.034 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=16 ttl=64 time=0.036 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=17 ttl=64 time=0.034 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=18 ttl=64 time=0.036 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=19 ttl=64 time=0.032 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=20 ttl=64 time=0.032 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=21 ttl=64 time=0.033 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=22 ttl=64 time=0.034 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=23 ttl=64 time=0.035 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=24 ttl=64 time=0.037 ms\n",
"...\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=340 ttl=64 time=0.034 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=341 ttl=64 time=0.033 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=342 ttl=64 time=0.034 ms\n",
"\u001b[36mdockercomposefiles-container2-1  | \u001b[0m64 bytes from 127.0.0.1: icmp_seq=343 ttl=64 time=0.036 ms\n"
          ]
        }
      ],
      "source": [
      "!cd dockerComposeFiles && docker compose logs container2"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se quisermos ver os registros continuamente, podemos adicionar a opção `-f`, `docker compose logs - <service name>`."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se você tiver criado um docker compose com mais de dois serviços, quando quiser ver os registros de vários serviços, basta adicionar mais nomes ao comando, `docker compose logs <nome do serviço 1> <nome do serviço 2> ...`."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Serviços de execução"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Como vimos, usando o comando `exec`, podemos entrar em um contêiner especificando o nome do contêiner, o comando que queremos executar e a opção `-it`. Com o docker compose, isso é mais fácil, já que apenas o nome do serviço e o comando são necessários, mas a opção `-it` não é necessária, pois o docker compose a considera garantida.\n",
"\n",
"````bash\n",
"$ docker compose exec container1 bash\n",
"root@a7cf282fe66c:/#\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Parando o docker compose"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Quando terminamos de trabalhar, com um único comando (`stop`), o docker compose para tudo, não há necessidade de parar cada contêiner um a um."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Running 0/0\n",
"\u001b[37m ⠋ Container dockercomposefiles-container2-1  Stopping                     0.1s\n",
"\u001b[0m\u001b[37m ⠋ Container dockercomposefiles-container1-1  Stopping                     0.1s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠙ Container dockercomposefiles-container2-1  Stopping                     0.2s\n",
"\u001b[0m\u001b[37m ⠙ Container dockercomposefiles-container1-1  Stopping                     0.2s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠹ Container dockercomposefiles-container2-1  Stopping                     0.3s\n",
"\u001b[0m\u001b[37m ⠹ Container dockercomposefiles-container1-1  Stopping                     0.3s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠸ Container dockercomposefiles-container2-1  Stopping                     0.4s\n",
"\u001b[0m\u001b[37m ⠸ Container dockercomposefiles-container1-1  Stopping                     0.4s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠼ Container dockercomposefiles-container2-1  Stopping                     0.5s\n",
"\u001b[0m\u001b[37m ⠼ Container dockercomposefiles-container1-1  Stopping                     0.5s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠴ Container dockercomposefiles-container2-1  Stopping                     0.6s\n",
"\u001b[0m\u001b[37m ⠴ Container dockercomposefiles-container1-1  Stopping                     0.6s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠦ Container dockercomposefiles-container2-1  Stopping                     0.7s\n",
"\u001b[0m\u001b[37m ⠦ Container dockercomposefiles-container1-1  Stopping                     0.7s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠧ Container dockercomposefiles-container2-1  Stopping                     0.8s\n",
"\u001b[0m\u001b[37m ⠧ Container dockercomposefiles-container1-1  Stopping                     0.8s\n",
"...\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[34m ⠿ Container dockercomposefiles-container2-1  Stopped                     10.4s\n",
"\u001b[0m\u001b[37m ⠸ Container dockercomposefiles-container1-1  Stopping                    10.4s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l\u001b[34m[+] Running 2/2\u001b[0m\n",
"\u001b[34m ⠿ Container dockercomposefiles-container2-1  Stopped                     10.4s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container1-1  Stopped                     10.4s\n",
"\u001b[0m\u001b[?25h"
          ]
        }
      ],
      "source": [
      "!cd dockerComposeFiles && docker compose stop"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Como você pode ver, o docker compose parou os dois contêineres, mas não os excluiu, nem excluiu a rede."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
          ]
        }
      ],
      "source": [
      "!docker ps"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE                  COMMAND          CREATED          STATUS                        PORTS     NAMES\n",
"1e6c1dd9adb2   maximofn/ubuntu:ping   \"ping 0.0.0.0\"   16 minutes ago   Exited (137) 25 seconds ago             dockercomposefiles-container2-1\n",
"a7cf282fe66c   maximofn/ubuntu:ping   \"ping 0.0.0.0\"   16 minutes ago   Exited (137) 25 seconds ago             dockercomposefiles-container1-1\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "NETWORK ID     NAME                         DRIVER    SCOPE\n",
"13cc632147f3   bridge                       bridge    local\n",
"d4a2f718cd83   dockercomposefiles_default   bridge    local\n",
"da1f5f6fccc0   host                         host      local\n",
"d3b0d93993c0   none                         null      local\n"
          ]
        }
      ],
      "source": [
      "!docker network ls"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Docker compose como uma ferramenta de desenvolvimento"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Como vimos anteriormente, para que seja possível desenvolver, o ideal seria compartilhar a pasta que contém o código com o serviço. Isso é feito com o docker compose, adicionando a tag `volumes` ao arquivo docker compose. Primeiro, temos de adicionar o caminho para a pasta onde o código está no host e, em seguida, o caminho para o contêiner.\n",
"\n",
"*docker-compose.yml*:\n",
"```json\n",
"    versão: \"3.8\".\n",
"\n",
"    serviços:\n",
"      contêiner1:\n",
"        imagem: ubuntu\n",
"        comando: ping 0.0.0.0.0.0\n",
"        volumes:\n",
"            - ../dockerHostFolder/:/dockerContainerFolder\n",
"\n",
"    contêiner2:\n",
"        imagem: ubuntu\n",
"        comando: ping 0.0.0.0.0.0\n",
"```\n",
"\n",
"Como você pode ver, o caminho para a pasta do host que defini em relação a\n",
"\n",
"Se levantarmos o docker compose"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Running 1/0\n",
"\u001b[37m ⠋ Container dockercomposefiles-container1-1  Recreate                     0.1s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container2-1  Created                      0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠿ Container dockercomposefiles-container1-1  Starting                     0.2s\n",
"\u001b[0m\u001b[37m ⠿ Container dockercomposefiles-container2-1  Starting                     0.2s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠿ Container dockercomposefiles-container1-1  Starting                     0.3s\n",
"\u001b[0m\u001b[37m ⠿ Container dockercomposefiles-container2-1  Starting                     0.3s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠿ Container dockercomposefiles-container1-1  Starting                     0.4s\n",
"\u001b[0m\u001b[37m ⠿ Container dockercomposefiles-container2-1  Starting                     0.4s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[34m ⠿ Container dockercomposefiles-container1-1  Started                      0.5s\n",
"\u001b[0m\u001b[37m ⠿ Container dockercomposefiles-container2-1  Starting                     0.5s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l\u001b[34m[+] Running 2/2\u001b[0m\n",
"\u001b[34m ⠿ Container dockercomposefiles-container1-1  Started                      0.5s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container2-1  Started                      0.6s\n",
"\u001b[0m\u001b[?25h"
          ]
        }
      ],
      "source": [
      "!cd dockerComposeFiles && docker compose up -d"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se entrarmos no contêiner, poderemos ver o que está dentro do arquivo text.txt.\n",
"\n",
"````bash\n",
"$ docker compose exec container1 bash\n",
"root@c8aae9d619d3:/# ls dockerContainerFolder/\n",
"bindFile.txt fileExtract.txt fileExtract.txt text.txt\n",
"root@c8aae9d619d3:/# cat dockerContainerFolder/text.txt\n",
"hello container\n",
"```\n",
"\n",
"Se agora o abrirmos no host, digitaremos `hello host` e veremos novamente no contêiner\n",
"\n",
"````bash\n",
"root@c8aae9d619d3:/# cat dockerContainerFolder/text.txt\n",
"olá host\n",
"```\n",
"\n",
"E agora, ao contrário, se o modificarmos no contêiner\n",
"\n",
"````bash\n",
"root@c8aae9d619d3:/# echo hello compose > dockerContainerFolder/text.txt\n",
"root@c8aae9d619d3:/# exit\n",
"saída\n",
"```\n",
"\n",
"Se olharmos para ele a partir do host, devemos obter `hello compose`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "hola compose\n"
          ]
        }
      ],
      "source": [
      "!cat dockerHostFolder/text.txt"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Exposição de portas no docker compose"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Também podemos configurar as portas no arquivo docker compose, usando a tag `ports`, especificando a porta do host e, em seguida, o ip do serviço\n",
"\n",
"```json\n",
"portos:\n",
"    - <porta do host>:<porta do serviço>:<porta do serviço>.\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Docker compose na equipe - substituição do docker"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se formos um grupo de pessoas desenvolvendo no docker com o docker compose, é provável que muitas pessoas estejam alterando o arquivo docker compose, o que pode fazer com que eles não sincronizem bem e causem conflitos.\n",
"\n",
"Para resolver isso, o docker oferece uma ferramenta chamada docker override. Dessa forma, pode haver um arquivo de composição do docker básico e todos podem modificá-lo usando o docker override.\n",
"\n",
"Para isso, agora precisamos criar um arquivo chamado `docker-compose.override.yml` que podemos editar."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
      "!touch dockerComposeFiles/docker-compose.override.yml"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se agora tentarmos aumentar o docker compose, receberemos um erro"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Top-level object must be a mapping\n"
          ]
        }
      ],
      "source": [
      "!cd dockerComposeFiles && docker compose up -d"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Isso ocorre porque o docker compose detectou que existe um arquivo chamado `docker-compose.override.yml` e ele está vazio, portanto, vamos editá-lo. O arquivo `docker-compose.override.yml` edita o arquivo `docker-compose.yml`, portanto, se, por exemplo, quisermos fazer uma alteração no serviço `container2` para adicionar um volume a ele, escreveremos o arquivo `docker-compose.override.yml` da seguinte forma\n",
"\n",
"*docker-compose.override.yml*:\n",
"```json\n",
"    versão: \"3.8\".\n",
"\n",
"    serviços:\n",
"    contêiner2:\n",
"        volumes:\n",
"        - ../dockerHostFolder/:/dockerOverrideFolder\n",
"```\n",
"\n",
"Observe que a pasta compartilhada no serviço é chamada de `dockerOverrideFolder`, portanto, vamos abrir o docker compose e ver se vemos essa pasta no contêiner `container2`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Running 1/0\n",
"\u001b[37m ⠋ Container dockercomposefiles-container2-1  Recreate                     0.1s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container1-1  Running                      0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[37m ⠙ Container dockercomposefiles-container2-1  Recreate                     0.2s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container1-1  Running                      0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[37m ⠹ Container dockercomposefiles-container2-1  Recreate                     0.3s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container1-1  Running                      0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[37m ⠸ Container dockercomposefiles-container2-1  Recreate                     0.4s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container1-1  Running                      0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[37m ⠼ Container dockercomposefiles-container2-1  Recreate                     0.5s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container1-1  Running                      0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[37m ⠴ Container dockercomposefiles-container2-1  Recreate                     0.6s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container1-1  Running                      0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[37m ⠦ Container dockercomposefiles-container2-1  Recreate                     0.7s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container1-1  Running                      0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[37m ⠧ Container dockercomposefiles-container2-1  Recreate                     0.8s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container1-1  Running                      0.0s\n",
"...\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[37m ⠿ Container dockercomposefiles-container2-1  Starting                    10.8s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container1-1  Running                      0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l\u001b[34m[+] Running 2/2\u001b[0m\n",
"\u001b[34m ⠿ Container dockercomposefiles-container2-1  Started                     10.8s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container1-1  Running                      0.0s\n",
"\u001b[0m\u001b[?25h"
          ]
        }
      ],
      "source": [
      "!cd dockerComposeFiles && docker compose up -d"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vemos que foram necessários 10 segundos para montar o serviço `container2`, o que se deve ao fato de ele estar aplicando as alterações.\n",
"\n",
"````bash\n",
"$ docker compose exec container2 bash\n",
"root@d8777a4e611a:/# ls dockerOverrideFolder/\n",
"bindFile.txt fileExtract.txt fileExtract.txt text.txt\n",
"root@d8777a4e611a:/# cat dockerOverrideFolder/text.txt\n",
"hello compose\n",
"root@d8777a4e611a:/# exit\n",
"saída\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Baixamos a composição e excluímos os contêineres e a rede criada."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Running 0/0\n",
"\u001b[37m ⠋ Container dockercomposefiles-container2-1  Stopping                     0.1s\n",
"\u001b[0m\u001b[37m ⠋ Container dockercomposefiles-container1-1  Stopping                     0.1s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠙ Container dockercomposefiles-container2-1  Stopping                     0.2s\n",
"\u001b[0m\u001b[37m ⠙ Container dockercomposefiles-container1-1  Stopping                     0.2s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠹ Container dockercomposefiles-container2-1  Stopping                     0.3s\n",
"\u001b[0m\u001b[37m ⠹ Container dockercomposefiles-container1-1  Stopping                     0.3s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠸ Container dockercomposefiles-container2-1  Stopping                     0.4s\n",
"\u001b[0m\u001b[37m ⠸ Container dockercomposefiles-container1-1  Stopping                     0.4s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠼ Container dockercomposefiles-container2-1  Stopping                     0.5s\n",
"\u001b[0m\u001b[37m ⠼ Container dockercomposefiles-container1-1  Stopping                     0.5s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠴ Container dockercomposefiles-container2-1  Stopping                     0.6s\n",
"\u001b[0m\u001b[37m ⠴ Container dockercomposefiles-container1-1  Stopping                     0.6s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠦ Container dockercomposefiles-container2-1  Stopping                     0.7s\n",
"\u001b[0m\u001b[37m ⠦ Container dockercomposefiles-container1-1  Stopping                     0.7s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/2\n",
"\u001b[37m ⠧ Container dockercomposefiles-container2-1  Stopping                     0.8s\n",
"\u001b[0m\u001b[37m ⠧ Container dockercomposefiles-container1-1  Stopping                     0.8s\n",
"...\n",
"\u001b[37m ⠸ Container dockercomposefiles-container2-1  Stopping                    10.4s\n",
"\u001b[0m\u001b[37m ⠸ Container dockercomposefiles-container1-1  Stopping                    10.4s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
"\u001b[34m ⠿ Container dockercomposefiles-container2-1  Removed                     10.4s\n",
"\u001b[0m\u001b[37m ⠿ Container dockercomposefiles-container1-1  Removing                    10.5s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l\u001b[34m[+] Running 2/2\u001b[0m\n",
"\u001b[34m ⠿ Container dockercomposefiles-container2-1  Removed                     10.4s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container1-1  Removed                     10.5s\n",
"\u001b[0m\u001b[37m ⠋ Network dockercomposefiles_default         Removing                     0.1s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l\u001b[34m[+] Running 3/3\u001b[0m\n",
"\u001b[34m ⠿ Container dockercomposefiles-container2-1  Removed                     10.4s\n",
"\u001b[0m\u001b[34m ⠿ Container dockercomposefiles-container1-1  Removed                     10.5s\n",
"\u001b[0m\u001b[34m ⠿ Network dockercomposefiles_default         Removed                      0.2s\n",
"\u001b[0m\u001b[?25h"
          ]
        }
      ],
      "source": [
      "!cd dockerComposeFiles && docker compose down"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Nesse caso, apenas com `down` o docker compose parou e excluiu tudo, como podemos ver nos contêineres e na rede, onde está escrito `Removed`."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Reiniciar o Docker compose"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Ao escrever um docker compose, podemos adicionar a tag `restart` para que, se o contêiner falhar, ele seja reiniciado automaticamente.\n",
"\n",
"```json\n",
"reiniciar: sempre\n",
"```\n",
"\n",
"Dessa forma, se o contêiner falhar, ele será reiniciado automaticamente. Se quisermos que ele seja reiniciado apenas um determinado número de vezes, podemos adicionar a opção `on-failure`.\n",
"\n",
"```json\n",
"reiniciar: on-failure:<número>\n",
"```\n",
"\n",
"Agora, o contêiner será reiniciado várias vezes, mas, se houver mais falhas, ele não será reiniciado. Se quisermos que ele sempre reinicie, podemos adicionar a opção `unless-stopped` a ele.\n",
"\n",
"```json\n",
"reiniciar: a menos que seja interrompido\n",
"```\n",
"\n",
"Agora, o contêiner será sempre reiniciado, a menos que seja interrompido manualmente."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "## Docker avançado"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Gerenciar o ambiente de trabalho"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "#### Exclusão de contêineres desativados"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Depois de um tempo de desenvolvimento, podemos ter vários contêineres desativados, mas armazenados no computador. Isso acaba ocupando memória, portanto, com o `docker contanier prune`, podemos excluir todos os contêineres parados."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
      "!docker run ubuntu"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
          ]
        }
      ],
      "source": [
      "!docker ps"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND   CREATED          STATUS                      PORTS     NAMES\n",
"effcee24f54a   ubuntu    \"bash\"    37 seconds ago   Exited (0) 36 seconds ago             musing_rosalind\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "``` bash\n",
"$ docker container prune\n",
"AVISO: Isso removerá todos os contêineres parados.\n",
"Tem certeza de que deseja continuar? [y/N] y\n",
"Contêineres excluídos:\n",
"effcee24f54aab22e34fdea2465b3b7af132d8c627e5432ba3e915a370876977\n",
"\n",
"Total de espaço recuperado: 0B\n",
"```\n",
"\n",
"Nesse caso, economizamos 0 bytes, mas no caso de deixar os contêineres desativados após muito desenvolvimento, a economia de memória certamente será maior."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "#### Exclusão de todos os contêineres"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Caso tenhamos contêineres em execução, podemos eliminar todos os contêineres com outro comando\n",
"\n",
"O comando `docker ps -q` retorna o ID de todos os contêineres, portanto, com o comando `docker rm -f $(docker ps -aq)`, interromperemos e excluiremos todos os contêineres."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "c22516186ef7e3561fb1ad0d508a914857dbc61274a218f297c4d80b1fc33863\n"
          ]
        }
      ],
      "source": [
      "!docker run -d ubuntu tail -f /dev/null"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND               CREATED              STATUS              PORTS     NAMES\n",
"c22516186ef7   ubuntu    \"tail -f /dev/null\"   About a minute ago   Up About a minute             agitated_knuth\n"
          ]
        }
      ],
      "source": [
      "!docker ps"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "c22516186ef7\n"
          ]
        }
      ],
      "source": [
      "!docker rm -f $(docker ps -aq)"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "#### Excluiu tudo"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Como vimos, o docker também cria redes, imagens, volumes etc. Portanto, com o comando `docker system prune`, podemos excluir todos os contêineres parados, todas as redes que não são usadas por pelo menos um contêiner, as imagens repetidas e tudo o que estiver repetido no cache de compilação.\n",
"\n",
"``` bash\n",
"$ docker system prune\n",
"AVISO: Isso removerá:\n",
"  - todos os contêineres parados\n",
"  - todas as redes não usadas por pelo menos um contêiner\n",
"  - todas as imagens suspensas\n",
"  - todos os cache de compilação pendentes\n",
"\n",
"Tem certeza de que deseja continuar? [y/N] y\n",
"Total de espaço recuperado: 0B\n",
"```\n",
"\n",
"Como antes, não foi economizado muito espaço, mas após um longo período de desenvolvimento, a economia será considerável."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Uso de recursos do host pelo contêiner"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Por exemplo, ao criar um contêiner, podemos limitar a RAM do host que ele pode usar usando a opção `--memory`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "d84888eafe531831ef8915d2270422365adec02678122bf59580e2da782e6972\n"
          ]
        }
      ],
      "source": [
      "!docker run -d --memory 1g ubuntu tail -f /dev/null"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Mas com o `docker ps` não temos acesso aos recursos que estão sendo consumidos pelo contêiner."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE     COMMAND               CREATED          STATUS          PORTS     NAMES\n",
"d84888eafe53   ubuntu    \"tail -f /dev/null\"   35 seconds ago   Up 34 seconds             musing_ritchie\n"
          ]
        }
      ],
      "source": [
      "!docker ps"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Para isso, temos o comando `docker stats`.\n",
"\n",
"````bash\n",
"$ docker stats\n",
"CONTÊINER ID NOME CPU % MEM USO / LIMITE MEM % NET I/O BLOCK I/O PIDS\n",
"d84888eafe53 musing_ritchie 0.00% 540KiB / 1GiB 0.05% 5.62kB / 0B 0B / 0B 1\n",
"```\n",
"\n",
"Isso é muito útil se quisermos simular um ambiente com um limite de RAM."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Parando os contêineres corretamente: SHELL vs EXEC"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Como explicamos, quando atribuímos um processo a um contêiner, quando esse processo termina, o contêiner para, mas às vezes podemos encontrar problemas com isso. Vamos criar uma nova pasta chamada Dockerfile_loop"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
      "!mkdir Dockerfile_loop"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Agora, vamos criar um arquivo chamado `loop.sh` dentro de `Dockerfile_loop`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
      "!touch Dockerfile_loop/loop.sh"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "E vamos escrever o seguinte dentro do `loop.sh`\n",
"\n",
"``` shell\n",
"#!/usr/bin/env bash\n",
"trap \"exit 0\" SIGTERM\n",
"while true; do :; done\n",
"```\n",
"\n",
"Se eu executar esse script no host, ele será executado até que eu digite `CTRL+C`.\n",
"\n",
"\n",
"``` bash\n",
" ./loop\n",
" ^C\n",
" ```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Agora vamos criar um arquivo `Dockerfile` dentro de `Dockerfile_loop`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
      "!touch Dockerfile_loop/Dockerfile"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "*Arquivo do Docker:\n",
"``` docker\n",
"DE ubuntu:trusty\n",
"COPY [\"loop.sh\", \"/\"]\n",
"CMD /loop.sh\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Criaremos uma imagem baseada no Ubuntu que copia o script dentro dele e o executa, e o script é executado até receber o sinal `SIGTERM` do sistema operacional. Compilamos a imagem"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Sending build context to Docker daemon  3.072kB\n",
"Step 1/3 : FROM ubuntu:trusty\n",
" ---> 13b66b487594\n",
"Step 2/3 : COPY [\"loop.sh\", \"/\"]\n",
" ---> 89f2bbd25a88\n",
"Step 3/3 : CMD /loop.sh\n",
" ---> Running in ff52569c35fd\n",
"Removing intermediate container ff52569c35fd\n",
" ---> feb091e4efa3\n",
"Successfully built feb091e4efa3\n",
"Successfully tagged ubuntu:loop\n",
"\n",
"Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\n"
          ]
        }
      ],
      "source": [
      "!docker build -t ubuntu:loop ./Dockerfile_loop"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Executamos o contêiner\n",
"\n",
"``` bash\n",
"docker run -d --name looper ubuntu:loop bash\n",
"```"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "8a28f8cc9892213c4e0603dfdde320edf52c091b82c60510083549a391cd6645\n"
          ]
        }
      ],
      "source": [
      "!docker run -d --name looper ubuntu:loop"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Verificamos e constatamos que o contêiner está em execução"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE         COMMAND                 CREATED         STATUS         PORTS     NAMES\n",
"8a28f8cc9892   ubuntu:loop   \"/bin/sh -c /loop.sh\"   4 seconds ago   Up 3 seconds             looper\n"
          ]
        }
      ],
      "source": [
      "!docker ps"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Tentamos parar o contêiner com o `docker stop looper`. O Docker stop tenta parar o contêiner enviando-lhe o sinal `SIGTERM`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "looper\n",
"CPU times: user 89.2 ms, sys: 21.7 ms, total: 111 ms\n",
"Wall time: 10.6 s\n"
          ]
        }
      ],
      "source": [
      "%%time\n",
"!docker stop looper"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Isso levou cerca de 10 segundos para parar, quando deveria ter parado imediatamente. Isso ocorre porque o `stop` enviou o comando `SIGTERM` para parar o contêiner, mas como ele não parou, depois de algum tempo ele enviou um `SIGKILL` para forçá-lo a parar. Vamos ver o que acontece se listarmos os contêineres."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE         COMMAND                 CREATED          STATUS                       PORTS     NAMES\n",
"8a28f8cc9892   ubuntu:loop   \"/bin/sh -c /loop.sh\"   23 seconds ago   Exited (137) 2 seconds ago             looper\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Podemos ver que o sinal `Exited` é `137`, o que significa SIGKILL, ou seja, o docker teve que forçar o desligamento."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vamos excluir o contêiner e executá-lo novamente."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "looper\n"
          ]
        }
      ],
      "source": [
      "!docker rm looper"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "84bc37f944d270be5f84a952968db2b8cf5372c61146d29383468198ceed18fd\n"
          ]
        }
      ],
      "source": [
      "!docker run -d --name looper ubuntu:loop"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se agora tentarmos parar o contêiner com `docker kill looper`, tentaremos parar o contêiner com `docker kill looper`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "looper\n",
"CPU times: user 9.1 ms, sys: 857 µs, total: 9.96 ms\n",
"Wall time: 545 ms\n"
          ]
        }
      ],
      "source": [
      "%%time\n",
"!docker kill looper"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Podemos ver que o tempo é de aproximadamente 500 ms, ou seja, o docker o parou em um momento enviando o comando `SIGKILL`. Como o `kill` não envia o `SIGTERM` e, se o contêiner não tiver sido parado há algum tempo, ele envia o `SIGKILL`, o que ele faz é enviar o `SIGKILL` desde o início.\n",
"\n",
"Se observarmos os contêineres, veremos que o sinal de saída é o mesmo, `137`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE         COMMAND                 CREATED         STATUS                       PORTS     NAMES\n",
"84bc37f944d2   ubuntu:loop   \"/bin/sh -c /loop.sh\"   6 seconds ago   Exited (137) 2 seconds ago             looper\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Essa não é a maneira correta de encerrar um contêiner, pois quando quisermos encerrar o contêiner, teremos que fazer isso com o sinal `SIGTERM`, para que o contêiner termine de processar o que estava fazendo e, em seguida, encerre."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se excluirmos o contêiner e o executarmos novamente"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "looper\n"
          ]
        }
      ],
      "source": [
      "!docker rm looper"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "b9d9f370cc0de7569eb09d0a85cd67e8ea6babc0754a517ccba5c5057f5cc50e\n"
          ]
        }
      ],
      "source": [
      "!docker run -d --name looper ubuntu:loop"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se observarmos agora os processos que estão sendo executados dentro do contêiner"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "UID          PID    PPID  C STIME TTY          TIME CMD\n",
"root           1       0  0 14:05 ?        00:00:00 /bin/sh -c /loop.sh\n",
"root           7       1 93 14:05 ?        00:00:02 bash /loop.sh\n",
"root           8       0  0 14:05 ?        00:00:00 ps -ef\n"
          ]
        }
      ],
      "source": [
      "!docker exec looper ps -ef"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Na verdade, o processo principal, o processo 1, não é o `/loop.sh`, mas o `/bin/sh -c /loop.sh`, ou seja, é um processo filho do `shell`. Portanto, quando o sinal `SIGTERM` chegou, ele foi enviado para o `shell`, mas ele não o envia para seus processos filhos, por isso não chegou ao `loop.sh`."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Para evitar que isso aconteça, altere o `Dockerfile` para o seguinte\n",
"\n",
"*Arquivo do Docker:\n",
"``` docker\n",
"DE ubuntu:trusty\n",
"COPY [\"loop.sh\", \"/\"]\n",
"CMD [\"/loop.sh\"] # costumava ser CMD /loop.sh\n",
"```\n",
"\n",
"Esse formulário é chamado de `exec form`, enquanto o formulário anterior é chamado de `shell form`, de modo que o formulário anterior executa o processo como um filho do `shell`, enquanto o `exec form` executa o processo que lhe indicamos. Portanto, excluímos o contêiner, recompilamos e executamos o contêiner com a imagem novamente."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "looper\n"
          ]
        }
      ],
      "source": [
      "!docker rm -f looper"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Sending build context to Docker daemon  3.072kB\n",
"Step 1/3 : FROM ubuntu:trusty\n",
" ---> 13b66b487594\n",
"Step 2/3 : COPY [\"loop.sh\", \"/\"]\n",
" ---> Using cache\n",
" ---> 89f2bbd25a88\n",
"Step 3/3 : CMD [\"/loop.sh\"]\n",
" ---> Running in 6b8d92fcd57c\n",
"Removing intermediate container 6b8d92fcd57c\n",
" ---> 35a7bb2b1892\n",
"Successfully built 35a7bb2b1892\n",
"Successfully tagged ubuntu:loop\n",
"\n",
"Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\n"
          ]
        }
      ],
      "source": [
      "!docker build -t ubuntu:loop ./Dockerfile_loop"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "850ae70c071426850b28428ac60dcbf875c6d35d9b7cc66c17cf391a23392965\n"
          ]
        }
      ],
      "source": [
      "!docker run -d --name looper ubuntu:loop"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se agora eu olhar para os processos dentro do contêiner"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "UID          PID    PPID  C STIME TTY          TIME CMD\n",
"root           1       0 88 14:14 ?        00:00:02 bash /loop.sh\n",
"root           7       0  0 14:14 ?        00:00:00 ps -ef\n"
          ]
        }
      ],
      "source": [
      "!docker exec looper ps -ef"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Agora vejo que o processo principal, o processo 1, é o `/loop.sh`.\n",
"\n",
"Se agora eu tentar parar o contêiner"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "looper\n",
"CPU times: user 989 µs, sys: 7.55 ms, total: 8.54 ms\n",
"Wall time: 529 ms\n"
          ]
        }
      ],
      "source": [
      "%%time\n",
"!docker stop looper"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vemos que isso leva ms. Vamos ver o código com o qual ele parou"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE         COMMAND      CREATED              STATUS                      PORTS     NAMES\n",
"850ae70c0714   ubuntu:loop   \"/loop.sh\"   About a minute ago   Exited (0) 33 seconds ago             looper\n"
          ]
        }
      ],
      "source": [
      "!docker ps -a"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Contêineres executáveis"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se quisermos que um binário seja executado como um executável, no `dockerfile` temos que especificar o comando em `ENTRYPOINT` e os parâmetros de comando em `CMD`."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vamos criar uma nova pasta onde salvaremos o `Dockerfile`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
      "!mkdir dockerfile_ping"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Agora, criamos um Dockerfile dentro de"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
      "!touch dockerfile_ping/Dockerfile"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Escrevemos o seguinte no Dockerfile\n",
"\n",
"``` docker\n",
"DE ubuntu:trusty\n",
"ENTRYPOINT [ \"/bin/ping\", \"-c\", \"3\" ]\n",
"CMD [ \"localhost\" ]\n",
"```\n",
"\n",
"Compilamos a imagem"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Sending build context to Docker daemon  3.072kB\n",
"Step 1/3 : FROM ubuntu:trusty\n",
" ---> 13b66b487594\n",
"Step 2/3 : ENTRYPOINT [ \"/bin/ping\", \"-c\", \"3\" ]\n",
" ---> Using cache\n",
" ---> 1cebcfb542b1\n",
"Step 3/3 : CMD [ \"localhost\" ]\n",
" ---> Using cache\n",
" ---> 04ddc3de52a2\n",
"Successfully built 04ddc3de52a2\n",
"Successfully tagged ubuntu:ping\n",
"\n",
"Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\n"
          ]
        }
      ],
      "source": [
      "!docker build -t ubuntu:ping ./dockerfile_ping"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se agora executarmos a imagem sem passar um parâmetro, o contêiner fará ping em si mesmo."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "PING localhost (127.0.0.1) 56(84) bytes of data.\n",
"64 bytes from localhost (127.0.0.1): icmp_seq=1 ttl=64 time=0.041 ms\n",
"64 bytes from localhost (127.0.0.1): icmp_seq=2 ttl=64 time=0.058 ms\n",
"64 bytes from localhost (127.0.0.1): icmp_seq=3 ttl=64 time=0.054 ms\n",
"\n",
"--- localhost ping statistics ---\n",
"3 packets transmitted, 3 received, 0% packet loss, time 2027ms\n",
"rtt min/avg/max/mdev = 0.041/0.051/0.058/0.007 ms\n"
          ]
        }
      ],
      "source": [
      "!docker run --name ping_localhost ubuntu:ping"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Mas, se agora passarmos um parâmetro, ele fará o ping do endereço que dissermos para ele fazer."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "PING google.com (216.58.209.78) 56(84) bytes of data.\n",
"64 bytes from waw02s06-in-f14.1e100.net (216.58.209.78): icmp_seq=1 ttl=111 time=3.93 ms\n",
"64 bytes from waw02s06-in-f14.1e100.net (216.58.209.78): icmp_seq=2 ttl=111 time=6.80 ms\n",
"64 bytes from waw02s06-in-f14.1e100.net (216.58.209.78): icmp_seq=3 ttl=111 time=6.92 ms\n",
"\n",
"--- google.com ping statistics ---\n",
"3 packets transmitted, 3 received, 0% packet loss, time 2002ms\n",
"rtt min/avg/max/mdev = 3.930/5.886/6.920/1.383 ms\n"
          ]
        }
      ],
      "source": [
      "!docker run --name ping_google ubuntu:ping google.com"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Excluímos os contêineres"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "ping_localhost\n",
"ping_google\n"
          ]
        }
      ],
      "source": [
      "!docker rm ping_localhost ping_google"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### O contexto do `build`"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vamos criar uma pasta chamada `dockerfile_context`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
      "!mkdir dokerfile_contexto"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Agora, criamos dois arquivos nele, um `test.txt` e o `Dockerfile`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
      "!touch dokerfile_contexto/Dockerfile dokerfile_contexto/text.txt"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Modifique o Dockerfile e adicione o seguinte\n",
"\n",
"``` docker\n",
"DE ubuntu:trusty\n",
"COPIAR [\".\", \"/\"]\n",
"```\n",
"\n",
"Isso fará com que seja copiado para a imagem tudo o que você tem na pasta em que o `Dockerfile` está localizado. Compilar a imagem"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Sending build context to Docker daemon   2.56kB\n",
"Step 1/2 : FROM ubuntu:trusty\n",
" ---> 13b66b487594\n",
"Step 2/2 : COPY [\".\", \"/\"]\n",
" ---> 3ab79fdce389\n",
"Successfully built 3ab79fdce389\n",
"Successfully tagged ubuntu:contexto\n",
"\n",
"Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\n"
          ]
        }
      ],
      "source": [
      "!docker build -t ubuntu:contexto ./dokerfile_contexto"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vamos ver o que há dentro do contêiner"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Dockerfile\n",
"bin\n",
"boot\n",
"dev\n",
"etc\n",
"home\n",
"lib\n",
"lib64\n",
"media\n",
"mnt\n",
"opt\n",
"proc\n",
"root\n",
"run\n",
"sbin\n",
"srv\n",
"sys\n",
"text.txt\n",
"tmp\n",
"usr\n",
"var\n"
          ]
        }
      ],
      "source": [
      "!docker run --name ls ubuntu:contexto ls"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Como podemos ver, há o arquivo `text.txt`. Mas talvez dentro da pasta que está no mesmo diretório que o `Dockerfile` existam arquivos ou pastas que não queremos que sejam copiados na imagem, por qualquer motivo, então, assim como no git temos o `.gitignore`, no docker temos o `.dockerignore`, onde colocamos os arquivos ou pastas que não queremos que sejam levados em consideração ao compilar.\n",
"\n",
"Portanto, criamos um arquivo `.dockerignore`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
      "!touch dokerfile_contexto/.dockerignore"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Dentro dela, adicionamos o `text.txt` e, a propósito, o `Dockerfile` que não precisamos dentro da imagem.\n",
"\n",
"*.dockerignore*:\n",
"```\n",
"Dockerfile\n",
"text.txt\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Excluímos o contêiner que criamos, compilamos novamente e vemos o que está dentro do contêiner."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "ls\n"
          ]
        }
      ],
      "source": [
      "!docker rm ls"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Sending build context to Docker daemon  3.072kB\n",
"Step 1/2 : FROM ubuntu:trusty\n",
" ---> 13b66b487594\n",
"Step 2/2 : COPY [\".\", \"/\"]\n",
" ---> 7a6689546da4\n",
"Successfully built 7a6689546da4\n",
"Successfully tagged ubuntu:contexto\n",
"\n",
"Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\n"
          ]
        }
      ],
      "source": [
      "!docker build -t ubuntu:contexto ./dokerfile_contexto"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "bin\n",
"boot\n",
"dev\n",
"etc\n",
"home\n",
"lib\n",
"lib64\n",
"media\n",
"mnt\n",
"opt\n",
"proc\n",
"root\n",
"run\n",
"sbin\n",
"srv\n",
"sys\n",
"tmp\n",
"usr\n",
"var\n"
          ]
        }
      ],
      "source": [
      "!docker run --name ls ubuntu:contexto ls"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vemos que agora nem o `Dockerfile`, nem o `text.txt` estão lá. Excluímos o contêiner"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "ls\n"
          ]
        }
      ],
      "source": [
      "!docker rm ls"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Construção em vários estágios"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "No final de um desenvolvimento, não queremos que todo o código esteja na imagem a ser enviada para a produção.\n",
"\n",
"Podemos dividir o `dockerfile` em dois, por exemplo, o `developer.Dockerfile` e o `production.Dockerfile`, onde no desenvolvimento haverá mais coisas do que na produção. Ao compilá-los, usando a opção `f`, escolhemos o `dockerfile` que queremos usar\n",
"\n",
"``` bash\n",
"docker build -t <tag> -f developer.Dockerfile\n",
"docker build -t <tag> -f production.Dockerfile\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Mas para evitar ter que criar dois arquivos `Dockerfile`, o docker criou o `multi stage buils`. Com um único `Dockerfile`, resolveremos o problema"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Crie a pasta onde salvaremos o `Dockerfile`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
      "!mkdir docker_multi_stage"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Dentro dele, criamos o arquivo `Dockerfile`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
      "!cd docker_multi_stage && touch Dockerfile"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Editamos o arquivo inserindo o seguinte\n",
"\n",
"``` dockerfile\n",
"# Etapa 1: gerar o executável com Python baseado no Alpine\n",
"DE python:3.9-alpine como estágio de compilação\n",
"WORKDIR /app\n",
"# Instalar dependências para o PyInstaller\n",
"Executar apk add --no-cache gcc musl-dev libc-dev\n",
"# Gerar hello.py\n",
"RUN echo 'print(\"Hello from Alpine!\")' > hello.py\n",
"# Instalar o PyInstaller\n",
"Execute o pip install pyinstaller\n",
"# Use o PyInstaller para criar um executável autônomo\n",
"EXECUTAR pyinstaller --onefile hello.py\n",
"\n",
"# Etapa 2: Executar o executável em uma imagem do Alpine\n",
"DE alpine:latest\n",
"WORKDIR /app\n",
"# Copie o executável do estágio de compilação\n",
"COPY --from=build-stage /app/dist/hello .\n",
"# Comando padrão para executar o executável\n",
"CMD [\"./hello\"]\n",
"```\n",
"\n",
"Como você pode ver, o `Dockerfile` é dividido em dois, de um lado trabalhamos com a imagem `python:3.9-alpine` que é chamada de `build-stage`. E, do outro lado, trabalhamos com a imagem `alpine:latest`, que é uma imagem muito leve do Linux e é muito utilizada na produção.\n",
"\n",
"Nós o compilamos"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/2)                                          docker:default\n",
"\u001b[?25h"
          ]
        },
{
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.2s (4/6)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 722B                                       0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/alpine:latest           0.1s\n",
" => [internal] load metadata for docker.io/library/python:3.9-alpine       0.1s\n",
"...\n",
"\u001b[0m\u001b[34m => CACHED [stage-1 3/3] COPY --from=build-stage /app/dist/hello .         0.0s\n",
"\u001b[0m\u001b[34m => exporting to image                                                     0.0s\n",
"\u001b[0m\u001b[34m => => exporting layers                                                    0.0s\n",
"\u001b[0m\u001b[34m => => writing image sha256:7fb090d1495d00e892118b6bc3c03400b63a435fd4703  0.0s\n",
"\u001b[0m\u001b[34m => => naming to docker.io/maximofn/multistagebuild:latest                 0.0s\n",
"\u001b[0m\u001b[?25h"
          ]
        }
      ],
      "source": [
      "!docker build -t maximofn/multistagebuild:latest ./docker_multi_stage"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se olharmos agora para as imagens que temos"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "REPOSITORY                 TAG       IMAGE ID       CREATED         SIZE\n",
"maximofn/multistagebuild   latest    7fb090d1495d   8 minutes ago   13.6MB\n"
          ]
        }
      ],
      "source": [
      "!docker image ls"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Podemos ver a imagem que acabamos de criar e ela pesa apenas 13,6 MB. Vamos baixar a imagem do Python para ver quanto ela pesa"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "3.9-alpine: Pulling from library/python\n",
"\n",
"\u001b[1Ba8db6415: Already exists \n",
"\u001b[1Bd5e70e42: Already exists \n",
"\u001b[1B3fe96417: Already exists \n",
"\u001b[1Baa4dddbb: Already exists \n",
"\u001b[1B518be9f7: Already exists Digest: sha256:6e508b43604ff9a81907ec17405c9ad5c13664e45a5affa2206af128818c7486\n",
"Status: Downloaded newer image for python:3.9-alpine\n",
"docker.io/library/python:3.9-alpine\n"
          ]
        }
      ],
      "source": [
      "!docker pull python:3.9-alpine"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "REPOSITORY                 TAG          IMAGE ID       CREATED         SIZE\n",
"maximofn/multistagebuild   latest       7fb090d1495d   9 minutes ago   13.6MB\n",
"python                     3.9-alpine   6946662f018b   9 days ago      47.8MB\n"
          ]
        }
      ],
      "source": [
      "!docker image ls"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Podemos ver que, enquanto nossa imagem pesa apenas 13,6 MB, a imagem python com a qual ele criou o aplicativo pesa 47,8 MB. Portanto, podemos tirar duas conclusões: com a primeira imagem, a do python, ele criou o aplicativo, gerou o executável e esse executável é o que usamos na segunda imagem, a do alpine. Também podemos ver que, embora a primeira imagem usada seja a imagem python, ela não foi baixada em nosso sistema, pois tivemos que baixá-la nós mesmos."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Tudo o que resta é experimentá-lo"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Hello from Alpine!\n"
          ]
        }
      ],
      "source": [
      "!docker run --rm --name multi_stage_build maximofn/multistagebuild"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Funciona!"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Compilações multiarquitetura"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Suponha que queiramos criar uma imagem que será executada em um computador e em um Raspberry. O computador provavelmente tem um micro com arquitetura AMD64, enquanto o Raspberry tem um micro com arquitetura ARM. Portanto, não podemos criar a mesma imagem para ambos, ou seja, quando criamos uma imagem, nós a criamos com um `Dockerfile` que geralmente começa assim\n",
"\n",
"``` Dockerfile\n",
"DE ...\n",
"```\n",
"\n",
"Portanto, o `Dockerfile` da imagem do computador poderia começar assim\n",
"\n",
"``` Dockerfile\n",
"DE ubuntu:latest\n",
"```\n",
"\n",
"Já o de framboesa poderia começar assim\n",
"\n",
"``` Dockerfile\n",
"DE arm64v8/ubuntu:latest\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Teríamos que criar dois arquivos `Dockerfile`, compilá-los e, no computador, usar uma imagem e, na impressora, usar outra."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Para não ter que ficar olhando a arquitetura do computador e ver qual imagem temos que usar o Docker eu crio o `manifest`, que como o próprio nome indica é um manifesto que indica dependendo de qual arquitetura de micro temos usa uma imagem ou outra."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Então, vamos ver como fazer isso"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Primeiro, criamos uma pasta na qual criaremos nossos arquivos `Dockerfile`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
      "!mkdir docker_multi_arch"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Agora, criamos os dois dockerfiles"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
      "!cd docker_multi_arch && touch Dockerfile_arm64 Dockerfile_amd64"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Escrevemos a partir do `Dockerfile` para AMD64"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
      "!cd docker_multi_arch && echo \"FROM ubuntu:20.04\" >> Dockerfile_amd64 && echo \"CMD echo 'Hello from amd64'\" >> Dockerfile_amd64"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
      "!cd docker_multi_arch && echo \"FROM arm64v8/ubuntu:latest\" >> Dockerfile_arm && echo \"CMD echo 'Hello from ARM'\" >> Dockerfile_arm"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Agora, compilamos as duas imagens"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/1)                                          docker:default\n",
"\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.2s (2/3)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/ubuntu:20.04            0.1s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.3s (2/3)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/ubuntu:20.04            0.2s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.5s (2/3)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/ubuntu:20.04            0.4s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.6s (2/3)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/ubuntu:20.04            0.5s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.7s (2/4)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/ubuntu:20.04            0.6s\n",
" => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.9s (3/4)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/ubuntu:20.04            0.8s\n",
"\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.0s (3/4)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/ubuntu:20.04            0.9s\n",
"\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.2s (3/4)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/ubuntu:20.04            1.1s\n",
"\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.3s (3/4)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/ubuntu:20.04            1.2s\n",
"\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.5s (3/4)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/ubuntu:20.04            1.4s\n",
"\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.6s (3/4)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/ubuntu:20.04            1.5s\n",
"\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.8s (3/4)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/ubuntu:20.04            1.7s\n",
"\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.9s (3/4)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/ubuntu:20.04            1.8s\n",
"\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.1s (3/4)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.0s\n",
"\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.2s (3/4)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.1s\n",
"\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.4s (3/4)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.3s\n",
"\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.5s (3/4)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.4s\n",
"\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.7s (3/4)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.6s\n",
"\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.8s (4/4)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.9s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.1s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b11063bc4 0B / 27.51MB  0.1s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.0s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.2s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b11063bc4 0B / 27.51MB  0.2s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.1s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.3s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b11063bc4 0B / 27.51MB  0.3s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.3s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.5s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b11063bc4 0B / 27.51MB  0.4s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.4s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.6s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b11063bc4 0B / 27.51MB  0.6s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.5s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.7s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b11063bc4 0B / 27.51MB  0.7s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.7s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.9s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b11063bc4 0B / 27.51MB  0.8s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.8s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  1.0s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b1106 1.05MB / 27.51MB  1.0s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 4.0s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  1.2s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b1106 1.05MB / 27.51MB  1.1s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 4.1s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  1.3s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b1106 2.10MB / 27.51MB  1.3s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 4.2s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  1.4s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b1106 2.10MB / 27.51MB  1.4s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 4.4s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  1.6s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b1106 2.10MB / 27.51MB  1.5s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 4.5s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  1.7s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b1106 3.15MB / 27.51MB  1.7s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 4.6s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  1.8s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b1106 3.15MB / 27.51MB  1.8s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 4.8s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  2.0s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b1106 4.19MB / 27.51MB  1.9s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 4.9s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  2.1s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b1106 4.19MB / 27.51MB  2.1s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 5.0s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  2.2s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b1106 5.24MB / 27.51MB  2.2s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 5.2s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  2.4s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b1106 5.24MB / 27.51MB  2.3s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 5.3s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  2.5s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b1106 6.29MB / 27.51MB  2.5s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 5.4s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  2.6s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b1106 6.29MB / 27.51MB  2.6s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 5.6s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  2.8s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b1106 6.29MB / 27.51MB  2.7s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 5.7s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  2.9s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b1106 7.34MB / 27.51MB  2.9s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 5.8s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  3.0s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b1106 8.39MB / 27.51MB  3.0s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 6.0s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  3.2s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b1106 8.39MB / 27.51MB  3.1s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 6.1s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  3.3s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b1106 9.44MB / 27.51MB  3.3s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 6.3s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  3.5s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b1106 9.44MB / 27.51MB  3.4s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 6.4s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  3.6s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 10.49MB / 27.51MB  3.6s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 6.5s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  3.7s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 10.49MB / 27.51MB  3.7s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 6.6s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  3.8s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 11.53MB / 27.51MB  3.8s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 6.8s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  4.0s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 11.53MB / 27.51MB  3.9s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 6.9s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  4.1s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 12.58MB / 27.51MB  4.1s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 7.1s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  4.3s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 12.58MB / 27.51MB  4.2s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 7.2s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  4.4s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 13.63MB / 27.51MB  4.4s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 7.4s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  4.6s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 14.68MB / 27.51MB  4.5s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 7.5s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  4.7s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 15.73MB / 27.51MB  4.7s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 7.6s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  4.8s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 15.73MB / 27.51MB  4.8s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 7.8s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  5.0s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 16.78MB / 27.51MB  4.9s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 7.9s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  5.1s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 16.78MB / 27.51MB  5.1s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 8.1s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  5.3s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 17.83MB / 27.51MB  5.2s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 8.2s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  5.4s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 18.87MB / 27.51MB  5.4s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 8.4s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  5.6s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 19.92MB / 27.51MB  5.5s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 8.5s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  5.7s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 19.92MB / 27.51MB  5.7s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 8.7s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  5.9s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 20.97MB / 27.51MB  5.8s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 8.8s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  6.0s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 22.02MB / 27.51MB  6.0s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 8.9s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  6.1s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 23.07MB / 27.51MB  6.1s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 9.1s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  6.3s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 23.07MB / 27.51MB  6.2s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 9.2s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  6.4s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 24.12MB / 27.51MB  6.4s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 9.3s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  6.5s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 25.17MB / 27.51MB  6.5s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 9.5s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  6.7s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 25.17MB / 27.51MB  6.6s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 9.6s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  6.8s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 26.21MB / 27.51MB  6.8s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 9.7s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  6.9s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 27.26MB / 27.51MB  6.9s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 9.8s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  7.0s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 27.51MB / 27.51MB  7.0s\n",
"\u001b[0m => => extracting sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b11063bc445  0.0s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 9.9s (4/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  7.1s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 27.51MB / 27.51MB  7.0s\n",
"\u001b[0m => => extracting sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b11063bc445  0.1s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 10.0s (4/5)                                         docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  7.2s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 27.51MB / 27.51MB  7.0s\n",
"\u001b[0m => => extracting sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b11063bc445  0.2s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 10.1s (4/5)                                         docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  7.4s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 27.51MB / 27.51MB  7.0s\n",
"\u001b[0m => => extracting sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b11063bc445  0.3s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 10.3s (4/5)                                         docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  7.5s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 27.51MB / 27.51MB  7.0s\n",
"\u001b[0m => => extracting sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b11063bc445  0.4s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 10.4s (4/5)                                         docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  7.6s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 27.51MB / 27.51MB  7.0s\n",
"\u001b[0m => => extracting sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b11063bc445  0.5s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 10.5s (4/5)                                         docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  7.7s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 27.51MB / 27.51MB  7.0s\n",
"\u001b[0m => => extracting sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b11063bc445  0.6s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 10.6s (4/5)                                         docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  7.8s\n",
"\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 27.51MB / 27.51MB  7.0s\n",
"\u001b[0m\u001b[34m => => extracting sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b11063bc445  0.7s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 10.7s (5/5)                                         docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[34m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  7.9s\n",
"\u001b[0m\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 27.51MB / 27.51MB  7.0s\n",
"\u001b[0m\u001b[34m => => extracting sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b11063bc445  0.7s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 10.8s (6/6) FINISHED                                docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile_amd64                 0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 89B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:20.04            2.7s\n",
"\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[34m => [1/1] FROM docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  7.9s\n",
"\u001b[0m\u001b[34m => => resolve docker.io/library/ubuntu:20.04@sha256:33a5cc25d22c45900796  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:33a5cc25d22c45900796a1aca487ad7a7cb09f09ea0 1.13kB / 1.13kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:3246518d9735254519e1b2ff35f95686e4a5011c90c8534 424B / 424B  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:6df89402372646d400cf092016c28066391a26f5d46 2.30kB / 2.30kB  0.0s\n",
"\u001b[0m\u001b[34m => => sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b110 27.51MB / 27.51MB  7.0s\n",
"\u001b[0m\u001b[34m => => extracting sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b11063bc445  0.7s\n",
"\u001b[0m\u001b[34m => exporting to image                                                     0.0s\n",
"\u001b[0m\u001b[34m => => exporting layers                                                    0.0s\n",
"\u001b[0m\u001b[34m => => writing image sha256:5b612c83025ff77a7237d662357a1b7f07ff1bfb4aadf  0.0s\n",
"\u001b[0m\u001b[34m => => naming to docker.io/maximofn/multiarch:amd64                        0.0s\n",
"\u001b[0m\u001b[?25h"
          ]
        }
      ],
      "source": [
      "!cd docker_multi_arch && docker build -t maximofn/multiarch:amd64 -f Dockerfile_amd64 ."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/1)                                          docker:default\n",
"\u001b[?25h"
          ]
        },
{
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.2s (2/3)                                          docker:default\n",
"\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile_arm                   0.0s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 94B                                        0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/arm64v8/ubuntu:latest           0.1s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.3s (2/3)                                          docker:default\n",
"\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile_arm                   0.0s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 94B                                        0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/arm64v8/ubuntu:latest           0.3s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.5s (2/3)                                          docker:default\n",
"\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile_arm                   0.0s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 94B                                        0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/arm64v8/ubuntu:latest           0.4s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.6s (2/3)                                          docker:default\n",
"\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile_arm                   0.0s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 94B                                        0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/arm64v8/ubuntu:latest           0.6s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.8s (2/3)                                          docker:default\n",
"\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile_arm                   0.0s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 94B                                        0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/arm64v8/ubuntu:latest           0.7s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.9s (2/4)                                          docker:default\n",
"\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile_arm                   0.0s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 94B                                        0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/arm64v8/ubuntu:latest           0.8s\n",
" => [auth] arm64v8/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.0s (3/4)                                          docker:default\n",
"\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile_arm                   0.0s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 94B                                        0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/arm64v8/ubuntu:latest           1.0s\n",
"\u001b[34m => [auth] arm64v8/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.2s (3/4)                                          docker:default\n",
"\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile_arm                   0.0s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 94B                                        0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/arm64v8/ubuntu:latest           1.1s\n",
"\u001b[34m => [auth] arm64v8/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.3s (3/4)                                          docker:default\n",
"\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile_arm                   0.0s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 94B                                        0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/arm64v8/ubuntu:latest           1.3s\n",
"\u001b[34m => [auth] arm64v8/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.5s (3/4)                                          docker:default\n",
"\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile_arm                   0.0s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 94B                                        0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/arm64v8/ubuntu:latest           1.4s\n",
"\u001b[34m => [auth] arm64v8/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.6s (3/4)                                          docker:default\n",
"\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile_arm                   0.0s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 94B                                        0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/arm64v8/ubuntu:latest           1.6s\n",
"\u001b[34m => [auth] arm64v8/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.8s (3/4)                                          docker:default\n",
"\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile_arm                   0.0s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 94B                                        0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/arm64v8/ubuntu:latest           1.7s\n",
"\u001b[34m => [auth] arm64v8/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.9s (6/6) FINISHED                                 docker:default\n",
"\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile_arm                   0.0s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 94B                                        0.0s\n",
"\u001b[0m\u001b[34m => [internal] load metadata for docker.io/arm64v8/ubuntu:latest           1.8s\n",
"\u001b[0m\u001b[34m => [auth] arm64v8/ubuntu:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[34m => CACHED [1/1] FROM docker.io/arm64v8/ubuntu:latest@sha256:94d12db896d0  0.0s\n",
"\u001b[0m\u001b[34m => exporting to image                                                     0.0s\n",
"\u001b[0m\u001b[34m => => exporting layers                                                    0.0s\n",
"\u001b[0m\u001b[34m => => writing image sha256:a9732c1988756dc8e836fd96e5c9512e349c97ea5af46  0.0s\n",
"\u001b[0m\u001b[34m => => naming to docker.io/maximofn/multiarch:arm                          0.0s\n",
"\u001b[0m\u001b[?25h"
          ]
        }
      ],
      "source": [
      "!cd docker_multi_arch && docker build -t maximofn/multiarch:arm -f Dockerfile_arm ."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vejamos que temos as imagens compiladas ods"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "REPOSITORY           TAG       IMAGE ID       CREATED       SIZE\n",
"maximofn/multiarch   arm       a9732c198875   4 weeks ago   69.2MB\n",
"maximofn/multiarch   amd64     5b612c83025f   6 weeks ago   72.8MB\n"
          ]
        }
      ],
      "source": [
      "!docker image ls"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vemos que compilamos as duas imagens. Para criar um manifesto, primeiro precisamos fazer upload das imagens para o docker hub, portanto, fazemos upload delas"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "The push refers to repository [docker.io/maximofn/multiarch]\n",
"\n",
"\u001b[1B82bdeb5f: Mounted from library/ubuntu amd64: digest: sha256:30e820f2a11a24ad4d8fb624ae485f7c1bcc299e8cfc72c88adce1acd0447e1d size: 529\n"
          ]
        }
      ],
      "source": [
      "!docker push maximofn/multiarch:amd64"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "The push refers to repository [docker.io/maximofn/multiarch]\n"
          ]
        },
{
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "\n",
"\u001b[1Beda53374: Layer already exists arm: digest: sha256:6ec5a0752d49d3805061314147761bf25b5ff7430ce143adf34b70d4eda15fb8 size: 529\n"
          ]
        }
      ],
      "source": [
      "!docker push maximofn/multiarch:arm"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se eu acessar meu hub do docker, verei que minha imagem `maximofn/multiarch` tem as tags `amd64` e `arm`.\n",
"\n",
"![docker_multi_arch_tags](https://maximofn.com/wp-content/uploads/2023/09/docker_multi_arch_tags.png)"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Agora, vamos criar o `manifesto` com base nessas duas imagens"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Created manifest list docker.io/maximofn/multiarch:latest\n"
          ]
        }
      ],
      "source": [
      "!docker manifest create maximofn/multiarch:latest maximofn/multiarch:amd64 maximofn/multiarch:arm"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Depois de criadas, precisamos indicar as arquiteturas de CPU às quais cada uma corresponde."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
      "!docker manifest annotate maximofn/multiarch:latest maximofn/multiarch:amd64 --os linux --arch amd64"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "manifest for image maximofn/multiarch:arm64 does not exist in maximofn/multiarch:latest\n"
          ]
        }
      ],
      "source": [
      "!docker manifest annotate maximofn/multiarch:latest maximofn/multiarch:arm64 --os linux --arch arm64"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Depois de criado e anotado, podemos fazer upload do `manifest` para o hub do docker"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "sha256:1ea28e9a04867fe0e0d8b0efa455ce8e4e29e7d9fd4531412b75dbd0325e9304\n"
          ]
        }
      ],
      "source": [
      "!docker manifest push maximofn/multiarch:latest"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se eu observar as tags na minha imagem `maximofn/multiarch` agora, também verei a tag `latest`.\n",
"\n",
"docker_multi_arch_tags_manifest](https://maximofn.com/wp-content/uploads/2023/09/docker_multi_arch_tags_manifest.png)"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Agora, se eu quiser usar minha imagem a partir de uma máquina com CPU AMD64 ou ARM, ao fazer `FROM maximofn/multiarch:latest`, o docker verificará a arquitetura da CPU e puxará a tag `amd64` ou a tag `arm`. Vejamos, se eu executar a imagem em meu computador, obterei"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Unable to find image 'maximofn/multiarch:latest' locally\n"
          ]
        },
{
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "latest: Pulling from maximofn/multiarch\n",
"Digest: sha256:7cef0de10f7fa2b3b0dca0fbf398d1f48af17a0bbc5b9beca701d7c427c9fd84\n",
"Status: Downloaded newer image for maximofn/multiarch:latest\n",
"Hello from amd64\n"
          ]
        }
      ],
      "source": [
      "!docker run maximofn/multiarch:latest"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Como não o tem, ele faz o download e, em seguida, aparece o texto `Hello from amd64`, pois a CPU do meu computador tem arquitetura AMD64."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se agora eu me conectar via ssh a um raspberry pi e tentar a mesma coisa, obtenho\n",
"\n",
"````bash\n",
"raspiberry@raspberrypi:~ $ docker run maximofn/multiarch:latest\n",
"    Não foi possível localizar a imagem 'maximofn/multiarch:latest' localmente\n",
"    mais recente: Extraindo do maximofn/multiarch\n",
"    Digest: sha256:1ea28e9a04867fe0e0d8b0efa455ce8e4e29e7d9fd4531412b75dbd0325e9304\n",
"    Status: Imagem mais recente baixada para maximofn/multiarch:latest\n",
"    Olá da ARM\n",
"```\n",
"\n",
"Hello from ARM\" aparece porque o Raspberry tem uma microarquitetura ARM."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Como você pode ver, cada máquina baixou a imagem de que precisava."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Correção da gravação de Dockerfiles avançados"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Já vimos como escrever dockerfiles corretamente, mas há mais uma coisa que podemos fazer agora que conhecemos a compilação em vários estágios: criar um contêiner para criar o executável e outro menor para executá-lo\n",
"\n",
"Chegamos à conclusão de que um bom dockerfile poderia ser este\n",
"\n",
"``` Dockerfile\n",
"DE python:3.9.18-alpine\n",
"WORKDIR /sourceCode/sourceApp\n",
"COPY ./sourceCode/sourceApp .\n",
"CMD [\"python3\", \"app.py\"]\n",
"```\n",
"\n",
"Agora, criaremos um executável em um contêiner do construtor e o executaremos em um contêiner menor.\n",
"\n",
"``` dockerfile\n",
"FROM python:3.9.18-alpine as builder\n",
"WORKDIR /sourceCode/sourceApp\n",
"Execute o apk add --no-cache gcc musl-dev libc-dev && pip install pyinstaller\n",
"COPY ./sourceCode/sourceApp .\n",
"EXECUTAR pyinstaller --onefile app.py\n",
"\n",
"DE alpine:3.18.3\n",
"WORKDIR /sourceCode/sourceApp\n",
"COPY --from=builder /sourceCode/sourceApp/dist/app .\n",
"CMD [\"./app\"]\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Criamos o código python no caminho necessário"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
      "!mkdir multistagebuild/sourceCode\n",
"!mkdir multistagebuild/sourceCode/sourceApp\n",
"!touch multistagebuild/sourceCode/sourceApp/app.py\n",
"!echo 'print(\"Hello from Alpine!\")' > multistagebuild/sourceCode/sourceApp/app.py"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Agora, compilamos a imagem"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/0)                                          docker:default\n",
"\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.0s (0/1)                                          docker:default\n",
"\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.2s (3/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile                       0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 357B                                       0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/alpine:3.18.3           0.1s\n",
" => [internal] load metadata for docker.io/library/python:3.9.18-alpine    0.1s\n",
"\u001b[34m => [auth] library/alpine:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.3s (3/5)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile                       0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 357B                                       0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/alpine:3.18.3           0.2s\n",
" => [internal] load metadata for docker.io/library/python:3.9.18-alpine    0.2s\n",
"\u001b[34m => [auth] library/alpine:pull token for registry-1.docker.io              0.0s\n",
"\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.5s (4/6)                                          docker:default\n",
"\u001b[34m => [internal] load build definition from Dockerfile                       0.1s\n",
"\u001b[0m\u001b[34m => => transferring dockerfile: 357B                                       0.0s\n",
"\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
"\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
"\u001b[0m => [internal] load metadata for docker.io/library/alpine:3.18.3           0.4s\n",
"...\n",
"\u001b[0m\u001b[34m => exporting to image                                                     0.1s\n",
"\u001b[0m\u001b[34m => => exporting layers                                                    0.1s\n",
"\u001b[0m\u001b[34m => => writing image sha256:8a22819145c6fee17e138e818610ccf46d7e13c786825  0.0s\n",
"\u001b[0m\u001b[34m => => naming to docker.io/maximofn/multistagebuild:alpine-3.18.3          0.0s\n",
"\u001b[0m\u001b[?25h"
          ]
        }
      ],
      "source": [
      "!docker build -t maximofn/multistagebuild:alpine-3.18.3 ./multistagebuild"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Nós o executamos"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Hello from Alpine!\n"
          ]
        }
      ],
      "source": [
      "!docker run --rm --name multi_stage_build maximofn/multistagebuild:alpine-3.18.3"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "A imagem `maximofn/multistagebuild:alpine-3.18.3` pesa apenas 13,6 MB"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Diferença entre RUN, CMD e ENTRYPOINT"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "#### RUN"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "O comando `RUN` é o comando mais simples, ele simplesmente executa um comando no momento da compilação da imagem. Por exemplo, se quisermos instalar um pacote na imagem, faremos isso com o `RUN`.\n",
"\n",
"Portanto, é importante ressaltar que o `RUN` é executado no momento da compilação da imagem, e não quando o contêiner é executado."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "#### CMD"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "O comando `CMD` é o comando que é executado quando o contêiner é executado. Por exemplo, se quisermos que o contêiner execute um comando quando for executado, faremos isso com o `CMD`. Por exemplo, se tivermos um aplicativo python em um contêiner, com `CMD` podemos dizer a ele para executar o aplicativo python quando o contêiner for executado.\n",
"\n",
"Dessa forma, quando o contêiner for criado, o aplicativo python será executado. Ou seja, se fizermos `docker run <image>`, ele executará o aplicativo python. Mas o `CMD` nos permite substituir o comando que é executado quando o contêiner é levantado, ou seja, se fizermos `docker run <image> bash`, ele executará `bash` em vez do aplicativo python."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "#### ENTRYPOINT"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "O comando `ENTRYPOINT` é semelhante ao comando `CMD`, mas com uma diferença: o `ENTRYPOINT` não se destina a ser sobrescrito. Ou seja, se tivermos um aplicativo python em um contêiner, com o `ENTRYPOINT` podemos dizer a ele para executar o aplicativo python quando o contêiner for executado. Mas se fizermos `docker run <image> bash`, ele executará o aplicativo python, não o `bash`.\n",
"\n",
"Um uso muito comum do `ENTRYPOINT` é quando queremos que o contêiner seja um executável, por exemplo, se quisermos que o contêiner seja um executável de uma versão do python que não temos em nosso host, porque, por exemplo, queremos testar a nova versão do python que foi lançada, poderíamos fazer\n",
"\n",
"``` Dockerfile\n",
"DE python:3.9.18-alpine\n",
"ENTRYPOINT [\"python3\"]\n",
"```\n",
"\n",
"Dessa forma, quando o contêiner for levantado, o python será executado. Ou seja, se fizermos `docker run <image>`, ele executará o python. Mas o `ENTRYPOINT` nos permite sobrescrever o comando que é executado quando o contêiner é levantado, ou seja, se fizermos `docker run <image> myapp.py`, ele executará `python3 myapp.py` dentro do contêiner. Dessa forma, podemos testar nosso aplicativo python na nova versão do python."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "### Docker no Docker"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Suponhamos que tenhamos contêineres que precisem levantar ou desligar outros contêineres. Isso é feito da seguinte maneira\n",
"\n",
"Como no Linux tudo é um arquivo e o host se comunica com o docker por meio de um soquete. Portanto, para o Linux, esse soquete é um arquivo. Portanto, um contêiner que montar esse soquete como um arquivo poderá se comunicar com o docker."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Primeiro, vamos montar um contêiner com o ubuntu"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "144091e4a3325c9068064ff438f8865b40f944af5ce649c7156ca55a3453e423\n"
          ]
        }
      ],
      "source": [
      "!docker run -d --name ubuntu ubuntu:latest tail -f /dev/null"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vamos montar o contêiner que poderá se comunicar com o docker montando a pasta `/var/run/docker.sock`.\n",
"\n",
"``` bash\n",
"$ docker run -it --rm --name main -v /var/run/docker.sock:/var/run/docker.sock docker:19.03.12\n",
"\n",
"```\n",
"\n",
"Nós nos colocamos dentro de um contêiner e, se estivermos dentro, executamos o `docker ps`\n",
"\n",
"``` bash\n",
"# docker ps\n",
"ID DO CONTÊINER ID DO CONTÊINER IMAGE COMMAND CREATED STATUS PORTS NAMES\n",
"9afb778d6c20 docker:19.03.12 \"docker-entrypoint.s...\"   3 segundos atrás Up 2 segundos main\n",
"144091e4a332 ubuntu:latest \"tail -f /dev/null\" 19 seconds ago Up 18 seconds ubuntu\n",
"```\n",
"\n",
"Como podemos ver, dentro da janela de encaixe, podemos ver os contêineres do host"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Podemos executar um novo contêiner\n",
"\n",
"``` bash\n",
"# docker run -d --name ubuntu_from_main ubuntu:latest tail -f /dev/null\n",
"362654a72bb0fb047c13968707a6f16b87fed7ce051eb5c1a146b15828589a1a\n",
"\n",
"```\n",
"\n",
"E se virmos os contêineres novamente\n",
"\n",
"``` bash\n",
"# docker ps\n",
"ID DO CONTÊINER ID DO CONTÊINER IMAGE COMMAND CREATED STATUS PORTS NAMES\n",
"362654a72bb0 ubuntu:latest \"tail -f /dev/null\" 3 seconds ago Up 3 seconds ubuntu_from_main\n",
"9afb778d6c20 docker:19.03.12 \"docker-entrypoint.s...\"   Cerca de um minuto atrás Up Cerca de um minuto atrás\n",
"144091e4a332 ubuntu:latest \"tail -f /dev/null\" 2 minutes ago Up Cerca de um minuto ubuntu\n",
"```\n",
"\n",
"Mas se agora executarmos um novo terminal de host, veremos o contêiner criado dentro do contêiner."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "CONTAINER ID   IMAGE             COMMAND                  CREATED              STATUS              PORTS     NAMES\n",
"362654a72bb0   ubuntu:latest     \"tail -f /dev/null\"      About a minute ago   Up About a minute             ubuntu_from_main\n",
"9afb778d6c20   docker:19.03.12   \"docker-entrypoint.s…\"   3 minutes ago        Up 3 minutes                  main\n",
"144091e4a332   ubuntu:latest     \"tail -f /dev/null\"      3 minutes ago        Up 3 minutes                  ubuntu\n"
          ]
        }
      ],
      "source": [
      "!docker ps"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Tudo o que fizermos no contêiner `main` será refletido no host."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Isso tem a vantagem de permitir a instalação de programas em um contêiner que tenha acesso ao host, de modo que não seja necessário instalá-los no host. Por exemplo, [dive](https://github.com/wagoodman/dive) é uma ferramenta para explorar contêineres, mas se você não quiser instalá-la no host, poderá instalá-la em um contêiner com acesso ao host, de modo que, a partir desse contêiner `principal`, você poderá explorar o restante dos contêineres sem precisar instalá-la no host."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.7.6 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "d5745ab6aba164e1152437c779991855725055592b9f2bdb41a4825db7168d26"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
