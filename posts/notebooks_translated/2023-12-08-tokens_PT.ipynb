{
  "cells": [
  {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "# Tokens"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Agora que os `LLLMs` est√£o na moda, continuamos ouvindo sobre o n√∫mero de `tokens` suportados por cada modelo, mas o que s√£o `tokens`? S√£o as unidades m√≠nimas de representa√ß√£o de palavras."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Este caderno foi traduzido automaticamente para torn√°-lo acess√≠vel a mais pessoas, por favor me avise se voc√™ vir algum erro de digita√ß√£o..\n",
"\n",
"Para explicar o que s√£o `tokens`, vamos primeiro dar uma olhada em um exemplo pr√°tico: vamos usar o tokenizador da OpenAI, chamado [tiktoken] (https://github.com/openai/tiktoken).\n",
"\n",
"Ent√£o, primeiro instalamos o pacote:\n",
"\n",
"````bash\n",
"pip install tiktoken\n",
"```"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Depois de instalado, criamos um tokenizador usando o modelo `cl100k_base`, que o notebook de exemplo [How to count tokens with tiktoken] (https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb) explica que √© usado pelos modelos `gpt-4`, `gpt-3.5-turbo` e `text-embedding-ada-002`."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
      "import tiktoken\n",
"\n",
"encoder = tiktoken.get_encoding(\"cl100k_base\")"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Agora, criamos uma palavra de amostra tara e a tokenizamos"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
      "example_word = \"breakdown\""
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "E n√≥s o simbolizamos"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
      {
          "data": {
            "text/plain": [
            "[9137, 2996]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
      "tokens = encoder.encode(example_word)\n",
"tokens"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "A palavra foi dividida em 2 tokens, o `9137` e o `2996`. Vamos ver a quais palavras elas correspondem"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
      {
          "data": {
            "text/plain": [
            "('break', 'down')"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
      "word1 = encoder.decode([tokens[0]])\n",
"word2 = encoder.decode([tokens[1]])\n",
"word1, word2"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "O tokenizador `OpenAI` dividiu a palavra `breakdown` nas palavras `break` e `down`. Ou seja, ele dividiu a palavra em duas palavras mais simples.\n",
"\n",
"Isso √© importante porque, quando se diz que um `LLM` suporta x `token`s`, n√£o significa que ele suporta x palavras, mas que suporta x unidades m√≠nimas de representa√ß√£o de palavras."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Se voc√™ tiver um texto e quiser ver o n√∫mero de `token`s que ele tem para o tokenizador `OpenAI`, poder√° visualiz√°-lo na p√°gina [Tokenizer](https://platform.openai.com/tokenizer), que mostra cada `token` em uma cor diferente.\n",
"\n",
"![tokenizer](http://maximofn.com/wp-content/uploads/2023/12/tokenizer.webp)"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vimos o tokenizador `OpenAI`, mas cada `LLM` poder√° usar outro."
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Como dissemos, os `tokens` s√£o as unidades m√≠nimas de representa√ß√£o de palavras, portanto, vamos ver quantos tokens diferentes o `tiktoken` tem."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Vocab size: 100277\n"
          ]
        }
      ],
      "source": [
      "n_vocab = encoder.n_vocab\n",
"print(f\"Vocab size: {n_vocab}\")"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Vamos ver como ele tokeniza outros tipos de palavras."
      ]
    },
{
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
      "def encode_decode(word):\n",
"    tokens = encoder.encode(word)\n",
"    decode_tokens = []\n",
"    for token in tokens:\n",
"        decode_tokens.append(encoder.decode([token]))\n",
"    return tokens, decode_tokens"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Word: dog ==> tokens: [18964], decode_tokens: ['dog']\n",
"Word: tomorrow... ==> tokens: [38501, 7924, 1131], decode_tokens: ['tom', 'orrow', '...']\n",
"Word: artificial intelligence ==> tokens: [472, 16895, 11478], decode_tokens: ['art', 'ificial', ' intelligence']\n",
"Word: Python ==> tokens: [31380], decode_tokens: ['Python']\n",
"Word: 12/25/2023 ==> tokens: [717, 14, 914, 14, 2366, 18], decode_tokens: ['12', '/', '25', '/', '202', '3']\n",
"Word: üòä ==> tokens: [76460, 232], decode_tokens: ['ÔøΩ', 'ÔøΩ']\n"
          ]
        }
      ],
      "source": [
      "word = \"dog\"\n",
"tokens, decode_tokens = encode_decode(word)\n",
"print(f\"Word: {word} ==> tokens: {tokens}, decode_tokens: {decode_tokens}\")\n",
"\n",
"word = \"tomorrow...\"\n",
"tokens, decode_tokens = encode_decode(word)\n",
"print(f\"Word: {word} ==> tokens: {tokens}, decode_tokens: {decode_tokens}\")\n",
"\n",
"word = \"artificial intelligence\"\n",
"tokens, decode_tokens = encode_decode(word)\n",
"print(f\"Word: {word} ==> tokens: {tokens}, decode_tokens: {decode_tokens}\")\n",
"\n",
"word = \"Python\"\n",
"tokens, decode_tokens = encode_decode(word)\n",
"print(f\"Word: {word} ==> tokens: {tokens}, decode_tokens: {decode_tokens}\")\n",
"\n",
"word = \"12/25/2023\"\n",
"tokens, decode_tokens = encode_decode(word)\n",
"print(f\"Word: {word} ==> tokens: {tokens}, decode_tokens: {decode_tokens}\")\n",
"\n",
"word = \"üòä\"\n",
"tokens, decode_tokens = encode_decode(word)\n",
"print(f\"Word: {word} ==> tokens: {tokens}, decode_tokens: {decode_tokens}\")"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Por fim, vamos dar uma olhada em palavras em outro idioma"
      ]
    },
{
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
      {
          "name": "stdout",
          "output_type": "stream",
          "text": [
          "Word: perro ==> tokens: [716, 299], decode_tokens: ['per', 'ro']\n",
"Word: perra ==> tokens: [79, 14210], decode_tokens: ['p', 'erra']\n",
"Word: ma√±ana... ==> tokens: [1764, 88184, 1131], decode_tokens: ['ma', '√±ana', '...']\n",
"Word: inteligencia artificial ==> tokens: [396, 39567, 8968, 21075], decode_tokens: ['int', 'elig', 'encia', ' artificial']\n",
"Word: Python ==> tokens: [31380], decode_tokens: ['Python']\n",
"Word: 12/25/2023 ==> tokens: [717, 14, 914, 14, 2366, 18], decode_tokens: ['12', '/', '25', '/', '202', '3']\n",
"Word: üòä ==> tokens: [76460, 232], decode_tokens: ['ÔøΩ', 'ÔøΩ']\n"
          ]
        }
      ],
      "source": [
      "word = \"perro\"\n",
"tokens, decode_tokens = encode_decode(word)\n",
"print(f\"Word: {word} ==> tokens: {tokens}, decode_tokens: {decode_tokens}\")\n",
"\n",
"word = \"perra\"\n",
"tokens, decode_tokens = encode_decode(word)\n",
"print(f\"Word: {word} ==> tokens: {tokens}, decode_tokens: {decode_tokens}\")\n",
"\n",
"word = \"ma√±ana...\"\n",
"tokens, decode_tokens = encode_decode(word)\n",
"print(f\"Word: {word} ==> tokens: {tokens}, decode_tokens: {decode_tokens}\")\n",
"\n",
"word = \"inteligencia artificial\"\n",
"tokens, decode_tokens = encode_decode(word)\n",
"print(f\"Word: {word} ==> tokens: {tokens}, decode_tokens: {decode_tokens}\")\n",
"\n",
"word = \"Python\"\n",
"tokens, decode_tokens = encode_decode(word)\n",
"print(f\"Word: {word} ==> tokens: {tokens}, decode_tokens: {decode_tokens}\")\n",
"\n",
"word = \"12/25/2023\"\n",
"tokens, decode_tokens = encode_decode(word)\n",
"print(f\"Word: {word} ==> tokens: {tokens}, decode_tokens: {decode_tokens}\")\n",
"\n",
"word = \"üòä\"\n",
"tokens, decode_tokens = encode_decode(word)\n",
"print(f\"Word: {word} ==> tokens: {tokens}, decode_tokens: {decode_tokens}\")"
      ]
    },
{
      "cell_type": "markdown",
      "metadata": {},
      "source": [
      "Podemos ver que, para palavras semelhantes, mais tokens s√£o gerados em espanhol do que em ingl√™s, portanto, para o mesmo texto, com um n√∫mero semelhante de palavras, o n√∫mero de tokens ser√° maior em espanhol do que em ingl√™s."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "openai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
