{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Medida de similaridade entre embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " > Aviso: Este post foi traduzido para o portugu\u00eas usando um modelo de tradu\u00e7\u00e3o autom\u00e1tica. Por favor, me avise se encontrar algum erro."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Agora que vimos o que s\u00e3o os [embeddings](https://maximofn.com/embeddings), sabemos que podemos medir a similaridade entre duas palavras medindo a similaridade entre seus embeddings. No post de [embeddings](https://maximofn.com/embeddings) vimos o exemplo do uso da medida de similaridade por cosseno, mas existem outras medidas de similaridade que podemos usar, como o quadrado L2, a similaridade do produto escalar, a similaridade por cosseno, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Neste post, vamos ver essas tr\u00eas que mencionamos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Similaridade pelo quadrado L2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Esta similaridade \u00e9 derivada da dist\u00e2ncia euclidiana, que \u00e9 a dist\u00e2ncia em linha reta entre dois pontos em um espa\u00e7o multidimensional, que \u00e9 calculada com o teorema de Pit\u00e1goras.",
        "\n",
        "![dist\u00e2ncia euclidiana](https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/distancia_euclidiana.webp)",
        "\n",
        "A dist\u00e2ncia euclidiana entre dois pontos $p$ e $q$ \u00e9 calculada como:",
        "\n",
        "$$",
        "d(p,q) = \\sqrt{(p_1 - q_1)^2 + (p_2 - q_2)^2 + \\cdots + (p_n - q_n)^2} = \\sqrt{\\sum_{i=1}^n (p_i - q_i)^2}",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A similaridade pelo quadrado L2 \u00e9 o quadrado da dist\u00e2ncia euclidiana, ou seja:",
        "\n",
        "$$",
        "similidade(p,q) = d(p,q)^2 = \\sum_{i=1}^n (p_i - q_i)^2",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Similaridade cosseno"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se lembrarmos do que aprendemos sobre senos e cossenos na escola, lembraremos que quando dois vetores t\u00eam um \u00e2ngulo de 0\u00ba entre eles, seu cosseno \u00e9 1, quando o \u00e2ngulo entre eles \u00e9 de 90\u00ba, seu cosseno \u00e9 0 e quando o \u00e2ngulo \u00e9 de 180\u00ba, seu cosseno \u00e9 -1.",
        "\n",
        "![similaridade cosseno](https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/dot-product.gif)",
        "\n",
        "![similaridade cosseno](https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/dot-product-unity.gif)",
        "\n",
        "Portanto, podemos usar o cosseno do \u00e2ngulo entre dois vetores para medir sua similaridade. Pode-se demonstrar que o cosseno do \u00e2ngulo entre dois vetores \u00e9 igual ao produto escalar dos dois vetores dividido pelo produto de seus m\u00f3dulos. N\u00e3o \u00e9 o objetivo deste post demonstr\u00e1-lo, mas se quiserem podem ver a demonstra\u00e7\u00e3o [aqui](https://www.wwwinsights.com/wp-content/uploads/2023/05/image-11-1024x694.png).",
        "\n",
        "$$",
        "similitude(U,V) = \\frac{U \\cdot V}{\\|U\\| \\|V\\|}",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Similaridade do produto escalar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A similaridade do produto escalar \u00e9 o produto escalar de dois vetores",
        "\n",
        "$$",
        "similaridade(U,V) = U \\cdot V",
        "$$",
        "\n",
        "Como escrevemos a f\u00f3rmula da similaridade cosseno, quando o comprimento dos vetores \u00e9 1, ou seja, est\u00e3o normalizados, a similaridade cosseno \u00e9 igual \u00e0 similaridade do produto escalar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ent\u00e3o, para que serve a similaridade pelo produto escalar? Para medir a similaridade entre dois vetores que n\u00e3o est\u00e3o normalizados, ou seja, que n\u00e3o t\u00eam comprimento 1.",
        "\n",
        "Por exemplo, o YouTube, para criar os embeddings dos seus v\u00eddeos, faz com que os embeddings dos v\u00eddeos que classifica como de maior qualidade sejam mais longos do que os dos v\u00eddeos que classifica como de menor qualidade.",
        "\n",
        "Desta forma, quando um usu\u00e1rio faz uma pesquisa, a similaridade pelo produto escalar dar\u00e1 maior similaridade aos v\u00eddeos de maior qualidade, portanto fornecer\u00e1 ao usu\u00e1rio os v\u00eddeos de maior qualidade em primeiro lugar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Qual sistema de similaridade usar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para escolher o sistema de similaridade que vamos usar, devemos ter em conta o espa\u00e7o no qual estamos trabalhando.",
        "\n",
        "* Se estivermos trabalhando em um espa\u00e7o de alta dimensionalidade, com embeddings normalizados, a similaridade cosseno \u00e9 a que melhor funciona. Por exemplo, a OpenAI gera embeddings normalizados, portanto a similaridade cosseno \u00e9 a que melhor funciona.",
        "* Se estivermos trabalhando em um sistema de classifica\u00e7\u00e3o, onde a dist\u00e2ncia entre duas classes \u00e9 importante, a similaridade pelo quadrado L2 \u00e9 a que melhor funciona.",
        "* Se estivermos trabalhando em um sistema de recomenda\u00e7\u00e3o, onde a comprimento dos vetores \u00e9 importante, a similaridade do produto escalar \u00e9 a que melhor funciona."
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "maximofn": {
      "date": "2023-12-18",
      "description_en": "Discover how similarity is measured between embeddings, the basis of the attention mechanism of transformers and RAG algorithms",
      "description_es": "Descubre c\u00f3mo se mide la similitud entre embeddings, la base del mecanismo de atenci\u00f3n de los transformers y de los algoritmos de RAG",
      "description_pt": "Descubra como \u00e9 medida a similaridade entre embeddings, a base do mecanismo de aten\u00e7\u00e3o dos transformers e dos algoritmos de RAG",
      "end_url": "embeddings-similarity",
      "image": "https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/embeddings-similarity.webp",
      "image_hover_path": "https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/embeddings-similarity.webp",
      "keywords_en": "embeddings, similarity, cosine similarity, L2 similarity, dot product similarity",
      "keywords_es": "embeddings, similitud, similitud por coseno, similitud L2, similitud por producto escalar",
      "keywords_pt": "embeddings, similaridade, similaridade por cosseno, similaridade L2, similaridade por produto escalar",
      "title_en": "Medida de similitud entre embeddings",
      "title_es": "Embeddings similarity measure",
      "title_pt": "Medida de similaridade entre embeddings"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}