{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FastRTC: The Real-Time Communication Library for Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " > Disclaimer: This post has been translated to English using a machine translation model. Please, let me know if you find any mistakes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In recent months, we have seen significant advancements in real-time voice models, with entire companies being founded around both open-source and closed models. Some key milestones include:\n",
        "\n",
        "* ``OpenAI`` and ``Google`` launched their live multimodal APIs for ChatGPT and Gemini. OpenAI even launched a phone number ``1-800-ChatGPT``!\n",
        "* ``Kyutai`` launched [Moshi](https://huggingface.co/kyutai), a fully open-source audio-to-audio LLM.\n",
        "* ``Alibaba`` launched [Qwen2-Audio](https://huggingface.co/Qwen/Qwen2-Audio-7B-Instruct), an open-source LLM that natively understands audio.\n",
        "* ``Fixie.ai`` launched [Ultravox](https://huggingface.co/fixie-ai/ultravox-v0_5-llama-3_3-70b), another open-source LLM that also natively understands audio.\n",
        "* ``ElevenLabs`` raised 180 million dollars in its Series C."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Despite this explosion in models and funding, it remains difficult to build real-time AI applications that stream audio and video, especially in Python.\n",
        "\n",
        "* Machine learning engineers may not have experience with the necessary technologies to build real-time applications, such as ``WebRTC``.\n",
        "* Even code assistance tools like ``Cursor`` and ``Copilot`` struggle to write Python code that supports real-time audio/video applications.\n",
        "\n",
        "That's why the announcement of `FastRTC`, the real-time communication library for Python, is exciting. The library is designed to make it easy to build real-time audio and video AI applications entirely in Python!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Main Features of FastRTC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* üó£Ô∏è Automatic voice detection and built-in turn taking, so you only have to worry about the user response logic.\n",
        "* üíª Automatic UI - Built-in Gradio UI enabled for WebRTC for testing (or deployment to production!).\n",
        "* üìû Phone call - Use ``fastphone()`` to get a **free** phone number to call your audio stream (HF token required).\n",
        "* ‚ö°Ô∏è Support for ``WebRTC`` and ``Websocket``.\n",
        "* üí™ Customizable - You can mount the stream in any ``FastAPI`` application to serve a custom UI and deploy beyond ``Gradio``.\n",
        "* üß∞ Many utilities for `text-to-speech`, `speech-to-text`, `stop detection` to help you get started."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To be able to use `FastRTC`, you first need to install the library:\n",
        "\n",
        "``` bash\n",
        "pip install fastrtc\n",
        "```\n",
        "\n",
        "But if we want to install the pause detection, speech-to-text, and text-to-speech functionalities, we need to install some additional dependencies:\n",
        "\n",
        "``` bash\n",
        "pip install \"fastrtc[vad, stt, tts]\"\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Getting Started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will start by building the `hello world` of real-time audio: echoing what the user says. In `FastRTC`, this is as simple as:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7872\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7872/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:     127.0.0.1:58223 - \"GET / HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58223 - \"GET /assets/index-C7PS0jJm.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58225 - \"GET /assets/index-Bo0Yq5bb.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58223 - \"GET /assets/svelte/svelte.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58225 - \"GET /assets/Embed-FUIL71FR.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58223 - \"GET /assets/Index-wMEhc4G9.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58228 - \"GET /assets/StreamingBar-DOagx4HU.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58227 - \"GET /assets/index-B1gfMDT9.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58230 - \"GET /assets/IconButtonWrapper-EOzMzU45.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58229 - \"GET /assets/StreamingBar.svelte_svelte_type_style_lang-CDNxkBIr.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58225 - \"GET /assets/MarkdownCode-DPiWQnAx.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58223 - \"GET /assets/DownloadLink-CqD3Uu0l.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58227 - \"GET /assets/IconButtonWrapper.svelte_svelte_type_style_lang-BOpxTcdu.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58229 - \"GET /assets/prism-python-qapVsvY8.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58228 - \"GET /assets/Index-BJ_RfjVB.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58230 - \"GET /assets/MarkdownCode.svelte_svelte_type_style_lang-3tofWDHK.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58225 - \"GET /assets/IconButton-B-aAVSzy.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58229 - \"GET /assets/Clear-By3xiIwg.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58228 - \"GET /assets/context-TgWPFwN2.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58230 - \"GET /theme.css?v=63194d3741d384f9f85db890247b6c0ef9e7abac0f297f40a15c59fe4baba916 HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58228 - \"GET /assets/Button-BWSOH8Qq.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58225 - \"GET /assets/Image-CsmDAdIf.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58229 - \"GET /assets/Blocks-E57YC_S0.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58227 - \"GET /assets/Button-DTh9AgeE.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58223 - \"GET /assets/Image-B8dFOee4.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58230 - \"GET /assets/ImagePreview-DJhr8Mfv.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58223 - \"GET /assets/file-url-DgijyRSD.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58225 - \"GET /assets/Dropdown-CWxB-qJp.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58228 - \"GET /assets/Example-D7K5RtQ2.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58227 - \"GET /assets/Blocks-B5wxaDIo.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58229 - \"GET /assets/Dropdown-DjrBHETv.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58230 - \"GET /assets/Block-DZqtZLFP.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58228 - \"GET /assets/BlockTitle-BIcnzvtg.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58225 - \"GET /assets/index-CvpmwOJi.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58223 - \"GET /assets/MarkdownCode-DJM7o_VY.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58230 - \"GET /assets/Info-DcCn6tHi.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58227 - \"GET /assets/DropdownArrow-dYuMZY9s.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58229 - \"GET /assets/Toast-DdWZrg4w.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58230 - \"GET /assets/utils-BsGrhMNe.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58223 - \"GET /gradio_api/custom_component/91a0d0cc3e6164063c775a057aff53510cb8fc04c8b99d010e09ce4ba9beb99d/client/component/style.css HTTP/1.1\" 304 Not Modified\n",
            "INFO:     127.0.0.1:58230 - \"GET /assets/Index-ChJkSByh.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58227 - \"GET /assets/Index-CfowPFmo.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58228 - \"GET /assets/Index-CptIZeFZ.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58229 - \"GET /assets/Index-Csm0OGa9.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58225 - \"GET /assets/Index-Cgj6KPvj.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58223 - \"GET /assets/Code-DGNrTu_I.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58225 - \"GET /gradio_api/custom_component/91a0d0cc3e6164063c775a057aff53510cb8fc04c8b99d010e09ce4ba9beb99d/client/component/index.js HTTP/1.1\" 304 Not Modified\n",
            "INFO:     127.0.0.1:58228 - \"GET /assets/Index-HXWviefR.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58229 - \"GET /assets/Index-WEzAIkMk.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58230 - \"GET /assets/BlockLabel-DqHge3FF.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58227 - \"GET /assets/Index-CRGGsrTx.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58241 - \"GET / HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58241 - \"GET /theme.css?v=63194d3741d384f9f85db890247b6c0ef9e7abac0f297f40a15c59fe4baba916 HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58241 - \"GET /gradio_api/custom_component/91a0d0cc3e6164063c775a057aff53510cb8fc04c8b99d010e09ce4ba9beb99d/client/component/style.css HTTP/1.1\" 304 Not Modified\n",
            "INFO:     127.0.0.1:58244 - \"GET /gradio_api/custom_component/91a0d0cc3e6164063c775a057aff53510cb8fc04c8b99d010e09ce4ba9beb99d/client/component/index.js HTTP/1.1\" 304 Not Modified\n",
            "INFO:     127.0.0.1:58260 - \"GET /static/fonts/ui-sans-serif/ui-sans-serif-Bold.woff2 HTTP/1.1\" 404 Not Found\n",
            "INFO:     127.0.0.1:58260 - \"GET /static/fonts/system-ui/system-ui-Bold.woff2 HTTP/1.1\" 404 Not Found\n"
          ]
        }
      ],
      "source": [
        "from fastrtc import Stream, ReplyOnPause\n",
        "import numpy as np\n",
        "\n",
        "def echo(audio: tuple[int, np.ndarray]) -> tuple[int, np.ndarray]:\n",
        "    yield audio\n",
        "\n",
        "stream = Stream(ReplyOnPause(echo), modality=\"audio\", mode=\"send-receive\")\n",
        "stream.ui.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When we go to the link that Gradio suggests, we first have to give permissions to the browser to access the microphone. Next, this will appear:\n",
        "\n",
        "![fastrct - hello world - init](https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/fastRTC%20-%20hello%20world%20-%20init.webp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we click on the tab to the right of the word `Record`, we can select the microphone we want to use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When we press the `Record` button, everything we say will be repeated by the application. That is, it captures the audio, detects when we have stopped speaking, and repeats it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's break it down:\n",
        "\n",
        "* `ReplyOnPause` will handle voice detection and turn-taking for you. You only need to worry about the logic for responding to the user. You have to pass it the function that will manage the input audio. In our case, it's the `echo` function, which captures the input audio and returns it as a stream using `yield`, which many people don't know, but is a generator, meaning it's a Python method for creating iterators. If you want to learn more about `yield`, you can read my post on [Python](https://www.maximofn.com/python#6.5.-Generators). Any generator that returns an audio tuple (represented as `(sample_rate, audio_data)`) will work.\n",
        "* The `Stream` class will build a Gradio UI for you to quickly test your stream. Once you have finished prototyping, you can deploy your Stream as a production-ready FastAPI application in a single line of code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we can see an example from the creators of `FastRTC`\n",
        "\n",
        "<video src=\"https://github.com/user-attachments/assets/fcf2d30e-3e98-47c9-8dc3-23340784c441\" controls></video>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Leveling Up: Voice Chat with LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The next level is to use an LLM to respond to the user. `FastRTC` comes with built-in `speech-to-text` and `text-to-speech` capabilities, so working with LLMs is really easy. Let's modify our `echo` function accordingly:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded as API: https://maximofn-smollm2-localmodel.hf.space ‚úî\n",
            "* Running on local URL:  http://127.0.0.1:7871\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7871/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:     127.0.0.1:58224 - \"GET / HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58224 - \"GET /assets/index-Bo0Yq5bb.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58226 - \"GET /assets/index-C7PS0jJm.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58226 - \"GET /assets/svelte/svelte.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58226 - \"GET /assets/Index-wMEhc4G9.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58232 - \"GET /assets/StreamingBar-DOagx4HU.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58234 - \"GET /assets/IconButtonWrapper-EOzMzU45.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58224 - \"GET /assets/Embed-FUIL71FR.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58233 - \"GET /assets/StreamingBar.svelte_svelte_type_style_lang-CDNxkBIr.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58231 - \"GET /assets/index-B1gfMDT9.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58231 - \"GET /assets/MarkdownCode-DPiWQnAx.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58224 - \"GET /assets/MarkdownCode.svelte_svelte_type_style_lang-3tofWDHK.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58233 - \"GET /assets/Index-BJ_RfjVB.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58232 - \"GET /assets/DownloadLink-CqD3Uu0l.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58234 - \"GET /assets/IconButtonWrapper.svelte_svelte_type_style_lang-BOpxTcdu.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58226 - \"GET /assets/prism-python-qapVsvY8.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58231 - \"GET /assets/IconButton-B-aAVSzy.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58233 - \"GET /assets/Clear-By3xiIwg.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58234 - \"GET /assets/context-TgWPFwN2.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58224 - \"GET /theme.css?v=63194d3741d384f9f85db890247b6c0ef9e7abac0f297f40a15c59fe4baba916 HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58234 - \"GET /assets/Blocks-E57YC_S0.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58231 - \"GET /assets/Image-B8dFOee4.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58226 - \"GET /assets/ImagePreview-DJhr8Mfv.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58233 - \"GET /assets/Button-BWSOH8Qq.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58232 - \"GET /assets/Button-DTh9AgeE.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58224 - \"GET /assets/Dropdown-CWxB-qJp.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58232 - \"GET /assets/Image-CsmDAdIf.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58226 - \"GET /assets/Blocks-B5wxaDIo.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58233 - \"GET /assets/Example-D7K5RtQ2.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58234 - \"GET /assets/Block-DZqtZLFP.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58231 - \"GET /assets/file-url-DgijyRSD.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58224 - \"GET /assets/Info-DcCn6tHi.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58232 - \"GET /assets/MarkdownCode-DJM7o_VY.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58234 - \"GET /assets/Dropdown-DjrBHETv.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58233 - \"GET /assets/index-CvpmwOJi.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58226 - \"GET /assets/BlockTitle-BIcnzvtg.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58231 - \"GET /assets/DropdownArrow-dYuMZY9s.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58224 - \"GET /assets/Toast-DdWZrg4w.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58234 - \"GET /assets/utils-BsGrhMNe.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58232 - \"GET /assets/Index-CfowPFmo.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58234 - \"GET /assets/Index-ChJkSByh.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58224 - \"GET /assets/Code-DGNrTu_I.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58226 - \"GET /assets/Index-Csm0OGa9.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58233 - \"GET /assets/Index-HXWviefR.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58231 - \"GET /assets/BlockLabel-DqHge3FF.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58224 - \"GET /gradio_api/custom_component/91a0d0cc3e6164063c775a057aff53510cb8fc04c8b99d010e09ce4ba9beb99d/client/component/style.css HTTP/1.1\" 304 Not Modified\n",
            "INFO:     127.0.0.1:58231 - \"GET /assets/Index-Cgj6KPvj.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58233 - \"GET /gradio_api/custom_component/91a0d0cc3e6164063c775a057aff53510cb8fc04c8b99d010e09ce4ba9beb99d/client/component/index.js HTTP/1.1\" 304 Not Modified\n",
            "INFO:     127.0.0.1:58226 - \"GET /assets/Index-CptIZeFZ.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58232 - \"GET /assets/Index-CRGGsrTx.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58234 - \"GET /assets/Index-WEzAIkMk.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58242 - \"GET / HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58242 - \"GET /theme.css?v=63194d3741d384f9f85db890247b6c0ef9e7abac0f297f40a15c59fe4baba916 HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58242 - \"GET /gradio_api/custom_component/91a0d0cc3e6164063c775a057aff53510cb8fc04c8b99d010e09ce4ba9beb99d/client/component/style.css HTTP/1.1\" 304 Not Modified\n",
            "INFO:     127.0.0.1:58243 - \"GET /gradio_api/custom_component/91a0d0cc3e6164063c775a057aff53510cb8fc04c8b99d010e09ce4ba9beb99d/client/component/index.js HTTP/1.1\" 304 Not Modified\n",
            "INFO:     127.0.0.1:58250 - \"GET /static/fonts/ui-sans-serif/ui-sans-serif-Bold.woff2 HTTP/1.1\" 404 Not Found\n",
            "INFO:     127.0.0.1:58250 - \"GET /static/fonts/system-ui/system-ui-Bold.woff2 HTTP/1.1\" 404 Not Found\n"
          ]
        }
      ],
      "source": [
        "from fastrtc import ReplyOnPause, Stream, get_stt_model, get_tts_model\n",
        "from gradio_client import Client\n",
        "\n",
        "client = Client(\"Maximofn/SmolLM2_localModel\")\n",
        "stt_model = get_stt_model()\n",
        "tts_model = get_tts_model()\n",
        "\n",
        "def echo(audio):\n",
        "    prompt = stt_model.stt(audio)\n",
        "    response = client.predict(\n",
        "            message=prompt,\n",
        "            system_message=\"You are a friendly Chatbot. Always reply in the language in which the user is writing to you.\",\n",
        "            max_tokens=512,\n",
        "            temperature=0.7,\n",
        "            top_p=0.95,\n",
        "            api_name=\"/chat\"\n",
        "    )\n",
        "    prompt = response\n",
        "    for audio_chunk in tts_model.stream_tts_sync(prompt):\n",
        "        yield audio_chunk\n",
        "\n",
        "stream = Stream(ReplyOnPause(echo), modality=\"audio\", mode=\"send-receive\")\n",
        "stream.ui.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As a ``speech-to-text`` model, use ``Moonshine``, which supposedly only supports English, but I have tested it in Spanish and it understands well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As a language model, we will use the model I deployed in a backend on Hugging Face and wrote about in the post [Deploying a Backend with LLM on HuggingFace](https://www.maximofn.com/deploy-backend-with-llm-in-huggingface). It uses the LLM `HuggingFaceTB/SmolLM2-1.7B-Instruct`, which is a small model since it's running on a backend with CPU, but it works quite well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As a ``text-to-speech`` model, use ``Kokoro``, which does have options to speak in other languages, but is not yet implemented in the `FastRTC` library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we are very interested in using `speech-to-speech` and `text-to-speech` models in other languages, we could implement them ourselves, because the greatest potential of `FastRTC` lies in the real-time communication layer, but I won't go into that now."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now if we test the code we just wrote, we can have a voice chatbot in real time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phone Call\n",
        "\n",
        "If you call `stream.fastphone()` instead of `stream.ui.launch()`, you will get a free phone number to call your stream. Note that a Hugging Face token is required.\n",
        "\n",
        "We generated a script because it doesn't always work in a Jupyter Notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile fastrtc_phone_demo.py\n",
        "\n",
        "from fastrtc import ReplyOnPause, Stream, get_stt_model, get_tts_model\n",
        "import gradio\n",
        "from gradio_client import Client\n",
        "import os\n",
        "from gradio.networking import setup_tunnel as original_setup_tunnel\n",
        "import socket\n",
        "\n",
        "# Monkey patch setup_tunnel para que acepte el par√°metro adicional\n",
        "def patched_setup_tunnel(host, port, share_token, share_server_address, share_server_tls_certificate=None):\n",
        "    return original_setup_tunnel(host, port, share_token, share_server_address, share_server_tls_certificate)\n",
        "\n",
        "# Replace the original function with our patched version\n",
        "gradio.networking.setup_tunnel = patched_setup_tunnel\n",
        "\n",
        "# Get the token from the environment variable\n",
        "HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN = os.getenv(\"HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN\")\n",
        "\n",
        "# Initialize the LLM client\n",
        "llm_client = Client(\"Maximofn/SmolLM2_localModel\")\n",
        "\n",
        "# Initialize the STT and TTS models\n",
        "stt_model = get_stt_model()\n",
        "tts_model = get_tts_model()\n",
        "\n",
        "# Define the echo function\n",
        "def echo(audio):\n",
        "    # Convert the audio to text\n",
        "    prompt = stt_model.stt(audio)\n",
        "\n",
        "    # Generate the response\n",
        "    response = llm_client.predict(\n",
        "            message=prompt,\n",
        "            system_message=\"You are a friendly Chatbot. Always reply in the language in which the user is writing to you.\",\n",
        "            max_tokens=512,\n",
        "            temperature=0.7,\n",
        "            top_p=0.95,\n",
        "            api_name=\"/chat\"\n",
        "    )\n",
        "    \n",
        "    # Convert the response to audio\n",
        "    prompt = response\n",
        "\n",
        "    # Stream the audio\n",
        "    for audio_chunk in tts_model.stream_tts_sync(prompt):\n",
        "        yield audio_chunk\n",
        "\n",
        "def find_free_port(start_port=8000, max_port=9000):\n",
        "    \"\"\"Find the first free port starting from start_port.\"\"\"\n",
        "    print(f\"Searching for a free port starting from {start_port}...\")\n",
        "    for port in range(start_port, max_port):\n",
        "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:\n",
        "            result = sock.connect_ex(('127.0.0.1', port))\n",
        "            if result != 0:  # If result != 0, the port is free\n",
        "                print(f\"Free port found: {port}\")\n",
        "                return port\n",
        "    raise RuntimeError(f\"No free port found between {start_port} and {max_port}\")\n",
        "    \n",
        "free_port = find_free_port()    # Search for a free port\n",
        "\n",
        "stream = Stream(ReplyOnPause(echo), modality=\"audio\", mode=\"send-receive\")\n",
        "stream.fastphone(token=HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN, port=free_port)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We explain the code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The part\n",
        "\n",
        "``` pyhon\n",
        "# Monkey patch `setup_tunnel` to accept the additional parameter\n",
        "def patched_setup_tunnel(host, port, share_token, share_server_address, share_server_tls_certificate=None):\n",
        "return original_setup_tunnel(host, port, share_token, share_server_address, share_server_tls_certificate)\n",
        "\n",
        "# Replace the original function with our patched version\n",
        "gradio.networking.setup_tunnel = patched_setup_tunnel\n",
        "```\n",
        "\n",
        "It is necessary because `FastRTC` is written for an older version of `gradio` that does not support the `share_server_address` parameter in the `setup_tunnel` method. So we patch it to accept the additional parameter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As a Hugging Face token is required, we obtain it from the environment variable `HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN`.\n",
        "\n",
        "``` python\n",
        "# Get the token from the environment variable\n",
        "HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN = os.getenv(\"HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN\")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The language models, the `speech-to-text` model, and the `text-to-speech` model are created below, along with the `echo` function that will handle the input and output audio.\n",
        "\n",
        "``` python\n",
        "# Initialize the LLM client\n",
        "llm_client = Client(\"Maximofn/SmolLM2_localModel\")\n",
        "\n",
        "# Initialize the STT and TTS models\n",
        "stt_model = get_stt_model()\n",
        "tts_model = get_tts_model()\n",
        "\n",
        "# Define the echo function\n",
        "def echo(audio):\n",
        "# Convert the audio to text\n",
        "prompt = stt_model.stt(audio)\n",
        "\n",
        "# Generate the response\n",
        "response = llm_client.predict(\n",
        "message=prompt,\n",
        "system_message=\"You are a friendly Chatbot. Always reply in the language in which the user is writing to you.\"\n",
        "max_tokens=512,\n",
        "temperature=0.7,\n",
        "top_p=0.95,\n",
        "api_name=\"/chat\"\n",
        ")\n",
        "    \n",
        "# Convert the response to audio\n",
        "prompt = response\n",
        "\n",
        "# Stream the audio\n",
        "for audio_chunk in tts_model.stream_tts_sync(prompt):\n",
        "yield audio_chunk\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we have used port `8000` before, in case it tells you that it is occupied, we create a function to find a free port and find one.\n",
        "\n",
        "``` python\n",
        "def find_free_port(start_port=8000, max_port=9000):\n",
        "    \"\"\"Find the first free port starting from start_port.\"\"\"\n",
        "    print(f\"Searching for a free port starting from {start_port}...\")\n",
        "    for port in range(start_port, max_port):\n",
        "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:\n",
        "            result = sock.connect_ex(('127.0.0.1', port))\n",
        "            if result != 0:  # If result != 0, the port is free\n",
        "                print(f\"Free port found: {port}\")\n",
        "                return port\n",
        "    raise RuntimeError(f\"No free port found between {start_port} and {max_port}\")\n",
        "    \n",
        "free_port = find_free_port()    # Search for a free port\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The stream is created and now `stream.fastphone()` is used to get a free phone number to call your stream, instead of `stream.ui.launch()` which we used before to create the graphical interface.\n",
        "\n",
        "``` python\n",
        "stream = Stream(ReplyOnPause(echo), modality=\"audio\", mode=\"send-receive\")\n",
        "stream.fastphone(token=HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN, port=free_port)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we run it, we will see something like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded as API: https://maximofn-smollm2-localmodel.hf.space ‚úî\n",
            "\u001b[32mINFO\u001b[0m:\t  Warming up STT model.\n",
            "\u001b[32mINFO\u001b[0m:\t  STT model warmed up.\n",
            "\u001b[32mINFO\u001b[0m:\t  Warming up VAD model.\n",
            "\u001b[32mINFO\u001b[0m:\t  VAD model warmed up.\n",
            "Searching for a free port starting from 8000...\n",
            "Free port found: 8004\n",
            "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m24029\u001b[0m]\n",
            "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
            "\u001b[32mINFO\u001b[0m:\t  Visit \u001b[36mhttps://fastrtc.org/userguide/api/\u001b[0m for WebRTC or Websocket API docs.\n",
            "\u001b[32mINFO\u001b[0m:     Application startup complete.\n",
            "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://127.0.0.1:8004\u001b[0m (Press CTRL+C to quit)\n",
            "\u001b[32mINFO\u001b[0m:\t  Your FastPhone is now live! Call \u001b[36m+1 877-713-4471\u001b[0m and use code \u001b[36m994514\u001b[0m to connect to your stream.\n",
            "\u001b[32mINFO\u001b[0m:\t  You have \u001b[36m30:00\u001b[0m minutes remaining in your quota (Resetting on \u001b[36m2025-04-07\u001b[0m)\n",
            "\u001b[32mINFO\u001b[0m:\t  Visit \u001b[36mhttps://fastrtc.org/userguide/audio/#telephone-integration\u001b[0m for information on making your handler compatible with phone usage.\n"
          ]
        }
      ],
      "source": [
        "!python fastrtc_phone_demo.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that it appears\n",
        "\n",
        "``` bash\n",
        "INFO:\tYour FastPhone is now live! Call +1 877-713-4471 and use code 994514 to connect to your stream.\n",
        "INFO:\tYou have 30:00 minutes remaining in your quota (Resetting on 2025-04-07)\n",
        "```\n",
        "\n",
        "That is, if we call the number `+1 877-713-4471` and use the code `994514`, it will connect us to our stream."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we go to [Telephone Integration](https://fastrtc.org/userguide/audio/#telephone-integration) in the `FastRTC` documentation, we will see that it uses [twilio](https://www.twilio.com/) to make the call. It has an option to configure a local number from the United States, Dublin, Frankfurt, Tokyo, Singapore, Sydney, and S√£o Paulo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I tried making the call from Spain (which is going to be quite expensive for me) and it works, but it's slow. I called, entered the code, and waited for the agent to connect, but since it was taking too long, I hung up."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "fastrtc",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "maximofn": {
      "date": "2025-03-08",
      "description_en": "If you have problems making a real-time AI application, FastRTC can help you. In this post I explain how to use it.",
      "description_es": "Si tienes problemas para hacer una aplicaci√≥n de IA en tiempo real, FastRTC es una biblioteca que te puede ayudar. En este post te explico c√≥mo usarla.",
      "description_pt": "Se voc√™ tem problemas para fazer uma aplica√ß√£o de IA em tempo real, o FastRTC pode te ajudar. Neste post, explico como us√°-lo.",
      "end_url": "fastrtc",
      "image": "https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/fastrtc-thumbnail.webp",
      "image_hover_path": "https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/fastrtc-thumbnail.webp",
      "keywords_en": "fastrtc, real-time, ai, application, phone",
      "keywords_es": "fastrtc, real-time, ai, aplicaci√≥n, tel√©fono",
      "keywords_pt": "fastrtc, real-time, ai, aplica√ß√£o, telefone",
      "title_en": "Make a real-time AI application with FastRTC",
      "title_es": "Hacer una aplicaci√≥n de IA en tiempo real con FastRTC",
      "title_pt": "Fazer uma aplica√ß√£o de IA em tempo real com FastRTC"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
