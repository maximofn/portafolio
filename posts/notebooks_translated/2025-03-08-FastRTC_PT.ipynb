{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FastRTC: A Biblioteca de Comunica\u00e7\u00e3o em Tempo Real para Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " > Aviso: Este post foi traduzido para o portugu\u00eas usando um modelo de tradu\u00e7\u00e3o autom\u00e1tica. Por favor, me avise se encontrar algum erro."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nos \u00faltimos meses, temos visto um grande avan\u00e7o em modelos de voz em tempo real, com empresas inteiras fundadas ao redor de modelos tanto de c\u00f3digo aberto quanto fechado. Alguns marcos importantes incluem:",
        "\n",
        "* ``OpenAI`` e ``Google`` lan\u00e7aram suas APIs multimodais ao vivo para ChatGPT e Gemini. \u00a1A OpenAI at\u00e9 lan\u00e7ou um n\u00famero de telefone ``1-800-ChatGPT``!",
        "* ``Kyutai`` lan\u00e7ou [Moshi](https://huggingface.co/kyutai), um LLM de \u00e1udio para \u00e1udio totalmente de c\u00f3digo aberto.",
        "* ``Alibaba`` lan\u00e7ou [Qwen2-Audio](https://huggingface.co/Qwen/Qwen2-Audio-7B-Instruct), um LLM de c\u00f3digo aberto que entende \u00e1udio de forma nativa.",
        "* ``Fixie.ai`` lan\u00e7ou [Ultravox](https://huggingface.co/fixie-ai/ultravox-v0_5-llama-3_3-70b), outro LLM de c\u00f3digo aberto que tamb\u00e9m entende \u00e1udio de forma nativa.",
        "* ``ElevenLabs`` arrecadou 180 milh\u00f5es de d\u00f3lares na sua S\u00e9rie C."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Apesar desta explos\u00e3o em modelos e financiamento, ainda \u00e9 dif\u00edcil construir aplica\u00e7\u00f5es de IA em tempo real que transmitam \u00e1udio e v\u00eddeo, especialmente em Python.",
        "\n",
        "* Os engenheiros de ML podem n\u00e3o ter experi\u00eancia com as tecnologias necess\u00e1rias para construir aplica\u00e7\u00f5es em tempo real, como ``WebRTC``.",
        "* Mesmo ferramentas de assist\u00eancia de c\u00f3digo como ``Cursor`` e ``Copilot`` t\u00eam dificuldades em escrever c\u00f3digo Python que suporte aplica\u00e7\u00f5es de \u00e1udio/v\u00eddeo em tempo real.",
        "\n",
        "Por isso \u00e9 empolgante o an\u00fancio de `FastRTC`, a biblioteca de comunica\u00e7\u00e3o em tempo real para Python. A biblioteca foi projetada para facilitar a constru\u00e7\u00e3o de aplica\u00e7\u00f5es de IA de \u00e1udio e v\u00eddeo em tempo real totalmente em Python!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Principais caracter\u00edsticas de FastRTC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* \ud83d\udde3\ufe0f Detec\u00e7\u00e3o de voz autom\u00e1tica e gerenciamento de turnos integrado, para que voc\u00ea s\u00f3 precise se preocupar com a l\u00f3gica de resposta ao usu\u00e1rio.",
        "* \ud83d\udcbb UI autom\u00e1tica - UI do Gradio habilitada para WebRTC integrada para testes (ou implanta\u00e7\u00e3o em produ\u00e7\u00e3o!).",
        "* \ud83d\udcde Chamada telef\u00f4nica - Use ``fastphone()`` para obter um n\u00famero de telefone **gratuito** para ligar para o seu fluxo de \u00e1udio (\u00e9 necess\u00e1rio um token HF).",
        "* \u26a1\ufe0f Suporte para ``WebRTC`` e ``Websocket``.",
        "* \ud83d\udcaa Personaliz\u00e1vel - Voc\u00ea pode montar o stream em qualquer aplica\u00e7\u00e3o ``FastAPI`` para servir uma UI personalizada e implantar al\u00e9m do ``Gradio``.",
        "* \ud83e\uddf0 Muitas utilidades para ``text-to-speech``, ``speech-to-text``, ``detec\u00e7\u00e3o de parada`` para te ajudar a come\u00e7ar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Instala\u00e7\u00e3o"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para poder usar `FastRTC`, primeiro voc\u00ea precisa instalar a biblioteca:",
        "\n",
        "``` bash\n",
        "pip install fastrtc",
        "```\n",
        "\n",
        "Mas se quisermos instalar as funcionalidades de detec\u00e7\u00e3o de pausa, speech-to-text e text-to-speech, precisamos instalar algumas depend\u00eancias adicionais:",
        "\n",
        "``` bash\n",
        "pip install \"fastrtc[vad, stt, tts]\"",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Primeiros passos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Come\u00e7aremos construindo o `ol\u00e1 mundo` do \u00e1udio em tempo real: fazer eco do que o usu\u00e1rio diz. Em `FastRTC`, isso \u00e9 t\u00e3o simples quanto:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7872\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7872/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:     127.0.0.1:58223 - \"GET / HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58223 - \"GET /assets/index-C7PS0jJm.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58225 - \"GET /assets/index-Bo0Yq5bb.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58223 - \"GET /assets/svelte/svelte.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58225 - \"GET /assets/Embed-FUIL71FR.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58223 - \"GET /assets/Index-wMEhc4G9.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58228 - \"GET /assets/StreamingBar-DOagx4HU.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58227 - \"GET /assets/index-B1gfMDT9.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58230 - \"GET /assets/IconButtonWrapper-EOzMzU45.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58229 - \"GET /assets/StreamingBar.svelte_svelte_type_style_lang-CDNxkBIr.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58225 - \"GET /assets/MarkdownCode-DPiWQnAx.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58223 - \"GET /assets/DownloadLink-CqD3Uu0l.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58227 - \"GET /assets/IconButtonWrapper.svelte_svelte_type_style_lang-BOpxTcdu.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58229 - \"GET /assets/prism-python-qapVsvY8.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58228 - \"GET /assets/Index-BJ_RfjVB.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58230 - \"GET /assets/MarkdownCode.svelte_svelte_type_style_lang-3tofWDHK.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58225 - \"GET /assets/IconButton-B-aAVSzy.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58229 - \"GET /assets/Clear-By3xiIwg.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58228 - \"GET /assets/context-TgWPFwN2.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58230 - \"GET /theme.css?v=63194d3741d384f9f85db890247b6c0ef9e7abac0f297f40a15c59fe4baba916 HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58228 - \"GET /assets/Button-BWSOH8Qq.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58225 - \"GET /assets/Image-CsmDAdIf.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58229 - \"GET /assets/Blocks-E57YC_S0.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58227 - \"GET /assets/Button-DTh9AgeE.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58223 - \"GET /assets/Image-B8dFOee4.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58230 - \"GET /assets/ImagePreview-DJhr8Mfv.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58223 - \"GET /assets/file-url-DgijyRSD.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58225 - \"GET /assets/Dropdown-CWxB-qJp.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58228 - \"GET /assets/Example-D7K5RtQ2.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58227 - \"GET /assets/Blocks-B5wxaDIo.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58229 - \"GET /assets/Dropdown-DjrBHETv.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58230 - \"GET /assets/Block-DZqtZLFP.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58228 - \"GET /assets/BlockTitle-BIcnzvtg.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58225 - \"GET /assets/index-CvpmwOJi.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58223 - \"GET /assets/MarkdownCode-DJM7o_VY.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58230 - \"GET /assets/Info-DcCn6tHi.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58227 - \"GET /assets/DropdownArrow-dYuMZY9s.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58229 - \"GET /assets/Toast-DdWZrg4w.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58230 - \"GET /assets/utils-BsGrhMNe.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58223 - \"GET /gradio_api/custom_component/91a0d0cc3e6164063c775a057aff53510cb8fc04c8b99d010e09ce4ba9beb99d/client/component/style.css HTTP/1.1\" 304 Not Modified\n",
            "INFO:     127.0.0.1:58230 - \"GET /assets/Index-ChJkSByh.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58227 - \"GET /assets/Index-CfowPFmo.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58228 - \"GET /assets/Index-CptIZeFZ.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58229 - \"GET /assets/Index-Csm0OGa9.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58225 - \"GET /assets/Index-Cgj6KPvj.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58223 - \"GET /assets/Code-DGNrTu_I.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58225 - \"GET /gradio_api/custom_component/91a0d0cc3e6164063c775a057aff53510cb8fc04c8b99d010e09ce4ba9beb99d/client/component/index.js HTTP/1.1\" 304 Not Modified\n",
            "INFO:     127.0.0.1:58228 - \"GET /assets/Index-HXWviefR.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58229 - \"GET /assets/Index-WEzAIkMk.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58230 - \"GET /assets/BlockLabel-DqHge3FF.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58227 - \"GET /assets/Index-CRGGsrTx.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58241 - \"GET / HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58241 - \"GET /theme.css?v=63194d3741d384f9f85db890247b6c0ef9e7abac0f297f40a15c59fe4baba916 HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58241 - \"GET /gradio_api/custom_component/91a0d0cc3e6164063c775a057aff53510cb8fc04c8b99d010e09ce4ba9beb99d/client/component/style.css HTTP/1.1\" 304 Not Modified\n",
            "INFO:     127.0.0.1:58244 - \"GET /gradio_api/custom_component/91a0d0cc3e6164063c775a057aff53510cb8fc04c8b99d010e09ce4ba9beb99d/client/component/index.js HTTP/1.1\" 304 Not Modified\n",
            "INFO:     127.0.0.1:58260 - \"GET /static/fonts/ui-sans-serif/ui-sans-serif-Bold.woff2 HTTP/1.1\" 404 Not Found\n",
            "INFO:     127.0.0.1:58260 - \"GET /static/fonts/system-ui/system-ui-Bold.woff2 HTTP/1.1\" 404 Not Found\n"
          ]
        }
      ],
      "source": [
        "from fastrtc import Stream, ReplyOnPause\n",
        "import numpy as np\n",
        "\n",
        "def echo(audio: tuple[int, np.ndarray]) -> tuple[int, np.ndarray]:\n",
        "    yield audio\n",
        "\n",
        "stream = Stream(ReplyOnPause(echo), modality=\"audio\", mode=\"send-receive\")\n",
        "stream.ui.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Quando vamos ao link que o Gradio sugere, primeiro temos que dar permiss\u00f5es ao navegador para acessar o microfone. A seguir, aparecer\u00e1 isto",
        "\n",
        "![fastrct - hello world - init](https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/fastRTC%20-%20hello%20world%20-%20init.webp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se clicarmos na guia \u00e0 direita da palavra `Record`, podemos selecionar o microfone que queremos usar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ao clicar no bot\u00e3o `Record`, tudo o que dissermos ser\u00e1 repetido pelo aplicativo. Isso significa que ele captura o \u00e1udio, detecta quando paramos de falar e o repete."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos a desmembr\u00e1-lo:",
        "\n",
        "* `ReplyOnPause` ir\u00e1 tratar a detec\u00e7\u00e3o de voz e a passagem de turnos para voc\u00ea. Voc\u00ea s\u00f3 precisa se preocupar com a l\u00f3gica para responder ao usu\u00e1rio. \u00c9 necess\u00e1rio passar a fun\u00e7\u00e3o que ser\u00e1 respons\u00e1vel por gerenciar o \u00e1udio de entrada. No nosso caso, \u00e9 a fun\u00e7\u00e3o `echo`, que captura o \u00e1udio de entrada e o retorna em stream usando `yield`, que muitas pessoas n\u00e3o conhecem, mas \u00e9 um gerador, ou seja, \u00e9 um m\u00e9todo do Python para criar iteradores. Se quiser saber mais sobre `yield`, pode ler meu post sobre [Python](https://www.maximofn.com/python#6.5.-Generadores). Qualquer gerador que retorne uma tupla de \u00e1udio (representada como `(sample_rate, audio_data)`) funcionar\u00e1.",
        "* A classe `Stream` construir\u00e1 uma UI do Gradio para que voc\u00ea possa testar rapidamente seu stream. Uma vez que voc\u00ea tenha terminado de prototipar, voc\u00ea pode implantar seu Stream como um aplicativo FastAPI pronto para produ\u00e7\u00e3o em uma \u00fanica linha de c\u00f3digo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Aqui podemos ver um exemplo dos criadores de `FastRTC`",
        "\n",
        "<video src=\"https://github.com/user-attachments/assets/fcf2d30e-3e98-47c9-8dc3-23340784c441\" controls></video>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Subindo de n\u00edvel: Bate-papo de voz com LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "O pr\u00f3ximo n\u00edvel \u00e9 usar um LLM para responder ao usu\u00e1rio. `FastRTC` vem com capacidades de ``speech-to-text`` e ``text-to-speech`` incorporadas, portanto trabalhar com LLMs \u00e9 realmente f\u00e1cil. Vamos alterar nossa fun\u00e7\u00e3o `echo` accordingly:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded as API: https://maximofn-smollm2-localmodel.hf.space \u2714\n",
            "* Running on local URL:  http://127.0.0.1:7871\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7871/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:     127.0.0.1:58224 - \"GET / HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58224 - \"GET /assets/index-Bo0Yq5bb.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58226 - \"GET /assets/index-C7PS0jJm.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58226 - \"GET /assets/svelte/svelte.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58226 - \"GET /assets/Index-wMEhc4G9.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58232 - \"GET /assets/StreamingBar-DOagx4HU.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58234 - \"GET /assets/IconButtonWrapper-EOzMzU45.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58224 - \"GET /assets/Embed-FUIL71FR.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58233 - \"GET /assets/StreamingBar.svelte_svelte_type_style_lang-CDNxkBIr.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58231 - \"GET /assets/index-B1gfMDT9.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58231 - \"GET /assets/MarkdownCode-DPiWQnAx.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58224 - \"GET /assets/MarkdownCode.svelte_svelte_type_style_lang-3tofWDHK.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58233 - \"GET /assets/Index-BJ_RfjVB.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58232 - \"GET /assets/DownloadLink-CqD3Uu0l.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58234 - \"GET /assets/IconButtonWrapper.svelte_svelte_type_style_lang-BOpxTcdu.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58226 - \"GET /assets/prism-python-qapVsvY8.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58231 - \"GET /assets/IconButton-B-aAVSzy.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58233 - \"GET /assets/Clear-By3xiIwg.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58234 - \"GET /assets/context-TgWPFwN2.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58224 - \"GET /theme.css?v=63194d3741d384f9f85db890247b6c0ef9e7abac0f297f40a15c59fe4baba916 HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58234 - \"GET /assets/Blocks-E57YC_S0.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58231 - \"GET /assets/Image-B8dFOee4.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58226 - \"GET /assets/ImagePreview-DJhr8Mfv.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58233 - \"GET /assets/Button-BWSOH8Qq.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58232 - \"GET /assets/Button-DTh9AgeE.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58224 - \"GET /assets/Dropdown-CWxB-qJp.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58232 - \"GET /assets/Image-CsmDAdIf.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58226 - \"GET /assets/Blocks-B5wxaDIo.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58233 - \"GET /assets/Example-D7K5RtQ2.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58234 - \"GET /assets/Block-DZqtZLFP.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58231 - \"GET /assets/file-url-DgijyRSD.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58224 - \"GET /assets/Info-DcCn6tHi.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58232 - \"GET /assets/MarkdownCode-DJM7o_VY.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58234 - \"GET /assets/Dropdown-DjrBHETv.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58233 - \"GET /assets/index-CvpmwOJi.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58226 - \"GET /assets/BlockTitle-BIcnzvtg.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58231 - \"GET /assets/DropdownArrow-dYuMZY9s.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58224 - \"GET /assets/Toast-DdWZrg4w.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58234 - \"GET /assets/utils-BsGrhMNe.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58232 - \"GET /assets/Index-CfowPFmo.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58234 - \"GET /assets/Index-ChJkSByh.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58224 - \"GET /assets/Code-DGNrTu_I.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58226 - \"GET /assets/Index-Csm0OGa9.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58233 - \"GET /assets/Index-HXWviefR.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58231 - \"GET /assets/BlockLabel-DqHge3FF.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58224 - \"GET /gradio_api/custom_component/91a0d0cc3e6164063c775a057aff53510cb8fc04c8b99d010e09ce4ba9beb99d/client/component/style.css HTTP/1.1\" 304 Not Modified\n",
            "INFO:     127.0.0.1:58231 - \"GET /assets/Index-Cgj6KPvj.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58233 - \"GET /gradio_api/custom_component/91a0d0cc3e6164063c775a057aff53510cb8fc04c8b99d010e09ce4ba9beb99d/client/component/index.js HTTP/1.1\" 304 Not Modified\n",
            "INFO:     127.0.0.1:58226 - \"GET /assets/Index-CptIZeFZ.css HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58232 - \"GET /assets/Index-CRGGsrTx.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58234 - \"GET /assets/Index-WEzAIkMk.js HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58242 - \"GET / HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58242 - \"GET /theme.css?v=63194d3741d384f9f85db890247b6c0ef9e7abac0f297f40a15c59fe4baba916 HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58242 - \"GET /gradio_api/custom_component/91a0d0cc3e6164063c775a057aff53510cb8fc04c8b99d010e09ce4ba9beb99d/client/component/style.css HTTP/1.1\" 304 Not Modified\n",
            "INFO:     127.0.0.1:58243 - \"GET /gradio_api/custom_component/91a0d0cc3e6164063c775a057aff53510cb8fc04c8b99d010e09ce4ba9beb99d/client/component/index.js HTTP/1.1\" 304 Not Modified\n",
            "INFO:     127.0.0.1:58250 - \"GET /static/fonts/ui-sans-serif/ui-sans-serif-Bold.woff2 HTTP/1.1\" 404 Not Found\n",
            "INFO:     127.0.0.1:58250 - \"GET /static/fonts/system-ui/system-ui-Bold.woff2 HTTP/1.1\" 404 Not Found\n"
          ]
        }
      ],
      "source": [
        "from fastrtc import ReplyOnPause, Stream, get_stt_model, get_tts_model\n",
        "from gradio_client import Client\n",
        "\n",
        "client = Client(\"Maximofn/SmolLM2_localModel\")\n",
        "stt_model = get_stt_model()\n",
        "tts_model = get_tts_model()\n",
        "\n",
        "def echo(audio):\n",
        "    prompt = stt_model.stt(audio)\n",
        "    response = client.predict(\n",
        "            message=prompt,\n",
        "            system_message=\"You are a friendly Chatbot. Always reply in the language in which the user is writing to you.\",\n",
        "            max_tokens=512,\n",
        "            temperature=0.7,\n",
        "            top_p=0.95,\n",
        "            api_name=\"/chat\"\n",
        "    )\n",
        "    prompt = response\n",
        "    for audio_chunk in tts_model.stream_tts_sync(prompt):\n",
        "        yield audio_chunk\n",
        "\n",
        "stream = Stream(ReplyOnPause(echo), modality=\"audio\", mode=\"send-receive\")\n",
        "stream.ui.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como modelo de ``speech-to-text`` use ``Moonshine``, que supostamente s\u00f3 suporta ingl\u00eas, mas eu o testei em espanhol e ele entende bem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como modelo de linguagem vamos usar o modelo que desployei em um backend no Hugging Face e que escrevi no post [Desplegar backend com LLM em HuggingFace](https://www.maximofn.com/deploy-backend-with-llm-in-huggingface). Utiliza o LLM `HuggingFaceTB/SmolLM2-1.7B-Instruct` que \u00e9 um modelo pequeno, j\u00e1 que est\u00e1 rodando em um backend com CPU, mas que funciona bastante bem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como modelo de ``text-to-speech`` use ``Kokoro`` que sim tem op\u00e7\u00f5es de falar em outros idiomas, mas que por enquanto na biblioteca `FastRTC` ainda n\u00e3o est\u00e1 implementado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se nos interessa muito usar modelos de `speech-to-speech` e `text-to-speech` em outros idiomas, poder\u00edamos implement\u00e1-los n\u00f3s mesmos, pois o maior potencial do `FastRTC` est\u00e1 na camada de comunica\u00e7\u00e3o em tempo real, mas n\u00e3o vou me aprofundar nisso agora."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Agora, se testarmos o c\u00f3digo que acabamos de escrever, podemos ter um chatbot, por voz em tempo real."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chamada telef\u00f4nica",
        "\n",
        "Se voc\u00ea chamar `stream.fastphone()` em vez de `stream.ui.launch()`, obter\u00e1 um n\u00famero de telefone gratuito para ligar para o seu stream. Tenha em mente que \u00e9 necess\u00e1rio um token do Hugging Face.",
        "\n",
        "Geramos um script, pois nem sempre funciona em um Jupyter Notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile fastrtc_phone_demo.py\n",
        "\n",
        "from fastrtc import ReplyOnPause, Stream, get_stt_model, get_tts_model\n",
        "import gradio\n",
        "from gradio_client import Client\n",
        "import os\n",
        "from gradio.networking import setup_tunnel as original_setup_tunnel\n",
        "import socket\n",
        "\n",
        "# Monkey patch setup_tunnel para que acepte el par\u00e1metro adicional\n",
        "def patched_setup_tunnel(host, port, share_token, share_server_address, share_server_tls_certificate=None):\n",
        "    return original_setup_tunnel(host, port, share_token, share_server_address, share_server_tls_certificate)\n",
        "\n",
        "# Replace the original function with our patched version\n",
        "gradio.networking.setup_tunnel = patched_setup_tunnel\n",
        "\n",
        "# Get the token from the environment variable\n",
        "HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN = os.getenv(\"HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN\")\n",
        "\n",
        "# Initialize the LLM client\n",
        "llm_client = Client(\"Maximofn/SmolLM2_localModel\")\n",
        "\n",
        "# Initialize the STT and TTS models\n",
        "stt_model = get_stt_model()\n",
        "tts_model = get_tts_model()\n",
        "\n",
        "# Define the echo function\n",
        "def echo(audio):\n",
        "    # Convert the audio to text\n",
        "    prompt = stt_model.stt(audio)\n",
        "\n",
        "    # Generate the response\n",
        "    response = llm_client.predict(\n",
        "            message=prompt,\n",
        "            system_message=\"You are a friendly Chatbot. Always reply in the language in which the user is writing to you.\",\n",
        "            max_tokens=512,\n",
        "            temperature=0.7,\n",
        "            top_p=0.95,\n",
        "            api_name=\"/chat\"\n",
        "    )\n",
        "    \n",
        "    # Convert the response to audio\n",
        "    prompt = response\n",
        "\n",
        "    # Stream the audio\n",
        "    for audio_chunk in tts_model.stream_tts_sync(prompt):\n",
        "        yield audio_chunk\n",
        "\n",
        "def find_free_port(start_port=8000, max_port=9000):\n",
        "    \"\"\"Find the first free port starting from start_port.\"\"\"\n",
        "    print(f\"Searching for a free port starting from {start_port}...\")\n",
        "    for port in range(start_port, max_port):\n",
        "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:\n",
        "            result = sock.connect_ex(('127.0.0.1', port))\n",
        "            if result != 0:  # If result != 0, the port is free\n",
        "                print(f\"Free port found: {port}\")\n",
        "                return port\n",
        "    raise RuntimeError(f\"No free port found between {start_port} and {max_port}\")\n",
        "    \n",
        "free_port = find_free_port()    # Search for a free port\n",
        "\n",
        "stream = Stream(ReplyOnPause(echo), modality=\"audio\", mode=\"send-receive\")\n",
        "stream.fastphone(token=HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN, port=free_port)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Explicamos o c\u00f3digo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A parte",
        "\n",
        "``` pyhon\n",
        "# Monkey patch setup_tunnel para aceitar o par\u00e2metro adicional",
        "def patched_setup_tunnel(host, port, share_token, share_server_address, share_server_tls_certificate=None):",
        "return original_setup_tunnel(host, port, share_token, share_server_address, share_server_tls_certificate)",
        "\n",
        "# Substitua a fun\u00e7\u00e3o original pela nossa vers\u00e3o patchada",
        "gradio.networking.setup_tunnel = patched_setup_tunnel",
        "```\n",
        "\n",
        "\u00c9 necess\u00e1rio porque `FastRTC` foi escrito para uma vers\u00e3o antiga do `gradio` que n\u00e3o suporta o par\u00e2metro `share_server_address` no m\u00e9todo `setup_tunnel`. Ent\u00e3o, n\u00f3s o patcheamos para aceitar o par\u00e2metro adicional."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como \u00e9 necess\u00e1rio um token do Hugging Face, obtemos o token da vari\u00e1vel de ambiente `HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN`.",
        "\n",
        "``` python\n",
        "# Obtenha o token da vari\u00e1vel de ambiente",
        "HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN = os.getenv(\"HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN\")",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A seguir s\u00e3o criados os modelos de linguagem, de `speech-to-text` e de `text-to-speech`, e criamos a fun\u00e7\u00e3o `echo` que ser\u00e1 respons\u00e1vel por gerenciar o \u00e1udio de entrada e sa\u00edda.",
        "\n",
        "``` python\n",
        "# Inicialize o cliente LLM",
        "llm_client = Client(\"Maximofn/SmolLM2_localModel\")",
        "\n",
        "# Inicialize os modelos STT e TTS",
        "stt_model = get_stt_model()",
        "tts_model = get_tts_model()",
        "\n",
        "# Defina a fun\u00e7\u00e3o echo",
        "def eco(\u00e1udio):",
        "# Converter o \u00e1udio em texto",
        "prompt = stt_model.stt(audio)",
        "\n",
        "# Gerar a resposta",
        "resposta = llm_client.predict(",
        "message=prompt,",
        "Entendido. Estou pronto para traduzir o texto markdown para o portugu\u00eas conforme solicitado. Por favor, forne\u00e7a o texto que deseja traduzir.",
        "max_tokens=512,",
        "temperature=0.7,",
        "top_p=0,95,",
        "api_name=\"/chat\"",
        ")",
        "    \n",
        "# Converter a resposta em \u00e1udio",
        "prompt = resposta",
        "\n",
        "# Transmita o \u00e1udio",
        "for audio_chunk in tts_model.stream_tts_sync(prompt):",
        "yield audio_chunk",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como antes usamos a porta `8000`, caso voc\u00eas digam que ela est\u00e1 ocupada, criamos uma fun\u00e7\u00e3o para encontrar uma porta livre e encontramos uma.",
        "\n",
        "``` python\n",
        "def find_free_port(start_port=8000, max_port=9000):",
        "\"\"\"Encontre a primeira porta livre a partir de start_port.\"\"\"",
        "print(f\"Procurando uma porta livre a partir de {start_port}...\")",
        "for port in range(start_port, max_port):",
        "com socket.socket(socket.AF_INET, socket.SOCK_STREAM) como sock:",
        "result = sock.connect_ex(('127.0.0.1', port))",
        "if result != 0:  # Se result != 0, a porta est\u00e1 livre",
        "print(f\"Porta livre encontrada: {port}\")",
        "retornar portugu\u00eas",
        "raise RuntimeError(f\"Nenhuma porta livre encontrada entre {start_port} e {max_port}\")",
        "    \n",
        "porta_livre = encontrar_porta_livre()    # Procurar uma porta livre",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "O fluxo \u00e9 criado e agora `stream.fastphone()` \u00e9 usado para obter um n\u00famero de telefone gratuito para ligar ao seu fluxo, em vez de `stream.ui.launch()`, que usamos anteriormente para criar a interface gr\u00e1fica.",
        "\n",
        "``` python\n",
        "stream = Stream(ReplyOnPause(echo), modality=\"audio\", mode=\"send-receive\")",
        "stream.fastphone(token=HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN, port=free_port)",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se o executarmos, veremos algo assim:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded as API: https://maximofn-smollm2-localmodel.hf.space \u2714\n",
            "\u001b[32mINFO\u001b[0m:\t  Warming up STT model.\n",
            "\u001b[32mINFO\u001b[0m:\t  STT model warmed up.\n",
            "\u001b[32mINFO\u001b[0m:\t  Warming up VAD model.\n",
            "\u001b[32mINFO\u001b[0m:\t  VAD model warmed up.\n",
            "Searching for a free port starting from 8000...\n",
            "Free port found: 8004\n",
            "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m24029\u001b[0m]\n",
            "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
            "\u001b[32mINFO\u001b[0m:\t  Visit \u001b[36mhttps://fastrtc.org/userguide/api/\u001b[0m for WebRTC or Websocket API docs.\n",
            "\u001b[32mINFO\u001b[0m:     Application startup complete.\n",
            "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://127.0.0.1:8004\u001b[0m (Press CTRL+C to quit)\n",
            "\u001b[32mINFO\u001b[0m:\t  Your FastPhone is now live! Call \u001b[36m+1 877-713-4471\u001b[0m and use code \u001b[36m994514\u001b[0m to connect to your stream.\n",
            "\u001b[32mINFO\u001b[0m:\t  You have \u001b[36m30:00\u001b[0m minutes remaining in your quota (Resetting on \u001b[36m2025-04-07\u001b[0m)\n",
            "\u001b[32mINFO\u001b[0m:\t  Visit \u001b[36mhttps://fastrtc.org/userguide/audio/#telephone-integration\u001b[0m for information on making your handler compatible with phone usage.\n"
          ]
        }
      ],
      "source": [
        "!python fastrtc_phone_demo.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vemos que aparece",
        "\n",
        "``` bash\n",
        "INFO: Seu FastPhone est\u00e1 agora ativo! Ligue para +1 877-713-4471 e use o c\u00f3digo 994514 para se conectar ao seu stream.",
        "INFO: Voc\u00ea tem 30:00 minutos restantes em sua cota (Redefinindo em 2025-04-07)",
        "```\n",
        "\n",
        "Isto \u00e9, se ligarmos para o n\u00famero `+1 877-713-4471` e usarmos o c\u00f3digo `994514`, seremos conectados ao nosso stream."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se formos at\u00e9 [Telephone Integration](https://fastrtc.org/userguide/audio/#telephone-integration) da documenta\u00e7\u00e3o de `FastRTC`, veremos que usa [twilio](https://www.twilio.com/) para fazer a chamada. Tem op\u00e7\u00e3o para configurar um n\u00famero local nos Estados Unidos, Dublin, Frankfurt, T\u00f3quio, Singapura, Sydney e S\u00e3o Paulo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tente testeado fazer a chamada da Espanha (o que vai me custar bastante) e funciona, mas \u00e9 lento. Liguei, inseri o c\u00f3digo e fiquei esperando para ser conectado com o agente, mas como estava demorando muito, desliguei."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "fastrtc",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "maximofn": {
      "date": "2025-03-08",
      "description_en": "If you have problems making a real-time AI application, FastRTC can help you. In this post I explain how to use it.",
      "description_es": "Si tienes problemas para hacer una aplicaci\u00f3n de IA en tiempo real, FastRTC es una biblioteca que te puede ayudar. En este post te explico c\u00f3mo usarla.",
      "description_pt": "Se voc\u00ea tem problemas para fazer uma aplica\u00e7\u00e3o de IA em tempo real, o FastRTC pode te ajudar. Neste post, explico como us\u00e1-lo.",
      "end_url": "fastrtc",
      "image": "https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/fastrtc-thumbnail.webp",
      "image_hover_path": "https://pub-fb664c455eca46a2ba762a065ac900f7.r2.dev/fastrtc-thumbnail.webp",
      "keywords_en": "fastrtc, real-time, ai, application, phone",
      "keywords_es": "fastrtc, real-time, ai, aplicaci\u00f3n, tel\u00e9fono",
      "keywords_pt": "fastrtc, real-time, ai, aplica\u00e7\u00e3o, telefone",
      "title_en": "Make a real-time AI application with FastRTC",
      "title_es": "Hacer una aplicaci\u00f3n de IA en tiempo real con FastRTC",
      "title_pt": "Fazer uma aplica\u00e7\u00e3o de IA em tempo real com FastRTC"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}