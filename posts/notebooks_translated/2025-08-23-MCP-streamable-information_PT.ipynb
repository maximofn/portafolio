{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51775080",
   "metadata": {},
   "source": [
    "# Streaming de informa√ß√£o no MCP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973534fb",
   "metadata": {},
   "source": [
    "Quando usamos o MCP, pode ser que a tarefa que estamos executando seja longa e queiramos que o cliente possa ver o progresso da tarefa. Embora no post sobre [MCP](https://www.maximofn.com/pt-br/mcp) tenhamos visto uma maneira de fazer isso usando `Context`, como o protocolo MCP evoluiu, agora podemos us√°-lo de uma maneira melhor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f8648c",
   "metadata": {},
   "source": [
    "## Servidor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6683f3eb",
   "metadata": {},
   "source": [
    "No post do [MCP](https://www.maximofn.com/pt-br/mcp), vimos que pod√≠amos criar um servidor MCP usando"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a967eb2",
   "metadata": {},
   "source": [
    "Criar um objeto mcp da classe FastMCP\n",
    "\n",
    "``` python\n",
    "from fastmcp import FastMCP\n",
    "\n",
    "# Create FastMCP server\n",
    "mcp = FastMCP(\n",
    "    name=\"MCP server name\",\n",
    "    instructions=\"MCP server instructions\",\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18a931d",
   "metadata": {},
   "source": [
    "Criar tools adicionando decoradores √†s fun√ß√µes\n",
    "\n",
    "``` python\n",
    "@mcp.tool\n",
    "def tool_name(param1: str, param2: int) -> str:\n",
    "    return \"result\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60906a48",
   "metadata": {},
   "source": [
    "E executar o servidor usando o m√©todo `run`. Al√©m disso, poder√≠amos definir http como camada de transporte.\n",
    "\n",
    "``` python\n",
    "mcp.run(\n",
    "    transport=\"http\",\n",
    "    host=\"0.0.0.0\",\n",
    "    port=8000\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0e4189",
   "metadata": {},
   "source": [
    "Agora importamos a fun√ß√£o `create_streamable_http_app` do pacote `fastmcp.server.http` e a usamos para criar um aplicativo HTTP que suporta streaming.\n",
    "\n",
    "```python\n",
    "from fastmcp.server.http import create_streamable_http_app\n",
    "\n",
    "app = create_streamable_http_app(\n",
    "    server=mcp,\n",
    "    streamable_http_path=\"/mcp/\",\n",
    "    stateless_http=False,  # Keep session state\n",
    "    debug=True\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286073e4",
   "metadata": {},
   "source": [
    "Criamos um servidor com `uvicorn`\n",
    "\n",
    "``` python\n",
    "import uvicorn\n",
    "\n",
    "# Configure uvicorn\n",
    "config = uvicorn.Config(\n",
    "    app=app,\n",
    "    host=host,\n",
    "    port=port,\n",
    "    log_level=\"info\",\n",
    "    access_log=False\n",
    ")\n",
    "\n",
    "# Run server\n",
    "server = uvicorn.Server(config)\n",
    "await server.serve()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bb8d61",
   "metadata": {},
   "source": [
    "E o executamos de forma ass√≠ncrona.\n",
    "\n",
    "``` python\n",
    "import asyncio\n",
    "\n",
    "asyncio.run(run_streaming_server())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0c5e1c",
   "metadata": {},
   "source": [
    "### Implementa√ß√£o do servidor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df20cbb1",
   "metadata": {},
   "source": [
    "Agora que explicamos como criar o servidor, vamos criar um."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f43571",
   "metadata": {},
   "source": [
    "#### Criar ambiente virtual para o servidor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7c2332",
   "metadata": {},
   "source": [
    "Primeiro criamos a pasta onde vamos desenvolv√™-lo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d87940f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir MCP_streamable_server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1170e5",
   "metadata": {},
   "source": [
    "Criamos o ambiente com `uv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afe25a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized project `\u001b[36mmcp-streamable-server\u001b[39m` at `\u001b[36m/Users/macm1/Documents/web/portafolio/posts/MCP_streamable_server\u001b[39m`\n"
     ]
    }
   ],
   "source": [
    "!cd MCP_streamable_server && uv init ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46d61b2",
   "metadata": {},
   "source": [
    "Iniciamos o ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11a7d891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPython \u001b[36m3.12.8\u001b[39m\n",
      "Creating virtual environment at: \u001b[36m.venv\u001b[39m\n",
      "Activate with: \u001b[32msource .venv/bin/activate\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "!cd MCP_streamable_server && uv venv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a6218d",
   "metadata": {},
   "source": [
    "Instalamos as bibliotecas necess√°rias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08d759fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2mResolved \u001b[1m64 packages\u001b[0m \u001b[2min 673ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)                                                   \u001b[37m‚†ã\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/0)                                                   \n",
      "\u001b[2K\u001b[1A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m     0 B/87.93 KiB           \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m     0 B/87.93 KiB           \u001b[1A\n",
      "\u001b[2mrequests            \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/63.22 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m     0 B/87.93 KiB           \u001b[2A\n",
      "\u001b[2mrequests            \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/63.22 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m 16.00 KiB/87.93 KiB         \u001b[2A\n",
      "\u001b[2mrequests            \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 14.88 KiB/63.22 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m 16.00 KiB/87.93 KiB         \u001b[2A\n",
      "\u001b[2mrequests            \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 14.88 KiB/63.22 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m 32.00 KiB/87.93 KiB         \u001b[2A\n",
      "\u001b[2mrequests            \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 14.88 KiB/63.22 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)m-------------\u001b[0m\u001b[0m 48.00 KiB/87.93 KiB         \u001b[2A\n",
      "\u001b[2mrequests            \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 14.88 KiB/63.22 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--\u001b[2m--------\u001b[0m\u001b[0m 64.00 KiB/87.93 KiB         \u001b[2A\n",
      "\u001b[2mrequests            \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 14.88 KiB/63.22 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------\u001b[2m--\u001b[0m\u001b[0m 80.00 KiB/87.93 KiB         \u001b[2A\n",
      "\u001b[2mrequests            \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 30.88 KiB/63.22 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------\u001b[2m--\u001b[0m\u001b[0m 80.00 KiB/87.93 KiB         \u001b[2A\n",
      "\u001b[2mrequests            \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 30.88 KiB/63.22 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)----------\u001b[2m\u001b[0m\u001b[0m 87.93 KiB/87.93 KiB         \u001b[2A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m 30.88 KiB/63.22 KiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)---\u001b[2m-------\u001b[0m\u001b[0m 46.88 KiB/63.22 KiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)----------\u001b[2m\u001b[0m\u001b[0m 62.88 KiB/63.22 KiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)----------\u001b[2m\u001b[0m\u001b[0m 62.88 KiB/63.22 KiB         \u001b[1A\n",
      "\u001b[2mrequests            \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 62.88 KiB/63.22 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m     0 B/157.71 KiB          \u001b[2A\n",
      "\u001b[2mrequests            \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 63.22 KiB/63.22 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m     0 B/157.71 KiB          \u001b[2A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m     0 B/157.71 KiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m 16.00 KiB/157.71 KiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m 16.00 KiB/157.71 KiB        \u001b[1A\n",
      "\u001b[2mlazy-object-proxy   \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/26.12 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m 16.00 KiB/157.71 KiB        \u001b[2A\n",
      "\u001b[2mlazy-object-proxy   \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 16.00 KiB/26.12 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m 16.00 KiB/157.71 KiB        \u001b[2A\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m4 packages\u001b[0m \u001b[2min 180ms\u001b[0m\u001b[0m                                                 \u001b[1A\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m61 packages\u001b[0m \u001b[2min 140ms\u001b[0m\u001b[0mtor==0.6.3                    \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mannotated-types\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1manyio\u001b[0m\u001b[2m==4.10.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mattrs\u001b[0m\u001b[2m==25.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mauthlib\u001b[0m\u001b[2m==1.6.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcertifi\u001b[0m\u001b[2m==2025.8.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcffi\u001b[0m\u001b[2m==1.17.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcharset-normalizer\u001b[0m\u001b[2m==3.4.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mclick\u001b[0m\u001b[2m==8.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcryptography\u001b[0m\u001b[2m==45.0.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcyclopts\u001b[0m\u001b[2m==3.22.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdnspython\u001b[0m\u001b[2m==2.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdocstring-parser\u001b[0m\u001b[2m==0.17.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdocutils\u001b[0m\u001b[2m==0.22\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1memail-validator\u001b[0m\u001b[2m==2.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mexceptiongroup\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfastmcp\u001b[0m\u001b[2m==2.11.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mh11\u001b[0m\u001b[2m==0.16.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttpcore\u001b[0m\u001b[2m==1.0.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttpx\u001b[0m\u001b[2m==0.28.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttpx-sse\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1midna\u001b[0m\u001b[2m==3.10\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1misodate\u001b[0m\u001b[2m==0.7.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjsonschema\u001b[0m\u001b[2m==4.25.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjsonschema-path\u001b[0m\u001b[2m==0.3.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjsonschema-specifications\u001b[0m\u001b[2m==2025.4.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlazy-object-proxy\u001b[0m\u001b[2m==1.12.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarkdown-it-py\u001b[0m\u001b[2m==4.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==3.0.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmcp\u001b[0m\u001b[2m==1.13.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmdurl\u001b[0m\u001b[2m==0.1.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmore-itertools\u001b[0m\u001b[2m==10.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopenapi-core\u001b[0m\u001b[2m==0.19.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopenapi-pydantic\u001b[0m\u001b[2m==0.5.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopenapi-schema-validator\u001b[0m\u001b[2m==0.6.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopenapi-spec-validator\u001b[0m\u001b[2m==0.7.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mparse\u001b[0m\u001b[2m==1.20.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpathable\u001b[0m\u001b[2m==0.4.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpycparser\u001b[0m\u001b[2m==2.22\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic\u001b[0m\u001b[2m==2.11.7\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic-core\u001b[0m\u001b[2m==2.33.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic-settings\u001b[0m\u001b[2m==2.10.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpygments\u001b[0m\u001b[2m==2.19.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyperclip\u001b[0m\u001b[2m==1.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-dotenv\u001b[0m\u001b[2m==1.1.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-multipart\u001b[0m\u001b[2m==0.0.20\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyyaml\u001b[0m\u001b[2m==6.0.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mreferencing\u001b[0m\u001b[2m==0.36.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrequests\u001b[0m\u001b[2m==2.32.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrfc3339-validator\u001b[0m\u001b[2m==0.1.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrich\u001b[0m\u001b[2m==14.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrich-rst\u001b[0m\u001b[2m==1.3.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrpds-py\u001b[0m\u001b[2m==0.27.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msix\u001b[0m\u001b[2m==1.17.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msniffio\u001b[0m\u001b[2m==1.3.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msse-starlette\u001b[0m\u001b[2m==3.0.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mstarlette\u001b[0m\u001b[2m==0.47.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyping-extensions\u001b[0m\u001b[2m==4.14.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyping-inspection\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.5.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1muvicorn\u001b[0m\u001b[2m==0.35.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwerkzeug\u001b[0m\u001b[2m==3.1.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd MCP_streamable_server && uv add fastmcp uvicorn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180c721d",
   "metadata": {},
   "source": [
    "#### C√≥digo do servidor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440f5fb1",
   "metadata": {},
   "source": [
    "Agora vamos criar o c√≥digo do servidor. Vamos criar um servidor com tudo o que falamos anteriormente e com quatro tools que simulam tarefas muito longas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "103360ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing MCP_streamable_server/server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile MCP_streamable_server/server.py\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "MCP server for streaming and partial results.\n",
    "Shows how to send real-time progress updates to the client.\n",
    "\"\"\"\n",
    "\n",
    "import asyncio\n",
    "import uvicorn\n",
    "from typing import Dict, List, Any\n",
    "from fastmcp import FastMCP, Context\n",
    "from fastmcp.server.http import create_streamable_http_app\n",
    "\n",
    "\n",
    "# Create MCP server instance\n",
    "mcp = FastMCP(\n",
    "    name=\"Streaming Server\",\n",
    "    instructions=\"Streaming Server with real-time progress updates\"\n",
    ")\n",
    "\n",
    "\n",
    "@mcp.tool\n",
    "async def long_running_task(\n",
    "    name: str = \"Task\", \n",
    "    steps: int = 10,\n",
    "    context: Context = None\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Long running task with real-time progress updates.\n",
    "    \n",
    "    Args:\n",
    "        name: Task name\n",
    "        steps: Number of steps to execute\n",
    "    \"\"\"\n",
    "    if context:\n",
    "        await context.info(f\"üöÄ Initializing {name} with {steps} steps...\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i in range(steps):\n",
    "        # Simulate work\n",
    "        await asyncio.sleep(1)\n",
    "        \n",
    "        # Create partial result\n",
    "        partial_result = f\"Step {i + 1}: Processed {name}\"\n",
    "        results.append(partial_result)\n",
    "        \n",
    "        # Report progress\n",
    "        if context:\n",
    "            await context.report_progress(\n",
    "                progress=i + 1,\n",
    "                total=steps,\n",
    "                message=f\"Step {i + 1}/{steps} - {partial_result}\"\n",
    "            )\n",
    "            \n",
    "            await context.debug(f\"‚úÖ {partial_result}\")\n",
    "    \n",
    "    if context:\n",
    "        await context.info(f\"üéâ {name} completed successfully!\")\n",
    "    \n",
    "    return {\n",
    "        \"task_name\": name,\n",
    "        \"steps_completed\": steps,\n",
    "        \"results\": results,\n",
    "        \"status\": \"completed\"\n",
    "    }\n",
    "\n",
    "\n",
    "@mcp.tool\n",
    "async def streaming_data_processor(\n",
    "    data_size: int = 100,\n",
    "    context: Context = None\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Processes data sending real-time progress updates.\n",
    "    \n",
    "    Args:\n",
    "        data_size: Number of data items to process\n",
    "    \"\"\"\n",
    "    if context:\n",
    "        await context.info(f\"üìä Procesando {data_size} elementos de datos...\")\n",
    "    \n",
    "    processed = []\n",
    "    batch_size = max(1, data_size // 10)  # Process in batches\n",
    "    \n",
    "    for i in range(0, data_size, batch_size):\n",
    "        batch_end = min(i + batch_size, data_size)\n",
    "        \n",
    "        # Simulate batch processing\n",
    "        await asyncio.sleep(0.5)\n",
    "        \n",
    "        # Process batch\n",
    "        batch_results = [f\"item_{j}\" for j in range(i, batch_end)]\n",
    "        processed.extend(batch_results)\n",
    "        \n",
    "        # Report progress\n",
    "        if context:\n",
    "            progress = len(processed)\n",
    "            await context.report_progress(\n",
    "                progress=progress,\n",
    "                total=data_size,\n",
    "                message=f\"Processed {progress}/{data_size} items\"\n",
    "            )\n",
    "            \n",
    "            await context.debug(f\"Batch processed: {i}-{batch_end-1}\")\n",
    "    \n",
    "    if context:\n",
    "        await context.info(f\"‚úÖ Processing completed: {len(processed)} items\")\n",
    "    \n",
    "    return {\n",
    "        \"total_processed\": len(processed),\n",
    "        \"processed_items\": processed[:10],  # Show first 10 items\n",
    "        \"status\": \"completed\"\n",
    "    }\n",
    "\n",
    "\n",
    "@mcp.tool\n",
    "async def file_upload_simulation(\n",
    "    file_count: int = 5,\n",
    "    context: Context = None\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Simulates file upload with progress updates.\n",
    "    \n",
    "    Args:\n",
    "        file_count: Number of files to upload\n",
    "    \"\"\"\n",
    "    if context:\n",
    "        await context.info(f\"üì§ Starting upload of {file_count} files...\")\n",
    "    \n",
    "    uploaded_files = []\n",
    "    \n",
    "    for i in range(file_count):\n",
    "        file_name = f\"file_{i+1}.dat\"\n",
    "        \n",
    "        if context:\n",
    "            await context.info(f\"Uploading {file_name}...\")\n",
    "        \n",
    "        # Simulate upload by chunks\n",
    "        chunks = 10\n",
    "        for chunk in range(chunks):\n",
    "            await asyncio.sleep(0.2)  # Simulate upload time\n",
    "            \n",
    "            if context:\n",
    "                await context.report_progress(\n",
    "                    progress=(i * chunks) + chunk + 1,\n",
    "                    total=file_count * chunks,\n",
    "                    message=f\"Uploading {file_name} - chunk {chunk+1}/{chunks}\"\n",
    "                )\n",
    "        \n",
    "        uploaded_files.append({\n",
    "            \"name\": file_name,\n",
    "            \"size\": f\"{(i+1) * 1024} KB\",\n",
    "            \"status\": \"uploaded\"\n",
    "        })\n",
    "        \n",
    "        if context:\n",
    "            await context.debug(f\"‚úÖ {file_name} uploaded successfully\")\n",
    "    \n",
    "    if context:\n",
    "        await context.info(f\"üéâ Upload completed: {len(uploaded_files)} files\")\n",
    "    \n",
    "    return {\n",
    "        \"uploaded_count\": len(uploaded_files),\n",
    "        \"files\": uploaded_files,\n",
    "        \"total_size\": sum(int(f[\"size\"].split()[0]) for f in uploaded_files),\n",
    "        \"status\": \"completed\"\n",
    "    }\n",
    "\n",
    "\n",
    "@mcp.tool\n",
    "async def realtime_monitoring(\n",
    "    duration_seconds: int = 30,\n",
    "    context: Context = None\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Real-time monitoring with periodic updates.\n",
    "    \n",
    "    Args:\n",
    "        duration_seconds: Monitoring duration in seconds\n",
    "    \"\"\"\n",
    "    if context:\n",
    "        await context.info(f\"üì° Starting monitoring for {duration_seconds} seconds...\")\n",
    "    \n",
    "    metrics = []\n",
    "    interval = 2  # Update every 2 seconds\n",
    "    total_intervals = duration_seconds // interval\n",
    "    \n",
    "    for i in range(total_intervals):\n",
    "        # Simulate metrics\n",
    "        import random\n",
    "        cpu_usage = random.randint(20, 80)\n",
    "        memory_usage = random.randint(40, 90)\n",
    "        network_io = random.randint(100, 1000)\n",
    "        \n",
    "        metric = {\n",
    "            \"timestamp\": i * interval,\n",
    "            \"cpu\": cpu_usage,\n",
    "            \"memory\": memory_usage,\n",
    "            \"network_io\": network_io\n",
    "        }\n",
    "        metrics.append(metric)\n",
    "        \n",
    "        if context:\n",
    "            await context.report_progress(\n",
    "                progress=i + 1,\n",
    "                total=total_intervals,\n",
    "                message=f\"Monitoring active - CPU: {cpu_usage}%, MEM: {memory_usage}%, NET: {network_io}KB/s\"\n",
    "            )\n",
    "            \n",
    "            await context.debug(f\"Metrics collected: interval {i+1}\")\n",
    "        \n",
    "        await asyncio.sleep(interval)\n",
    "    \n",
    "    if context:\n",
    "        await context.info(f\"üìä Monitoring completed: {len(metrics)} data points\")\n",
    "    \n",
    "    avg_cpu = sum(m[\"cpu\"] for m in metrics) / len(metrics)\n",
    "    avg_memory = sum(m[\"memory\"] for m in metrics) / len(metrics)\n",
    "    \n",
    "    return {\n",
    "        \"duration\": duration_seconds,\n",
    "        \"data_points\": len(metrics),\n",
    "        \"avg_cpu\": round(avg_cpu, 2),\n",
    "        \"avg_memory\": round(avg_memory, 2),\n",
    "        \"metrics\": metrics,\n",
    "        \"status\": \"completed\"\n",
    "    }\n",
    "\n",
    "\n",
    "async def run_streaming_server(host: str = \"127.0.0.1\", port: int = 8000):\n",
    "    \"\"\"Run the streaming server.\"\"\"\n",
    "    print(f\"üöÄ Starting MCP streaming server on {host}:{port}\")\n",
    "    \n",
    "    # Create Starlette application with streaming support\n",
    "    app = create_streamable_http_app(\n",
    "        server=mcp,\n",
    "        streamable_http_path=\"/mcp/\",\n",
    "        stateless_http=False,  # Keep session state\n",
    "        debug=True\n",
    "    )\n",
    "    \n",
    "    # Configure uvicorn\n",
    "    config = uvicorn.Config(\n",
    "        app=app,\n",
    "        host=host,\n",
    "        port=port,\n",
    "        log_level=\"info\",\n",
    "        access_log=False\n",
    "    )\n",
    "    \n",
    "    # Run server\n",
    "    server = uvicorn.Server(config)\n",
    "    print(f\"‚úÖ Server ready at http://{host}:{port}/mcp/\")\n",
    "    print(\"üì° Available tools:\")\n",
    "    print(\"  - long_running_task: Long running task with progress\")\n",
    "    print(\"  - streaming_data_processor: Data processing\")\n",
    "    print(\"  - file_upload_simulation: File upload simulation\")\n",
    "    print(\"  - realtime_monitoring: Real-time monitoring\")\n",
    "    \n",
    "    await server.serve()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        asyncio.run(run_streaming_server())\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n‚èπÔ∏è  Server stopped by user\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error running server: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954e7d9c",
   "metadata": {},
   "source": [
    "## Cliente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84ed1cd",
   "metadata": {},
   "source": [
    "Antes cri√°vamos um cliente com a classe `Client` do `fastmcp`.\n",
    "\n",
    "``` python\n",
    "from fastmcp import Client\n",
    "\n",
    "client = Client(\n",
    "    server_url=\"http://localhost:8000/mcp/\",\n",
    "    name=\"MCP client name\",\n",
    "    instructions=\"MCP client instructions\",\n",
    ")\n",
    "```\n",
    "\n",
    "E com o cliente, cham√°vamos as tools do servidor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e139cdc",
   "metadata": {},
   "source": [
    "Agora usamos a classe `StreamableHttpTransport` de `fastmcp.client.transports` para criar uma camada de transporte que suporte streaming e criamos o cliente da mesma forma que antes, s√≥ que indicamos a camada de transporte.\n",
    "\n",
    "``` python\n",
    "from fastmcp import Client\n",
    "from fastmcp.client.transports import StreamableHttpTransport\n",
    "\n",
    "transport = StreamableHttpTransport(\n",
    "    url=\"http://localhost:8000/mcp/\",\n",
    "    sse_read_timeout=60.0  # Timeout for streaming\n",
    ")\n",
    "\n",
    "client = Client(transport=transport)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36eb8d1",
   "metadata": {},
   "source": [
    "O restante permanece igual."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75999b89",
   "metadata": {},
   "source": [
    "### Implementa√ß√£o do cliente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20d2178",
   "metadata": {},
   "source": [
    "Agora que explicamos como criar o cliente que suporta o streaming, vamos implement√°-lo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01afa19d",
   "metadata": {},
   "source": [
    "#### Criar o ambiente virtual para o cliente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0449ac",
   "metadata": {},
   "source": [
    "Primeiro criamos a pasta onde vamos desenvolv√™-lo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e870d8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir MCP_streamable_client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7734feb",
   "metadata": {},
   "source": [
    "Criamos o ambiente com `uv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20872e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized project `\u001b[36mmcp-streamable-client\u001b[39m` at `\u001b[36m/Users/macm1/Documents/web/portafolio/posts/MCP_streamable_client\u001b[39m`\n"
     ]
    }
   ],
   "source": [
    "!cd MCP_streamable_client && uv init ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ffe7b1",
   "metadata": {},
   "source": [
    "Iniciamos no ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85f0292f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPython \u001b[36m3.12.8\u001b[39m\n",
      "Creating virtual environment at: \u001b[36m.venv\u001b[39m\n",
      "Activate with: \u001b[32msource .venv/bin/activate\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "!cd MCP_streamable_server && uv venv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb747ee0",
   "metadata": {},
   "source": [
    "Instalamos as bibliotecas necess√°rias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d14b104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPython \u001b[36m3.12.8\u001b[39m\n",
      "Creating virtual environment at: \u001b[36m.venv\u001b[39m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m64 packages\u001b[0m \u001b[2min 517ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)                                                   \u001b[37m‚†ã\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/0)                                                   \n",
      "\u001b[2K\u001b[1A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m     0 B/233.99 KiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 16.00 KiB/233.99 KiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 32.00 KiB/233.99 KiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 48.00 KiB/233.99 KiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 64.00 KiB/233.99 KiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 80.00 KiB/233.99 KiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 96.00 KiB/233.99 KiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 112.00 KiB/233.99 KiB       \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)m-------------\u001b[0m\u001b[0m 128.00 KiB/233.99 KiB       \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)[2m-----------\u001b[0m\u001b[0m 144.00 KiB/233.99 KiB       \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-\u001b[2m---------\u001b[0m\u001b[0m 160.00 KiB/233.99 KiB       \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)---\u001b[2m-------\u001b[0m\u001b[0m 176.00 KiB/233.99 KiB       \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-----\u001b[2m-----\u001b[0m\u001b[0m 192.00 KiB/233.99 KiB       \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------\u001b[2m---\u001b[0m\u001b[0m 208.00 KiB/233.99 KiB       \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)---------\u001b[2m-\u001b[0m\u001b[0m 224.00 KiB/233.99 KiB       \u001b[1A\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 182ms\u001b[0m\u001b[0m                                                  \u001b[1A\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m61 packages\u001b[0m \u001b[2min 96ms\u001b[0m\u001b[0m                               \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mannotated-types\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1manyio\u001b[0m\u001b[2m==4.10.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mattrs\u001b[0m\u001b[2m==25.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mauthlib\u001b[0m\u001b[2m==1.6.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcertifi\u001b[0m\u001b[2m==2025.8.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcffi\u001b[0m\u001b[2m==1.17.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcharset-normalizer\u001b[0m\u001b[2m==3.4.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mclick\u001b[0m\u001b[2m==8.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcryptography\u001b[0m\u001b[2m==45.0.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcyclopts\u001b[0m\u001b[2m==3.22.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdnspython\u001b[0m\u001b[2m==2.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdocstring-parser\u001b[0m\u001b[2m==0.17.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdocutils\u001b[0m\u001b[2m==0.22\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1memail-validator\u001b[0m\u001b[2m==2.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mexceptiongroup\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfastmcp\u001b[0m\u001b[2m==2.11.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mh11\u001b[0m\u001b[2m==0.16.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttpcore\u001b[0m\u001b[2m==1.0.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttpx\u001b[0m\u001b[2m==0.28.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttpx-sse\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1midna\u001b[0m\u001b[2m==3.10\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1misodate\u001b[0m\u001b[2m==0.7.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjsonschema\u001b[0m\u001b[2m==4.25.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjsonschema-path\u001b[0m\u001b[2m==0.3.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjsonschema-specifications\u001b[0m\u001b[2m==2025.4.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlazy-object-proxy\u001b[0m\u001b[2m==1.12.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarkdown-it-py\u001b[0m\u001b[2m==4.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==3.0.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmcp\u001b[0m\u001b[2m==1.13.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmdurl\u001b[0m\u001b[2m==0.1.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmore-itertools\u001b[0m\u001b[2m==10.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopenapi-core\u001b[0m\u001b[2m==0.19.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopenapi-pydantic\u001b[0m\u001b[2m==0.5.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopenapi-schema-validator\u001b[0m\u001b[2m==0.6.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopenapi-spec-validator\u001b[0m\u001b[2m==0.7.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mparse\u001b[0m\u001b[2m==1.20.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpathable\u001b[0m\u001b[2m==0.4.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpycparser\u001b[0m\u001b[2m==2.22\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic\u001b[0m\u001b[2m==2.11.7\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic-core\u001b[0m\u001b[2m==2.33.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic-settings\u001b[0m\u001b[2m==2.10.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpygments\u001b[0m\u001b[2m==2.19.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyperclip\u001b[0m\u001b[2m==1.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-dotenv\u001b[0m\u001b[2m==1.1.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-multipart\u001b[0m\u001b[2m==0.0.20\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyyaml\u001b[0m\u001b[2m==6.0.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mreferencing\u001b[0m\u001b[2m==0.36.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrequests\u001b[0m\u001b[2m==2.32.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrfc3339-validator\u001b[0m\u001b[2m==0.1.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrich\u001b[0m\u001b[2m==14.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrich-rst\u001b[0m\u001b[2m==1.3.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrpds-py\u001b[0m\u001b[2m==0.27.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msix\u001b[0m\u001b[2m==1.17.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msniffio\u001b[0m\u001b[2m==1.3.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msse-starlette\u001b[0m\u001b[2m==3.0.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mstarlette\u001b[0m\u001b[2m==0.47.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyping-extensions\u001b[0m\u001b[2m==4.14.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyping-inspection\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.5.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1muvicorn\u001b[0m\u001b[2m==0.35.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwerkzeug\u001b[0m\u001b[2m==3.1.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd MCP_streamable_client && uv add fastmcp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b60c6ae",
   "metadata": {},
   "source": [
    "#### C√≥digo do cliente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b1a167",
   "metadata": {},
   "source": [
    "Agora vamos criar o c√≥digo do cliente. Vamos criar um cliente com tudo o que falamos anteriormente, que executar√° as quatro tools do servidor e mostrar√° o progresso de cada uma delas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61fc9283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing MCP_streamable_client/client.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile MCP_streamable_client/client.py\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "MCP client for streaming and partial results.\n",
    "Shows how to receive and handle partial results from the server.\n",
    "\"\"\"\n",
    "\n",
    "import asyncio\n",
    "import json\n",
    "import time\n",
    "from typing import Any, Dict, List, Optional, Callable\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "\n",
    "from fastmcp import Client\n",
    "from fastmcp.client.transports import StreamableHttpTransport\n",
    "\n",
    "@dataclass\n",
    "class ProgressUpdate:\n",
    "    \"\"\"Represents a progress update.\"\"\"\n",
    "    progress: float\n",
    "    total: float\n",
    "    message: str\n",
    "    percentage: float\n",
    "    timestamp: datetime = field(default_factory=datetime.now)\n",
    "\n",
    "\n",
    "@dataclass  \n",
    "class TaskResult:\n",
    "    \"\"\"Represents the result of a task.\"\"\"\n",
    "    task_name: str\n",
    "    result: Dict[str, Any]\n",
    "    progress_updates: List[ProgressUpdate]\n",
    "    duration: float\n",
    "    success: bool\n",
    "    error_message: Optional[str] = None\n",
    "\n",
    "\n",
    "class StreamingProgressHandler:\n",
    "    \"\"\"Handles streaming progress in a visual way.\"\"\"\n",
    "    \n",
    "    def __init__(self, task_name: str):\n",
    "        self.task_name = task_name\n",
    "        self.progress_updates: List[ProgressUpdate] = []\n",
    "        self.start_time = time.time()\n",
    "        \n",
    "    async def __call__(self, progress: float, total: float, message: str):\n",
    "        \"\"\"Callback called when there are progress updates.\"\"\"\n",
    "        percentage = (progress / total) * 100 if total > 0 else 0\n",
    "        \n",
    "        update = ProgressUpdate(\n",
    "            progress=progress,\n",
    "            total=total,\n",
    "            message=message,\n",
    "            percentage=percentage\n",
    "        )\n",
    "        self.progress_updates.append(update)\n",
    "        \n",
    "        # Display progress visually\n",
    "        self._display_progress(update)\n",
    "    \n",
    "    def _display_progress(self, update: ProgressUpdate):\n",
    "        \"\"\"Display progress visually.\"\"\"\n",
    "        bar_length = 30\n",
    "        filled_length = int(bar_length * update.percentage / 100)\n",
    "        bar = '‚ñà' * filled_length + '‚ñë' * (bar_length - filled_length)\n",
    "        \n",
    "        elapsed = time.time() - self.start_time\n",
    "\n",
    "        print(f\"\\tüìä {self.task_name}: |{bar}| {update.percentage:.1f}% \"\n",
    "              f\"({update.progress:.0f}/{update.total:.0f}) - \"\n",
    "              f\"{update.message} [{elapsed:.1f}s]\")\n",
    "        \n",
    "        if update.progress >= update.total:\n",
    "            print()  # New line when complete\n",
    "\n",
    "\n",
    "class MCPStreamingClient:\n",
    "    \"\"\"MCP client with streaming capabilities.\"\"\"\n",
    "    \n",
    "    def __init__(self, server_url: str = \"http://localhost:8000/mcp/\"):\n",
    "        self.server_url = server_url\n",
    "        self.transport = None\n",
    "        self.client = None\n",
    "        \n",
    "    async def __aenter__(self):\n",
    "        \"\"\"Initialize connection to the server.\"\"\"\n",
    "            \n",
    "        self.transport = StreamableHttpTransport(\n",
    "            url=self.server_url,\n",
    "            sse_read_timeout=60.0  # Timeout for streaming\n",
    "        )\n",
    "        \n",
    "        self.client = Client(transport=self.transport)\n",
    "        await self.client.__aenter__()\n",
    "        return self\n",
    "        \n",
    "    async def __aexit__(self, exc_type, exc_val, exc_tb):\n",
    "        \"\"\"Close connection.\"\"\"\n",
    "        if self.client:\n",
    "            await self.client.__aexit__(exc_type, exc_val, exc_tb)\n",
    "    \n",
    "    async def test_connection(self) -> bool:\n",
    "        \"\"\"Test connection to the server.\"\"\"\n",
    "        try:\n",
    "            if not self.client:\n",
    "                print(f\"‚ùå Client not initialized\")\n",
    "                return False\n",
    "                \n",
    "            result = await self.client.ping()\n",
    "            print(f\"‚úÖ Connection established with the server\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error de conexi√≥n: {e}\")\n",
    "            return False\n",
    "    \n",
    "    async def call_streaming_tool(\n",
    "        self,\n",
    "        tool_name: str,\n",
    "        parameters: Dict[str, Any],\n",
    "        progress_callback: Optional[Callable] = None\n",
    "    ) -> TaskResult:\n",
    "        \"\"\"Call a tool with progress handling.\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            if not self.client:\n",
    "                raise Exception(\"Client not initialized\")\n",
    "                \n",
    "            print(f\"Executing {tool_name} tool:\")\n",
    "            \n",
    "            result = await self.client.call_tool(\n",
    "                tool_name,\n",
    "                parameters,\n",
    "                progress_handler=progress_callback\n",
    "            )\n",
    "            \n",
    "            duration = time.time() - start_time\n",
    "            \n",
    "            # FastMCP returns a CallToolResult object with content attribute\n",
    "            result_data = result.content if hasattr(result, 'content') else result\n",
    "            \n",
    "            # If result_data is a list of TextContent, extract the text\n",
    "            if isinstance(result_data, list) and len(result_data) > 0:\n",
    "                # Handle list of TextContent objects\n",
    "                if hasattr(result_data[0], 'text'):\n",
    "                    result_data = result_data[0].text\n",
    "            \n",
    "            # If result_data is string, try to parse it as JSON\n",
    "            if isinstance(result_data, str):\n",
    "                try:\n",
    "                    result_data = json.loads(result_data)\n",
    "                except json.JSONDecodeError:\n",
    "                    result_data = {\"output\": result_data}\n",
    "            \n",
    "            return TaskResult(\n",
    "                task_name=tool_name,\n",
    "                result=result_data,\n",
    "                progress_updates=getattr(progress_callback, 'progress_updates', []),\n",
    "                duration=duration,\n",
    "                success=True\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            duration = time.time() - start_time\n",
    "            \n",
    "            return TaskResult(\n",
    "                task_name=tool_name,\n",
    "                result={},\n",
    "                progress_updates=getattr(progress_callback, 'progress_updates', []),\n",
    "                duration=duration,\n",
    "                success=False,\n",
    "                error_message=str(e)\n",
    "            )\n",
    "    \n",
    "    async def list_available_tools(self) -> List[str]:\n",
    "        \"\"\"List available tools on the server.\"\"\"\n",
    "        try:\n",
    "            if not self.client:\n",
    "                print(f\"‚ùå Client not initialized\")\n",
    "                return []\n",
    "                \n",
    "            tools = await self.client.list_tools()\n",
    "            # FastMCP returns a list of tools directly\n",
    "            if isinstance(tools, list):\n",
    "                return [tool.name for tool in tools]\n",
    "            # If it has attribute tools\n",
    "            elif hasattr(tools, 'tools'):\n",
    "                return [tool.name for tool in tools.tools]\n",
    "            else:\n",
    "                return []\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error listing tools: {e}\")\n",
    "            return []\n",
    "\n",
    "\n",
    "async def demo_long_running_task(client: MCPStreamingClient) -> TaskResult:\n",
    "    \"\"\"Demo of long running task with progress.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìã DEMO: Long Running Task with Progress\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    progress_handler = StreamingProgressHandler(\"Long Running Task\")\n",
    "    \n",
    "    result = await client.call_streaming_tool(\n",
    "        \"long_running_task\",\n",
    "        {\"name\": \"Data Processing\", \"steps\": 8},\n",
    "        progress_callback=progress_handler\n",
    "    )\n",
    "    \n",
    "    if result.success:\n",
    "        print(f\"‚úÖ Task completed in {result.duration:.2f}s\")\n",
    "        print(f\"üìä Progress updates received: {len(result.progress_updates)}\")\n",
    "        # Safe handling of the result\n",
    "        status = result.result.get('status', 'N/A') if isinstance(result.result, dict) else 'N/A'\n",
    "        print(f\"üìã Result: {status}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Task failed: {result.error_message}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "async def demo_data_processing(client: MCPStreamingClient) -> TaskResult:\n",
    "    \"\"\"Demo of data processing.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üíæ DEMO: Data Processing\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    progress_handler = StreamingProgressHandler(\"Procesamiento\")\n",
    "    \n",
    "    result = await client.call_streaming_tool(\n",
    "        \"streaming_data_processor\",\n",
    "        {\"data_size\": 50},\n",
    "        progress_callback=progress_handler\n",
    "    )\n",
    "    \n",
    "    if result.success:\n",
    "        print(f\"‚úÖ Processing completed in {result.duration:.2f}s\")\n",
    "        # Safe handling of the result\n",
    "        total = result.result.get('total_processed', 0) if isinstance(result.result, dict) else 0\n",
    "        print(f\"üìä Processed elements: {total}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Processing failed: {result.error_message}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "async def demo_file_upload(client: MCPStreamingClient) -> TaskResult:\n",
    "    \"\"\"Demo of file upload.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üì§ DEMO: File Upload\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    progress_handler = StreamingProgressHandler(\"File Upload\")\n",
    "    \n",
    "    result = await client.call_streaming_tool(\n",
    "        \"file_upload_simulation\",\n",
    "        {\"file_count\": 3},\n",
    "        progress_callback=progress_handler\n",
    "    )\n",
    "    \n",
    "    if result.success:\n",
    "        print(f\"‚úÖ Upload completed in {result.duration:.2f}s\")\n",
    "        # Safe handling of the result\n",
    "        count = result.result.get('uploaded_count', 0) if isinstance(result.result, dict) else 0\n",
    "        print(f\"üìÅ Uploaded files: {count}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Upload failed: {result.error_message}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "async def demo_realtime_monitoring(client: MCPStreamingClient) -> TaskResult:\n",
    "    \"\"\"Demo of real-time monitoring.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üì° DEMO: Real-time Monitoring\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    progress_handler = StreamingProgressHandler(\"Monitoring\")\n",
    "    \n",
    "    result = await client.call_streaming_tool(\n",
    "        \"realtime_monitoring\",\n",
    "        {\"duration_seconds\": 20},\n",
    "        progress_callback=progress_handler\n",
    "    )\n",
    "    \n",
    "    if result.success:\n",
    "        print(f\"‚úÖ Monitoring completed in {result.duration:.2f}s\")\n",
    "        # Safe handling of the result\n",
    "        if isinstance(result.result, dict):\n",
    "            print(f\"üìä Average CPU: {result.result.get('avg_cpu', 0)}%\")\n",
    "            print(f\"üíæ Average memory: {result.result.get('avg_memory', 0)}%\")\n",
    "        else:\n",
    "            print(f\"üìä Result: {result.result}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Monitoring failed: {result.error_message}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def print_summary(results: List[TaskResult]):\n",
    "    \"\"\"Print summary of all tasks.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"üìà EXECUTION SUMMARY\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    for result in results:\n",
    "        status = \"\\t‚úÖ SUCCESS\" if result.success else \"\\t‚ùå FAILURE\"\n",
    "        print(f\"{status} {result.task_name}: {result.duration:.2f}s \"\n",
    "              f\"({len(result.progress_updates)} updates)\")\n",
    "    \n",
    "    total_time = sum(r.duration for r in results)\n",
    "    successful = len([r for r in results if r.success])\n",
    "    \n",
    "    print(f\"\\nüìä Total: {successful}/{len(results)} successful tasks\")\n",
    "    print(f\"‚è±Ô∏è  Total time: {total_time:.2f}s\")\n",
    "\n",
    "\n",
    "async def run_streaming_demo():\n",
    "    \"\"\"Run complete streaming client demo.\"\"\"\n",
    "    print(\"MCP Streaming Client\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    try:\n",
    "        async with MCPStreamingClient() as client:\n",
    "            # Test connection\n",
    "            if not await client.test_connection():\n",
    "                print(\"‚ùå Could not connect to the server. Make sure it's running.\")\n",
    "                return\n",
    "            \n",
    "            # List tools\n",
    "            tools = await client.list_available_tools()\n",
    "            print(\"üîß Available tools:\")\n",
    "            for tool in tools:\n",
    "                print(f\"\\t * {tool}\")\n",
    "            \n",
    "            # Run demos\n",
    "            results = []\n",
    "            \n",
    "            # Demo 1: Long running task\n",
    "            result1 = await demo_long_running_task(client)\n",
    "            results.append(result1)\n",
    "            \n",
    "            await asyncio.sleep(1)  # Pause between demos\n",
    "            \n",
    "            # Demo 2: Data processing  \n",
    "            result2 = await demo_data_processing(client)\n",
    "            results.append(result2)\n",
    "            \n",
    "            await asyncio.sleep(1)\n",
    "            \n",
    "            # Demo 3: File upload\n",
    "            result3 = await demo_file_upload(client)\n",
    "            results.append(result3)\n",
    "            \n",
    "            await asyncio.sleep(1)\n",
    "            \n",
    "            # Demo 4: Real-time monitoring\n",
    "            result4 = await demo_realtime_monitoring(client)\n",
    "            results.append(result4)\n",
    "            \n",
    "            # Final summary\n",
    "            print_summary(results)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in the demo: {e}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        asyncio.run(run_streaming_demo())\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n‚èπÔ∏è  Demo interrupted by the user\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error running demo: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca9f594",
   "metadata": {},
   "source": [
    "## Execu√ß√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777642f3",
   "metadata": {},
   "source": [
    "Agora que temos o servidor e o cliente, vamos execut√°-los."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e521f1a7",
   "metadata": {},
   "source": [
    "Primeiro, iniciamos o servidor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "775fcda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting MCP streaming server on 127.0.0.1:8000\n",
      "‚úÖ Server ready at http://127.0.0.1:8000/mcp/\n",
      "üì° Available tools:\n",
      "  - long_running_task: Long running task with progress\n",
      "  - streaming_data_processor: Data processing\n",
      "  - file_upload_simulation: File upload simulation\n",
      "  - realtime_monitoring: Real-time monitoring\n",
      "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m62601\u001b[0m]\n",
      "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
      "\u001b[32mINFO\u001b[0m:     Application startup complete.\n",
      "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://127.0.0.1:8000\u001b[0m (Press CTRL+C to quit)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cd MCP_streamable_server && source .venv/bin/activate && uv run server.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15ec902",
   "metadata": {},
   "source": [
    "Depois de iniciado, executamos o cliente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60e671c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCP Streaming Client\n",
      "====================================================================================================\n",
      "‚úÖ Connection established with the server\n",
      "üîß Available tools:\n",
      "\t * long_running_task\n",
      "\t * streaming_data_processor\n",
      "\t * file_upload_simulation\n",
      "\t * realtime_monitoring\n",
      "\n",
      "============================================================\n",
      "üìã DEMO: Long Running Task with Progress\n",
      "============================================================\n",
      "Executing long_running_task tool:\n",
      "\u001b[2;36m[08/23/25 11:19:20]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Server log: üöÄ Initializing Data      \u001b]8;id=664702;file:///Users/macm1/Documents/web/portafolio/posts/MCP_streamable_client/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\u001b\\\\\u001b[2mlogging.py\u001b[0m\u001b]8;;\u001b\\\\\u001b[2m:\u001b[0m\u001b]8;id=102228;file:///Users/macm1/Documents/web/portafolio/posts/MCP_streamable_client/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#40\u001b\\\\\u001b[2m40\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         Processing with \u001b[1;36m8\u001b[0m steps\u001b[33m...\u001b[0m            \u001b[2m             \u001b[0m\n",
      "\tüìä Long Running Task: |‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 12.5% (1/8) - Step 1/8 - Step 1: Processed Data Processing [1.0s]\n",
      "\tüìä Long Running Task: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 25.0% (2/8) - Step 2/8 - Step 2: Processed Data Processing [2.0s]\n",
      "\tüìä Long Running Task: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 37.5% (3/8) - Step 3/8 - Step 3: Processed Data Processing [3.0s]\n",
      "\tüìä Long Running Task: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 50.0% (4/8) - Step 4/8 - Step 4: Processed Data Processing [4.0s]\n",
      "\tüìä Long Running Task: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 62.5% (5/8) - Step 5/8 - Step 5: Processed Data Processing [5.0s]\n",
      "\tüìä Long Running Task: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 75.0% (6/8) - Step 6/8 - Step 6: Processed Data Processing [6.0s]\n",
      "\tüìä Long Running Task: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë| 87.5% (7/8) - Step 7/8 - Step 7: Processed Data Processing [7.0s]\n",
      "\tüìä Long Running Task: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100.0% (8/8) - Step 8/8 - Step 8: Processed Data Processing [8.0s]\n",
      "\n",
      "\u001b[2;36m[08/23/25 11:19:28]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Server log: üéâ Data Processing        \u001b]8;id=444005;file:///Users/macm1/Documents/web/portafolio/posts/MCP_streamable_client/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\u001b\\\\\u001b[2mlogging.py\u001b[0m\u001b]8;;\u001b\\\\\u001b[2m:\u001b[0m\u001b]8;id=432539;file:///Users/macm1/Documents/web/portafolio/posts/MCP_streamable_client/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#40\u001b\\\\\u001b[2m40\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         completed successfully!               \u001b[2m             \u001b[0m\n",
      "‚úÖ Task completed in 8.03s\n",
      "üìä Progress updates received: 8\n",
      "üìã Result: completed\n",
      "\n",
      "============================================================\n",
      "üíæ DEMO: Data Processing\n",
      "============================================================\n",
      "Executing streaming_data_processor tool:\n",
      "\u001b[2;36m[08/23/25 11:19:29]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Server log: üìä Procesando \u001b[1;36m50\u001b[0m          \u001b]8;id=212017;file:///Users/macm1/Documents/web/portafolio/posts/MCP_streamable_client/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\u001b\\\\\u001b[2mlogging.py\u001b[0m\u001b]8;;\u001b\\\\\u001b[2m:\u001b[0m\u001b]8;id=588573;file:///Users/macm1/Documents/web/portafolio/posts/MCP_streamable_client/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#40\u001b\\\\\u001b[2m40\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         elementos de datos\u001b[33m...\u001b[0m                 \u001b[2m             \u001b[0m\n",
      "\tüìä Procesamiento: |‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 10.0% (5/50) - Processed 5/50 items [0.5s]\n",
      "\tüìä Procesamiento: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 20.0% (10/50) - Processed 10/50 items [1.0s]\n",
      "\tüìä Procesamiento: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 30.0% (15/50) - Processed 15/50 items [1.5s]\n",
      "\tüìä Procesamiento: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 40.0% (20/50) - Processed 20/50 items [2.0s]\n",
      "\tüìä Procesamiento: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 50.0% (25/50) - Processed 25/50 items [2.5s]\n",
      "\tüìä Procesamiento: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 60.0% (30/50) - Processed 30/50 items [3.0s]\n",
      "\tüìä Procesamiento: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 70.0% (35/50) - Processed 35/50 items [3.5s]\n",
      "\tüìä Procesamiento: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 80.0% (40/50) - Processed 40/50 items [4.0s]\n",
      "\tüìä Procesamiento: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë| 90.0% (45/50) - Processed 45/50 items [4.5s]\n",
      "\tüìä Procesamiento: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100.0% (50/50) - Processed 50/50 items [5.0s]\n",
      "\n",
      "\u001b[2;36m[08/23/25 11:19:34]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Server log: ‚úÖ Processing completed:  \u001b]8;id=495673;file:///Users/macm1/Documents/web/portafolio/posts/MCP_streamable_client/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\u001b\\\\\u001b[2mlogging.py\u001b[0m\u001b]8;;\u001b\\\\\u001b[2m:\u001b[0m\u001b]8;id=761216;file:///Users/macm1/Documents/web/portafolio/posts/MCP_streamable_client/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#40\u001b\\\\\u001b[2m40\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[1;36m50\u001b[0m items                              \u001b[2m             \u001b[0m\n",
      "‚úÖ Processing completed in 5.03s\n",
      "üìä Processed elements: 50\n",
      "\n",
      "============================================================\n",
      "üì§ DEMO: File Upload\n",
      "============================================================\n",
      "Executing file_upload_simulation tool:\n",
      "\u001b[2;36m[08/23/25 11:19:35]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Server log: üì§ Starting upload of \u001b[1;36m3\u001b[0m   \u001b]8;id=903659;file:///Users/macm1/Documents/web/portafolio/posts/MCP_streamable_client/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\u001b\\\\\u001b[2mlogging.py\u001b[0m\u001b]8;;\u001b\\\\\u001b[2m:\u001b[0m\u001b]8;id=90481;file:///Users/macm1/Documents/web/portafolio/posts/MCP_streamable_client/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#40\u001b\\\\\u001b[2m40\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         files\u001b[33m...\u001b[0m                              \u001b[2m             \u001b[0m\n",
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Server log: Uploading file_1.dat\u001b[33m...\u001b[0m   \u001b]8;id=894672;file:///Users/macm1/Documents/web/portafolio/posts/MCP_streamable_client/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\u001b\\\\\u001b[2mlogging.py\u001b[0m\u001b]8;;\u001b\\\\\u001b[2m:\u001b[0m\u001b]8;id=979097;file:///Users/macm1/Documents/web/portafolio/posts/MCP_streamable_client/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#40\u001b\\\\\u001b[2m40\u001b[0m\u001b]8;;\u001b\\\\\n",
      "\tüìä File Upload: |‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 3.3% (1/30) - Uploading file_1.dat - chunk 1/10 [0.2s]\n",
      "\tüìä File Upload: |‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 6.7% (2/30) - Uploading file_1.dat - chunk 2/10 [0.4s]\n",
      "\tüìä File Upload: |‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 10.0% (3/30) - Uploading file_1.dat - chunk 3/10 [0.6s]\n",
      "\tüìä File Upload: |‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 13.3% (4/30) - Uploading file_1.dat - chunk 4/10 [0.8s]\n",
      "\tüìä File Upload: |‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 16.7% (5/30) - Uploading file_1.dat - chunk 5/10 [1.0s]\n",
      "\tüìä File Upload: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 20.0% (6/30) - Uploading file_1.dat - chunk 6/10 [1.2s]\n",
      "\tüìä File Upload: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 23.3% (7/30) - Uploading file_1.dat - chunk 7/10 [1.4s]\n",
      "\tüìä File Upload: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 26.7% (8/30) - Uploading file_1.dat - chunk 8/10 [1.6s]\n",
      "\tüìä File Upload: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 30.0% (9/30) - Uploading file_1.dat - chunk 9/10 [1.8s]\n",
      "\tüìä File Upload: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 33.3% (10/30) - Uploading file_1.dat - chunk 10/10 [2.0s]\n",
      "\u001b[2;36m[08/23/25 11:19:37]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Server log: Uploading file_2.dat\u001b[33m...\u001b[0m   \u001b]8;id=537276;file:///Users/macm1/Documents/web/portafolio/posts/MCP_streamable_client/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\u001b\\\\\u001b[2mlogging.py\u001b[0m\u001b]8;;\u001b\\\\\u001b[2m:\u001b[0m\u001b]8;id=555236;file:///Users/macm1/Documents/web/portafolio/posts/MCP_streamable_client/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#40\u001b\\\\\u001b[2m40\u001b[0m\u001b]8;;\u001b\\\\\n",
      "\tüìä File Upload: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 36.7% (11/30) - Uploading file_2.dat - chunk 1/10 [2.2s]\n",
      "\tüìä File Upload: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 40.0% (12/30) - Uploading file_2.dat - chunk 2/10 [2.4s]\n",
      "\tüìä File Upload: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 43.3% (13/30) - Uploading file_2.dat - chunk 3/10 [2.6s]\n",
      "\tüìä File Upload: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 46.7% (14/30) - Uploading file_2.dat - chunk 4/10 [2.8s]\n",
      "\tüìä File Upload: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 50.0% (15/30) - Uploading file_2.dat - chunk 5/10 [3.0s]\n",
      "\tüìä File Upload: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 53.3% (16/30) - Uploading file_2.dat - chunk 6/10 [3.2s]\n",
      "\tüìä File Upload: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 56.7% (17/30) - Uploading file_2.dat - chunk 7/10 [3.4s]\n",
      "\tüìä File Upload: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 60.0% (18/30) - Uploading file_2.dat - chunk 8/10 [3.6s]\n",
      "\tüìä File Upload: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 63.3% (19/30) - Uploading file_2.dat - chunk 9/10 [3.8s]\n",
      "\tüìä File Upload: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 66.7% (20/30) - Uploading file_2.dat - chunk 10/10 [4.0s]\n",
      "\u001b[2;36m[08/23/25 11:19:39]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Server log: Uploading file_3.dat\u001b[33m...\u001b[0m   \u001b]8;id=170215;file:///Users/macm1/Documents/web/portafolio/posts/MCP_streamable_client/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\u001b\\\\\u001b[2mlogging.py\u001b[0m\u001b]8;;\u001b\\\\\u001b[2m:\u001b[0m\u001b]8;id=598020;file:///Users/macm1/Documents/web/portafolio/posts/MCP_streamable_client/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#40\u001b\\\\\u001b[2m40\u001b[0m\u001b]8;;\u001b\\\\\n",
      "\tüìä File Upload: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 70.0% (21/30) - Uploading file_3.dat - chunk 1/10 [4.2s]\n",
      "\tüìä File Upload: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 73.3% (22/30) - Uploading file_3.dat - chunk 2/10 [4.4s]\n",
      "\tüìä File Upload: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 76.7% (23/30) - Uploading file_3.dat - chunk 3/10 [4.6s]\n",
      "\tüìä File Upload: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 80.0% (24/30) - Uploading file_3.dat - chunk 4/10 [4.8s]\n",
      "\tüìä File Upload: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë| 83.3% (25/30) - Uploading file_3.dat - chunk 5/10 [5.0s]\n",
      "\tüìä File Upload: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë| 86.7% (26/30) - Uploading file_3.dat - chunk 6/10 [5.2s]\n",
      "\tüìä File Upload: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë| 90.0% (27/30) - Uploading file_3.dat - chunk 7/10 [5.4s]\n",
      "\tüìä File Upload: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë| 93.3% (28/30) - Uploading file_3.dat - chunk 8/10 [5.6s]\n",
      "\tüìä File Upload: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë| 96.7% (29/30) - Uploading file_3.dat - chunk 9/10 [5.9s]\n",
      "\tüìä File Upload: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100.0% (30/30) - Uploading file_3.dat - chunk 10/10 [6.1s]\n",
      "\n",
      "\u001b[2;36m[08/23/25 11:19:41]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Server log: üéâ Upload completed: \u001b[1;36m3\u001b[0m    \u001b]8;id=658055;file:///Users/macm1/Documents/web/portafolio/posts/MCP_streamable_client/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\u001b\\\\\u001b[2mlogging.py\u001b[0m\u001b]8;;\u001b\\\\\u001b[2m:\u001b[0m\u001b]8;id=313220;file:///Users/macm1/Documents/web/portafolio/posts/MCP_streamable_client/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#40\u001b\\\\\u001b[2m40\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         files                                 \u001b[2m             \u001b[0m\n",
      "‚úÖ Upload completed in 6.06s\n",
      "üìÅ Uploaded files: 3\n",
      "\n",
      "============================================================\n",
      "üì° DEMO: Real-time Monitoring\n",
      "============================================================\n",
      "Executing realtime_monitoring tool:\n",
      "\u001b[2;36m[08/23/25 11:19:42]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Server log: üì° Starting monitoring    \u001b]8;id=50717;file:///Users/macm1/Documents/web/portafolio/posts/MCP_streamable_client/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\u001b\\\\\u001b[2mlogging.py\u001b[0m\u001b]8;;\u001b\\\\\u001b[2m:\u001b[0m\u001b]8;id=158771;file:///Users/macm1/Documents/web/portafolio/posts/MCP_streamable_client/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#40\u001b\\\\\u001b[2m40\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         for \u001b[1;36m20\u001b[0m seconds\u001b[33m...\u001b[0m                     \u001b[2m             \u001b[0m\n",
      "\tüìä Monitoring: |‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 10.0% (1/10) - Monitoring active - CPU: 57%, MEM: 62%, NET: 211KB/s [0.0s]\n",
      "\tüìä Monitoring: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 20.0% (2/10) - Monitoring active - CPU: 31%, MEM: 48%, NET: 675KB/s [2.0s]\n",
      "\tüìä Monitoring: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 30.0% (3/10) - Monitoring active - CPU: 45%, MEM: 71%, NET: 721KB/s [4.0s]\n",
      "\tüìä Monitoring: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 40.0% (4/10) - Monitoring active - CPU: 62%, MEM: 87%, NET: 879KB/s [6.0s]\n",
      "\tüìä Monitoring: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 50.0% (5/10) - Monitoring active - CPU: 29%, MEM: 55%, NET: 120KB/s [8.0s]\n",
      "\tüìä Monitoring: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 60.0% (6/10) - Monitoring active - CPU: 80%, MEM: 77%, NET: 819KB/s [10.0s]\n",
      "\tüìä Monitoring: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 70.0% (7/10) - Monitoring active - CPU: 59%, MEM: 69%, NET: 438KB/s [12.0s]\n",
      "\tüìä Monitoring: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 80.0% (8/10) - Monitoring active - CPU: 73%, MEM: 68%, NET: 774KB/s [14.0s]\n",
      "\tüìä Monitoring: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë| 90.0% (9/10) - Monitoring active - CPU: 68%, MEM: 42%, NET: 528KB/s [16.0s]\n",
      "\tüìä Monitoring: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100.0% (10/10) - Monitoring active - CPU: 69%, MEM: 42%, NET: 707KB/s [18.0s]\n",
      "\n",
      "\u001b[2;36m[08/23/25 11:20:02]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Server log: üìä Monitoring completed:  \u001b]8;id=795212;file:///Users/macm1/Documents/web/portafolio/posts/MCP_streamable_client/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\u001b\\\\\u001b[2mlogging.py\u001b[0m\u001b]8;;\u001b\\\\\u001b[2m:\u001b[0m\u001b]8;id=762919;file:///Users/macm1/Documents/web/portafolio/posts/MCP_streamable_client/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#40\u001b\\\\\u001b[2m40\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[1;36m10\u001b[0m data points                        \u001b[2m             \u001b[0m\n",
      "‚úÖ Monitoring completed in 20.03s\n",
      "üìä Average CPU: 57.3%\n",
      "üíæ Average memory: 62.1%\n",
      "\n",
      "====================================================================================================\n",
      "üìà EXECUTION SUMMARY\n",
      "====================================================================================================\n",
      "\t‚úÖ SUCCESS long_running_task: 8.03s (8 updates)\n",
      "\t‚úÖ SUCCESS streaming_data_processor: 5.03s (10 updates)\n",
      "\t‚úÖ SUCCESS file_upload_simulation: 6.06s (30 updates)\n",
      "\t‚úÖ SUCCESS realtime_monitoring: 20.03s (10 updates)\n",
      "\n",
      "üìä Total: 4/4 successful tasks\n",
      "‚è±Ô∏è  Total time: 39.14s\n"
     ]
    }
   ],
   "source": [
    "!cd MCP_streamable_client && source .venv/bin/activate && uv run client.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cf7c92",
   "metadata": {},
   "source": [
    "Como se pode ver, obtivemos do servidor o processo de cada uma das execu√ß√µes das tools."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "maximofn": {
   "date": "2025-08-23",
   "description_en": "Learn how to implement real-time streaming in MCP (Model Context Protocol) applications using FastMCP. This comprehensive guide shows you how to create MCP servers and clients that support progress updates and streaming information for long-running tasks. You'll build streaming-enabled tools that provide real-time feedback during data processing, file uploads, monitoring tasks, and other time-intensive operations. Discover how to use StreamableHttpTransport, implement progress handlers with Context, and create visual progress bars that enhance user experience when working with MCP applications that require continuous feedback.",
   "description_es": "Aprende c√≥mo implementar streaming en tiempo real en aplicaciones MCP (Model Context Protocol) usando FastMCP. Esta gu√≠a completa te muestra c√≥mo crear servidores y clientes MCP que soportan actualizaciones de progreso e informaci√≥n streaming para tareas de larga duraci√≥n. Construir√°s herramientas habilitadas para streaming que proporcionan retroalimentaci√≥n en tiempo real durante el procesamiento de datos, subida de archivos, tareas de monitoreo y otras operaciones que requieren mucho tiempo. Descubre c√≥mo usar StreamableHttpTransport, implementar manejadores de progreso con Context y crear barras de progreso visuales que mejoran la experiencia del usuario al trabajar con aplicaciones MCP que requieren retroalimentaci√≥n continua.",
   "description_pt": "Aprenda como implementar streaming em tempo real em aplica√ß√µes MCP (Model Context Protocol) usando FastMCP. Este guia abrangente mostra como criar servidores e clientes MCP que suportam atualiza√ß√µes de progresso e informa√ß√µes streaming para tarefas de longa dura√ß√£o. Voc√™ construir√° ferramentas habilitadas para streaming que fornecem feedback em tempo real durante processamento de dados, upload de arquivos, tarefas de monitoramento e outras opera√ß√µes que demandam muito tempo. Descubra como usar StreamableHttpTransport, implementar manipuladores de progresso com Context e criar barras de progresso visuais que melhoram a experi√™ncia do usu√°rio ao trabalhar com aplica√ß√µes MCP que requerem feedback cont√≠nuo.",
   "end_url": "streamable-mcp",
   "image": "https://images.maximofn.com/streamableMCP_resized.webp",
   "image_hover_path": "https://images.maximofn.com/streamableMCP_resized.webp",
   "keywords_en": "MCP Streaming, Model Context Protocol, FastMCP, Real-time Progress, StreamableHttpTransport, Progress Handlers, Context Progress, Visual Progress Bars, Long-running Tasks, Data Processing Streaming, File Upload Progress, Real-time Monitoring, MCP Client Server, Python Streaming, Uvicorn Server, Anthropic MCP, Tool Progress Updates",
   "keywords_es": "MCP Streaming, Model Context Protocol, FastMCP, Progreso en Tiempo Real, StreamableHttpTransport, Manejadores de Progreso, Context Progress, Barras de Progreso Visuales, Tareas de Larga Duraci√≥n, Streaming de Procesamiento de Datos, Progreso de Subida de Archivos, Monitoreo en Tiempo Real, Cliente Servidor MCP, Python Streaming, Servidor Uvicorn, Anthropic MCP, Actualizaciones de Progreso de Herramientas",
   "keywords_pt": "MCP Streaming, Model Context Protocol, FastMCP, Progresso em Tempo Real, StreamableHttpTransport, Manipuladores de Progresso, Context Progress, Barras de Progresso Visuais, Tarefas de Longa Dura√ß√£o, Streaming de Processamento de Dados, Progresso de Upload de Arquivos, Monitoramento em Tempo Real, Cliente Servidor MCP, Python Streaming, Servidor Uvicorn, Anthropic MCP, Atualiza√ß√µes de Progresso de Ferramentas",
   "title_en": "Stream Information in MCP: Complete Guide to Real-time Progress Updates with FastMCP",
   "title_es": "Stream informaci√≥n en MCP: Gu√≠a Completa para Actualizaciones de Progreso en Tiempo Real con FastMCP",
   "title_pt": "Stream Informa√ß√µes em MCP: Guia Completo para Atualiza√ß√µes de Progresso em Tempo Real com FastMCP"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
