<?xml version='1.0' encoding='utf-8'?>
<notebook>
  <markdown># FastRTC: A Biblioteca de Comunica√ß√£o em Tempo Real para Python</markdown>
  <markdown> &gt; Aviso: Este post foi traduzido para o portugu√™s usando um modelo de tradu√ß√£o autom√°tica. Por favor, me avise se encontrar algum erro.</markdown>
  <markdown>Nos √∫ltimos meses, temos visto um grande avan√ßo em modelos de voz em tempo real, com empresas inteiras fundadas ao redor de modelos tanto de c√≥digo aberto quanto fechado. Alguns marcos importantes incluem:

* ``OpenAI`` e ``Google`` lan√ßaram suas APIs multimodais ao vivo para ChatGPT e Gemini. ¬°A OpenAI at√© lan√ßou um n√∫mero de telefone ``1-800-ChatGPT``!
* ``Kyutai`` lan√ßou [Moshi](https://huggingface.co/kyutai), um LLM de √°udio para √°udio totalmente de c√≥digo aberto.
* ``Alibaba`` lan√ßou [Qwen2-Audio](https://huggingface.co/Qwen/Qwen2-Audio-7B-Instruct), um LLM de c√≥digo aberto que entende √°udio de forma nativa.
* ``Fixie.ai`` lan√ßou [Ultravox](https://huggingface.co/fixie-ai/ultravox-v0_5-llama-3_3-70b), outro LLM de c√≥digo aberto que tamb√©m entende √°udio de forma nativa.
* ``ElevenLabs`` arrecadou 180 milh√µes de d√≥lares na sua S√©rie C.
</markdown>
  <markdown>Apesar desta explos√£o em modelos e financiamento, ainda √© dif√≠cil construir aplica√ß√µes de IA em tempo real que transmitam √°udio e v√≠deo, especialmente em Python.

* Os engenheiros de ML podem n√£o ter experi√™ncia com as tecnologias necess√°rias para construir aplica√ß√µes em tempo real, como ``WebRTC``.
* Mesmo ferramentas de assist√™ncia de c√≥digo como ``Cursor`` e ``Copilot`` t√™m dificuldades em escrever c√≥digo Python que suporte aplica√ß√µes de √°udio/v√≠deo em tempo real.
Por isso √© empolgante o an√∫ncio de `FastRTC`, a biblioteca de comunica√ß√£o em tempo real para Python. A biblioteca foi projetada para facilitar a constru√ß√£o de aplica√ß√µes de IA de √°udio e v√≠deo em tempo real totalmente em Python!
</markdown>
  <markdown>## Principais caracter√≠sticas de FastRTC</markdown>
  <markdown>* üó£Ô∏è Detec√ß√£o de voz autom√°tica e gerenciamento de turnos integrado, para que voc√™ s√≥ precise se preocupar com a l√≥gica de resposta ao usu√°rio.
* üíª UI autom√°tica - UI do Gradio habilitada para WebRTC integrada para testes (ou implanta√ß√£o em produ√ß√£o!).
* üìû Chamada telef√¥nica - Use ``fastphone()`` para obter um n√∫mero de telefone **gratuito** para ligar para o seu fluxo de √°udio (√© necess√°rio um token HF).
* ‚ö°Ô∏è Suporte para ``WebRTC`` e ``Websocket``.
* üí™ Personaliz√°vel - Voc√™ pode montar o stream em qualquer aplica√ß√£o ``FastAPI`` para servir uma UI personalizada e implantar al√©m do ``Gradio``.
* üß∞ Muitas utilidades para ``text-to-speech``, ``speech-to-text``, ``detec√ß√£o de parada`` para te ajudar a come√ßar.
</markdown>
  <markdown>## Instala√ß√£o</markdown>
  <markdown>Para poder usar `FastRTC`, primeiro voc√™ precisa instalar a biblioteca:

``` bash
pip install fastrtc
```

Mas se quisermos instalar as funcionalidades de detec√ß√£o de pausa, speech-to-text e text-to-speech, precisamos instalar algumas depend√™ncias adicionais:

``` bash
pip install "fastrtc[vad, stt, tts]"
```
</markdown>
  <markdown>## Primeiros passos</markdown>
  <markdown>Come√ßaremos construindo o `ol√° mundo` do √°udio em tempo real: fazer eco do que o usu√°rio diz. Em `FastRTC`, isso √© t√£o simples quanto:</markdown>
  <input_code>from fastrtc import Stream, ReplyOnPause
import numpy as np

def echo(audio: tuple[int, np.ndarray]) -&gt; tuple[int, np.ndarray]:
    yield audio

stream = Stream(ReplyOnPause(echo), modality="audio", mode="send-receive")
stream.ui.launch()</input_code>
  <output_code>* Running on local URL:  http://127.0.0.1:7872

To create a public link, set `share=True` in `launch()`.
</output_code>
  <output_code>&lt;IPython.core.display.HTML object&gt;</output_code>
  <output_code />
  <output_code>INFO:     127.0.0.1:58223 - "GET / HTTP/1.1" 200 OK
INFO:     127.0.0.1:58223 - "GET /assets/index-C7PS0jJm.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58225 - "GET /assets/index-Bo0Yq5bb.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58223 - "GET /assets/svelte/svelte.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58225 - "GET /assets/Embed-FUIL71FR.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58223 - "GET /assets/Index-wMEhc4G9.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58228 - "GET /assets/StreamingBar-DOagx4HU.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58227 - "GET /assets/index-B1gfMDT9.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58230 - "GET /assets/IconButtonWrapper-EOzMzU45.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58229 - "GET /assets/StreamingBar.svelte_svelte_type_style_lang-CDNxkBIr.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58225 - "GET /assets/MarkdownCode-DPiWQnAx.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58223 - "GET /assets/DownloadLink-CqD3Uu0l.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58227 - "GET /assets/IconButtonWrapper.svelte_svelte_type_style_lang-BOpxTcdu.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58229 - "GET /assets/prism-python-qapVsvY8.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58228 - "GET /assets/Index-BJ_RfjVB.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58230 - "GET /assets/MarkdownCode.svelte_svelte_type_style_lang-3tofWDHK.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58225 - "GET /assets/IconButton-B-aAVSzy.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58229 - "GET /assets/Clear-By3xiIwg.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58228 - "GET /assets/context-TgWPFwN2.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58230 - "GET /theme.css?v=63194d3741d384f9f85db890247b6c0ef9e7abac0f297f40a15c59fe4baba916 HTTP/1.1" 200 OK
INFO:     127.0.0.1:58228 - "GET /assets/Button-BWSOH8Qq.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58225 - "GET /assets/Image-CsmDAdIf.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58229 - "GET /assets/Blocks-E57YC_S0.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58227 - "GET /assets/Button-DTh9AgeE.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58223 - "GET /assets/Image-B8dFOee4.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58230 - "GET /assets/ImagePreview-DJhr8Mfv.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58223 - "GET /assets/file-url-DgijyRSD.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58225 - "GET /assets/Dropdown-CWxB-qJp.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58228 - "GET /assets/Example-D7K5RtQ2.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58227 - "GET /assets/Blocks-B5wxaDIo.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58229 - "GET /assets/Dropdown-DjrBHETv.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58230 - "GET /assets/Block-DZqtZLFP.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58228 - "GET /assets/BlockTitle-BIcnzvtg.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58225 - "GET /assets/index-CvpmwOJi.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58223 - "GET /assets/MarkdownCode-DJM7o_VY.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58230 - "GET /assets/Info-DcCn6tHi.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58227 - "GET /assets/DropdownArrow-dYuMZY9s.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58229 - "GET /assets/Toast-DdWZrg4w.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58230 - "GET /assets/utils-BsGrhMNe.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58223 - "GET /gradio_api/custom_component/91a0d0cc3e6164063c775a057aff53510cb8fc04c8b99d010e09ce4ba9beb99d/client/component/style.css HTTP/1.1" 304 Not Modified
INFO:     127.0.0.1:58230 - "GET /assets/Index-ChJkSByh.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58227 - "GET /assets/Index-CfowPFmo.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58228 - "GET /assets/Index-CptIZeFZ.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58229 - "GET /assets/Index-Csm0OGa9.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58225 - "GET /assets/Index-Cgj6KPvj.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58223 - "GET /assets/Code-DGNrTu_I.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58225 - "GET /gradio_api/custom_component/91a0d0cc3e6164063c775a057aff53510cb8fc04c8b99d010e09ce4ba9beb99d/client/component/index.js HTTP/1.1" 304 Not Modified
INFO:     127.0.0.1:58228 - "GET /assets/Index-HXWviefR.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58229 - "GET /assets/Index-WEzAIkMk.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58230 - "GET /assets/BlockLabel-DqHge3FF.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58227 - "GET /assets/Index-CRGGsrTx.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58241 - "GET / HTTP/1.1" 200 OK
INFO:     127.0.0.1:58241 - "GET /theme.css?v=63194d3741d384f9f85db890247b6c0ef9e7abac0f297f40a15c59fe4baba916 HTTP/1.1" 200 OK
INFO:     127.0.0.1:58241 - "GET /gradio_api/custom_component/91a0d0cc3e6164063c775a057aff53510cb8fc04c8b99d010e09ce4ba9beb99d/client/component/style.css HTTP/1.1" 304 Not Modified
INFO:     127.0.0.1:58244 - "GET /gradio_api/custom_component/91a0d0cc3e6164063c775a057aff53510cb8fc04c8b99d010e09ce4ba9beb99d/client/component/index.js HTTP/1.1" 304 Not Modified
INFO:     127.0.0.1:58260 - "GET /static/fonts/ui-sans-serif/ui-sans-serif-Bold.woff2 HTTP/1.1" 404 Not Found
INFO:     127.0.0.1:58260 - "GET /static/fonts/system-ui/system-ui-Bold.woff2 HTTP/1.1" 404 Not Found
</output_code>
  <markdown>Quando vamos ao link que o Gradio sugere, primeiro temos que dar permiss√µes ao navegador para acessar o microfone. A seguir, aparecer√° isto

![fastrct - hello world - init](https://images.maximofn.com/fastRTC%20-%20hello%20world%20-%20init.webp)
</markdown>
  <markdown>Se clicarmos na guia √† direita da palavra `Record`, podemos selecionar o microfone que queremos usar.</markdown>
  <markdown>Ao clicar no bot√£o `Record`, tudo o que dissermos ser√° repetido pelo aplicativo. Isso significa que ele captura o √°udio, detecta quando paramos de falar e o repete.</markdown>
  <markdown>Vamos a desmembr√°-lo:

* `ReplyOnPause` ir√° tratar a detec√ß√£o de voz e a passagem de turnos para voc√™. Voc√™ s√≥ precisa se preocupar com a l√≥gica para responder ao usu√°rio. √â necess√°rio passar a fun√ß√£o que ser√° respons√°vel por gerenciar o √°udio de entrada. No nosso caso, √© a fun√ß√£o `echo`, que captura o √°udio de entrada e o retorna em stream usando `yield`, que muitas pessoas n√£o conhecem, mas √© um gerador, ou seja, √© um m√©todo do Python para criar iteradores. Se quiser saber mais sobre `yield`, pode ler meu post sobre [Python](https://www.maximofn.com/python#6.5.-Generadores). Qualquer gerador que retorne uma tupla de √°udio (representada como `(sample_rate, audio_data)`) funcionar√°.* A classe `Stream` construir√° uma UI do Gradio para que voc√™ possa testar rapidamente seu stream. Uma vez que voc√™ tenha terminado de prototipar, voc√™ pode implantar seu Stream como um aplicativo FastAPI pronto para produ√ß√£o em uma √∫nica linha de c√≥digo
</markdown>
  <markdown>Aqui podemos ver um exemplo dos criadores de `FastRTC`

&lt;video src="https://github.com/user-attachments/assets/fcf2d30e-3e98-47c9-8dc3-23340784c441" controls&gt;&lt;/video&gt;
</markdown>
  <markdown>## Subindo de n√≠vel: Bate-papo de voz com LLM</markdown>
  <markdown>O pr√≥ximo n√≠vel √© usar um LLM para responder ao usu√°rio. `FastRTC` vem com capacidades de ``speech-to-text`` e ``text-to-speech`` incorporadas, portanto trabalhar com LLMs √© realmente f√°cil. Vamos alterar nossa fun√ß√£o `echo` accordingly:</markdown>
  <input_code>from fastrtc import ReplyOnPause, Stream, get_stt_model, get_tts_model
from gradio_client import Client

client = Client("Maximofn/SmolLM2_localModel")
stt_model = get_stt_model()
tts_model = get_tts_model()

def echo(audio):
    prompt = stt_model.stt(audio)
    response = client.predict(
            message=prompt,
            system_message="You are a friendly Chatbot. Always reply in the language in which the user is writing to you.",
            max_tokens=512,
            temperature=0.7,
            top_p=0.95,
            api_name="/chat"
    )
    prompt = response
    for audio_chunk in tts_model.stream_tts_sync(prompt):
        yield audio_chunk

stream = Stream(ReplyOnPause(echo), modality="audio", mode="send-receive")
stream.ui.launch()</input_code>
  <output_code>Loaded as API: https://maximofn-smollm2-localmodel.hf.space ‚úî
* Running on local URL:  http://127.0.0.1:7871

To create a public link, set `share=True` in `launch()`.
</output_code>
  <output_code>&lt;IPython.core.display.HTML object&gt;</output_code>
  <output_code />
  <output_code>INFO:     127.0.0.1:58224 - "GET / HTTP/1.1" 200 OK
INFO:     127.0.0.1:58224 - "GET /assets/index-Bo0Yq5bb.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58226 - "GET /assets/index-C7PS0jJm.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58226 - "GET /assets/svelte/svelte.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58226 - "GET /assets/Index-wMEhc4G9.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58232 - "GET /assets/StreamingBar-DOagx4HU.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58234 - "GET /assets/IconButtonWrapper-EOzMzU45.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58224 - "GET /assets/Embed-FUIL71FR.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58233 - "GET /assets/StreamingBar.svelte_svelte_type_style_lang-CDNxkBIr.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58231 - "GET /assets/index-B1gfMDT9.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58231 - "GET /assets/MarkdownCode-DPiWQnAx.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58224 - "GET /assets/MarkdownCode.svelte_svelte_type_style_lang-3tofWDHK.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58233 - "GET /assets/Index-BJ_RfjVB.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58232 - "GET /assets/DownloadLink-CqD3Uu0l.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58234 - "GET /assets/IconButtonWrapper.svelte_svelte_type_style_lang-BOpxTcdu.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58226 - "GET /assets/prism-python-qapVsvY8.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58231 - "GET /assets/IconButton-B-aAVSzy.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58233 - "GET /assets/Clear-By3xiIwg.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58234 - "GET /assets/context-TgWPFwN2.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58224 - "GET /theme.css?v=63194d3741d384f9f85db890247b6c0ef9e7abac0f297f40a15c59fe4baba916 HTTP/1.1" 200 OK
INFO:     127.0.0.1:58234 - "GET /assets/Blocks-E57YC_S0.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58231 - "GET /assets/Image-B8dFOee4.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58226 - "GET /assets/ImagePreview-DJhr8Mfv.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58233 - "GET /assets/Button-BWSOH8Qq.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58232 - "GET /assets/Button-DTh9AgeE.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58224 - "GET /assets/Dropdown-CWxB-qJp.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58232 - "GET /assets/Image-CsmDAdIf.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58226 - "GET /assets/Blocks-B5wxaDIo.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58233 - "GET /assets/Example-D7K5RtQ2.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58234 - "GET /assets/Block-DZqtZLFP.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58231 - "GET /assets/file-url-DgijyRSD.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58224 - "GET /assets/Info-DcCn6tHi.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58232 - "GET /assets/MarkdownCode-DJM7o_VY.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58234 - "GET /assets/Dropdown-DjrBHETv.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58233 - "GET /assets/index-CvpmwOJi.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58226 - "GET /assets/BlockTitle-BIcnzvtg.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58231 - "GET /assets/DropdownArrow-dYuMZY9s.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58224 - "GET /assets/Toast-DdWZrg4w.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58234 - "GET /assets/utils-BsGrhMNe.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58232 - "GET /assets/Index-CfowPFmo.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58234 - "GET /assets/Index-ChJkSByh.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58224 - "GET /assets/Code-DGNrTu_I.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58226 - "GET /assets/Index-Csm0OGa9.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58233 - "GET /assets/Index-HXWviefR.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58231 - "GET /assets/BlockLabel-DqHge3FF.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58224 - "GET /gradio_api/custom_component/91a0d0cc3e6164063c775a057aff53510cb8fc04c8b99d010e09ce4ba9beb99d/client/component/style.css HTTP/1.1" 304 Not Modified
INFO:     127.0.0.1:58231 - "GET /assets/Index-Cgj6KPvj.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58233 - "GET /gradio_api/custom_component/91a0d0cc3e6164063c775a057aff53510cb8fc04c8b99d010e09ce4ba9beb99d/client/component/index.js HTTP/1.1" 304 Not Modified
INFO:     127.0.0.1:58226 - "GET /assets/Index-CptIZeFZ.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:58232 - "GET /assets/Index-CRGGsrTx.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58234 - "GET /assets/Index-WEzAIkMk.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:58242 - "GET / HTTP/1.1" 200 OK
INFO:     127.0.0.1:58242 - "GET /theme.css?v=63194d3741d384f9f85db890247b6c0ef9e7abac0f297f40a15c59fe4baba916 HTTP/1.1" 200 OK
INFO:     127.0.0.1:58242 - "GET /gradio_api/custom_component/91a0d0cc3e6164063c775a057aff53510cb8fc04c8b99d010e09ce4ba9beb99d/client/component/style.css HTTP/1.1" 304 Not Modified
INFO:     127.0.0.1:58243 - "GET /gradio_api/custom_component/91a0d0cc3e6164063c775a057aff53510cb8fc04c8b99d010e09ce4ba9beb99d/client/component/index.js HTTP/1.1" 304 Not Modified
INFO:     127.0.0.1:58250 - "GET /static/fonts/ui-sans-serif/ui-sans-serif-Bold.woff2 HTTP/1.1" 404 Not Found
INFO:     127.0.0.1:58250 - "GET /static/fonts/system-ui/system-ui-Bold.woff2 HTTP/1.1" 404 Not Found
</output_code>
  <markdown>Como modelo de ``speech-to-text`` use ``Moonshine``, que supostamente s√≥ suporta ingl√™s, mas eu o testei em espanhol e ele entende bem.</markdown>
  <markdown>Como modelo de linguagem vamos usar o modelo que desployei em um backend no Hugging Face e que escrevi no post [Desplegar backend com LLM em HuggingFace](https://www.maximofn.com/deploy-backend-with-llm-in-huggingface). Utiliza o LLM `HuggingFaceTB/SmolLM2-1.7B-Instruct` que √© um modelo pequeno, j√° que est√° rodando em um backend com CPU, mas que funciona bastante bem.</markdown>
  <markdown>Como modelo de ``text-to-speech`` use ``Kokoro`` que sim tem op√ß√µes de falar em outros idiomas, mas que por enquanto na biblioteca `FastRTC` ainda n√£o est√° implementado.</markdown>
  <markdown>Se nos interessa muito usar modelos de `speech-to-speech` e `text-to-speech` em outros idiomas, poder√≠amos implement√°-los n√≥s mesmos, pois o maior potencial do `FastRTC` est√° na camada de comunica√ß√£o em tempo real, mas n√£o vou me aprofundar nisso agora.</markdown>
  <markdown>Agora, se testarmos o c√≥digo que acabamos de escrever, podemos ter um chatbot, por voz em tempo real.</markdown>
  <markdown>## Chamada telef√¥nica

Se voc√™ chamar `stream.fastphone()` em vez de `stream.ui.launch()`, obter√° um n√∫mero de telefone gratuito para ligar para o seu stream. Tenha em mente que √© necess√°rio um token do Hugging Face.

Geramos um script, pois nem sempre funciona em um Jupyter Notebook.
</markdown>
  <input_code>%%writefile fastrtc_phone_demo.py

from fastrtc import ReplyOnPause, Stream, get_stt_model, get_tts_model
import gradio
from gradio_client import Client
import os
from gradio.networking import setup_tunnel as original_setup_tunnel
import socket

# Monkey patch setup_tunnel para que acepte el par√°metro adicional
def patched_setup_tunnel(host, port, share_token, share_server_address, share_server_tls_certificate=None):
    return original_setup_tunnel(host, port, share_token, share_server_address, share_server_tls_certificate)

# Replace the original function with our patched version
gradio.networking.setup_tunnel = patched_setup_tunnel

# Get the token from the environment variable
HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN = os.getenv("HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN")

# Initialize the LLM client
llm_client = Client("Maximofn/SmolLM2_localModel")

# Initialize the STT and TTS models
stt_model = get_stt_model()
tts_model = get_tts_model()

# Define the echo function
def echo(audio):
    # Convert the audio to text
    prompt = stt_model.stt(audio)

    # Generate the response
    response = llm_client.predict(
            message=prompt,
            system_message="You are a friendly Chatbot. Always reply in the language in which the user is writing to you.",
            max_tokens=512,
            temperature=0.7,
            top_p=0.95,
            api_name="/chat"
    )
    
    # Convert the response to audio
    prompt = response

    # Stream the audio
    for audio_chunk in tts_model.stream_tts_sync(prompt):
        yield audio_chunk

def find_free_port(start_port=8000, max_port=9000):
    """Find the first free port starting from start_port."""
    print(f"Searching for a free port starting from {start_port}...")
    for port in range(start_port, max_port):
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
            result = sock.connect_ex(('127.0.0.1', port))
            if result != 0:  # If result != 0, the port is free
                print(f"Free port found: {port}")
                return port
    raise RuntimeError(f"No free port found between {start_port} and {max_port}")
    
free_port = find_free_port()    # Search for a free port

stream = Stream(ReplyOnPause(echo), modality="audio", mode="send-receive")
stream.fastphone(token=HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN, port=free_port)</input_code>
  <markdown>Explicamos o c√≥digo</markdown>
  <markdown>A parte

``` pyhon
# Monkey patch setup_tunnel para aceitar o par√¢metro adicional
def patched_setup_tunnel(host, port, share_token, share_server_address, share_server_tls_certificate=None):
return original_setup_tunnel(host, port, share_token, share_server_address, share_server_tls_certificate)

# Substitua a fun√ß√£o original pela nossa vers√£o patchadagradio.networking.setup_tunnel = patched_setup_tunnel
```

√â necess√°rio porque `FastRTC` foi escrito para uma vers√£o antiga do `gradio` que n√£o suporta o par√¢metro `share_server_address` no m√©todo `setup_tunnel`. Ent√£o, n√≥s o patcheamos para aceitar o par√¢metro adicional.
</markdown>
  <markdown>Como √© necess√°rio um token do Hugging Face, obtemos o token da vari√°vel de ambiente `HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN`.

``` python
# Obtenha o token da vari√°vel de ambiente
HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN = os.getenv("HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN")
```
</markdown>
  <markdown>A seguir s√£o criados os modelos de linguagem, de `speech-to-text` e de `text-to-speech`, e criamos a fun√ß√£o `echo` que ser√° respons√°vel por gerenciar o √°udio de entrada e sa√≠da.

``` python
# Inicialize o cliente LLM
llm_client = Client("Maximofn/SmolLM2_localModel")

# Inicialize os modelos STT e TTS
stt_model = get_stt_model()
tts_model = get_tts_model()

# Defina a fun√ß√£o echo
def eco(√°udio):
# Converter o √°udio em texto
prompt = stt_model.stt(audio)

# Gerar a resposta
resposta = llm_client.predict(
message=prompt,
Entendido. Estou pronto para traduzir o texto markdown para o portugu√™s conforme solicitado. Por favor, forne√ßa o texto que deseja traduzir.max_tokens=512,
temperature=0.7,
top_p=0,95,
api_name="/chat"
)
    
# Converter a resposta em √°udio
prompt = resposta

# Transmita o √°udio
for audio_chunk in tts_model.stream_tts_sync(prompt):
yield audio_chunk
```
</markdown>
  <markdown>Como antes usamos a porta `8000`, caso voc√™s digam que ela est√° ocupada, criamos uma fun√ß√£o para encontrar uma porta livre e encontramos uma.

``` python
def find_free_port(start_port=8000, max_port=9000):
"""Encontre a primeira porta livre a partir de start_port."""
print(f"Procurando uma porta livre a partir de {start_port}...")
for port in range(start_port, max_port):
com socket.socket(socket.AF_INET, socket.SOCK_STREAM) como sock:
result = sock.connect_ex(('127.0.0.1', port))
if result != 0:  # Se result != 0, a porta est√° livre
print(f"Porta livre encontrada: {port}")
retornar portugu√™s
raise RuntimeError(f"Nenhuma porta livre encontrada entre {start_port} e {max_port}")
    
porta_livre = encontrar_porta_livre()    # Procurar uma porta livre
```
</markdown>
  <markdown>O fluxo √© criado e agora `stream.fastphone()` √© usado para obter um n√∫mero de telefone gratuito para ligar ao seu fluxo, em vez de `stream.ui.launch()`, que usamos anteriormente para criar a interface gr√°fica.

``` python
stream = Stream(ReplyOnPause(echo), modality="audio", mode="send-receive")
stream.fastphone(token=HUGGINGFACE_FASTRTC_PHONE_CALL_TOKEN, port=free_port)
```
</markdown>
  <markdown>Se o executarmos, veremos algo assim:</markdown>
  <input_code>!python fastrtc_phone_demo.py</input_code>
  <output_code>Loaded as API: https://maximofn-smollm2-localmodel.hf.space ‚úî
[32mINFO[0m:	  Warming up STT model.
[32mINFO[0m:	  STT model warmed up.
[32mINFO[0m:	  Warming up VAD model.
[32mINFO[0m:	  VAD model warmed up.
Searching for a free port starting from 8000...
Free port found: 8004
[32mINFO[0m:     Started server process [[36m24029[0m]
[32mINFO[0m:     Waiting for application startup.
[32mINFO[0m:	  Visit [36mhttps://fastrtc.org/userguide/api/[0m for WebRTC or Websocket API docs.
[32mINFO[0m:     Application startup complete.
[32mINFO[0m:     Uvicorn running on [1mhttp://127.0.0.1:8004[0m (Press CTRL+C to quit)
[32mINFO[0m:	  Your FastPhone is now live! Call [36m+1 877-713-4471[0m and use code [36m994514[0m to connect to your stream.
[32mINFO[0m:	  You have [36m30:00[0m minutes remaining in your quota (Resetting on [36m2025-04-07[0m)
[32mINFO[0m:	  Visit [36mhttps://fastrtc.org/userguide/audio/#telephone-integration[0m for information on making your handler compatible with phone usage.
</output_code>
  <markdown>Vemos que aparece

``` bash
INFO: Seu FastPhone est√° agora ativo! Ligue para +1 877-713-4471 e use o c√≥digo 994514 para se conectar ao seu stream.
INFO: Voc√™ tem 30:00 minutos restantes em sua cota (Redefinindo em 2025-04-07)
```

Isto √©, se ligarmos para o n√∫mero `+1 877-713-4471` e usarmos o c√≥digo `994514`, seremos conectados ao nosso stream.
</markdown>
  <markdown>Se formos at√© [Telephone Integration](https://fastrtc.org/userguide/audio/#telephone-integration) da documenta√ß√£o de `FastRTC`, veremos que usa [twilio](https://www.twilio.com/) para fazer a chamada. Tem op√ß√£o para configurar um n√∫mero local nos Estados Unidos, Dublin, Frankfurt, T√≥quio, Singapura, Sydney e S√£o Paulo.</markdown>
  <markdown>Tente testeado fazer a chamada da Espanha (o que vai me custar bastante) e funciona, mas √© lento. Liguei, inseri o c√≥digo e fiquei esperando para ser conectado com o agente, mas como estava demorando muito, desliguei.</markdown>
</notebook>