<section class="section-block-markdown-cell">
<h1 id="DataLoader-+-pin_memory">DataLoader + pin_memory<a class="anchor-link" href="#DataLoader-+-pin_memory">¶</a></h1>
</section>
<section class="section-block-markdown-cell">
<p>En PyTorch, cuando se entrenan redes neuronales, especialmente en grandes conjuntos de datos, aprovechar el <code>DataLoader</code> con <code>pin_memory=True</code> y establecer <code>num_workers</code> en un número positivo aumenta significativamente el rendimiento.</p>
</section>
<section class="section-block-markdown-cell">
<p><code>pin_memory=True</code> permite una transferencia más rápida de los datos a la GPU manteniéndolos en memoria <code>pinned</code> (bloqueada por página).</p>
</section>
<section class="section-block-markdown-cell">
<p>Al mismo tiempo, <code>num_workers</code> determina el número de subprocesos utilizados para la carga de datos, lo que permite la obtención asíncrona de datos sin bloquear el cálculo de la GPU</p>
</section>
<section class="section-block-markdown-cell">
<p>Esta combinación minimiza el tiempo de inactividad de la GPU, lo que garantiza un uso más eficiente de los recursos de hardware y tiempos de entrenamiento del modelo más rápidos.</p>
</section>
<section class="section-block-code-cell-">
<div class="input-code">
<div class="highlight hl-python"><pre><span></span><span class="n">data_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</section>
